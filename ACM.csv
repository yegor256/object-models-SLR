included in data,Item type,Authors,Title,Journal,Publication year,Volume,Issue,Pages,Publisher,Address,Book title,Proceedings title,Conference location,Date published,ISBN,ISSN,URLs,DOI,Abstract,Keywords,Series,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Sharma M,Gill NS,Sikka S",Survey of Object-Oriented Metrics: Focusing on Validation and Formal Specification,SIGSOFT Softw. Eng. Notes,2012,37,6,1–5,Association for Computing Machinery,"New York, NY, USA",,,,2012-11,,0163-5948,https://doi.org/10.1145/2382756.2382770;http://dx.doi.org/10.1145/2382756.2382770,10.1145/2382756.2382770,"To quantify various attributes of object-oriented software systems, numerous object-oriented metrics have been proposed by various researchers. This paper surveys existing object-oriented metrics by focusing on the two major issues-Validation and Formal Specification. This paper provides researchers with an understanding of existing object-oriented metrics in terms of validation and formal specification. Because few metrics are validated and formally specified, there is a need of both validation and formal specification of object-oriented metrics.","validation, object-oriented metric, formal specification",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shen X,Zhang P,Yang J,Chen W,Zhang L",Research on Object-Oriented Exploration Algorithm,,2020,,,59–64,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 International Conference on Cyberspace Innovation of Advanced Technologies,"Guangzhou, China",2020,9781450387828,,https://doi.org/10.1145/3444370.3444548;http://dx.doi.org/10.1145/3444370.3444548,10.1145/3444370.3444548,"In formal concept analysis, attribute exploration is a very important methodology, which can explore the logical laws between attributes in a continuous and interactive way. Object-oriented exploration is very meaningful while it is similar to attribute exploration. It can explore the implication relationship between objects. But for the existing work, almost all are attribute exploration, object-oriented exploration is rare. Research on object-oriented exploration has great practical value, such as object classification, retrieval and excavation. In order to address this problem, this article takes the object as the main research point in formal concept analysis based on related knowledge of traditional attribute exploration, and proposes theories of object-oriented exploration. According to these related theories and the framework of attribute exploration algorithm, an object-oriented exploration algorithm is proposed in this paper. The algorithm can be used to explore and understand the relationship between objects, which facilitates to understand better the relationship between objects and attributes.","Implication, Attribute exploration, Object exploration, Formal concept analysis, Concept lattice",CIAT 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Chen J,A Typed Intermediate Language for Supporting Interfaces,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Workshop on Formal Techniques for Java-like Programs,"Genova, Italy",2009,9781605585406,,https://doi.org/10.1145/1557898.1557899;http://dx.doi.org/10.1145/1557898.1557899,10.1145/1557898.1557899,"Object-oriented languages such as Java and C# provide interfaces to support a restricted form of multiple inheritance. Existing low-level typed intermediate languages for object-oriented languages, however, either do not support interfaces or require non-standard interface implementations. This paper describes a low-level typed intermediate language that can express the standard interface implementation strategies based on interface tables (itables). The language can faithfully model itables, the standard itable-based interface method invocation, and interface cast. The type system is sound and the type checking is decidable.",,FTfJP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Inostroza P,van der Storm T",JEff: Objects for Effect,,2018,,,111–124,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2018 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software","Boston, MA, USA",2018,9781450360319,,https://doi.org/10.1145/3276954.3276955;http://dx.doi.org/10.1145/3276954.3276955,10.1145/3276954.3276955,"Effect handling is a way to structure and scope side-effects which is gaining popularity as an alternative to monads in purely functional programming languages. Languages with support for effect handling allow the programmer to define idioms for state, exception handling, asynchrony, backtracking, etc. from within the language. Functional programming languages, however, prohibit certain patterns of modularity well-known from object-oriented languages. In this paper we introduce JEff, an object-oriented programming language with native support for effect handling, to provide first answers to the question what it would mean to integrate object-oriented programming with effect handling. We illustrate how user-defined effects could benefit from interface polymorphism, and present its runtime semantics and type system.","effect handling, object-oriented languages",Onward! 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Gupta V,Validation of Dynamic Coupling Metrics for Object-Oriented Software,SIGSOFT Softw. Eng. Notes,2011,36,5,1–3,Association for Computing Machinery,"New York, NY, USA",,,,2011-09,,0163-5948,https://doi.org/10.1145/2020976.2020985;http://dx.doi.org/10.1145/2020976.2020985,10.1145/2020976.2020985,"Dynamic coupling metrics for object-oriented software provide scope of coupling measurement up to the object level and take into account important and widely used object-oriented features such as inheritance, polymorphism and dynamic binding during measurement. The dynamic measures are computed at run-time, which take into consideration the actual interactions taking place among members of a class. In this paper, an attempt has been made to evaluate dynamic coupling metrics for object-oriented software using formal evaluation framework proposed by Briand et al. A practical and useful coupling measure must satisfy most of the properties given in this framework. The results of this study show that dynamic coupling metrics satisfy all properties and parameters required by the evaluation framework and thus dynamic coupling measures are robust and useful.","software metrics, dynamic metrics, coupling, object-oriented software",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Balzer S,Pfenning F",Objects as Session-Typed Processes,,2015,,,13–24,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 5th International Workshop on Programming Based on Actors, Agents, and Decentralized Control","Pittsburgh, PA, USA",2015,9781450339018,,https://doi.org/10.1145/2824815.2824817;http://dx.doi.org/10.1145/2824815.2824817,10.1145/2824815.2824817,"A key idea in object-oriented programming is that objects encapsulate state and interact with each other by message exchange. This perspective suggests a model of computation that is inherently concurrent (to facilitate simultaneous message exchange) and that accounts for the effect of message exchange on an object's state (to express valid sequences of state transitions). In this paper we show that such a model of computation arises naturally from session-based communication. We introduce an object-oriented programming language that has processes as its only objects and employs linear session types to express the protocols of message exchange and to reason about concurrency and state. Based on various examples we show that our language supports the typical patterns of object-oriented programming (e.g., encapsulation, dynamic dispatch, and subtyping) while guaranteeing session fidelity in a concurrent setting. In addition, we show that our language facilitates new forms of expression (e.g., type-directed reuse, internal choice), which are not available in current object-oriented languages. We have implemented our language in a prototype compiler.","object, session types, protocol, linear types, process",AGERE! 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gay SJ,Vasconcelos VT,Ravara A,Gesbert N,Caldeira AZ",Modular Session Types for Distributed Object-Oriented Programming,,2010,,,299–312,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Madrid, Spain",2010,9781605584799,,https://doi.org/10.1145/1706299.1706335;http://dx.doi.org/10.1145/1706299.1706335,10.1145/1706299.1706335,"Session types allow communication protocols to be specified type-theoretically so that protocol implementations can be verified by static type-checking. We extend previous work on session types for distributed object-oriented languages in three ways. (1) We attach a session type to a class definition, to specify the possible sequences of method calls. (2) We allow a session type (protocol) implementation to be modularized , i.e. partitioned into separately-callable methods. (3) We treat session-typed communication channels as objects, integrating their session types with the session types of classes. The result is an elegant unification of communication channels and their session types, distributed object-oriented programming, and a form of typestates supporting non-uniform objects, i.e. objects that dynamically change the set of available methods. We define syntax, operational semantics, a sound type system, and a correct and complete type checking algorithm for a small distributed class-based object-oriented language. Static typing guarantees that both sequences of messages on channels, and sequences of method calls on objects, conform to type-theoretic specifications, thus ensuring type-safety. The language includes expected features of session types, such as delegation, and expected features of object-oriented programming, such as encapsulation of local state. We also describe a prototype implementation as an extension of Java.","typestates, session types, object-oriented calculus, non-uniform method availability",POPL '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gay SJ,Vasconcelos VT,Ravara A,Gesbert N,Caldeira AZ",Modular Session Types for Distributed Object-Oriented Programming,SIGPLAN Not.,2010,45,1,299–312,Association for Computing Machinery,"New York, NY, USA",,,,2010-01,,0362-1340,https://doi.org/10.1145/1707801.1706335;http://dx.doi.org/10.1145/1707801.1706335,10.1145/1707801.1706335,"Session types allow communication protocols to be specified type-theoretically so that protocol implementations can be verified by static type-checking. We extend previous work on session types for distributed object-oriented languages in three ways. (1) We attach a session type to a class definition, to specify the possible sequences of method calls. (2) We allow a session type (protocol) implementation to be modularized , i.e. partitioned into separately-callable methods. (3) We treat session-typed communication channels as objects, integrating their session types with the session types of classes. The result is an elegant unification of communication channels and their session types, distributed object-oriented programming, and a form of typestates supporting non-uniform objects, i.e. objects that dynamically change the set of available methods. We define syntax, operational semantics, a sound type system, and a correct and complete type checking algorithm for a small distributed class-based object-oriented language. Static typing guarantees that both sequences of messages on channels, and sequences of method calls on objects, conform to type-theoretic specifications, thus ensuring type-safety. The language includes expected features of session types, such as delegation, and expected features of object-oriented programming, such as encapsulation of local state. We also describe a prototype implementation as an extension of Java.","object-oriented calculus, session types, typestates, non-uniform method availability",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nistor L,Kurilova D,Balzer S,Chung B,Potanin A,Aldrich J","Wyvern: A Simple, Typed, and Pure Object-Oriented Language",,2013,,,9–16,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 5th Workshop on MechAnisms for SPEcialization, Generalization and InHerItance","Montpellier, France",2013,9781450320467,,https://doi.org/10.1145/2489828.2489830;http://dx.doi.org/10.1145/2489828.2489830,10.1145/2489828.2489830,"The simplest and purest practical object-oriented language designs today are seen in dynamically-typed languages, such as Smalltalk and Self. Static types, however, have potential benefits for productivity, security, and reasoning about programs. In this paper, we describe the design of Wyvern, a statically typed, pure object-oriented language that attempts to retain much of the simplicity and expressiveness of these iconic designs.Our goals lead us to combine pure object-oriented and functional abstractions in a simple, typed setting. We present a foundational object-based language that we believe to be as close as one can get to simple typed lambda calculus while keeping object-orientation. We show how this foundational language can be translated to the typed lambda calculus via standard encodings. We then define a simple extension to this language that introduces classes and show that classes are no more than sugar for the foundational object-based language. Our future intention is to demonstrate that modules and other object-oriented features can be added to our language as not more than such syntactical extensions while keeping the object-oriented core as pure as possible.The design of Wyvern closely follows both historical and modern ideas about the essence of object-orientation, suggesting a new way to think about a minimal, practical, typed core language for objects.","first-class classes, object-oriented, static type checking",MASPEGHI '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chhabra JK,Gupta V",Evaluation of Object-Oriented Spatial Complexity Measures,SIGSOFT Softw. Eng. Notes,2009,34,3,1–5,Association for Computing Machinery,"New York, NY, USA",,,,2009-05,,0163-5948,https://doi.org/10.1145/1527202.1527208;http://dx.doi.org/10.1145/1527202.1527208,10.1145/1527202.1527208,"Spatial complexity measures help in the estimation of the effort re-quired in the process of program comprehension. These spatial com-plexity measures have been proposed for procedure-oriented software as well as object-oriented software. In this paper, an at-tempt has been made to evaluate object-oriented spatial complexity measures using formal evaluation frameworks proposed by Weyu-ker and Briand et al. A practical and useful complexity measure must satisfy most of the properties given in these frameworks. The results of this study show that object-oriented spatial metrics satisfy all properties and parameters required by these two evaluation frameworks and thus these spatial measures are robust and useful.","software metrics, spatial complexity measures, software complexity, software engineering, object-oriented software",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gerakios P,Fourtounis G,Smaragdakis Y",Fᴏᴏ: A Minimal Modern OO Calculus,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th Workshop on Formal Techniques for Java-like Programs,"Prague, Czech Republic",2015,9781450336567,,https://doi.org/10.1145/2786536.2786540;http://dx.doi.org/10.1145/2786536.2786540,10.1145/2786536.2786540,"We present the Flyweight Object-Oriented (Fᴏᴏ) calculus for the modeling of object-oriented languages. Fᴏᴏ is a simple, minimal class-based calculus, modeling only essential computational aspects and emphasizing larger-scale features (e.g., inheritance and generics). Fᴏᴏ is motivated by the observation that recent language design work focuses on elements not well-captured either by traditional object calculi or by language-specific modeling efforts, such as Featherweight Java. Fᴏᴏ integrates seamlessly both nominal and structural subtyping ideas, leveraging the latter to eliminate the need for modeling object fields and constructors. Comparing to recent formalization efforts in the literature, Fᴏᴏ is more compact, yet versatile enough to be usable in multiple settings modeling Java, C#, or Scala extensions.","object-oriented programming, type system, formal semantics, nominal types, structural types",FTfJP '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chanda J,Sengupta S,Kanjilal A,Bhattacharya S",Behavioral and Structural Evolution of SOA from OO: An Integrated Approach,SIGSOFT Softw. Eng. Notes,2013,38,5,1–9,Association for Computing Machinery,"New York, NY, USA",,,,2013-08,,0163-5948,https://doi.org/10.1145/2507288.2507304;http://dx.doi.org/10.1145/2507288.2507304,10.1145/2507288.2507304,"Service Oriented Architecture caters to the \Separation of Concerns\"" and incorporates reusability",granularity,modularity,componentization and interoperability. There are many software products that have been developed in the object-oriented paradigm. To incorporate the positive aspects of the service-oriented paradigm,they need to be evolved to the service-oriented domain. In this paper,we define an integrated approach towards consistent evolution of Object Oriented (OO) paradigm to the Service Oriented (SOA) domain. There are some proven Object Oriented Design Tools that can be used for Service Oriented Application design incorporating both the behavioral and structural aspects. The work in this paper involves a set of activities like formalizing the different UML diagrams,"formal mapping of object components to service level components and establishing consistency among them. We also establish a traceability model for consistent evolution of Service Oriented Applications from existing Object Oriented Applications by mapping behavioral and structural artifacts of both domains. This will establish traceability from implementation phases back to the requirements phases of an SOA application.""","evolution, service oriented architecture, formalization",,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Merunka V,Brožek J,Šebek M,Molhanec M",Normalization Rules of the Object-Oriented Data Model,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Workshop on Enterprises & Organizational Modeling and Simulation,"Amsterdam, The Netherlands",2009,9781450373012,,https://doi.org/10.1145/1750405.1750420;http://dx.doi.org/10.1145/1750405.1750420,10.1145/1750405.1750420,"There are only very few approaches to normalizing object-oriented data. In this paper we present an approach to normalization of the object-oriented conceptual model based on UML class diagrams. First part of the paper describes the current status in the area of formal methods used for object-oriented data modeling. Second part presents four normalization rules, which are based on own experience and modified Ambler-Beck approach. These normalization rules are introduced on an example. Our method has been used in education at several universities. It has been and is also used for database design in software development projects, which we carried out. Recently, development of the CASE tool based on this approach has been started.","object-oriented data model (ODM), fourth object-oriented normal form (4ONF), third object-oriented normal form (3ONF), second object-oriented normal form (2ONF), first object-oriented normal form (1ONF), relational data model (RDM), data normalization",EOMAS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Callaú O,Robbes R,Tanter É,Röthlisberger D,Bergel A",On the Use of Type Predicates in Object-Oriented Software: The Case of Smalltalk,,2014,,,135–146,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th ACM Symposium on Dynamic Languages,"Portland, Oregon, USA",2014,9781450332118,,https://doi.org/10.1145/2661088.2661091;http://dx.doi.org/10.1145/2661088.2661091,10.1145/2661088.2661091,"Object-orientation relies on polymorphism to express behavioral variants. As opposed to traditional procedural design, explicit type-based conditionals should be avoided. This message is conveyed in introductory material on object orientation, as well as in object-oriented reengineering patterns. Is this principle followed in practice? In other words, are type predicates actually used in object-oriented software, and if so, to which extent?Answering these questions will assist practitioners and researchers with providing information about the state of the practice, and informing the active research program of retrofitting type systems, clarifying whether complex flow-sensitive typing approaches are necessary. Other areas, such as refactoring and teaching object orientation, can also benefit from empirical evidence on the matter.We report on a study of the use of type predicates in a large base of over 4 million lines of Smalltalk code. Our study shows that type predicates are in fact widely used to do explicit type dispatch, suggesting that flow-sensitive typing approaches are necessary for a type system retrofitted for a dynamic object-oriented language.","object-oriented languages, flow-sensitive typing, type predicates",DLS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Callaú O,Robbes R,Tanter É,Röthlisberger D,Bergel A",On the Use of Type Predicates in Object-Oriented Software: The Case of Smalltalk,SIGPLAN Not.,2014,50,2,135–146,Association for Computing Machinery,"New York, NY, USA",,,,2014-10,,0362-1340,https://doi.org/10.1145/2775052.2661091;http://dx.doi.org/10.1145/2775052.2661091,10.1145/2775052.2661091,"Object-orientation relies on polymorphism to express behavioral variants. As opposed to traditional procedural design, explicit type-based conditionals should be avoided. This message is conveyed in introductory material on object orientation, as well as in object-oriented reengineering patterns. Is this principle followed in practice? In other words, are type predicates actually used in object-oriented software, and if so, to which extent?Answering these questions will assist practitioners and researchers with providing information about the state of the practice, and informing the active research program of retrofitting type systems, clarifying whether complex flow-sensitive typing approaches are necessary. Other areas, such as refactoring and teaching object orientation, can also benefit from empirical evidence on the matter.We report on a study of the use of type predicates in a large base of over 4 million lines of Smalltalk code. Our study shows that type predicates are in fact widely used to do explicit type dispatch, suggesting that flow-sensitive typing approaches are necessary for a type system retrofitted for a dynamic object-oriented language.","type predicates, object-oriented languages, flow-sensitive typing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ancona D,Zucca E",Corecursive Featherweight Java,,2012,,,3–10,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th Workshop on Formal Techniques for Java-like Programs,"Beijing, China",2012,9781450312721,,https://doi.org/10.1145/2318202.2318205;http://dx.doi.org/10.1145/2318202.2318205,10.1145/2318202.2318205,"Despite cyclic data structures occur often in many application domains, object-oriented programming languages provide poor abstraction mechanisms for dealing with cyclic objects.Such a deficiency is reflected also in the research on theoretical foundation of object-oriented languages; for instance, Featherweigh Java (FJ), which is one of the most widespread object-oriented calculi, does not allow creation and manipulation of cyclic objects.We propose an extension to Featherweight Java, called COFJ, where it is possible to define cyclic objects, abstractly corresponding to regular terms, and where an abstraction mechanism, called regular corecursion, is provided for supporting implementation of coinductive operations on cyclic objects.We formally define the operational semantics of COFJ, and provide a handful of examples showing the expressive power of regular corecursion; such a mechanism promotes a novel programming style particularly well-suited for implementing cyclic data structures, and for supporting coinductive reasoning.","coinduction, regular terms, Java-like languages, programming paradigms",FTfJP '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ancona D,Corradi A",A Formal Account of SSA in Java-like Languages,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th Workshop on Formal Techniques for Java-like Programs,"Rome, Italy",2016,9781450344395,,https://doi.org/10.1145/2955811.2955813;http://dx.doi.org/10.1145/2955811.2955813,10.1145/2955811.2955813,"Static Single Assignment (SSA) intermediate representation is widely used to optimize and compile code in imperative and object-oriented languages, but it can also be useful for static type analysis.We introduce FJSSA, a Java-like imperative calculus supporting programs in SSA form; we define its big-step operational semantics, and a judgment to statically check whether a program is in SSA form, and prove its soundness.FJSSA provides a formal basis for type analysis of programs in SSA form in object-oriented languages.","type analysis, operational semantics, object-oriented languages, SSA form",FTfJP'16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oliveira BC,Gibbons J",Scala for Generic Programmers,,2008,,,25–36,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM SIGPLAN Workshop on Generic Programming,"Victoria, BC, Canada",2008,9781605580609,,https://doi.org/10.1145/1411318.1411323;http://dx.doi.org/10.1145/1411318.1411323,10.1145/1411318.1411323,"Datatype-generic programming involves parametrization by the shape of data, in the form of type constructors such as \list of\"". Most approaches to datatype-generic programming are developed in the lazy functional programming language Haskell. We argue that the functional object-oriented language Scala is in many ways a better setting. Not only does Scala provide equivalents of all the necessary functional programming features (such parametric polymorphism",higher-order functions,higher-kinded type operations,and type- and constructor-classes),but it also provides the most useful features of object-oriented languages (such as subtyping,overriding,traditional single inheritance,and multiple inheritance in the form of traits). We show how this combination of features benefits datatype-generic programming,"using three different approaches as illustrations.""","scala, polytypic programming, datatype-generic programming",WGP '08,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mouelhi S,Agrou K,Chouali S,Mountassir H",Object-Oriented Component-Based Design Using Behavioral Contracts: Application to Railway Systems,,2015,,,49–58,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th International ACM SIGSOFT Symposium on Component-Based Software Engineering,"Montréal, QC, Canada",2015,9781450334716,,https://doi.org/10.1145/2737166.2737171;http://dx.doi.org/10.1145/2737166.2737171,10.1145/2737166.2737171,"In this paper, we propose a formal approach for the design of object-oriented component-based systems using behavioral contracts. This formalism merges interface automata describing communication protocols of components with the semantics of their operations. On grounds of consistency with the object-oriented paradigms, we revisit the notions of incremental design and independent implementability of interface automata by novel definitions of components compatibility, composition, and refinement. Our work is illustrated by a design case study of CBTC railway systems.","interface automata, refinement, railway systems, behavioral contracts, method semantics, object-oriented components",CBSE '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Park G,Hong J,Steele Jr GL,Ryu S",Polymorphic Symmetric Multiple Dispatch with Variance,Proc. ACM Program. Lang.,2019,3,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-01,,,https://doi.org/10.1145/3290324;http://dx.doi.org/10.1145/3290324,10.1145/3290324,"Many object-oriented languages provide method overloading, which allows multiple method declarations with the same name. For a given method invocation, in order to choose what method declaration to invoke, multiple dispatch considers the run-time types of the arguments. While multiple dispatch can support binary methods (such as mathematical operators) intuitively and consistently, it is difficult to guarantee that calls will be neither ambiguous nor undefined at run time, especially in the presence of expressive language features such as multiple inheritance and parametric polymorphism. Previous efforts have formalized languages that include such features by using overloading rules that guarantee a unique and type-sound resolution of each overloaded method call; in many cases, such rules resolve ambiguity by treating the arguments asymmetrically. Here we present the first formal specification of a strongly typed object-oriented language with symmetric multiple dispatch, multiple inheritance, and parametric polymorphism with variance. We define both a static (type- checking) semantics and a dynamic (dispatching) semantics and prove the type soundness of the language, thus demonstrating that our novel dynamic dispatch algorithm is consistent with the static semantics. Details of our dynamic dispatch algorithm address certain technical challenges that arise from structural asymmetries inherent in object-oriented languages (e.g., classes typically declare ancestors explicitly but not descendants).","Variance, Parametric Polymorphism, Symmetric Multiple Dispatch, Method Overloading",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Ryu S,ThisType for Object-Oriented Languages: From Theory to Practice,ACM Trans. Program. Lang. Syst.,2016,38,3,,Association for Computing Machinery,"New York, NY, USA",,,,2016-04,,0164-0925,https://doi.org/10.1145/2888392;http://dx.doi.org/10.1145/2888392,10.1145/2888392,"In object-oriented programs, objects often provide methods whose parameter types or return types are the object types themselves. For example, the parameter types of binary methods are the types of their receiver objects, and the return types of some factory methods are the types of their enclosing objects. However, most object-oriented languages do not support such methods precisely because their type systems do not support explicit recursive types, which lead to a mismatch between subclassing and subtyping. This mismatch means that an expression of a subclass may not always be usable in a context where an expression of a superclass is expected, which is not intuitive in an object-oriented setting. Researchers have proposed various type-sound approaches to support methods with types of their enclosing object types denoted by some variants of ThisType, but they reject reasonable and useful methods due to unpermissive type systems or they use less precise declared inexact types rather than runtime exact types.In this article, we present a thorough approach to support methods with ThisTypes: from a new encoding of objects in a typed lambda calculus that allows subtyping by subclassing to an open-source implementation as an extension of the Java programming language. We first provide real-world examples that motivate the need for ThisTyped methods to precisely describe desired properties of programs. We define a new object encoding that enables subtyping by subclassing even in the presence of negative occurrences of type recursion variables by distinguishing object types from existential object types. Based on this object encoding, we formalize language features to support ThisTyped methods with a core calculus CoreThisJava, and prove its type soundness. Finally, we provide ThisJava, a prototype implementation of the calculus, to show its backward compatibility, and we make it publicly available. We believe that our approach theoretically expands the long pursuit of an object-oriented language with ThisTypes to support more useful methods with more precise types.","ThisType, binary methods, generic factory methods, exact types, virtual constructors, Object-oriented languages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tardieu O,Nystrom N,Peshansky I,Saraswat V",Constrained Kinds,,2012,,,811–830,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Tucson, Arizona, USA",2012,9781450315616,,https://doi.org/10.1145/2384616.2384675;http://dx.doi.org/10.1145/2384616.2384675,10.1145/2384616.2384675,"Modern object-oriented languages such as X10 require a rich framework for types capable of expressing both value-dependency and genericity, and supporting pluggable, domain-specific extensions. In earlier work, we presented a framework for constrained types in object-oriented languages, parametrized by an underlying constraint system. Types are viewed as formulas Cc where C is the name of a class or an interface and c is a constraint on the immutable instance state (the properties) of C. Constraint systems are a very expressive framework for partial information. Many (value-)dependent type systems for object-oriented languages can be viewed as constrained types.This paper extends the constrained types approach to handle type-dependency (\genericity\""). The key idea is to introduce constrained kinds: in the same way that constraints on values can be used to define constrained types",constraints on types can define constrained kinds.We develop a core programming language with constrained kinds. Generic types are supported by introducing type variables---literally,"variables with \""type\"" Type---and permitting programs to impose subtyping and equality constraints on such variables. We formalize the type-checking rules and establish soundness.While the language now intertwines constraints on types and values","its type system remains parametric in the choice of the value constraint system (language and solver). We demonstrate that constrained kinds are expressive and practical and sketch possible extensions with a discussion of the design and implementation of X10.""","X10, generics, types, constraints",OOPSLA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Tardieu O,Nystrom N,Peshansky I,Saraswat V",Constrained Kinds,SIGPLAN Not.,2012,47,10,811–830,Association for Computing Machinery,"New York, NY, USA",,,,2012-10,,0362-1340,https://doi.org/10.1145/2398857.2384675;http://dx.doi.org/10.1145/2398857.2384675,10.1145/2398857.2384675,"Modern object-oriented languages such as X10 require a rich framework for types capable of expressing both value-dependency and genericity, and supporting pluggable, domain-specific extensions. In earlier work, we presented a framework for constrained types in object-oriented languages, parametrized by an underlying constraint system. Types are viewed as formulas Cc where C is the name of a class or an interface and c is a constraint on the immutable instance state (the properties) of C. Constraint systems are a very expressive framework for partial information. Many (value-)dependent type systems for object-oriented languages can be viewed as constrained types.This paper extends the constrained types approach to handle type-dependency (\genericity\""). The key idea is to introduce constrained kinds: in the same way that constraints on values can be used to define constrained types",constraints on types can define constrained kinds.We develop a core programming language with constrained kinds. Generic types are supported by introducing type variables---literally,"variables with \""type\"" Type---and permitting programs to impose subtyping and equality constraints on such variables. We formalize the type-checking rules and establish soundness.While the language now intertwines constraints on types and values","its type system remains parametric in the choice of the value constraint system (language and solver). We demonstrate that constrained kinds are expressive and practical and sketch possible extensions with a discussion of the design and implementation of X10.""","X10, types, generics, constraints",,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Parkinson MJ,Bierman GM","Separation Logic, Abstraction and Inheritance",,2008,,,75–86,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"San Francisco, California, USA",2008,9781595936899,,https://doi.org/10.1145/1328438.1328451;http://dx.doi.org/10.1145/1328438.1328451,10.1145/1328438.1328451,"Inheritance is a fundamental concept in object-oriented programming, allowing new classes to be defined in terms of old classes. When used with care, inheritance is an essential tool for object-oriented programmers. Thus, for those interested in developing formal verification techniques, the treatment of inheritance is of paramount importance. Unfortunately, inheritance comes in a number of guises, all requiring subtle techniques.To address these subtleties, most existing verification methodologies typically adopt one of two restrictions to handle inheritance: either (1) they prevent a derived class from restricting the behaviour of its base class (typically by syntactic means) to trivialize the proof obligations; or (2) they allow a derived class to restrict the behaviour of its base class, but require that every inherited method must be reverified. Unfortunately, this means that typical inheritance-rich code either cannot be verified or results in an unreasonable number of proof obligations.In this paper, we develop a separation logic for a core object-oriented language. It allows derived classes which override the behaviour of their base class, yet supports the inheritance of methods without reverification where this is safe. For each method, we require two specifications: a static specification that is used to verify the implementation and direct method calls (in Java this would be with a super call); and a dynamic specification that is used for calls that are dynamically dispatched; along with a simple relationship between the two specifications. Only the dynamic specification is involved with behavioural subtyping. This simple separation of concerns leads to a powerful system that supports all forms of inheritance with low proof-obligation overheads. We both formalize our methodology and demonstrate its power with a series of inheritance examples.","classes, modularity, separation logic",POPL '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Parkinson MJ,Bierman GM","Separation Logic, Abstraction and Inheritance",SIGPLAN Not.,2008,43,1,75–86,Association for Computing Machinery,"New York, NY, USA",,,,2008-01,,0362-1340,https://doi.org/10.1145/1328897.1328451;http://dx.doi.org/10.1145/1328897.1328451,10.1145/1328897.1328451,"Inheritance is a fundamental concept in object-oriented programming, allowing new classes to be defined in terms of old classes. When used with care, inheritance is an essential tool for object-oriented programmers. Thus, for those interested in developing formal verification techniques, the treatment of inheritance is of paramount importance. Unfortunately, inheritance comes in a number of guises, all requiring subtle techniques.To address these subtleties, most existing verification methodologies typically adopt one of two restrictions to handle inheritance: either (1) they prevent a derived class from restricting the behaviour of its base class (typically by syntactic means) to trivialize the proof obligations; or (2) they allow a derived class to restrict the behaviour of its base class, but require that every inherited method must be reverified. Unfortunately, this means that typical inheritance-rich code either cannot be verified or results in an unreasonable number of proof obligations.In this paper, we develop a separation logic for a core object-oriented language. It allows derived classes which override the behaviour of their base class, yet supports the inheritance of methods without reverification where this is safe. For each method, we require two specifications: a static specification that is used to verify the implementation and direct method calls (in Java this would be with a super call); and a dynamic specification that is used for calls that are dynamically dispatched; along with a simple relationship between the two specifications. Only the dynamic specification is involved with behavioural subtyping. This simple separation of concerns leads to a powerful system that supports all forms of inheritance with low proof-obligation overheads. We both formalize our methodology and demonstrate its power with a series of inheritance examples.","modularity, separation logic, classes",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bocchino RL,Adve VS,Dig D,Adve SV,Heumann S,Komuravelli R,Overbey J,Simmons P,Sung H,Vakilian M",A Type and Effect System for Deterministic Parallel Java,,2009,,,97–116,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th ACM SIGPLAN Conference on Object Oriented Programming Systems Languages and Applications,"Orlando, Florida, USA",2009,9781605587660,,https://doi.org/10.1145/1640089.1640097;http://dx.doi.org/10.1145/1640089.1640097,10.1145/1640089.1640097,"Today's shared-memory parallel programming models are complex and error-prone.While many parallel programs are intended to be deterministic, unanticipated thread interleavings can lead to subtle bugs and nondeterministic semantics. In this paper, we demonstrate that a practical type and effect system can simplify parallel programming by guaranteeing deterministic semantics with modular, compile-time type checking even in a rich, concurrent object-oriented language such as Java. We describe an object-oriented type and effect system that provides several new capabilities over previous systems for expressing deterministic parallel algorithms.We also describe a language called Deterministic Parallel Java (DPJ) that incorporates the new type system features, and we show that a core subset of DPJ is sound. We describe an experimental validation showing thatDPJ can express a wide range of realistic parallel programs; that the new type system features are useful for such programs; and that the parallel programs exhibit good performance gains (coming close to or beating equivalent, nondeterministic multithreaded programs where those are available).","deterministic parallelism, effect systems, effects, commutativity, determinism",OOPSLA '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Bocchino RL,Adve VS,Dig D,Adve SV,Heumann S,Komuravelli R,Overbey J,Simmons P,Sung H,Vakilian M",A Type and Effect System for Deterministic Parallel Java,SIGPLAN Not.,2009,44,10,97–116,Association for Computing Machinery,"New York, NY, USA",,,,2009-10,,0362-1340,https://doi.org/10.1145/1639949.1640097;http://dx.doi.org/10.1145/1639949.1640097,10.1145/1639949.1640097,"Today's shared-memory parallel programming models are complex and error-prone.While many parallel programs are intended to be deterministic, unanticipated thread interleavings can lead to subtle bugs and nondeterministic semantics. In this paper, we demonstrate that a practical type and effect system can simplify parallel programming by guaranteeing deterministic semantics with modular, compile-time type checking even in a rich, concurrent object-oriented language such as Java. We describe an object-oriented type and effect system that provides several new capabilities over previous systems for expressing deterministic parallel algorithms.We also describe a language called Deterministic Parallel Java (DPJ) that incorporates the new type system features, and we show that a core subset of DPJ is sound. We describe an experimental validation showing thatDPJ can express a wide range of realistic parallel programs; that the new type system features are useful for such programs; and that the parallel programs exhibit good performance gains (coming close to or beating equivalent, nondeterministic multithreaded programs where those are available).","effect systems, deterministic parallelism, effects, determinism, commutativity",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lemma R,Lanza M,Olivero F",CEL: Modeling Everywhere,,2013,,,1323–1326,IEEE Press,"San Francisco, CA, USA",,Proceedings of the 2013 International Conference on Software Engineering,,2013,9781467330763,,,,"The design of object-oriented systems starts with modeling, a process to identify core concepts and their relations. Mainstream modeling techniques can be either informal (white board, CRC cards, etc.) or formal (e.g., UML editors). The former support well the creative modeling process, but their output is difficult to store, process and maintain. The latter reduce these problems, at the expense of creativity and productivity because they are tedious and not trivial to use. We present CEL, a touch- and gesture-based iPad application to rapidly create, manipulate, and store language agnostic object- oriented software models, based on a minimal set of constructs. Demo video URL: http://youtu.be/icQVS6w0jTE.",,ICSE '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chrząszcz J,Schubert A",Function Definitions for Compound Values in Object-Oriented Languages,,2017,,,61–72,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th International Symposium on Principles and Practice of Declarative Programming,"Namur, Belgium",2017,9781450352918,,https://doi.org/10.1145/3131851.3131860;http://dx.doi.org/10.1145/3131851.3131860,10.1145/3131851.3131860,"Declarative programming features are gradually included in the design of object-oriented languages such as Java and C++. These languages recently adopted anonymous function definitions and offer basic primitives that restrict changes on data, namely final and const keywords, respectively.We propose a type system for an object-oriented Java-like language that facilitates declarative programming while leaving programmers significant freedom in use of imperative features. The system allows one to delimit compound value representations and effectively define values that are common in functional programming languages. Given that, we distinguish methods that work as first-order functions on such values. In this framework functions may modify internal working state that is clearly separated from the global state of the program. The system exploits access modes for method arguments, which describe the way the method operates on the given entity representation.","extensionality, compound data types, functional programming, object-oriented programming, functions",PPDP '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Bierhoff K,Checking API Protocol Compliance in Java,,2008,,,915–916,Association for Computing Machinery,"New York, NY, USA",,Companion to the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582207,,https://doi.org/10.1145/1449814.1449906;http://dx.doi.org/10.1145/1449814.1449906,10.1145/1449814.1449906,Reusable APIs often define usage protocols. The author previously developed a sound and modular type system that checks compliance to typestate-based protocols while affording a great deal of aliasing flexibility. This paper focuses on making these ideas available in tools for mainstream object-oriented languages and evaluating their practical effectiveness.,"permissions, typestate",OOPSLA Companion '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Takikawa A,Strickland TS,Dimoulas C,Tobin-Hochstadt S,Felleisen M",Gradual Typing for First-Class Classes,,2012,,,793–810,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Tucson, Arizona, USA",2012,9781450315616,,https://doi.org/10.1145/2384616.2384674;http://dx.doi.org/10.1145/2384616.2384674,10.1145/2384616.2384674,"Dynamic type-checking and object-oriented programming often go hand-in-hand; scripting languages such as Python, Ruby, and JavaScript all embrace object-oriented (OO) programming. When scripts written in such languages grow and evolve into large programs, the lack of a static type discipline reduces maintainability. A programmer may thus wish to migrate parts of such scripts to a sister language with a static type system. Unfortunately, existing type systems neither support the flexible OO composition mechanisms found in scripting languages nor accommodate sound interoperation with untyped code. In this paper, we present the design of a gradual typing system that supports sound interaction between statically- and dynamically-typed units of class-based code. The type system uses row polymorphism for classes and thus supports mixin-based OO composition. To protect migration of mixins from typed to untyped components, the system employs a novel form of contracts that partially seal classes. The design comes with a theorem that guarantees the soundness of the type system even in the presence of untyped components.","first-class classes, contracts, blame theorem (proof technique), design by contract, row polymorphism, gradual typing, sealing",OOPSLA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Takikawa A,Strickland TS,Dimoulas C,Tobin-Hochstadt S,Felleisen M",Gradual Typing for First-Class Classes,SIGPLAN Not.,2012,47,10,793–810,Association for Computing Machinery,"New York, NY, USA",,,,2012-10,,0362-1340,https://doi.org/10.1145/2398857.2384674;http://dx.doi.org/10.1145/2398857.2384674,10.1145/2398857.2384674,"Dynamic type-checking and object-oriented programming often go hand-in-hand; scripting languages such as Python, Ruby, and JavaScript all embrace object-oriented (OO) programming. When scripts written in such languages grow and evolve into large programs, the lack of a static type discipline reduces maintainability. A programmer may thus wish to migrate parts of such scripts to a sister language with a static type system. Unfortunately, existing type systems neither support the flexible OO composition mechanisms found in scripting languages nor accommodate sound interoperation with untyped code. In this paper, we present the design of a gradual typing system that supports sound interaction between statically- and dynamically-typed units of class-based code. The type system uses row polymorphism for classes and thus supports mixin-based OO composition. To protect migration of mixins from typed to untyped components, the system employs a novel form of contracts that partially seal classes. The design comes with a theorem that guarantees the soundness of the type system even in the presence of untyped components.","row polymorphism, contracts, first-class classes, gradual typing, sealing, design by contract, blame theorem (proof technique)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Binder D,Jabs J,Skupin I,Ostermann K",Decomposition Diversity with Symmetric Data and Codata,Proc. ACM Program. Lang.,2019,4,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-12,,,https://doi.org/10.1145/3371098;http://dx.doi.org/10.1145/3371098,10.1145/3371098,"The expression problem describes a fundamental trade-off in program design: Should a program's primary decomposition be determined by the way its domain objects are constructed (\functional\"" decomposition)","or by the way they are destructed (\""object-oriented\"" decomposition)? We argue that programming languages should not force one of these decompositions on the programmer; rather",a programming language should support both ways of decomposing a program in a symmetric way,with an easy translation between these decompositions. However,"current programming languages are usually not symmetric and hence make it unnecessarily hard to switch the decomposition. We propose a language that is symmetric in this regard and allows a fully automatic translation between \""functional\"" and \""object-oriented\"" decomposition. We present a language with algebraic data types and pattern matching for \""functional\"" decomposition and codata types and copattern matching for \""object-oriented\"" decomposition","together with a bijective translation that turns a data type into a codata type (\""destructorization\"") or vice versa (\""constructorization\""). We present the first symmetric programming language with support for local (co)pattern matching",which includes local anonymous function or object definitions,that allows an automatic translation as described above. We also present the first mechanical formalization of such a language and prove i) that the type system is sound,that the translations between data and codata types are ii) type-preserving,"iii) behavior-preserving and iv) inverses of each other. We also extract a mechanically verified implementation from our formalization and have implemented an IDE with direct support for these translations.""","Refunctionalization, Codata, Types, Defunctionalization",,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"de Moor O,Sereni D,Avgustinov P,Verbaere M",Type Inference for Datalog and Its Application to Query Optimisation,,2008,,,291–300,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Twenty-Seventh ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,"Vancouver, Canada",2008,9781605581521,,https://doi.org/10.1145/1376916.1376957;http://dx.doi.org/10.1145/1376916.1376957,10.1145/1376916.1376957,"Certain variants of object-oriented Datalog can be compiled to Datalog with negation. We seek to apply optimisations akin to virtual method resolution (a well-known technique in compiling Java and other OO languages) to improve efficiency of the resulting Datalog programs. The effectiveness of such optimisations strongly depends on the precision of the underlying type inference algorithm. Previous work on type inference for Datalog has focussed on Cartesian abstractions, where the type of each field is computed separately. Such Cartesian type inference is inherently imprecise in the presence of field equalities. We propose a type system where equalities are tracked, and present a type inference algorithm. The algorithm is proved sound. We also prove that it is optimal for Datalog without negation, in the sense that the inferred type is as tight as possible. Extensive experiments with our type-based optimisations, in a commercial implementation of object-oriented Datalog, confirm the benefits of this non-Cartesian type inference algorithm.","datalog, type inference, query optimization",PODS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lo D,Maoz S",Specification Mining of Symbolic Scenario-Based Models,,2008,,,29–35,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM SIGPLAN-SIGSOFT Workshop on Program Analysis for Software Tools and Engineering,"Atlanta, Georgia",2008,9781605583822,,https://doi.org/10.1145/1512475.1512482;http://dx.doi.org/10.1145/1512475.1512482,10.1145/1512475.1512482,"Many dynamic analysis approaches to specification mining, which extract behavioral models from execution traces, do not consider object identities. This limits their power when used to analyze traces of general object oriented programs. In this work we present a novel specification mining approach that considers object identities, and, moreover, generalizes from specifications involving concrete objects to their symbolic class-level abstractions. Our approach uses data mining methods to extract significant scenario-based specifications in the form of Damm and Harel's live sequence charts (LSC), a formal and expressive extension of classic sequence diagrams. We guarantee that all mined symbolic LSCs are significant (statistically sound) and all significant symbolic LSCs are mined (statistically complete). The technique can potentially be applied to general object oriented programs to reveal expressive and useful reverse-engineered candidate specifications.",,PASTE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oliveira BC,Wang M,Gibbons J","The Visitor Pattern as a Reusable, Generic, Type-Safe Component",,2008,,,439–456,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582153,,https://doi.org/10.1145/1449764.1449799;http://dx.doi.org/10.1145/1449764.1449799,10.1145/1449764.1449799,"The VISITOR design pattern shows how to separate the structure of an object hierarchy from the behaviour of traversals over that hierarchy. The pattern is very flexible; this very flexibility makes it difficult to capture the pattern as anything more formal than prose, pictures and prototypes.We show how to capture the essence of the VISITOR pattern as a reusable software library, by using advanced type system features appearing in modern object-oriented languages such as Scala. We preserve type-safety statically and modularly: no reflection or similar mechanisms are used and modules can be independently compiled. The library is generic, in two senses: not only is it parametrised by both the return type and the shape of the object hierarchy, but also it allows a number of implementation choices (internal versus external control, imperative versus functional behaviour, orthogonal aspects such as tracing and memoisation) to be specified by parameters rather than fixed in early design decisions. Finally, we propose a generalised datatype-like notation,on top of our visitor library: this provides a convenient functional decomposition style in object-oriented languages.","traversal, program extensibility, visitor pattern, algebraic datatypes, software components, design patterns",OOPSLA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Oliveira BC,Wang M,Gibbons J","The Visitor Pattern as a Reusable, Generic, Type-Safe Component",SIGPLAN Not.,2008,43,10,439–456,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,0362-1340,https://doi.org/10.1145/1449955.1449799;http://dx.doi.org/10.1145/1449955.1449799,10.1145/1449955.1449799,"The VISITOR design pattern shows how to separate the structure of an object hierarchy from the behaviour of traversals over that hierarchy. The pattern is very flexible; this very flexibility makes it difficult to capture the pattern as anything more formal than prose, pictures and prototypes.We show how to capture the essence of the VISITOR pattern as a reusable software library, by using advanced type system features appearing in modern object-oriented languages such as Scala. We preserve type-safety statically and modularly: no reflection or similar mechanisms are used and modules can be independently compiled. The library is generic, in two senses: not only is it parametrised by both the return type and the shape of the object hierarchy, but also it allows a number of implementation choices (internal versus external control, imperative versus functional behaviour, orthogonal aspects such as tracing and memoisation) to be specified by parameters rather than fixed in early design decisions. Finally, we propose a generalised datatype-like notation,on top of our visitor library: this provides a convenient functional decomposition style in object-oriented languages.","traversal, algebraic datatypes, design patterns, visitor pattern, program extensibility, software components",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"van Bakel S,Rowe RN",Semantic Predicate Types and Approximation for Class-Based Object Oriented Programming,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Workshop on Formal Techniques for Java-like Programs,"Genova, Italy",2009,9781605585406,,https://doi.org/10.1145/1557898.1557901;http://dx.doi.org/10.1145/1557898.1557901,10.1145/1557898.1557901,"We apply the principles of the intersection type discipline to the study of class-based object oriented programs and; our work follows from a similar approach (in the context of Abadi and Cardelli's ς-object calculus) taken by van Bakel and de'Liguoro. We define an extension of Featherweight Java, pFJ, and present a predicate system which we show to be sound and expressive. We also show that our system provides a semantic underpinning for the object oriented paradigm by generalising the concept of approximant from the Lambda Calculus and demonstrating an approximation result: all expressions to which we can assign a predicate have an approximant that satisfies the same predicate. Crucial to this result is the notion of predicate language, which associates a family of predicates with a class.",,FTfJP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Damiani F,Dovland J,Johnsen EB,Schaefer I",Verifying Traits: A Proof System for Fine-Grained Reuse,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th Workshop on Formal Techniques for Java-Like Programs,"Lancaster, United Kingdom",2011,9781450308939,,https://doi.org/10.1145/2076674.2076682;http://dx.doi.org/10.1145/2076674.2076682,10.1145/2076674.2076682,"Traits have been proposed as a more flexible mechanism for code structuring in object-oriented programming than class inheritance, for achieving fine-grained code reuse. A trait originally developed for one purpose can be modified and reused in a completely different context. Formalizations of traits have been extensively studied, and implementations of traits have started to appear in programming languages. However, work on formally establishing properties of trait-based programs has so far mostly concentrated on type systems. This paper proposes the first deductive proof system for a trait-based object-oriented language. If a specification for a trait can be given a priori, covering all actual usage of that trait, our proof system is modular as each trait is analyzed only once. In order to reflect the flexible reuse potential of traits, our proof system additionally allows new specifications to be added to a trait in an incremental way which does not violate established proofs. We formalize and show the soundness of the proof system.","incremental reasoning, program verification, proof system, trait",FTfJP '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schippers H,Janssens D,Haupt M,Hirschfeld R",Delegation-Based Semantics for Modularizing Crosscutting Concerns,,2008,,,525–542,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582153,,https://doi.org/10.1145/1449764.1449806;http://dx.doi.org/10.1145/1449764.1449806,10.1145/1449764.1449806,"We describe semantic mappings of four high-level programming languages to our delegation-based machine model for aspect-oriented programming. One of the languages is a class-based object-oriented one. The other three represent extensions thereof that support various approaches to modularizing crosscutting concerns. We explain informally that an operational semantics expressed in terms of the model's concepts preserves the behavior of a program written in one of the high-level languages. We hence argue our model to be semantically sound in that sense, as well as sufficiently expressive in order to correctly support features such as class-based object-oriented programming, the open-classes and pointcut-and-advice flavors of aspect-oriented programming, and dynamic layers. For the latter, being a core feature of context-oriented programming, we also provide a formal semantics.","aspect-oriented semantics, context-oriented programming, semantic mappings, modularization",OOPSLA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Schippers H,Janssens D,Haupt M,Hirschfeld R",Delegation-Based Semantics for Modularizing Crosscutting Concerns,SIGPLAN Not.,2008,43,10,525–542,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,0362-1340,https://doi.org/10.1145/1449955.1449806;http://dx.doi.org/10.1145/1449955.1449806,10.1145/1449955.1449806,"We describe semantic mappings of four high-level programming languages to our delegation-based machine model for aspect-oriented programming. One of the languages is a class-based object-oriented one. The other three represent extensions thereof that support various approaches to modularizing crosscutting concerns. We explain informally that an operational semantics expressed in terms of the model's concepts preserves the behavior of a program written in one of the high-level languages. We hence argue our model to be semantically sound in that sense, as well as sufficiently expressive in order to correctly support features such as class-based object-oriented programming, the open-classes and pointcut-and-advice flavors of aspect-oriented programming, and dynamic layers. For the latter, being a core feature of context-oriented programming, we also provide a formal semantics.","context-oriented programming, semantic mappings, aspect-oriented semantics, modularization",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gaster BR,Howes L",OpenCL C++,,2013,,,86–95,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th Workshop on General Purpose Processor Using Graphics Processing Units,"Houston, Texas, USA",2013,9781450320177,,https://doi.org/10.1145/2458523.2458532;http://dx.doi.org/10.1145/2458523.2458532,10.1145/2458523.2458532,"With the success of programming models such as Khronos' OpenCL, heterogeneous computing is going mainstream. However, these models are low-level, even when considering them as systems programming models. For example, OpenCL is effectively an extended subset of C99, limited to the type unsafe procedural abstraction that C has provided for more than 30 years. Computer systems programming has for more than two decades been able to do a lot better. One successful case in point is the systems programming language C++, known for its strong(er) type system, templates, and object-oriented abstraction features.In this paper we introduce OpenCL C++, an object-oriented programming model (based on C++11) for heterogeneous computing and an alternative for developers targeting OpenCL enabled devices. We show that OpenCL C's address space qualifiers, and by implication Embedded C's, can be lifted into C++'s type system. A novel application of C++11's new type inference features (auto/decltype) with respect to address space qualifiers allows natural and generic use of the this pointer. We qualitatively show that OpenCL C++ is a simpler and a more expressive development platform than its OpenCL C counter part.","OpenCL, GPGPU, parallel programming, GPU, C++",GPGPU-6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Furr M,An JH,Foster JS,Hicks M",Static Type Inference for Ruby,,2009,,,1859–1866,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 ACM Symposium on Applied Computing,"Honolulu, Hawaii",2009,9781605581668,,https://doi.org/10.1145/1529282.1529700;http://dx.doi.org/10.1145/1529282.1529700,10.1145/1529282.1529700,"Many general-purpose, object-oriented scripting languages are dynamically typed, which provides flexibility but leaves the programmer without the benefits of static typing, including early error detection and the documentation provided by type annotations. This paper describes Diamondback Ruby (DRuby), a tool that blends Ruby's dynamic type system with a static typing discipline. DRuby provides a type language that is rich enough to precisely type Ruby code we have encountered, without unneeded complexity. When possible, DRuby infers static types to discover type errors in Ruby programs. When necessary, the programmer can provide DRuby with annotations that assign static types to dynamic code. These annotations are checked at run time, isolating type errors to unverified code. We applied DRuby to a suite of benchmarks and found several bugs that would cause run-time type errors. DRuby also reported a number of warnings that reveal questionable programming practices in the benchmarks. We believe that DRuby takes a major step toward bringing the benefits of combined static and dynamic typing to Ruby and other object-oriented languages.","Ruby, type inference, contracts, dynamic typing",SAC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Haddad G,Leavens GT",Specifying Subtypes in SCJ Programs,,2011,,,40–46,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Workshop on Java Technologies for Real-Time and Embedded Systems,"York, United Kingdom",2011,9781450307314,,https://doi.org/10.1145/2043910.2043917;http://dx.doi.org/10.1145/2043910.2043917,10.1145/2043910.2043917,"Modular reasoning about programs that use subtypes requires that an overriding method in a subtype obeys the specifications of all methods that it overrides. For example, if method m is specified in a supertype T to take at most 42 nanoseconds to execute, then m cannot take more than 42 nanoseconds to execute in any subtype of T. Subtyping is an important aid to maintenance of programs, since it allows one to write polymorphic code (reducing code size and increasing reuse), and allows for convenient extension and enhancement of programs, all of which could be very useful in real-time programming. In this paper we show how to specify timing constraints for subtypes in a way that: permits modular reasoning about timing constraints, supports subtype polymorphism and object-oriented design patterns, and still permits precise reasoning about execution times. This technique supports object-oriented coding and design patterns based on subtype polymorphism, with all their maintenance advantages, to be used in real-time software.","Java modeling language (JML), SafeJML, performance, WCET, safety critical Java (SCJ), duration, timing behavior",JTRES '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Thaler J,Altenkirch T,Siebers PO",Pure Functional Epidemics: An Agent-Based Approach,,2018,,,1–12,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th Symposium on Implementation and Application of Functional Languages,"Lowell, MA, USA",2018,9781450371438,,https://doi.org/10.1145/3310232.3310372;http://dx.doi.org/10.1145/3310232.3310372,10.1145/3310232.3310372,"Agent-Based Simulation (ABS) is a methodology in which a system is simulated in a bottom-up approach by modelling the micro interactions of its constituting parts, called agents, out of which the global system behaviour emerges.So far mainly object-oriented techniques and languages have been used in ABS. Using the SIR model of epidemiology, which simulates the spreading of an infectious disease through a population, we demonstrate how to use pure Functional Reactive Programming to implement ABS. With our approach we can guarantee the reproducibility of the simulation at compile time and rule out specific classes of run-time bugs, something that is not possible with traditional object-oriented languages. Also, we found that the representation in a purely functional format is conceptually quite elegant and opens the way to formally reason about ABS.","Monadic Stream Functions, Agent-Based Simulation, Functional Reactive Programming",IFL 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Besson F,CPA Beats ∞-CFA,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Workshop on Formal Techniques for Java-like Programs,"Genova, Italy",2009,9781605585406,,https://doi.org/10.1145/1557898.1557905;http://dx.doi.org/10.1145/1557898.1557905,10.1145/1557898.1557905,"Context-sensitive points-to analysis is the current most scalable technology for constructing a precise control-flow graph for large object-oriented programs. One appealing feature of this framework is that it is parametric thus allowing to trade time for precision. Typical instances of this framework are κ-CFAs and Agesen's Cartesian Product Algorithm (CPA). It is common sense that κ-CFAs (for increasing κs) form a hierarchy. Yet, what is the relative precision of κ-CFA and CPA? Grove and Chambers [2] conjecture that CPA is more precise than ∞-CFA. For a core object-oriented language, we formally compare the precision of ∞-CFA and CPA. We prove that CPA is indeed strictly more precise than ∞-CFA. On a theoretical level, this result confirms the findings of empiric studies concluding the superiority of object-sensitivity with respect to call-string sensitivity.",,FTfJP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chugh R,Herman D,Jhala R",Dependent Types for JavaScript,,2012,,,587–606,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Tucson, Arizona, USA",2012,9781450315616,,https://doi.org/10.1145/2384616.2384659;http://dx.doi.org/10.1145/2384616.2384659,10.1145/2384616.2384659,"We present Dependent JavaScript (DJS), a statically typed dialect of the imperative, object-oriented, dynamic language. DJS supports the particularly challenging features such as run-time type-tests, higher-order functions, extensible objects, prototype inheritance, and arrays through a combination of nested refinement types, strong updates to the heap, and heap unrolling to precisely track prototype hierarchies. With our implementation of DJS, we demonstrate that the type system is expressive enough to reason about a variety of tricky idioms found in small examples drawn from several sources, including the popular book JavaScript: The Good Parts and the SunSpider benchmark suite.","strong updates, arrays, refinement types, JavaScript, prototype inheritance",OOPSLA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chugh R,Herman D,Jhala R",Dependent Types for JavaScript,SIGPLAN Not.,2012,47,10,587–606,Association for Computing Machinery,"New York, NY, USA",,,,2012-10,,0362-1340,https://doi.org/10.1145/2398857.2384659;http://dx.doi.org/10.1145/2398857.2384659,10.1145/2398857.2384659,"We present Dependent JavaScript (DJS), a statically typed dialect of the imperative, object-oriented, dynamic language. DJS supports the particularly challenging features such as run-time type-tests, higher-order functions, extensible objects, prototype inheritance, and arrays through a combination of nested refinement types, strong updates to the heap, and heap unrolling to precisely track prototype hierarchies. With our implementation of DJS, we demonstrate that the type system is expressive enough to reason about a variety of tricky idioms found in small examples drawn from several sources, including the popular book JavaScript: The Good Parts and the SunSpider benchmark suite.","refinement types, JavaScript, prototype inheritance, arrays, strong updates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ducournau R,Morandat F",Towards a Full Multiple-Inheritance Virtual Machine,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Workshop on the Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems","Maribor, Slovenia",2010,9781450305372,,https://doi.org/10.1145/1925801.1925802;http://dx.doi.org/10.1145/1925801.1925802,10.1145/1925801.1925802,"Late binding and subtyping create run-time overhead for object-oriented languages, especially in the context of both multiple inheritance and dynamic loading, for instance for Java interfaces. It is, however, generally agreed that the efficiency of Java and .Net systems comes from the fact that, in these languages, classes are in single inheritance. In this paper, we present the abstract architecture of a virtual machine for unrestricted multiple-inheritance, which should provide the same runtime efficiency as Java and .Net.","closed-world assumption, adaptive compiler, perfect hashing, open-world assumption, multiple inheritance, method tables, virtual machine, late binding, dynamic loading, subtype test",ICOOOLPS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Amrani M,Schobbens PY",Formal Analysis of Object-Oriented Mograms,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th Workshop on Formal Techniques for Java-like Programs,"Barcelona, Spain",2017,9781450350983,,https://doi.org/10.1145/3103111.3104042;http://dx.doi.org/10.1145/3103111.3104042,10.1145/3103111.3104042,"A mogram designates a software language implemented in either a programming or a modelling language. Object-Oriented mograms share many common language features, but also have specificities related to inheritance, collection values, opposite and contained references, or overloading. We propose a mathematical framework that captures the semantics of such mograms with a precise characterisation of the variation points. We implemented a prototype tool that enables formal analysis in a uniform way.","Formal Verification, OO Languages, Semantics",FTFJP'17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Welsch Y,Grey-Box Specifications for Object-Oriented Program Components,,2008,,,913–914,Association for Computing Machinery,"New York, NY, USA",,Companion to the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582207,,https://doi.org/10.1145/1449814.1449905;http://dx.doi.org/10.1145/1449814.1449905,10.1145/1449814.1449905,"We present a formal specification technique for object-oriented program components based on their boundary message behaviour. Component specifications describe restrictions on the set of message traces for a component without referring to actual implementations. Finally, we provide a framework to link specifications with abstract states to their implementations.","grey-box specifications, components, oop",OOPSLA Companion '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Elliott MR,Heller P",Object-Oriented Software Considerations in Airborne Systems and Equipment Certification,,2010,,,85–96,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference Companion on Object Oriented Programming Systems Languages and Applications Companion,"Reno/Tahoe, Nevada, USA",2010,9781450302401,,https://doi.org/10.1145/1869542.1869558;http://dx.doi.org/10.1145/1869542.1869558,10.1145/1869542.1869558,"This is a practitioner's discussion of the production of software in airborne systems which operate in civil airspace and the changes impacting it with the introduction of DO-178C/ED-12C, the emerging standard for the development of safety-critical software in airborne systems. A focus is made on the impact of the object-oriented supplement to this document which establishes, for the first time, a standard for the use of object-oriented programming and design in this environment.Discussion is made of the state of airworthiness certification where software is concerned, the existing standard DO-178B/ED-12B[1], its history, perceived shortcomings, existing practice and how that may change with the new standard. Additionally, an overview is given of how this supplement introduces a formal type theory basis for reducing the amount of verification an applicant for airworthiness must demonstrate in order to provide the necessary safety assurance for an airborne system.","ED-12C, standards development, ED-12B, DO-178C, DO-178B, safety-critical software, DO-178, airborne software certification",OOPSLA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Drossopoulou S,Noble J,Miller MS,Murray T",Permission and Authority Revisited towards a Formalisation,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th Workshop on Formal Techniques for Java-like Programs,"Rome, Italy",2016,9781450344395,,https://doi.org/10.1145/2955811.2955821;http://dx.doi.org/10.1145/2955811.2955821,10.1145/2955811.2955821,"Miller's notions of permissions and authority are foundational to the analysis of object-capability programming. Informal definitions of these concepts were given in Miller's thesis. In this paper we propose precise definitions for permissions and authority, based on a small object-oriented calculus. We quantify their bounds (current, eventual, behavioural, topological), and delineate the relationships between these definitions.","Object-Capabilities, Permission, Authority",FTfJP'16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Karanikolas C,Dimitroulakos G,Masselos K",Early Evaluation of Implementation Alternatives of Composite Data Structures Toward Maintainability,ACM Trans. Softw. Eng. Methodol.,2017,26,2,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,1049-331X,https://doi.org/10.1145/3132731;http://dx.doi.org/10.1145/3132731,10.1145/3132731,"Selecting between different design options is a crucial decision for object-oriented software developers that affects code quality characteristics. Conventionally developers use their experience to make such decisions, which leads to suboptimal results regarding code quality. In this article, a formal model for providing early estimates of quality metrics of object-oriented software implementation alternatives is proposed. The model supports software developers in making fast decisions in a systematic way early during the design phase to achieve improved code characteristics. The approach employs a comparison model related to the application of the Visitor design pattern and inheritance-based implementation on structures following the Composite design pattern. The model captures maintainability as a metric of software quality and provides precise assessments of the quality of each implementation alternative. Furthermore, the model introduces the structural maintenance cost metric based on which the progressive analysis of the maintenance process is introduced. The proposed approach has been applied to several test cases for different relevant quality metrics. The results prove that the proposed model delivers accurate estimations. Thus, the proposed methodology can be used for comparing different implementation alternatives against various measures and quality factors before code development, leading to reduced effort and cost for software maintenance.","Visitor, Composition",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Findler RB,Felleisen M",ICFP 2002: Contracts for Higher-Order Functions,SIGPLAN Not.,2013,48,4S,34–45,Association for Computing Machinery,"New York, NY, USA",,,,2013-07,,0362-1340,https://doi.org/10.1145/2502508.2502521;http://dx.doi.org/10.1145/2502508.2502521,10.1145/2502508.2502521,"Assertions play an important role in the construction of robust software. Their use in programming languages dates back to the 1970s. Eiffel, an object-oriented programming language, wholeheartedly adopted assertions and developed the \Design by Contract\"" philosophy. Indeed",the entire object-oriented community recognizes the value of assertion-based contracts on methods.In contrast,languages with higher-order functions do not support assertion-based contracts. Because predicates on functions are,in general,undecidable,specifying such predicates appears to be meaningless. Instead,the functional languages community developed type systems that statically approximate interesting predicates.In this paper,we show how to support higher-order function contracts in a theoretically well-founded and practically viable manner. Specifically,we introduce ?CON,a typed lambda calculus with assertions for higher-order functions. The calculus models the assertion monitoring system that we employ in Dr Scheme. We establish basic properties of the model (type soundness,etc.) and illustrate the usefulness of contract checking with examples from Dr Scheme's code base.We believe that the development of an assertion system for higherorder functions serves two purposes. On one hand,the system has strong practical potential because existing type systems simply cannot express many assertions that programmers would like to state. nOn the other hand,"an inspection of a large base of invariants may provide inspiration for the direction of practical future type system research.""","software reliability, behavioral specifications, contracts, predicate typing, higher-order functions",,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Milojković N,Caracciolo A,Lungu MF,Nierstrasz O,Röthlisberger D,Robbes R",Polymorphism in the Spotlight: Studying Its Prevalence in Java and Smalltalk,,2015,,,186–195,IEEE Press,"Florence, Italy",,Proceedings of the 2015 IEEE 23rd International Conference on Program Comprehension,,2015,,,,,"Subtype polymorphism is a cornerstone of object-oriented programming. By hiding variability in behavior behind a uniform interface, polymorphism decouples clients from providers and thus enables genericity, modularity and extensibility. At the same time, however, it scatters the implementation of the behavior over multiple classes thus potentially hampering program comprehension.The extent to which polymorphism is used in real programs and the impact of polymorphism on program comprehension are not very well understood. We report on a preliminary study of the prevalence of polymorphism in several hundred open source software systems written in Smalltalk, one of the oldest object-oriented programming languages, and in Java, one of the most widespread ones.Although a large portion of the call sites in these systems are polymorphic, a majority have a small number of potential candidates. Smalltalk uses polymorphism to a much greater extent than Java. We discuss how these findings can be used as input for more detailed studies in program comprehension and for better developer support in the IDE.","polymorphism, programming languages, object-oriented programming, programming environments",ICPC '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Krishnaswami NR,Aldrich J,Birkedal L,Svendsen K,Buisse A",Design Patterns in Separation Logic,,2009,,,105–116,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th International Workshop on Types in Language Design and Implementation,"Savannah, GA, USA",2009,9781605584201,,https://doi.org/10.1145/1481861.1481874;http://dx.doi.org/10.1145/1481861.1481874,10.1145/1481861.1481874,"Object-oriented programs are notable for making use of both higher-order abstractions and mutable, aliased state. Either feature alone is challenging for formal verification, and the combination yields very flexible program designs and correspondingly difficult verification problems. In this paper, we show how to formally specify and verify programs that use several common design patterns in concert.","separation logic, design patterns",TLDI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hallett JJ,Luchangco V,Ryu S,Steele GL",Integrating Coercion with Subtyping and Multiple Dispatch,,2008,,,166–170,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Symposium on Applied Computing,"Fortaleza, Ceara, Brazil",2008,9781595937537,,https://doi.org/10.1145/1363686.1363733;http://dx.doi.org/10.1145/1363686.1363733,10.1145/1363686.1363733,"Coercion can greatly improve the readability of programs, especially in arithmetic expressions. However, coercion interacts with other features of programming languages, particularly subtyping and overloaded functions and operators, in ways that can produce surprising behavior. We study examples of such surprising behavior in existing languages. This study informs the design of the coercion mechanism of Fortress, an object-oriented language with multiple dynamic dispatch, multiple inheritance and user-defined coercion. We describe this design and show how its restrictions on overloaded declarations prevent ambiguous calls due to coercion.",,SAC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li L,Lu Y,Xue J",Dynamic Symbolic Execution for Polymorphism,,2017,,,120–130,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th International Conference on Compiler Construction,"Austin, TX, USA",2017,9781450352338,,https://doi.org/10.1145/3033019.3033029;http://dx.doi.org/10.1145/3033019.3033029,10.1145/3033019.3033029,"Symbolic execution is an important program analysis technique that provides auxiliary execution semantics to execute programs with symbolic rather than concrete values. There has been much recent interest in symbolic execution for automatic test case generation and security vulnerability detection, resulting in various tools being deployed in academia and industry. Nevertheless, (subtype or dynamic) polymorphism of object-oriented programs has been neglected: existing symbolic execution techniques can explore different targets of conditional branches but not different targets of method invocations. We address the problem of how this polymorphism can be expressed in a symbolic execution framework. We propose the notion of symbolic types, which make object types symbolic. With symbolic types,[ various targets of a method invocation can be explored systematically by mutating the type of the receiver object of the method during automatic test case generation. To the best of our knowledge, this is the first attempt to address polymorphism in symbolic execution. Mutation of method invocation targets is critical for effectively testing object-oriented programs, especially libraries. Our experimental results show that symbolic types are significantly more effective than existing symbolic execution techniques in achieving test coverage and finding bugs and security vulnerabilities in OpenJDK.","object-oriented programs, Concolic testing",CC 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Agrawal A,Khan RA",Impact of Inheritance on Vulnerability Propagation at Design Phase,SIGSOFT Softw. Eng. Notes,2009,34,4,1–5,Association for Computing Machinery,"New York, NY, USA",,,,2009-07,,0163-5948,https://doi.org/10.1145/1543405.1543411;http://dx.doi.org/10.1145/1543405.1543411,10.1145/1543405.1543411,"The design phase of software development provides the foundation for secure software. Reducing vulnerability at this phase minimizes rework in subsequent development phases. Currently, no efficient measure or method is available to reduce this vulnerability. In or-der to address this problem, we have proposed an algorithm to measure vulnerability propagation for an object-oriented design that calculates the Attribute Vulnerability Ratio (AVR).","software security, vulnerability, measurement, object oriented design, design, inheritance, class hierarchy",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Leavens GT,Naumann DA","Behavioral Subtyping, Specification Inheritance, and Modular Reasoning",ACM Trans. Program. Lang. Syst.,2015,37,4,,Association for Computing Machinery,"New York, NY, USA",,,,2015-08,,0164-0925,https://doi.org/10.1145/2766446;http://dx.doi.org/10.1145/2766446,10.1145/2766446,"Verification of a dynamically dispatched method call, E.m(), seems to depend on E’s dynamic type. To avoid case analysis and allow incremental development, object-oriented program verification uses supertype abstraction. In other words, one reasons about E.m() using m’s specification for E’s static type. Supertype abstraction is valid when each subtype in the program is a behavioral subtype. This article semantically formalizes supertype abstraction and behavioral subtyping for a Java-like sequential language with mutation and proves that behavioral subtyping is both necessary and sufficient for the validity of supertype abstraction. Specification inheritance, as in JML, is also formalized and proved to entail behavioral subtyping.","specification inheritance, verification, predicate transformer, dynamic dispatch, refinement, Eiffel language, supertype abstraction, JML language, Behavioral subtyping, state transformer, modularity, specification",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Briggs D,Alagić S",Algebraic Specification Techniques for Parametric Types with Logic-Based Constraints,,2009,,,1890–1897,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 ACM Symposium on Applied Computing,"Honolulu, Hawaii",2009,9781605581668,,https://doi.org/10.1145/1529282.1529705;http://dx.doi.org/10.1145/1529282.1529705,10.1145/1529282.1529705,"Mainstream object-oriented languages now offer capabilities of generic types with bounded type parameters, but they typically do not provide support for specifying semantic requirements on the type parameters' methods beyond conformance of signatures. Regrettably, even object-oriented assertion languages, such as JML, have nontrivial limitations in this regard. Yet many interesting parameterized types require additional semantic features if they are to function as intended. We illustrate the issues with a case study of project scheduling based on the Project Management Institute's generic characterization of task breakdowns. We consider algebraic techniques for instantiating parametric types in such a way that the semantic requirements expressed by logic-based constraints propagate to the instantiating types. These techniques argue for more general bindings of actual type parameters for the formal ones which do not have the restrictions of current programming languages. We show that types equipped with constraints should be viewed as theories, and the bindings as morphisms of types as theories. We translate these software specifications into theories in the PVS specification language. These proposals lead to conclusions about language features for more general, semantic bindings of the actual for the formal type parameters, at least in the assertion languages.","verification theories, assertions, parametric types, JML, PVS",SAC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Peldszus S,Kulcsár G,Lochau M,Schulze S",Incremental Co-Evolution of Java Programs Based on Bidirectional Graph Transformation,,2015,,,138–151,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Principles and Practices of Programming on The Java Platform,"Melbourne, FL, USA",2015,9781450337120,,https://doi.org/10.1145/2807426.2807438;http://dx.doi.org/10.1145/2807426.2807438,10.1145/2807426.2807438,"Modern Java IDE aim at assisting object-oriented software development workflows with continuously interleaved co-evolution steps of program editing and program refactoring. Program editing usually comprises manually performed program changes applied by a programmer at source code level. In contrast, refactorings consist of behavior-preserving program restructuring rules with complex preconditions, usually formulated over an appropriate program abstraction. To integrate both steps into a comprehensive program evolution framework, we present a graph-based approach for incremental co-evolution of Java programs. Our approach is based on a concise graph-based representation of Java programs by means of a reduced abstract syntax tree, augmented with additional cross-tree edges denoting crucial semantic information. On this basis, a precise formal specification of object-oriented program refactorings can be defined in terms of endogenous graph-transformation rules. In addition, we use Triple Graph Grammars (TGG) to define exogenous bidirectional graph transformation rules for automated incremental synchronization between a program graph and the corresponding source code. Our implementation relies on the graph-transformation engine eMoflon and currently supports the Java refactorings Pull Up Method and Create Superclass.","incremental synchronization, bidirectional graph transformation, program refactoring, program evolution",PPPJ '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Garrido JM,Applying Empirical and Formal Methods for Modelling Systems with Concurrency and Timing Aspects,,2017,,,81–87,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the SouthEast Conference,"Kennesaw, GA, USA",2017,9781450350242,,https://doi.org/10.1145/3077286.3077299;http://dx.doi.org/10.1145/3077286.3077299,10.1145/3077286.3077299,"Software systems with concurrency are very complicated because they consist of many components that run in parallel and there can be a large number of combinations of how the components can interact. Deadlock, livelock, and other behavior can easily get out of control. Timing aspect adds another degree to the complexity. A pragmatic approach is presented for improving the specification and modelling of concurrency and timing by combining the use of the formal specification language Timed Communicating Object Z (TCOZ) and object-oriented simulation with OOSimL.The specification language TCOZ is well-suited for specifying complex systems that include components with their own thread of control. Object-Oriented simulation with OOSimL provides a powerful approach and tool for modeling large and complex systems and is compatible with the CSP semantics of concurrency. The output of the simulation runs provide traces of the timed interactions that can be used for verification with respect to the specification of the system. There is a simple and consisting correspondence from a formal specification to the corresponding simulation modelling. A simple problem is specified with TCOZ and the simulation model implemented with OOSimL is used to carry out simulation runs. This problem consists of three concurrent processes communicating among themselves and with the environment, subject to timing constraints.","concurrency, Simulation Models, Formal Specification",ACM SE '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sprock T,McGinnis LF",Simulation Model Generation of Discrete Event Logistics Systems (Dels) Using Software Design Patterns,,2014,,,2714–2725,IEEE Press,"Savannah, Georgia",,Proceedings of the 2014 Winter Simulation Conference,,2014,,,,,"To provide automated access from a formal system model to multiple analysis tools, such as discrete event simulation or optimization, we extend current model-based systems engineering (MBSE) methodologies by introducing a new model to model transformation method based on object-oriented creational patterns from software design. Implemented in MATLAB's discrete event simulation tool, SimEvents, we demonstrate the methodology by generating two distinct use cases based on a distribution supply chain and manufacturing system.",,WSC '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ina L,Igarashi A",Gradual Typing for Generics,,2011,,,609–624,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Portland, Oregon, USA",2011,9781450309400,,https://doi.org/10.1145/2048066.2048114;http://dx.doi.org/10.1145/2048066.2048114,10.1145/2048066.2048114,"Gradual typing is a framework to combine static and dynamic typing in a single programming language. In this paper, we develop a gradual type system for class-based object-oriented languages with generics. We introduce a special type to denote dynamically typed parts of a program; unlike dynamic types introduced to C# 4.0, however, our type system allows for more seamless integration of dynamically and statically typed code.We formalize a gradual type system for Featherweight GJ with a semantics given by a translation that inserts explicit run-time checks. The type system guarantees that statically typed parts of a program do not go wrong, even if it includes dynamically typed parts. We also describe a basic implementation scheme for Java and report preliminary performance evaluation.","gradual typing, generics, dynamic types",OOPSLA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ina L,Igarashi A",Gradual Typing for Generics,SIGPLAN Not.,2011,46,10,609–624,Association for Computing Machinery,"New York, NY, USA",,,,2011-10,,0362-1340,https://doi.org/10.1145/2076021.2048114;http://dx.doi.org/10.1145/2076021.2048114,10.1145/2076021.2048114,"Gradual typing is a framework to combine static and dynamic typing in a single programming language. In this paper, we develop a gradual type system for class-based object-oriented languages with generics. We introduce a special type to denote dynamically typed parts of a program; unlike dynamic types introduced to C# 4.0, however, our type system allows for more seamless integration of dynamically and statically typed code.We formalize a gradual type system for Featherweight GJ with a semantics given by a translation that inserts explicit run-time checks. The type system guarantees that statically typed parts of a program do not go wrong, even if it includes dynamically typed parts. We also describe a basic implementation scheme for Java and report preliminary performance evaluation.","gradual typing, generics, dynamic types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ancona D,Corradi A",Semantic Subtyping for Imperative Object-Oriented Languages,,2016,,,568–587,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Amsterdam, Netherlands",2016,9781450344449,,https://doi.org/10.1145/2983990.2983992;http://dx.doi.org/10.1145/2983990.2983992,10.1145/2983990.2983992,"Semantic subtyping is an approach for defining sound and complete procedures to decide subtyping for expressive types, including union and intersection types; although it has been exploited especially in functional languages for XML based programming, recently it has been partially investigated in the context of object-oriented languages, and a sound and complete subtyping algorithm has been proposed for record types, but restricted to immutable fields, with union and recursive types interpreted coinductively to support cyclic objects. In this work we address the problem of studying semantic subtyping for imperative object-oriented languages, where fields can be mutable; in particular, we add read/write field annotations to record types, and, besides union, we consider intersection types as well, while maintaining coinductive interpretation of recursive types. In this way, we get a richer notion of type with a flexible subtyping relation, able to express a variety of type invariants useful for enforcing static guarantees for mutable objects. The addition of these features radically changes the defi- nition of subtyping, and, hence, the corresponding decision procedure, and surprisingly invalidates some subtyping laws that hold in the functional setting. We propose an intuitive model where mutable record val- ues contain type information to specify the values that can be correctly stored in fields. Such a model, and the correspond- ing subtyping rules, require particular care to avoid circularity between coinductive judgments and their negations which, by duality, have to be interpreted inductively. A sound and complete subtyping algorithm is provided, together with a prototype implementation.","Structural Types for Objects, Semantic Subtyp- ing, Read/Write Field Annotations",OOPSLA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ancona D,Corradi A",Semantic Subtyping for Imperative Object-Oriented Languages,SIGPLAN Not.,2016,51,10,568–587,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,0362-1340,https://doi.org/10.1145/3022671.2983992;http://dx.doi.org/10.1145/3022671.2983992,10.1145/3022671.2983992,"Semantic subtyping is an approach for defining sound and complete procedures to decide subtyping for expressive types, including union and intersection types; although it has been exploited especially in functional languages for XML based programming, recently it has been partially investigated in the context of object-oriented languages, and a sound and complete subtyping algorithm has been proposed for record types, but restricted to immutable fields, with union and recursive types interpreted coinductively to support cyclic objects. In this work we address the problem of studying semantic subtyping for imperative object-oriented languages, where fields can be mutable; in particular, we add read/write field annotations to record types, and, besides union, we consider intersection types as well, while maintaining coinductive interpretation of recursive types. In this way, we get a richer notion of type with a flexible subtyping relation, able to express a variety of type invariants useful for enforcing static guarantees for mutable objects. The addition of these features radically changes the defi- nition of subtyping, and, hence, the corresponding decision procedure, and surprisingly invalidates some subtyping laws that hold in the functional setting. We propose an intuitive model where mutable record val- ues contain type information to specify the values that can be correctly stored in fields. Such a model, and the correspond- ing subtyping rules, require particular care to avoid circularity between coinductive judgments and their negations which, by duality, have to be interpreted inductively. A sound and complete subtyping algorithm is provided, together with a prototype implementation.","Semantic Subtyp- ing, Read/Write Field Annotations, Structural Types for Objects",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lohfink A,Carnduff T,Thomas N,Ware M",An Object-Oriented Approach to the Representation of Spatiotemporal Geographic Features,,2007,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th Annual ACM International Symposium on Advances in Geographic Information Systems,"Seattle, Washington",2007,9781595939142,,https://doi.org/10.1145/1341012.1341058;http://dx.doi.org/10.1145/1341012.1341058,10.1145/1341012.1341058,"Geographic features change over time, this change being the result of some kind of event or occurrence. It has been a research challenge to represent this data in a manner that reflects human perception. Most database systems used in GIS are relational, and change is either captured by exhaustively storing all versions of data, or updates replace previous versions. This stems from the inherent difficulty of modelling geographic objects in relational tables. This difficulty is compounded when the necessary time dimension is introduced to model how those objects evolve. There is little doubt that the object-oriented (OO) paradigm holds significant advantages over the relational model when it comes to modelling real-world entities and spatial data, and we believe that this contention is particularly true when it comes to spatiotemporal data. In this paper, we describe a generic, object-oriented model for representing spatiotemporal geographic data, called the Feature Evolution Model (FEM), based on a 'state-event-state' approach. The model exploits the expressiveness of OO technology by representing both geographic entities and change as objects, and the potential complexities introduced by the temporal elements of change are minimised by subtyping. The conceptual model is represented using UML and has the advantage of being implementable by any OO programming language and database development environment. The generic model is applied to real-world geographic data, that of OS MasterMap Integrated Transport Network (ITN) data.","geographic data modeling spatial and spatio-temporal data modeling, object-orientation",GIS '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vergu V,Haisma M,Visser E",The Semantics of Name Resolution in Grace,,2017,,,63–74,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM SIGPLAN International Symposium on on Dynamic Languages,"Vancouver, BC, Canada",2017,9781450355261,,https://doi.org/10.1145/3133841.3133847;http://dx.doi.org/10.1145/3133841.3133847,10.1145/3133841.3133847,"Grace is a dynamic object oriented programming language designed to aid programming education. We present a formal model of and give an operational semantics for its object model and name resolution algorithm. Our main contributions are a systematic model of Grace’s name resolution using scope graphs, relating linguistic features to other languages, and an operationalization of this model in the form of an operational semantics which is readable and executable. The semantics are extensively tested against a reference Grace implementation.","name resolution, object orientation, dynamic semantics",DLS 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Vergu V,Haisma M,Visser E",The Semantics of Name Resolution in Grace,SIGPLAN Not.,2017,52,11,63–74,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,0362-1340,https://doi.org/10.1145/3170472.3133847;http://dx.doi.org/10.1145/3170472.3133847,10.1145/3170472.3133847,"Grace is a dynamic object oriented programming language designed to aid programming education. We present a formal model of and give an operational semantics for its object model and name resolution algorithm. Our main contributions are a systematic model of Grace’s name resolution using scope graphs, relating linguistic features to other languages, and an operationalization of this model in the form of an operational semantics which is readable and executable. The semantics are extensively tested against a reference Grace implementation.","object orientation, name resolution, dynamic semantics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Golovanov I,Hüttel H,Jakobsen M,Kettunen M",Behavioural Separation with Parallel Usages,,2021,,,51–58,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd ACM International Workshop on Formal Techniques for Java-like Programs,"Virtual, Denmark",2021,9781450385435,,https://doi.org/10.1145/3464971.3468424;http://dx.doi.org/10.1145/3464971.3468424,10.1145/3464971.3468424,"Mungo is an object-oriented language that uses typestates with a behavioural type system to ensure the absence of null-dereferencing. Typestates are usages that specify the admissible sequences of method calls on objects. Previous type systems for Mungo have all had a linearity constraint on objects. We present an extension of these systems, where usage specifications can now include a parallel construct that lets us describe separate local behaviour. A parallel usage describes a separation of the heap, and this allows us to reason about aliasing and to express arbitrary interleaving of local protocols. This also solves the state-space explosion problem for usages. Our extension retains the safety properties of previous type systems for Mungo.","separation logic, Behavioural types",FTfJP 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chiba S,Igarashi A,Zakirov S",Mostly Modular Compilation of Crosscutting Concerns by Contextual Predicate Dispatch,,2010,,,539–554,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Reno/Tahoe, Nevada, USA",2010,9781450302036,,https://doi.org/10.1145/1869459.1869503;http://dx.doi.org/10.1145/1869459.1869503,10.1145/1869459.1869503,"The modularity of aspect-oriented programming (AOP) has been a controversial issue. To investigate this issue compared with object-oriented programming (OOP), we propose a simple language providing AOP mechanisms, which are enhanced traditional OOP mechanisms. We also present its formal system and then show that programs in this language can be only mostly modularly (i.e. separately) typechecked and compiled.We mention a source of this unmodularity and discuss whether or not it is appropriate to claim that AOP breaks modularity compared with OOP.","java, AspectJ, aspect oriented programming",OOPSLA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chiba S,Igarashi A,Zakirov S",Mostly Modular Compilation of Crosscutting Concerns by Contextual Predicate Dispatch,SIGPLAN Not.,2010,45,10,539–554,Association for Computing Machinery,"New York, NY, USA",,,,2010-10,,0362-1340,https://doi.org/10.1145/1932682.1869503;http://dx.doi.org/10.1145/1932682.1869503,10.1145/1932682.1869503,"The modularity of aspect-oriented programming (AOP) has been a controversial issue. To investigate this issue compared with object-oriented programming (OOP), we propose a simple language providing AOP mechanisms, which are enhanced traditional OOP mechanisms. We also present its formal system and then show that programs in this language can be only mostly modularly (i.e. separately) typechecked and compiled.We mention a source of this unmodularity and discuss whether or not it is appropriate to claim that AOP breaks modularity compared with OOP.","java, AspectJ, aspect oriented programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Boronat A,Structural Model Subtyping with OCL Constraints,,2017,,,194–205,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th ACM SIGPLAN International Conference on Software Language Engineering,"Vancouver, BC, Canada",2017,9781450355254,,https://doi.org/10.1145/3136014.3136026;http://dx.doi.org/10.1145/3136014.3136026,10.1145/3136014.3136026,"In model-driven engineering (MDE), models abstract the relevant features of software artefacts and model management operations, including model transformations, act on them automating large tasks of the development process. Flexible reuse of such operations is an important factor to improve productivity when developing and maintaining MDE solutions. In this work, we revisit the traditional notion of object subtyping based on subsumption, discarded by other approaches to model subtyping. We refine a type system for object-oriented programming, with multiple inheritance, to support model types in order to analyse its advantages and limitations with respect to reuse in MDE. Specifically, we extend type expressions with referential constraints and with OCL constraints. Our approach has been validated with a tool that extracts model types from (EMF) metamodels, paired with their OCL constraints, automatically and that exploits the extended subtyping relation to reuse model management operations. We show that structural model subtyping is expressive enough to support variants of model subtyping, including multiple, partial and dynamic model subtyping. The tool has received the ACM badge \Artifacts Evaluated - Functional\"".""","EMF, type theory, Model subtyping, OCL",SLE 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Campos J,Vasconcelos VT",Imperative Objects with Dependent Types,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th Workshop on Formal Techniques for Java-like Programs,"Prague, Czech Republic",2015,9781450336567,,https://doi.org/10.1145/2786536.2786538;http://dx.doi.org/10.1145/2786536.2786538,10.1145/2786536.2786538,"Index refinements (or dependent types over a restricted domain) enable the expression of many desirable invariants that can be verified at compile time. We propose to incorporate a system of index refinements in a small, class-based, imperative, object-oriented language. While rooted in techniques formulated for dependently-typed functional languages, our type system is able to capture more than just value properties and pure computations. Index refinements, combined with a notion of pre- and post-type to track state, give programmers the ability to reason about effectful computations. Our type system distinguishes between two classes of objects, imposing an affine discipline to objects whose types are governed by indices, as opposed to conventional objects which can be freely shared. We have designed and implemented an expressive and decidable type system, which we illustrate through a number of examples.","mutable objects, dependent types, index refinements",FTfJP '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Doligez D,Jaume M,Rioboo R","Development of Secured Systems by Mixing Programs, Specifications and Proofs in an Object-Oriented Programming Environment: A Case Study within the FoCaLiZe Environment",,2012,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th Workshop on Programming Languages and Analysis for Security,"Beijing, China",2012,9781450314411,,https://doi.org/10.1145/2336717.2336726;http://dx.doi.org/10.1145/2336717.2336726,10.1145/2336717.2336726,"FoCaLiZe is an object-oriented programming environment that combines specifications, programs and proofs in the same language. This paper describes how its features can be used to formally express specifications and to develop by stepwise refinement the design and implementation of secured systems, while proving that the implementation meets its specification or design requirements. We thus obtain a modular implementation of a generic framework for the definition of security policies together with certified enforcement mechanism for these policies.","FoCaLiZe, security policies, enforcement mechanisms",PLAS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Felgentreff T,Millstein T,Borning A,Hirschfeld R",Checks and Balances: Constraint Solving without Surprises in Object-Constraint Programming Languages,,2015,,,767–782,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Pittsburgh, PA, USA",2015,9781450336895,,https://doi.org/10.1145/2814270.2814311;http://dx.doi.org/10.1145/2814270.2814311,10.1145/2814270.2814311,"Object-constraint programming systems integrate declarative constraint solving with imperative, object-oriented languages, seamlessly providing the power of both paradigms. However, experience with object-constraint systems has shown that giving too much power to the constraint solver opens up the potential for solutions that are surprising and unintended as well as for complex interactions between constraints and imperative code. On the other hand, systems that overly limit the power of the solver, for example by disallowing constraints involving mutable objects, object identity, or polymorphic message sends, run the risk of excluding the core object-oriented features of the language from the constraint part, and consequently not being able to express declaratively a large set of interesting problem solutions. In this paper we present design principles that tame the power of the constraint solver in object-constraint languages to avoid difficult corner cases and surprising solutions while retaining the key features of the approach, including constraints over mutable objects, constraints involving object identity, and constraints on the results of message sends. We present our solution concretely in the context of the Babelsberg object-constraint language framework, providing both an informal description of the resulting language and a formal semantics for a core subset of it. We validate the utility of this semantics with an executable version that allows us to run test programs and to verify that they provide the same results as existing implementations of Babelsberg in JavaScript, Ruby, and Smalltalk.","Object-Constraint Programming, Executable Semantics Test Suites, Constraints, Constraint Imperative Programming",OOPSLA 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Felgentreff T,Millstein T,Borning A,Hirschfeld R",Checks and Balances: Constraint Solving without Surprises in Object-Constraint Programming Languages,SIGPLAN Not.,2015,50,10,767–782,Association for Computing Machinery,"New York, NY, USA",,,,2015-10,,0362-1340,https://doi.org/10.1145/2858965.2814311;http://dx.doi.org/10.1145/2858965.2814311,10.1145/2858965.2814311,"Object-constraint programming systems integrate declarative constraint solving with imperative, object-oriented languages, seamlessly providing the power of both paradigms. However, experience with object-constraint systems has shown that giving too much power to the constraint solver opens up the potential for solutions that are surprising and unintended as well as for complex interactions between constraints and imperative code. On the other hand, systems that overly limit the power of the solver, for example by disallowing constraints involving mutable objects, object identity, or polymorphic message sends, run the risk of excluding the core object-oriented features of the language from the constraint part, and consequently not being able to express declaratively a large set of interesting problem solutions. In this paper we present design principles that tame the power of the constraint solver in object-constraint languages to avoid difficult corner cases and surprising solutions while retaining the key features of the approach, including constraints over mutable objects, constraints involving object identity, and constraints on the results of message sends. We present our solution concretely in the context of the Babelsberg object-constraint language framework, providing both an informal description of the resulting language and a formal semantics for a core subset of it. We validate the utility of this semantics with an executable version that allows us to run test programs and to verify that they provide the same results as existing implementations of Babelsberg in JavaScript, Ruby, and Smalltalk.","Constraint Imperative Programming, Object-Constraint Programming, Executable Semantics Test Suites, Constraints",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Aichernig BK,Brandl H,Jöbstl E,Krenn W",UML in Action: A Two-Layered Interpretation for Testing,SIGSOFT Softw. Eng. Notes,2011,36,1,1–8,Association for Computing Machinery,"New York, NY, USA",,,,2011-01,,0163-5948,https://doi.org/10.1145/1921532.1921559;http://dx.doi.org/10.1145/1921532.1921559,10.1145/1921532.1921559,"This paper presents a novel model-based test case generation approach that automatically derives test cases from UML state machines. UML is given a two-layered formal semantics by (1) mapping UML class diagrams and state charts to Back's Action Systems, (2) by interpreting these action systems as labeled transition systems. The first semantics provides a formal framework to capture the object-oriented machinery: classes, objects, inheritance, transitions, time-outs, signals, nested and parallel regions. The second mapping represents the tester's view on the interface in terms of input and output actions. Tretman's input-output conformance relation (ioco) forms the basis of our fault models. Mutation analysis on the models is used to generate test cases. A car alarm system serves as a running example",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Muehlboeck F,Tate R",Sound Gradual Typing is Nominally Alive and Well,Proc. ACM Program. Lang.,2017,1,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,,https://doi.org/10.1145/3133880;http://dx.doi.org/10.1145/3133880,10.1145/3133880,"Recent research has identified significant performance hurdles that sound gradual typing needs to overcome. These performance hurdles stem from the fact that the run-time checks gradual type systems insert into code can cause significant overhead. We propose that designing a type system for a gradually typed language hand in hand with its implementation from scratch is a possible way around these and several other hurdles on the way to efficient sound gradual typing. Such a design process also highlights the type-system restrictions required for efficient composition with gradual typing. We formalize the core of a nominal object-oriented language that fulfills a variety of desirable properties for gradually typed languages, and present evidence that an implementation of this language suffers minimal overhead even in adversarial benchmarks identified in earlier work.","Nominal, Transparency, Immediate Accountability, Gradual Typing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Köhler M,Eskandani N,Weisenburger P,Margara A,Salvaneschi G",Rethinking Safe Consistency in Distributed Object-Oriented Programming,Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428256;http://dx.doi.org/10.1145/3428256,10.1145/3428256,"Large scale distributed systems require to embrace the trade off between consistency and availability, accepting lower levels of consistency to guarantee higher availability. Existing programming languages are, however, agnostic to this compromise, resulting in consistency guarantees that are the same for the whole application and are implicitly adopted from the middleware or hardcoded in configuration files. In this paper, we propose to integrate availability in the design of an object-oriented language, allowing developers to specify different consistency and isolation constraints in the same application at the granularity of single objects. We investigate how availability levels interact with object structure and define a type system that preserves correct program behavior. Our evaluation shows that our solution performs efficiently and improves the design of distributed applications.","Java, replication, type systems, consistency",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Allier S,Sahraoui HA,Sadou S",Identifying Components in Object-Oriented Programs Using Dynamic Analysis and Clustering,,2009,,,136–148,IBM Corp.,USA,,Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research,"Ontario, Canada",2009,,,https://doi.org/10.1145/1723028.1723045;http://dx.doi.org/10.1145/1723028.1723045,10.1145/1723028.1723045,"We propose an approach for component candidate identification as a first step towards the extraction of component-based architectures from object-oriented programs. Our approach uses as input dynamic call graphs, built from execution traces corresponding to use cases. This allows to better capture the functional dependencies between classes. The component identification is treated as a clustering problem. To this end, we use formal concept analysis and design heuristics.We evaluate the feasibility of our approach on two programs. The obtained results are very satisfactory from both the performance and qualitative points of view.",,CASCON '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Given-Wilson T,Huang F,Jay B",Multi-Polymorphic Programming in Bondi,,2013,,,53–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM SIGPLAN Workshop on Generic Programming,"Boston, Massachusetts, USA",2013,9781450323895,,https://doi.org/10.1145/2502488.2502493;http://dx.doi.org/10.1145/2502488.2502493,10.1145/2502488.2502493,"The bondi programming language is multi-polymorphic, in that it supports four polymorphic programming styles within a small core of computation, namely a typed pattern calculus. bondi's expressive power is illustrated by considering the problem of assigning reviewers to a paper. As the context generalises from a committee to a committee with additional reviewers, to a conference, to a federation or confederation, the solution incorporates polymorphism familiar from the functional, generic functional, relational, path-based, and object-oriented programming styles, respectively. These experiments show that multi-polymorphic programming is both practical and desirable.","polymorphism, pattern matching, pattern calculus, generic programming, bondi",WGP '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rompf T,Amin N",Type Soundness for Dependent Object Types (DOT),,2016,,,624–641,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Amsterdam, Netherlands",2016,9781450344449,,https://doi.org/10.1145/2983990.2984008;http://dx.doi.org/10.1145/2983990.2984008,10.1145/2983990.2984008,"Scala’s type system unifies aspects of ML modules, object- oriented, and functional programming. The Dependent Object Types (DOT) family of calculi has been proposed as a new theoretic foundation for Scala and similar expressive languages. Unfortunately, type soundness has only been established for restricted subsets of DOT. In fact, it has been shown that important Scala features such as type refinement or a subtyping relation with lattice structure break at least one key metatheoretic property such as environment narrowing or invertible subtyping transitivity, which are usually required for a type soundness proof. The main contribution of this paper is to demonstrate how, perhaps surprisingly, even though these properties are lost in their full generality, a rich DOT calculus that includes recursive type refinement and a subtyping lattice with intersection types can still be proved sound. The key insight is that subtyping transitivity only needs to be invertible in code paths executed at runtime, with contexts consisting entirely of valid runtime objects, whereas inconsistent subtyping contexts can be permitted for code that is never executed.","dependent object types, soundness, Scala, DOT",OOPSLA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rompf T,Amin N",Type Soundness for Dependent Object Types (DOT),SIGPLAN Not.,2016,51,10,624–641,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,0362-1340,https://doi.org/10.1145/3022671.2984008;http://dx.doi.org/10.1145/3022671.2984008,10.1145/3022671.2984008,"Scala’s type system unifies aspects of ML modules, object- oriented, and functional programming. The Dependent Object Types (DOT) family of calculi has been proposed as a new theoretic foundation for Scala and similar expressive languages. Unfortunately, type soundness has only been established for restricted subsets of DOT. In fact, it has been shown that important Scala features such as type refinement or a subtyping relation with lattice structure break at least one key metatheoretic property such as environment narrowing or invertible subtyping transitivity, which are usually required for a type soundness proof. The main contribution of this paper is to demonstrate how, perhaps surprisingly, even though these properties are lost in their full generality, a rich DOT calculus that includes recursive type refinement and a subtyping lattice with intersection types can still be proved sound. The key insight is that subtyping transitivity only needs to be invertible in code paths executed at runtime, with contexts consisting entirely of valid runtime objects, whereas inconsistent subtyping contexts can be permitted for code that is never executed.","dependent object types, soundness, Scala, DOT",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chin WN,David C,Nguyen HH,Qin S",Enhancing Modular OO Verification with Separation Logic,,2008,,,87–99,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"San Francisco, California, USA",2008,9781595936899,,https://doi.org/10.1145/1328438.1328452;http://dx.doi.org/10.1145/1328438.1328452,10.1145/1328438.1328452,"Conventional specifications for object-oriented (OO) programs must adhere to behavioral subtyping in support of class inheritance and method overriding. However, this requirement inherently weakens the specifications of overridden methods in superclasses, leading to imprecision during program reasoning. To address this, we advocate a fresh approach to OO verification that focuses on the distinction and relation between specifications that cater to calls with static dispatching from those for calls with dynamic dispatching. We formulate a novel specification subsumption that can avoid code re-verification, where possible. Using a predicate mechanism, we propose a flexible scheme for supporting class invariant and lossless casting. Our aim is to lay the foundation for a practical verification system that is precise, concise and modular for sequential OO programs. We exploit the separation logic formalism to achieve this.","automated verification, lossless casting, static and dynamic specifications, enhanced subsumption, separation logic",POPL '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chin WN,David C,Nguyen HH,Qin S",Enhancing Modular OO Verification with Separation Logic,SIGPLAN Not.,2008,43,1,87–99,Association for Computing Machinery,"New York, NY, USA",,,,2008-01,,0362-1340,https://doi.org/10.1145/1328897.1328452;http://dx.doi.org/10.1145/1328897.1328452,10.1145/1328897.1328452,"Conventional specifications for object-oriented (OO) programs must adhere to behavioral subtyping in support of class inheritance and method overriding. However, this requirement inherently weakens the specifications of overridden methods in superclasses, leading to imprecision during program reasoning. To address this, we advocate a fresh approach to OO verification that focuses on the distinction and relation between specifications that cater to calls with static dispatching from those for calls with dynamic dispatching. We formulate a novel specification subsumption that can avoid code re-verification, where possible. Using a predicate mechanism, we propose a flexible scheme for supporting class invariant and lossless casting. Our aim is to lay the foundation for a practical verification system that is precise, concise and modular for sequential OO programs. We exploit the separation logic formalism to achieve this.","automated verification, separation logic, enhanced subsumption, static and dynamic specifications, lossless casting",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Clarke D,Sergey I",A Semantics for Context-Oriented Programming with Layers,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,International Workshop on Context-Oriented Programming,"Genova, Italy",2009,9781605585383,,https://doi.org/10.1145/1562112.1562122;http://dx.doi.org/10.1145/1562112.1562122,10.1145/1562112.1562122,"Context-oriented programming (COP) is a new programming approach whereby the context in which expressions evaluate can be adapted as a program runs. COP provides a degree of flexibility beyond object-oriented programming, while arguably retaining more modularity and structure than aspect-oriented programming. Although many languages exploring the context-oriented approach exist, to our knowledge no formal type-sound dynamic semantics of these languages exists. We address this shortcoming by providing a concise syntax-based formal semantics for context-oriented programming with layers, as witnessed by ContextL, ContextJ*, and other languages. Our language is based on Featherweight Java extended with layers and scoped layer activation and deactivation. As layers may introduce methods not appearing in classes, we also give a static type system that ensures that no program gets stuck (i.e., there exists a binding for each dispatched method call).",,COP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Saini D,Sunshine J,Aldrich J",A Theory of Typestate-Oriented Programming,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Workshop on Formal Techniques for Java-Like Programs,"Maribor, Slovenia",2010,9781450305402,,https://doi.org/10.1145/1924520.1924529;http://dx.doi.org/10.1145/1924520.1924529,10.1145/1924520.1924529,"Engineers in many disciplines use state machines to reason about system changes, and many object-oriented libraries require their clients to follow state machine protocols. No existing language, however, has native support for state machines, and programmers often lose productivity and introduce errors when trying to understand and follow interaction protocols. The Plaid language extends the object paradigm with explicit states and state transitions, in order to better model object state transitions. In this paper, we present Plaidcore, a core calculus for Plaid, which uses states and permissions to statically guarantee that clients use object protocols correctly.","verification, typestate oriented programming",FTFJP '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schaefer I,Bettini L,Damiani F",Compositional Type-Checking for Delta-Oriented Programming,,2011,,,43–56,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Tenth International Conference on Aspect-Oriented Software Development,"Porto de Galinhas, Brazil",2011,9781450306058,,https://doi.org/10.1145/1960275.1960283;http://dx.doi.org/10.1145/1960275.1960283,10.1145/1960275.1960283,"Delta-oriented programming is a compositional approach to flexibly implementing software product lines. A product line is represented by a code base and a product line declaration. The code base consists of a set of delta modules specifying modifications to object-oriented programs. The product line declaration provides the connection of the delta modules with the product features. This separation increases the reusability of delta modules. In this paper, we provide a foundation for compositional type checking of delta-oriented product lines of Java programs by presenting a minimal core calculus for delta-oriented programming. The calculus is equipped with a constraint-based type system that allows analyzing each delta module in isolation, such that that also the results of the analysis can be reused. By combining the analysis results for the delta modules with the product line declaration it is possible to establish that all the products of the product line are well-typed according to the Java type system.","software product line, type system, java",AOSD '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"McKeever S,Gill M,Connor A,Johnson D",Abstraction in Physiological Modelling Languages,,2013,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the Symposium on Theory of Modeling & Simulation - DEVS Integrative M&S Symposium,"San Diego, California",2013,9781627480321,,,,"In this paper we discuss two projects looking at applying advanced abstraction mechanisms from software engineering to the field of physiological modelling. We focus on two abstraction mechanisms commonly found in modern object-oriented programming languages: generics and inheritance. Generics allows classes to take other classes as parameters, allowing common behaviour to be described with particularities abstracted away. We demonstrate this technique on an example from heart modelling. Inheritance allows one to reuse code and to establish a subtype of an existing object. We focus on the benefits reaped from inheritance where this property enables run-time substitutability. This technique is demonstrated within the context of multi-scale tumour modelling. Finally, we look at how combining both techniques enables greater modularity and the construction of a model driven framework for the rapid creation and extension of families of biological models.","biological modelling, generics, domain specific languages, mathematical modelling, inheritance",DEVS 13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Miller H,Haller P,Burmako E,Odersky M",Instant Pickles: Generating Object-Oriented Pickler Combinators for Fast and Extensible Serialization,,2013,,,183–202,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages & Applications,"Indianapolis, Indiana, USA",2013,9781450323741,,https://doi.org/10.1145/2509136.2509547;http://dx.doi.org/10.1145/2509136.2509547,10.1145/2509136.2509547,"As more applications migrate to the cloud, and as \big data\"" edges into even more production environments",the performance and simplicity of exchanging data between compute nodes/devices is increasing in importance. An issue central to distributed programming,yet often under-considered,is serialization or pickling,i.e.,persisting runtime objects by converting them into a binary or text representation. Pickler combinators are a popular approach from functional programming; their composability alleviates some of the tedium of writing pickling code by hand,but they don't translate well to object-oriented programming due to qualities like open class hierarchies and subtyping polymorphism. Furthermore,both functional pickler combinators and popular,Java-based serialization frameworks tend to be tied to a specific pickle format,leaving programmers with no choice of how their data is persisted. In this paper,we present object-oriented pickler combinators and a framework for generating them at compile-time,called scala/pickling,designed to be the default serialization mechanism of the Scala programming language. The static generation of OO picklers enables significant performance improvements,outperforming Java and Kryo in most of our benchmarks. In addition to high performance and the need for little to no boilerplate,our framework is extensible: using the type class pattern,users can provide both (1) custom,easily interchangeable pickle formats and (2) custom picklers,to override the default behavior of the pickling framework. In benchmarks,we compare scala/pickling with other popular industrial frameworks,and present results on time,memory usage,and size when pickling/unpickling a number of data types used in real-world,"large-scale distributed applications and frameworks.""","serialization, meta-programming, scala, distributed programming, pickling",OOPSLA '13,,,,,,,,
1,Journal Article,"Miller H,Haller P,Burmako E,Odersky M",Instant Pickles: Generating Object-Oriented Pickler Combinators for Fast and Extensible Serialization,SIGPLAN Not.,2013,48,10,183–202,Association for Computing Machinery,"New York, NY, USA",,,,2013-10,,0362-1340,https://doi.org/10.1145/2544173.2509547;http://dx.doi.org/10.1145/2544173.2509547,10.1145/2544173.2509547,"As more applications migrate to the cloud, and as \big data\"" edges into even more production environments",the performance and simplicity of exchanging data between compute nodes/devices is increasing in importance. An issue central to distributed programming,yet often under-considered,is serialization or pickling,i.e.,persisting runtime objects by converting them into a binary or text representation. Pickler combinators are a popular approach from functional programming; their composability alleviates some of the tedium of writing pickling code by hand,but they don't translate well to object-oriented programming due to qualities like open class hierarchies and subtyping polymorphism. Furthermore,both functional pickler combinators and popular,Java-based serialization frameworks tend to be tied to a specific pickle format,leaving programmers with no choice of how their data is persisted. In this paper,we present object-oriented pickler combinators and a framework for generating them at compile-time,called scala/pickling,designed to be the default serialization mechanism of the Scala programming language. The static generation of OO picklers enables significant performance improvements,outperforming Java and Kryo in most of our benchmarks. In addition to high performance and the need for little to no boilerplate,our framework is extensible: using the type class pattern,users can provide both (1) custom,easily interchangeable pickle formats and (2) custom picklers,to override the default behavior of the pickling framework. In benchmarks,we compare scala/pickling with other popular industrial frameworks,and present results on time,memory usage,and size when pickling/unpickling a number of data types used in real-world,"large-scale distributed applications and frameworks.""","distributed programming, scala, pickling, serialization, meta-programming",,,,,,,,,
1,Conference Paper,"da Silva Feitosa S,Ribeiro RG,Du Bois AR",Property-Based Testing for Lambda Expressions Semantics in Featherweight Java,,2018,,,43–50,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the XXII Brazilian Symposium on Programming Languages,"Sao Carlos, Brazil",2018,9781450364805,,https://doi.org/10.1145/3264637.3264643;http://dx.doi.org/10.1145/3264637.3264643,10.1145/3264637.3264643,"The release of Java 8 represents one of the most significant updates to the Java language since its inception. The addition of λ-expressions allows the treatment of code as data in a compact way, improving the language expressivity. This paper addresses the problem of defining rigorous semantics for new features of Java, such as λ-expressions and default methods, using Featherweight Java (FJ), a well-known object-oriented calculus. To accomplish this task, we embed the formalization of these new features in two different semantics, checking them for safety properties using QuickCheck, a property-based testing library for Haskell.","property-based testing, featherweight Java, λ-expressions",SBLP '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Damiani F,Padovani L,Schaefer I",A Formal Foundation for Dynamic Delta-Oriented Software Product Lines,,2012,,,1–10,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Generative Programming and Component Engineering,"Dresden, Germany",2012,9781450311298,,https://doi.org/10.1145/2371401.2371403;http://dx.doi.org/10.1145/2371401.2371403,10.1145/2371401.2371403,"Delta-oriented programming (DOP) is a flexible approach for implementing software product lines (SPLs). DOP SPLs are implemented by a code base (a set of delta modules encapsulating changes to object-oriented programs) and a product line declaration (providing the connection of the delta modules with the product features). In this paper, we extend DOP by the capability to switch the implemented product configuration at runtime and present a formal foundation for dynamic DOP. A dynamic DOP SPL is a DOP SPL with a dynamic reconfiguration graph that specifies how to switch between different feature configurations. Dynamic DOP supports (unanticipated) software evolution such that at runtime, the product line declaration, the code base and the dynamic reconfiguration graph can be changed in any (unanticipated) way that preserves the currently running product. The type system of our dynamic DOP core calculus ensures that the dynamic reconfigurations lead to type safe products and do not cause runtime type errors.","dynamic software product lines, programming languages, featherweight Java, type soundness, evolution, runtime reconfiguration",GPCE '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Damiani F,Padovani L,Schaefer I",A Formal Foundation for Dynamic Delta-Oriented Software Product Lines,SIGPLAN Not.,2012,48,3,1–10,Association for Computing Machinery,"New York, NY, USA",,,,2012-09,,0362-1340,https://doi.org/10.1145/2480361.2371403;http://dx.doi.org/10.1145/2480361.2371403,10.1145/2480361.2371403,"Delta-oriented programming (DOP) is a flexible approach for implementing software product lines (SPLs). DOP SPLs are implemented by a code base (a set of delta modules encapsulating changes to object-oriented programs) and a product line declaration (providing the connection of the delta modules with the product features). In this paper, we extend DOP by the capability to switch the implemented product configuration at runtime and present a formal foundation for dynamic DOP. A dynamic DOP SPL is a DOP SPL with a dynamic reconfiguration graph that specifies how to switch between different feature configurations. Dynamic DOP supports (unanticipated) software evolution such that at runtime, the product line declaration, the code base and the dynamic reconfiguration graph can be changed in any (unanticipated) way that preserves the currently running product. The type system of our dynamic DOP core calculus ensures that the dynamic reconfigurations lead to type safe products and do not cause runtime type errors.","programming languages, featherweight Java, dynamic software product lines, evolution, type soundness, runtime reconfiguration",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sallenave O,Ducournau R",Efficient Compilation of .NET Programs for Embedded Systems,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Workshop on the Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems","Maribor, Slovenia",2010,9781450305372,,https://doi.org/10.1145/1925801.1925804;http://dx.doi.org/10.1145/1925801.1925804,10.1145/1925801.1925804,"The overhead associated with object-oriented languages has been the major drawback in their adoption by the embedded world. In this paper, we propose a compilation approach based on the closed-world assumption (CWA) that should enable OO technologies such as .Net on small embedded systems. Our implementation is based on a type analysis algorithm, which extends RTA so that it eliminates some subtype tests due to array covariance, and coloring, which maintain single subtyping invariants under the CWA. The impact of our global optimizations has been evaluated on embedded applications written in C#. Preliminary results show a noticeable reduction of the code size, class hierarchy and object mechanisms such as virtual calls and subtype tests.","embedded systems, late binding, subtype test, closed-world assumption",ICOOOLPS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Ducournau R,Implementing Statically Typed Object-Oriented Programming Languages,ACM Comput. Surv.,2011,43,3,,Association for Computing Machinery,"New York, NY, USA",,,,2011-04,,0360-0300,https://doi.org/10.1145/1922649.1922655;http://dx.doi.org/10.1145/1922649.1922655,10.1145/1922649.1922655,"Object-oriented programming represents an original implementation issue due to its philosophy of making the program behavior depend on the dynamic type of objects. This is expressed by the late binding mechanism, aka message sending. The underlying principle is that the address of the actually called procedure is not statically determined at compile-time, but depends on the dynamic type of a distinguished parameter known as the receiver. A similar issue arises with attributes, because their position in the object layout may also depend on the object's dynamic type. Furthermore, subtyping introduces another original feature (i.e., runtime subtype checks). All three mechanisms need specific implementations and data structures. In static typing, late binding is generally implemented with so-called virtual function tables. These tables reduce method calls to pointers to functions via a small fixed number of extra indirections. It follows that object-oriented programming yields some overhead, as compared to the usual procedural languages.The different techniques and their resulting overhead depend on several parameters. First, inheritance and subtyping may be single or multiple, and even a mixing is possible, as in Java and ˙NET which present single inheritance for classes and multiple subtyping for interfaces. Multiple inheritance is a well-known complication. Second, the production of executable programs may involve various schemes, from global compilation, which implies the closed-world assumption (CWA), as the whole program is known at compile time, to separate compilation and dynamic loading, where each program unit is compiled and loaded independently of any usage, hence under the open-world assumption (OWA). Global compilation is well-known to facilitate optimization.This article reviews the various implementation techniques available in static typing and in the three cases of single inheritance, multiple inheritance, and multiple subtyping. This language-independent survey focuses on separate compilation and dynamic loading, as they represent the most commonly used and the most demanding framework. However, many works have been undertaken in the global compilation framework, mostly for dynamically typed languages, but also applied to the EIFFEL language. Hence, we also examine global techniques and how they can improve implementation efficiency. Finally, mixed frameworks that combine open and closed world assumptions are considered. For instance, just-in-time (JIT) compilers work under provisional CWA, at the expense of possible recompilations. In contrast, we present an experimental compiler-linker, where separate compilation implies the OWA, whereas the whole program is finally linked under the CWA.","virtual function tables, Theta, Eiffel, Java, Binary tree dispatch, separate compilation, genericity, downcast, type analysis, static typing, multiple inheritance, message sending, C++, pointer adjustment, casting, coloring, PRM, single inheritance, method dispatch, linking, late binding, C#, dynamic loading",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oliveira BC,Moors A,Odersky M",Type Classes as Objects and Implicits,,2010,,,341–360,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Reno/Tahoe, Nevada, USA",2010,9781450302036,,https://doi.org/10.1145/1869459.1869489;http://dx.doi.org/10.1145/1869459.1869489,10.1145/1869459.1869489,"Type classes were originally developed in Haskell as a disciplined alternative to ad-hoc polymorphism. Type classes have been shown to provide a type-safe solution to important challenges in software engineering and programming languages such as, for example, retroactive extension of programs. They are also recognized as a good mechanism for concept-based generic programming and, more recently, have evolved into a mechanism for type-level computation.This paper presents a lightweight approach to type classes in object-oriented (OO) languages with generics using the CONCEPT pattern and implicits (a type-directed implicit parameter passing mechanism). This paper also shows how Scala's type system conspires with implicits to enable, and even surpass, many common extensions of the Haskell type class system, making Scala ideally suited for generic programming in the large.","c++ concepts, abstract datatypes, scala, type classes",OOPSLA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Oliveira BC,Moors A,Odersky M",Type Classes as Objects and Implicits,SIGPLAN Not.,2010,45,10,341–360,Association for Computing Machinery,"New York, NY, USA",,,,2010-10,,0362-1340,https://doi.org/10.1145/1932682.1869489;http://dx.doi.org/10.1145/1932682.1869489,10.1145/1932682.1869489,"Type classes were originally developed in Haskell as a disciplined alternative to ad-hoc polymorphism. Type classes have been shown to provide a type-safe solution to important challenges in software engineering and programming languages such as, for example, retroactive extension of programs. They are also recognized as a good mechanism for concept-based generic programming and, more recently, have evolved into a mechanism for type-level computation.This paper presents a lightweight approach to type classes in object-oriented (OO) languages with generics using the CONCEPT pattern and implicits (a type-directed implicit parameter passing mechanism). This paper also shows how Scala's type system conspires with implicits to enable, and even surpass, many common extensions of the Haskell type class system, making Scala ideally suited for generic programming in the large.","c++ concepts, type classes, abstract datatypes, scala",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Clark T,Static Meta-Object Protocols: Towards Efficient Reflective Object-Oriented Languages,,2016,,,160–167,Association for Computing Machinery,"New York, NY, USA",,Companion Proceedings of the 15th International Conference on Modularity,"Málaga, Spain",2016,9781450340335,,https://doi.org/10.1145/2892664.2892694;http://dx.doi.org/10.1145/2892664.2892694,10.1145/2892664.2892694,Reflection and extensibility in object-oriented programming languages can be supported by meta-object protocols (MOP) that define class-based interfaces over data representation and execution features. MOPs are typically dynamic in the sense that type-based dispatching is used to select between feature implementations at run time leading to a significant difference in execution speed compared to non-MOP-based languages. Defining a corresponding static-MOP would seem to be a solution whereby type-dispatching can occur at compile time. Such an approach requires the integration of a static type system with a MOP. This paper introduces a new reflective and extensible language called JMF written in Java that aims to generate efficient code through the use of a static-MOP. The contribution of this paper is to characterise a static-MOP and to show how it integrates with a type system for JMF.,"Type-Checking, Meta-Object Protocol, Reflection",MODULARITY Companion 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Qayum F,Heckel R",Analysing Refactoring Dependencies Using Unfolding of Graph Transformation Systems,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Frontiers of Information Technology,"Abbottabad, Pakistan",2009,9781605586427,,https://doi.org/10.1145/1838002.1838019;http://dx.doi.org/10.1145/1838002.1838019,10.1145/1838002.1838019,"Refactoring has emerged as a successful technique to reduce complexity of object oriented designs. But due to implicit dependencies not all sequences of refactorings are appropriate. In this paper we model refactoring steps as graph transformation and use the unfolding analysis technique to choose the sequence of refactorings best suited in order to improve the design. We use graphs to represent software architectures at the class level and graph transformation to formally describe their refactoring operations. This makes it possible to use concepts and techniques from the theory of graph transformation, such as unfolding to identify dependencies between refactoring steps.","search based refactoring, unfolding of graph transformation system, graph transformation systems",FIT '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ren BM,Toman J,Strickland TS,Foster JS",The Ruby Type Checker,,2013,,,1565–1572,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual ACM Symposium on Applied Computing,"Coimbra, Portugal",2013,9781450316569,,https://doi.org/10.1145/2480362.2480655;http://dx.doi.org/10.1145/2480362.2480655,10.1145/2480362.2480655,"We present the Ruby Type Checker (rtc), a tool that adds type checking to Ruby, an object-oriented, dynamic scripting language. Rtc is implemented as a Ruby library in which all type checking occurs at run time; thus it checks types later than a purely static system, but earlier than a traditional dynamic type system. Rtc supports type annotations on classes, methods, and objects and rtc provides a rich type language that includes union and intersection types, higherorder (block) types, and parametric polymorphism among other features. Rtc is designed so programmers can control exactly where type checking occurs: type-annotated objects serve as the \roots\"" of the type checking process","and unannotated objects are not type checked. We have applied rtc to several programs and found it to be easy to use and effective at checking types.""","ruby, gradual typing, run-time type systems, object-oriented type systems",SAC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Salan S,Teaching Object-Oriented Programming with Geometry,J. Comput. Sci. Coll.,2019,34,7,84,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,,2019-04,,1937-4771,,,"This tutorial provides a method to teach object-oriented programming (OOP) to new programmers. The method relies on using a running example to explain basic to advanced concepts in OOP. The example is based on geometry objects, e.g., a point, a triangle, a rectangle, as well as known concepts such as calculating a distance. Geometry is an area of mathematics that is accessible to students, and the teacher does not usually need to provide background knowledge before starting the lecture. Furthermore, it gives a natural way to illustrate the topic with figures, which allows the students to rely on visualization to better understand the material.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wegmann L,Mehta F,Sommerlad P,Stocker M",Scaps: Type-Directed API Search for Scala,,2016,,,95–104,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 7th ACM SIGPLAN Symposium on Scala,"Amsterdam, Netherlands",2016,9781450346481,,https://doi.org/10.1145/2998392.2998405;http://dx.doi.org/10.1145/2998392.2998405,10.1145/2998392.2998405,"Type-directed API search, using queries composed of both keywords and type signatures to retrieve definitions from APIs, are popular in the functional programming community. This search technique allows programmers to easily navigate complex and large APIs in order to find the definitions they are interested in. While there exist some effective approaches to address type-directed API search for functional languages, we observed that none of these have been successfully adapted for use with statically-typed, object-oriented languages. The challenge here is incorporating large and unified inheritance hierarchies and the resulting prevalence of subtyping into an API retrieval model. We describe a new approach to API retrieval and provide an implementation thereof for the Scala language. Our evaluation with queries mined from Q&A websites shows that the model retrieves definitions from the Scala standard library with 94% of the relevant results in the top 10.","Polarized Types, API Search and Retrieval",SCALA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zhang Y,Myers AC","Familia: Unifying Interfaces, Type Classes, and Family Polymorphism",Proc. ACM Program. Lang.,2017,1,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,,https://doi.org/10.1145/3133894;http://dx.doi.org/10.1145/3133894,10.1145/3133894,"Parametric polymorphism and inheritance are both important, extensively explored language mechanisms for providing code reuse and extensibility. But harmoniously integrating these apparently distinct mechanisms—and powerful recent forms of them, including type classes and family polymorphism—in a single language remains an elusive goal. In this paper, we show that a deep unification can be achieved by generalizing the semantics of interfaces and classes. The payoff is a significant increase in expressive power with little increase in programmer-visible complexity. Salient features of the new programming language include retroactive constraint modeling, underpinning both object-oriented programming and generic programming, and module-level inheritance with further-binding, allowing family polymorphism to be deployed at large scale. The resulting mechanism is syntactically light, and the more advanced features are transparent to the novice programmer. We describe the design of a programming language that incorporates this mechanism; using a core calculus, we show that the type system is sound. We demonstrate that this language is highly expressive by illustrating how to use it to implement highly extensible software and by showing that it can not only concisely model state-of-the-art features for code reuse, but also go beyond them.","Familia, language design, extensibility, type classes, family polymorphism, genericity, type-safety",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mokhov SA,Vassev E,Paquet J,Debbabi M",Towards a Self-Forensics Property in the ASSL Toolset,,2010,,,108–113,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third C* Conference on Computer Science and Software Engineering,"Montréal, Quebec, Canada",2010,9781605589015,,https://doi.org/10.1145/1822327.1822342;http://dx.doi.org/10.1145/1822327.1822342,10.1145/1822327.1822342,"This preliminary conceptual work discusses a notion of self-forensics as an autonomic property to augment the Autonomic System Specification Language (ASSL) framework of formal specification tools for autonomic systems. The core of the proposed methodology leverages existing designs, theoretical results, and implementing systems to enable rapid completion of and validation of the experiments and their the results initiated in this work. Specifically, we leverage the ASSL toolkit to add the self-forensics autonomic property (SFAP) to enable generation of the Java-based Object-Oriented Intensional Programming (JOOIP) language code laced with traces of Forensic Lucid to encode contextual forensic evidence and other expressions.","forensic lucid, JOOIP, forensic computing, GIPSY, self-forensics, ASSL, autonomic computing",C3S2E '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fähndrich M,Barnett M,Logozzo F",Embedded Contract Languages,,2010,,,2103–2110,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Symposium on Applied Computing,"Sierre, Switzerland",2010,9781605586397,,https://doi.org/10.1145/1774088.1774531;http://dx.doi.org/10.1145/1774088.1774531,10.1145/1774088.1774531,"Specifying application interfaces (APIs) with information that goes beyond method argument and return types is a long-standing quest of programming language researchers and practitioners. The number of type system extensions or specification languages is a testament to that. Unfortunately, the number of such systems is also roughly equal to the number of tools that consume them. In other words, every tool comes with its own specification language.In this paper we argue that for modern object-oriented languages, using an embedding of contracts as code is a better approach. We exemplify our embedding of Code Contracts on the Microsoft managed execution platform (.NET) using the C# programming language. The embedding works as well in Visual Basic. We discuss the numerous advantages of our approach and the technical challenges, as well as the status of tools that consume the embedded contracts.","CodeContracts, .NET, C#",SAC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schmid GS,Kuncak V",SMT-Based Checking of Predicate-Qualified Types for Scala,,2016,,,31–40,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 7th ACM SIGPLAN Symposium on Scala,"Amsterdam, Netherlands",2016,9781450346481,,https://doi.org/10.1145/2998392.2998398;http://dx.doi.org/10.1145/2998392.2998398,10.1145/2998392.2998398,"We present *qualified types* for Scala, a form of refinement types adapted to the Scala language. Qualified types allow users to refine base types and classes using predicate expressions. We implemented a type checker for qualified types that is embedded in Scala's next-generation compiler Dotty and delegates constraint checking to an SMT solver. Our system supports many of Scala's functional as well as its object-oriented constructs. To propagate user-provided qualifier ascriptions we utilize both Scala's own type system and an incomplete, but effective qualifier inference algorithm. Our evaluation shows that for a series of examples exerting various of Scala's language features, the additional compile-time overhead is manageable. By combining these features we show that one can verify essential safety properties such as static bounds-checks while retaining several of Scala's advanced features.","Refinement Types, Scala",SCALA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bagherzadeh M,Dyer R,Fernando RD,Sánchez J,Rajan H",Modular Reasoning in the Presence of Event Subtyping,,2015,,,117–132,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th International Conference on Modularity,"Fort Collins, CO, USA",2015,9781450332491,,https://doi.org/10.1145/2724525.2724569;http://dx.doi.org/10.1145/2724525.2724569,10.1145/2724525.2724569,"Separating crosscutting concerns while preserving modular reasoning is challenging. Type-based interfaces (event types) separate modularized crosscutting concerns (observers) and traditional object-oriented concerns (subjects). Event types paired with event specifications were shown to be effective in enabling modular reasoning about subjects and observers. Similar to class subtyping, organizing event types into subtyping hierarchies is beneficial. However, unrelated behaviors of observers and their arbitrary execution orders could cause unique, somewhat counterintuitive, reasoning challenges in the presence of event subtyping. These challenges threaten both tractability of reasoning and reuse of event types. This work makes three contributions. First, we pose and explain these challenges. Second, we propose an event-based calculus to show how these challenges can be overcome. Finally, we present modular reasoning rules of our technique and show its applicability to other event-based techniques.","Event subtyping, event type inheritance, translucid contracts, event specification refinement, modular rea- soning",MODULARITY 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sun X,Li B,Zhang S,Tao C,Chen X,Wen W",Using Lattice of Class and Method Dependence for Change Impact Analysis of Object Oriented Programs,,2011,,,1439–1444,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM Symposium on Applied Computing,"TaiChung, Taiwan",2011,9781450301138,,https://doi.org/10.1145/1982185.1982495;http://dx.doi.org/10.1145/1982185.1982495,10.1145/1982185.1982495,"Software change impact analysis (CIA) is a key technique to identify unpredicted and potential effects caused by software changes. In this paper, we propose a new CIA technique based on a compact and effective representation for object oriented programs, called lattice of class and method dependence (LoCMD). This novel representation can effectively capture the dependences between classes and methods. Based on the LoCMD, our CIA technique calculates a ranked list of potential impacted methods according to a metric, impact factor, which corresponds to the priority of these methods to be inspected. Initial case study validates the reasonability of our two assumptions, and demonstrates the effectiveness of our technique.","change impact analysis, impact factor, formal concept analysis, lattice of class and method dependence",SAC '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kim T,Bierhoff K,Aldrich J,Kang S",Typestate Protocol Specification in JML,,2009,,,11–18,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Workshop on Specification and Verification of Component-Based Systems,"Amsterdam, The Netherlands",2009,9781605586809,,https://doi.org/10.1145/1596486.1596490;http://dx.doi.org/10.1145/1596486.1596490,10.1145/1596486.1596490,"The Java Modeling Language (JML) is a language for specifying the behavior of Java source code. However, it can describe the protocols of Java classes and interfaces only implicitly. Typestate protocol specification is a more direct, lightweight and abstract way of documenting usage protocols for object-oriented programs. In this paper, we propose a technique for incorporating the typestate concept into JML for specifying protocols of Java classes and interfaces, based on our previous research on typestate protocol specifications [4]. This paper presents a set of formal translation rules for encoding typestate protocol specifications into pre/post-condition specifications. It shows how typestate protocol specifications can be mixed with pre/post-condition specifications and how violations of code contracts in inheritance can be handled. Finally, our proposed technique is demonstrated within the Java/JML environment to show its effectiveness.","usage protocol, jml, behavioral subtyping, typestate",SAVCBS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Karakoidas V,Mitropoulos D,Louridas P,Gousios G,Spinellis D",Generating the Blueprints of the Java Ecosystem,,2015,,,510–513,IEEE Press,"Florence, Italy",,Proceedings of the 12th Working Conference on Mining Software Repositories,,2015,9780769555942,,,,"Examining a large number of software artifacts can provide the research community with data regarding quality and design. We present a dataset obtained by statically analyzing 22730 jar files taken from the Maven central archive, which is the de-facto application library repository for the Java ecosystem. For our analysis we used three popular static analysis tools that calculate metrics regarding object-oriented design, program size, and package design. The dataset contains the metrics results that every tool reports for every selected jar of the ecosystem. Our dataset can be used to produce interesting research results, such as measure the domain-specific language usage.",,MSR '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Söderberg E,Hedin G",Building Semantic Editors Using JastAdd: Tool Demonstration,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Eleventh Workshop on Language Descriptions, Tools and Applications","Saarbrucken, Germany",2011,9781450306652,,https://doi.org/10.1145/1988783.1988794;http://dx.doi.org/10.1145/1988783.1988794,10.1145/1988783.1988794,"A semantic editor, providing services like completion and code browsing, can help users to quickly develop high-quality source code. However, a lot of languages still lack semantic editor support due to the difficulty and costs of development. Tool generation and reuse can greatly alleviate this development task. Specifically, tool generation from a formal specification, such as reference attribute grammars (RAGs), can increase development speed by reusing existing specifications. In this tool demonstration we demonstrate how semantic editors can be built with the aid of JastAdd, a meta-compilation tool based on RAGs. We demonstrate two editors built this way. One for a small object-oriented language, PicoJava, and one for the JastAdd specification language itself.","semantic editors, refererence attribute grammars, tool generation",LDTA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Garredu S,Vittori E,Santucci JF",A DEVS-Oriented Intuitive Modeling Language,,2009,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2009 Spring Simulation Multiconference,"San Diego, California",2009,,,,,"The purpose of this paper is to introduce a new graphical and intuitive programming language for DEVS models. It is the result of our global approach whose general aim is to enable a scientist to create and simulate DEVS models without the constraint of asking a DEVS expert to create the formal models and a computer scientist to program them. We explain here how our language is built, and we give an example of a model designed using it. Models from this language can be mapped onto DEVS models, using a model-driven approach (based on MDA) which is really helpful to perform an automated code generation towards an Object Oriented Language.","code generation, MDA, DEVS, specification languages, methodology",SpringSim '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Y,Zhang H,Oliveira BC,Servetto M",Classless Java,,2016,,,14–24,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences,"Amsterdam, Netherlands",2016,9781450344463,,https://doi.org/10.1145/2993236.2993238;http://dx.doi.org/10.1145/2993236.2993238,10.1145/2993236.2993238,"This paper presents an OO style without classes, which we call interface-based object-oriented programming (IB). IB is a natural extension of closely related ideas such as traits. Abstract state operations provide a new way to deal with state, which allows for flexibility not available in class-based languages. In IB state can be type-refined in subtypes. The combination of a purely IB style and type-refinement enables powerful idioms using multiple inheritance and state. To introduce IB to programmers we created Classless Java: an embedding of IB directly into Java. Classless Java uses annotation processing for code generation and relies on new features of Java 8 for interfaces. The code generation techniques used in Classless Java have interesting properties, including guarantees that the generated code is type-safe and good integration with IDEs. Usefulness of IB and Classless Java is shown with examples and case studies.","code generation, multiple inheritance, Interface-based programming",GPCE 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wang Y,Zhang H,Oliveira BC,Servetto M",Classless Java,SIGPLAN Not.,2016,52,3,14–24,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,0362-1340,https://doi.org/10.1145/3093335.2993238;http://dx.doi.org/10.1145/3093335.2993238,10.1145/3093335.2993238,"This paper presents an OO style without classes, which we call interface-based object-oriented programming (IB). IB is a natural extension of closely related ideas such as traits. Abstract state operations provide a new way to deal with state, which allows for flexibility not available in class-based languages. In IB state can be type-refined in subtypes. The combination of a purely IB style and type-refinement enables powerful idioms using multiple inheritance and state. To introduce IB to programmers we created Classless Java: an embedding of IB directly into Java. Classless Java uses annotation processing for code generation and relies on new features of Java 8 for interfaces. The code generation techniques used in Classless Java have interesting properties, including guarantees that the generated code is type-safe and good integration with IDEs. Usefulness of IB and Classless Java is shown with examples and case studies.","code generation, Interface-based programming, multiple inheritance",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ureche V,Biboudis A,Smaragdakis Y,Odersky M",Automating Ad Hoc Data Representation Transformations,,2015,,,801–820,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Pittsburgh, PA, USA",2015,9781450336895,,https://doi.org/10.1145/2814270.2814271;http://dx.doi.org/10.1145/2814270.2814271,10.1145/2814270.2814271,"To maximize run-time performance, programmers often specialize their code by hand, replacing library collections and containers by custom objects in which data is restructured for efficient access. However, changing the data representation is a tedious and error-prone process that makes it hard to test, maintain and evolve the source code. We present an automated and composable mechanism that allows programmers to safely change the data representation in delimited scopes containing anything from expressions to entire class definitions. To achieve this, programmers define a transformation and our mechanism automatically and transparently applies it during compilation, eliminating the need to manually change the source code. Our technique leverages the type system in order to offer correctness guarantees on the transformation and its interaction with object-oriented language features, such as dynamic dispatch, inheritance and generics. We have embedded this technique in a Scala compiler plugin and used it in four very different transformations, ranging from improving the data layout and encoding, to retrofitting specialization and value class status, and all the way to collection deforestation. On our benchmarks, the technique obtained speedups between 1.8x and 24.5x.","safety, optimization, jvm, transformation, data representation, compatibility, bytecode, semantics",OOPSLA 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ureche V,Biboudis A,Smaragdakis Y,Odersky M",Automating Ad Hoc Data Representation Transformations,SIGPLAN Not.,2015,50,10,801–820,Association for Computing Machinery,"New York, NY, USA",,,,2015-10,,0362-1340,https://doi.org/10.1145/2858965.2814271;http://dx.doi.org/10.1145/2858965.2814271,10.1145/2858965.2814271,"To maximize run-time performance, programmers often specialize their code by hand, replacing library collections and containers by custom objects in which data is restructured for efficient access. However, changing the data representation is a tedious and error-prone process that makes it hard to test, maintain and evolve the source code. We present an automated and composable mechanism that allows programmers to safely change the data representation in delimited scopes containing anything from expressions to entire class definitions. To achieve this, programmers define a transformation and our mechanism automatically and transparently applies it during compilation, eliminating the need to manually change the source code. Our technique leverages the type system in order to offer correctness guarantees on the transformation and its interaction with object-oriented language features, such as dynamic dispatch, inheritance and generics. We have embedded this technique in a Scala compiler plugin and used it in four very different transformations, ranging from improving the data layout and encoding, to retrofitting specialization and value class status, and all the way to collection deforestation. On our benchmarks, the technique obtained speedups between 1.8x and 24.5x.","transformation, bytecode, jvm, safety, compatibility, semantics, optimization, data representation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Todorova M,Kanev K",Educational Framework for Verification of Object-Oriented Programs,,2012,,,23–27,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2012 Joint International Conference on Human-Centered Computer Environments,"Aizu-Wakamatsu, Japan",2012,9781450311915,,https://doi.org/10.1145/2160749.2160755;http://dx.doi.org/10.1145/2160749.2160755,10.1145/2160749.2160755,"This article presents an educational framework, designed to support knowledge acquisition and skills development pertinent to program validation and in particular to formal methods for verification of object-oriented programs. The framework is intended to span from undergraduate classes, for junior and sophomore students, up to advanced classes, for graduate students. It supports distinct levels of access targeting: i) beginner, ii) intermediate, and iii) advanced users. Background knowledge and preliminarily acquired skills, associated with each access level, are well defined and reflected into the interaction interface that the framework presents to the user. For completeness, a reference description of the formal program verification method employed in the framework is included in the text, along with the underlying mathematical means supporting the method.","formal verification methods, object-oriented programming, education, verification, educational support and e-learning, generalized net, modeling, algorithm and program validation",HCCE '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Villavicencio G,A Bottom-up Approach to Understand Functional Programs,,2011,,,111–120,Association for Computing Machinery,"New York, NY, USA",,Proceedings of The Fourth International C* Conference on Computer Science and Software Engineering,"Montreal, Quebec, Canada",2011,9781450306263,,https://doi.org/10.1145/1992896.1992910;http://dx.doi.org/10.1145/1992896.1992910,10.1145/1992896.1992910,"One affective way to carry out a program comprehension process is by refactoring the source code. In this paper we explore this approach in the functional programming paradigm, on Haskell programs specifically. As result, we have identified many correlations between the traditional (procedural and object-oriented) program comprehension process and the so called understanding-oriented refactorings, in the functional programming context. Besides, we have identified a catalog of refactorings used to improve program efficiency which, applied in reverse order, are valuable for program understanding purposes. Coupled to these refactorings, there is a calculational process by (means of) which we obtain a full formal description of program functionality. All together, a bottom-up program comprehension strategy in the functional setting is described.","program comprehension, formal methods, refactorings",C3S2E '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"\rAkerblom B,Castegren E,Wrigstad T",Parallel Programming with Arrays in Kappa,,2018,,,24–33,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 5th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming","Philadelphia, PA, USA",2018,9781450358521,,https://doi.org/10.1145/3219753.3219757;http://dx.doi.org/10.1145/3219753.3219757,10.1145/3219753.3219757,"Array algorithms where operations are applied to disjoint parts of an array lend themselves well to parallelism, since parallel threads can operate on the parts of the array without synchronisation. However, implementing such algorithms requires programmer diligence to verify that a thread does not accidentally access an element of the array while another thread is updating the same element. An off-by-one error can lead to data-races and non-deterministic bugs which are notoriously hard to track down. Previous work on Kappa, a capability-based type system, provides data-race freedom for concurrent, object-oriented programs, even in the presence of concurrent mutating accesses to the same object. In this paper we show how Kappa can be extended to handle concurrent programming with arrays. By defining array capabilities which grant access to (parts of) an array, we can piggy-back on the existing type system in a straightforward fashion. We illustrate how split and merge operations integrate with Kappa in practise by discussing the implementation of a divide-and-conquer quicksort algorithm. We explore the semantics of the Kappa extension by using a simple imperative calculus and sketch on how it could be implemented efficiently.","Arrays, Capabilities, Concurrency, Type systems",ARRAY 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bertaux N,Delahaye D",Developing Structured Libraries Using the Focal Environment,,2009,,,2–10,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st Workshop on Modules and Libraries for Proof Assistants,"Montreal, Canada",2009,9781605589541,,https://doi.org/10.1145/1735813.1735815;http://dx.doi.org/10.1145/1735813.1735815,10.1145/1735813.1735815,"We introduce the Focal environment, which is an integrated development environment, offering functional and object-oriented features, and designed to build certified components using theorem proving. In Focal, inheritance provides a suitable notion of refinement, allowing us to go step by step (in an incremental approach) from abstract specifications to concrete implementations while proving that these implementations meet their specifications or design requirements. In addition, inheritance and parameterization offer a high level of reusability. To highlight these features, we present a survey of Focal, with a complete example of formalization in support. Finally, Focal is equipped with a compiler producing OCaml code for execution and Coq code for certification, and we also propose a compilation scheme based on modules, which is supposed to be an alternative to the current scheme using records and aims to provide a higher level view of compiled specifications supplying in particular traceability. This compilation scheme is not only described through an example, but also formally.","modules, OCaml, objects, Coq, Focal",MLPA '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Patrignani M,Agten P,Strackx R,Jacobs B,Clarke D,Piessens F",Secure Compilation to Protected Module Architectures,ACM Trans. Program. Lang. Syst.,2015,37,2,,Association for Computing Machinery,"New York, NY, USA",,,,2015-04,,0164-0925,https://doi.org/10.1145/2699503;http://dx.doi.org/10.1145/2699503,10.1145/2699503,"A fully abstract compiler prevents security features of the source language from being bypassed by an attacker operating at the target language level. Unfortunately, developing fully abstract compilers is very complex, and it is even more so when the target language is an untyped assembly language. To provide a fully abstract compiler that targets untyped assembly, it has been suggested to extend the target language with a protected module architecture—an assembly-level isolation mechanism which can be found in next-generation processors. This article provides a fully abstract compilation scheme whose source language is an object-oriented, high-level language and whose target language is such an extended assembly language. The source language enjoys features such as dynamic memory allocation and exceptions. Secure compilation of first-order method references, cross-package inheritance, and inner classes is also presented. Moreover, this article contains the formal proof of full abstraction of the compilation scheme. Measurements of the overhead introduced by the compilation scheme indicate that it is negligible.","Fully abstract compilation, protected module architecture",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Broman D,Siek JG",Gradually Typed Symbolic Expressions,,2017,,,15–29,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation,"Los Angeles, CA, USA",2017,9781450355872,,https://doi.org/10.1145/3162068;http://dx.doi.org/10.1145/3162068,10.1145/3162068,"Embedding a domain-specific language (DSL) in a general purpose host language is an efficient way to develop a new DSL. Various kinds of languages and paradigms can be used as host languages, including object-oriented, functional, statically typed, and dynamically typed variants, all having their pros and cons. For deep embedding, statically typed languages enable early checking and potentially good DSL error messages, instead of reporting runtime errors. Dynamically typed languages, on the other hand, enable flexible transformations, thus avoiding extensive boilerplate code. In this paper, we introduce the concept of gradually typed symbolic expressions that mix static and dynamic typing for symbolic data. The key idea is to combine the strengths of dynamic and static typing in the context of deep embedding of DSLs. We define a gradually typed calculus λ, formalize its type system and dynamic semantics, and prove type safety. We introduce a host language called Modelyze that is based on λ, and evaluate the approach by embedding a series of equation-based domain-specific modeling languages, all within the domain of physical modeling and simulation.","DSL, Type systems, Symbolic expressions",PEPM '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Haller P,Loiko A",LaCasa: Lightweight Affinity and Object Capabilities in Scala,,2016,,,272–291,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Amsterdam, Netherlands",2016,9781450344449,,https://doi.org/10.1145/2983990.2984042;http://dx.doi.org/10.1145/2983990.2984042,10.1145/2983990.2984042,"Aliasing is a known source of challenges in the context of imperative object-oriented languages, which have led to important advances in type systems for aliasing control. However, their large-scale adoption has turned out to be a surprisingly difficult challenge. While new language designs show promise, they do not address the need of aliasing control in existing languages. This paper presents a new approach to isolation and uniqueness in an existing, widely-used language, Scala. The approach is unique in the way it addresses some of the most important obstacles to the adoption of type system extensions for aliasing control. First, adaptation of existing code requires only a minimal set of annotations. Only a single bit of information is required per class. Surprisingly, the paper shows that this information can be provided by the object-capability discipline, widely-used in program security. We formalize our approach as a type system and prove key soundness theorems. The type system is implemented for the full Scala language, providing, for the first time, a sound integration with Scala's local type inference. Finally, we empirically evaluate the conformity of existing Scala open-source code on a corpus of over 75,000 LOC.","object capabilities, Scala, uniqueness, Aliasing",OOPSLA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Haller P,Loiko A",LaCasa: Lightweight Affinity and Object Capabilities in Scala,SIGPLAN Not.,2016,51,10,272–291,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,0362-1340,https://doi.org/10.1145/3022671.2984042;http://dx.doi.org/10.1145/3022671.2984042,10.1145/3022671.2984042,"Aliasing is a known source of challenges in the context of imperative object-oriented languages, which have led to important advances in type systems for aliasing control. However, their large-scale adoption has turned out to be a surprisingly difficult challenge. While new language designs show promise, they do not address the need of aliasing control in existing languages. This paper presents a new approach to isolation and uniqueness in an existing, widely-used language, Scala. The approach is unique in the way it addresses some of the most important obstacles to the adoption of type system extensions for aliasing control. First, adaptation of existing code requires only a minimal set of annotations. Only a single bit of information is required per class. Surprisingly, the paper shows that this information can be provided by the object-capability discipline, widely-used in program security. We formalize our approach as a type system and prove key soundness theorems. The type system is implemented for the full Scala language, providing, for the first time, a sound integration with Scala's local type inference. Finally, we empirically evaluate the conformity of existing Scala open-source code on a corpus of over 75,000 LOC.","Aliasing, object capabilities, Scala, uniqueness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Ducournau R,Perfect Hashing as an Almost Perfect Subtype Test,ACM Trans. Program. Lang. Syst.,2008,30,6,,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,0164-0925,https://doi.org/10.1145/1391956.1391960;http://dx.doi.org/10.1145/1391956.1391960,10.1145/1391956.1391960,"Subtype tests are an important issue in the implementation of object-oriented programming languages. Many techniques have been proposed, but none of them perfectly fulfills the five requirements that we have identified: constant-time, linear-space, multiple inheritance, dynamic loading and inlining. In this article, we propose a subtyping test implementation that involves a combination of usual hashtables and Cohen's display, which is a well-known technique for single inheritance hierarchies. This novel approach is based on perfect hashing, that is, an optimized and truly constant-time variant of hashing that applies to immutable hashtables. We show that the resulting technique closely meets all five requirements. Furthermore, in the framework of Java-like languages—characterized by single inheritance of classes and multiple subtyping of interfaces—perfect hashing also applies to method invocation when the receiver is typed by an interface. The proposed technique is compared to some alternatives, including the proposal by Palacz and Vitek [2003]. Time-efficiency is assessed at the cycle level in the framework of Driesen's pseudo-code and the linear-space criterion is validated by statistical simulation on benchmarks consisting of large-scale class hierarchies.","subtype test, single inheritance, virtual function tables, multiple inheritance, Casting, multiple subtyping, coloring, perfect hashing, downcast, interfaces, dynamic loading, method tables",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Allam D,Grall H,Royer JC",The Substitution Principle in an Object-Oriented Framework for Web Services: From Failure to Success,,2013,,,250–259,Association for Computing Machinery,"New York, NY, USA",,Proceedings of International Conference on Information Integration and Web-Based Applications & Services,"Vienna, Austria",2013,9781450321136,,https://doi.org/10.1145/2539150.2539192;http://dx.doi.org/10.1145/2539150.2539192,10.1145/2539150.2539192,"Nowadays, services are more and more implemented by using object-oriented frameworks. In this context, two properties could be particularly required in the specification of these frameworks: (i) a loose coupling between the service layer and the object layer, allowing evolution of the service layer with a minimal impact on the object layer, (ii) an interoperability induced by the substitution principle associated to subtyping in the object layer, allowing to freely convert a value of a subtype into a supertype. However, experimenting with the popular cxf framework, we observed some undesirable coupling and interoperability issues, due to the failure of the substitution principle. Therefore we propose a new specification of the data binding used to translate data between the object and service layers. We show that if the cxf framework followed the specification, then the substitution principle would be recovered, with all its advantages.","Interoperability, Subtyping, Basics of Category Theory, Service-Oriented Computing, Object-Oriented Programming, Loose Coupling",IIWAS '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Olszewski M,Cyra L",An Integrated Framework for Security Protocol Analysis,,2008,,,77–86,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2008 ACM Symposium on Information, Computer and Communications Security","Tokyo, Japan",2008,9781595939791,,https://doi.org/10.1145/1368310.1368325;http://dx.doi.org/10.1145/1368310.1368325,10.1145/1368310.1368325,"Assurance of security protocols needs particular attention. Flaws in a protocol can devastate security of the applications that rely on it. Analysis of the protocols is difficult and it is recommended that formal methods are employed to provide for higher levels of assurance. However, the formal methods can cover only a part of the scope of the problem. It is important that the formal models are valid representations of the protocol and that the application context is adequately represented. In the paper we present an analytical framework that integrates the object-oriented and formal modeling approaches. Object models are used to capture the relevant aspects of the protocol and its security context and to communicate with the protocol designers. Formal models are applied to verify the protocol security properties. Applicability of the framework was demonstrated by several industrial case studies.","object orientation, analytical framework",ASIACCS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,,VDMTools: Advances in Support for Formal Modeling in VDM,SIGPLAN Not.,2008,43,2,3–11,Association for Computing Machinery,"New York, NY, USA",,,,2008-02,,0362-1340,https://doi.org/10.1145/1361213.1361214;http://dx.doi.org/10.1145/1361213.1361214,10.1145/1361213.1361214,"We describe the current status of \VDMTools\""",a group of tools supporting the analysis of system models expressed in the formal language of the Vienna Development Method. Three dialects of the language are supported: the ISO standard VDM specification language with support for modular structuring,the extension VDM++ which supports object-oriented structuring and concurrency,and a version extending VDM++ with features for modeling and analysing distributed embedded real-time systems. VDMTools provides extensive static semantics checking,automatic code generation,round-trip mapping to UML class diagrams,documentation support,"test coverage analysis and debugging support. The tools' focus is on supporting the cost-effective development and exploitation of formal models in industrial settings. The paper presents the components of VDMTools and reports recent experience using them for the development of large models.""","tool support, validation, VDM, formal methods, vienna development method",,,,,,,,,,,,,,,,,,,,,,,,
1,Book Chapter,"Theisz Z,Bácsi S,Mezei G,Somogyi FA,Palatinszky D",By Multi-Layer to Multi-Level Modeling,,2019,,,134–141,IEEE Press,,Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems,,,2019,9781728151250,,https://doi.org/10.1109/MODELS-C.2019.00024;http://dx.doi.org/10.1109/MODELS-C.2019.00024,10.1109/MODELS-C.2019.00024,"Multi-level modeling has a well-defined and commonly agreed on aim of avoiding any kind of accidental complexity by the introduction of meta-levels. However, the actual means of achieving this goal are left to the discretion of the particular approach to decide on. Potency notion-based clabjects provide a suitable trade-off in this regard, hence other approaches tend to imitate these characteristics. Dynamic MultiLayer Algebra (DMLA) is such an alternative formal modeling technique that has already been tested successfully against multilevel challenges such as the MULTI 2018 workshop's Bicycle Challenge. Although DMLA has proved its merit, it has still been lacking the capability of integrating object-oriented features such as inheritance into its formalism. Therefore, in this paper, we showcase one potential way of incorporating inheritance with abstract entities into DMLA without having to relinquish any of its formal precision such as self-validation or self-description. The paper both describes our technical solution and illustrates it through a model excerpt borrowed from the Bicycle Challenge.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lu S,Paris C,Linden KV,Colineau N",Generating UML Diagrams from Task Models,,2003,,,9–14,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th Annual Conference of the ACM Special Interest Group on Computer-Human Interaction,"Dunedin, New Zealand",2003,9780473095536,,https://doi.org/10.1145/2331829.2331832;http://dx.doi.org/10.1145/2331829.2331832,10.1145/2331829.2331832,"The importance of task analysis and modelling to software system development is well recognised. After all, the central mission for most software systems is to help users accomplish their tasks. However, while object-oriented analysis and design (OOAD) has been established as the major paradigm in the software industry, effectively incorporating task analysis and modelling into that process is still in the realm of research. In this paper, we propose a novel approach for integrating OOAD and Task Modelling. By exploiting the common semantic ground between task models and system behaviour models, we describe how UML diagrams, such as use cases, use case diagrams and scenario diagrams, can be automatically generated from task models represented in a semi-formal notation. We demonstrate our approach with a working example.","information reuse, methodology, domain models, UML, tools, task models, object-oriented analysis and design",CHINZ '03,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Feitosa SS,Mena AS,Ribeiro RG,Bois AR",An Inherently-Typed Formalization for Featherweight Java,,2019,,,11–18,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the XXIII Brazilian Symposium on Programming Languages,"Salvador, Brazil",2019,9781450376389,,https://doi.org/10.1145/3355378.3355385;http://dx.doi.org/10.1145/3355378.3355385,10.1145/3355378.3355385,"Featherweight Java is one of the most popular calculi which specify object-oriented programming features. It has been used as the basis for investigating novel language functionalities, as well as to specify and understand the formal properties of existing features for languages in this paradigm. However, when considering mechanized formalization, it is hard to find an implementation for languages with complex structures and binding mechanisms as Featherweight Java. In this paper we explore an inherently-typed approach to formalize Featherweight Java, implementing the static and dynamic semantics in Agda using dependent types, and then replicating it in Coq (the latter using the Equations plug-in). Using this approach, the interpreter is correct by construction, since the type checker of the host language is responsible for verifying type safety, thus avoiding repetitions of proofs and error checking.","Featherweight Java, Dependent Types, Agda, Mechanized Semantics",SBLP 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hu T,Yao Y,Yao F",An Object Class Interaction Graph Modeling Method That Supports Parallel Discrete Event Simulation,,2019,,,56–60,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 3rd International Conference on Management Engineering, Software Engineering and Service Sciences","Wuhan, China",2019,9781450361897,,https://doi.org/10.1145/3312662.3312684;http://dx.doi.org/10.1145/3312662.3312684,10.1145/3312662.3312684,"Parallel Discrete Event simulation (PDEs) is an important technology for studying large-scale complex systems[1]. And there are some problems in the present PDEs modeling, such as poor intuitiveness, low efficiency, difficulty in expansion and reuse, insufficient support of modeling environment for model checking, difficulty in model checking and so on. For these problems, a parallel discrete event simulation modeling method, named Object Class Interaction Graph(OCIG), based on basic event graph and object-oriented thinking is proposed. It has the natural and simple advantages of event graph modeling for discrete event simulation, and it can well meet the requirements of scalable, easy assembly, and layered parallelism for parallel discrete event simulation applications. The article also uses the set theory to formally define it, laying the foundation for the subsequent formal checking of the model [2].","Object Class Interaction Graph, Model Checking, Event Graph, Parallel Discrete Event Simulation",ICMSS 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Kosiuczenko P,On the Synthesis of Protocol State Machines from Contracts,,2016,,,76–85,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM/IEEE 19th International Conference on Model Driven Engineering Languages and Systems,"Saint-malo, France",2016,9781450343213,,https://doi.org/10.1145/2976767.2976783;http://dx.doi.org/10.1145/2976767.2976783,10.1145/2976767.2976783,"Contractual specifications and UML state machines belong to the basic means for the specification and modelling of object-oriented system behaviour and are the subject of active research. However, the problem of state machines synthesis from contracts has not been researched. In this paper, this problem is investigated and a suitable procedure for protocol state machine generation is presented. This procedure is based on a method used in specification-based testing; it is formally defined, stepwise and based on a well-defined mathematical model. Its applicability is demonstrated on a bank account example often used in the literature. It is shown that resulting protocol state machines help to grasp the meaning of specifications and, as a side effect, to identify flaws in the specification such as unreachable states.","first-order logic, synthesis of protocol state machines, state-invariants, OCL, pre- post-conditions, contractual specification",MODELS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Damiani F,Schaefer I",Dynamic Delta-Oriented Programming,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 15th International Software Product Line Conference, Volume 2","Munich, Germany",2011,9781450307895,,https://doi.org/10.1145/2019136.2019175;http://dx.doi.org/10.1145/2019136.2019175,10.1145/2019136.2019175,"Modern software systems should be designed to dynamically adapt to changing user requirements or resource constraints. Delta-oriented programming (DOP) is a compositional approach to flexibly implement software product lines. In DOP, a product line is represented by a code base and a product line declaration. The code base consists of a set of delta modules specifying modifications to object-oriented programs. The product line declaration provides the connection of the delta modules with the product features and describes how the product for a particular feature configuration is generated. DOP has so far only been used for static variability. In this paper, we present dynamic DOP, an extension of DOP that supports changing the feature configuration of a product at runtime. A dynamic DOP product line is a standard DOP product line with a reconfiguration automaton that specifies how to switch between different feature configurations. The type system of our dynamic DOP language ensures that any reconfiguration leads to a type safe product. Dynamic DOP is an approach for realizing dynamic product lines which also supports (unanticipated) software evolution.","runtime reconfiguration, programming languages, dynamic software product lines, evolution",SPLC '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cohen M,Zhu HS,Senem EE,Liu YD",Energy Types,,2012,,,831–850,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Tucson, Arizona, USA",2012,9781450315616,,https://doi.org/10.1145/2384616.2384676;http://dx.doi.org/10.1145/2384616.2384676,10.1145/2384616.2384676,"This paper presents a novel type system to promote and facilitate energy-aware programming. Energy Types is built upon a key insight into today's energy-efficient systems and applications: despite the popular perception that energy and power can only be described in joules and watts, real-world energy management is often based on discrete phases and modes, which in turn can be reasoned about by type systems very effectively. A phase characterizes a distinct pattern of program workload, and a mode represents an energy state the program is expected to execute in. This paper describes a programming model where phases and modes can be intuitively specified by programmers or inferred by the compiler as type information. It demonstrates how a type-based approach to reasoning about phases and modes can help promote energy efficiency. The soundness of our type system and the invariants related to inter-phase and inter-mode interactions are rigorously proved. Energy Types is implemented as the core of a prototyped object-oriented language ET for smartphone programming. Preliminary studies show ET can lead to significant energy savings for Android Apps.","type systems, energy efficiency, energy-aware software",OOPSLA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Cohen M,Zhu HS,Senem EE,Liu YD",Energy Types,SIGPLAN Not.,2012,47,10,831–850,Association for Computing Machinery,"New York, NY, USA",,,,2012-10,,0362-1340,https://doi.org/10.1145/2398857.2384676;http://dx.doi.org/10.1145/2398857.2384676,10.1145/2398857.2384676,"This paper presents a novel type system to promote and facilitate energy-aware programming. Energy Types is built upon a key insight into today's energy-efficient systems and applications: despite the popular perception that energy and power can only be described in joules and watts, real-world energy management is often based on discrete phases and modes, which in turn can be reasoned about by type systems very effectively. A phase characterizes a distinct pattern of program workload, and a mode represents an energy state the program is expected to execute in. This paper describes a programming model where phases and modes can be intuitively specified by programmers or inferred by the compiler as type information. It demonstrates how a type-based approach to reasoning about phases and modes can help promote energy efficiency. The soundness of our type system and the invariants related to inter-phase and inter-mode interactions are rigorously proved. Energy Types is implemented as the core of a prototyped object-oriented language ET for smartphone programming. Preliminary studies show ET can lead to significant energy savings for Android Apps.","energy efficiency, energy-aware software, type systems",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sundaram D,Wolf E",Enterprise Model Management Systems,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Workshop on Enterprises & Organizational Modeling and Simulation,"Amsterdam, The Netherlands",2009,9781450373012,,https://doi.org/10.1145/1750405.1750412;http://dx.doi.org/10.1145/1750405.1750412,10.1145/1750405.1750412,"Decision making in the managerial context is often unstructured, ad-hoc, and complex. It involves structuring and solving the problem, and interpreting the results. A computer-based environment that supports these decision making processes is characterised by a modelling approach that enables the representation of the complexity of the problem, access to data and solvers, persistence of problem representation, and the ability to manipulate and integrate problem representations. Lack of a general framework for conceptual modelling and constraints imposed by technology have, in the past, limited the design and implementation of enterprise model management systems (EMMS). This research attempts to overcome key problems in EMMS design and implementation by proposing, implementing, and evaluating a modelling framework that uses Structured Modelling to describe models, object-oriented and relational constructs to represent models, and predicate calculus-based extended Structured Query Language (ESQL) to manipulate models.","enterprise model management systems, structured modelling, object-relational, decision making, model management",EOMAS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ross KA,Stoyanovich J",Schema Polynomials and Applications,,2008,,,404–415,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Extending Database Technology: Advances in Database Technology,"Nantes, France",2008,9781595939265,,https://doi.org/10.1145/1353343.1353394;http://dx.doi.org/10.1145/1353343.1353394,10.1145/1353343.1353394,"Conceptual complexity is emerging as a new bottleneck as data-base developers, application developers, and database administrators struggle to design and comprehend large, complex schemas. The simplicity and conciseness of a schema depends critically on the idioms available to express the schema. We propose a formal conceptual schema representation language that combines different design formalisms, and allows schema manipulation that exposes the strengths of each of these formalisms. We demonstrate how the schema factorization framework can be used to generate relational, object-oriented, and faceted physical schemas, allowing a wider exploration of physical schema alternatives than traditional methodologies. We illustrate the potential practical benefits of schema factorization by showing that simple heuristics can significantly reduce the size of a real-world schema description. We also propose the use of schema polynomials to model and derive alternative representations for complex relationships with constraints.",,EDBT '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tërnava X,Mortara J,Collet P",Identifying and Visualizing Variability in Object-Oriented Variability-Rich Systems,,2019,,,231–243,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Systems and Software Product Line Conference - Volume A,"Paris, France",2019,9781450371384,,https://doi.org/10.1145/3336294.3336311;http://dx.doi.org/10.1145/3336294.3336311,10.1145/3336294.3336311,"In many variability-intensive systems, variability is implemented in code units provided by a host language, such as classes or functions, which do not align well with the domain features. Annotating or creating an orthogonal decomposition of code in terms of features implies extra effort, as well as massive and cumbersome refactoring activities. In this paper, we introduce an approach for identifying and visualizing the variability implementation places within the main decomposition structure of object-oriented code assets in a single variability-rich system. First, we propose to use symmetry, as a common property of some main implementation techniques, such as inheritance or overloading, to identify uniformly these places. We study symmetry in different constructs (e.g., classes), techniques (e.g., subtyping, overloading) and design patterns (e.g., strategy, factory), and we also show how we can use such symmetries to find variation points with variants. We then report on the implementation and application of a toolchain, symfinder, which automatically identifies and visualizes places with symmetry. The publicly available application to several large open-source systems shows that symfinder can help in characterizing code bases that are variability-rich or not, as well as in discerning zones of interest w.r.t. variability.","tool support for understanding software variability, software product line engineering, object-oriented variability-rich systems, identifying software variability, visualizing software variability",SPLC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Jalila A,Mala DJ",Object-Oriented Model-Based Specification Languages: A Comparison,SIGSOFT Softw. Eng. Notes,2014,39,5,1–4,Association for Computing Machinery,"New York, NY, USA",,,,2014-09,,0163-5948,https://doi.org/10.1145/2659118.2659132;http://dx.doi.org/10.1145/2659118.2659132,10.1145/2659118.2659132,"Complex, soft-real-time system development is one of the challenges in the software industry, as it is difficult to understand, test and maintain such systems. However, the software development goal is to operate reliably despite this complexity. This can be achieved by applying formal methods, which use a language that has a strong mathematical foundation for describing the system. To be more specific, model-based specification languages are used to resolve ambiguities in user requirements or detect design errors early in the software life cycle. This paper compares object-oriented model-based formal languages such as Zed (Z), Vienna Development Method (VDM) and Object Constraint Language (OCL) based on various factors. Also, the issues surrounding the application of these formal methods to various software problems are discussed in this paper. The present research work enables software developers to select an appropriate language suiting their specific requirements.","Z, OCL, specification, formal methods, formal specification language, VDM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"De Fraine B,Ernst E,Südholt M",Essential AOP: The a Calculus,ACM Trans. Program. Lang. Syst.,2012,34,3,,Association for Computing Machinery,"New York, NY, USA",,,,2012-11,,0164-0925,https://doi.org/10.1145/2362389.2362391;http://dx.doi.org/10.1145/2362389.2362391,10.1145/2362389.2362391,"Aspect-oriented programming (AOP) has produced interesting language designs, but also ad hoc semantics that needs clarification. We contribute to this clarification with a calculus that models essential AOP, both simpler and more general than existing formalizations. In AOP, advice may intercept method invocations, and proceed executes the suspended call. Proceed is an ad hoc mechanism, only usable inside advice bodies. Many pointcut mechanisms, for example, wildcards, also lack regularity. We model proceed using first-class closures, and shift complexity from pointcuts to ordinary object-oriented code. Two well-known pointcut categories, call and execution, are commonly considered similar. We formally expose their differences, and resolve the associated soundness problem. Our calculus includes type ranges, an intuitive and concise alternative to explicit type variables that allows advice to be polymorphic over intercepted methods. We use calculus parameters to cover type safety for a wide design space of other features. Type soundness is verified in Coq.","typing, semantics, Aspect-oriented programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Garcia R,Cimini M",Principal Type Schemes for Gradual Programs,,2015,,,303–315,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Mumbai, India",2015,9781450333009,,https://doi.org/10.1145/2676726.2676992;http://dx.doi.org/10.1145/2676726.2676992,10.1145/2676726.2676992,"Gradual typing is a discipline for integrating dynamic checking into a static type system. Since its introduction in functional languages, it has been adapted to a variety of type systems, including object-oriented, security, and substructural. This work studies its application to implicitly typed languages based on type inference. Siek and Vachharajani designed a gradual type inference system and algorithm that infers gradual types but still rejects ill-typed static programs. However, the type system requires local reasoning about type substitutions, an imperative inference algorithm, and a subtle correctness statement.This paper introduces a new approach to gradual type inference, driven by the principle that gradual inference should only produce static types. We present a static implicitly typed language, its gradual counterpart, and a type inference procedure. The gradual system types the same programs as Siek and Vachharajani, but has a modular structure amenable to extension. The language admits let-polymorphism, and its dynamics are defined by translation to the Polymorphic Blame Calculus.The principal types produced by our initial type system mask the distinction between static parametric polymorphism and polymorphism that can be attributed to gradual typing. To expose this difference, we distinguish static type parameters from gradual type parameters and reinterpret gradual type consistency accordingly. The resulting extension enables programs to be interpreted using either the polymorphic or monomorphic Blame Calculi.","gradual typing, type inference",POPL '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Garcia R,Cimini M",Principal Type Schemes for Gradual Programs,SIGPLAN Not.,2015,50,1,303–315,Association for Computing Machinery,"New York, NY, USA",,,,2015-01,,0362-1340,https://doi.org/10.1145/2775051.2676992;http://dx.doi.org/10.1145/2775051.2676992,10.1145/2775051.2676992,"Gradual typing is a discipline for integrating dynamic checking into a static type system. Since its introduction in functional languages, it has been adapted to a variety of type systems, including object-oriented, security, and substructural. This work studies its application to implicitly typed languages based on type inference. Siek and Vachharajani designed a gradual type inference system and algorithm that infers gradual types but still rejects ill-typed static programs. However, the type system requires local reasoning about type substitutions, an imperative inference algorithm, and a subtle correctness statement.This paper introduces a new approach to gradual type inference, driven by the principle that gradual inference should only produce static types. We present a static implicitly typed language, its gradual counterpart, and a type inference procedure. The gradual system types the same programs as Siek and Vachharajani, but has a modular structure amenable to extension. The language admits let-polymorphism, and its dynamics are defined by translation to the Polymorphic Blame Calculus.The principal types produced by our initial type system mask the distinction between static parametric polymorphism and polymorphism that can be attributed to gradual typing. To expose this difference, we distinguish static type parameters from gradual type parameters and reinterpret gradual type consistency accordingly. The resulting extension enables programs to be interpreted using either the polymorphic or monomorphic Blame Calculi.","type inference, gradual typing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Lee EA,Liu X,Neuendorffer S",Classes and Inheritance in Actor-Oriented Design,ACM Trans. Embed. Comput. Syst.,2009,8,4,,Association for Computing Machinery,"New York, NY, USA",,,,2009-07,,1539-9087,https://doi.org/10.1145/1550987.1550992;http://dx.doi.org/10.1145/1550987.1550992,10.1145/1550987.1550992,"Actor-oriented components emphasize concurrency and temporal semantics and are used for modeling and designing embedded software and hardware. Actors interact with one another through ports via a messaging schema that can follow any of several concurrent semantics. Domain-specific actor-oriented languages and frameworks are common (Simulink, LabVIEW, SystemC, etc.). However, they lack many modularity and abstraction mechanisms that programmers have become accustomed to in object-oriented components, such as classes, inheritance, interfaces, and polymorphism, except as inherited from the host language. This article shows a form that such mechanisms can take in actor-oriented components, gives a formal structure, and describes a prototype implementation. The mechanisms support actor-oriented class definitions, subclassing, inheritance, and overriding. The formal structure imposes structural constraints on a model (mainly the “derivation invariant”) that lead to a policy to govern inheritance. In particular, the structural constraints permit a disciplined form of multiple inheritance with unambiguous inheritance and overriding behavior. The policy is based formally on a generalized ultrametric space with some remarkable properties. In this space, inheritance is favored when actors are “closer” (in the generalized ultrametric), and we show that when inheritance can occur from multiple sources, one source is always unambiguously closer than the other.","interfaces, Actors, generalized ultrametric, inheritance, overriding, components, type systems",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Fonseca i Casas P,Using Specification and Description Language to Define and Implement Discrete Simulation Models,,2010,,,419–426,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2010 Summer Computer Simulation Conference,"Ottawa, Ontario, Canada",2010,,,,,"The formal languages become important tools since they allow the complete understanding of the model and help in its implementation. However only a few simulation tools allow an automatic execution of a simulation model based in a formalization of the system.Specification and Description Language is a modern object oriented graphical formal language that allows the definition of distributed systems. It has focused on the modeling of reactive, state/event driven systems, and has been standardized by the International Telecommunications Union (ITU) in the Z.100. Since it is a graphical formalism simplifies the understanding of the model.In this paper we show how we can use Specification and Description Language to represent a discrete simulation model. We propose a solution, implemented in SDLPS, regarding how to manage the time in Specification and Description Language. Also, we show how SDLPS infrastructure allows a distribute simulation of the models.","simulation, SDL, formalisms",SCSC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Efftinge S,Eysholdt M,Köhnlein J,Zarnekow S,von Massow R,Hasselbring W,Hanus M",Xbase: Implementing Domain-Specific Languages for Java,,2012,,,112–121,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Generative Programming and Component Engineering,"Dresden, Germany",2012,9781450311298,,https://doi.org/10.1145/2371401.2371419;http://dx.doi.org/10.1145/2371401.2371419,10.1145/2371401.2371419,"Xtext is an open-source framework for implementing external, textual domain-specific languages (DSLs). So far, most DSLs implemented with Xtext and similar tools focus on structural aspects such as service specifications and entities. Because behavioral aspects are significantly more complicated to implement, they are often delegated to general-purpose programming languages. This approach introduces complex integration patterns and the DSL's high level of abstraction is compromised.We present Xbase as part of Xtext, an expression language that can be reused via language inheritance in any DSL implementation based on Xtext. Xbase expressions provide both control structures and program expressions in a uniform way. Xbase is statically typed and tightly integrated with the Java type system. Languages extending Xbase inherit the syntax of a Java-like expression language as well as language infrastructure components, including a parser, an unparser, a linker, a compiler and an interpreter. Furthermore, the framework provides integration into the Eclipse IDE including debug and refactoring support.The application of Xbase is presented by means of a domain model language which serves as a tutorial example and by the implementation of the programming language Xtend. Xtend is a functional and object-oriented general purpose language for the Java Virtual Machine (JVM). It is built on top of Xbase which is the reusable expression language that is the foundation of Xtend.","object-oriented programming, domain-specific languages, language inheritance",GPCE '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Efftinge S,Eysholdt M,Köhnlein J,Zarnekow S,von Massow R,Hasselbring W,Hanus M",Xbase: Implementing Domain-Specific Languages for Java,SIGPLAN Not.,2012,48,3,112–121,Association for Computing Machinery,"New York, NY, USA",,,,2012-09,,0362-1340,https://doi.org/10.1145/2480361.2371419;http://dx.doi.org/10.1145/2480361.2371419,10.1145/2480361.2371419,"Xtext is an open-source framework for implementing external, textual domain-specific languages (DSLs). So far, most DSLs implemented with Xtext and similar tools focus on structural aspects such as service specifications and entities. Because behavioral aspects are significantly more complicated to implement, they are often delegated to general-purpose programming languages. This approach introduces complex integration patterns and the DSL's high level of abstraction is compromised.We present Xbase as part of Xtext, an expression language that can be reused via language inheritance in any DSL implementation based on Xtext. Xbase expressions provide both control structures and program expressions in a uniform way. Xbase is statically typed and tightly integrated with the Java type system. Languages extending Xbase inherit the syntax of a Java-like expression language as well as language infrastructure components, including a parser, an unparser, a linker, a compiler and an interpreter. Furthermore, the framework provides integration into the Eclipse IDE including debug and refactoring support.The application of Xbase is presented by means of a domain model language which serves as a tutorial example and by the implementation of the programming language Xtend. Xtend is a functional and object-oriented general purpose language for the Java Virtual Machine (JVM). It is built on top of Xbase which is the reusable expression language that is the foundation of Xtend.","language inheritance, domain-specific languages, object-oriented programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Mackay J,Potanin A,Aldrich J,Groves L",Decidable Subtyping for Path Dependent Types,Proc. ACM Program. Lang.,2019,4,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-12,,,https://doi.org/10.1145/3371134;http://dx.doi.org/10.1145/3371134,10.1145/3371134,"Path dependent types have long served as an expressive component of the Scala programming language. They allow for the modelling of both bounded polymorphism and a degree of nominal subtyping. Nominality in turn provides the ability to capture first class modules. Thus a single language feature gives rise to a rich array of expressiveness. Recent work has proven path dependent types sound in the presence of both intersection and recursive types, but unfortunately typing remains undecidable, posing problems for programmers who rely on the results of type checkers. The Wyvern programming language is an object oriented language with path dependent types, recursive types and first class modules. In this paper we define two variants of Wyvern that feature decidable typing, along with machine checked proofs of decidability. Despite the restrictions, our approaches retain the ability to encode the parameteric polymorphism of Java generics along with many idioms of the Scala module system.","Subtyping, Object Oriented Languages, Structural Subtyping, Functional Languages, Nominal Subtyping, Wyvern, Scala, Decidability, Language Design, Path Dependent Types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Qu Y,Kerne A,Lupfer N,Linder R,Jain A","Metadata Type System: Integrate Presentation, Data Models and Extraction to Enable Exploratory Browsing Interfaces",,2014,,,107–116,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2014 ACM SIGCHI Symposium on Engineering Interactive Computing Systems,"Rome, Italy",2014,9781450327251,,https://doi.org/10.1145/2607023.2607030;http://dx.doi.org/10.1145/2607023.2607030,10.1145/2607023.2607030,"Exploratory browsing involves encountering new information during open-ended tasks. Disorientation and digression are problems that arise, as the user repeatedly loses context while clicking hyperlinks. To maintain context, exploratory browsing interfaces must present multiple web pages at once.Design of exploratory browsing interfaces must address the limits of display and human working memory. Our approach is based on expandable metadata summaries. Prior semantic web exploration tools represent documents as metadata, but often depend on semantic web formats and datasets assembled in advance. They do not support dynamically encountered information from popular web sites. Optimizing presentation of metadata summaries for particular types of documents is important as a further means for reducing the cognitive load of rapidly browsing across many documents. To address these issues, we develop a metadata type system as the basis for building exploratory browsing interfaces that maintain context. The type system leverages constructs from object-oriented programming languages. We integrate data models, extraction rules, and presentation semantics in types to operationalize type specific dynamic metadata extraction and rich presentation. Using the type system, we built the Metadata In-Context Expander (MICE) interface as a proof of concept. A study, in which students engaged in exploring prior work, showed that MICE's metadata summaries help users maintain context during exploratory browsing.","dynamic metadata, type systems, exploratory browsing",EICS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ancona D,Lagorio G",Complete Coinductive Subtyping for Abstract Compilation of Object-Oriented Languages,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Workshop on Formal Techniques for Java-Like Programs,"Maribor, Slovenia",2010,9781450305402,,https://doi.org/10.1145/1924520.1924521;http://dx.doi.org/10.1145/1924520.1924521,10.1145/1924520.1924521,"Coinductive abstract compilation is a novel technique, which has been recently introduced, for defining precise type systems for object-oriented languages. In this approach, type inference consists in translating the program to be analyzed into a Horn formula f, and in resolving a certain goal w.r.t. the coinductive (that is, the greatest) Herbrand model of f.Type systems defined in this way are idealized, since types and, consequently, goal derivations, are not finitely representable. Hence, sound implementable approximations have to rely on the notions of regular types and derivations, and of subtyping and subsumption between types and atoms, respectively.In this paper we address the problem of defining a complete subtyping relation ≤ between types built on object and union type constructors: we interpret types as sets of values, and investigate on a definition of subtyping such that t1 ≤ t2 is derivable whenever the interpretation of t1 is contained in the interpretation of t2. Besides being an important theoretical result, completeness is useful for reasoning about possible implementations of the subtyping relation, when restricted to regular types.","coinduction, Java, subtyping, union types, type inference",FTFJP '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pan N,Song E",An Aspect-Oriented Testability Framework,,2012,,,356–363,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2012 ACM Research in Applied Computation Symposium,"San Antonio, Texas",2012,9781450314923,,https://doi.org/10.1145/2401603.2401682;http://dx.doi.org/10.1145/2401603.2401682,10.1145/2401603.2401682,"We can specify design constraints of a software system using a formal language such as Object Constraint Language (OCL). However, OCL is not executable and cannot be explicitly used as a testing method. So runtime constraint checking is needed to mitigate this problem. Checking design constraints at runtime can help to detect design drift. On the other hand, making a software testable is also hard since testing requires active involvement of programmers. Testable software introduces a quality characteristics of software artifact called testability. This paper mainly concentrates on improving observability, one of the major factors that determine testability of a software artifact. To avoid design drift and make software more testable, this paper proposes an aspect-oriented testability framework for object oriented software testing, which enables runtime constraint checking against implementation code and improves the testability of a software system. This framework completely takes the advantage of aspect-oriented programming (AOP) approaches and is totally modular and plug-and-playable.","AspectJ, observability, testing, testability, AOP, logging",RACS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chanda J,Sengupta S,Kanjilal A,Bhattacharya S",Formalization of the Design Phase of Software Lifecycle: A Grammar Based Approach,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Workshop on Formalization of Modeling Languages,"Maribor, Slovenia",2010,9781450305327,,https://doi.org/10.1145/1943397.1943401;http://dx.doi.org/10.1145/1943397.1943401,10.1145/1943397.1943401,"In Object Oriented systems, the design phase can be modeled using the three diagrams: Sequence diagram (which depicts responses of all objects that are involved in a single use case), Class Diagram (which is used to depict the structural aspect of design) and State chart diagram (which is used to depicts the states and state dependent behavior for objects). In this paper, we have proposed a framework for verification of these diagrams, which includes syntactic correctness and inter-diagram consistency. This is done by proposing Context Free Grammar for the three diagrams. The proposed grammar is validated by using Lex and Yacc and parse tree is generated which is an alternate form of the grammar. This framework, being built based on a formal approach, would enable us to automate the process of correctness and consistency verification among the diagrams used in design phase. This would also help us in ensuring requirement traceability on the long run.","parse tree, context free grammar, UML formalization",FML '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Allen E,Hilburn J,Kilpatrick S,Luchangco V,Ryu S,Chase D,Steele G",Type Checking Modular Multiple Dispatch with Parametric Polymorphism and Multiple Inheritance,,2011,,,973–992,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Portland, Oregon, USA",2011,9781450309400,,https://doi.org/10.1145/2048066.2048140;http://dx.doi.org/10.1145/2048066.2048140,10.1145/2048066.2048140,"In previous work, we presented rules for defining overloaded functions that ensure type safety under symmetric multiple dispatch in an object-oriented language with multiple inheritance, and we showed how to check these rules without requiring the entire type hierarchy to be known, thus supporting modularity and extensibility. In this work, we extend these rules to a language that supports parametric polymorphism on both classes and functions.In a multiple-inheritance language in which any type may be extended by types in other modules, some overloaded functions that might seem valid are correctly rejected by our rules. We explain how these functions can be permitted in a language that additionally supports an exclusion relation among types, allowing programmers to declare \nominal exclusions\"" and also implicitly imposing exclusion among different instances of each polymorphic type. We give rules for computing the exclusion relation",deriving many type exclusions from declared and implicit ones.We also show how to check our rules for ensuring the safety of overloaded functions. In particular,"we reduce the problem of handling parametric polymorphism to one of determining subtyping relationships among universal and existential types. Our system has been implemented as part of the open-source Fortress compiler.""","multimethods, object-oriented programming, symmetric dispatch, multiple inheritance, modularity, methods, static types, components, meet rule, separate compilation, ilks, run-time types, overloading, fortress, multiple dispatch",OOPSLA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Allen E,Hilburn J,Kilpatrick S,Luchangco V,Ryu S,Chase D,Steele G",Type Checking Modular Multiple Dispatch with Parametric Polymorphism and Multiple Inheritance,SIGPLAN Not.,2011,46,10,973–992,Association for Computing Machinery,"New York, NY, USA",,,,2011-10,,0362-1340,https://doi.org/10.1145/2076021.2048140;http://dx.doi.org/10.1145/2076021.2048140,10.1145/2076021.2048140,"In previous work, we presented rules for defining overloaded functions that ensure type safety under symmetric multiple dispatch in an object-oriented language with multiple inheritance, and we showed how to check these rules without requiring the entire type hierarchy to be known, thus supporting modularity and extensibility. In this work, we extend these rules to a language that supports parametric polymorphism on both classes and functions.In a multiple-inheritance language in which any type may be extended by types in other modules, some overloaded functions that might seem valid are correctly rejected by our rules. We explain how these functions can be permitted in a language that additionally supports an exclusion relation among types, allowing programmers to declare \nominal exclusions\"" and also implicitly imposing exclusion among different instances of each polymorphic type. We give rules for computing the exclusion relation",deriving many type exclusions from declared and implicit ones.We also show how to check our rules for ensuring the safety of overloaded functions. In particular,"we reduce the problem of handling parametric polymorphism to one of determining subtyping relationships among universal and existential types. Our system has been implemented as part of the open-source Fortress compiler.""","multiple dispatch, static types, multiple inheritance, components, symmetric dispatch, ilks, fortress, meet rule, object-oriented programming, run-time types, overloading, separate compilation, methods, multimethods, modularity",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Casas PF,Casanovas J,Figueras J,Guasch A",Formalizing Geographical Models Using Specification and Description Language: The Wildfire Example,,2013,,,1961–1972,IEEE Press,"Washington, D.C.",,Proceedings of the 2013 Winter Simulation Conference: Simulation: Making Decisions in a Complex World,,2013,9781479920778,,,,"In this paper we explore how we can use Specification and Description Language, to represent simulation models that make an intensive use of geographical information, like environmental simulation models. The purpose is to perform a complete unambiguous, graphical and formal representation of a wildfire simulation model. Specification and Description Language is a modern object oriented language that allows the definition of distributed systems. It has focused on the modeling of reactive, state/event driven systems, and has been standardized by the International Telecommunications Union (ITU) in the Z.100. Thanks to the graphical representation of the simulation model, the interaction between the experts that usually come from different areas is simplified. Also, due to the unambiguous and modular nature of the language, all the details of the model can be validated by personnel that do not necessarily are used with programming languages or simulation infrastructures.",,WSC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"de Melo AC,Nunes PR,Xavier KS",Towards Verification and Testing of Java Programs,,2008,,,730–734,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Symposium on Applied Computing,"Fortaleza, Ceara, Brazil",2008,9781595937537,,https://doi.org/10.1145/1363686.1363858;http://dx.doi.org/10.1145/1363686.1363858,10.1145/1363686.1363858,"Testing object-oriented programs is still a hard task, despite many studies on criteria to better cover the test space. Test criteria establish requirements one want to achieve in testing programs to help in finding software defects. On the other hand, program verification guarantees that a program preserves its specification but it is not very straightforwardly applicable in many cases. Both program testing and verification are expensive tasks and could be used to complement each other.This paper presents a study on using formal verification to reduce the space of program testing. As properties are checked using program model checkers, programs are traced. Information from these traces can be used to realize how much testing criteria have been satisfied, reducing the further program test space. The present work is a study on how much the test space of concurrent Java programs can be reduced if DeadlockFreedom is checked prior to testing.","object-oriented testing, program verification, java programs",SAC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nagoya F,Liu S",Development of a Web-Based Conference Management System Using SOFL,,2015,,,337–342,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 Conference on Research in Adaptive and Convergent Systems,"Prague, Czech Republic",2015,9781450337380,,https://doi.org/10.1145/2811411.2811502;http://dx.doi.org/10.1145/2811411.2811502,10.1145/2811411.2811502,"Currently, there are several systems in use to support paper submissions to academic conferences, but they still require program chairs to spend a lot of time in organizing paper reviewing. To further improve the situation and reduce the burden of the chairs, a completely automatic reviewing system is desirable. Our research presented in this paper is part of the effort toward realizing such an automatic system. Specifically, we focus on two functions of the entire system, which manage paper assignments to referees and paper evaluations based on the feedback from the referees. To ensure the quality of the system, we adopt the Structured Object-oriented Formal Language (SOFL) for the requirements analysis and design. In this paper, we describe how the requirements are analyzed through writing an informal specification and then refining it into a semi-formal specification. We also discuss how the design is carried out by constructing a formal specification in SOFL. Finally, we present the implementation and testing details on our system.","specification based testing, formal specification, peer review",RACS,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mostowski W,Ulbrich M",Dynamic Dispatch for Method Contracts through Abstract Predicates,,2015,,,109–116,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th International Conference on Modularity,"Fort Collins, CO, USA",2015,9781450332491,,https://doi.org/10.1145/2724525.2724574;http://dx.doi.org/10.1145/2724525.2724574,10.1145/2724525.2724574,"Dynamic method dispatch is a core feature of object-oriented programming by which the executed implementation for a polymorphic method is only chosen at runtime. In this paper, we present a specification and verification methodology which extends the concept of dynamic dispatch to design-by-contract specifications. The formal specification language JML has only rudimentary means for polymorphic abstraction in expressions. We promote these to fully flexible specification-only query methods called model methods that can, like ordinary methods, be overridden to give specifications a new semantics in subclasses in a transparent and modular fashion. Moreover, we allow them to refer to more than one program state which give us the possibility to fully abstract and encapsulate two-state specification contexts, i.e., history constraints and method postconditions. We provide the semantics for model methods by giving a translation into a first order logic and according proof obligations. We fully implemented this framework in the KeY program verifier and successfully verified relevant examples.","Abstract predicates, JML, Dynamic dispatch, Modular specification, Design by Contract",MODULARITY 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hamri M,Zacharewicz G",Automatic Generation of Object-Oriented Code from DEVS Graphical Specifications,,2012,,,,Winter Simulation Conference,"Berlin, Germany",,Proceedings of the Winter Simulation Conference,,2012,,,,,"The paper presents an approach to automatically generate object-oriented code from DEVS graphical model specification. Afterward the generated DEVS code is given to the LSIS DME DEVS simulator to execute the corresponding behavior. This research is driven by the idea that the user of M&S, even not computer scientist and/or beginner in formal modeling like DEVS can increase his trust in the models he creates and the simulation results he is able to obtain due to the fact he is directly involved at the modeling stage and not anymore interfaced with an intermediate actor (modeler or programmer expert) that would interpret user requirements in the modeling and simulation activities. Using the proposed tool with its user friendly framework and appropriate graphical items, the user is capable to skip learning installation set up and user manual to rapidly develop his own DEVS models, to carry out simulations and to analyze them.",,WSC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pradel M,Gross TR",Fully Automatic and Precise Detection of Thread Safety Violations,,2012,,,521–530,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd ACM SIGPLAN Conference on Programming Language Design and Implementation,"Beijing, China",2012,9781450312059,,https://doi.org/10.1145/2254064.2254126;http://dx.doi.org/10.1145/2254064.2254126,10.1145/2254064.2254126,"Concurrent, object-oriented programs often use thread-safe library classes. Existing techniques for testing a thread-safe class either rely on tests using the class, on formal specifications, or on both. Unfortunately, these techniques often are not fully automatic as they involve the user in analyzing the output. This paper presents an automatic testing technique that reveals concurrency bugs in supposedly thread-safe classes. The analysis requires as input only the class under test and reports only true positives. The key idea is to generate tests in which multiple threads call methods on a shared instance of the tested class. If a concurrent test exhibits an exception or a deadlock that cannot be triggered in any linearized execution of the test, the analysis reports a thread safety violation. The approach is easily applicable, because it is independent of hand-written tests and explicit specifications. The analysis finds 15 concurrency bugs in popular Java libraries, including two previously unknown bugs in the Java standard library.","testing, thread safety, concurrent test generation",PLDI '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Pradel M,Gross TR",Fully Automatic and Precise Detection of Thread Safety Violations,SIGPLAN Not.,2012,47,6,521–530,Association for Computing Machinery,"New York, NY, USA",,,,2012-06,,0362-1340,https://doi.org/10.1145/2345156.2254126;http://dx.doi.org/10.1145/2345156.2254126,10.1145/2345156.2254126,"Concurrent, object-oriented programs often use thread-safe library classes. Existing techniques for testing a thread-safe class either rely on tests using the class, on formal specifications, or on both. Unfortunately, these techniques often are not fully automatic as they involve the user in analyzing the output. This paper presents an automatic testing technique that reveals concurrency bugs in supposedly thread-safe classes. The analysis requires as input only the class under test and reports only true positives. The key idea is to generate tests in which multiple threads call methods on a shared instance of the tested class. If a concurrent test exhibits an exception or a deadlock that cannot be triggered in any linearized execution of the test, the analysis reports a thread safety violation. The approach is easily applicable, because it is independent of hand-written tests and explicit specifications. The analysis finds 15 concurrency bugs in popular Java libraries, including two previously unknown bugs in the Java standard library.","thread safety, testing, concurrent test generation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gramoli V,Santosa AE",Why Inheritance Anomaly is Not Worth Solving,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 9th International Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems PLE","Uppsala, Sweden",2014,9781450329149,,https://doi.org/10.1145/2633301.2633307;http://dx.doi.org/10.1145/2633301.2633307,10.1145/2633301.2633307,"Modern computers improve their predecessors with additional parallelism but require concurrent software to exploit it. Object-orientation is instrumental in simplifying sequential programming, however, in a concurrent setting, programmers adding new methods in a subclass typically have to modify the code of the superclass, which inhibits reuse, a problem known as inheritance anomaly. There have been much efforts by researchers in the last two decades to solve the problem by deriving anomaly-free languages. Yet, these proposals have not ended up as practical solutions, thus one may ask why.In this article, we investigate from a theoretical perspective if a solution of the problem would introduce extra code complexity. We model object behavior as a regular language, and show that freedom from inheritance anomaly necessitates a language where ensuring Liskov-Wing substitutability becomes a language containment problem, which in our modeling is PSPACE hard. This indicates that we cannot expect programmers to manually ensure that subtyping holds in an anomaly-free language. Anomaly freedom thus predictably leads to software bugs and we doubt the value of providing it.From the practical perspective, the problem is already solved. Inheritance anomaly is part of the general fragile base class problem of object-oriented programming, that arises due to code coupling in implementation inheritance. In modern software practice, the fragile base class problem is circumvented by interface abstraction to avoid implementation inheritance, and opting for composition as means for reuse. We discuss concurrent programming issues with composition for reuse.","inheritance anomaly, concurrent programming, object-oriented programming",ICOOOLPS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lincke R,Lundberg J,Löwe W",Comparing Software Metrics Tools,,2008,,,131–142,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 International Symposium on Software Testing and Analysis,"Seattle, WA, USA",2008,9781605580500,,https://doi.org/10.1145/1390630.1390648;http://dx.doi.org/10.1145/1390630.1390648,10.1145/1390630.1390648,"This paper shows that existing software metric tools interpret and implement the definitions of object-oriented software metrics differently. This delivers tool-dependent metrics results and has even implications on the results of analyses based on these metrics results. In short, the metrics-based assessment of a software system and measures taken to improve its design differ considerably from tool to tool. To support our case, we conducted an experiment with a number of commercial and free metrics tools. We calculated metrics values using the same set of standard metrics for three software systems of different sizes. Measurements show that, for the same software system and metrics, the metrics values are tool depended. We also defined a (simple) software quality model for \maintainability\"" based on the metrics selected. It defines a ranking of the classes that are most critical wrt. maintainability. Measurements show that even the ranking of classes in a software system is metrics tool dependent.""","comparing tools, software quality metrics",ISSTA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yasir RM,Asad M,Galib AH,Ganguly KK,Siddik MS",GodExpo: An Automated God Structure Detection Tool for Golang,,2019,,,47–50,IEEE Press,"Montreal, Quebec, Canada",,Proceedings of the 3rd International Workshop on Refactoring,,2019,,,https://doi.org/10.1109/IWoR.2019.00016;http://dx.doi.org/10.1109/IWoR.2019.00016,10.1109/IWoR.2019.00016,"God Class is a class that threatens maintainability and understandability of code by performing most of the work alone. Various tools exist that can detect God Class of Java or C++ programs, however, there is no existing tool for detecting God Class(Structure) in Golang. Although Golang is not an object-oriented language, it offers structures which are similar to classes in OOP as they can contain fields and methods. Unlike OOP, methods of a structure can be defined on any file in the package of Golang. This paper presents a tool entitled GodExpo to detect God Structures in Golang programs by calculating metrics namely Weighted Method Count, Tight Class Cohesion, and Access to Foreign Data. In addition, GodExpo can provide version wise result to observe the evolution of God structures. To evaluate GodExpo, an experiment has been conducted on several versions of two open source Golang projects and the tool successfully found God structures in all versions of those projects.","OOP metrics, code smell, Golang, god class",IWOR '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Choppy C,Reggio G",A Well-Founded Approach to Service Modelling with Casl4Soa: Part 1 (Service in Isolation),,2010,,,2451–2458,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Symposium on Applied Computing,"Sierre, Switzerland",2010,9781605586397,,https://doi.org/10.1145/1774088.1774596;http://dx.doi.org/10.1145/1774088.1774596,10.1145/1774088.1774596,"We propose in this paper the first part of Casl4Soa a notation and a technique to model a SOA (Service Oriented Architecture), i.e., here we consider only services in isolation. Our Casl4Soa approach is to provide a well-founded modelling to SOA, using the Casl-Ltl formal specification language as an underlying foundation. We explore then the various possible visual presentation of the Casl4Soa notation, so as to ensure as much as possible readability and communicability. Given the Casl-Ltl concept of a simple system as a labelled transition system we propose a new way to model the services that is not object-oriented. While modelling the static, the behavioural, and the semantic aspects of a service, we pay a specific attention to the protocols between the provider and the consumer of the service for which we propose either a logical specification of their properties, or a constructive specification expressed by interaction machines. Our ideas are illustrated by the example of a printing service offered by a printer to a user.","temporal logic, SOA, CASL, UML",SAC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nageba E,Rubel P,Fayn J",Semantic Agent System for Automatic Mobilization of Distributed and Heterogeneous Resources,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 3rd International Conference on Web Intelligence, Mining and Semantics","Madrid, Spain",2013,9781450318501,,https://doi.org/10.1145/2479787.2479810;http://dx.doi.org/10.1145/2479787.2479810,10.1145/2479787.2479810,"Advanced information systems increasingly use diverse domain-specific resources like services, data, knowledge, etc. One of the today's ubiquitous computing challenges is to automate the mobilization of heterogeneous distributed resources and to allocate them to user-tasks. In this paper, we propose a semantic agent system to solve the problem of resources mobilization and allocation taking into account the continuous changes of the resources conditions. We first propose a formal model of an efficient Resources Mobilization Semantic Agent. Our proposed model is mainly based on ontological models representing basic entities of a collaborative environment as well as their interrelations, rules, inference engine, and object oriented components for resources data processing. Then we suggest mechanisms to handle the discovered resources in terms of updating, filtering, ranking, and allocating. We also provide an application example from the eHealth domain to demonstrate how the proposed semantic agent system can efficiently support the mobilization and allocation of different types of resources according to the user-tasks specifications and to the discovered resources conditions in terms of availability, accessibility, and capability.","collaborative environment, ontology, rule-based reasoning, knowledge representation, resources management, task-based computing",WIMS '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Naden K,Bocchino R,Aldrich J,Bierhoff K",A Type System for Borrowing Permissions,,2012,,,557–570,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Philadelphia, PA, USA",2012,9781450310833,,https://doi.org/10.1145/2103656.2103722;http://dx.doi.org/10.1145/2103656.2103722,10.1145/2103656.2103722,"In object-oriented programming, unique permissions to object references are useful for checking correctness properties such as consistency of typestate and noninterference of concurrency. To be usable, unique permissions must be borrowed --- for example, one must be able to read a unique reference out of a field, use it for something, and put it back. While one can null out the field and later reassign it, this paradigm is ungainly and requires unnecessary writes, potentially hurting cache performance. Therefore, in practice borrowing must occur in the type system, without requiring memory updates. Previous systems support borrowing with external alias analysis and/or explicit programmer management of fractional permissions. While these approaches are powerful, they are also awkward and difficult for programmers to understand. We present an integrated language and type system with unique, immutable, and shared permissions, together with new local permissions that say that a reference may not be stored to the heap. Our system also includes change permissions such as unique>>unique and unique>>none that describe how permissions flow in and out of method formal parameters. Together, these features support common patterns of borrowing, including borrowing multiple local permissions from a unique reference and recovering the unique reference when the local permissions go out of scope, without any explicit management of fractions in the source language. All accounting of fractional permissions is done by the type system \under the hood.\"" We present the syntax and static and dynamic semantics of a formal core language and state soundness results. We also illustrate the utility and practicality of our design by using it to express several realistic examples.""","immutability, types, uniqueness, borrowing, permissions",POPL '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Naden K,Bocchino R,Aldrich J,Bierhoff K",A Type System for Borrowing Permissions,SIGPLAN Not.,2012,47,1,557–570,Association for Computing Machinery,"New York, NY, USA",,,,2012-01,,0362-1340,https://doi.org/10.1145/2103621.2103722;http://dx.doi.org/10.1145/2103621.2103722,10.1145/2103621.2103722,"In object-oriented programming, unique permissions to object references are useful for checking correctness properties such as consistency of typestate and noninterference of concurrency. To be usable, unique permissions must be borrowed --- for example, one must be able to read a unique reference out of a field, use it for something, and put it back. While one can null out the field and later reassign it, this paradigm is ungainly and requires unnecessary writes, potentially hurting cache performance. Therefore, in practice borrowing must occur in the type system, without requiring memory updates. Previous systems support borrowing with external alias analysis and/or explicit programmer management of fractional permissions. While these approaches are powerful, they are also awkward and difficult for programmers to understand. We present an integrated language and type system with unique, immutable, and shared permissions, together with new local permissions that say that a reference may not be stored to the heap. Our system also includes change permissions such as unique>>unique and unique>>none that describe how permissions flow in and out of method formal parameters. Together, these features support common patterns of borrowing, including borrowing multiple local permissions from a unique reference and recovering the unique reference when the local permissions go out of scope, without any explicit management of fractions in the source language. All accounting of fractional permissions is done by the type system \under the hood.\"" We present the syntax and static and dynamic semantics of a formal core language and state soundness results. We also illustrate the utility and practicality of our design by using it to express several realistic examples.""","permissions, immutability, uniqueness, borrowing, types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ducournau R,Morandat F,Privat J",Empirical Assessment of Object-Oriented Implementations with Multiple Inheritance and Static Typing,,2009,,,41–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th ACM SIGPLAN Conference on Object Oriented Programming Systems Languages and Applications,"Orlando, Florida, USA",2009,9781605587660,,https://doi.org/10.1145/1640089.1640093;http://dx.doi.org/10.1145/1640089.1640093,10.1145/1640089.1640093,"Object-oriented languages involve a threefold tradeoff between runtime efficiency, expressiveness (multiple inheritance), and modularity, i.e. open-world assumption (OWA). Runtime efficiency is conditioned by both the implementation technique and compilation scheme. The former specifies the data structures that support method invocation, attribute access and subtype testing. The latter consists of the production line of an executable from the source code. Many implementation techniques have been proposed and several compilation schemes can be considered from fully global compilation under the closed-world assumption (CWA) to separate compilation with dynamic loading under the OWA, with midway solutions. This article reviews a significant subset of possible combinations and presents a systematic, empirical comparison of their respective efficiencies with all other things being equal. The testbed consists of the Prm compiler that has been designed for this purpose. The considered techniques include C++ subobjects, coloring, perfect hashing, binary tree dispatch and caching. A variety of processors were considered. Qualitatively, these first results confirm the intuitive or theoretical abstract assessments of the tested approaches. As expected, efficiency increases as CWA strengthens. From a quantitative standpoint, the results are the first to precisely compare the efficiency of techniques that are closely associated with specific languages like C++ and Eiffel. They also confirm that perfect hashing should be considered for implementing Java and .Net interfaces.","multiple inheritance, closed-world assumption, downcast, multiple subtyping, coloring, late binding, perfect hashing, virtual function table, method tables, subtype test, interfaces, dynamic loading, type analysis, open-world assumption, binary tree dispatch, single inheritance",OOPSLA '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ducournau R,Morandat F,Privat J",Empirical Assessment of Object-Oriented Implementations with Multiple Inheritance and Static Typing,SIGPLAN Not.,2009,44,10,41–60,Association for Computing Machinery,"New York, NY, USA",,,,2009-10,,0362-1340,https://doi.org/10.1145/1639949.1640093;http://dx.doi.org/10.1145/1639949.1640093,10.1145/1639949.1640093,"Object-oriented languages involve a threefold tradeoff between runtime efficiency, expressiveness (multiple inheritance), and modularity, i.e. open-world assumption (OWA). Runtime efficiency is conditioned by both the implementation technique and compilation scheme. The former specifies the data structures that support method invocation, attribute access and subtype testing. The latter consists of the production line of an executable from the source code. Many implementation techniques have been proposed and several compilation schemes can be considered from fully global compilation under the closed-world assumption (CWA) to separate compilation with dynamic loading under the OWA, with midway solutions. This article reviews a significant subset of possible combinations and presents a systematic, empirical comparison of their respective efficiencies with all other things being equal. The testbed consists of the Prm compiler that has been designed for this purpose. The considered techniques include C++ subobjects, coloring, perfect hashing, binary tree dispatch and caching. A variety of processors were considered. Qualitatively, these first results confirm the intuitive or theoretical abstract assessments of the tested approaches. As expected, efficiency increases as CWA strengthens. From a quantitative standpoint, the results are the first to precisely compare the efficiency of techniques that are closely associated with specific languages like C++ and Eiffel. They also confirm that perfect hashing should be considered for implementing Java and .Net interfaces.","multiple subtyping, binary tree dispatch, method tables, subtype test, late binding, interfaces, dynamic loading, virtual function table, type analysis, single inheritance, downcast, perfect hashing, coloring, multiple inheritance, open-world assumption, closed-world assumption",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Yang Y,Oliveira BC",Unifying Typing and Subtyping,Proc. ACM Program. Lang.,2017,1,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,,https://doi.org/10.1145/3133871;http://dx.doi.org/10.1145/3133871,10.1145/3133871,"In recent years dependent types have become a hot topic in programming language research. A key reason why dependent types are interesting is that they allow unifying types and terms, which enables both additional expressiveness and economy of concepts. Unfortunately there has been much less work on dependently typed calculi for object-oriented programming. This is partly because it is widely acknowledged that the combination between dependent types and subtyping is particularly challenging.This paper presents λ I≤, which is a dependently typed generalization of System F≤. The resulting calculus follows the style of Pure Type Systems, and contains a single unified syntactic sort that accounts for expressions, types and kinds. To address the challenges posed by the combination of dependent types and subtyping, λ I≤ employs a novel technique that unifies typing and subtyping. In λ I≤ there is only a judgement that is akin to a typed version of subtyping. Both the typing relation, as well as type well-formedness are just special cases of the subtyping relation. The resulting calculus has a rich metatheory and enjoys of several standard and desirable properties, such as subject reduction, transitivity of subtyping, narrowing as well as standard substitution lemmas. All the metatheory of λ I≤ is mechanically proved in the Coq theorem prover. Furthermore, (and as far as we are aware) λ I≤ is the first dependently typed calculus that completely subsumes System F≤, while preserving various desirable properties.","dependent types, subtyping, object-oriented programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Strickland TS,Ren BM,Foster JS",Contracts for Domain-Specific Languages in Ruby,,2014,,,23–34,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th ACM Symposium on Dynamic Languages,"Portland, Oregon, USA",2014,9781450332118,,https://doi.org/10.1145/2661088.2661092;http://dx.doi.org/10.1145/2661088.2661092,10.1145/2661088.2661092,"This paper concerns object-oriented embedded DSLs, which are popular in the Ruby community but have received little attention in the research literature. Ruby DSLs implement language keywords as implicit method calls to self; language structure is enforced by adjusting which object is bound to self in different scopes. While Ruby DSLs are powerful and elegant, they suffer from a lack of specification. In this paper, we introduce contracts for Ruby DSLs, which allow us to attribute blame appropriately when there are inconsistencies between an implementation and client. We formalize Ruby DSL contract checking in DSL, a core calculus that uses premethods with instance evaluation to enforce contracts. We then describe RDL, an implementation of Ruby DSL contracts. Finally, we present two tools that automatically infer RDL contracts: TypeInfer infers simple, type-like contracts based on observed method calls, and DSLInfer infers DSL keyword scopes and nesting by generating and testing candidate DSL usages based on initial examples. The type contracts generated by TypeInfer work well enough, though they are limited in precision by the small number of tests, while DSLInfer finds almost all DSL structure. Our goal is to help users understand a DSL from example programs.","software contracts, domain-specific languages",DLS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Strickland TS,Ren BM,Foster JS",Contracts for Domain-Specific Languages in Ruby,SIGPLAN Not.,2014,50,2,23–34,Association for Computing Machinery,"New York, NY, USA",,,,2014-10,,0362-1340,https://doi.org/10.1145/2775052.2661092;http://dx.doi.org/10.1145/2775052.2661092,10.1145/2775052.2661092,"This paper concerns object-oriented embedded DSLs, which are popular in the Ruby community but have received little attention in the research literature. Ruby DSLs implement language keywords as implicit method calls to self; language structure is enforced by adjusting which object is bound to self in different scopes. While Ruby DSLs are powerful and elegant, they suffer from a lack of specification. In this paper, we introduce contracts for Ruby DSLs, which allow us to attribute blame appropriately when there are inconsistencies between an implementation and client. We formalize Ruby DSL contract checking in DSL, a core calculus that uses premethods with instance evaluation to enforce contracts. We then describe RDL, an implementation of Ruby DSL contracts. Finally, we present two tools that automatically infer RDL contracts: TypeInfer infers simple, type-like contracts based on observed method calls, and DSLInfer infers DSL keyword scopes and nesting by generating and testing candidate DSL usages based on initial examples. The type contracts generated by TypeInfer work well enough, though they are limited in precision by the small number of tests, while DSLInfer finds almost all DSL structure. Our goal is to help users understand a DSL from example programs.","software contracts, domain-specific languages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mäkelä S,Leppänen V",External Views on Class Cohesion,,2007,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2007 International Conference on Computer Systems and Technologies,Bulgaria,2007,9789549641509,,https://doi.org/10.1145/1330598.1330707;http://dx.doi.org/10.1145/1330598.1330707,10.1145/1330598.1330707,"Several cohesion metrics measuring quality of object-oriented programs have been proposed recently. Typically some kind of bipartite usage graph is calculated between methods of a class and its variables, and interpretations of what constitutes methods, variables, usage relation and calculation method have served as sources of variation. By advancing the usage of instance variables by the instance methods to measure relatedness of the class properties, the values given by metrics depend on implementation choices -- how the contents of an object is presented as instance variable values. Another problem is that objects often consist of property sets that are only slightly related internally, but clients of objects make such connections between the property sets by advancing internally seemingly unrelated property sets simultaneously.In this paper, we propose forming cohesion graphs between the clients of a class and its abstract properties. Since abstract properties are usually not specified in program code, in practice we use the actual instance variables instead. Our approach complements the internal cohesion view with external views based on the external usage of class properties. We show results for some parts of the Java SDK 5.0 library.","metrics, software engineering",CompSysTech '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Flatland RY,Matthews JR",Using Modes of Inquiry and Engaging Problems to Link Computer Science and Mathematics,,2009,,,387–391,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 40th ACM Technical Symposium on Computer Science Education,"Chattanooga, TN, USA",2009,9781605581835,,https://doi.org/10.1145/1508865.1509002;http://dx.doi.org/10.1145/1508865.1509002,10.1145/1508865.1509002,"In this paper we show how an engaging problem can be used in both a discrete mathematics course and a programming course as a way to expose students to multiple methods of inquiry and to strengthen the links between the two courses. Since students typically take Discrete Mathematics and a programming course simultaneously, this is an opportunity for them to analyze a problem from multiple perspectives during a single semester. We describe how we have accomplished this using a relatively new problem that is easily stated and has a surprising solution that defies intuition. In the programming course, students experienced a design/empirical approach to the problem by implementing simulations of various solutions and collecting experimental results. By adjusting the emphasis of the programming assignment, we show that it can fit naturally into a range of programming courses, i.e. courses on introductory programming, data structures, and object-oriented techniques. In the Discrete Mathematics course, students analyzed solutions using tools from counting, probability, and calculus. We observed that by linking the two courses using a common problem, our students were more cognizant of inquiry methods and student engagement increased.","methods of inquiry, java interface, simulation, collections class shuffle, locker problem, cycles",SIGCSE '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Flatland RY,Matthews JR",Using Modes of Inquiry and Engaging Problems to Link Computer Science and Mathematics,SIGCSE Bull.,2009,41,1,387–391,Association for Computing Machinery,"New York, NY, USA",,,,2009-03,,0097-8418,https://doi.org/10.1145/1539024.1509002;http://dx.doi.org/10.1145/1539024.1509002,10.1145/1539024.1509002,"In this paper we show how an engaging problem can be used in both a discrete mathematics course and a programming course as a way to expose students to multiple methods of inquiry and to strengthen the links between the two courses. Since students typically take Discrete Mathematics and a programming course simultaneously, this is an opportunity for them to analyze a problem from multiple perspectives during a single semester. We describe how we have accomplished this using a relatively new problem that is easily stated and has a surprising solution that defies intuition. In the programming course, students experienced a design/empirical approach to the problem by implementing simulations of various solutions and collecting experimental results. By adjusting the emphasis of the programming assignment, we show that it can fit naturally into a range of programming courses, i.e. courses on introductory programming, data structures, and object-oriented techniques. In the Discrete Mathematics course, students analyzed solutions using tools from counting, probability, and calculus. We observed that by linking the two courses using a common problem, our students were more cognizant of inquiry methods and student engagement increased.","cycles, collections class shuffle, java interface, simulation, methods of inquiry, locker problem",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Jacobs B,Piessens F,Smans J,Leino KR,Schulte W",A Programming Model for Concurrent Object-Oriented Programs,ACM Trans. Program. Lang. Syst.,2008,31,1,,Association for Computing Machinery,"New York, NY, USA",,,,2008-12,,0164-0925,https://doi.org/10.1145/1452044.1452045;http://dx.doi.org/10.1145/1452044.1452045,10.1145/1452044.1452045,"Reasoning about multithreaded object-oriented programs is difficult, due to the nonlocal nature of object aliasing and data races. We propose a programming regime (or programming model) that rules out data races, and enables local reasoning in the presence of object aliasing and concurrency. Our programming model builds on the multithreading and synchronization primitives as they are present in current mainstream programming languages. Java or C# programs developed according to our model can be annotated by means of stylized comments to make the use of the model explicit. We show that such annotated programs can be formally verified to comply with the programming model. If the annotated program verifies, the underlying Java or C# program is guaranteed to be free from data races, and it is sound to reason locally about program behavior. Verification is modular: a program is valid if all methods are valid, and validity of a method does not depend on program elements that are not visible to the method. We have implemented a verifier for programs developed according to our model in a custom build of the Spec# programming system, and we have validated our approach on a case study.","Aliasing, data races, local reasoning, ownership, modular reasoning, verification condition generation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Drey Z,Teodorov C",Object-Oriented Design Pattern for DSL Program Monitoring,,2016,,,70–83,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 ACM SIGPLAN International Conference on Software Language Engineering,"Amsterdam, Netherlands",2016,9781450344470,,https://doi.org/10.1145/2997364.2997373;http://dx.doi.org/10.1145/2997364.2997373,10.1145/2997364.2997373,"To ease domain-specific language (DSL) development, a range of language workbenches have been created, which provide language design facilities and programming tools, like editors and validators. In spite of these developments, there is a perceived lack of tool support for execution monitoring, which is the basic block for program validation and maintenance. To partially address this issue some language workbenches offer ad-hoc solutions for DSL debugging, but lack support for other monitoring features. In the literature, a number of domain-specific monitoring tools have been proposed. However, there is no clear way for integrating these developments in existing language workbenches. This paper presents ten requirements needed for creating a modular and composable DSL monitoring infrastructure and proposes an object-oriented design pattern for DSL program monitoring. This pattern provides a practical answer to the problem of interfacing the runtime of a DSL with concrete domain-specific monitoring tools. To show the practicability of our approach, we add monitoring support to a simple lambda calculus, without changing the standard interpreter. The ease of integrating monitoring tools is shown through the development of a tracer and the integration of an off-the-shelf domain-specific profiler.","language workbench, domain-specific language, execution monitoring",SLE 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Garcia R,Tanter É,Wolff R,Aldrich J",Foundations of Typestate-Oriented Programming,ACM Trans. Program. Lang. Syst.,2014,36,4,,Association for Computing Machinery,"New York, NY, USA",,,,2014-10,,0164-0925,https://doi.org/10.1145/2629609;http://dx.doi.org/10.1145/2629609,10.1145/2629609,"Typestate reflects how the legal operations on imperative objects can change at runtime as their internal state changes. A typestate checker can statically ensure, for instance, that an object method is only called when the object is in a state for which the operation is well defined. Prior work has shown how modular typestate checking can be achieved thanks to access permissions and state guarantees. However, typestate was not treated as a primitive language concept: typestate checkers are an additional verification layer on top of an existing language. In contrast, a typestate-oriented programming (TSOP) language directly supports expressing typestates. For example, in the Plaid programming language, the typestate of an object directly corresponds to its class, and that class can change dynamically. Plaid objects have not only typestate-dependent interfaces but also typestate-dependent behaviors and runtime representations.This article lays foundations for TSOP by formalizing a nominal object-oriented language with mutable state that integrates typestate change and typestate checking as primitive concepts. We first describe a statically typed language—Featherweight Typestate (FT)—where the types of object references are augmented with access permissions and state guarantees. We describe a novel flow-sensitive permission-based type system for FT. Because static typestate checking is still too rigid for some applications, we then extend this language into a gradually typed language—Gradual Featherweight Typestate (GFT). This language extends the notion of gradual typing to account for typestate: gradual typestate checking seamlessly combines static and dynamic checking by automatically inserting runtime checks into programs. The gradual type system of GFT allows programmers to write dynamically safe code even when the static type checker can only partly verify it.","gradual typing, types, Access permissions, typestates",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Roberson M,Harries M,Darga PT,Boyapati C",Efficient Software Model Checking of Soundness of Type Systems,,2008,,,493–504,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582153,,https://doi.org/10.1145/1449764.1449803;http://dx.doi.org/10.1145/1449764.1449803,10.1145/1449764.1449803,"This paper presents novel techniques for checking the soundness of a type system automatically using a software model checker. Our idea is to systematically generate every type correct intermediate program state (within some finite bounds), execute the program one step forward if possible using its small step operational semantics, and then check that the resulting intermediate program state is also type correct--but do so efficiently by detecting similarities in this search space and pruning away large portions of the search space. Thus, given only a specification of type correctness and the small step operational semantics for a language, our system automatically checks type soundness by checking that the progress and preservation theorems hold for the language (albeit for program states of at most some finite size). Our preliminary experimental results on several languages--including a language of integer and boolean expressions, a simple imperative programming language, an object-oriented language which is a subset of Java, and a language with ownership types--indicate that our approach is feasible and that our search space pruning techniques do indeed significantly reduce what is otherwise an extremely large search space. Our paper thus makes contributions both in the area of checking soundness of type systems, and in the area of reducing the state space of a software model checker.","type soundness, software model checking",OOPSLA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Roberson M,Harries M,Darga PT,Boyapati C",Efficient Software Model Checking of Soundness of Type Systems,SIGPLAN Not.,2008,43,10,493–504,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,0362-1340,https://doi.org/10.1145/1449955.1449803;http://dx.doi.org/10.1145/1449955.1449803,10.1145/1449955.1449803,"This paper presents novel techniques for checking the soundness of a type system automatically using a software model checker. Our idea is to systematically generate every type correct intermediate program state (within some finite bounds), execute the program one step forward if possible using its small step operational semantics, and then check that the resulting intermediate program state is also type correct--but do so efficiently by detecting similarities in this search space and pruning away large portions of the search space. Thus, given only a specification of type correctness and the small step operational semantics for a language, our system automatically checks type soundness by checking that the progress and preservation theorems hold for the language (albeit for program states of at most some finite size). Our preliminary experimental results on several languages--including a language of integer and boolean expressions, a simple imperative programming language, an object-oriented language which is a subset of Java, and a language with ownership types--indicate that our approach is feasible and that our search space pruning techniques do indeed significantly reduce what is otherwise an extremely large search space. Our paper thus makes contributions both in the area of checking soundness of type systems, and in the area of reducing the state space of a software model checker.","software model checking, type soundness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Dolby J,Hammer C,Marino D,Tip F,Vaziri M,Vitek J",A Data-Centric Approach to Synchronization,ACM Trans. Program. Lang. Syst.,2012,34,1,,Association for Computing Machinery,"New York, NY, USA",,,,2012-05,,0164-0925,https://doi.org/10.1145/2160910.2160913;http://dx.doi.org/10.1145/2160910.2160913,10.1145/2160910.2160913,"Concurrency-related errors, such as data races, are frustratingly difficult to track down and eliminate in large object-oriented programs. Traditional approaches to preventing data races rely on protecting instruction sequences with synchronization operations. Such control-centric approaches are inherently brittle, as the burden is on the programmer to ensure that all concurrently accessed memory locations are consistently protected. Data-centric synchronization is an alternative approach that offloads some of the work on the language implementation. Data-centric synchronization groups fields of objects into atomic sets to indicate that these fields must always be updated atomically. Each atomic set has associated units of work, that is, code fragments that preserve the consistency of that atomic set. Synchronization operations are added automatically by the compiler. We present an extension to the Java programming language that integrates annotations for data-centric concurrency control. The resulting language, called AJ, relies on a type system that enables separate compilation and supports atomic sets that span multiple objects and that also supports full encapsulation for more efficient code generation. We evaluate our proposal by refactoring classes from standard libraries, as well as a number of multithreaded benchmarks, to use atomic sets. Our results suggest that data-centric synchronization is easy to use and enjoys low annotation overhead, while successfully preventing data races. Moreover, experiments on the SPECjbb benchmark suggest that acceptable performance can be achieved with a modest amount of tuning.","serializability, data races, programming model, Concurrent object-oriented programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Helm D,Kübler F,Eichberg M,Reif M,Mezini M",A Unified Lattice Model and Framework for Purity Analyses,,2018,,,340–350,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering,"Montpellier, France",2018,9781450359375,,https://doi.org/10.1145/3238147.3238226;http://dx.doi.org/10.1145/3238147.3238226,10.1145/3238147.3238226,"Analyzing methods in object-oriented programs whether they are side-effect free and also deterministic, i.e., mathematically pure, has been the target of extensive research. Identifying such methods helps to find code smells and security related issues, and also helps analyses detecting concurrency bugs. Pure methods are also used by formal verification approaches as the foundations for specifications and proving the pureness is necessary to ensure correct specifications. However, so far no common terminology exists which describes the purity of methods. Furthermore, some terms (e.g., pure or side-effect free) are also used inconsistently. Further, all current approaches only report selected purity information making them only suitable for a smaller subset of the potential use cases. In this paper, we present a fine-grained unified lattice model which puts the purity levels found in the literature into relation and which adds a new level that generalizes existing definitions. We have also implemented a scalable, modularized purity analysis which produces significantly more precise results for real-world programs than the best-performing related work. The analysis shows that all defined levels are found in real-world projects.","side-effects, lattice, Purity, Java, static analysis",ASE 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"El Hajj I,Jablin TB,Milojicic D,Hwu WM",SAVI Objects: Sharing and Virtuality Incorporated,Proc. ACM Program. Lang.,2017,1,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,,https://doi.org/10.1145/3133869;http://dx.doi.org/10.1145/3133869,10.1145/3133869,"Direct sharing and storing of memory objects allows high-performance and low-overhead collaboration between parallel processes or application workflows with loosely coupled programs. However, sharing of objects is hindered by the inability to use subtype polymorphism which is common in object-oriented programming languages. That is because implementations of subtype polymorphism in modern compilers rely on using virtual tables stored at process-specific locations, which makes objects unusable in processes other than the creating process. In this paper, we present SAVI Objects, objects with Sharing and Virtuality Incorporated. SAVI Objects support subtype polymorphism but can still be shared across processes and stored in persistent data structures. We propose two different techniques to implement SAVI Objects and evaluate the tradeoffs between them. The first technique is virtual table duplication which adheres to the virtual-table-based implementation of subtype polymorphism, but duplicates virtual tables for shared objects to fixed memory addresses associated with each shared memory region. The second technique is hashing-based dynamic dispatch which re-implements subtype polymorphism using hashing-based look-ups to a global virtual table. Our results show that SAVI Objects enable direct sharing and storing of memory objects that use subtype polymorphism by adding modest overhead costs to object construction and dynamic dispatch time. SAVI Objects thus enable faster inter-process communication, improving the overall performance of production applications that share polymorphic objects.","Devirtualization, Dynamic dispatch, Inter-process communication, Managed data structures, Shared memory regions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gupta N,Singh D,Sharma A",Identifying Effective Software Metrics for Categorical Defect Prediction Using Structural Equation Modeling,,2015,,,59–65,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third International Symposium on Women in Computing and Informatics,"Kochi, India",2015,9781450333610,,https://doi.org/10.1145/2791405.2791484;http://dx.doi.org/10.1145/2791405.2791484,10.1145/2791405.2791484,"Software Defect prediction is the pre-eminent area of software engineering which has witnessed huge importance over last decades. The identification of defects in the early stages of software development improve the quality of the software system and reduce the effort in maintaining the quality of software product. Many research studies have been conducted to construct the prediction model that considers the CK metrics suite and object oriented software metrics. For the prediction model development, consideration of interaction among the metrics is not a common practice. This paper presents the empirical evaluation in which several software metrics were investigated in order to identify the effective set of the metrics for each defect category which can significantly improve the defect prediction model made for each defect category. For each of the metrics, Pearson correlation coefficient with the number of defect categories were calculated and subsequently stepwise regression model is constructed to predict the reduced set metrics for each defect category. We have proposed a novel approach for modeling the defects using structural equation modeling further which validates our work. Structural models were built for each defect category using structural equation modeling which claims that results are validated.","Defect Prediction, Stepwise regression model, Structural Equation Modeling, Software Metrics",WCI '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Millstein T,Frost C,Ryder J,Warth A",Expressive and Modular Predicate Dispatch for Java,ACM Trans. Program. Lang. Syst.,2009,31,2,,Association for Computing Machinery,"New York, NY, USA",,,,2009-02,,0164-0925,https://doi.org/10.1145/1462166.1462168;http://dx.doi.org/10.1145/1462166.1462168,10.1145/1462166.1462168,"Predicate dispatch is an object-oriented (OO) language mechanism for determining the method implementation to be invoked upon a message send. With predicate dispatch, each method implementation includes a predicate guard specifying the conditions under which the method should be invoked, and logical implication of predicates determines the method overriding relation. Predicate dispatch naturally unifies and generalizes several common forms of dynamic dispatch, including traditional OO dispatch, multimethod dispatch, and functional-style pattern matching. Unfortunately, prior languages supporting predicate dispatch have had several deficiencies that limit the practical utility of this language feature.We describe JPred, a backward-compatible extension to Java supporting predicate dispatch. While prior languages with predicate dispatch have been extensions to toy or nonmainstream languages, we show how predicate dispatch can be naturally added to a traditional OO language. While prior languages with predicate dispatch have required the whole program to be available for typechecking and compilation, JPred retains Java's modular typechecking and compilation strategies. While prior languages with predicate dispatch have included special-purpose algorithms for reasoning about predicates, JPred employs general-purpose, off-the-shelf decision procedures. As a result, JPred's type system is more flexible, allowing several useful programming idioms that are spuriously rejected by those other languages. After describing the JPred language informally, we present an extension to Featherweight Java that formalizes the language and its modular type system, which we have proven sound. Finally, we discuss two case studies that illustrate the practical utility of JPred, including its use in the detection of several errors.","Predicate dispatch, dynamic dispatch, modular typechecking",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zhang S,Palus: A Hybrid Automated Test Generation Tool for Java,,2011,,,1182–1184,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd International Conference on Software Engineering,"Waikiki, Honolulu, HI, USA",2011,9781450304450,,https://doi.org/10.1145/1985793.1986036;http://dx.doi.org/10.1145/1985793.1986036,10.1145/1985793.1986036,"In object-oriented programs, a unit test often consists of a sequence of method calls that create and mutate objects. It is challenging to automatically generate sequences that are legal and behaviorally-diverse, that is, reaching as many different program states as possible.This paper proposes a combined static and dynamic test generation approach to address these problems, for code without a formal specification. Our approach first uses dynamic analysis to infer a call sequence model from a sample execution, then uses static analysis to identify method dependence relations based on the fields they may read or write. Finally, both the dynamically-inferred model (which tends to be accurate but incomplete) and the statically-identified dependence information (which tends to be conservative) guide a random test generator to create legal and behaviorally-diverse tests.Our Palus tool implements this approach. We compared it with a pure random approach, a dynamic-random approach (without a static phase), and a static-random approach (without a dynamic phase) on six popular open-source Java programs. Tests generated by Palus achieved 35% higher structural coverage on average. Palus is also internally used in Google, and has found 22 new bugs in four well-tested products.","static and dynamic analyses, automated test generation",ICSE '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shanthi IE,Izaaz Y,Nadarajan R",On the SD-Tree Construction for Optimal Signature Operations,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st Bangalore Annual Compute Conference,"Bangalore, India",2008,9781595939500,,https://doi.org/10.1145/1341771.1341786;http://dx.doi.org/10.1145/1341771.1341786,10.1145/1341771.1341786,Signature file based access methods initially applied on text have now been used to handle set-oriented queries in Object-Oriented Data Bases (OODB). All the proposed methods use either efficient search method or tree based intermediate data structure to filter data objects matching the query. Use of search techniques retrieves the objects by sequentially comparing the positions of 1s in it. Such methods take longer retrieval time. On the other hand tree based structures traverse multiple paths making comparison process tedious. In this paper we describe a new indexing technique for OODB using the dynamic balancing of B+ tree called SD (Signature Declustering) tree. In this work the positions of 1s in the signatures are distributed over a set of leaf nodes. Using this for a given query signature all the matching signatures can be retrieved cumulatively in a single node. Also for signature insertion and query searching an optimal search path is calculated so that the entire process is speeded up. Experiments have been conducted to analyze the time and space overhead of the SD-tree by varying the signature length and the distribution of signature weight. The study clearly indicates the advantage of fast retrieval time in a way quite different from the other methods suggested in the past.,"information retrieval, signature file, OODB, indexing",COMPUTE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Titzer BL,"Harmonizing Classes, Functions, Tuples, and Type Parameters in Virgil Iii",,2013,,,85–94,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Seattle, Washington, USA",2013,9781450320146,,https://doi.org/10.1145/2491956.2491962;http://dx.doi.org/10.1145/2491956.2491962,10.1145/2491956.2491962,"Languages are becoming increasingly multi-paradigm. Subtype polymorphism in statically-typed object-oriented languages is being supplemented with parametric polymorphism in the form of generics. Features like first-class functions and lambdas are appearing everywhere. Yet existing languages like Java, C#, C++, D, and Scala seem to accrete ever more complexity when they reach beyond their original paradigm into another; inevitably older features have some rough edges that lead to nonuniformity and pitfalls. Given a fresh start, a new language designer is faced with a daunting array of potential features. Where to start? What is important to get right first, and what can be added later? What features must work together, and what features are orthogonal? We report on our experience with Virgil III, a practical language with a careful balance of classes, functions, tuples and type parameters. Virgil intentionally lacks many advanced features, yet we find its core feature set enables new species of design patterns that bridge multiple paradigms and emulate features not directly supported such as interfaces, abstract data types, ad hoc polymorphism, and variant types. Surprisingly, we find variance for function types and tuple types often replaces the need for other kinds of type variance when libraries are designed in a more functional style.","variance, flattening, tuples, functional programming, parametric types, unboxing, static compi- lation, multi-paradigm languages, closures, monomorphization, object- oriented programmin",PLDI '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Titzer BL,"Harmonizing Classes, Functions, Tuples, and Type Parameters in Virgil Iii",SIGPLAN Not.,2013,48,6,85–94,Association for Computing Machinery,"New York, NY, USA",,,,2013-06,,0362-1340,https://doi.org/10.1145/2499370.2491962;http://dx.doi.org/10.1145/2499370.2491962,10.1145/2499370.2491962,"Languages are becoming increasingly multi-paradigm. Subtype polymorphism in statically-typed object-oriented languages is being supplemented with parametric polymorphism in the form of generics. Features like first-class functions and lambdas are appearing everywhere. Yet existing languages like Java, C#, C++, D, and Scala seem to accrete ever more complexity when they reach beyond their original paradigm into another; inevitably older features have some rough edges that lead to nonuniformity and pitfalls. Given a fresh start, a new language designer is faced with a daunting array of potential features. Where to start? What is important to get right first, and what can be added later? What features must work together, and what features are orthogonal? We report on our experience with Virgil III, a practical language with a careful balance of classes, functions, tuples and type parameters. Virgil intentionally lacks many advanced features, yet we find its core feature set enables new species of design patterns that bridge multiple paradigms and emulate features not directly supported such as interfaces, abstract data types, ad hoc polymorphism, and variant types. Surprisingly, we find variance for function types and tuple types often replaces the need for other kinds of type variance when libraries are designed in a more functional style.","monomorphization, static compi- lation, functional programming, parametric types, object- oriented programmin, flattening, multi-paradigm languages, closures, variance, unboxing, tuples",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Esteban G,Fernández C,Conde MA,Matellán V",Design of a Haptic Simulator Framework for Modelling Surgical Learning Systems,,2013,,,87–94,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the First International Conference on Technological Ecosystem for Enhancing Multiculturality,"Salamanca, Spain",2013,9781450323451,,https://doi.org/10.1145/2536536.2536551;http://dx.doi.org/10.1145/2536536.2536551,10.1145/2536536.2536551,"Performing a surgery requires a high degree of skill and experience, so it is well known that in order to become a surgeon someone must take several years of intense study and practice. The use of virtual reality simulators aids in this process by offering new features that the traditional methods simply can not include, like experience unfamiliar scenarios or practice several times without having an economic cost. In this context, when developers try to create a new medical haptic simulator, they face many problems: existing dedicated frameworks are not standard and mature enough and the development often requires interviews with experts, which turns into long development times. This paper is the continuation of a previous work that presented an approach to surgical procedures using computer haptic simulators. Here, we describe a detailed version of the model beneath that approach by showing its software architecture. This description will cover the formal definition of the model, its modelization using BPMN notation and its software object-oriented design focusing on its core functionality, which is based on combining three design patterns: the State Machine (for controlling the execution flow of the simulation through events), the Visitor (for setting the actions within the simulation) and the Observer (for collecting the outcome of the simulation execution).","haptic simulator, e-learning framework, design pattern",TEEM '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Shareef JW,Pandey RK",CAME: Component Assembly Metrics Extraction Using UML,SIGSOFT Softw. Eng. Notes,2013,38,4,1–12,Association for Computing Machinery,"New York, NY, USA",,,,2013-07,,0163-5948,https://doi.org/10.1145/2492248.2492273;http://dx.doi.org/10.1145/2492248.2492273,10.1145/2492248.2492273,"In Object-Oriented software development, complexity metrics help software engineers to identify the deficiencies in the design of the software system that are likely to become problem points in the subsequent phases of the SDLC, like testing and maintenance. Metrics for Component Based Software Development (CBSD) have also been proposed by the researchers. Lately the emphasis has been on metrics that are applicable during early phases of the SDLC. The XML Meta Data Interchange (XMI) standard has been implemented in most of the commercial and open source UML tools. It is now possible to automate the metrics extraction procedure right from the UML design documents. Detection of design deficiencies early in the design phase saves a lot of time and effort and results in a more maintainable design. In the present paper, we discuss the design and implementation of a metrics tool for CBSD. We have implemented component based metrics in a parserbased tool, which hereafter we refer to as CAME (Component Assembly Metrics Extraction), to calculate metrics from UML design documents. CAME is capable of generating software metrics proposed by researchers for Component Based Software Systems. We demonstrate our tool using UML component assembly diagrams for a University Case Registration System (UCRS) and its representation in UML and metrics extraction procedure.","CBS, XML, software metrics, XMI, SAX parser, component diagram, UML",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Clebsch S,Drossopoulou S",Fully Concurrent Garbage Collection of Actors on Many-Core Machines,,2013,,,553–570,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages & Applications,"Indianapolis, Indiana, USA",2013,9781450323741,,https://doi.org/10.1145/2509136.2509557;http://dx.doi.org/10.1145/2509136.2509557,10.1145/2509136.2509557,"Disposal of dead actors in actor-model languages is as important as disposal of unreachable objects in object-oriented languages. In current practice, programmers are required to either manually terminate actors, or they have to rely on garbage collection systems that monitor actor mutation through write barriers, thread coordination through locks etc. These techniques, however, prevent the collector from being fully concurrent.We developed a protocol that allows garbage collection to run fully concurrently with all actors. The main challenges in concurrent garbage collection is the detection of cycles of sleeping actors in the actors graph, in the presence of concurrent mutation of this graph. Our protocol is solely built on message passing: it uses deferred direct reference counting, a dedicated actor for the detection of (cyclic) garbage, and a confirmation protocol (to deal with the mutation of the actor graph).We present our ideas informally through an example, and then present a formal model, prove soundness and argue completeness. We have implemented the protocol as part of a runtime library. As a preliminary performance evaluation, we discuss the performance of our approach as currently used at a financial institution, and use four benchmarks from the literature to compare our approach with other actor-model systems. These preliminary results indicate that the overhead of our approach is small.","concurrency, many-core, garbage collection, message passing, actors",OOPSLA '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Clebsch S,Drossopoulou S",Fully Concurrent Garbage Collection of Actors on Many-Core Machines,SIGPLAN Not.,2013,48,10,553–570,Association for Computing Machinery,"New York, NY, USA",,,,2013-10,,0362-1340,https://doi.org/10.1145/2544173.2509557;http://dx.doi.org/10.1145/2544173.2509557,10.1145/2544173.2509557,"Disposal of dead actors in actor-model languages is as important as disposal of unreachable objects in object-oriented languages. In current practice, programmers are required to either manually terminate actors, or they have to rely on garbage collection systems that monitor actor mutation through write barriers, thread coordination through locks etc. These techniques, however, prevent the collector from being fully concurrent.We developed a protocol that allows garbage collection to run fully concurrently with all actors. The main challenges in concurrent garbage collection is the detection of cycles of sleeping actors in the actors graph, in the presence of concurrent mutation of this graph. Our protocol is solely built on message passing: it uses deferred direct reference counting, a dedicated actor for the detection of (cyclic) garbage, and a confirmation protocol (to deal with the mutation of the actor graph).We present our ideas informally through an example, and then present a formal model, prove soundness and argue completeness. We have implemented the protocol as part of a runtime library. As a preliminary performance evaluation, we discuss the performance of our approach as currently used at a financial institution, and use four benchmarks from the literature to compare our approach with other actor-model systems. These preliminary results indicate that the overhead of our approach is small.","concurrency, garbage collection, many-core, message passing, actors",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang S,Saff D,Bu Y,Ernst MD",Combined Static and Dynamic Automated Test Generation,,2011,,,353–363,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 International Symposium on Software Testing and Analysis,"Toronto, Ontario, Canada",2011,9781450305624,,https://doi.org/10.1145/2001420.2001463;http://dx.doi.org/10.1145/2001420.2001463,10.1145/2001420.2001463,"In an object-oriented program, a unit test often consists of a sequence of method calls that create and mutate objects, then use them as arguments to a method under test. It is challenging to automatically generate sequences that are legal and behaviorally-diverse, that is, reaching as many different program states as possible.This paper proposes a combined static and dynamic automated test generation approach to address these problems, for code without a formal specification. Our approach first uses dynamic analysis to infer a call sequence model from a sample execution, then uses static analysis to identify method dependence relations based on the fields they may read or write. Finally, both the dynamically-inferred model (which tends to be accurate but incomplete) and the statically-identified dependence information (which tends to be conservative) guide a random test generator to create legal and behaviorally-diverse tests.Our Palus tool implements this testing approach. We compared its effectiveness with a pure random approach, a dynamic-random approach (without a static phase), and a static-random approach (without a dynamic phase) on several popular open-source Java programs. Tests generated by Palus achieved higher structural coverage and found more bugs.Palus is also internally used in Google. It has found 22 previously-unknown bugs in four well-tested Google products.","static, dynamic analyses, automated test generation",ISSTA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Al-Fedaghi S,Sets with Members as Machines with Things That Flow,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing","Cambridge, United Kingdom",2017,9781450347747,,https://doi.org/10.1145/3018896.3018943;http://dx.doi.org/10.1145/3018896.3018943,10.1145/3018896.3018943,"Mathematics and computer science are strongly intertwined, especially in using the language of set theory as a suitable base for transitions between formal (human-computer) and informal (human-human) communications and in supporting modeling, e.g., object oriented concepts. Yet, it seems that difficulties occur when set notations and diagrams are applied, which has motivated a search for an alternative to traditional ways of visually depicting set theory. Some researchers propose distinguishing between \set\"" and \""collection.\"" Others claim that the fundamental error in metaphysical interpretations of set theory",the reification of a collection as a separate object,is a result of grammatical confusion. Another issue raised in this context with regard to set theory is the static state that has been imposed on its representation; e.g.,sets are spaces of containers,"and \""movements\"" of members are conceptualized as \""arches\"" called mapping and functions. This paper offers a visual representation of set theory that may benefit modeling in computer science based on the familiar notion of machines. A machine can be seen as an extended form of the input-process-output system with five basic \""operations\"": releasing",transferring,receiving,processing,"and creating of things that flow. The paper employs such a schematization apparatus to construct a high-level description of sets and functions. The resultant diagrammatic representation seems a viable tool for enhancing the relationship between mathematics and computer science.""","conceptual modeling, diagrammatic representation, abstract machine, things that flow, set theory",ICC '17,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Melo LT,Ribeiro RG,Guimarães BC,Pereira FM",Type Inference for C: Applications to the Static Analysis of Incomplete Programs,ACM Trans. Program. Lang. Syst.,2020,42,3,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,0164-0925,https://doi.org/10.1145/3421472;http://dx.doi.org/10.1145/3421472,10.1145/3421472,"Type inference is a feature that is common to a variety of programming languages. While, in the past, it has been prominently present in functional ones (e.g., ML and Haskell), today, many object-oriented/multi-paradigm languages such as C# and C++ offer, to a certain extent, such a feature. Nevertheless, type inference still is an unexplored subject in the realm of C. In particular, it remains open whether it is possible to devise a technique that encompasses the idiosyncrasies of this language. The first difficulty encountered when tackling this problem is that parsing C requires, not only syntactic, but also semantic information. Yet, greater challenges emerge due to C’s intricate type system. In this work, we present a unification-based framework that lets us infer the missing struct, union, enum, and typedef declarations in a program.As an application of our technique, we investigate the reconstruction of partial programs. Incomplete source code naturally appears in software development: during design and while evolving, testing, and analyzing programs; therefore, understanding it is a valuable asset. With a reconstructed well-typed program, one can: (i) enable static analysis tools in scenarios where components are absent; (ii) improve precision of “zero setup” static analysis tools; (iii) apply stub generators, symbolic executors, and testing tools on code snippets; and (iv) provide engineers with an assortment of compilable benchmarks for performance and correctness validation. We evaluate our technique on code from a variety of C libraries, including GNU’s Coreutils and on snippets from popular projects such as CPython, FreeBSD, and Git.","type inference, Partial programs, parsing, C language",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kang S,Ryu S",FortressCheck: Automatic Testing for Generic Properties,,2011,,,1290–1296,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM Symposium on Applied Computing,"TaiChung, Taiwan",2011,9781450301138,,https://doi.org/10.1145/1982185.1982465;http://dx.doi.org/10.1145/1982185.1982465,10.1145/1982185.1982465,"QuickCheck is a random testing library designed for the purely functional programming language Haskell. Its main features include a descriptive yet embedded domain-specific testing language, a variety of test generators including a generator for functions, and a set of operations for monitoring generated inputs. QuickCheck is limited to ad-hoc testing, compared to more systematic testing methods such as full coverage testing. However, experiences showed that well-factored functions and properties make the QuickCheck approach as effective as systematic testing while maintaining its conciseness. QuickCheck and its variants are now available in dozens of programming languages.We present a version of QuickCheck for the Fortress programming language in this paper. Fortress is an object-oriented language with extensive support for functional programming, with the strong emphasis on high-performance computing, parallelism by default, and growability of the language. While the main features of QuickCheck are straight-forward to implement, we are extending them to support unique features of Fortress and to support seamless integration to Fortress. We observed that the prevalent uses of implicit parallelism in Fortress call for testing parallel language constructs especially those using side effects. Also, because Fortress provides both subtype polymorphism and parametric polymorphism unlike Haskell, testing both polymorphic properties becomes interesting. We propose FortressCheck to test implicit parallelism and to test parametric polymorphism via reflection, by generating first-class type objects and using QuickCheck's own implication checking as a safety mechanism.","QuickCheck, Fortress, automatic testing",SAC '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Godio A,Bengolea V,Ponzio P,Aguirre N,Frias MF",Efficient Test Generation Guided by Field Coverage Criteria,,2019,,,91–101,IEEE Press,"San Diego, California",,Proceedings of the 34th IEEE/ACM International Conference on Automated Software Engineering,,2019,9781728125084,,https://doi.org/10.1109/ASE.2019.00019;http://dx.doi.org/10.1109/ASE.2019.00019,10.1109/ASE.2019.00019,"Field-exhaustive testing is a testing criterion suitable for object-oriented code over complex, heap-allocated, data structures. It requires test suites to contain enough test inputs to cover all feasible values for the object's fields within a certain scope (input-size bound). While previous work shows that field-exhaustive suites can be automatically generated, the generation technique required a formal specification of the inputs that can be subject to SAT-based analysis. Moreover, the restriction of producing all feasible values for inputs' fields makes test generation costly.In this paper, we deal with field coverage as testing criteria that measure the quality of a test suite in terms of coverage and mutation score, by examining to what extent the values of inputs' fields are covered. In particular, we consider field coverage in combination with test generation based on symbolic execution to produce underapproximations of field-exhaustive suites, using the Symbolic Pathfinder tool. To underapproximate these suites we use tranScoping, a technique that estimates characteristics of yet to be run analyses for large scopes, based on data obtained from analyses performed in small scopes. This provides us with a suitable condition to prematurely stop the symbolic execution.As we show, tranScoping different metrics regarding field coverage allows us to produce significantly smaller suites using a fraction of the generation time. All this while retaining the effectiveness of field exhaustive suites in terms of test suite quality.","field-based testing, symbolic execution, field-exhaustive testing, transcoping",ASE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brotherston D,Dietl W,Lhoták O",Granullar: Gradual Nullable Types for Java,,2017,,,87–97,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th International Conference on Compiler Construction,"Austin, TX, USA",2017,9781450352338,,https://doi.org/10.1145/3033019.3033032;http://dx.doi.org/10.1145/3033019.3033032,10.1145/3033019.3033032,"Object-oriented languages like Java and C# allow the null value for all references. This supports many flexible patterns, but has led to many errors, security vulnerabilities, and system crashes. % Static type systems can prevent null-pointer exceptions at compile time, but require annotations, in particular for used libraries. Conservative defaults choose the most restrictive typing, preventing many errors, but requiring a large annotation effort. Liberal defaults choose the most flexible typing, requiring less annotations, but giving weaker guarantees. Trusted annotations can be provided, but are not checked and require a large manual effort. None of these approaches provide a strong guarantee that the checked part of the program is isolated from the unchecked part: even with conservative defaults, null-pointer exceptions can occur in the checked part. This paper presents Granullar, a gradual type system for null-safety. Developers start out verifying null-safety for the most important components of their applications. At the boundary to unchecked components, runtime checks are inserted by Granullar to guard the verified system from being polluted by unexpected null values. This ensures that null-pointer exceptions can only occur within the unchecked code or at the boundary to checked code; the checked code is free of null-pointer exceptions. We present Granullar for Java, define the checked-unchecked boundary, and how runtime checks are generated. We evaluate our approach on real world software annotated for null-safety. We demonstrate the runtime checks, and acceptable compile-time and run-time performance impacts. Granullar enables combining a checked core with untrusted libraries in a safe manner, improving on the practicality of such a system.","pluggable type systems, nullness, gradual type systems, runtime checks",CC 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kellogg M,Ran M,Sridharan M,Schäf M,Ernst MD",Verifying Object Construction,,2020,,,1447–1458,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering,"Seoul, South Korea",2020,9781450371216,,https://doi.org/10.1145/3377811.3380341;http://dx.doi.org/10.1145/3377811.3380341,10.1145/3377811.3380341,"In object-oriented languages, constructors often have a combination of required and optional formal parameters. It is tedious and inconvenient for programmers to write a constructor by hand for each combination. The multitude of constructors is error-prone for clients, and client code is difficult to read due to the large number of constructor arguments. Therefore, programmers often use design patterns that enable more flexible object construction---the builder pattern, dependency injection, or factory methods.However, these design patterns can be too flexible: not all combinations of logical parameters lead to the construction of well-formed objects. When a client uses the builder pattern to construct an object, the compiler does not check that a valid set of values was provided. Incorrect use of builders can lead to security vulnerabilities, run-time crashes, and other problems.This work shows how to statically verify uses of object construction, such as the builder pattern. Using a simple specification language, programmers specify which combinations of logical arguments are permitted. Our compile-time analysis detects client code that may construct objects unsafely. Our analysis is based on a novel special case of typestate checking, accumulation analysis, that modularly reasons about accumulations of method calls. Because accumulation analysis does not require precise aliasing information for soundness, our analysis scales to industrial programs. We evaluated it on over 9 million lines of code, discovering defects which included previously-unknown security vulnerabilities and potential null-pointer violations in heavily-used open-source codebases. Our analysis has a low false positive rate and low annotation burden.Our implementation and experimental data are publicly available.","AMI sniping, builder pattern, lombok, pluggable type systems, autovalue, lightweight verification",ICSE '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gupta N,Panwar D,Sharma A",Modeling Structural Model for Defect Categories Based On Software Metrics for Categorical Defect Prediction,,2015,,,46–50,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Sixth International Conference on Computer and Communication Technology 2015,"Allahabad, India",2015,9781450335522,,https://doi.org/10.1145/2818567.2818576;http://dx.doi.org/10.1145/2818567.2818576,10.1145/2818567.2818576,"Software Defect prediction is the pre-eminent area of software engineering which has witnessed huge importance over last decades. The identification of defects in the early stages of software development not only improve the quality of the software system but also reduce the time, cost and effort associated in maintaining the quality of software product. The quality of the software can be best assessed by software metrics. To evaluate the quality of the software, a number of software metrics have been proposed. Many research studies have been conducted to construct the prediction model that considers the CK (Chidamber and Kemerer) metrics suite and object oriented software metrics. For the prediction model development, consideration of interaction among the metrics is not a common practice. This paper presents the empirical evaluation in which several software metrics were investigated in order to identify the effective set of the metrics for each defect category which can significantly improve the defect prediction model made for each defect category. For each of the metrics, Pearson correlation coefficient with the number of defect categories were calculated and subsequently stepwise regression model is constructed for each defect category to predict the set of the metrics that are the good indicator of each defect category. We have proposed a novel approach for modelling the defects using structural equation modeling further which validates our work. Structural models were built for each defect category using structural equation modeling which claims that results are validated.","Defect Prediction, Stepwise regression model, Software Metrics, Structural Equation Modeling",ICCCT '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Moreira GY,Santos JA",Applying Coupling and Cohesion Concepts in Object-Oriented Software: A Controlled Experiment,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,19th Brazilian Symposium on Software Quality,"São Luís, Brazil",2020,9781450389235,,https://doi.org/10.1145/3439961.3439969;http://dx.doi.org/10.1145/3439961.3439969,10.1145/3439961.3439969,"Context: Coupling and cohesion concepts support the object-oriented (OO) design activity. A better design implies less coupled and more cohesive classes. Thus, it is expected studies on OO design investigate issues impacting the good application of these concepts. However, most studies in the area have focused on high-level metaphors, such as code smells and design patterns; or software metrics. Objective: This study aims to build empirical evidence reinforcing that basic concepts deserve more attention towards better OO design. The study investigates the application of coupling and cohesion concepts during programming activity. Two topics are addressed: i) how developer characteristics (“previous knowledge on the concepts” and “developers experience”) impact on software design during programming activity; and ii) the differences in applying the concepts, independently. Method: A quasi-experiment with 17 participants. The participants were graduate and undergraduate students, but all have professional experience in software development. The software they programmed was compared with the experiment’s oracle in terms of the application of coupling and cohesion concepts. Result: One finding is previous knowledge on the concepts impacts on design quality, in some way; while developers experience doesn’t. Another finding is: application of cohesion is significantly easier than application of coupling. Conclusion: A conjecture based on these findings is training on basic OO principles (including formal education) might be more relevant than developer experience towards better software design. At last, the topic needs more investigation. We suggest this approach brings a complementary perspective of analysis to discuss the topic.","programming, coupling, cohesion, object oriented",SBQS'20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Smaragdakis Y,Bravenboer M,Lhoták O",Pick Your Contexts Well: Understanding Object-Sensitivity,,2011,,,17–30,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Austin, Texas, USA",2011,9781450304900,,https://doi.org/10.1145/1926385.1926390;http://dx.doi.org/10.1145/1926385.1926390,10.1145/1926385.1926390,"Object-sensitivity has emerged as an excellent context abstraction for points-to analysis in object-oriented languages. Despite its practical success, however, object-sensitivity is poorly understood. For instance, for a context depth of 2 or higher, past scalable implementations deviate significantly from the original definition of an object-sensitive analysis. The reason is that the analysis has many degrees of freedom, relating to which context elements are picked at every method call and object creation. We offer a clean model for the analysis design space, and discuss a formal and informal understanding of object-sensitivity and of how to create good object-sensitive analyses. The results are surprising in their extent. We find that past implementations have made a sub-optimal choice of contexts, to the severe detriment of precision and performance. We define a \full-object-sensitive\"" analysis that results in significantly higher precision",and often performance,"for the exact same context depth. We also introduce \""type-sensitivity\"" as an explicit approximation of object-sensitivity that preserves high context quality at substantially reduced cost. A type-sensitive points-to analysis makes an unconventional use of types as context: the context types are not dynamic types of objects involved in the analysis",but instead upper bounds on the dynamic types of their allocator objects. Our results expose the influence of context choice on the quality of points-to analysis and demonstrate type-sensitivity to be an idea with major impact: It decisively advances the state-of-the-art with a spectrum of analyses that simultaneously enjoy speed (several times faster than an analogous object-sensitive analysis),scalability (comparable to analyses with much less context-sensitivity),"and precision (comparable to the best object-sensitive analysis with the same context depth).""","points-to analysis, context-sensitivity, type-sensitivity, object-sensitivity",POPL '11,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Smaragdakis Y,Bravenboer M,Lhoták O",Pick Your Contexts Well: Understanding Object-Sensitivity,SIGPLAN Not.,2011,46,1,17–30,Association for Computing Machinery,"New York, NY, USA",,,,2011-01,,0362-1340,https://doi.org/10.1145/1925844.1926390;http://dx.doi.org/10.1145/1925844.1926390,10.1145/1925844.1926390,"Object-sensitivity has emerged as an excellent context abstraction for points-to analysis in object-oriented languages. Despite its practical success, however, object-sensitivity is poorly understood. For instance, for a context depth of 2 or higher, past scalable implementations deviate significantly from the original definition of an object-sensitive analysis. The reason is that the analysis has many degrees of freedom, relating to which context elements are picked at every method call and object creation. We offer a clean model for the analysis design space, and discuss a formal and informal understanding of object-sensitivity and of how to create good object-sensitive analyses. The results are surprising in their extent. We find that past implementations have made a sub-optimal choice of contexts, to the severe detriment of precision and performance. We define a \full-object-sensitive\"" analysis that results in significantly higher precision",and often performance,"for the exact same context depth. We also introduce \""type-sensitivity\"" as an explicit approximation of object-sensitivity that preserves high context quality at substantially reduced cost. A type-sensitive points-to analysis makes an unconventional use of types as context: the context types are not dynamic types of objects involved in the analysis",but instead upper bounds on the dynamic types of their allocator objects. Our results expose the influence of context choice on the quality of points-to analysis and demonstrate type-sensitivity to be an idea with major impact: It decisively advances the state-of-the-art with a spectrum of analyses that simultaneously enjoy speed (several times faster than an analogous object-sensitive analysis),scalability (comparable to analyses with much less context-sensitivity),"and precision (comparable to the best object-sensitive analysis with the same context depth).""","type-sensitivity, points-to analysis, context-sensitivity, object-sensitivity",,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Malhotra R,Chug A,Khosla P",Prioritization of Classes for Refactoring: A Step towards Improvement in Software Quality,,2015,,,228–234,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third International Symposium on Women in Computing and Informatics,"Kochi, India",2015,9781450333610,,https://doi.org/10.1145/2791405.2791463;http://dx.doi.org/10.1145/2791405.2791463,10.1145/2791405.2791463,"Bad Smells are certain structures in the software which violates the design principles and ruin the software quality. In order to deals with the bad smells, often refactoring treatment is provided in the code which further improves the software quality. However, it's not possible to refactor each and every class of the software in maintenance phase due to certain deadlines. Prioritization of classes helps the developer to identify the software portions requiring urgent refactoring. In the current study, we propose a framework to identify the potential classes which immediately require refactoring based on the bad smells as well as design characteristics. We evaluate our approach on medium sized open-source systems ORDrumbox. Four types of code-smells Feature Envy, Long Method, God Class and Type Checking were identified and well known Chidamber and Kemerer metric suite is used to evaluate the object oriented characteristics. Both are combined in certain ratio to calculate new proposed metric Quality Depreciation Index Rule (QDIR) for each class. Classes are further arranged as per their QDIR values to identify the severely affected classes requiring immediate refactoring treatment. This study works on 80:20 principles conveying 80% of the code quality can be improved by just providing refactoring treatment to 20% of the severely affected classes. Results reflects that the bad smells and design metrics can be used as an important source of information to quantify the flaws in the classes, thus helpful to maintainers in performing their task under strict time constraints while maintaining the overall software quality.","Bad Smell, Software Quality, Refactoring, Object Oriented Metrics, Software Maintenance",WCI '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Lee EA,A Fundamental Look at Models and Intelligence: Abstract of Keynote,,2019,,,1,IEEE Press,"Montreal, Quebec, Canada",,Proceedings of the 5th International Workshop on Software Engineering for Smart Cyber-Physical Systems,,2019,,,https://doi.org/10.1109/SEsCPS.2019.00007;http://dx.doi.org/10.1109/SEsCPS.2019.00007,10.1109/SEsCPS.2019.00007,"Comprehensible and analyzable models are central to building confidence in cyber-physical systems. Hybrid systems theories, interface theories, formal semantics, concurrent models of computation, component models, and ontologies all augment classical software engineering techniques such as object-oriented design to catch errors and to make systems more modular and composable. However, as systems integrate self-adaptive capabilities and learning algorithms, keeping models comprehensible and analyzable gets challenging.Every model lives within a modeling framework, ideally giving semantics to the model, and many modeling frameworks have been developed that enable rigorous analysis and proof of properties. But every such modeling framework is an imperfect mirror of reality. An engineered system operating in the physical world may or may not accurately reflect behaviors predicted by a model, and the model may not reflect behaviors that are critical to correct operation of the system. Software in a cyber-physical system, for example, has timing properties that are rarely represented in formal models. As artificial intelligence gets more widely used, the problem gets worse, with predictability and explainability seemingly evaporating.In this keynote talk, I examine the strengths and limitations in the use of models. I will show that two very different classes of models are used in practice, classes that I call \scientific models\"" and \""engineering models\"" [1]. These two classes have complementary properties","and many misuses of models stem from confusion about which class is being used. Scientific models of intelligent systems are very different from engineering models. I will argue that rigorous and analyzable engineering models are useful even in the face of uncertainty and can be used to regulate adaptation and circumscribe the behaviors of learning-based systems.""","cyber-physical systems, self-adaptive systems, model-based design",SEsCPS '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jiang D,Jiang Y,Li J",A Session-Based Interaction Model for Cloud Service,,2020,,,25–28,Association for Computing Machinery,"New York, NY, USA",,2020 The 8th International Conference on Information Technology: IoT and Smart City,"Xi'an, China",2020,9781450388559,,https://doi.org/10.1145/3446999.3447004;http://dx.doi.org/10.1145/3446999.3447004,10.1145/3446999.3447004,"Being executed in the Internet space, cloud services provide elastic computing resource to satisfy customers’ demand. Since single service usually can't suit their complex need, customers need to assemble multiple services into one service workflow which coordinates individual service to fulfill the specific task by means of service interaction. Obviously, the interaction mechanism of cloud service is the glue of workflow and plays an important role in service workflow. However, owing to the dynamic characteristic of the Internet, cloud service interaction is complicated and volatile. Hence, the question how to describe and formalize the complex interaction of cloud service workflow is a non-trivial work, which has directly influence on the overall design of cloud service architecture engineering and its performance.Consider the question above, this article put forward a session-based interaction model of cloud service. Regarding the complexity of service workflow, this paper applies the divide-and-conquer strategy to decompose the interaction of cloud services into session, then constructs the interaction model of cloud service. In the first step, we introduce and formalize the notion of session, so the complex interaction of cloud service workflow can be decomposed into hierarchical session pattern, which is easy to formalize by the guard automata. Next, using the session as the abstract data type, the session-based interaction model is proposed in order to facilitate the formalization of cloud service workflow. In addition, the model incorporates the notion of role and business protocol to strength the model flexibility. Like the role of object in object-oriented programming language, this model provides a new perspective for modelling the cloud service workflow and lay the solid foundation for its formal verification.","role, service workflow, cloud service, session, interface",ICIT 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Gestwicki P,A Case Study Approach for Teaching Design Patterns through Computer Game Programming: Tutorial Presentation,J. Comput. Sci. Coll.,2008,24,1,36–37,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,,2008-10,,1937-4771,,,"This workshop presents an approach for teaching design patterns through computer game programming. In the workshop, we will begin by discussing the fundamental aspects of game engine software, including rendering models, animation techniques, and collision processing. Then we will explore how design patterns can be applied to manage the complexity of game software development.This case study approach has been successfully used with undergraduate students ranging from sophomore to senior standing. Among these students, none had any formal introduction to game programming, and only one had prior exposure to design patterns. A study conducted eight months after the students completed the course found that, although none of the students were developing games, all of them were using design patterns. These results suggest that our approach positively impacts students' learning; unfortunately, our sample size was too small for statistic significance.The specific case study we will use is EEClone, a simple arcade-style computer game that was designed to demonstrate design patterns for object-oriented programming. The specific patterns reified in EEClone include the State, Facade, Observer, Strategy, Singleton, and Visitor patterns. It is important to note that the design patterns are not \forced\"" into this context: they emerge from a disciplined software design process. They complement the domain-specific concepts such as the main game loop",active rendering,sprite animation,collision processing,controller management,"and audio playback.The pedagogic motivation and results of this approach have recently been published in the Journal on Educational Resources in Computing [1]. This workshop provides an interactive forum for educators to learn about our approach and its application in the classroom.""",,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zhang Y,Salvaneschi G,Myers AC",Handling Bidirectional Control Flow,Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428207;http://dx.doi.org/10.1145/3428207,10.1145/3428207,"Pressed by the difficulty of writing asynchronous, event-driven code, mainstream languages have recently been building in support for a variety of advanced control-flow features. Meanwhile, experimental language designs have suggested effect handlers as a unifying solution to programmer-defined control effects, subsuming exceptions, generators, and async–await. However, despite these trends, complex control flow—in particular, control flow that exhibits a bidirectional pattern—remains challenging to manage. We introduce bidirectional algebraic effects, a new programming abstraction that supports bidirectional control transfer in a more natural way. Handlers of bidirectional effects can raise further effects to transfer control back to the site where the initiating effect was raised, and can use themselves to handle their own effects. We present applications of this expressive power, which falls out naturally as we push toward the unification of effectful programming with object-oriented programming. We pin down the mechanism and the unification formally using a core language that makes generalizations to effect operations and effect handlers. The usual propagation semantics of control effects such as exceptions conflicts with modular reasoning in the presence of effect polymorphism—it breaks parametricity. Bidirectionality exacerbates the problem. Hence, we set out to show the core language, which builds on the existing tunneling semantics for algebraic effects, is not only type-safe (no effects go unhandled), but also abstraction-safe (no effects are accidentally handled). We devise a step-indexed logical-relations model, and construct its parametricity and soundness proofs. These core results are fully mechanized in Coq. While a full-featured compiler is left to future work, experiments show that as a first-class language feature, bidirectional handlers can be implemented efficiently.","parametricity, promises, type systems, Effect handlers, exceptions, iterators",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kim C,Kim J,Kim S,Kim D,Kim N,Na G,Oh YH,Cho HG,Lee JW",Typed Architectures: Architectural Support for Lightweight Scripting,,2017,,,77–90,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems,"Xi'an, China",2017,9781450344654,,https://doi.org/10.1145/3037697.3037726;http://dx.doi.org/10.1145/3037697.3037726,10.1145/3037697.3037726,"Dynamic scripting languages are becoming more and more widely adopted not only for fast prototyping but also for developing production-grade applications. They provide high-productivity programming environments featuring high levels of abstraction with powerful built-in functions, automatic memory management, object-oriented programming paradigm and dynamic typing. However, their flexible, dynamic type systems easily become the source of inefficiency in terms of instruction count, memory footprint, and energy consumption. This overhead makes it challenging to deploy these high-productivity programming technologies on emerging single-board computers for IoT applications. Addressing this challenge, this paper introduces Typed Architectures, a high-efficiency, low-cost execution substrate for dynamic scripting languages, where each data variable retains high-level type information at an ISA level. Typed Architectures calculate and check the dynamic type of each variable implicitly in hardware, rather than explicitly in software, hence significantly reducing instruction count for dynamic type checking. Besides, Typed Architectures introduce polymorphic instructions (e.g., xadd), which are bound to the correct native instruction at runtime within the pipeline (e.g., add or fadd) to efficiently implement polymorphic operators. Finally, Typed Architectures provide hardware support for flexible yet efficient type tag extraction and insertion, capturing common data layout patterns of tag-value pairs. Our evaluation using a fully synthesizable RISC-V RTL design on FPGA shows that Typed Architectures achieve geomean speedups of 11.2% and 9.9% with maximum speedups of 32.6% and 43.5% for two production-grade scripting engines for JavaScript and Lua, respectively. Moreover, Typed Architectures improve the energy-delay product (EDP) by 19.3% for JavaScript and 16.5% for Lua with an area overhead of 1.6% at a 40nm technology node.","javascript, instruction set architecture, pipeline, performance, lua, scripting languages, internet of things (iot), microarchitecture, interpreters, type checking",ASPLOS '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kim C,Kim J,Kim S,Kim D,Kim N,Na G,Oh YH,Cho HG,Lee JW",Typed Architectures: Architectural Support for Lightweight Scripting,SIGPLAN Not.,2017,52,4,77–90,Association for Computing Machinery,"New York, NY, USA",,,,2017-04,,0362-1340,https://doi.org/10.1145/3093336.3037726;http://dx.doi.org/10.1145/3093336.3037726,10.1145/3093336.3037726,"Dynamic scripting languages are becoming more and more widely adopted not only for fast prototyping but also for developing production-grade applications. They provide high-productivity programming environments featuring high levels of abstraction with powerful built-in functions, automatic memory management, object-oriented programming paradigm and dynamic typing. However, their flexible, dynamic type systems easily become the source of inefficiency in terms of instruction count, memory footprint, and energy consumption. This overhead makes it challenging to deploy these high-productivity programming technologies on emerging single-board computers for IoT applications. Addressing this challenge, this paper introduces Typed Architectures, a high-efficiency, low-cost execution substrate for dynamic scripting languages, where each data variable retains high-level type information at an ISA level. Typed Architectures calculate and check the dynamic type of each variable implicitly in hardware, rather than explicitly in software, hence significantly reducing instruction count for dynamic type checking. Besides, Typed Architectures introduce polymorphic instructions (e.g., xadd), which are bound to the correct native instruction at runtime within the pipeline (e.g., add or fadd) to efficiently implement polymorphic operators. Finally, Typed Architectures provide hardware support for flexible yet efficient type tag extraction and insertion, capturing common data layout patterns of tag-value pairs. Our evaluation using a fully synthesizable RISC-V RTL design on FPGA shows that Typed Architectures achieve geomean speedups of 11.2% and 9.9% with maximum speedups of 32.6% and 43.5% for two production-grade scripting engines for JavaScript and Lua, respectively. Moreover, Typed Architectures improve the energy-delay product (EDP) by 19.3% for JavaScript and 16.5% for Lua with an area overhead of 1.6% at a 40nm technology node.","instruction set architecture, scripting languages, pipeline, type checking, performance, microarchitecture, interpreters, lua, internet of things (iot), javascript",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kim C,Kim J,Kim S,Kim D,Kim N,Na G,Oh YH,Cho HG,Lee JW",Typed Architectures: Architectural Support for Lightweight Scripting,SIGARCH Comput. Archit. News,2017,45,1,77–90,Association for Computing Machinery,"New York, NY, USA",,,,2017-04,,0163-5964,https://doi.org/10.1145/3093337.3037726;http://dx.doi.org/10.1145/3093337.3037726,10.1145/3093337.3037726,"Dynamic scripting languages are becoming more and more widely adopted not only for fast prototyping but also for developing production-grade applications. They provide high-productivity programming environments featuring high levels of abstraction with powerful built-in functions, automatic memory management, object-oriented programming paradigm and dynamic typing. However, their flexible, dynamic type systems easily become the source of inefficiency in terms of instruction count, memory footprint, and energy consumption. This overhead makes it challenging to deploy these high-productivity programming technologies on emerging single-board computers for IoT applications. Addressing this challenge, this paper introduces Typed Architectures, a high-efficiency, low-cost execution substrate for dynamic scripting languages, where each data variable retains high-level type information at an ISA level. Typed Architectures calculate and check the dynamic type of each variable implicitly in hardware, rather than explicitly in software, hence significantly reducing instruction count for dynamic type checking. Besides, Typed Architectures introduce polymorphic instructions (e.g., xadd), which are bound to the correct native instruction at runtime within the pipeline (e.g., add or fadd) to efficiently implement polymorphic operators. Finally, Typed Architectures provide hardware support for flexible yet efficient type tag extraction and insertion, capturing common data layout patterns of tag-value pairs. Our evaluation using a fully synthesizable RISC-V RTL design on FPGA shows that Typed Architectures achieve geomean speedups of 11.2% and 9.9% with maximum speedups of 32.6% and 43.5% for two production-grade scripting engines for JavaScript and Lua, respectively. Moreover, Typed Architectures improve the energy-delay product (EDP) by 19.3% for JavaScript and 16.5% for Lua with an area overhead of 1.6% at a 40nm technology node.","instruction set architecture, javascript, lua, pipeline, internet of things (iot), scripting languages, interpreters, microarchitecture, performance, type checking",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chandra S,Gordon CS,Jeannin JB,Schlesinger C,Sridharan M,Tip F,Choi Y",Type Inference for Static Compilation of JavaScript,,2016,,,410–429,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Amsterdam, Netherlands",2016,9781450344449,,https://doi.org/10.1145/2983990.2984017;http://dx.doi.org/10.1145/2983990.2984017,10.1145/2983990.2984017,"We present a type system and inference algorithm for a rich subset of JavaScript equipped with objects, structural subtyping, prototype inheritance, and first-class methods. The type system supports abstract and recursive objects, and is expressive enough to accommodate several standard benchmarks with only minor workarounds. The invariants enforced by the types enable an ahead-of-time compiler to carry out optimizations typically beyond the reach of static compilers for dynamic languages. Unlike previous inference techniques for prototype inheritance, our algorithm uses a combination of lower and upper bound propagation to infer types and discover type errors in all code, including uninvoked functions. The inference is expressed in a simple constraint language, designed to leverage off-the-shelf fixed point solvers. We prove soundness for both the type system and inference algorithm. An experimental evaluation showed that the inference is powerful, handling the aforementioned benchmarks with no manual type annotation, and that the inferred types enable effective static compilation.","object-oriented type systems, type inference, JavaScript",OOPSLA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chandra S,Gordon CS,Jeannin JB,Schlesinger C,Sridharan M,Tip F,Choi Y",Type Inference for Static Compilation of JavaScript,SIGPLAN Not.,2016,51,10,410–429,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,0362-1340,https://doi.org/10.1145/3022671.2984017;http://dx.doi.org/10.1145/3022671.2984017,10.1145/3022671.2984017,"We present a type system and inference algorithm for a rich subset of JavaScript equipped with objects, structural subtyping, prototype inheritance, and first-class methods. The type system supports abstract and recursive objects, and is expressive enough to accommodate several standard benchmarks with only minor workarounds. The invariants enforced by the types enable an ahead-of-time compiler to carry out optimizations typically beyond the reach of static compilers for dynamic languages. Unlike previous inference techniques for prototype inheritance, our algorithm uses a combination of lower and upper bound propagation to infer types and discover type errors in all code, including uninvoked functions. The inference is expressed in a simple constraint language, designed to leverage off-the-shelf fixed point solvers. We prove soundness for both the type system and inference algorithm. An experimental evaluation showed that the inference is powerful, handling the aforementioned benchmarks with no manual type annotation, and that the inferred types enable effective static compilation.","object-oriented type systems, type inference, JavaScript",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Giarrusso PG,Stefanesco L,Timany A,Birkedal L,Krebbers R",Scala Step-by-Step: Soundness for DOT with Step-Indexed Logical Relations in Iris,Proc. ACM Program. Lang.,2020,4,ICFP,,Association for Computing Machinery,"New York, NY, USA",,,,2020-08,,,https://doi.org/10.1145/3408996;http://dx.doi.org/10.1145/3408996,10.1145/3408996,"The metatheory of Scala’s core type system—the Dependent Object Types (DOT) calculus—is hard to extend, like the metatheory of other type systems combining subtyping and dependent types. Soundness of important Scala features therefore remains an open problem in theory and in practice. To address some of these problems, we use a semantics-first approach to develop a logical relations model for a new version of DOT, called guarded DOT (gDOT). Our logical relations model makes use of an abstract form of step-indexing, as supported by the Iris framework, to model various forms of recursion in gDOT. To demonstrate the expressiveness of gDOT, we show that it handles Scala examples that could not be handled by previous versions of DOT, and prove using our logical relations model that gDOT provides the desired data abstraction. The gDOT type system, its semantic model, its soundness proofs, and all examples in the paper have been mechanized in Coq.","type soundness, Iris, Coq, logical relations, Scala, step-indexing, data abstraction, DOT",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Bogdanov V,An Idea for a Type System of Multi-Paradigm Language with Extensible Syntax,,2012,,,141–147,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th International Conference on Computer Systems and Technologies,"Ruse, Bulgaria",2012,9781450311939,,https://doi.org/10.1145/2383276.2383298;http://dx.doi.org/10.1145/2383276.2383298,10.1145/2383276.2383298,"This article proposes a type system for a multi-paradigm language paradigm. A practical solution that provides the benefits of both static and dynamic typing is proposed, while using the features of the prototype - extensible declarative syntax. A checking algorithm is described that covers both explicit type hierarchy definitions and subtyping based on object's methods. Both compile time and runtime checking responsibilities are added to the type system allowing fluent integration between statically and dynamically checked code segments. Declarative definition of preconditions is provided.","type checks, strong typing, dynamic typing, subtyping, static typing, duck typing, type system, defensive programming, multi-paradigm programming language, subtype polymorphism",CompSysTech '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Nieto A,Towards Algorithmic Typing for DOT (Short Paper),,2017,,,2–7,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM SIGPLAN International Symposium on Scala,"Vancouver, BC, Canada",2017,9781450355292,,https://doi.org/10.1145/3136000.3136003;http://dx.doi.org/10.1145/3136000.3136003,10.1145/3136000.3136003,"The Dependent Object Types (DOT) calculus formalizes key features of Scala. The D<: calculus is the core of DOT. To date, presentations of D<: have used declarative, as opposed to algorithmic, typing and subtyping rules. Unfortunately, algorithmic typing for full D<: is known to be an undecidable problem. We explore the design space for a restricted version of D<: that has decidable typechecking. Even in this simplified D<:, algorithmic typing and subtyping are tricky, due to the \bad bounds\"" problem. The Scala compiler bypasses bad bounds at the cost of a loss in expressiveness in its type system. Based on the approach taken in the Scala compiler, we present the Step Typing and Step Subtyping relations for D<:. These relations are sound and decidable. They are not complete with respect to the original D<: typing rules.""",,"Scala, DOT calculus, algorithmic typing, dependent object types",SCALA 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Racordon D,Buchs D",Featherweight Swift: A Core Calculus for Swift’s Type System,,2020,,,140–154,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM SIGPLAN International Conference on Software Language Engineering,"Virtual, USA",2020,9781450381765,,https://doi.org/10.1145/3426425.3426939;http://dx.doi.org/10.1145/3426425.3426939,10.1145/3426425.3426939,"Swift is a modern general-purpose programming language, designed to be a replacement for C-based languages. Although primarily directed at development of applications for Apple's operating systems, Swift's adoption has been growing steadily in other domains, ranging from server-side services to machine learning. This success can be partly attributed to a rich type system that enables the design of safe, fast, and expressive programming interfaces. Unfortunately, this richness comes at the cost of complexity, setting a high entry barrier to exploit Swift's full potential. Furthermore, existing documentation typically only relies on examples, leaving new users with little help to build a deeper understanding of the underlying rules and mechanisms. This paper aims to tackle this issue by laying out the foundations for a formal framework to reason about Swift's type system. We introduce Featherweight Swift, a minimal language stripped of all features not essential to describe its typing rules. Featherweight Swift features classes and protocol inheritance, supports retroactive modeling, and emulates Swift's overriding mechanisms. Yet its formalization fits on a few pages. We present Featherweight Swift's syntax and semantics. We then elaborate on the usability of our framework to reason about Swift's features, future extensions, and implementation by discussing a bug in Swift's compiler, discovered throughout the design of our calculus.","language semantics, language calculus, type systems, swift, protocol oriented programming",SLE 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Amin N,Rompf T,Odersky M",Foundations of Path-Dependent Types,,2014,,,233–249,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2014 ACM International Conference on Object Oriented Programming Systems Languages & Applications,"Portland, Oregon, USA",2014,9781450325851,,https://doi.org/10.1145/2660193.2660216;http://dx.doi.org/10.1145/2660193.2660216,10.1145/2660193.2660216,"A scalable programming language is one in which the same concepts can describe small as well as large parts. Towards this goal, Scala unifies concepts from object and module systems. An essential ingredient of this unification is the concept of objects with type members, which can be referenced through path-dependent types. Unfortunately, path-dependent types are not well-understood, and have been a roadblock in grounding the Scala type system on firm theory.We study several calculi for path-dependent types. We present DOT which captures the essence - DOT stands for Dependent Object Types. We explore the design space bottom-up, teasing apart inherent from accidental complexities, while fully mechanizing our models at each step. Even in this simple setting, many interesting patterns arise from the interaction of structural and nominal features.Whereas our simple calculus enjoys many desirable and intuitive properties, we demonstrate that the theory gets much more complicated once we add another Scala feature, type refinement, or extend the subtyping relation to a lattice. We discuss possible remedies and trade-offs in modeling type systems for Scala-like languages.","objects, dependent types, calculus",OOPSLA '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Amin N,Rompf T,Odersky M",Foundations of Path-Dependent Types,SIGPLAN Not.,2014,49,10,233–249,Association for Computing Machinery,"New York, NY, USA",,,,2014-10,,0362-1340,https://doi.org/10.1145/2714064.2660216;http://dx.doi.org/10.1145/2714064.2660216,10.1145/2714064.2660216,"A scalable programming language is one in which the same concepts can describe small as well as large parts. Towards this goal, Scala unifies concepts from object and module systems. An essential ingredient of this unification is the concept of objects with type members, which can be referenced through path-dependent types. Unfortunately, path-dependent types are not well-understood, and have been a roadblock in grounding the Scala type system on firm theory.We study several calculi for path-dependent types. We present DOT which captures the essence - DOT stands for Dependent Object Types. We explore the design space bottom-up, teasing apart inherent from accidental complexities, while fully mechanizing our models at each step. Even in this simple setting, many interesting patterns arise from the interaction of structural and nominal features.Whereas our simple calculus enjoys many desirable and intuitive properties, we demonstrate that the theory gets much more complicated once we add another Scala feature, type refinement, or extend the subtyping relation to a lattice. We discuss possible remedies and trade-offs in modeling type systems for Scala-like languages.","dependent types, objects, calculus",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rastogi A,Swamy N,Fournet C,Bierman G,Vekris P",Safe & Efficient Gradual Typing for TypeScript,,2015,,,167–180,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Mumbai, India",2015,9781450333009,,https://doi.org/10.1145/2676726.2676971;http://dx.doi.org/10.1145/2676726.2676971,10.1145/2676726.2676971,"Current proposals for adding gradual typing to JavaScript, such as Closure, TypeScript and Dart, forgo soundness to deal with issues of scale, code reuse, and popular programming patterns. We show how to address these issues in practice while retaining soundness. We design and implement a new gradual type system, prototyped for expediency as a 'Safe' compilation mode for TypeScript. Our compiler achieves soundness by enforcing stricter static checks and embedding residual runtime checks in compiled code. It emits plain JavaScript that runs on stock virtual machines. Our main theorem is a simulation that ensures that the checks introduced by Safe TypeScript (1) catch any dynamic type error, and (2) do not alter the semantics of type-safe TypeScript code.Safe TypeScript is carefully designed to minimize the performance overhead of runtime checks. At its core, we rely on two new ideas: differential subtyping, a new form of coercive subtyping that computes the minimum amount of runtime type information that must be added to each object; and an erasure modality, which we use to safely and selectively erase type information. This allows us to scale our design to full-fledged TypeScript, including arrays, maps, classes, inheritance, overloading, and generic types.We validate the usability and performance of Safe TypeScript empirically by type-checking and compiling around 120,000 lines of existing TypeScript source code. Although runtime checks can be expensive, the end-to-end overhead is small for code bases that already have type annotations. For instance, we bootstrap the Safe TypeScript compiler (90,000 lines including the base TypeScript compiler): we measure a 15% runtime overhead for type safety, and also uncover programming errors as type safety violations. We conclude that, at least during development and testing, subjecting JavaScript/TypeScript programs to safe gradual typing adds significant value to source type annotations at a modest cost.","javascript, gradual typing, typescript, type safety",POPL '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rastogi A,Swamy N,Fournet C,Bierman G,Vekris P",Safe & Efficient Gradual Typing for TypeScript,SIGPLAN Not.,2015,50,1,167–180,Association for Computing Machinery,"New York, NY, USA",,,,2015-01,,0362-1340,https://doi.org/10.1145/2775051.2676971;http://dx.doi.org/10.1145/2775051.2676971,10.1145/2775051.2676971,"Current proposals for adding gradual typing to JavaScript, such as Closure, TypeScript and Dart, forgo soundness to deal with issues of scale, code reuse, and popular programming patterns. We show how to address these issues in practice while retaining soundness. We design and implement a new gradual type system, prototyped for expediency as a 'Safe' compilation mode for TypeScript. Our compiler achieves soundness by enforcing stricter static checks and embedding residual runtime checks in compiled code. It emits plain JavaScript that runs on stock virtual machines. Our main theorem is a simulation that ensures that the checks introduced by Safe TypeScript (1) catch any dynamic type error, and (2) do not alter the semantics of type-safe TypeScript code.Safe TypeScript is carefully designed to minimize the performance overhead of runtime checks. At its core, we rely on two new ideas: differential subtyping, a new form of coercive subtyping that computes the minimum amount of runtime type information that must be added to each object; and an erasure modality, which we use to safely and selectively erase type information. This allows us to scale our design to full-fledged TypeScript, including arrays, maps, classes, inheritance, overloading, and generic types.We validate the usability and performance of Safe TypeScript empirically by type-checking and compiling around 120,000 lines of existing TypeScript source code. Although runtime checks can be expensive, the end-to-end overhead is small for code bases that already have type annotations. For instance, we bootstrap the Safe TypeScript compiler (90,000 lines including the base TypeScript compiler): we measure a 15% runtime overhead for type safety, and also uncover programming errors as type safety violations. We conclude that, at least during development and testing, subjecting JavaScript/TypeScript programs to safe gradual typing adds significant value to source type annotations at a modest cost.","typescript, javascript, type safety, gradual typing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Amin N,Rompf T",Type Soundness Proofs with Definitional Interpreters,,2017,,,666–679,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 44th ACM SIGPLAN Symposium on Principles of Programming Languages,"Paris, France",2017,9781450346603,,https://doi.org/10.1145/3009837.3009866;http://dx.doi.org/10.1145/3009837.3009866,10.1145/3009837.3009866,"While type soundness proofs are taught in every graduate PL class, the gap between realistic languages and what is accessible to formal proofs is large. In the case of Scala, it has been shown that its formal model, the Dependent Object Types (DOT) calculus, cannot simultaneously support key metatheoretic properties such as environment narrowing and subtyping transitivity, which are usually required for a type soundness proof. Moreover, Scala and many other realistic languages lack a general substitution property. The first contribution of this paper is to demonstrate how type soundness proofs for advanced, polymorphic, type systems can be carried out with an operational semantics based on high-level, definitional interpreters, implemented in Coq. We present the first mechanized soundness proofs in this style for System F and several extensions, including mutable references. Our proofs use only straightforward induction, which is significant, as the combination of big-step semantics, mutable references, and polymorphism is commonly believed to require coinductive proof techniques. The second main contribution of this paper is to show how DOT-like calculi emerge from straightforward generalizations of the operational aspects of F, exposing a rich design space of calculi with path-dependent types inbetween System F and DOT, which we dub the System D Square. By working directly on the target language, definitional interpreters can focus the design space and expose the invariants that actually matter at runtime. Looking at such runtime invariants is an exciting new avenue for type system design.","type soundness, dependent object types, Scala, Definitional interpreters, DOT",POPL 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Amin N,Rompf T",Type Soundness Proofs with Definitional Interpreters,SIGPLAN Not.,2017,52,1,666–679,Association for Computing Machinery,"New York, NY, USA",,,,2017-01,,0362-1340,https://doi.org/10.1145/3093333.3009866;http://dx.doi.org/10.1145/3093333.3009866,10.1145/3093333.3009866,"While type soundness proofs are taught in every graduate PL class, the gap between realistic languages and what is accessible to formal proofs is large. In the case of Scala, it has been shown that its formal model, the Dependent Object Types (DOT) calculus, cannot simultaneously support key metatheoretic properties such as environment narrowing and subtyping transitivity, which are usually required for a type soundness proof. Moreover, Scala and many other realistic languages lack a general substitution property. The first contribution of this paper is to demonstrate how type soundness proofs for advanced, polymorphic, type systems can be carried out with an operational semantics based on high-level, definitional interpreters, implemented in Coq. We present the first mechanized soundness proofs in this style for System F and several extensions, including mutable references. Our proofs use only straightforward induction, which is significant, as the combination of big-step semantics, mutable references, and polymorphism is commonly believed to require coinductive proof techniques. The second main contribution of this paper is to show how DOT-like calculi emerge from straightforward generalizations of the operational aspects of F, exposing a rich design space of calculi with path-dependent types inbetween System F and DOT, which we dub the System D Square. By working directly on the target language, definitional interpreters can focus the design space and expose the invariants that actually matter at runtime. Looking at such runtime invariants is an exciting new avenue for type system design.","type soundness, dependent object types, DOT, Definitional interpreters, Scala",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Maidl AM,Mascarenhas F,Ierusalimschy R",A Formalization of Typed Lua,,2015,,,13–25,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th Symposium on Dynamic Languages,"Pittsburgh, PA, USA",2015,9781450336901,,https://doi.org/10.1145/2816707.2816709;http://dx.doi.org/10.1145/2816707.2816709,10.1145/2816707.2816709,"Programmers often migrate from a dynamically typed to a statically typed language when their simple scripts evolve into complex programs. Optional type systems are one way of having both static and dynamic typing in the same language, while keeping its dynamically typed semantics. This makes evolving a program from dynamic to static typing a matter of describing the implied types that it is using and adding annotations to make those types explicit. Designing an optional type system for an existing dynamically typed language is challenging, as its types should feel natural to programmers that are already familiar with this language. In this work, we give a formal description of Typed Lua, an optional type system for Lua, with a focus on two of its novel type system features: incremental evolution of imperative record and object types that is both lightweight and type-safe, and projection types, a combination of flow typing, functions that return multiple values, and multiple assignment. While our type system is tailored to the features and idioms of Lua, its features can be adapted to other imperative scripting languages.","Lua, Gradual Typing, Optional Type Systems",DLS 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Maidl AM,Mascarenhas F,Ierusalimschy R",A Formalization of Typed Lua,SIGPLAN Not.,2015,51,2,13–25,Association for Computing Machinery,"New York, NY, USA",,,,2015-10,,0362-1340,https://doi.org/10.1145/2936313.2816709;http://dx.doi.org/10.1145/2936313.2816709,10.1145/2936313.2816709,"Programmers often migrate from a dynamically typed to a statically typed language when their simple scripts evolve into complex programs. Optional type systems are one way of having both static and dynamic typing in the same language, while keeping its dynamically typed semantics. This makes evolving a program from dynamic to static typing a matter of describing the implied types that it is using and adding annotations to make those types explicit. Designing an optional type system for an existing dynamically typed language is challenging, as its types should feel natural to programmers that are already familiar with this language. In this work, we give a formal description of Typed Lua, an optional type system for Lua, with a focus on two of its novel type system features: incremental evolution of imperative record and object types that is both lightweight and type-safe, and projection types, a combination of flow typing, functions that return multiple values, and multiple assignment. While our type system is tailored to the features and idioms of Lua, its features can be adapted to other imperative scripting languages.","Gradual Typing, Lua, Optional Type Systems",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hirschfeld R,Igarashi A,Masuhara H",ContextFJ: A Minimal Core Calculus for Context-Oriented Programming,,2011,,,19–23,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Workshop on Foundations of Aspect-Oriented Languages,"Porto de Galinhas, Brazil",2011,9781450306447,,https://doi.org/10.1145/1960510.1960515;http://dx.doi.org/10.1145/1960510.1960515,10.1145/1960510.1960515,"We develop a minimal core calculus called ContextFJ to model language mechanisms for context-oriented programming (COP). Unlike other formal models of COP, ContextFJ has a direct operational semantics that can serve as a precise description of the core of COP languages. We also discuss a simple type system that helps to prevent undefined methods from being accessed via proceed.","context-oriented programming, operational semantics",FOAL '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kabir I,Li Y,Lhoták O",ιDOT: A DOT Calculus with Object Initialization,Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428276;http://dx.doi.org/10.1145/3428276,10.1145/3428276,"The Dependent Object Types (DOT) calculus serves as a foundation of the Scala programming language, with a machine-verified soundness proof. However, Scala's type system has been shown to be unsound due to null references, which are used as default values of fields of objects before they have been initialized. This paper proposes ιDOT, an extension of DOT for ensuring safe initialization of objects. DOT was previously extended to κDOT with the addition of mutable fields and constructors. To κDOT, ιDOT adds an initialization effect system that statically prevents the possibility of reading a null reference from an uninitialized object. To design ιDOT, we have reformulated the Freedom Before Commitment object initialization scheme in terms of disjoint subheaps to make it easier to formalize in an effect system and prove sound. Soundness of ιDOT depends on the interplay of three systems of rules: a type system close to that of DOT, an effect system to ensure definite assignment of fields in each constructor, and an initialization system that tracks the initialization status of objects in a stack of subheaps. We have proven the overall system sound and verified the soundness proof using the Coq proof assistant.","type safety, DOT, Scala, dependent objects, initialization",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Malayeri D,Aldrich J",CZ: Multiple Inheritance without Diamonds,,2009,,,21–40,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th ACM SIGPLAN Conference on Object Oriented Programming Systems Languages and Applications,"Orlando, Florida, USA",2009,9781605587660,,https://doi.org/10.1145/1640089.1640092;http://dx.doi.org/10.1145/1640089.1640092,10.1145/1640089.1640092,"Multiple inheritance has long been plagued with the \diamond\"" inheritance problem",leading to solutions that restrict expressiveness,such as mixins and traits. Instead,we address the diamond problem directly,considering two difficulties it causes: ensuring a correct semantics for object initializers,and typechecking multiple dispatch in a modular fashion-the latter problem arising even with multiple interface inheritance. We show that previous solutions to these problems are either unsatisfactory or cumbersome,"and suggest a novel approach: supporting multiple inheritance but forbidding diamond inheritance. Expressiveness is retained through two features: a \""requires\"" construct that provides a form of subtyping without inheritance (inspired by Scala)","and a dynamically-dispatched \""super\"" call similar to that found in traits. Through examples","we illustrate that inheritance diamonds can be eliminated via a combination of \""requires\"" and ordinary inheritance. We provide a sound formal model for our language and demonstrate its modularity and expressiveness.""","modularity, diamond problem, multiple inheritance, multimethods",OOPSLA '09,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Malayeri D,Aldrich J",CZ: Multiple Inheritance without Diamonds,SIGPLAN Not.,2009,44,10,21–40,Association for Computing Machinery,"New York, NY, USA",,,,2009-10,,0362-1340,https://doi.org/10.1145/1639949.1640092;http://dx.doi.org/10.1145/1639949.1640092,10.1145/1639949.1640092,"Multiple inheritance has long been plagued with the \diamond\"" inheritance problem",leading to solutions that restrict expressiveness,such as mixins and traits. Instead,we address the diamond problem directly,considering two difficulties it causes: ensuring a correct semantics for object initializers,and typechecking multiple dispatch in a modular fashion-the latter problem arising even with multiple interface inheritance. We show that previous solutions to these problems are either unsatisfactory or cumbersome,"and suggest a novel approach: supporting multiple inheritance but forbidding diamond inheritance. Expressiveness is retained through two features: a \""requires\"" construct that provides a form of subtyping without inheritance (inspired by Scala)","and a dynamically-dispatched \""super\"" call similar to that found in traits. Through examples","we illustrate that inheritance diamonds can be eliminated via a combination of \""requires\"" and ordinary inheritance. We provide a sound formal model for our language and demonstrate its modularity and expressiveness.""","multiple inheritance, diamond problem, multimethods, modularity",,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Huang W,Milanova A,Dietl W,Ernst MD",Reim & ReImInfer: Checking and Inference of Reference Immutability and Method Purity,,2012,,,879–896,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Tucson, Arizona, USA",2012,9781450315616,,https://doi.org/10.1145/2384616.2384680;http://dx.doi.org/10.1145/2384616.2384680,10.1145/2384616.2384680,"Reference immutability ensures that a reference is not used to modify the referenced object, and enables the safe sharing of object structures. A pure method does not cause side-effects on the objects that existed in the pre-state of the method execution. Checking and inference of reference immutability and method purity enables a variety of program analyses and optimizations. We present ReIm, a type system for reference immutability, and ReImInfer, a corresponding type inference analysis. The type system is concise and context-sensitive. The type inference analysis is precise and scalable, and requires no manual annotations. In addition, we present a novel application of the reference immutability type system: method purity inference.To support our theoretical results, we implemented the type system and the type inference analysis for Java. We include a type checker to verify the correctness of the inference result. Empirical results on Java applications and libraries of up to 348kLOC show that our approach achieves both scalability and precision.","reference immutability, method purity, type system, inference",OOPSLA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Huang W,Milanova A,Dietl W,Ernst MD",Reim & ReImInfer: Checking and Inference of Reference Immutability and Method Purity,SIGPLAN Not.,2012,47,10,879–896,Association for Computing Machinery,"New York, NY, USA",,,,2012-10,,0362-1340,https://doi.org/10.1145/2398857.2384680;http://dx.doi.org/10.1145/2398857.2384680,10.1145/2398857.2384680,"Reference immutability ensures that a reference is not used to modify the referenced object, and enables the safe sharing of object structures. A pure method does not cause side-effects on the objects that existed in the pre-state of the method execution. Checking and inference of reference immutability and method purity enables a variety of program analyses and optimizations. We present ReIm, a type system for reference immutability, and ReImInfer, a corresponding type inference analysis. The type system is concise and context-sensitive. The type inference analysis is precise and scalable, and requires no manual annotations. In addition, we present a novel application of the reference immutability type system: method purity inference.To support our theoretical results, we implemented the type system and the type inference analysis for Java. We include a type checker to verify the correctness of the inference result. Empirical results on Java applications and libraries of up to 348kLOC show that our approach achieves both scalability and precision.","reference immutability, type system, inference, method purity",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Matsakis ND,Gross TR",A Time-Aware Type System for Data-Race Protection and Guaranteed Initialization,,2010,,,634–651,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Reno/Tahoe, Nevada, USA",2010,9781450302036,,https://doi.org/10.1145/1869459.1869511;http://dx.doi.org/10.1145/1869459.1869511,10.1145/1869459.1869511,"We introduce a type system based on intervals, objects representing the time in which a block of code will execute. The type system can verify time-based properties such as when a field will be accessed or a method will be invoked.One concrete application of our type system is data-race protection: For fields which are initialized during one phase of the program and constant thereafter, users can designate the interval during which the field is mutable. Code which happens after this initialization interval can safely read the field in parallel. We also support fields guarded by a lock and even the use of dynamic race detectors.Another use for intervals is to designate different phases in the object's lifetime, such as a constructor phase. The type system then ensures that only appropriate methods are invoked in each phase.","intervals, type systems, data race, time-based properties",OOPSLA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Matsakis ND,Gross TR",A Time-Aware Type System for Data-Race Protection and Guaranteed Initialization,SIGPLAN Not.,2010,45,10,634–651,Association for Computing Machinery,"New York, NY, USA",,,,2010-10,,0362-1340,https://doi.org/10.1145/1932682.1869511;http://dx.doi.org/10.1145/1932682.1869511,10.1145/1932682.1869511,"We introduce a type system based on intervals, objects representing the time in which a block of code will execute. The type system can verify time-based properties such as when a field will be accessed or a method will be invoked.One concrete application of our type system is data-race protection: For fields which are initialized during one phase of the program and constant thereafter, users can designate the interval during which the field is mutable. Code which happens after this initialization interval can safely read the field in parallel. We also support fields guarded by a lock and even the use of dynamic race detectors.Another use for intervals is to designate different phases in the object's lifetime, such as a constructor phase. The type system then ensures that only appropriate methods are invoked in each phase.","time-based properties, type systems, data race, intervals",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Apel S,Kästner C,Lengauer C",Feature Featherweight Java: A Calculus for Feature-Oriented Programming and Stepwise Refinement,,2008,,,101–112,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Generative Programming and Component Engineering,"Nashville, TN, USA",2008,9781605582672,,https://doi.org/10.1145/1449913.1449931;http://dx.doi.org/10.1145/1449913.1449931,10.1145/1449913.1449931,"Feature-oriented programming (FOP) is a paradigm that incorporates programming language technology, program generation techniques, and stepwise refinement. In their GPCE'07 paper, Thaker et al. suggest the development of a type system for FOP to guarantee safe feature composition, i.e, to guarantee the absence of type errors during feature composition. We present such a type system along with a calculus for a simple feature-oriented, Java-like language, called Feature Featherweight Java (FFJ). Furthermore, we explore four extensions of FFJ and how they affect type soundness.","stepwise refinement, feature-oriented programming, type systems, safe feature composition, featherweight java",GPCE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rapoport M,Kabir I,He P,Lhoták O",A Simple Soundness Proof for Dependent Object Types,Proc. ACM Program. Lang.,2017,1,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,,https://doi.org/10.1145/3133870;http://dx.doi.org/10.1145/3133870,10.1145/3133870,"Dependent Object Types (DOT) is intended to be a core calculus for modelling Scala. Its distinguishing feature is abstract type members, fields in objects that hold types rather than values. Proving soundness of DOT has been surprisingly challenging, and existing proofs are complicated, and reason about multiple concepts at the same time (e.g. types, values, evaluation). To serve as a core calculus for Scala, DOT should be easy to experiment with and extend, and therefore its soundness proof needs to be easy to modify. This paper presents a simple and modular proof strategy for reasoning in DOT. The strategy separates reasoning about types from other concerns. It is centred around a theorem that connects the full DOT type system to a restricted variant in which the challenges and paradoxes caused by abstract type members are eliminated. Almost all reasoning in the proof is done in the intuitive world of this restricted type system. Once we have the necessary results about types, we observe that the other aspects of DOT are mostly standard and can be incorporated into a soundness proof using familiar techniques known from other calculi.","DOT calculus, type safety, Scala, dependent object types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cave A,Pientka B",Programming with Binders and Indexed Data-Types,,2012,,,413–424,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Philadelphia, PA, USA",2012,9781450310833,,https://doi.org/10.1145/2103656.2103705;http://dx.doi.org/10.1145/2103656.2103705,10.1145/2103656.2103705,"We show how to combine a general purpose type system for an existing language with support for programming with binders and contexts by refining the type system of ML with a restricted form of dependent types where index objects are drawn from contextual LF. This allows the user to specify formal systems within the logical framework LF and index ML types with contextual LF objects. Our language design keeps the index language generic only requiring decidability of equality of the index language providing a modular design. To illustrate the elegance and effectiveness of our language, we give programs for closure conversion and normalization by evaluation.Our three key technical contribution are: 1) We give a bi-directional type system for our core language which is centered around refinement substitutions instead of constraint solving. As a consequence, type checking is decidable and easy to trust, although constraint solving may be undecidable. 2) We give a big-step environment based operational semantics with environments which lends itself to efficient implementation. 3) We prove our language to be type safe and have mechanized our theoretical development in the proof assistant Coq using the fresh approach to binding.","higher-order abstract syntax, logical frameworks, recursive types, dependent types",POPL '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Cave A,Pientka B",Programming with Binders and Indexed Data-Types,SIGPLAN Not.,2012,47,1,413–424,Association for Computing Machinery,"New York, NY, USA",,,,2012-01,,0362-1340,https://doi.org/10.1145/2103621.2103705;http://dx.doi.org/10.1145/2103621.2103705,10.1145/2103621.2103705,"We show how to combine a general purpose type system for an existing language with support for programming with binders and contexts by refining the type system of ML with a restricted form of dependent types where index objects are drawn from contextual LF. This allows the user to specify formal systems within the logical framework LF and index ML types with contextual LF objects. Our language design keeps the index language generic only requiring decidability of equality of the index language providing a modular design. To illustrate the elegance and effectiveness of our language, we give programs for closure conversion and normalization by evaluation.Our three key technical contribution are: 1) We give a bi-directional type system for our core language which is centered around refinement substitutions instead of constraint solving. As a consequence, type checking is decidable and easy to trust, although constraint solving may be undecidable. 2) We give a big-step environment based operational semantics with environments which lends itself to efficient implementation. 3) We prove our language to be type safe and have mechanized our theoretical development in the proof assistant Coq using the fresh approach to binding.","recursive types, higher-order abstract syntax, logical frameworks, dependent types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Bach Poulsen C,Rouvoet A,Tolmach A,Krebbers R,Visser E",Intrinsically-Typed Definitional Interpreters for Imperative Languages,Proc. ACM Program. Lang.,2017,2,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2017-12,,,https://doi.org/10.1145/3158104;http://dx.doi.org/10.1145/3158104,10.1145/3158104,"A definitional interpreter defines the semantics of an object language in terms of the (well-known) semantics of a host language, enabling understanding and validation of the semantics through execution. Combining a definitional interpreter with a separate type system requires a separate type safety proof. An alternative approach, at least for pure object languages, is to use a dependently-typed language to encode the object language type system in the definition of the abstract syntax. Using such intrinsically-typed abstract syntax definitions allows the host language type checker to verify automatically that the interpreter satisfies type safety. Does this approach scale to larger and more realistic object languages, and in particular to languages with mutable state and objects? In this paper, we describe and demonstrate techniques and libraries in Agda that successfully scale up intrinsically-typed definitional interpreters to handle rich object languages with non-trivial binding structures and mutable state. While the resulting interpreters are certainly more complex than the simply-typed λ-calculus interpreter we start with, we claim that they still meet the goals of being concise, comprehensible, and executable, while guaranteeing type safety for more elaborate object languages. We make the following contributions: (1) A dependent-passing style technique for hiding the weakening of indexed values as they propagate through monadic code. (2) An Agda library for programming with scope graphs and frames, which provides a uniform approach to dealing with name binding in intrinsically-typed interpreters. (3) Case studies of intrinsically-typed definitional interpreters for the simply-typed λ-calculus with references (STLC+Ref) and for a large subset of Middleweight Java (MJ).","dependent types, mechanized semantics, Java, definitional interpreters, type safety, scope graphs, Agda",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Na H,Ryu S,Choe K",Exact Type Parameterization and ThisType Support,,2012,,,13–24,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM SIGPLAN Workshop on Types in Language Design and Implementation,"Philadelphia, Pennsylvania, USA",2012,9781450311205,,https://doi.org/10.1145/2103786.2103790;http://dx.doi.org/10.1145/2103786.2103790,10.1145/2103786.2103790,"We propose language support for binary methods and generic factory methods using ThisType. We present three new language features: (1) exact type capture which relaxes the restriction of earlier static approaches to binary methods that the run-time type of a binary method's receiver should be statically fixed, (2) named wildcards which allow more binary method invocations and more precise typing results, and (3) virtual constructors which support method definitions with return types of ThisType. We formalize these features with a core calculus CoreThisJava and prove its type soundness, exact type match and algorithmic subtyping.A modified notion of ThisType and exact type parameterization with bidirectional F-bound property form the basis of the above features. We also show that \inheritance makes subtypes\"" with our notion of ThisType and existential types as object types.""","generic factory methods, exact types, exact type capture, binary methods, virtual constructors, object-oriented languages, thistype, named wildcards",TLDI '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Osvald L,Rompf T",Rust-like Borrowing with 2nd-Class Values (Short Paper),,2017,,,13–17,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM SIGPLAN International Symposium on Scala,"Vancouver, BC, Canada",2017,9781450355292,,https://doi.org/10.1145/3136000.3136010;http://dx.doi.org/10.1145/3136000.3136010,10.1145/3136000.3136010,"The Rust programming language demonstrates that memory safety can be achieved in a practical systems language, based on a sophisticated type system that controls object lifetimes and aliasing through notions of ownership and borrowing. While Scala has traditionally targeted only managed language runtimes, the ScalaNative effort makes Scala a viable low-level language as well. Thus, memory safety becomes an important concern, and the question bears asking what, if anything, Scala can learn from Rust. In addition, Rust's type system can encode forms of protocols, state machines, and session types, which would also be useful for Scala in general. A key challenge is that Rust's typing rules are inherently flow-sensitive, but Scala's type system is not. In this paper, we sketch one possible method of achieving static guarantees similar to Rust with only mild extensions to Scala's type system. Our solution is based on two components: First, the observation that continuation passing style (CPS) or monadic style can transform a flow-sensitive checking problem into a type-checking problem based on scopes. Second, on a previously presented type system extension with second-class values, which we use to model scope-based lifetimes.","safety, Scala, memory model, borrowing, second-class, programming model, Rust",SCALA 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Liquori L,Spiwack A",FeatherTrait: A Modest Extension of Featherweight Java,ACM Trans. Program. Lang. Syst.,2008,30,2,,Association for Computing Machinery,"New York, NY, USA",,,,2008-03,,0164-0925,https://doi.org/10.1145/1330017.1330022;http://dx.doi.org/10.1145/1330017.1330022,10.1145/1330017.1330022,"In the context of statically typed, class-based languages, we investigate classes that can be extended with trait composition. A trait is a collection of methods without state; it can be viewed as an incomplete stateless class. Traits can be composed in any order, but only make sense when imported by a class that provides state variables and additional methods to disambiguate conflicting names arising between the imported traits. We introduce FeatherTrait Java (FTJ), a conservative extension of the simple lightweight class-based calculus Featherweight Java (FJ) with statically typed traits. In FTJ, classes can be built using traits as basic behavioral bricks; method conflicts between imported traits must be resolved explicitly by the user either by (i) aliasing or excluding method names in traits, or by (ii) overriding explicitly the conflicting methods in the class or in the trait itself. We present an operational semantics with a lookup algorithm, and a sound type system that guarantees that evaluating a well-typed expression never yields a message-not-understood run-time error nor gets the interpreter stuck. We give examples of the increased expressive power of the trait-based inheritance model. The resulting calculus appears to be a good starting point for a rigorous mathematical analysis of typed class-based languages featuring trait-based inheritance.","language design, inheritance, Java, language semantics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gordon CS,Parkinson MJ,Parsons J,Bromfield A,Duffy J",Uniqueness and Reference Immutability for Safe Parallelism,,2012,,,21–40,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Tucson, Arizona, USA",2012,9781450315616,,https://doi.org/10.1145/2384616.2384619;http://dx.doi.org/10.1145/2384616.2384619,10.1145/2384616.2384619,"A key challenge for concurrent programming is that side-effects (memory operations) in one thread can affect the behavior of another thread. In this paper, we present a type system to restrict the updates to memory to prevent these unintended side-effects. We provide a novel combination of immutable and unique (isolated) types that ensures safe parallelism (race freedom and deterministic execution). The type system includes support for polymorphism over type qualifiers, and can easily create cycles of immutable objects. Key to the system's flexibility is the ability to recover immutable or externally unique references after violating uniqueness without any explicit alias tracking. Our type system models a prototype extension to C# that is in active use by a Microsoft team. We describe their experiences building large systems with this extension. We prove the soundness of the type system by an embedding into a program logic.","concurrency, reference immutability, type systems, views",OOPSLA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gordon CS,Parkinson MJ,Parsons J,Bromfield A,Duffy J",Uniqueness and Reference Immutability for Safe Parallelism,SIGPLAN Not.,2012,47,10,21–40,Association for Computing Machinery,"New York, NY, USA",,,,2012-10,,0362-1340,https://doi.org/10.1145/2398857.2384619;http://dx.doi.org/10.1145/2398857.2384619,10.1145/2398857.2384619,"A key challenge for concurrent programming is that side-effects (memory operations) in one thread can affect the behavior of another thread. In this paper, we present a type system to restrict the updates to memory to prevent these unintended side-effects. We provide a novel combination of immutable and unique (isolated) types that ensures safe parallelism (race freedom and deterministic execution). The type system includes support for polymorphism over type qualifiers, and can easily create cycles of immutable objects. Key to the system's flexibility is the ability to recover immutable or externally unique references after violating uniqueness without any explicit alias tracking. Our type system models a prototype extension to C# that is in active use by a Microsoft team. We describe their experiences building large systems with this extension. We prove the soundness of the type system by an embedding into a program logic.","reference immutability, views, concurrency, type systems",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bettini L,Damiani F,Schaefer I",Implementing Software Product Lines Using Traits,,2010,,,2096–2102,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Symposium on Applied Computing,"Sierre, Switzerland",2010,9781605586397,,https://doi.org/10.1145/1774088.1774530;http://dx.doi.org/10.1145/1774088.1774530,10.1145/1774088.1774530,"A software product line (SPL) is a set of software systems with well-defined commonalities and variabilities that are developed by managed reuse of common artifacts. In this paper, we present a novel approach to implement SPL by fine-grained reuse mechanisms which are orthogonal to class-based inheritance. We introduce the Featherweight Record-Trait Java (FRTJ) calculus where units of product functionality are modeled by traits, a construct that was already shown useful with respect to code reuse, and by records, a construct that complements traits to model the variability of the state part of products explicitly. Records and traits are assembled in classes that are used to build products. This composition of product functionalities is realized by explicit operators of the calculus, allowing code manipulations for modeling product variability. The FRTJ type system ensures that the products in the SPL are type-safe by type-checking only once the records, traits and classes shared by different products. Moreover, type-safety of an extension of a (type-safe) SPL can be guaranteed by checking only the newly added parts.","type system, software product line, trait, featherweight java, feature model",SAC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zhao T,Polymorphic Type Inference for Scripting Languages with Object Extensions,,2011,,,37–50,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th Symposium on Dynamic Languages,"Portland, Oregon, USA",2011,9781450309394,,https://doi.org/10.1145/2047849.2047855;http://dx.doi.org/10.1145/2047849.2047855,10.1145/2047849.2047855,This paper presents a polymorphic type inference algorithm for a small subset of JavaScript. The goal is to prevent accessing undefined members of objects. We define a type system that allows explicit extension of objects through add operation and implicit extension through method calls. The type system also permits strong updates and unrestricted extensions to new objects. The type inference algorithm is modular so that each function definition is only analyzed once and larger programs can be checked incrementally.,"type inference, javascript, dynamic languages, static types",DLS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Zhao T,Polymorphic Type Inference for Scripting Languages with Object Extensions,SIGPLAN Not.,2011,47,2,37–50,Association for Computing Machinery,"New York, NY, USA",,,,2011-10,,0362-1340,https://doi.org/10.1145/2168696.2047855;http://dx.doi.org/10.1145/2168696.2047855,10.1145/2168696.2047855,This paper presents a polymorphic type inference algorithm for a small subset of JavaScript. The goal is to prevent accessing undefined members of objects. We define a type system that allows explicit extension of objects through add operation and implicit extension through method calls. The type system also permits strong updates and unrestricted extensions to new objects. The type inference algorithm is modular so that each function definition is only analyzed once and larger programs can be checked incrementally.,"dynamic languages, javascript, static types, type inference",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Dietl W,Drossopoulou S,Müller P",Separating Ownership Topology and Encapsulation with Generic Universe Types,ACM Trans. Program. Lang. Syst.,2012,33,6,,Association for Computing Machinery,"New York, NY, USA",,,,2012-01,,0164-0925,https://doi.org/10.1145/2049706.2049709;http://dx.doi.org/10.1145/2049706.2049709,10.1145/2049706.2049709,"Ownership is a powerful concept to structure the object store and to control aliasing and modifications of objects. This article presents an ownership type system for a Java-like programming language with generic types.Like our earlier Universe type system, Generic Universe Types structure the heap hierarchically. In contrast to earlier work, we separate the enforcement of an ownership topology from an encapsulation system. The topological system uses an existential modifier to express that no ownership information is available statically. On top of the topological system, we build an encapsulation system that enforces the owner-as-modifier discipline. This discipline does not restrict aliasing, but requires modifications of an object to be initiated by its owner. This allows owner objects to control state changes of owned objects—for instance, to maintain invariants. Separating the topological system from the encapsulation system allows for a cleaner formalization, separation of concerns, and simpler reuse of the individual systems in different contexts.","ownership types, owner-as-modifier, generic, Encapsulation, universe types, topology",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sunshine J,Aldrich J",Usability Hypotheses in the Design of Plaid,,2014,,,63–66,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th Workshop on Evaluation and Usability of Programming Languages and Tools,"Portland, Oregon, USA",2014,9781450322775,,https://doi.org/10.1145/2688204.2688219;http://dx.doi.org/10.1145/2688204.2688219,10.1145/2688204.2688219,"Plaid is a research programming language with a focus on typestate, permissions, and concurrency. Typestate describes ordering constraints on method calls to an object; Plaid incorporates typestate into both its object model and its type system. Permissions, incorporated into Plaid's type system and runtime, describe whether a reference can be aliased and whether aliases can change that reference. Permissions support static typestate checking, but they also allow Plaid's compiler to automatically parallelize Plaid code.In this paper, we describe the usability-related hypotheses that drove the design of Plaid. We describe the evidence, both informal and scientific, that inspired and (in some cases) validated these hypotheses, and reflect on our experience designing and validating the language.","programmability, permissions, typestate",PLATEAU '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Militão F,Aldrich J,Caires L",Substructural Typestates,,2014,,,15–26,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM SIGPLAN 2014 Workshop on Programming Languages Meets Program Verification,"San Diego, California, USA",2014,9781450325677,,https://doi.org/10.1145/2541568.2541574;http://dx.doi.org/10.1145/2541568.2541574,10.1145/2541568.2541574,"Finding simple, yet expressive, verification techniques to reason about both aliasing and mutable state has been a major challenge for static program verification. One such approach, of practical relevance, is centered around a lightweight typing discipline where types denote abstract object states, known as typestates.In this paper, we show how key typestate concepts can be precisely captured by a substructural type-and-effect system, exploiting ideas from linear and separation logic. Building on this foundation, we show how a small set of primitive concepts can be composed to express high-level idioms such as objects with multiple independent state dimensions, dynamic state tests, and behavior-oriented usage protocols that enforce strong information hiding. By exploring the relationship between two mainstream modularity concepts, state abstraction and hiding, we also provide new insights on how they naturally fit together and complement one another.Technically, our results are based on a typed lambda calculus with mutable references, location-dependent types, and second-order polymorphism. The soundness of our type system is shown through progress and preservation theorems. We also describe a prototype implementation of a type checker for our system, which is available on the web and can be used to experiment with the examples in the paper.","linearity, capabilities, typestate, aliasing",PLPV '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hong J,Park J,Ryu S",Path Dependent Types with Path-Equality,,2018,,,35–39,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM SIGPLAN International Symposium on Scala,"St. Louis, MO, USA",2018,9781450358361,,https://doi.org/10.1145/3241653.3241657;http://dx.doi.org/10.1145/3241653.3241657,10.1145/3241653.3241657,"While the Scala type system provides expressive features like objects with type members, the lack of equality checking between path-dependent types prohibits some programming idioms. One such an example is abstract domain combinators in implementing static analyzers. In this paper, we propose to extend the Scala type system with path-equality, and formalize it as a DOT variant, π DOT, which supports records with type members and elds. We show that π DOT has the normalization property and prove its type soundness.","path equality, Scala, DOT",Scala 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Q,Schewe KD",A Typed Higher-Order Calculus for Querying XML Databases,,2008,,,115–125,"Australian Computer Society, Inc.",AUS,,Proceedings of the Nineteenth Conference on Australasian Database - Volume 75,"Gold Coast, Australia",2008,9781920682569,,,,"As the eXtensible Markup Language (XML) is about to emerge as a new standard for databases, the problem of providing solid logical grounds for XML query languages arises. For the relational data model first-order logic, i.e. the Relational Calculus turned out to be an intuitive basic approach to provide these foundations. For XML, however, it is necessary to deal with ordered trees. In this paper the problem is approached by viewing XML as a data model based on complex objects that are arranged in a class hierarchy. This results in the natural development of a higher-order type system for XML data, and henceforth a higher-order predicate typed logic, the XML calculus (XMLC). The paper presents the basics of the XML object model (XOM), the syntacs and semantics of XMLC, and discusses the expressiveness of the language by means of representative important query samples.","higher-order logic, eXten-sible markup language, query language, object model, type system",ADC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Aldrich J,Garcia R,Hahnenberg M,Mohr M,Naden K,Saini D,Stork S,Sunshine J,Tanter É,Wolff R",Permission-Based Programming Languages (NIER Track),,2011,,,828–831,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd International Conference on Software Engineering,"Waikiki, Honolulu, HI, USA",2011,9781450304450,,https://doi.org/10.1145/1985793.1985915;http://dx.doi.org/10.1145/1985793.1985915,10.1145/1985793.1985915,"Linear permissions have been proposed as a lightweight way to specify how an object may be aliased, and whether those aliases allow mutation. Prior work has demonstrated the value of permissions for addressing many software engineering concerns, including information hiding, protocol checking, concurrency, security, and memory management.We propose the concept of a permission-based programming language - a language whose object model, type system, and runtime are all co-designed with permissions in mind. This approach supports an object model in which the structure of an object can change over time, a type system that tracks changing structure in addition to addressing the other concerns above, and a runtime system that can dynamically check permission assertions and leverage permissions to parallelize code. We sketch the design of the permission-based programming language Plaid, and argue that the approach may provide significant software engineering benefits.","programming languages, permissions, types",ICSE '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chandra S,Saraswat V,Sarkar V,Bodik R",Type Inference for Locality Analysis of Distributed Data Structures,,2008,,,11–22,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming,"Salt Lake City, UT, USA",2008,9781595937957,,https://doi.org/10.1145/1345206.1345211;http://dx.doi.org/10.1145/1345206.1345211,10.1145/1345206.1345211,"In languages with distributed heap data structures, the type system typically conveys only coarse locality information: whether a reference is local or possibly remote. Often, of interest to the optimizing compiler or the user is a more fine-grain information, such as whether two remote references point to objects in the same partition of the distributed heap.This paper proposes a dependent type system, called place types, to capture such fine-grain locality information. The type of each reference identifies the heap partition, called a place, that the reference points to. This type system is expressive enough to statically type several commonly used distributed data structures. It also accommodates a \dynamic\"" type when no suitable static type exists. We show how to embed this type system as type annotations in the X10 programming language.We also present a type inference algorithm for saving programmers from the burden of inserting type annotations. The type inference has been inspired by the use of type inference in functional programming languages such as ML. We have implemented the type inference algorithm in the X10 compiler. Experiments with small programs",but with the full set the relevant language features,"have been successful in automatically finding the expected place types in these programs.""","unification, type inference, partitioned global address space, equality-based constraint system, x10",PPoPP '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Apel S,Hutchins D",A Calculus for Uniform Feature Composition,ACM Trans. Program. Lang. Syst.,2008,32,5,,Association for Computing Machinery,"New York, NY, USA",,,,2008-05,,0164-0925,https://doi.org/10.1145/1745312.1745316;http://dx.doi.org/10.1145/1745312.1745316,10.1145/1745312.1745316,"The goal of feature-oriented programming (FOP) is to modularize software systems in terms of features. A feature refines the content of a base program. Both base programs and features may contain various kinds of software artifacts, for example, source code in different languages, models, build scripts, and documentation. We and others have noticed that when composing features, different kinds of software artifacts can be refined in a uniform way, regardless of what they represent. We present gDeep, a core calculus for feature composition, which captures the language independence of FOP; it can be used to compose features containing many different kinds of artifact in a type-safe way. The calculus allows us to gain insight into the principles of FOP and to define general algorithms for feature composition and validation. We provide the formal syntax, operational semantics, and type system of gDeep and outline how languages like Java, Haskell, Bali, and XML can be plugged in.","Feature-oriented programming, type systems, principle of uniformity, feature composition",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Qi X,Myers AC",Masked Types for Sound Object Initialization,,2009,,,53–65,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Savannah, GA, USA",2009,9781605583792,,https://doi.org/10.1145/1480881.1480890;http://dx.doi.org/10.1145/1480881.1480890,10.1145/1480881.1480890,"This paper presents a type-based solution to the long-standing problem of object initialization. Constructors, the conventional mechanism for object initialization, have semantics that are surprising to programmers and that lead to bugs. They also contribute to the problem of null-pointer exceptions, which make software less reliable. Masked types are a new type-state mechanism that explicitly tracks the initialization state of objects and prevents reading from uninitialized fields. In the resulting language, constructors are ordinary methods that operate on uninitialized objects, and no special default value (null) is needed in the language. Initialization of cyclic data structures is achieved with the use of conditionally masked types. Masked types are modular and compatible with data abstraction. The type system is presented in a simplified object calculus and is proved to soundly prevent reading from uninitialized fields. Masked types have been implemented as an extension to Java, in which compilation simply erases extra type information. Experience using the extended language suggests that masked types work well on real code.","data abstraction, invariants, null pointer exceptions, cyclic data structures, conditional masks",POPL '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Qi X,Myers AC",Masked Types for Sound Object Initialization,SIGPLAN Not.,2009,44,1,53–65,Association for Computing Machinery,"New York, NY, USA",,,,2009-01,,0362-1340,https://doi.org/10.1145/1594834.1480890;http://dx.doi.org/10.1145/1594834.1480890,10.1145/1594834.1480890,"This paper presents a type-based solution to the long-standing problem of object initialization. Constructors, the conventional mechanism for object initialization, have semantics that are surprising to programmers and that lead to bugs. They also contribute to the problem of null-pointer exceptions, which make software less reliable. Masked types are a new type-state mechanism that explicitly tracks the initialization state of objects and prevents reading from uninitialized fields. In the resulting language, constructors are ordinary methods that operate on uninitialized objects, and no special default value (null) is needed in the language. Initialization of cyclic data structures is achieved with the use of conditionally masked types. Masked types are modular and compatible with data abstraction. The type system is presented in a simplified object calculus and is proved to soundly prevent reading from uninitialized fields. Masked types have been implemented as an extension to Java, in which compilation simply erases extra type information. Experience using the extended language suggests that masked types work well on real code.","cyclic data structures, conditional masks, data abstraction, null pointer exceptions, invariants",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Giannini P,Servetto M,Zucca E",Tracing Sharing in an Imperative Pure Calculus: Extended Abstract,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th Workshop on Formal Techniques for Java-like Programs,"Barcelona, Spain",2017,9781450350983,,https://doi.org/10.1145/3103111.3104038;http://dx.doi.org/10.1145/3103111.3104038,10.1145/3103111.3104038,"We introduce a type and effect system, for an imperative object calculus, which infers sharing possibly introduced by the evaluation of an expression. Sharing is directly represented at the syntactic level as a relation among free variables, thanks to the fact that the calculus is pure. That is, imperative features are modeled by just rewriting source code terms. We consider both standard variables and affine variables, which can occur at most once in their scope. The latter are used as temporary references, to \move\"" a capsule (an isolated portion of store) to another location in the store. The sharing effects inferred by the type system are very expressive","and generalize notions introduced in literature by type modifiers.""","type and effect systems, calculi, sharing",FTFJP'17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Vaughan JA,AuraConf: A Unified Approach to Authorization and Confidentiality,,2011,,,45–58,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th ACM SIGPLAN Workshop on Types in Language Design and Implementation,"Austin, Texas, USA",2011,9781450304849,,https://doi.org/10.1145/1929553.1929563;http://dx.doi.org/10.1145/1929553.1929563,10.1145/1929553.1929563,"This paper introduces AuraConf, the first programming language with a unified means to specify access-control and confidentially policies. In concert with a proof-carrying access control mechanism, to known-techniques for describing access-control, AuraConf allows confidentially policies to be specified declaratively using types and enforced via cryptography. Programs written in AuraConf enjoy a formal security guarantee via noninterference. Additionally, the language definition introduces a novel type system where the typechecker may use resources (i.e., private keys) and knowledge of an object's provenance (i.e., how a ciphertext was computed) to guide analysis.","dependent types, information flow, cryptography",TLDI '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Summers AJ,Mueller P",Freedom before Commitment: A Lightweight Type System for Object Initialisation,,2011,,,1013–1032,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Portland, Oregon, USA",2011,9781450309400,,https://doi.org/10.1145/2048066.2048142;http://dx.doi.org/10.1145/2048066.2048142,10.1145/2048066.2048142,"One of the main purposes of object initialisation is to establish invariants such as a field being non-null or an immutable data structure containing specific values. These invariants are then implicitly assumed by the rest of the implementation, for instance, to ensure that a field may be safely dereferenced or that immutable data may be accessed concurrently. Consequently, letting an object escape from its constructor is dangerous; the escaping object might not yet satisfy its invariants, leading to errors in code that relies on them. Nevertheless, preventing objects entirely from escaping from their constructors is too restrictive; it is often useful to call auxiliary methods on the object under initialisation or to pass it to another constructor to set up mutually-recursive structures.We present a type system that tracks which objects are fully initialised and which are still under initialisation. The system can be used to prevent objects from escaping, but also to allow safe escaping by making explicit which objects might not yet satisfy their invariants. We designed, formalised and implemented our system as an extension to a non-null type system, but it is not limited to this application. Our system is conceptually simple and requires little annotation overhead; it is sound and sufficiently expressive for many common programming idioms. Therefore, we believe it to be the first such system suitable for mainstream use.","simple, modular, sound, expressive, non-null, type-system, initialisation",OOPSLA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Summers AJ,Mueller P",Freedom before Commitment: A Lightweight Type System for Object Initialisation,SIGPLAN Not.,2011,46,10,1013–1032,Association for Computing Machinery,"New York, NY, USA",,,,2011-10,,0362-1340,https://doi.org/10.1145/2076021.2048142;http://dx.doi.org/10.1145/2076021.2048142,10.1145/2076021.2048142,"One of the main purposes of object initialisation is to establish invariants such as a field being non-null or an immutable data structure containing specific values. These invariants are then implicitly assumed by the rest of the implementation, for instance, to ensure that a field may be safely dereferenced or that immutable data may be accessed concurrently. Consequently, letting an object escape from its constructor is dangerous; the escaping object might not yet satisfy its invariants, leading to errors in code that relies on them. Nevertheless, preventing objects entirely from escaping from their constructors is too restrictive; it is often useful to call auxiliary methods on the object under initialisation or to pass it to another constructor to set up mutually-recursive structures.We present a type system that tracks which objects are fully initialised and which are still under initialisation. The system can be used to prevent objects from escaping, but also to allow safe escaping by making explicit which objects might not yet satisfy their invariants. We designed, formalised and implemented our system as an extension to a non-null type system, but it is not limited to this application. Our system is conceptually simple and requires little annotation overhead; it is sound and sufficiently expressive for many common programming idioms. Therefore, we believe it to be the first such system suitable for mainstream use.","modular, type-system, initialisation, expressive, sound, non-null, simple",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen S,Erwig M",Early Detection of Type Errors in C++ Templates,,2014,,,133–144,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM SIGPLAN 2014 Workshop on Partial Evaluation and Program Manipulation,"San Diego, California, USA",2014,9781450326193,,https://doi.org/10.1145/2543728.2543731;http://dx.doi.org/10.1145/2543728.2543731,10.1145/2543728.2543731,"Current C++ implementations typecheck templates in two phases: Before instantiation, those parts of the template are checked that do not depend on template parameters, while the checking of the remaining parts is delayed until template instantiation time when the template arguments become available. This approach is problematic because it causes two major usability problems. First, it prevents library developers to provide guarantees about the type correctness for modules involving templates. Second, it can lead, through the incorrect use of template functions, to inscrutable error messages. Moreover, errors are often reported far away from the source of the program fault.To address this problem, we have developed a type system for Garcia's type-reflective calculus that allows a more precise characterization of types and thus a better utilization of type information within template definitions. This type system allows the static detection of many type errors that could previously only be detected after template instantiation. The additional precision and earlier detection time is achieved through the use of so-called \choice types\"" and corresponding typing rules that support the static reasoning about underspecified template types. The main contribution of this paper is a guarantee of the type safety of C++ templates (general definitions with specializations) since we can show that well-typed templates only generate well-typed object programs.""","c++ templates, choice types, metaprogramming, type systems, type reflection",PEPM '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Tabareau N,A Theory of Distributed Aspects,,2010,,,133–144,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Aspect-Oriented Software Development,"Rennes and Saint-Malo, France",2010,9781605589589,,https://doi.org/10.1145/1739230.1739246;http://dx.doi.org/10.1145/1739230.1739246,10.1145/1739230.1739246,"Over the last five years, several systems have been proposed to take distribution into account in Aspect-Oriented Programming. While they appeared to be fruitful to develop or improve distributed component infrastructures or application servers, those systems are not underpinned with a formal semantics and so do not permit to establish properties on the code to be executed. This paper introduces the aspect join calculus -- an aspect-oriented and distributed language based on the join calculus, a member of the π-calculus family of process calculi suitable as a programming language. It provides a first formal theory of distributed AOP as well as a base language in which many features of previous distributed AOP systems can be formalized.The semantics of the aspect join calculus is given by a (chemical) operational semantics and a type system is developed to ensure properties satisfied by aspects during the execution of a process. We also give a translation of the aspect join calculus into the core join calculus. The translation is proved to be correct by a bisimilarity argument. In this way, we provide a well-defined version of a weaving algorithm which constitutes the main step towards an implementation of the aspect join calculus directly in JoCaml.We conclude this paper by showing that despite its minimal definition, the aspect join calculus is a convenient language in which existing distributed AOP languages can be formalized. Indeed, many features (such as remote pointcut, distributed advice, migration of aspects, asynchronous and synchronous aspects, re-routing of messages and distributed control flow) can be defined in this simple language.",,AOSD '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ramananandro T,Dos Reis G,Leroy X",Formal Verification of Object Layout for C++ Multiple Inheritance,,2011,,,67–80,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 38th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Austin, Texas, USA",2011,9781450304900,,https://doi.org/10.1145/1926385.1926395;http://dx.doi.org/10.1145/1926385.1926395,10.1145/1926385.1926395,"Object layout - the concrete in-memory representation of objects - raises many delicate issues in the case of the C++ language, owing in particular to multiple inheritance, C compatibility and separate compilation. This paper formalizes a family of C++ object layout schemes and mechanically proves their correctness against the operational semantics for multiple inheritance of Wasserrab et al. This formalization is flexible enough to account for space-saving techniques such as empty base class optimization and tail-padding optimization. As an application, we obtain the first formal correctness proofs for realistic, optimized object layout algorithms, including one based on the popular \common vendor\"" Itanium C++ application binary interface. This work provides semantic foundations to discover and justify new layout optimizations; it is also a first step towards the verification of a C++ compiler front-end.""","c++, empty base classes, object identity, data representation, multiple inheritance, compiler verification, object layout",POPL '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ramananandro T,Dos Reis G,Leroy X",Formal Verification of Object Layout for C++ Multiple Inheritance,SIGPLAN Not.,2011,46,1,67–80,Association for Computing Machinery,"New York, NY, USA",,,,2011-01,,0362-1340,https://doi.org/10.1145/1925844.1926395;http://dx.doi.org/10.1145/1925844.1926395,10.1145/1925844.1926395,"Object layout - the concrete in-memory representation of objects - raises many delicate issues in the case of the C++ language, owing in particular to multiple inheritance, C compatibility and separate compilation. This paper formalizes a family of C++ object layout schemes and mechanically proves their correctness against the operational semantics for multiple inheritance of Wasserrab et al. This formalization is flexible enough to account for space-saving techniques such as empty base class optimization and tail-padding optimization. As an application, we obtain the first formal correctness proofs for realistic, optimized object layout algorithms, including one based on the popular \common vendor\"" Itanium C++ application binary interface. This work provides semantic foundations to discover and justify new layout optimizations; it is also a first step towards the verification of a C++ compiler front-end.""","multiple inheritance, object identity, object layout, c++, data representation, compiler verification, empty base classes",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Mainland G,Explicitly Heterogeneous Metaprogramming with MetaHaskell,,2012,,,311–322,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming,"Copenhagen, Denmark",2012,9781450310543,,https://doi.org/10.1145/2364527.2364572;http://dx.doi.org/10.1145/2364527.2364572,10.1145/2364527.2364572,"Languages with support for metaprogramming, like MetaOCaml, offer a principled approach to code generation by guaranteeing that well-typed metaprograms produce well-typed programs. However, many problem domains where metaprogramming can fruitfully be applied require generating code in languages like C, CUDA, or assembly. Rather than resorting to add-hoc code generation techniques, these applications should be directly supported by explicitly heterogeneous metaprogramming languages.We present MetaHaskell, an extension of Haskell 98 that provides modular syntactic and type system support for type safe metaprogramming with multiple object languages. Adding a new object language to MetaHaskell requires only minor modifications to the host language to support type-level quantification over object language types and propagation of type equality constraints. We demonstrate the flexibility of our approach through three object languages: a core ML language, a linear variant of the core ML language, and a subset of C. All three languages support metaprogramming with open terms and guarantee that well-typed MetaHaskell programs will only produce closed object terms that are well-typed. The essence of MetaHaskell is captured in a type system for a simplified metalanguage. MetaHaskell, as well as all three object languages, are fully implemented in the mhc bytecode compiler.","metaprogramming, linear languages, quasiquotation, open terms, type systems",ICFP '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Mainland G,Explicitly Heterogeneous Metaprogramming with MetaHaskell,SIGPLAN Not.,2012,47,9,311–322,Association for Computing Machinery,"New York, NY, USA",,,,2012-09,,0362-1340,https://doi.org/10.1145/2398856.2364572;http://dx.doi.org/10.1145/2398856.2364572,10.1145/2398856.2364572,"Languages with support for metaprogramming, like MetaOCaml, offer a principled approach to code generation by guaranteeing that well-typed metaprograms produce well-typed programs. However, many problem domains where metaprogramming can fruitfully be applied require generating code in languages like C, CUDA, or assembly. Rather than resorting to add-hoc code generation techniques, these applications should be directly supported by explicitly heterogeneous metaprogramming languages.We present MetaHaskell, an extension of Haskell 98 that provides modular syntactic and type system support for type safe metaprogramming with multiple object languages. Adding a new object language to MetaHaskell requires only minor modifications to the host language to support type-level quantification over object language types and propagation of type equality constraints. We demonstrate the flexibility of our approach through three object languages: a core ML language, a linear variant of the core ML language, and a subset of C. All three languages support metaprogramming with open terms and guarantee that well-typed MetaHaskell programs will only produce closed object terms that are well-typed. The essence of MetaHaskell is captured in a type system for a simplified metalanguage. MetaHaskell, as well as all three object languages, are fully implemented in the mhc bytecode compiler.","quasiquotation, open terms, linear languages, metaprogramming, type systems",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mackay J,Mehnert H,Potanin A,Groves L,Cameron N",Encoding Featherweight Java with Assignment and Immutability Using the Coq Proof Assistant,,2012,,,11–19,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th Workshop on Formal Techniques for Java-like Programs,"Beijing, China",2012,9781450312721,,https://doi.org/10.1145/2318202.2318206;http://dx.doi.org/10.1145/2318202.2318206,10.1145/2318202.2318206,We develop a mechanized proof of Featherweight Java with Assignment and Immutability in the Coq proof assistant. This is a step towards more machine-checked proofs of a non-trivial type system. We used object immutability close to that of IGJ [9]. We describe the challenges of the mechanisation and the encoding we used inside of Coq.,"immutability, Coq, type systems, automated theorem provers",FTfJP '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Salgado R,Ducasse S",Lowcode: Extending Pharo with C Types to Improve Performance,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th Edition of the International Workshop on Smalltalk Technologies,"Prague, Czech Republic",2016,9781450345248,,https://doi.org/10.1145/2991041.2991064;http://dx.doi.org/10.1145/2991041.2991064,10.1145/2991041.2991064,"The highly dynamic nature of Smalltalk provides a high degree of flexibility, but at the expense of performance. On the other hand, static system programming languages such as C are really fast, but less flexible and harder to use than Smalltalk. Our hypothesis is that by mixing the concepts of these two worlds in a single programming environment, we are able to have improved performance and a high level of flexibility at the same time.In this work we extend Pharo by adding a type system that provides the native data types present in C along with the dynamic object type. We extend Pharo compiler and virtual machine to use our type system by add custom bytecode instructions for dealing with native data. With our approach we obtain a performance improvement on average between two and five times faster for numerical computations using single precision floating point arithmetic in Smalltalk.",,IWST'16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gaster BR,Howes L","Formalizing Address Spaces with Application to Cuda, OpenCL, and Beyond",,2013,,,32–41,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th Workshop on General Purpose Processor Using Graphics Processing Units,"Houston, Texas, USA",2013,9781450320177,,https://doi.org/10.1145/2458523.2458527;http://dx.doi.org/10.1145/2458523.2458527,10.1145/2458523.2458527,"Cuda and OpenCL are aimed at programmers developing parallel applications targeting GPUs and embedded micro-processors. These systems often have explicitly managed memories exposed directly though a notion of disjoint address spaces. OpenCL address spaces are based on a similar concept found in Embedded C. A limitation of OpenCL is that a specific pointer must be assigned to a particular address space and thus functions, for example, must say which pointer arguments point to which address spaces. This leads to a loss of composability and moreover can lead to implementing multiple versions of the same function. This problem is compounded in the OpenCL C++ variant where a class' implicit this pointer can be applied to multiple address spaces.Modern GPUs, such as AMD's Graphics Core Next and Nvidia's Fermi, support an additional generic address space that dynamically determines an address' disjoint address space, submitting the correct load/store operation to the particular memory subsystem. Generic address spaces allow for dynamic casting between generic and non-generic address spaces that is similar to the dynamic subtyping found in objected oriented languages. The advantage of the generic address space is it simplifies the programming model but sometimes at the cost of decreased performance, both dynamically and due to the optimization a compiler can safely perform.This paper describes a new type system for inferring Cuda and OpenCL style address spaces. We show that the address space system can be inferred. We extend this base system with a notion of generic address space, including dynamic casting, and show that there also exists a static translation to architectures without support for generic address spaces but comes at a potential performance cost. This performance cost can be reclaimed when an architecture directly supports generic address space.","GPU, OpenCL, C++, GPGPU",GPGPU-6,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ancona D,Zucca E",Safe Corecursion in CoFJ,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th Workshop on Formal Techniques for Java-like Programs,"Montpellier, France",2013,9781450320429,,https://doi.org/10.1145/2489804.2489807;http://dx.doi.org/10.1145/2489804.2489807,10.1145/2489804.2489807,"In previous work we have presented coFJ, an extension to Featherweight Java that promotes coinductive programming, a sub-paradigm expressly devised to ease high-level programming and reasoning with cyclic data structures.The coFJ language supports cyclic objects and regularly corecursive methods, that is, methods whose invocation terminates not only when the corresponding call trace is finite (as happens with ordinary recursion), but also when such a trace is infinite but cyclic, that is, can be specified by a regular term, or, equivalently, by a finite set of recursive syntactic equations.In coFJ it is not easy to ensure that the invocation of a corecursive method will return a well-defined value, since the recursive equations corresponding to the regular trace of the recursive calls may not admit a (unique) solution; in such cases we say that the value returned by the method call is undetermined.In this paper we propose two new contributions. First, we design a simpler construct for defining corecursive methods and, correspondingly, provide a more intuitive operational semantics. For this coFJ variant, we are able to define a type system that allows the user to specify that certain corecursive methods cannot return an undetermined value; in this way, it is possible to prevent unsafe use of such a value.The operational semantics and the type system of coFJ are fully formalized, and the soundness of the type system is proved.","regular terms, coinduction, Java, programming paradigms",FTfJP '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zimányi E,Sakr M,Lesuisse A",MobilityDB: A Mobility Database Based on PostgreSQL and PostGIS,ACM Trans. Database Syst.,2020,45,4,,Association for Computing Machinery,"New York, NY, USA",,,,2020-12,,0362-5915,https://doi.org/10.1145/3406534;http://dx.doi.org/10.1145/3406534,10.1145/3406534,"Despite two decades of research in moving object databases and a few research prototypes that have been proposed, there is not yet a mainstream system targeted for industrial use. In this article, we present MobilityDB, a moving object database that extends the type system of PostgreSQL and PostGIS with abstract data types for representing moving object data. The types are fully integrated into the platform to reuse its powerful data management features. Furthermore, MobilityDB builds on existing operations, indexing, aggregation, and optimization framework. This is all made accessible via the SQL query interface.","mobility data management, SQL, Moving object databases, spatiotemporal data management",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Corcoran BJ,Swamy N,Hicks M","Cross-Tier, Label-Based Security Enforcement for Web Applications",,2009,,,269–282,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 ACM SIGMOD International Conference on Management of Data,"Providence, Rhode Island, USA",2009,9781605585512,,https://doi.org/10.1145/1559845.1559875;http://dx.doi.org/10.1145/1559845.1559875,10.1145/1559845.1559875,"This paper presents SELinks, a programming language focused on building secure multi-tier web applications. SELinks provides a uniform programming model, in the style of LINQ and Ruby on Rails, with language syntax for accessing objects residing either in the database or at the server. Object-level security policies are expressed as fully-customizable, first-class labels which may themselves be subject to security policies. Access to labeled data is mediated via trusted, user-provided policy enforcement functions.SELinks has two novel features that ensure security policies are enforced correctly and efficiently. First, SELinks implements a type system called Fable that allows a protected object's type to refer to its protecting label. The type system can check that labeled data is never accessed directly by the program without first consulting the appropriate policy enforcement function. Second, SELinks compiles policy enforcement code to database-resident user-defined functions that can be called directly during query processing. Database-side checking avoids transferring data to the server needlessly, while still allowing policies to be expressed in a customizable and portable manner.Our experience with two sizable web applications, a modelhealth-care database and a secure wiki with fine-grained security policies, indicates that cross-tier policy enforcement in SELinks is flexible, relatively easy to use, and, when compared to a single-tier approach, improves throughput by nearly an order of magnitude. SELinks is freely available.","database programming, type systems, web applications, compilers, security enforcement",SIGMOD '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bavera F,Bonelli E",Type-Based Information Flow Analysis for Bytecode Languages with Variable Object Field Policies,,2008,,,347–351,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Symposium on Applied Computing,"Fortaleza, Ceara, Brazil",2008,9781595937537,,https://doi.org/10.1145/1363686.1363776;http://dx.doi.org/10.1145/1363686.1363776,10.1145/1363686.1363776,"Static, type-based information flow analysis techniques targeted at Java and JVM-like code typically assume a global security policy on object fields: all fields are assigned a fixed security level. In essence they are treated as standard variables. However different objects may be created under varying security contexts, particularly for widely used classes such as wrapper or collection classes. This entails an important loss in precision of the analysis. We present a flow-sensitive type system for statically detecting illegal flows of information in a JVM-like language that allows the level of a field to vary at different object creation points. Also, we prove a noninterference result for this language.",,SAC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gordon CS,Ernst MD,Grossman D",Rely-Guarantee References for Refinement Types over Aliased Mutable Data,,2013,,,73–84,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 34th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Seattle, Washington, USA",2013,9781450320146,,https://doi.org/10.1145/2491956.2462160;http://dx.doi.org/10.1145/2491956.2462160,10.1145/2491956.2462160,"Reasoning about side effects and aliasing is the heart of verifying imperative programs. Unrestricted side effects through one reference can invalidate assumptions about an alias. We present a new type system approach to reasoning about safe assumptions in the presence of aliasing and side effects, unifying ideas from reference immutability type systems and rely-guarantee program logics. Our approach, rely-guarantee references, treats multiple references to shared objects similarly to multiple threads in rely-guarantee program logics. We propose statically associating rely and guarantee conditions with individual references to shared objects. Multiple aliases to a given object may coexist only if the guarantee condition of each alias implies the rely condition for all other aliases. We demonstrate that existing reference immutability type systems are special cases of rely-guarantee references.In addition to allowing precise control over state modification, rely-guarantee references allow types to depend on mutable data while still permitting flexible aliasing. Dependent types whose denotation is stable over the actions of the rely and guarantee conditions for a reference and its data will not be invalidated by any action through any alias. We demonstrate this with refinement (subset) types that may depend on mutable data. As a special case, we derive the first reference immutability type system with dependent types over immutable data.We show soundness for our approach and describe experience using rely-guarantee references in a dependently-typed monadic DSL in Coq.","rely-guarantee, reference immutability, refinement types",PLDI '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gordon CS,Ernst MD,Grossman D",Rely-Guarantee References for Refinement Types over Aliased Mutable Data,SIGPLAN Not.,2013,48,6,73–84,Association for Computing Machinery,"New York, NY, USA",,,,2013-06,,0362-1340,https://doi.org/10.1145/2499370.2462160;http://dx.doi.org/10.1145/2499370.2462160,10.1145/2499370.2462160,"Reasoning about side effects and aliasing is the heart of verifying imperative programs. Unrestricted side effects through one reference can invalidate assumptions about an alias. We present a new type system approach to reasoning about safe assumptions in the presence of aliasing and side effects, unifying ideas from reference immutability type systems and rely-guarantee program logics. Our approach, rely-guarantee references, treats multiple references to shared objects similarly to multiple threads in rely-guarantee program logics. We propose statically associating rely and guarantee conditions with individual references to shared objects. Multiple aliases to a given object may coexist only if the guarantee condition of each alias implies the rely condition for all other aliases. We demonstrate that existing reference immutability type systems are special cases of rely-guarantee references.In addition to allowing precise control over state modification, rely-guarantee references allow types to depend on mutable data while still permitting flexible aliasing. Dependent types whose denotation is stable over the actions of the rely and guarantee conditions for a reference and its data will not be invalidated by any action through any alias. We demonstrate this with refinement (subset) types that may depend on mutable data. As a special case, we derive the first reference immutability type system with dependent types over immutable data.We show soundness for our approach and describe experience using rely-guarantee references in a dependently-typed monadic DSL in Coq.","reference immutability, rely-guarantee, refinement types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Castegren E,Wrigstad T",OOlong: An Extensible Concurrent Object Calculus,,2018,,,1022–1029,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd Annual ACM Symposium on Applied Computing,"Pau, France",2018,9781450351911,,https://doi.org/10.1145/3167132.3167243;http://dx.doi.org/10.1145/3167132.3167243,10.1145/3167132.3167243,"We present OOlong, an object calculus with interface inheritance, structured concurrency and locks. The goal of the calculus is extensibility and reuse. The semantics are therefore available in a version for LATEX typesetting (written in Ott), and a mechanised version for doing rigorous proofs in Coq.","concurrency, semantics, mechanisation, object calculi",SAC '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Corradi A,Servetto M,Zucca E",DeepFJig: Modular Composition of Nested Classes,,2011,,,101–110,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Principles and Practice of Programming in Java,"Kongens Lyngby, Denmark",2011,9781450309356,,https://doi.org/10.1145/2093157.2093172;http://dx.doi.org/10.1145/2093157.2093172,10.1145/2093157.2093172,"We present a new language design which smoothly integrates modular composition and nesting of Java-like classes. That is, inheritance has been replaced by an expressive set of composition operators, inspired by Bracha's Jigsaw framework, and these operators allow to manipulate (e.g., rename or duplicate) a nested class at any level of depth. Typing is nominal as characteristic of Java-like languages, so types are paths of the form outern. c1..... ck which, depending on the class (node) where they occur, denote another node in the nesting tree. However, paths denoting the same class are not equivalent, since they behave differently w.r.t. composition operators.The resulting language, called DeepFJig, obtains a great expressive power, allowing, e.g., to solve the expression problem, encode basic AOP mechanisms, and bring some refactoring techniques at the language level, while keeping a very simple semantics and type system which represent a natural extension for, say, a Java programmer.","Java, module composition, nested classes",PPPJ '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Milanova A,Dong Y",Inference and Checking of Object Immutability,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 13th International Conference on Principles and Practices of Programming on the Java Platform: Virtual Machines, Languages, and Tools","Lugano, Switzerland",2016,9781450341356,,https://doi.org/10.1145/2972206.2972208;http://dx.doi.org/10.1145/2972206.2972208,10.1145/2972206.2972208,"Reference immutability guarantees that a reference is not used to modify the referenced object. It is well-understood and there are several scalable inference systems. Object immutability, a stronger immutability guarantee, guarantees that an object is not modified. Unfortunately, object immutability is not as well-understood; specifically, we are unaware of an inference system that infers object immutability across large Java programs and libraries.It is tempting to use reference immutability to reason about object immutability. However, representation exposure and object initialization pose significant challenges.In this paper we present a novel type system and a corresponding inference analysis. We leverage reference immutability to infer object immutability overcoming the challenges due to representation exposure and object initialization.We have implemented our object immutability system for Java. Evaluation on the standard Dacapo benchmarks demonstrates precision and scalability. Nearly 40% of all static objects are inferred immutable. Analysis completes in under 2 minutes on all benchmarks.","immutability, object immutability, reference immutability",PPPJ '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vekris P,Cosman B,Jhala R",Refinement Types for TypeScript,,2016,,,310–325,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Santa Barbara, CA, USA",2016,9781450342612,,https://doi.org/10.1145/2908080.2908110;http://dx.doi.org/10.1145/2908080.2908110,10.1145/2908080.2908110,"We present Refined TypeScript (RSC), a lightweight refinement type system for TypeScript, that enables static verification of higher-order, imperative programs. We develop a formal system for RSC that delineates the interaction between refinement types and mutability, and enables flow-sensitive reasoning by translating input programs to an equivalent intermediate SSA form. By establishing type safety for the intermediate form, we prove safety for the input programs. Next, we extend the core to account for imperative and dynamic features of TypeScript, including overloading, type reflection, ad hoc type hierarchies and object initialization. Finally, we evaluate RSC on a set of real-world benchmarks, including parts of the Octane benchmarks, D3, Transducers, and the TypeScript compiler. We show how RSC successfully establishes a number of value dependent properties, such as the safety of array accesses and downcasts, while incurring a modest overhead in type annotations and code restructuring.","Immutability, Type Systems, TypeScript, Refinement Types",PLDI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Vekris P,Cosman B,Jhala R",Refinement Types for TypeScript,SIGPLAN Not.,2016,51,6,310–325,Association for Computing Machinery,"New York, NY, USA",,,,2016-06,,0362-1340,https://doi.org/10.1145/2980983.2908110;http://dx.doi.org/10.1145/2980983.2908110,10.1145/2980983.2908110,"We present Refined TypeScript (RSC), a lightweight refinement type system for TypeScript, that enables static verification of higher-order, imperative programs. We develop a formal system for RSC that delineates the interaction between refinement types and mutability, and enables flow-sensitive reasoning by translating input programs to an equivalent intermediate SSA form. By establishing type safety for the intermediate form, we prove safety for the input programs. Next, we extend the core to account for imperative and dynamic features of TypeScript, including overloading, type reflection, ad hoc type hierarchies and object initialization. Finally, we evaluate RSC on a set of real-world benchmarks, including parts of the Octane benchmarks, D3, Transducers, and the TypeScript compiler. We show how RSC successfully establishes a number of value dependent properties, such as the safety of array accesses and downcasts, while incurring a modest overhead in type annotations and code restructuring.","Type Systems, Refinement Types, TypeScript, Immutability",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Castegren E,Wrigstad T",OOlong: A Concurrent Object Calculus for Extensibility and Reuse,SIGAPP Appl. Comput. Rev.,2019,18,4,47–60,Association for Computing Machinery,"New York, NY, USA",,,,2019-01,,1559-6915,https://doi.org/10.1145/3307624.3307629;http://dx.doi.org/10.1145/3307624.3307629,10.1145/3307624.3307629,"We present OOlong, an object calculus with interface inheritance, structured concurrency and locks. The goal of the calculus is extensibility and reuse. The semantics are therefore available in a version for LATEX typesetting (written in Ott), a mechanised version for doing rigorous proofs in Coq, and a prototype interpreter (written in OCaml) for typechecking an running OOlong programs.","concurrency, semantics, mechanisation, object calculi",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Lew AK,Cusumano-Towner MF,Sherman B,Carbin M,Mansinghka VK",Trace Types and Denotational Semantics for Sound Programmable Inference in Probabilistic Languages,Proc. ACM Program. Lang.,2019,4,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-12,,,https://doi.org/10.1145/3371087;http://dx.doi.org/10.1145/3371087,10.1145/3371087,"Modern probabilistic programming languages aim to formalize and automate key aspects of probabilistic modeling and inference. Many languages provide constructs for programmable inference that enable developers to improve inference speed and accuracy by tailoring an algorithm for use with a particular model or dataset. Unfortunately, it is easy to use these constructs to write unsound programs that appear to run correctly but produce incorrect results. To address this problem, we present a denotational semantics for programmable inference in higher-order probabilistic programming languages, along with a type system that ensures that well-typed inference programs are sound by construction. A central insight is that the type of a probabilistic expression can track the space of its possible execution traces, not just the type of value that it returns, as these traces are often the objects that inference algorithms manipulate. We use our semantics and type system to establish soundness properties of custom inference programs that use constructs for variational, sequential Monte Carlo, importance sampling, and Markov chain Monte Carlo inference.","Probabilistic programming, type systems, programmable inference",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Hu JZ,Lhoták O",Undecidability of <i>d<sub><:</sub></i> And Its Decidable Fragments,Proc. ACM Program. Lang.,2019,4,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-12,,,https://doi.org/10.1145/3371077;http://dx.doi.org/10.1145/3371077,10.1145/3371077,"Dependent Object Types (DOT) is a calculus with path dependent types, intersection types, and object self-references, which serves as the core calculus of Scala 3. Although the calculus has been proven sound, it remains open whether type checking in DOT is decidable. In this paper, we establish undecidability proofs of type checking and subtyping of D<:, a syntactic subset of DOT. It turns out that even for D<:, undecidability is surprisingly difficult to show, as evidenced by counterexamples for past attempts. To prove undecidability, we discover an equivalent definition of the D<: subtyping rules in normal form. Besides being easier to reason about, this definition makes the phenomenon of subtyping reflection explicit as a single inference rule. After removing this rule, we discover two decidable fragments of D<: subtyping and identify algorithms to decide them. We prove soundness and completeness of the algorithms with respect to the fragments, and we prove that the algorithms terminate. Our proofs are mechanized in a combination of Coq and Agda.","Dependent Object Types, $D_<:$, Undecidability, Algorithmic Typing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Branco A,Costa F",High Precision Analysis of NPs with a Deep Processing Grammar,,2008,,,31–43,Association for Computational Linguistics,USA,,Proceedings of the 2008 Conference on Semantics in Text Processing,"Venice, Italy",2008,,,,,"In this paper we present LXGram, a general purpose grammar for the deep linguistic processing of Portuguese that aims at delivering detailed and high precision meaning representations. LXGram is grounded on the linguistic framework of Head-Driven Phrase Structure Grammar (HPSG). HPSG is a declarative formalism resorting to unification and a type system with multiple inheritance. The semantic representations that LXGram associates with linguistic expressions use the Minimal Recursion Semantics (MRS) format, which allows for the underspecification of scope effects. LXGram is developed in the Linguistic Knowledge Builder (LKB) system, a grammar development environment that provides debugging tools and efficient algorithms for parsing and generation. The implementation of LXGram has focused on the structure of Noun Phrases, and LXGram accounts for many NP related phenomena. Its coverage continues to be increased with new phenomena, and there is active work on extending the grammar's lexicon. We have already integrated, or plan to integrate, LXGram in a few applications, namely paraphrasing, treebanking and language variant detection. Grammar coverage has been tested on newspaper text.",,STEP '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Athanasopoulos D,Zarras A",Mining Abstract XML Data-Types,ACM Trans. Web,2018,13,1,,Association for Computing Machinery,"New York, NY, USA",,,,2018-12,,1559-1131,https://doi.org/10.1145/3267467;http://dx.doi.org/10.1145/3267467,10.1145/3267467,"Schema integration has been a long-standing challenge for the data-engineering community that has received steady attention over the past three decades. General-purpose integration approaches construct unified schemas that encompass all schema elements. Schema integration has been revisited in the past decade in service-oriented computing since the input/output data-types of service interfaces are heterogeneous XML schemas. However, service integration differs from the traditional integration problem, since it should generalize schemas (mining abstract data-types) instead of unifying all schema elements. To mine well-formed abstract data-types, the fundamental Liskov Substitution Principle (LSP), which generally holds between abstract data-types and their subtypes, should be followed. However, due to the heterogeneity of service data-types, the strict employment of LSP is not usually feasible. On top of that, XML offers a rich type system, based on which data-types are defined via combining type patterns (e.g., composition, aggregation). The existing integration approaches have not dealt with the challenges of a defining subtyping relation between XML type patterns. To address these challenges, we propose a relaxed version of LSP between XML type patterns and an automated generalization process for mining abstract XML data-types. We evaluate the effectiveness and the efficiency of the process on the schemas of two datasets against two representative state-of-the-art approaches.","pruning, embedded subtree, Type pattern, subtyping relation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rouvoet A,van Antwerpen H,Bach Poulsen C,Krebbers R,Visser E",Knowing When to Ask: Sound Scheduling of Name Resolution in Type Checkers Derived from Declarative Specifications,Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428248;http://dx.doi.org/10.1145/3428248,10.1145/3428248,"There is a large gap between the specification of type systems and the implementation of their type checkers, which impedes reasoning about the soundness of the type checker with respect to the specification. A vision to close this gap is to automatically obtain type checkers from declarative programming language specifications. This moves the burden of proving correctness from a case-by-case basis for concrete languages to a single correctness proof for the specification language. This vision is obstructed by an aspect common to all programming languages: name resolution. Naming and scoping are pervasive and complex aspects of the static semantics of programming languages. Implementations of type checkers for languages with name binding features such as modules, imports, classes, and inheritance interleave collection of binding information (i.e., declarations, scoping structure, and imports) and querying that information. This requires scheduling those two aspects in such a way that query answers are stable—i.e., they are computed only after all relevant binding structure has been collected. Type checkers for concrete languages accomplish stability using language-specific knowledge about the type system. In this paper we give a language-independent characterization of necessary and sufficient conditions to guarantee stability of name and type queries during type checking in terms of critical edges in an incomplete scope graph. We use critical edges to give a formal small-step operational semantics to a declarative specification language for type systems, that achieves soundness by delaying queries that may depend on missing information. This yields type checkers for the specified languages that are sound by construction—i.e., they schedule queries so that the answers are stable, and only accept programs that are name- and type-correct according to the declarative language specification. We implement this approach, and evaluate it against specifications of a small module and record language, as well as subsets of Java and Scala.","Static Semantics, Type Systems, Statix, Type Checker, Name Binding",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ramananandro T,Dos Reis G,Leroy X","A Mechanized Semantics for C++ Object Construction and Destruction, with Applications to Resource Management",,2012,,,521–532,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 39th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Philadelphia, PA, USA",2012,9781450310833,,https://doi.org/10.1145/2103656.2103718;http://dx.doi.org/10.1145/2103656.2103718,10.1145/2103656.2103718,"We present a formal operational semantics and its Coq mechanization for the C++ object model, featuring object construction and destruction, shared and repeated multiple inheritance, and virtual function call dispatch. These are key C++ language features for high-level system programming, in particular for predictable and reliable resource management. This paper is the first to present a formal mechanized account of the metatheory of construction and destruction in C++, and applications to popular programming techniques such as \resource acquisition is initialization\"". We also report on irregularities and apparent contradictions in the ISO C++03 and C++11 standards.""","Coq, classes, constructors, destructors, mechanized semantics, objects, C++",POPL '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ramananandro T,Dos Reis G,Leroy X","A Mechanized Semantics for C++ Object Construction and Destruction, with Applications to Resource Management",SIGPLAN Not.,2012,47,1,521–532,Association for Computing Machinery,"New York, NY, USA",,,,2012-01,,0362-1340,https://doi.org/10.1145/2103621.2103718;http://dx.doi.org/10.1145/2103621.2103718,10.1145/2103621.2103718,"We present a formal operational semantics and its Coq mechanization for the C++ object model, featuring object construction and destruction, shared and repeated multiple inheritance, and virtual function call dispatch. These are key C++ language features for high-level system programming, in particular for predictable and reliable resource management. This paper is the first to present a formal mechanized account of the metatheory of construction and destruction in C++, and applications to popular programming techniques such as \resource acquisition is initialization\"". We also report on irregularities and apparent contradictions in the ISO C++03 and C++11 standards.""","classes, constructors, mechanized semantics, C++, destructors, Coq, objects",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Malayeri D,CZ: Multiple Inheritance without Diamonds,,2008,,,923–924,Association for Computing Machinery,"New York, NY, USA",,Companion to the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582207,,https://doi.org/10.1145/1449814.1449910;http://dx.doi.org/10.1145/1449814.1449910,10.1145/1449814.1449910,"Multiple inheritance has long been plagued with the \diamond\"" inheritance problem",spurring a variety of solutions,such as virtual inheritance,"mixins and traits. We offer a different solution: a language that supports multiple inheritance but forbids diamond inheritance. We maintain expressiveness through a \""requires\"" construct (inspired by Scala) that provides subtyping without inheritance diamonds. Our novel no-diamond restriction offers the benefit of allowing multiple inheritance to co-exist neatly with fields","without resorting to tactics such as virtual inheritance. We believe our solution is more expressive than previous attempts to solve the diamond inheritance problem.""","diamond problem, multiple inheritance",OOPSLA Companion '08,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Geisler D,Yoon I,Kabra A,He H,Sanders Y,Sampson A",Geometry Types for Graphics Programming,Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428241;http://dx.doi.org/10.1145/3428241,10.1145/3428241,"In domains that deal with physical space and geometry, programmers need to track the coordinate systems that underpin a computation. We identify a class of geometry bugs that arise from confusing which coordinate system a vector belongs to. These bugs are not ruled out by current languages for vector-oriented computing, are difficult to check for at run time, and can generate subtly incorrect output that can be hard to test for. We introduce a type system and language that prevents geometry bugs by reflecting the coordinate system for each geometric object. A value's geometry type encodes its reference frame, the kind of geometric object (such as a point or a direction), and the coordinate representation (such as Cartesian or spherical coordinates). We show how these types can rule out geometrically incorrect operations, and we show how to use them to automatically generate correct-by-construction code to transform vectors between coordinate systems. We implement a language for graphics programming, Gator, that checks geometry types and compiles to OpenGL's shading language, GLSL. Using case studies, we demonstrate that Gator can raise the level of abstraction for shader programming and prevent common errors without inducing significant annotation overhead or performance cost.","type systems, language design, computer graphics, geometry",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Balatsouras G,Smaragdakis Y",Class Hierarchy Complementation: Soundly Completing a Partial Type Graph,,2013,,,515–532,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages & Applications,"Indianapolis, Indiana, USA",2013,9781450323741,,https://doi.org/10.1145/2509136.2509530;http://dx.doi.org/10.1145/2509136.2509530,10.1145/2509136.2509530,"We present the problem of class hierarchy complementation: given a partially known hierarchy of classes together with subtyping constraints (\A has to be a transitive subtype of B\"") complete the hierarchy so that it satisfies all constraints. The problem has immediate practical application to the analysis of partial programs--e.g.","it arises in the process of providing a sound handling of \""phantom classes\"" in the Soot program analysis framework. We provide algorithms to solve the hierarchy complementation problem in the single inheritance and multiple inheritance settings. We also show that the problem in a language such as Java",with single inheritance but multiple subtyping and distinguished class vs. interface types,can be decomposed into separate single- and multiple-subtyping instances. We implement our algorithms in a tool,JPhantom,"which complements partial Java bytecode programs so that the result is guaranteed to satisfy the Java verifier requirements. JPhantom is highly scalable and runs in mere seconds even for large input applications and complex constraints (with a maximum of 14s for a 19MB binary).""","single inheritance, type hierarchy, bytecode engineering, java, jphantom, multiple inheritance",OOPSLA '13,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Balatsouras G,Smaragdakis Y",Class Hierarchy Complementation: Soundly Completing a Partial Type Graph,SIGPLAN Not.,2013,48,10,515–532,Association for Computing Machinery,"New York, NY, USA",,,,2013-10,,0362-1340,https://doi.org/10.1145/2544173.2509530;http://dx.doi.org/10.1145/2544173.2509530,10.1145/2544173.2509530,"We present the problem of class hierarchy complementation: given a partially known hierarchy of classes together with subtyping constraints (\A has to be a transitive subtype of B\"") complete the hierarchy so that it satisfies all constraints. The problem has immediate practical application to the analysis of partial programs--e.g.","it arises in the process of providing a sound handling of \""phantom classes\"" in the Soot program analysis framework. We provide algorithms to solve the hierarchy complementation problem in the single inheritance and multiple inheritance settings. We also show that the problem in a language such as Java",with single inheritance but multiple subtyping and distinguished class vs. interface types,can be decomposed into separate single- and multiple-subtyping instances. We implement our algorithms in a tool,JPhantom,"which complements partial Java bytecode programs so that the result is guaranteed to satisfy the Java verifier requirements. JPhantom is highly scalable and runs in mere seconds even for large input applications and complex constraints (with a maximum of 14s for a 19MB binary).""","bytecode engineering, single inheritance, java, type hierarchy, jphantom, multiple inheritance",,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lienhardt M,Clarke D",Row Types for Delta-Oriented Programming,,2012,,,121–128,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Sixth International Workshop on Variability Modeling of Software-Intensive Systems,"Leipzig, Germany",2012,9781450310581,,https://doi.org/10.1145/2110147.2110161;http://dx.doi.org/10.1145/2110147.2110161,10.1145/2110147.2110161,"Delta-oriented programming (DOP) provides a technique for implementing Software Product Lines based on modifications (add, remove, modify) to a core program. Unfortunately, such modifications can introduce errors into a program, especially when type signatures of classes are modified in a non-monotonic fashion. To deal with this problem we present a type system for delta-oriented programs based on row polymorphism. This exercise elucidates the close correspondence between delta-oriented programs and row polymorphism.","structural typing, software product line engineering, delta-oriented programming",VaMoS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cameron N,Noble J,Wrigstad T",Tribal Ownership,,2010,,,618–633,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Reno/Tahoe, Nevada, USA",2010,9781450302036,,https://doi.org/10.1145/1869459.1869510;http://dx.doi.org/10.1145/1869459.1869510,10.1145/1869459.1869510,"Tribal Ownership unifies class nesting and object ownership. Tribal Ownership is based on Tribe, a language with nested classes and object families. In Tribal Ownership, a program's runtime object ownership structure is characterised by the lexical nesting structure of its classes.We build on a variant of Tribe to present a descriptive ownership system, using object nesting to describe heap partitions, but without imposing any restrictions on programming disciplines. We then demonstrate how a range of different prescriptive ownership policies can be supported on top of the descriptive Tribal Ownership mechanism; including a novel owners-as-local-dominators policy. We formalise our type system and prove soundness and several ownership invariants. The resulting system requires strikingly few annotations, and uses well-understood encapsulation techniques to create ownership systems that should be intuitive for programmers.","family polymorphism, virtual classes, nested classes, ownership types",OOPSLA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Cameron N,Noble J,Wrigstad T",Tribal Ownership,SIGPLAN Not.,2010,45,10,618–633,Association for Computing Machinery,"New York, NY, USA",,,,2010-10,,0362-1340,https://doi.org/10.1145/1932682.1869510;http://dx.doi.org/10.1145/1932682.1869510,10.1145/1932682.1869510,"Tribal Ownership unifies class nesting and object ownership. Tribal Ownership is based on Tribe, a language with nested classes and object families. In Tribal Ownership, a program's runtime object ownership structure is characterised by the lexical nesting structure of its classes.We build on a variant of Tribe to present a descriptive ownership system, using object nesting to describe heap partitions, but without imposing any restrictions on programming disciplines. We then demonstrate how a range of different prescriptive ownership policies can be supported on top of the descriptive Tribal Ownership mechanism; including a novel owners-as-local-dominators policy. We formalise our type system and prove soundness and several ownership invariants. The resulting system requires strikingly few annotations, and uses well-understood encapsulation techniques to create ownership systems that should be intuitive for programmers.","ownership types, nested classes, family polymorphism, virtual classes",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Dos Reis G,Stroustrup B",General Constant Expressions for System Programming Languages,,2010,,,2131–2136,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Symposium on Applied Computing,"Sierre, Switzerland",2010,9781605586397,,https://doi.org/10.1145/1774088.1774537;http://dx.doi.org/10.1145/1774088.1774537,10.1145/1774088.1774537,"Most mainstream system programming languages provide support for builtin types, and extension mechanisms through userdefined types. They also come with a notion of constant expressions whereby some expressions (such as array bounds) can be evaluated at compile time. However, they require constant expressions to be written in an impoverished language with minimal support from the type system; this is tedious and error-prone. This paper presents a framework for generalizing the notion of constant expressions in modern system programming languages. It extends compile time evaluation to functions and variables of user-defined types, thereby including formerly ad hoc notions of Read Only Memory (ROM) objects into a general and type safe framework. It allows a programmer to specify that an operation must be evaluated at compile time. Furthermore, it provides more direct support for key meta programming and generative programming techniques. The framework is formalized as an extension of underlying type system with a binding time analysis. It was designed to meet real-world requirements. In particular, key design decisions relate to balancing expressive power to implementability in industrial compilers and teachability. It has been implemented for C++ in the GNU Compiler Collection, and is part of the next ISO C++ standard.","compile time evaluation, standardization",SAC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Stork S,Naden K,Sunshine J,Mohr M,Fonseca A,Marques P,Aldrich J",ÆMinium: A Permission Based Concurrent-by-Default Programming Language Approach,,2014,,,26,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Edinburgh, United Kingdom",2014,9781450327848,,https://doi.org/10.1145/2594291.2594344;http://dx.doi.org/10.1145/2594291.2594344,10.1145/2594291.2594344,"The aim of ÆMINIUM is to study the implications of having a concurrent-by-default programming language. This includes language design, runtime system, performance and software engineering considerations.We conduct our study through the design of the concurrent-by-default ÆMINIUM programming language. ÆMINIUM leverages the permission flow of object and group permissions through the program to validate the program's correctness and to automatically infer a possible parallelization strategy via a dataflow graph. ÆMINIUM supports not only fork-join parallelism but more general dataflow patterns of parallelism.In this paper we present a formal system, called μÆMINIUM, modeling the core concepts of ÆMINIUM. μÆMINIUM's static type system is based on Featherweight Java with ÆMINIUM-specific extensions. Besides checking for correctness ÆMINIUM's type system it also uses the permission flow to compute a potential parallel execution strategy for the program. μÆMINIUM's dynamic semantics use a concurrent-by-default evaluation approach. Along with the formal system we present its soundness proof.We provide a full description of the implementation along with the description of various optimization techniques we used. We implemented ÆMINIUM as an extension of the Plaid programming language, which has first-class support for permissions built-in. The ÆMINIUM implementation and all case studies are publicly available under the General Public License.We use various case studies to evaluate ÆMINIUM's applicability and to demonstrate that ÆMINIUM parallelized code has performance improvements compared to its sequential counterpart. We chose to use case studies from common domains or problems that are known to benefit from parallelization, to show that ÆMINIUM is powerful enough to encode them. We demonstrate through a webserver application, which evaluates ÆMINIUM's impact on latency-bound applications, that ÆMINIUM can achieve a 70% performance improvement over the sequential counterpart. In another case study we chose to implement a dictionary function to evaluate ÆMINIUM's capabilities to express essential data structures. Our evaluation demonstrates that ÆMINIUM can be used to express parallelism in such data-structures and that the performance benefits scale with the amount of annotation effort which is put into the implementation. We chose an integral computationally example to evaluate pure functional programming and computational intensive use cases. Our experiments show that ÆMINIUM is capable of extracting parallelism from functional code and achieving performance improvements up to the limits of Plaid's inherent performance bounds.Overall, we hope that the work helps to advance concurrent programming in modern programming environments.","data groups, access permissions, permissions, concurrency",PLDI '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Stork S,Naden K,Sunshine J,Mohr M,Fonseca A,Marques P,Aldrich J",ÆMinium: A Permission Based Concurrent-by-Default Programming Language Approach,SIGPLAN Not.,2014,49,6,26,Association for Computing Machinery,"New York, NY, USA",,,,2014-06,,0362-1340,https://doi.org/10.1145/2666356.2594344;http://dx.doi.org/10.1145/2666356.2594344,10.1145/2666356.2594344,"The aim of ÆMINIUM is to study the implications of having a concurrent-by-default programming language. This includes language design, runtime system, performance and software engineering considerations.We conduct our study through the design of the concurrent-by-default ÆMINIUM programming language. ÆMINIUM leverages the permission flow of object and group permissions through the program to validate the program's correctness and to automatically infer a possible parallelization strategy via a dataflow graph. ÆMINIUM supports not only fork-join parallelism but more general dataflow patterns of parallelism.In this paper we present a formal system, called μÆMINIUM, modeling the core concepts of ÆMINIUM. μÆMINIUM's static type system is based on Featherweight Java with ÆMINIUM-specific extensions. Besides checking for correctness ÆMINIUM's type system it also uses the permission flow to compute a potential parallel execution strategy for the program. μÆMINIUM's dynamic semantics use a concurrent-by-default evaluation approach. Along with the formal system we present its soundness proof.We provide a full description of the implementation along with the description of various optimization techniques we used. We implemented ÆMINIUM as an extension of the Plaid programming language, which has first-class support for permissions built-in. The ÆMINIUM implementation and all case studies are publicly available under the General Public License.We use various case studies to evaluate ÆMINIUM's applicability and to demonstrate that ÆMINIUM parallelized code has performance improvements compared to its sequential counterpart. We chose to use case studies from common domains or problems that are known to benefit from parallelization, to show that ÆMINIUM is powerful enough to encode them. We demonstrate through a webserver application, which evaluates ÆMINIUM's impact on latency-bound applications, that ÆMINIUM can achieve a 70% performance improvement over the sequential counterpart. In another case study we chose to implement a dictionary function to evaluate ÆMINIUM's capabilities to express essential data structures. Our evaluation demonstrates that ÆMINIUM can be used to express parallelism in such data-structures and that the performance benefits scale with the amount of annotation effort which is put into the implementation. We chose an integral computationally example to evaluate pure functional programming and computational intensive use cases. Our experiments show that ÆMINIUM is capable of extracting parallelism from functional code and achieving performance improvements up to the limits of Plaid's inherent performance bounds.Overall, we hope that the work helps to advance concurrent programming in modern programming environments.","access permissions, concurrency, permissions, data groups",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Clebsch S,Franco J,Drossopoulou S,Yang AM,Wrigstad T,Vitek J",Orca: GC and Type System Co-Design for Actor Languages,Proc. ACM Program. Lang.,2017,1,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,,https://doi.org/10.1145/3133896;http://dx.doi.org/10.1145/3133896,10.1145/3133896,"ORCA is a concurrent and parallel garbage collector for actor programs, which does not require any STW steps, or synchronization mechanisms, and that has been designed to support zero-copy message passing and sharing of mutable data. ORCA is part of a runtime for actor-based languages, which was co-designed with the Pony programming language, and in particular, with its data race free type system. By co-designing an actor language with its runtime, it was possible to exploit certain language properties in order to optimize performance of garbage collection. Namely, ORCA relies on the guarantees of absence of race conditions in order to avoid read/write barriers, and it leverages the actor message passing, for synchronization among actors. In this paper we briefly describe Pony and its type system. We use pseudo-code in order to introduce how ORCA allocates and deallocates objects, how it shares mutable data without requiring barriers upon data mutation, and how can immutability be used to further optimize garbage collection. Moreover, we discuss the advantages of co-designing an actor language with its runtime, and we demonstrate that ORCA can be implemented in a performant and scalable way through a set of micro-benchmarks, including a comparison with other well-known collectors.","actors, messages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Carbone M,Montesi F",Deadlock-Freedom-by-Design: Multiparty Asynchronous Global Programming,,2013,,,263–274,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 40th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Rome, Italy",2013,9781450318327,,https://doi.org/10.1145/2429069.2429101;http://dx.doi.org/10.1145/2429069.2429101,10.1145/2429069.2429101,"Over the last decade, global descriptions have been successfully employed for the verification and implementation of communicating systems, respectively as protocol specifications and choreographies. In this work, we bring these two practices together by proposing a purely-global programming model. We show a novel interpretation of asynchrony and parallelism in a global setting and develop a typing discipline that verifies choreographies against protocol specifications, based on multiparty sessions. Exploiting the nature of global descriptions, our type system defines a new class of deadlock-free concurrent systems (deadlock-freedom-by-design), provides type inference, and supports session mobility. We give a notion of Endpoint Projection (EPP) which generates correct entity code (as pi-calculus terms) from a choreography. Finally, we evaluate our approach by providing a prototype implementation for a concrete programming language and by applying it to some examples from multicore and service-oriented programming.","concurrency, types, choreography, sessions",POPL '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Carbone M,Montesi F",Deadlock-Freedom-by-Design: Multiparty Asynchronous Global Programming,SIGPLAN Not.,2013,48,1,263–274,Association for Computing Machinery,"New York, NY, USA",,,,2013-01,,0362-1340,https://doi.org/10.1145/2480359.2429101;http://dx.doi.org/10.1145/2480359.2429101,10.1145/2480359.2429101,"Over the last decade, global descriptions have been successfully employed for the verification and implementation of communicating systems, respectively as protocol specifications and choreographies. In this work, we bring these two practices together by proposing a purely-global programming model. We show a novel interpretation of asynchrony and parallelism in a global setting and develop a typing discipline that verifies choreographies against protocol specifications, based on multiparty sessions. Exploiting the nature of global descriptions, our type system defines a new class of deadlock-free concurrent systems (deadlock-freedom-by-design), provides type inference, and supports session mobility. We give a notion of Endpoint Projection (EPP) which generates correct entity code (as pi-calculus terms) from a choreography. Finally, we evaluate our approach by providing a prototype implementation for a concrete programming language and by applying it to some examples from multicore and service-oriented programming.","types, concurrency, choreography, sessions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ahmed A,Appel AW,Richards CD,Swadi KN,Tan G,Wang DC",Semantic Foundations for Typed Assembly Languages,ACM Trans. Program. Lang. Syst.,2010,32,3,,Association for Computing Machinery,"New York, NY, USA",,,,2010-03,,0164-0925,https://doi.org/10.1145/1709093.1709094;http://dx.doi.org/10.1145/1709093.1709094,10.1145/1709093.1709094,"Typed Assembly Languages (TALs) are used to validate the safety of machine-language programs. The Foundational Proof-Carrying Code project seeks to verify the soundness of TALs using the smallest possible set of axioms: the axioms of a suitably expressive logic plus a specification of machine semantics. This article proposes general semantic foundations that permit modular proofs of the soundness of TALs. These semantic foundations include Typed Machine Language (TML), a type theory for specifying properties of low-level data with powerful and orthogonal type constructors, and Lc, a compositional logic for specifying properties of machine instructions with simplified reasoning about unstructured control flow. Both of these components, whose semantics we specify using higher-order logic, are useful for proving the soundness of TALs. We demonstrate this by using TML and Lc to verify the soundness of a low-level, typed assembly language, LTAL, which is the target of our core-ML-to-sparc compiler.To prove the soundness of the TML type system we have successfully applied a new approach, that of step-indexed logical relations. This approach provides the first semantic model for a type system with updatable references to values of impredicative quantified types. Both impredicative polymorphism and mutable references are essential when representing function closures in compilers with typed closure conversion, or when compiling objects to simpler typed primitives.","control flow, proof-carrying code, logical relations, semantic models, Typed assembly languages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Fairweather E,Fernández M",Typed Nominal Rewriting,ACM Trans. Comput. Logic,2018,19,1,,Association for Computing Machinery,"New York, NY, USA",,,,2018-02,,1529-3785,https://doi.org/10.1145/3161558;http://dx.doi.org/10.1145/3161558,10.1145/3161558,"Nominal terms extend first-order terms with nominal features and as such constitute a meta-language for reasoning about the named variables of an object language in the presence of meta-level variables. This article introduces a number of type systems for nominal terms of increasing sophistication and demonstrates their application in the areas of rewriting and equational reasoning. Two simple type systems inspired by Church’s simply typed lambda calculus are presented where only well-typed terms are considered to exist, over which α-equivalence is then axiomatised. The first requires atoms to be strictly annotated whilst the second explores the consequences of a more relaxed de Bruijn-style approach in the presence of atom-capturing substitution. A final type system of richer ML-like polymorphic types is then given in the style of Curry, in which elements of the term language are deemed typeable or not only subsequent to the definition of alpha-equivalence. Principal types are shown to exist and an inference algorithm given to compute them. This system is then used to define two presentations of typed nominal rewriting, one more expressive and one more efficient, the latter also giving rise to a notion of typed nominal equational reasoning.","Nominal syntax, nominal rewriting",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chaudhuri A,Naldurg P,Rajamani S",A Type System for Data-Flow Integrity on Windows Vista,SIGPLAN Not.,2009,43,12,9–20,Association for Computing Machinery,"New York, NY, USA",,,,2009-02,,0362-1340,https://doi.org/10.1145/1513443.1513447;http://dx.doi.org/10.1145/1513443.1513447,10.1145/1513443.1513447,"The Windows Vista operating system implements an interesting model of multi-level integrity. We observe that in this model, trusted code must participate in any information-flow attack. Thus, it is possible to eliminate such attacks by statically restricting trusted code. We formalize this model by designing a type system that can efficiently enforce data-flow integrity on Windows Vista. Typechecking guarantees that objects whose contents are statically trusted never contain untrusted values, regardless of what untrusted code runs in the environment. Some of Windows Vista's runtime access checks are necessary for soundness; others are redundant and can be optimized away.","explicit substitution, dynamic access control, hybrid type system, data-flow integrity",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Çiçek E,Paraskevopoulou Z,Garg D",A Type Theory for Incremental Computational Complexity with Control Flow Changes,,2016,,,132–145,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming,"Nara, Japan",2016,9781450342193,,https://doi.org/10.1145/2951913.2951950;http://dx.doi.org/10.1145/2951913.2951950,10.1145/2951913.2951950,"Incremental computation aims to speed up re-runs of a program after its inputs have been modified slightly. It works by recording a trace of the program's first run and propagating changes through the trace in incremental runs, trying to re-use as much of the original trace as possible. The recent work CostIt is a type and effect system to establish the time complexity of incremental runs of a program, as a function of input changes. However, CostIt is limited in two ways. First, it prohibits input changes that influence control flow. This makes it impossible to type programs that, for instance, branch on inputs that may change. Second, the soundness of CostIt is proved relative to an abstract cost semantics, but it is unclear how the semantics can be realized. In this paper, we address both these limitations. We present DuCostIt, a re-design of CostIt, that combines reasoning about costs of change propagation and costs of from-scratch evaluation. The latter lifts the restriction on control flow changes. To obtain the type system, we refine Flow Caml, a type system for information flow analysis, with cost effects. Additionally, we inherit from CostIt index refinements to track data structure sizes and a co-monadic type. Using a combination of binary and unary step-indexed logical relations, we prove DuCostIt's cost analysis sound relative to not only an abstract cost semantics, but also a concrete semantics, which is obtained by translation to an ML-like language.","Complexity analysis, incremental computation, type and effect systems",ICFP 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Çiçek E,Paraskevopoulou Z,Garg D",A Type Theory for Incremental Computational Complexity with Control Flow Changes,SIGPLAN Not.,2016,51,9,132–145,Association for Computing Machinery,"New York, NY, USA",,,,2016-09,,0362-1340,https://doi.org/10.1145/3022670.2951950;http://dx.doi.org/10.1145/3022670.2951950,10.1145/3022670.2951950,"Incremental computation aims to speed up re-runs of a program after its inputs have been modified slightly. It works by recording a trace of the program's first run and propagating changes through the trace in incremental runs, trying to re-use as much of the original trace as possible. The recent work CostIt is a type and effect system to establish the time complexity of incremental runs of a program, as a function of input changes. However, CostIt is limited in two ways. First, it prohibits input changes that influence control flow. This makes it impossible to type programs that, for instance, branch on inputs that may change. Second, the soundness of CostIt is proved relative to an abstract cost semantics, but it is unclear how the semantics can be realized. In this paper, we address both these limitations. We present DuCostIt, a re-design of CostIt, that combines reasoning about costs of change propagation and costs of from-scratch evaluation. The latter lifts the restriction on control flow changes. To obtain the type system, we refine Flow Caml, a type system for information flow analysis, with cost effects. Additionally, we inherit from CostIt index refinements to track data structure sizes and a co-monadic type. Using a combination of binary and unary step-indexed logical relations, we prove DuCostIt's cost analysis sound relative to not only an abstract cost semantics, but also a concrete semantics, which is obtained by translation to an ML-like language.","Complexity analysis, type and effect systems, incremental computation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chaudhuri A,Naldurg P,Rajamani S",A Type System for Data-Flow Integrity on Windows Vista,,2008,,,89–100,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third ACM SIGPLAN Workshop on Programming Languages and Analysis for Security,"Tucson, AZ, USA",2008,9781595939364,,https://doi.org/10.1145/1375696.1375708;http://dx.doi.org/10.1145/1375696.1375708,10.1145/1375696.1375708,"The Windows Vista operating system implements an interesting model of multi-level integrity. We observe that in this model, trusted code must participate in any information-flow attack. Thus, it is possible to eliminate such attacks by statically restricting trusted code. We formalize this model by designing a type system that can efficiently enforce data-flow integrity on Windows Vista. Typechecking guarantees that objects whose contents are statically trusted never contain untrusted values, regardless of what untrusted code runs in the environment. Some of Windows Vista's runtime access checks are necessary for soundness; others are redundant and can be optimized away.","hybrid type system, explicit substitution, dynamic access control, data-flow integrity",PLAS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ivašković A,Mycroft A",A Graded Monad for Deadlock-Free Concurrency (Functional Pearl),,2020,,,17–30,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM SIGPLAN International Symposium on Haskell,"Virtual Event, USA",2020,9781450380508,,https://doi.org/10.1145/3406088.3409024;http://dx.doi.org/10.1145/3406088.3409024,10.1145/3406088.3409024,"We present a new type-oriented framework for writing shared memory multithreaded programs that the Haskell type system guarantees are deadlock-free. The implementation wraps all concurrent computation inside a graded monad and assumes a total order is defined between locks. The grades within the type of such a computation specify which locks it acquires and releases. This information is drawn from an algebra that ensures that types can, in principle, be inferred in polynomial time.","concurrency, deadlock, graded monads, synchronization",Haskell 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hammer MA,Chang BY,Van Horn D",A Vision for Online Verification-Validation,,2016,,,190–201,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 ACM SIGPLAN International Conference on Generative Programming: Concepts and Experiences,"Amsterdam, Netherlands",2016,9781450344463,,https://doi.org/10.1145/2993236.2993255;http://dx.doi.org/10.1145/2993236.2993255,10.1145/2993236.2993255,"Today's programmers face a false choice between creating software that is extensible and software that is correct. Specifically, dynamic languages permit software that is richly extensible (via dynamic code loading, dynamic object extension, and various forms of reflection), and today's programmers exploit this flexibility to \bring their own language features\"" to enrich extensible languages (e.g.",by using common JavaScript libraries). Meanwhile,such library-based language extensions generally lack enforcement of their abstractions,leading to programming errors that are complex to avoid and predict. To offer verification for this extensible world,we propose online verification-validation (OVV),"which consists of language and VM design that enables a \""phaseless\"" approach to program analysis",in contrast to the standard static-dynamic phase distinction. Phaseless analysis freely interposes abstract interpretation with concrete execution,allowing analyses to use dynamic (concrete) information to prove universal (abstract) properties about future execution. In this paper,we present a conceptual overview of OVV through a motivating example program that uses a hypothetical database library. We present a generic semantics for OVV,and an extension to this semantics that offers a simple gradual type system for the database library primitives. The result of instantiating this gradual type system in an OVV setting is a checker that can progressively type successive continuations of the program until a continuation is fully verified. To evaluate the proposed vision of OVV for this example,we implement the VM semantics (in Rust),"and show that this design permits progressive typing in this manner.""","Call-by-Push-Value (CBPV), Online Verification-Validation, Phaseless Analysis, Exists Analysis, For-all Analysis, Type Systems, Virtual Machines",GPCE 2016,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Hammer MA,Chang BY,Van Horn D",A Vision for Online Verification-Validation,SIGPLAN Not.,2016,52,3,190–201,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,0362-1340,https://doi.org/10.1145/3093335.2993255;http://dx.doi.org/10.1145/3093335.2993255,10.1145/3093335.2993255,"Today's programmers face a false choice between creating software that is extensible and software that is correct. Specifically, dynamic languages permit software that is richly extensible (via dynamic code loading, dynamic object extension, and various forms of reflection), and today's programmers exploit this flexibility to \bring their own language features\"" to enrich extensible languages (e.g.",by using common JavaScript libraries). Meanwhile,such library-based language extensions generally lack enforcement of their abstractions,leading to programming errors that are complex to avoid and predict. To offer verification for this extensible world,we propose online verification-validation (OVV),"which consists of language and VM design that enables a \""phaseless\"" approach to program analysis",in contrast to the standard static-dynamic phase distinction. Phaseless analysis freely interposes abstract interpretation with concrete execution,allowing analyses to use dynamic (concrete) information to prove universal (abstract) properties about future execution. In this paper,we present a conceptual overview of OVV through a motivating example program that uses a hypothetical database library. We present a generic semantics for OVV,and an extension to this semantics that offers a simple gradual type system for the database library primitives. The result of instantiating this gradual type system in an OVV setting is a checker that can progressively type successive continuations of the program until a continuation is fully verified. To evaluate the proposed vision of OVV for this example,we implement the VM semantics (in Rust),"and show that this design permits progressive typing in this manner.""","Type Systems, Online Verification-Validation, Phaseless Analysis, Virtual Machines, Exists Analysis, Call-by-Push-Value (CBPV), For-all Analysis",,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pientka B,Dunfield J",Programming with Proofs and Explicit Contexts,,2008,,,163–173,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International ACM SIGPLAN Conference on Principles and Practice of Declarative Programming,"Valencia, Spain",2008,9781605581170,,https://doi.org/10.1145/1389449.1389469;http://dx.doi.org/10.1145/1389449.1389469,10.1145/1389449.1389469,"This paper explores a new point in the design space of functional programming: functional programming with dependently-typed higher-order data structures described in the logical framework LF. This allows us to program with proofs as higher-order data. We present a decidable bidirectional type system that distinguishes between dependently-typed data and computations. To support reasoning about open data, our foundation makes contexts explicit. This provides us with a concise characterization of open data, which is crucial to elegantly describe proofs. In addition, we present an operational semantics for this language based on higherorder pattern matching for dependently typed objects. Based on this development, we prove progress and preservation","dependent types, logical frameworks, type theory",PPDP '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Shih TK,Specification and Implementation of Reusable Multimedia Presentations,,1997,,,257–264,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th Annual Southeast Regional Conference,"Murfreesboro, Tennessee",1997,9780897919258,,https://doi.org/10.1145/2817460.2817526;http://dx.doi.org/10.1145/2817460.2817526,10.1145/2817460.2817526,"In this paper, we present the specification and implementation of a multimedia presentation database, which supports the reuse of many kinds of multimedia objects. A formal specification of the presentation database is introduced. The implementation of database and complexities are addressed. The main strength of our system is in a reuse mechanism, which allows the inheritance of multimedia properties and the instantiation of new multimedia objects, as well as large binary data sharing. The proposed system is implemented on the Microsoft Windows 95.","multimedia database, object reuse",ACM-SE 35,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Pientka B,A Type-Theoretic Foundation for Programming with Higher-Order Abstract Syntax and First-Class Substitutions,,2008,,,371–382,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"San Francisco, California, USA",2008,9781595936899,,https://doi.org/10.1145/1328438.1328483;http://dx.doi.org/10.1145/1328438.1328483,10.1145/1328438.1328483,"Higher-order abstract syntax (HOAS) is a simple, powerful technique for implementing object languages, since it directly supports common and tricky routines dealing with variables, such as capture-avoiding substitution and renaming. This is achieved by representing binders in the object-language via binders in the meta-language. However, enriching functional programming languages with direct support for HOAS has been a major challenge, because recursion over HOAS encodings requires one to traverse lambda-abstractions and necessitates programming with open objects.We present a novel type-theoretic foundation based on contextual modal types which allows us to recursively analyze open terms via higher-order pattern matching. By design, variables occurring in open terms can never escape their scope. Using several examples, we demonstrate that our framework provides a name-safe foundation to operations typically found in nominal systems. In contrast to nominal systems however, we also support capture-avoiding substitution operations and even provide first-class substitutions to the programmer. The main contribution of this paper is a syntax-directed bi-directional type system where we distinguish between the data language and the computation language together with the progress and preservation proof for our language.","type system, logical frameworks",POPL '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Pientka B,A Type-Theoretic Foundation for Programming with Higher-Order Abstract Syntax and First-Class Substitutions,SIGPLAN Not.,2008,43,1,371–382,Association for Computing Machinery,"New York, NY, USA",,,,2008-01,,0362-1340,https://doi.org/10.1145/1328897.1328483;http://dx.doi.org/10.1145/1328897.1328483,10.1145/1328897.1328483,"Higher-order abstract syntax (HOAS) is a simple, powerful technique for implementing object languages, since it directly supports common and tricky routines dealing with variables, such as capture-avoiding substitution and renaming. This is achieved by representing binders in the object-language via binders in the meta-language. However, enriching functional programming languages with direct support for HOAS has been a major challenge, because recursion over HOAS encodings requires one to traverse lambda-abstractions and necessitates programming with open objects.We present a novel type-theoretic foundation based on contextual modal types which allows us to recursively analyze open terms via higher-order pattern matching. By design, variables occurring in open terms can never escape their scope. Using several examples, we demonstrate that our framework provides a name-safe foundation to operations typically found in nominal systems. In contrast to nominal systems however, we also support capture-avoiding substitution operations and even provide first-class substitutions to the programmer. The main contribution of this paper is a syntax-directed bi-directional type system where we distinguish between the data language and the computation language together with the progress and preservation proof for our language.","logical frameworks, type system",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Beckman NE,Bierhoff K,Aldrich J",Verifying Correct Usage of Atomic Blocks and Typestate,,2008,,,227–244,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582153,,https://doi.org/10.1145/1449764.1449783;http://dx.doi.org/10.1145/1449764.1449783,10.1145/1449764.1449783,"The atomic block, a synchronization primitive provided to programmers in transactional memory systems, has the potential to greatly ease the development of concurrent software. However, atomic blocks can still be used incorrectly, and race conditions can still occur at the level of application logic. In this paper, we present a intraprocedural static analysis, formalized as a type system and proven sound, that helps programmers use atomic blocks correctly. Using access permissions, which describe how objects are aliased and modified, our system statically prevents race conditions and enforces typestate properties in concurrent programs. We have implemented a prototype static analysis for the Java language based on our system and have used it to verify several realistic examples.","permissions, typestate, transactional memory",OOPSLA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Beckman NE,Bierhoff K,Aldrich J",Verifying Correct Usage of Atomic Blocks and Typestate,SIGPLAN Not.,2008,43,10,227–244,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,0362-1340,https://doi.org/10.1145/1449955.1449783;http://dx.doi.org/10.1145/1449955.1449783,10.1145/1449955.1449783,"The atomic block, a synchronization primitive provided to programmers in transactional memory systems, has the potential to greatly ease the development of concurrent software. However, atomic blocks can still be used incorrectly, and race conditions can still occur at the level of application logic. In this paper, we present a intraprocedural static analysis, formalized as a type system and proven sound, that helps programmers use atomic blocks correctly. Using access permissions, which describe how objects are aliased and modified, our system statically prevents race conditions and enforces typestate properties in concurrent programs. We have implemented a prototype static analysis for the Java language based on our system and have used it to verify several realistic examples.","typestate, transactional memory, permissions",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Haque R,Richards D",Optimizing PGAS Overhead in a Multi-Locale Chapel Implementation of CoMD,,2016,,,25–32,IEEE Press,"Salt Lake City, Utah",,Proceedings of the First Workshop on PGAS Applications,,2016,9781509052141,,,,"Chapel supports distributed computing with an underlying PGAS memory address space. While it provides abstractions for writing simple and elegant distributed code, the type system currently lacks a notion of locality i.e. a description of an object's access behavior in relation to its actual location. This often necessitates programmer intervention to avoid redundant non-local data access. Moreover, due to insufficient locality information the compiler ends up using \wide\"" pointers---that can point to non-local data---for objects referenced in an otherwise completely local manner",adding to the runtime overhead.In this work we describe CoMD-Chapel,our distributed Chapel implementation of the CoMD benchmark. We demonstrate that optimizing data access through replication and localization is crucial for achieving performance comparable to the reference implementation. We discuss limitations of existing scope-based locality optimizations and argue instead for a more general (and robust) type-based approach. Lastly,"we also evaluate code performance and scaling characteristics. The fully optimized version of CoMD-Chapel can perform to within 62%--87% of the reference implementation.""","locality, distributed computing, parallel programming, chapel, CoMD, PGAS",PAW '16,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Nuyts A,Vezzosi A,Devriese D",Parametric Quantifiers for Dependent Type Theory,Proc. ACM Program. Lang.,2017,1,ICFP,,Association for Computing Machinery,"New York, NY, USA",,,,2017-08,,,https://doi.org/10.1145/3110276;http://dx.doi.org/10.1145/3110276,10.1145/3110276,"Polymorphic type systems such as System F enjoy the parametricity property: polymorphic functions cannot inspect their type argument and will therefore apply the same algorithm to any type they are instantiated on. This idea is formalized mathematically in Reynolds's theory of relational parametricity, which allows the metatheoretical derivation of parametricity theorems about all values of a given type. Although predicative System F embeds into dependent type systems such as Martin-Löf Type Theory (MLTT), parametricity does not carry over as easily. The identity extension lemma, which is crucial if we want to prove theorems involving equality, has only been shown to hold for small types, excluding the universe. We attribute this to the fact that MLTT uses a single type former Π to generalize both the parametric quantifier ∀ and the type former → which is non-parametric in the sense that its elements may use their argument as a value. We equip MLTT with parametric quantifiers ∀ and ∃ alongside the existing Π and Σ, and provide relation type formers for proving parametricity theorems internally. We show internally the existence of initial algebras and final co-algebras of indexed functors both by Church encoding and, for a large class of functors, by using sized types. We prove soundness of our type system by enhancing existing iterated reflexive graph (cubical set) models of dependently typed parametricity by distinguishing between edges that express relatedness of objects (bridges) and edges that express equality (paths). The parametric functions are those that map bridges to paths. We implement an extension to the Agda proof assistant that type-checks proofs in our type system.","presheaf semantics, Agda, cubical type theory, sized types, Parametricity",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Alhadidi D,Boukhtouta A,Belblidia N,Debbabi M,Bhattacharya P",The Dataflow Pointcut: A Formal and Practical Framework,,2009,,,15–26,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM International Conference on Aspect-Oriented Software Development,"Charlottesville, Virginia, USA",2009,9781605584423,,https://doi.org/10.1145/1509239.1509244;http://dx.doi.org/10.1145/1509239.1509244,10.1145/1509239.1509244,"Some security concerns are sensitive to flow of information in a program execution. The dataflow pointcut has been proposed by Masuhara and Kawauchi in order to easily implement such security concerns in aspect-oriented programming (AOP) languages. The pointcut identifies join points based on the origins of values. This paper presents a formal framework for this pointcut based on the λ_calculus. Dataflow tags are propagated statically to track data dependencies between expressions. We introduce a static semantics for tag propagation and prove that it is consistent with respect to the dynamic semantics of the propagation. We instrument the static effect-based type system to propagate tags, match and inject advices. This static approach can be used to minimize the cost of dataflow pointcuts by reducing the runtime overhead since much of the dataflow information would be available statically and at the same time it can be used for verification. The proposed semantics for advice weaving is in the spirit of AspectJ where advices are injected before, after, or around the join points that are matched by their respective pointcuts. Inspired from the formal framework, the AspectJ compiler ajc is extended with the dataflow pointcut that tracks data dependencies inside methods.","aspect-oriented programming, dataflow analysis, type theory",AOSD '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Elsman M,Henriksen T,Annenkov D,Oancea CE",Static Interpretation of Higher-Order Modules in Futhark: Functional GPU Programming in the Large,Proc. ACM Program. Lang.,2018,2,ICFP,,Association for Computing Machinery,"New York, NY, USA",,,,2018-07,,,https://doi.org/10.1145/3236792;http://dx.doi.org/10.1145/3236792,10.1145/3236792,"We present a higher-order module system for the purely functional data-parallel array language Futhark. The module language has the property that it is completely eliminated at compile time, yet it serves as a powerful tool for organizing libraries and complete programs. The presentation includes a static and a dynamic semantics for the language in terms of, respectively, a static type system and a provably terminating elaboration of terms into terms of an underlying target language. The development is formalised in Coq using a novel encoding of semantic objects based on products, sets, and finite maps. The module language features a unified treatment of module type abstraction and core language polymorphism and is rich enough for expressing practical forms of module composition.","GPGPU, functional languages, compilers, modules",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"De Fraine B,Südholt M,Jonckers V",StrongAspectJ: Flexible and Safe Pointcut/Advice Bindings,,2008,,,60–71,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Aspect-Oriented Software Development,"Brussels, Belgium",2008,9781605580449,,https://doi.org/10.1145/1353482.1353491;http://dx.doi.org/10.1145/1353482.1353491,10.1145/1353482.1353491,"AspectJ was designed as a seamless aspect-oriented extension of the Java programming language. However, unlike Java, AspectJ does not have a safe type system: an accepted binding between a pointcut and an advice can give rise to type errors at runtime. In addition, AspectJ's typing rules severely restrict the definition of certain generic advice behavior.In this paper, we analyze the roots of these type errors, and describe measures to recover type safety for both generic and non-generic pointcut/advice declarations. Pointcuts quantify over heterogeneous sets of join points and are hence typed using type ranges in our approach, while type variables and a dual advice signature allow to express the generic and invasive nature of advices. Using these mechanisms, we can express advice that augments, narrows or replaces base functionality in possibly generic contexts. As a language engineering contribution, we integrate our proposal with the AspectJ language, and we provide a prototype implementation as a plugin for the AspectBench Compiler (abc). On a theoretical level, we present a formal definition of the proposed constructs and typing rules, and develop proofs for their type safety properties.",,AOSD '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pouyanrad S,Mühlberg JT,Joosen W",SCF<sup>MSP</sup>: Static Detection of Side Channels in MSP430 Programs,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 15th International Conference on Availability, Reliability and Security","Virtual Event, Ireland",2020,9781450388337,,https://doi.org/10.1145/3407023.3407050;http://dx.doi.org/10.1145/3407023.3407050,10.1145/3407023.3407050,"Information leakage through side-channels poses a serious threat to the security of distributed systems. Recent research on countermeasures against side-channel attacks show that, on embedded platforms with predictable execution times, certain classes of these vulnerabilities can be detected and mitigated automatically by means of language-based security techniques. In this paper, we propose a security type system to statically analyse MSP430 assembly programs to detecting information leakage through novel interrupt-latency attacks (a.k.a. Nemesis), timing side-channels, and undesired information flow. We have implemented our technique in a tool, Side Channel FinderMSP, which automatically verifies MSP430 object-code programs to be free of such vulnerabilities. We evaluate the effectiveness of our tool by applying it to a representative set of vulnerable and benign programs. Our experiments demonstrate that the tool is both effective in detecting vulnerabilities, and scalable to realistic applications.","embedded devices, static analysis, side channel analysis, assembly programs, MSP430, nemesis attack, language-based security",ARES '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Thomas DB,Fleming ST,Constantinides GA,Ghica DR",Transparent Linking of Compiled Software and Synthesized Hardware,,2015,,,1084–1089,EDA Consortium,"San Jose, CA, USA",,"Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition","Grenoble, France",2015,9783981537048,,,,"Modern heterogeneous devices contain tightly coupled CPU and FPGA logic, allowing low latency access to accelerators. However, designers of the system need to treat accelerated functions specially, with device specific code for instantiating, configuring, and executing accelerators. We present a system level linker, which allows functions in hardware and software to be linked together to create heterogeneous systems. The linker works with post-compilation and post-synthesis components, allowing the designer to transparently move functions between devices simply by linking in either hardware or software object files. The linker places no special emphasis on the software, allowing computation to be initiated from within hardware, with function calls to software to provide services such as file access. A strong type-system ensures that individual code artifacts can be written using the conventions of that domain (C, HLS, VHDL), while allowing direct and transparent linking.",,DATE '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Slaughter E,Lee W,Treichler S,Bauer M,Aiken A",Regent: A High-Productivity Programming Language for HPC with Logical Regions,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the International Conference for High Performance Computing, Networking, Storage and Analysis","Austin, Texas",2015,9781450337236,,https://doi.org/10.1145/2807591.2807629;http://dx.doi.org/10.1145/2807591.2807629,10.1145/2807591.2807629,"We present Regent, a high-productivity programming language for high performance computing with logical regions. Regent users compose programs with tasks (functions eligible for parallel execution) and logical regions (hierarchical collections of structured objects). Regent programs appear to execute sequentially, require no explicit synchronization, and are trivially deadlock-free. Regent's type system catches many common classes of mistakes and guarantees that a program with correct serial execution produces identical results on parallel and distributed machines.We present an optimizing compiler for Regent that translates Regent programs into efficient implementations for Legion, an asynchronous task-based model. Regent employs several novel compiler optimizations to minimize the dynamic overhead of the runtime system and enable efficient operation. We evaluate Regent on three benchmark applications and demonstrate that Regent achieves performance comparable to hand-tuned Legion.","task-based, Regent, logical regions, legion, runtimes",SC '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gerakios P,Biboudis A,Smaragdakis Y",Forsaking Inheritance: Supercharged Delegation in DelphJ,,2013,,,233–252,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages & Applications,"Indianapolis, Indiana, USA",2013,9781450323741,,https://doi.org/10.1145/2509136.2509535;http://dx.doi.org/10.1145/2509136.2509535,10.1145/2509136.2509535,"We propose DelphJ: a Java-based OO language that eschews inheritance completely, in favor of a combination of class morphing and (deep) delegation. Compared to past delegation approaches, the novel aspect of our design is the ability to emulate the best aspects of inheritance while retaining maximum flexibility: using morphing, a class can select any of the methods of its delegatee and export them (if desired) or transform them (e.g., to add extra arguments or modify type signatures), yet without needing to name these methods explicitly and handle them one-by-one. Compared to past work on morphing, our approach adopts and adapts advanced delegation mechanisms, in order to add late binding capabilities and, thus, provide a full substitute of inheritance. Additionally, we explore complex semantic issues in the interaction of delegation with late binding. We present our language design both informally, with numerous examples, and formally in a core calculus.","meta-programming, static reflection, language extensions, object composition, delegation, morphing",OOPSLA '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gerakios P,Biboudis A,Smaragdakis Y",Forsaking Inheritance: Supercharged Delegation in DelphJ,SIGPLAN Not.,2013,48,10,233–252,Association for Computing Machinery,"New York, NY, USA",,,,2013-10,,0362-1340,https://doi.org/10.1145/2544173.2509535;http://dx.doi.org/10.1145/2544173.2509535,10.1145/2544173.2509535,"We propose DelphJ: a Java-based OO language that eschews inheritance completely, in favor of a combination of class morphing and (deep) delegation. Compared to past delegation approaches, the novel aspect of our design is the ability to emulate the best aspects of inheritance while retaining maximum flexibility: using morphing, a class can select any of the methods of its delegatee and export them (if desired) or transform them (e.g., to add extra arguments or modify type signatures), yet without needing to name these methods explicitly and handle them one-by-one. Compared to past work on morphing, our approach adopts and adapts advanced delegation mechanisms, in order to add late binding capabilities and, thus, provide a full substitute of inheritance. Additionally, we explore complex semantic issues in the interaction of delegation with late binding. We present our language design both informally, with numerous examples, and formally in a core calculus.","meta-programming, object composition, static reflection, language extensions, morphing, delegation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gräter F,Götz S,Stecklina J",Predicate-C: An Efficient and Generic Runtime System for Predicate Dispatch,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 6th Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems","Lancaster, United Kingdom",2011,9781450308946,,https://doi.org/10.1145/2069172.2069174;http://dx.doi.org/10.1145/2069172.2069174,10.1145/2069172.2069174,"Dynamically typed languages like Ruby [19] recently gained a growing popularity due to the simplification of unforeseen software extensibility. Extensibility is typically driven by method dispatch which in turn uses the type system to classify objects. Common type systems only support type classifications attached to objects in advance of a method call. By that, the applicability of methods can be only described using existing classifications limiting the generic reuse of methods. Furthermore, it is difficult to classify objects by dynamic conditions according to their runtime state or current execution context. As an alternative, predicate dispatching allows the dispatch of methods on arbitrary predicates. Criteria for applicability are directly bound to methods enabling a flexible classification of objects. However, existing solutions for predicate dispatch suffer from co-NP-completeness. Furthermore, these solutions depend on high-level programming languages, which limits a system-wide and cross-language application of predicate dispatch. In this work, we present Predicate-C, a runtime environment that provides predicate dispatch with polynomial dispatching overhead. It is implemented as a lightweight C library that can be integrated into arbitrary runtime environments.","predicate dispatch, method dispatching, dynamic type systems",ICOOOLPS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Militão F,Aldrich J,Caires L",Aliasing Control with View-Based Typestate,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Workshop on Formal Techniques for Java-Like Programs,"Maribor, Slovenia",2010,9781450305402,,https://doi.org/10.1145/1924520.1924527;http://dx.doi.org/10.1145/1924520.1924527,10.1145/1924520.1924527,"Tracking the state of an object (in the sense of how a File can be in an Open or Closed state) is difficult not just because of the problem of managing state transitions but also due to the complexity introduced by aliasing. Unchecked duplication of object references makes local reasoning impossible by allowing situations where transitions can be triggered unexpectedly (for instance, passing aliased parameters to a method that expects unaliased parameters, or calling a method that has a side effect through an alias deeply nested in a data structure).We propose a generalization of access permissions that goes beyond a fixed set of permissions to an object. In this paper we present a new aliasing control mechanism that uses a small set of permissions as building block for the creation of views that capture a projection of an object with specific access constraints to its fields and/or methods. This makes permission tracking more fine grained while also making the designer's intent more explicit.We present a few meaningful examples of how these views handle situations such as: separating different sections of an object for safe initialization; and access with either an unbounded number of readers or a single writer (multiple readers or unique writer). Finally, we show a type system for checking correctness of state use in the presence of this kind of controlled aliasing.","aliasing control, view typestate",FTFJP '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chen X,Roşu G",A General Approach to Define Binders Using Matching Logic,Proc. ACM Program. Lang.,2020,4,ICFP,,Association for Computing Machinery,"New York, NY, USA",,,,2020-08,,,https://doi.org/10.1145/3408970;http://dx.doi.org/10.1145/3408970,10.1145/3408970,"We propose a novel definition of binders using matching logic, where the binding behavior of object-level binders is directly inherited from the built-in exists binder of matching logic. We show that the behavior of binders in various logical systems such as lambda-calculus, System F, pi-calculus, pure type systems, can be axiomatically defined in matching logic as notations and logical theories. We show the correctness of our definitions by proving conservative extension theorems, which state that a sequent/judgment is provable in the original system if and only if it is provable in matching logic, in the corresponding theory. Our matching logic definition of binders also yields models to all binders, which are deductively complete with respect to formal reasoning in the original systems. For lambda-calculus, we further show that the yielded models are representationally complete, a desired property that is not enjoyed by many existing lambda-calculus semantics. This work is part of a larger effort to develop a logical foundation for the programming language semantics framework K (http://kframework.org).","completeness, conservative extension, matching logic, binders",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Castegren E,Clarke D,Fernandez-Reyes K,Wrigstad T,Yang AM",Attached and Detached Closures in Actors,,2018,,,54–61,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 8th ACM SIGPLAN International Workshop on Programming Based on Actors, Agents, and Decentralized Control","Boston, MA, USA",2018,9781450360661,,https://doi.org/10.1145/3281366.3281371;http://dx.doi.org/10.1145/3281366.3281371,10.1145/3281366.3281371,"Expressive actor models combine aspects of functional programming into the pure actor model enriched with futures. Such functional features include first-class closures which can be passed between actors and chained on futures. Combined with mutable objects, this opens the door to race conditions. In some situations, closures may not be evaluated by the actor that created them yet may access fields or objects owned by that actor. In other situations, closures may be safely fired off to run as a separate task. This paper discusses the problem of who can safely evaluate a closure to avoid race conditions, and presents the current solution to the problem adopted by the Encore language. The solution integrates with Encore's capability type system, which influences whether a closure is attached and must be evaluated by the creating actor, or whether it can be detached and evaluated independently of its creator. Encore's current solution to this problem is not final or optimal. We conclude by discussing a number of open problems related to dealing with closures in the actor model.","closures, parallel programming, concurrent programming, type systems",AGERE 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Hutchins DS,Pure Subtype Systems,,2010,,,287–298,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Madrid, Spain",2010,9781605584799,,https://doi.org/10.1145/1706299.1706334;http://dx.doi.org/10.1145/1706299.1706334,10.1145/1706299.1706334,"This paper introduces a new approach to type theory called pure subtype systems . Pure subtype systems differ from traditional approaches to type theory (such as pure type systems) because the theory is based on subtyping, rather than typing. Proper types and typing are completely absent from the theory; the subtype relation is defined directly over objects. The traditional typing relation is shown to be a special case of subtyping, so the loss of types comes without any loss of generality.Pure subtype systems provide a uniform framework which seamlessly integrates subtyping with dependent and singleton types. The framework was designed as a theoretical foundation for several problems of practical interest, including mixin modules, virtual classes, and feature-oriented programming.The cost of using pure subtype systems is the complexity of the meta-theory. We formulate the subtype relation as an abstract reduction system, and show that the theory is sound if the underlying reductions commute. We are able to show that the reductions commute locally, but have thus far been unable to show that they commute globally. Although the proof is incomplete, it is ``close enough'' to rule out obvious counter-examples. We present it as an open problem in type theory.","subtyping, transitivity elimination, abstract reduction systems, dependent types, singleton types",POPL '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Hutchins DS,Pure Subtype Systems,SIGPLAN Not.,2010,45,1,287–298,Association for Computing Machinery,"New York, NY, USA",,,,2010-01,,0362-1340,https://doi.org/10.1145/1707801.1706334;http://dx.doi.org/10.1145/1707801.1706334,10.1145/1707801.1706334,"This paper introduces a new approach to type theory called pure subtype systems . Pure subtype systems differ from traditional approaches to type theory (such as pure type systems) because the theory is based on subtyping, rather than typing. Proper types and typing are completely absent from the theory; the subtype relation is defined directly over objects. The traditional typing relation is shown to be a special case of subtyping, so the loss of types comes without any loss of generality.Pure subtype systems provide a uniform framework which seamlessly integrates subtyping with dependent and singleton types. The framework was designed as a theoretical foundation for several problems of practical interest, including mixin modules, virtual classes, and feature-oriented programming.The cost of using pure subtype systems is the complexity of the meta-theory. We formulate the subtype relation as an abstract reduction system, and show that the theory is sound if the underlying reductions commute. We are able to show that the reductions commute locally, but have thus far been unable to show that they commute globally. Although the proof is incomplete, it is ``close enough'' to rule out obvious counter-examples. We present it as an open problem in type theory.","subtyping, abstract reduction systems, dependent types, transitivity elimination, singleton types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rapoport M,Lhoták O",Mutable WadlerFest DOT,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th Workshop on Formal Techniques for Java-like Programs,"Barcelona, Spain",2017,9781450350983,,https://doi.org/10.1145/3103111.3104036;http://dx.doi.org/10.1145/3103111.3104036,10.1145/3103111.3104036,"The Dependent Object Types (DOT) calculus aims to model the essence of Scala, with a focus on abstract type members, path-dependent types, and subtyping. Other Scala features could be defined by translation to DOT.Mutation is a fundamental feature of Scala currently missing in DOT. Mutation in DOT is needed not only to model effectful computation and mutation in Scala programs, but even to precisely specify how Scala initializes immutable variables and fields (vals).We present an extension to DOT that adds typed mutable reference cells. We have proven the extension sound with a mechanized proof in Coq. We present the key features of our extended calculus and its soundness proof, and discuss the challenges that we encountered in our search for a sound design and the alternative solutions that we considered.",,FTFJP'17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Slepak J,Manolios P,Shivers O",Rank Polymorphism Viewed as a Constraint Problem,,2018,,,34–41,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 5th ACM SIGPLAN International Workshop on Libraries, Languages, and Compilers for Array Programming","Philadelphia, PA, USA",2018,9781450358521,,https://doi.org/10.1145/3219753.3219758;http://dx.doi.org/10.1145/3219753.3219758,10.1145/3219753.3219758,"Rank polymorphism serves as a type of control flow used in array-oriented languages, where functions are automatically lifted to operate on high-dimensional arguments. The iteration space is derived directly from the shape of the data, presenting a challenge to compilation. A type system can characterize data shape, though the level of detail is beyond what can be reasonably expected from entirely human-generated annotations. The task of checking or inferring shapes can be phrased as solving constraints in the theory of the free monoid over the natural numbers, but the constraints involve both universal and existential quantification. Here is a plan of attack for leveraging past work on decision procedures, which has generally focused on the purely existential fragment of the theory.","word equations, array-oriented languages, indexed types, free monoid, first-order logic, type inference",ARRAY 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sottile MJ,Hulette GC,Malony AD",Workflow Representation and Runtime Based on Lazy Functional Streams,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th Workshop on Workflows in Support of Large-Scale Science,"Portland, Oregon",2009,9781605587172,,https://doi.org/10.1145/1645164.1645174;http://dx.doi.org/10.1145/1645164.1645174,10.1145/1645164.1645174,"Workflows are a successful model for building both distributed and tightly-coupled programs based on a dataflow-oriented coordination of computations. Multiple programming languages have been proposed to represent workflow-based programs in the past. In this paper, we discuss a representation of workflows based on lazy functional streams implemented in the strongly typed language Haskell. Our intent is to demonstrate that streams are an expressive intermediate representation for higher-level workflow languages. By embedding our stream-based workflow representation in a language such as Haskell, we also gain with minimal effort the strong type system provided by the base language, the rich library of built-in functional primitives, and most recently, rich support for managing concurrency at the language level.",,WORKS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Baazizi MA,Colazzo D,Ghelli G,Sartiani C",Counting Types for Massive JSON Datasets,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of The 16th International Symposium on Database Programming Languages,"Munich, Germany",2017,9781450353540,,https://doi.org/10.1145/3122831.3122837;http://dx.doi.org/10.1145/3122831.3122837,10.1145/3122831.3122837,"Type systems express structural information about data, are human readable and hence crucial for understanding code, and are endowed with a formal definition that makes them a fundamental tool when proving program properties. Internal data structures of a database store quantitative information about data, information that is essential for optimization purposes, but is not used for documentation or for correctness proofs. In this paper we propose a new idea: raising a part of the quantitative information from the system-level structures to the type level.Our proposal is motivated by the problem of schema inference for massive collections of JSON data, which are nowadays often collected from external sources and stored in NoSQL systems without an a-priori schema, which makes a-posteriori schema inference extremely useful. NoSQL systems are oriented towards the management of heterogeneous data, and in this context we claim that quantitative information is important in order to assess the relative weight of different variants.We propose a type system where the same collection can be described at different levels of abstraction. Different abstraction levels are useful for different purposes, hence we describe a parametric inference mechanism, where a single parameter specifies the chosen trade-off between succinctness and precision for the inferred type. This algorithm is designed for massive JSON collection, and hence admits a simple and efficient map-reduce implementation.","type systems, descriptive schemas, map-reduce, JSON, schema inference",DBPL '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chu CX,Razniewski S,Weikum G",ENTYFI: Entity Typing in Fictional Texts,,2020,,,124–132,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th International Conference on Web Search and Data Mining,"Houston, TX, USA",2020,9781450368223,,https://doi.org/10.1145/3336191.3371808;http://dx.doi.org/10.1145/3336191.3371808,10.1145/3336191.3371808,"Fiction and fantasy are archetypes of long-tail domains that lack comprehensive methods for automated language processing and knowledge extraction. We present ENTYFI, the first methodology for typing entities in fictional texts coming from books, fan communities or amateur writers. ENTYFI builds on 205 automatically induced high-quality type systems for popular fictional domains, and exploits the overlap and reuse of these fictional domains for fine-grained typing in previously unseen texts. ENTYFI comprises five steps: type system induction, domain relatedness ranking, mention detection, mention typing, and type consolidation. The recall-oriented typing module combines a supervised neural model, unsupervised Hearst-style and dependency patterns, and knowledge base lookups. The precision-oriented consolidation stage utilizes co-occurrence statistics in order to remove noise and to identify the most relevant types. Extensive experiments on newly seen fictional texts demonstrate the quality of ENTYFI.","named entity recognition, knowledge acquisition, entity typing, fictional domains, neural networks",WSDM '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Browning S,"Cryptol, a DSL for Cryptographic Algorithms",,2010,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGPLAN Commercial Users of Functional Programming,"Baltimore, Maryland",2010,9781450305167,,https://doi.org/10.1145/1900160.1900171;http://dx.doi.org/10.1145/1900160.1900171,10.1145/1900160.1900171,"Cryptol is a domain-specific functional language designed by Galois, Inc in collaboration with the the NSA for specifying cryptographic algorithms. The Cryptol language includes native support for arbitrary sized words, a strong type-system based on Hindley-Milner style polymorphism extended with arithmetic size constraints, and the ability to generate proof-objects throughout the compiler toolchain to provide correctness evidence that can be independently verified. In addition, high-level specification is fully executable. The accompanying toolset provides a rich set of translators that can produce both hardware and software implementations for a variety of target platforms. In addition, the toolset can generate formal models representing the specification and an implementation, whether automatically generated from the Cryptol specification or written independently, and show that the two models are functionally equivalent.A team of developers from Rockwell Collins, Inc. and Galois, Inc. has successfully produced high-speed embedded Cryptographic Equipment Applications (CEAs), automatically generated from high-level specifications. These high-speed CEA implementations comprise a mixture of software code and VHDL, and target a compact new embedded platform designed by Rockwell Collins. Automated formal methods prove that algorithm implementations faithfully implement their high-level specifications.Cryptol's high-level approach to hardware implementation does not come at the expense of performance. For instance, an algorithm core generated from a Cryptol specification for AES-256 and running in Electronic Codebook mode demonstrated throughput in excess of 16 Gbps. When feedback from the output stage to the input was introduced, thereby defeating the advantage gained by \unrolling\"" AES rounds",encryption performance for AES-256 still exceeded 1 Gbps,while consuming less than 2% of the available programmable logic for the algorithm core.Significantly,the Rockwell Collins/Galois team was able to design,implement,simulate,integrate,analyze,and test a complex CEA on the new hardware,including AES-256 and Galois Counter Mode (GCM),in less than 3 months,"significantly reducing the usual time to produce a new design on a new platform.""",,CUFP '10,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Caspi P,Colaço JL,Gérard L,Pouzet M,Raymond P",Synchronous Objects with Scheduling Policies: Introducing Safe Shared Memory in Lustre,,2009,,,11–20,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2009 ACM SIGPLAN/SIGBED Conference on Languages, Compilers, and Tools for Embedded Systems","Dublin, Ireland",2009,9781605583563,,https://doi.org/10.1145/1542452.1542455;http://dx.doi.org/10.1145/1542452.1542455,10.1145/1542452.1542455,"This paper addresses the problem of designing and implementing complex control systems for real-time embedded software. Typical applications involve different control laws corresponding to different phases or modes, e.g., take-off, full flight and landing in a fly-by-wire control system. On one hand, existing methods such as the combination of Simulink/Stateflow provide powerful but unsafe mechanisms by means of imperative updates of shared variables. On the other hand, synchronous languages and tools such as Esterel or SCADE/Lustre are too restrictive and forbid to fully separate the specification of modes from their actual instantiation with a particular control automaton.In this paper, we introduce a conservative extension of a synchronous data-flow language close to Lustre, in order to be able to define systems with modes in a more modular way, while insuring the absence of data-races. We show that such a system can be viewed as an object where modes are methods acting on a shared memory. The object is associated to a scheduling policy which specifies the ways methods can be called to build a valid synchronous reaction. We show that the verification of the proper use of an object reduces to a type inference problem using row types introduced by Wand, Rémy and Vouillon. We define the semantics of the extended synchronous language and the type system. The proposed extension has been implemented and we illustrate its use through several examples.","compilation, block-diagrams, type systems, synchronous languages, semantics, real-time systems",LCTES '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Caspi P,Colaço JL,Gérard L,Pouzet M,Raymond P",Synchronous Objects with Scheduling Policies: Introducing Safe Shared Memory in Lustre,SIGPLAN Not.,2009,44,7,11–20,Association for Computing Machinery,"New York, NY, USA",,,,2009-06,,0362-1340,https://doi.org/10.1145/1543136.1542455;http://dx.doi.org/10.1145/1543136.1542455,10.1145/1543136.1542455,"This paper addresses the problem of designing and implementing complex control systems for real-time embedded software. Typical applications involve different control laws corresponding to different phases or modes, e.g., take-off, full flight and landing in a fly-by-wire control system. On one hand, existing methods such as the combination of Simulink/Stateflow provide powerful but unsafe mechanisms by means of imperative updates of shared variables. On the other hand, synchronous languages and tools such as Esterel or SCADE/Lustre are too restrictive and forbid to fully separate the specification of modes from their actual instantiation with a particular control automaton.In this paper, we introduce a conservative extension of a synchronous data-flow language close to Lustre, in order to be able to define systems with modes in a more modular way, while insuring the absence of data-races. We show that such a system can be viewed as an object where modes are methods acting on a shared memory. The object is associated to a scheduling policy which specifies the ways methods can be called to build a valid synchronous reaction. We show that the verification of the proper use of an object reduces to a type inference problem using row types introduced by Wand, Rémy and Vouillon. We define the semantics of the extended synchronous language and the type system. The proposed extension has been implemented and we illustrate its use through several examples.","real-time systems, synchronous languages, semantics, type systems, block-diagrams, compilation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Coblenz M,Aldrich J,Myers BA,Sunshine J","Can Advanced Type Systems Be Usable? An Empirical Study of Ownership, Assets, and Typestate in Obsidian",Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428200;http://dx.doi.org/10.1145/3428200,10.1145/3428200,"Some blockchain programs (smart contracts) have included serious security vulnerabilities. Obsidian is a new typestate-oriented programming language that uses a strong type system to rule out some of these vulnerabilities. Although Obsidian was designed to promote usability to make it as easy as possible to write programs, strong type systems can cause a language to be difficult to use. In particular, ownership, typestate, and assets, which Obsidian uses to provide safety guarantees, have not seen broad adoption together in popular languages and result in significant usability challenges. We performed an empirical study with 20 participants comparing Obsidian to Solidity, which is the language most commonly used for writing smart contracts today. We observed that Obsidian participants were able to successfully complete more of the programming tasks than the Solidity participants. We also found that the Solidity participants commonly inserted asset-related bugs, which Obsidian detects at compile time.","smart contracts, assets, linear types, permissions, empirical studies of programming languages, blockchain, typestate, ownership",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Noël C,Extensible Software Transactional Memory,,2010,,,23–34,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third C* Conference on Computer Science and Software Engineering,"Montréal, Quebec, Canada",2010,9781605589015,,https://doi.org/10.1145/1822327.1822331;http://dx.doi.org/10.1145/1822327.1822331,10.1145/1822327.1822331,"XSTM is a software transactional memory that can be extended by pluggable components. Extensions can access transactions read and write sets through an API, and process them e.g., for logging, change notification, state persistence or replication. This project explores ways to make memory transactions useful beyond thread synchronization. We describe in particular an application architecture enabled by extensions which aims to combine some of the strengths of shared state and of the Actor model. Shared state offers developers the modeling power of object orientation, and avoids the overhead of copying memory between components. The Actor model offers safety and composability when writing parallel and distributed applications. Our second design goal is to make memory transactions easy to reason about and safe to use. Opacity is achieved using a Multi Version Concurrency Control design where transactions are view-isolated, i.e., run in stable and consistent snapshots of the full memory. Transactions never encounter inconsistent data, do not abort while partially executed, and global progress is guaranteed. The programming model is further simplified by enforcing strong atomicity at the type system level, as transactional objects accessors require an ambient transaction. Finally, our design offers interesting performance characteristics by avoiding mutable shared state. Data is either mutable but private to a thread, or shared but immutable. This allows transactions to run without synchronization (no memory fence) between start and commit, which are themselves implemented in a lock-free way using O(1) memory fences and compare-and-swaps. We describe working implementations on the JVM and CLR for the STM and some extensions.","object replication, concurrent programming, transactional memory, composability, synchronization, software architecture",C3S2E '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vitousek MM,Kent AM,Siek JG,Baker J",Design and Evaluation of Gradual Typing for Python,,2014,,,45–56,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th ACM Symposium on Dynamic Languages,"Portland, Oregon, USA",2014,9781450332118,,https://doi.org/10.1145/2661088.2661101;http://dx.doi.org/10.1145/2661088.2661101,10.1145/2661088.2661101,"Combining static and dynamic typing within the same language offers clear benefits to programmers. It provides dynamic typing in situations that require rapid prototyping, heterogeneous data structures, and reflection, while supporting static typing when safety, modularity, and efficiency are primary concerns. Siek and Taha (2006) introduced an approach to combining static and dynamic typing in a fine-grained manner through the notion of type consistency in the static semantics and run-time casts in the dynamic semantics. However, many open questions remain regarding the semantics of gradually typed languages.In this paper we present Reticulated Python, a system for experimenting with gradual-typed dialects of Python. The dialects are syntactically identical to Python 3 but give static and dynamic semantics to the type annotations already present in Python 3. Reticulated Python consists of a typechecker and a source-to-source translator from Reticulated Python to Python 3. Using Reticulated Python, we evaluate a gradual type system and three approaches to the dynamic semantics of mutable objects: the traditional semantics based on Siek and Taha (2007) and Herman et al. (2007) and two new designs. We evaluate these designs in the context of several third-party Python programs.","proxy, gradual typing, case study, python",DLS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Vitousek MM,Kent AM,Siek JG,Baker J",Design and Evaluation of Gradual Typing for Python,SIGPLAN Not.,2014,50,2,45–56,Association for Computing Machinery,"New York, NY, USA",,,,2014-10,,0362-1340,https://doi.org/10.1145/2775052.2661101;http://dx.doi.org/10.1145/2775052.2661101,10.1145/2775052.2661101,"Combining static and dynamic typing within the same language offers clear benefits to programmers. It provides dynamic typing in situations that require rapid prototyping, heterogeneous data structures, and reflection, while supporting static typing when safety, modularity, and efficiency are primary concerns. Siek and Taha (2006) introduced an approach to combining static and dynamic typing in a fine-grained manner through the notion of type consistency in the static semantics and run-time casts in the dynamic semantics. However, many open questions remain regarding the semantics of gradually typed languages.In this paper we present Reticulated Python, a system for experimenting with gradual-typed dialects of Python. The dialects are syntactically identical to Python 3 but give static and dynamic semantics to the type annotations already present in Python 3. Reticulated Python consists of a typechecker and a source-to-source translator from Reticulated Python to Python 3. Using Reticulated Python, we evaluate a gradual type system and three approaches to the dynamic semantics of mutable objects: the traditional semantics based on Siek and Taha (2007) and Herman et al. (2007) and two new designs. We evaluate these designs in the context of several third-party Python programs.","case study, python, proxy, gradual typing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jansen JM,Plasmeijer R,Koopman P,Achten P",Embedding a Web-Based Workflow Management System in a Functional Language,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Tenth Workshop on Language Descriptions, Tools and Applications","Paphos, Cyprus",2010,9781450300636,,https://doi.org/10.1145/1868281.1868288;http://dx.doi.org/10.1145/1868281.1868288,10.1145/1868281.1868288,"Workflow management systems guide and monitor tasks performed by humans and computers. The workflow specifications are usually expressed in special purpose (graphical) formalisms. These formalisms impose severe restrictions on what can be expressed. Modern workflow management systems should handle intricate data dependencies, offer a web-based interface, and should adapt to dynamically changing situations, all based on a sound formalism. To address these challenges, we have developed the iTask system, which is a novel workflow management system. We entirely embed the iTask specification language in a modern general purpose functional language, and generate a complete workflow application. In this paper we report our experiences in developing the iTask system. It not only inherits state-of-the-art programming language concepts such as generic programming and a hybrid static/dynamic type system from the host language Clean, but also offers a number of novel concepts to generate complex, real-world, multi-user, web based workflow applications.","workflow system, embedded domain specific language, functional combinator library, experience paper",LDTA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Aotani T,Kamina T,Masuhara H",Type-Safe Layer-Introduced Base Functions with Imperative Layer Activation,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Workshop on Context-Oriented Programming,"Prague, Czech Republic",2015,9781450336543,,https://doi.org/10.1145/2786545.2786553;http://dx.doi.org/10.1145/2786545.2786553,10.1145/2786545.2786553,"Layer-introduced base methods, which are the methods with new signatures in a layer and are added to a class, give layers more freedom to organize definitions of context-dependent behavior. However, we need to be careful so as not to call a layer-introduced base method while the layers that provide the method are inactive. Type-based solutions would help to avoid such a problematic situation, but existing ones are limited to context-oriented programming (COP) languages that have dynamically-scoped (i.e., the \with\"" based) layer activation. We propose a COP framework in Haskell that supports both imperative and dynamically-scoped layer activation mechanisms",as well as layer-introduced base functions. By representing a context as a stack of active layers in a type of a function in Haskell,"type safety---including the guarantee of activation of a layer that provides a layer-introduced function---is checked by Haskell's type system. This paper shows how our framework encodes COP features in Haskell using a simple example.""","type safety, Haskell, layer-introduced base functions, Context-oriented programming",COP'15,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Figueroa I,Tabareau N,Tanter É",Taming Aspects with Monads and Membranes,,2013,,,1–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Workshop on Foundations of Aspect-Oriented Languages,"Fukuoka, Japan",2013,9781450318655,,https://doi.org/10.1145/2451598.2451600;http://dx.doi.org/10.1145/2451598.2451600,10.1145/2451598.2451600,"When a software system is developed using several aspects, special care must be taken to ensure that the resulting behavior is correct. This is known as the aspect interference problem, and existing approaches essentially aim to detect whether a system exhibits problematic interferences of aspects.In this paper we describe how to control aspect interference by construction by relying on the type system. More precisely, we combine a monadic embedding of the pointcut/advice model in Haskell with the notion of membranes for aspect-oriented programming. Aspects must explicitly declare the side effectsa nd the context they can act upon. Allowed patterns of control flow interference are declared at the membrane level and statically enforced. Finally, computational interference between aspects is controlled by the membrane topology. To combine independent and reusable aspects and monadic components into a program specification we use monad views, a recent technique for conveniently handling the monadic stack.","aspect-oriented programming, monad views, interference, monads, membranes",FOAL '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nishizaki SY,Kasuga R",Untyped Lambda Calculus with Functionally Referable Environments,,2021,,,100–104,Association for Computing Machinery,"New York, NY, USA",,2021 10th International Conference on Software and Computer Applications,"Kuala Lumpur, Malaysia",2021,9781450388825,,https://doi.org/10.1145/3457784.3457798;http://dx.doi.org/10.1145/3457784.3457798,10.1145/3457784.3457798,"The environment is the relationship between variables and their bound values during program execution and is a notion in program semantics. A first-class environment is a mechanism that allows the environment to be treated like data, such as integer values or Boolean values, and can be passed to a function as an argument or received as a return value. The environment calculus is a formal computational system proposed by Nishizaki and is a lambda calculus that extends the first-class environment mechanism. The formulation of the environment was based on explicit substitution by Curien et al., who viewed the environment as a substitution. The operational semantics of the environmental calculus, or the reduction, is based on the reduction of the lambda-sigma calculus. In the calculus, there are two constructs for first-class environments: one is the identity environment to reify the current environment, that is, to transfer a meta-level environment to object-level data; the other is the environment composition to reflect the object-level environment data, that is, to transfer object-level environment data back to a meta-level environment. In this paper, instead of the environment composition, we propose a new interface with a first-class environment, a functionally referable environment. If object-level environment data is given as an argument for a function application, the functional reflection brings the environment back to the meta-level and makes the lambda term evaluable under that environment. Using the functionally referable environment, one can unify the environment composition with the function application. We define the untyped lambda calculus with functionally referable environments: we give the syntax of the calculus and its reduction. Then we provide the semantics for the reduction using a translation of the environment calculus into the record calculus. We prove the soundness of the translation semantics. Finally, we discuss the evaluation strategy, especially the call-by-value reduction.","functional programming language, lambda calculus, first-class environment",ICSCA 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Viera M,Swierstra SD","First Class Syntax, Semantics, and Their Composition",,2013,,,73–84,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 25th Symposium on Implementation and Application of Functional Languages,"Nijmegen, Netherlands",2013,9781450329880,,https://doi.org/10.1145/2620678.2620686;http://dx.doi.org/10.1145/2620678.2620686,10.1145/2620678.2620686,"Ideally complexity is managed by composing a system out of quite a few, more or less independent, and much smaller descriptions of various aspects of the overall artefact. When describing (extensible) programming languages, attribute grammars have turned out to be an excellent tool for modular definition and integration of their different aspects. In this paper we show how to construct a programming language implementation by composing a collection of separately compiled attribute grammar fragments, each describing a separate aspect of the language.More specifically we describe how to use a coherent set of libraries and tools which together makes it possible to express this directly in Haskell, where the correctness of the composition is enforced through the Haskell type system's ability to represent attribute grammars as plain Haskell values and their interfaces as Haskell types makes this possible.Semantic objects thus constructed can be combined with parsers which are constructed on the fly out of a collection of grammar fragments, which are also represented by typed Haskell values. Again the type checker prevents unsound compositions.Using a very small example language and some simple extensions, we show how our techniques fit together towards the construction of extensible compilers out of a collection of pre-compiled, statically type-checked \language definition fragments\"".""","Extensible Languages, Typed Transformations, Attribute Grammars, Haskell, Typed Grammars",IFL '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lievens D,Harrison W",Symmetric Encapsulated Multi-Methods to Abstract over Application Structure,,2009,,,1873–1880,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 ACM Symposium on Applied Computing,"Honolulu, Hawaii",2009,9781605581668,,https://doi.org/10.1145/1529282.1529702;http://dx.doi.org/10.1145/1529282.1529702,10.1145/1529282.1529702,"In object systems, classes take the role of modules, and interfaces consist of methods. Because methods are encapsulated in objects, interfaces in object systems do not allow abstracting over where methods are implemented. This implies that any change to the implementation structure may cause a rippling effect. Sometimes this unduly restricts the scope of software evolution, in particular for methods with multiple parameters where there is no clear owner. We propose a simple scheme where symmetric methods may be defined in the classes of any of their parameters. This allows client code to be oblivious of what class contains a method implementation, and therefore immune against it changing. When combined with multiple dynamic dispatch, this scheme allows for modular extensibility (but not modular type-checking) where a method defined in one class is overridden by a method defined in a class that is not its subtype. In this paper, we illustrate the scheme by extending a core calculus of class-based languages with these symmetric encapsulated multi-methods, and prove the result sound.","software evolution, language design, type system, symmetric methods, multiple dispatch",SAC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bagherzadeh M,Rajan H,Darvish A","On Exceptions, Events and Observer Chains",,2013,,,185–196,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Annual International Conference on Aspect-Oriented Software Development,"Fukuoka, Japan",2013,9781450317665,,https://doi.org/10.1145/2451436.2451458;http://dx.doi.org/10.1145/2451436.2451458,10.1145/2451436.2451458,"Modular understanding of behaviors and flows of exceptions may help in their better use and handling. Such reasoning tasks about exceptions face unique challenges in event-based implicit invocation (II) languages that allow subjects to implicitly invoke observers, and run the observers in a chain. In this work, we illustrate these challenge in Ptolemy and propose Ptolemy-X that enables modular reasoning about behaviors and flows of exceptions for event announcement and handling. Ptolemy-X's exception-aware specification expressions and boundary exceptions limit the set of (un)checked exceptions of subjects and observers of an event. Exceptional postconditions specify the behaviors of these exceptions. Greybox specifications specify the flows of these exceptions among the observers in the chain. Ptolemy-X's type system and refinement rules enforce these specifications and thus enable its modular reasoning. We evaluate the utility of Ptolemy-X's exception flow reasoning by applying it to understand a set of aspect-oriented (AO) bug patterns. We also present Ptolemy-X's semantics including its sound static semantics.","exceptional behavior, event, exception flow",AOSD '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Stilkerich I,Strotz M,Erhardt C,Stilkerich M",RT-LAGC: Fragmentation-Tolerant Real-Time Memory Management Revisited,,2014,,,87–96,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Workshop on Java Technologies for Real-Time and Embedded Systems,"Niagara Falls, NY, USA",2014,9781450328135,,https://doi.org/10.1145/2661020.2661031;http://dx.doi.org/10.1145/2661020.2661031,10.1145/2661020.2661031,"The use of managed, type-safe languages such as Java in real-time and embedded systems is advantageous, as it offers productivity and especially safety and dependability benefits over dominating unsafe languages. A Java Virtual Machine (JVM) has to provide an implicit memory management system such as a garbage collector (GC), for example, as explicit memory management through allocation and release operations by the application developer is prone to programming errors and may result in a violation of the type system properties. Real-time systems have specific requirements regarding space and time bounds and a GC has to ensure that these defined upper limits will not be exceeded. A proper solution to address this issue is, for example, employing fragmentation-tolerant garbage collection as proposed by Pizlo et al. [16]. Their approach is called SCHISM/CMR. Based on their work, we developed an alternative fragmentation-tolerant GC variant called RT-LAGC, which is supported by our compiler jino and is part of the KESO JVM [18]. RT-LAGC is a cooperative GC, that is, the real-time system developer and the compiler assist the GC through system configuration (e.g. enough slack time for the GC to run) and program analyses, respectively. This is achieved by integrating the GCs in the design process of the whole system just as any other user application. In RT-LAGC, we designed a new bidirectional fragmented object layout. Furthermore, we implemented latency-aware management of fragmented memory as well as an alternative collection technique for array meta-information. Moreover, the execution properties of an exemplary application were improved by jino's extended escape analysis. RT-LAGC is evaluated against KESO's purely incremental non-fragmentation-tolerant GC called IRRGC and a throughput-optimized stop-the-world collector named CBGC. A classification of typical memory patterns for Java objects supports the predictability of the examined embedded system.","Java, memory management, KESO, real-time systems, embedded systems, garbage collection",JTRES '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Horváth G,Pataki N,Balassi M",Code Generation in Serializers and Comparators of Apache Flink,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 12th Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems","Barcelona, Spain",2017,9781450350884,,https://doi.org/10.1145/3098572.3098579;http://dx.doi.org/10.1145/3098572.3098579,10.1145/3098572.3098579,"There is a shift in the Big Data world. Applications used to be I/O bound. InfiniBand, SSDs reduced the I/O overhead and more sophisticated algorithms were developed. CPU became a bottleneck for some applications. Using state of the art CPUs, reduced CPU usage can lead to reduced electricity costs even when an application is I/O bound.Apache Flink is an open source framework for processing streams of data and batch jobs. It is using serialization for wide variety of purposes. Not only for sending data over the network, saving it to the hard disk, or for fault tolerance, but also some of the operators can work on the serialized representation of the data instead of Java objects. This approach can improve the performance significantly. Flink has a custom serialization method that enables operators to work on the serialized formats.Currently, Apache Flink uses reflection to serialize Plain Old Java Objects (POJOs). Reflection in Java is notoriously slow. Moreover, the structure of the code is harder to optimize for the JIT compiler. As a Google Summer of Code project in 2016, we implemented code generation for serializers and comparators for POJOs to improve the performance of Apache Flink. Flink has a delicate type system which provides us with lots of information about the types that need to be serialized. Using this information it is possible to generate specialized code with great performance.We achieved more than 6X performance improvement in the serialization which was a 20% overall improvement.","code generation, big data, Java, Janino, Flink",ICOOOLPS'17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Adams R,Coercive Subtyping in Lambda-Free Logical Frameworks,,2009,,,30–39,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice,"Montreal, Quebec, Canada",2009,9781605585291,,https://doi.org/10.1145/1577824.1577830;http://dx.doi.org/10.1145/1577824.1577830,10.1145/1577824.1577830,"We show how coercive subtyping may be added to a lambda-free logical framework, by constructing the logical framework TF<, an extension of the lambda-free logical framework TF with coercive subtyping. Instead of coercive application, TF< makes use of a typecasting operation. We develop the metatheory of the resulting framework, including providing some general conditions under which typecasting in an object theory with coercive subtyping is decidable. We show how TF< may be embedded in the logical framework LF, and hence how results about LF may be deduced from results about TF<.","typecasting, type theory, coercive subtyping, lambda-free logical framework, metatheory",LFMTP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tate R,Chen J,Hawblitzel C",Inferable Object-Oriented Typed Assembly Language,,2010,,,424–435,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st ACM SIGPLAN Conference on Programming Language Design and Implementation,"Toronto, Ontario, Canada",2010,9781450300193,,https://doi.org/10.1145/1806596.1806644;http://dx.doi.org/10.1145/1806596.1806644,10.1145/1806596.1806644,"A certifying compiler preserves type information through compilation to assembly language programs, producing typed assembly language (TAL) programs that can be verified for safety independently so that the compiler does not need to be trusted. There are two challenges for adopting certifying compilation in practice. First, requiring every compiler transformation and optimization to preserve types is a large burden on compilers, especially when adopting certifying compilation into existing optimizing non-certifying compilers. Second, type annotations significantly increase the size of assembly language programs.This paper proposes an alternative to traditional certifying compilers. It presents iTalX, the first inferable TAL type system that supports existential types, arrays, interfaces, and stacks. We have proved our inference algorithm is complete, meaning if an assembly language program is typeable with iTalX then our algorithm will infer an iTalX typing for that program. Furthermore, our algorithm is guaranteed to terminate even if the assembly language program is untypeable. We demonstrate that it is practical to infer such an expressive TAL by showing a prototype implementation of type inference for code compiled by Bartok, an optimizing C# compiler. Our prototype implementation infers complete type annotations for 98% of functions in a suite of realistic C# benchmarks. The type-inference time is about 8% of the compilation time. We needed to change only 2.5% of the compiler code, mostly adding new code for defining types and for writing types to object files. Most transformations are untouched. Type-annotation size is only 17% of the size of pure code and data, reducing type annotations in our previous certifying compiler [4] by 60%. The compiler needs to preserve only essential type information such as method signatures, object-layout information, and types for static data and external labels. Even non-certifying compilers have most of this information available.","type inference, object-oriented compiler, existential quantification, certifying compiler, typed assembly language (tal)",PLDI '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Tate R,Chen J,Hawblitzel C",Inferable Object-Oriented Typed Assembly Language,SIGPLAN Not.,2010,45,6,424–435,Association for Computing Machinery,"New York, NY, USA",,,,2010-06,,0362-1340,https://doi.org/10.1145/1809028.1806644;http://dx.doi.org/10.1145/1809028.1806644,10.1145/1809028.1806644,"A certifying compiler preserves type information through compilation to assembly language programs, producing typed assembly language (TAL) programs that can be verified for safety independently so that the compiler does not need to be trusted. There are two challenges for adopting certifying compilation in practice. First, requiring every compiler transformation and optimization to preserve types is a large burden on compilers, especially when adopting certifying compilation into existing optimizing non-certifying compilers. Second, type annotations significantly increase the size of assembly language programs.This paper proposes an alternative to traditional certifying compilers. It presents iTalX, the first inferable TAL type system that supports existential types, arrays, interfaces, and stacks. We have proved our inference algorithm is complete, meaning if an assembly language program is typeable with iTalX then our algorithm will infer an iTalX typing for that program. Furthermore, our algorithm is guaranteed to terminate even if the assembly language program is untypeable. We demonstrate that it is practical to infer such an expressive TAL by showing a prototype implementation of type inference for code compiled by Bartok, an optimizing C# compiler. Our prototype implementation infers complete type annotations for 98% of functions in a suite of realistic C# benchmarks. The type-inference time is about 8% of the compilation time. We needed to change only 2.5% of the compiler code, mostly adding new code for defining types and for writing types to object files. Most transformations are untouched. Type-annotation size is only 17% of the size of pure code and data, reducing type annotations in our previous certifying compiler [4] by 60%. The compiler needs to preserve only essential type information such as method signatures, object-layout information, and types for static data and external labels. Even non-certifying compilers have most of this information available.","object-oriented compiler, existential quantification, type inference, certifying compiler, typed assembly language (tal)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Jiang JM,Zhu H,Li Q,Zhao Y,Hong Z,Zhang S,Gong P",Isolation Modeling and Analysis Based on Mobility,ACM Trans. Softw. Eng. Methodol.,2019,28,2,,Association for Computing Machinery,"New York, NY, USA",,,,2019-02,,1049-331X,https://doi.org/10.1145/3306606;http://dx.doi.org/10.1145/3306606,10.1145/3306606,"In a mobile system, mobility refers to a change in position of a mobile object with respect to time and its reference point, whereas isolation means the isolation relationship between mobile objects under some scheduling policies. Inspired by event-based formal models and the ambient calculus, we first propose the two types of special events, entering and exiting an ambient, as movement events to model and analyze mobility. Based on mobility, we then introduce the notion of the isolation of mobile objects for ambients. To ensure the isolation, a priority policy needs to be used to schedule the movement of mobile objects. However, traditional scheduling policies focus on task scheduling and depend on the strong hypothesis: The scheduled tasks are independent—that is, the scheduled tasks do not affect each other. In a practical mobile system, mobile objects and ambients interact with each other. It is difficult to separate a mobile system into independent tasks. We finally present an automatic approach for generating a priority scheduling policy without considering the preceding assumption. The approach can guarantee the isolation of the mobile objects for ambients in a mobile system. Experiments demonstrate these results.","dependency structure, scheduling policy, Mobility, isolation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fouladgar M,Elmasri R",Formalization of Network-Constrained Moving Object Queries with Application to Benchmarking,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th ACM SIGSPATIAL International Workshop on GeoStreaming,"Burlingame, California",2016,9781450345798,,https://doi.org/10.1145/3003421.3003427;http://dx.doi.org/10.1145/3003421.3003427,10.1145/3003421.3003427,"In this paper, we first categorize the various types of Network-constrained moving object queries. We then propose benchmarks that can be used to compare the performance of systems and indexing schemes that are proposed for handling these types of queries. Network-constrained moving objects are objects that move in a specific network, such as vehicles that are constrained to move in a road (traffic) network.Our query categories are based on the Network-constrained moving object model presented by [4, 6, 14]. We formally define comprehensive categories of typical queries, based on whether the conditions involve space (point versus region), time (point versus interval), and object id. The categories are based on the various combinations of these features. We describe the types of queries as Relational Calculus expressions, based on the query constraints. We focus on three main constraints: Spatial constraints, Temporal constraints, or/and moving object ID constraints. For each types of query, we identify the types of results, and give examples to clarify the query types. This work can define a benchmark for the performance of different types of systems and indexes that are designed to answer queries on Network-constrained moving objects data. Certain indexes/systems may work well for some query categories but perform poorly for other types of queries.","benchmarking, data models, query categories, moving objects databases, constrained networks",IWGS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ahrens B,Hirschowitz A,Lafont A,Maggesi M",Reduction Monads and Their Signatures,Proc. ACM Program. Lang.,2019,4,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-12,,,https://doi.org/10.1145/3371099;http://dx.doi.org/10.1145/3371099,10.1145/3371099,"In this work, we study reduction monads, which are essentially the same as monads relative to the free functor from sets into multigraphs. Reduction monads account for two aspects of the lambda calculus: on the one hand, in the monadic viewpoint, the lambda calculus is an object equipped with a well-behaved substitution; on the other hand, in the graphical viewpoint, it is an oriented multigraph whose vertices are terms and whose edges witness the reductions between two terms. We study presentations of reduction monads. To this end, we propose a notion of reduction signature. As usual, such a signature plays the role of a virtual presentation, and specifies arities for generating operations—possibly subject to equations—together with arities for generating reduction rules. For each such signature, we define a category of models; any model is, in particular, a reduction monad. If the initial object of this category of models exists, we call it the reduction monad presented (or specified) by the given reduction signature. Our main result identifies a class of reduction signatures which specify a reduction monad in the above sense. We show in the examples that our approach covers several standard variants of the lambda calculus.","Reduction systems, Initial semantics, Lambda calculus, Monads, Higher-order languages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bettini L,Bono V,Naddeo M",A Trait Based Re-Engineering Technique for Java Hierarchies,,2008,,,149–158,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th International Symposium on Principles and Practice of Programming in Java,"Modena, Italy",2008,9781605582238,,https://doi.org/10.1145/1411732.1411753;http://dx.doi.org/10.1145/1411732.1411753,10.1145/1411732.1411753,"Traits are pure behavior components introduced in the Smalltalk community in order to integrate the traditional class inheritance with a composition mechanism: a class is composed by traits and inherits from superclasses. This offers the advantage of promoting code reuse. In this paper, we tackle the problem of re-engineering a Java hierarchy into traits, by adapting to a Java setting a methodology developed by Lienhard, Ducasse, and Arévalo for a Smalltalk setting, based on Formal Concept Analysis. We illustrate the approach by applying it to the Java input stream library. We also obtain two by-products: (i) we identify clearly some workarounds that programmers must exploit in order to overcome some of the limitations of Java single inheritance; (ii) we single out some features a Java with traits might include, as none of the proposals in the literature in this sense has taken the lead yet.","code reuse, formal concept analysis, Java, re-engineering, trait",PPPJ '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Krishnaswami NR,Turon A,Dreyer D,Garg D",Superficially Substructural Types,,2012,,,41–54,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th ACM SIGPLAN International Conference on Functional Programming,"Copenhagen, Denmark",2012,9781450310543,,https://doi.org/10.1145/2364527.2364536;http://dx.doi.org/10.1145/2364527.2364536,10.1145/2364527.2364536,"Many substructural type systems have been proposed for controlling access to shared state in higher-order languages. Central to these systems is the notion of a *resource*, which may be split into disjoint pieces that different parts of a program can manipulate independently without worrying about interfering with one another. Some systems support a *logical* notion of resource (such as permissions), under which two resources may be considered disjoint even if they govern the *same* piece of state. However, in nearly all existing systems, the notions of resource and disjointness are fixed at the outset, baked into the model of the language, and fairly coarse-grained in the kinds of sharing they enable.In this paper, inspired by recent work on \fictional disjointness\"" in separation logic",we propose a simple and flexible way of enabling any module in a program to create its own custom type of splittable resource (represented as a commutative monoid),thus providing fine-grained control over how the module's private state is shared with its clients. This functionality can be incorporated into an otherwise standard substructural type system by means of a new typing rule we call *the sharing rule*,"whose soundness we prove semantically via a novel resource-oriented Kripke logical relation.""","commutative monoids, fictional disjointness, adts, sharing rule, hidden state, capabilities, dependent types, substructural type systems, separation logic, kripke logical relations",ICFP '12,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Krishnaswami NR,Turon A,Dreyer D,Garg D",Superficially Substructural Types,SIGPLAN Not.,2012,47,9,41–54,Association for Computing Machinery,"New York, NY, USA",,,,2012-09,,0362-1340,https://doi.org/10.1145/2398856.2364536;http://dx.doi.org/10.1145/2398856.2364536,10.1145/2398856.2364536,"Many substructural type systems have been proposed for controlling access to shared state in higher-order languages. Central to these systems is the notion of a *resource*, which may be split into disjoint pieces that different parts of a program can manipulate independently without worrying about interfering with one another. Some systems support a *logical* notion of resource (such as permissions), under which two resources may be considered disjoint even if they govern the *same* piece of state. However, in nearly all existing systems, the notions of resource and disjointness are fixed at the outset, baked into the model of the language, and fairly coarse-grained in the kinds of sharing they enable.In this paper, inspired by recent work on \fictional disjointness\"" in separation logic",we propose a simple and flexible way of enabling any module in a program to create its own custom type of splittable resource (represented as a commutative monoid),thus providing fine-grained control over how the module's private state is shared with its clients. This functionality can be incorporated into an otherwise standard substructural type system by means of a new typing rule we call *the sharing rule*,"whose soundness we prove semantically via a novel resource-oriented Kripke logical relation.""","fictional disjointness, kripke logical relations, commutative monoids, substructural type systems, adts, separation logic, sharing rule, dependent types, capabilities, hidden state",,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Huang SS,Smaragdakis Y",Expressive and Safe Static Reflection with MorphJ,,2008,,,79–89,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Tucson, AZ, USA",2008,9781595938602,,https://doi.org/10.1145/1375581.1375592;http://dx.doi.org/10.1145/1375581.1375592,10.1145/1375581.1375592,"Recently, language extensions have been proposed for Java and C# to support pattern-based reflective declaration. These extensions introduce a disciplined form of meta-programming and aspect-oriented programming to mainstream languages: They allow members of a class (i.e., fields and methods) to be declared by statically iterating over and pattern-matching on members of other classes. Such techniques, however, have been unable to safely express simple, but common, idioms such as declaring getter and setter methods for fields.In this paper, we present a mechanism that addresses the lack of expressiveness in past work without sacrificing safety. Our technique is based on the idea of nested patterns that elaborate the outer-most pattern with blocking or enabling conditions. We implemented this mechanism in a language, MorphJ. We demonstrate the expressiveness of MorphJ with real-world applications. In particular, the MorphJ reimplementation of DSTM2, a software transactional memory library, reduces 1,107 lines of Java reflection and bytecode engineering library calls to just 374 lines of MorphJ code. At the same time, the MorphJ solution is both high level and safer, as MorphJ can separately type check generic classes and catch errors early. We present and formalize the MorphJ type system, and offer a type-checking algorithm.","class morphing, object-oriented programming, meta-programming, aspect-oriented programming, structural abstraction, language extensions",PLDI '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Huang SS,Smaragdakis Y",Expressive and Safe Static Reflection with MorphJ,SIGPLAN Not.,2008,43,6,79–89,Association for Computing Machinery,"New York, NY, USA",,,,2008-06,,0362-1340,https://doi.org/10.1145/1379022.1375592;http://dx.doi.org/10.1145/1379022.1375592,10.1145/1379022.1375592,"Recently, language extensions have been proposed for Java and C# to support pattern-based reflective declaration. These extensions introduce a disciplined form of meta-programming and aspect-oriented programming to mainstream languages: They allow members of a class (i.e., fields and methods) to be declared by statically iterating over and pattern-matching on members of other classes. Such techniques, however, have been unable to safely express simple, but common, idioms such as declaring getter and setter methods for fields.In this paper, we present a mechanism that addresses the lack of expressiveness in past work without sacrificing safety. Our technique is based on the idea of nested patterns that elaborate the outer-most pattern with blocking or enabling conditions. We implemented this mechanism in a language, MorphJ. We demonstrate the expressiveness of MorphJ with real-world applications. In particular, the MorphJ reimplementation of DSTM2, a software transactional memory library, reduces 1,107 lines of Java reflection and bytecode engineering library calls to just 374 lines of MorphJ code. At the same time, the MorphJ solution is both high level and safer, as MorphJ can separately type check generic classes and catch errors early. We present and formalize the MorphJ type system, and offer a type-checking algorithm.","class morphing, aspect-oriented programming, meta-programming, language extensions, structural abstraction, object-oriented programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gil J,Maman I",Whiteoak: Introducing Structural Typing into Java,,2008,,,73–90,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582153,,https://doi.org/10.1145/1449764.1449771;http://dx.doi.org/10.1145/1449764.1449771,10.1145/1449764.1449771,"This paper presents WHITEOAK: a JAVA extension that introduces structural type equivalence and subtyping into the language. We argue that structural subtyping addresses common software design problems, and promotes the development of loosely coupled modules without compromising type safety.We discuss language design issues, including subtyping in face of self-referencing structural types, compile-time operators for computing the new types from existing ones, and the semantics of constructors and non-abstract methods in structural types. We describe implementation techniques, including the compile-time and run-time challenges that we faced (in particular, preserving the identity of objects). Measurement indicate that the performance of our implementation of structural dispatching is comparable to that of the JVM's standard invocation mechanisms.","structural subtyping, abstraction, java",OOPSLA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gil J,Maman I",Whiteoak: Introducing Structural Typing into Java,SIGPLAN Not.,2008,43,10,73–90,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,0362-1340,https://doi.org/10.1145/1449955.1449771;http://dx.doi.org/10.1145/1449955.1449771,10.1145/1449955.1449771,"This paper presents WHITEOAK: a JAVA extension that introduces structural type equivalence and subtyping into the language. We argue that structural subtyping addresses common software design problems, and promotes the development of loosely coupled modules without compromising type safety.We discuss language design issues, including subtyping in face of self-referencing structural types, compile-time operators for computing the new types from existing ones, and the semantics of constructors and non-abstract methods in structural types. We describe implementation techniques, including the compile-time and run-time challenges that we faced (in particular, preserving the identity of objects). Measurement indicate that the performance of our implementation of structural dispatching is comparable to that of the JVM's standard invocation mechanisms.","structural subtyping, abstraction, java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Padhye R,Sen K",Efficient Fail-Fast Dynamic Subtype Checking,,2019,,,32–37,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th ACM SIGPLAN International Workshop on Virtual Machines and Intermediate Languages,"Athens, Greece",2019,9781450369879,,https://doi.org/10.1145/3358504.3361229;http://dx.doi.org/10.1145/3358504.3361229,10.1145/3358504.3361229,"We address the problem of dynamically checking if an instance of class S is also an instance of class T. Researchers have designed various strategies to perform constant-time subtype tests. Yet, well-known production implementations degrade to linear search in the worst case, in order to achieve other goals such as constant space and/or efficient dynamic class loading. The fast path is usually optimized for subtype tests that succeed. However, in workloads where dynamic type tests are common, such as Scala's pattern matching and LLVM compiler passes, we observe that 74%--93% of dynamic subtype tests return a negative result. We thus propose a scheme for fail-fast dynamic subtype checking. We assign each type a randomly generated type identifier with fixed size and fixed parity. In the compiled version of each class, we store a fixed-width bloom filter, which combines the type identifiers of all its transitive supertypes. At run-time, the bloom filters enable fast refutation of dynamic subtype tests with high probability. If such a refutation cannot be made, the scheme falls back to conventional techniques. This scheme works with multiple inheritance, separate compilation, and dynamic class loading. A prototype implementation of fail-fasts in the JVM provides provides 1.44x--2.74x speedup over HotSpot's native instanceof, on micro-benchmarks where worst-case behavior is likely.","dynamic casts, bloom filters, object-oriented programming, multiple inheritance",VMIL 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Barlas K,Berki E,Adomnita I,Nalam T,Nejad GS,Veijalainen J",Formal Specification of Open Standards and the Case of RSS v2.0,,2014,,,1–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th Panhellenic Conference on Informatics,"Athens, Greece",2014,9781450328975,,https://doi.org/10.1145/2645791.2645809;http://dx.doi.org/10.1145/2645791.2645809,10.1145/2645791.2645809,"Open standardization seems to be very popular among software developers as it makes the standard's adoption by the software engineering community easier and smoother. Formal specification methods, on the other hand, while very promising, are being adopted by protocol engineers very slowly; the industry seems to have little motivation to move into this, almost unknown, territory.In this paper the authors present the i) idea of applying formal methods (formal specification techniques) to open standards' specifications, and ii) an example of a formal specification of open standards, RSS v2.0 in particular. The authors support and provide evidence for the advantages of the open standards formal specification over natural language documentations (the current way that open standards' specifications are released). Formal specifications are more concise and consistent than the ones written in natural languages, while significantly less ambiguous and more complete with respect to the original documentation. Furthermore, they are executable in many cases and highly reusable as most formal methods automated support tools allow for module inheritance. The merging of formal specification methods and open standards allows for i) a more concrete standard design; ii) an improved understanding of the environment under design; iii) an enforced certain level of precision into the specification, and also iv) provides software engineers with extended property checking/verification capabilities, especially if they choose to use any of the algebraic specification languages. The authors showcase how the RSS v2.0 standard can formally be specified using the CafeOBJ formal specification language and demonstrate why the particular formal specification is beneficial.","Open standards, CafeOBJ, Formal Methods, Really Simple Syndication RSS v2.0 Protocol, Software Quality (Properties), Formal Specification Modeling",PCI '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Beillahi SM,Ciocarlie G,Emmi M,Enea C",Behavioral Simulation for Smart Contracts,,2020,,,470–486,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation,"London, UK",2020,9781450376136,,https://doi.org/10.1145/3385412.3386022;http://dx.doi.org/10.1145/3385412.3386022,10.1145/3385412.3386022,"While smart contracts have the potential to revolutionize many important applications like banking, trade, and supply-chain, their reliable deployment begs for rigorous formal verification. Since most smart contracts are not annotated with formal specifications, general verification of functional properties is impeded. In this work, we propose an automated approach to verify unannotated smart contracts against specifications ascribed to a few manually-annotated contracts. In particular, we propose a notion of behavioral refinement, which implies inheritance of functional properties. Furthermore, we propose an automated approach to inductive proof, by synthesizing simulation relations on the states of related contracts. Empirically, we demonstrate that behavioral simulations can be synthesized automatically for several ubiquitous classes like tokens, auctions, and escrow, thus enabling the verification of unannotated contracts against functional specifications.","Simulation, Refinement, Smart contracts, Blockchain",PLDI 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Crampes M,Plantié M",Visualizing and Interacting with Concept Hierarchies,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 4th International Conference on Web Intelligence, Mining and Semantics (WIMS14)","Thessaloniki, Greece",2014,9781450325387,,https://doi.org/10.1145/2611040.2611046;http://dx.doi.org/10.1145/2611040.2611046,10.1145/2611040.2611046,"Concept Hierarchies and Formal Concept Analysis are theoretically well grounded and largely experimented methods. They rely on line diagrams called Galois lattices for visualizing and analysing object-attribute sets. Galois lattices are visually seducing and conceptually rich for experts. However they present important drawbacks due to their concept oriented overall structure: analysing what they show is difficult for non experts, navigation is cumbersome, interaction is poor, and scalability is a deep bottleneck for visual interpretation even for experts. In this paper we introduce semantic probes as a means to overcome many of these problems and extend usability and application possibilities of traditional FCA visualization methods. Semantic probes are visual user centred objects which extract and organize reduced Galois sub-hierarchies. They are simpler, clearer, and they provide a better navigation support through a rich set of interaction possibilities. Since probe driven sub-hierarchies are limited to users' focus, scalability is under control and interpretation is facilitated. After some successful experiments, several applications are being developed with the remaining problem of finding a compromise between simplicity and conceptual expressivity.","Formal Concept Analysis, visualization, Galois sub-hierarchy",WIMS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Huchard M,Analyzing Inheritance Hierarchies through Formal Concept Analysis: A 22-Years Walk in a Landscape of Conceptual Structures,,2015,,,8–13,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the MechAnisms on SPEcialization, Generalization and InHerItance","Prague, Czech Republic",2015,9781450336598,,https://doi.org/10.1145/2786555.2786557;http://dx.doi.org/10.1145/2786555.2786557,10.1145/2786555.2786557,"Designing or renovating inheritance hierarchies in the domain of programming or in the domain of modeling still remains a tricky task. It involves integrating domain concepts sometimes with no clear frontier, finding the good abstractions and avoiding duplicated information. In this paper, we review research work that addressed this topic with the use of Formal Concept Analysis (concept lattices) since the seminal paper of R. Godin and H. Mili at OOPSLA'93. We overview the different attempts, the explored limits, and the current issues.","specialization/generalization hierarchy design, Formal Concept Analysis, Inheritance hierarchy design",MASPEGHI'15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Tan C,Liu Q,Chen E,Xiong H,Wu X",Object-Oriented Travel Package Recommendation,ACM Trans. Intell. Syst. Technol.,2014,5,3,,Association for Computing Machinery,"New York, NY, USA",,,,2014-09,,2157-6904,https://doi.org/10.1145/2542665;http://dx.doi.org/10.1145/2542665,10.1145/2542665,"Providing better travel services for tourists is one of the important applications in urban computing. Though many recommender systems have been developed for enhancing the quality of travel service, most of them lack a systematic and open framework to dynamically incorporate multiple types of additional context information existing in the tourism domain, such as the travel area, season, and price of travel packages. To that end, in this article, we propose an open framework, the Objected-Oriented Recommender System (ORS), for the developers performing personalized travel package recommendations to tourists. This framework has the ability to import all the available additional context information to the travel package recommendation process in a cost-effective way. Specifically, the different types of additional information are extracted and uniformly represented as feature--value pairs. Then, we define the Object, which is the collection of the feature--value pairs. We propose two models that can be used in the ORS framework for extracting the implicit relationships among Objects. The Objected-Oriented Topic Model (OTM) can extract the topics conditioned on the intrinsic feature--value pairs of the Objects. The Objected-Oriented Bayesian Network (OBN) can effectively infer the cotravel probability of two tourists by calculating the co-occurrence time of feature--value pairs belonging to different kinds of Objects. Based on the relationships mined by OTM or OBN, the recommendation list is generated by the collaborative filtering method. Finally, we evaluate these two models and the ORS framework on real-world travel package data, and the experimental results show that the ORS framework is more flexible in terms of incorporating additional context information, and thus leads to better performances for travel package recommendations. Meanwhile, for feature selection in ORS, we define the feature information entropy, and the experimental results demonstrate that using features with lower entropies usually leads to better recommendation results.","Bayesian, travel, topic model, object-oriented, collaborative filtering",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Liu F,Lhoták O,Biboudis A,Giarrusso PG,Odersky M",A Type-and-Effect System for Object Initialization,Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428243;http://dx.doi.org/10.1145/3428243,10.1145/3428243,"Every newly created object goes through several initialization states: starting from a state where all fields are uninitialized until all of them are assigned. Any operation on the object during its initialization process, which usually happens in the constructor via this, has to observe the initialization states of the object for correctness, i.e. only initialized fields may be used. Checking safe usage of this statically, without manual annotation of initialization states in the source code, is a challenge, due to aliasing and virtual method calls on this. Mainstream languages either do not check initialization errors, such as Java, C++, Scala, or they defend against them by not supporting useful initialization patterns, such as Swift. In parallel, past research has shown that safe initialization can be achieved for varying degrees of expressiveness but by sacrificing syntactic simplicity. We approach the problem by upholding local reasoning about initialization which avoids whole-program analysis, and we achieve typestate polymorphism via subtyping. On this basis, we put forward a novel type-and-effect system that can effectively ensure initialization safety while allowing flexible initialization patterns. We implement an initialization checker in the Scala 3 compiler and evaluate on several real-world projects.","Object initialization, Type-and-effect syste",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kegel H,Steimann F",Systematically Refactoring Inheritance to Delegation in Java,,2008,,,431–440,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th International Conference on Software Engineering,"Leipzig, Germany",2008,9781605580791,,https://doi.org/10.1145/1368088.1368147;http://dx.doi.org/10.1145/1368088.1368147,10.1145/1368088.1368147,"Because of the strong coupling of classes and the proliferation of unneeded class members induced by inheritance, the suggestion to use composition and delegation instead has become commonplace. The presentation of a corresponding refactoring in the literature may lead one to believe that such a transformation is a straightforward undertaking. However, closer analysis reveals that this refactoring is neither always possible, nor does it necessarily achieve its desired effect. We have therefore identified the necessary preconditions and realizable postconditions of the refactoring, and built a tool that can perform it completely automatically. By applying this tool to all subclasses of several open-source projects, we have collected evidence of the applicability of the refactoring and of its capability to deliver on its promises. The refactoring builds on constraint graphs originally developed for type inference to check the preconditions and to compute the necessary delegation as well as the subtype relationships that must be maintained.","evaluation, delegation, open recursion, refactoring, forwarding, inheritance, design",ICSE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Höger C,Modeling with Monads: Extensible Modeling Semantics as Syntactic Sugar,,2016,,,15–24,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Workshop on Equation-Based Object-Oriented Modeling Languages and Tools,"Milano, Italy",2016,9781450342025,,https://doi.org/10.1145/2904081.2904084;http://dx.doi.org/10.1145/2904081.2904084,10.1145/2904081.2904084,"We present an extensible implementation of Modelica-style modeling semantics. Modeling features are implemented using an intuitive encoding as an extensible state monad. Monadic computation naturally yields model composition and interpretation. This in turn allows for a clear separation between the modular aspects of a modeling language (e.g. classes and inheritance) and the symbolical and numerical treatment of models: While the former can be implemented by a compiler or interpreter, the latter can be moved into a core-library to be maintained by domain-experts. In a second step, we show how the elaboration aspects of the language can be removed by a correct and complete desugaring procedure. The residual language is a simple extension of a call-by-value λ-calculus. Thus it becomes possible to implement a compiler for a modeling language using existing standard techniques.","semantics, monad, desugaring, compiler, modelica",EOOLT '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Alshehri A,Benson J,Patwa F,Sandhu R",Access Control Model for Virtual Objects (Shadows) Communication for AWS Internet of Things,,2018,,,175–185,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Eighth ACM Conference on Data and Application Security and Privacy,"Tempe, AZ, USA",2018,9781450356329,,https://doi.org/10.1145/3176258.3176328;http://dx.doi.org/10.1145/3176258.3176328,10.1145/3176258.3176328,"The concept of Internet of Things (IoT) has received considerable attention and development in recent years. There have been significant studies on access control models for IoT in academia, while companies have already deployed several cloud-enabled IoT platforms. However, there is no consensus on a formal access control model for cloud-enabled IoT. The access-control oriented (ACO) architecture was recently proposed for cloud-enabled IoT, with virtual objects (VOs) and cloud services in the middle layers. Building upon ACO, operational and administrative access control models have been published for virtual object communication in cloud-enabled IoT illustrated by a use case of sensing speeding cars as a running example.In this paper, we study AWS IoT as a major commercial cloud-IoT platform and investigate its suitability for implementing the afore-mentioned academic models of ACO and VO communication control. While AWS IoT has a notion of digital shadows closely analogous to VOs, it lacks explicit capability for VO communication and thereby for VO communication control. Thus there is a significant mismatch between AWS IoT and these academic models. The principal contribution of this paper is to reconcile this mismatch by showing how to use the mechanisms of AWS IoT to effectively implement VO communication models. To this end, we develop an access control model for virtual objects (shadows) communication in AWS IoT called AWS-IoT-ACMVO. We develop a proof-of-concept implementation of the speeding cars use case in AWS IoT under guidance of this model, and provide selected performance measurements. We conclude with a discussion of possible alternate implementations of this use case in AWS IoT.","virtual objects, iot architecture, aws iot, security, acl, access control, internet of things (iot), rbac, abac, devices",CODASPY '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kästner A,Gogolla M,Selic B",From (Imperfect) Object Diagrams to (Imperfect) Class Diagrams: New Ideas and Vision Paper,,2018,,,13–22,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21th ACM/IEEE International Conference on Model Driven Engineering Languages and Systems,"Copenhagen, Denmark",2018,9781450349499,,https://doi.org/10.1145/3239372.3239381;http://dx.doi.org/10.1145/3239372.3239381,10.1145/3239372.3239381,"In order to achieve effective support for software development, the transition between an informal and provisional mode of tool operation, which is conducive to design exploration, and a formal mechanistic mode required for computer-based design capture is crucial. This contribution proposes a smooth transition for designing class models starting from informal, sketchy object models. We propose a lenient development approach and discuss the possibilities and problems of a transformation from object diagrams to class diagrams. While classes describe abstract concepts, objects are representations of what can be seen in the real world, so it might be easier to start modeling with objects instead of classes. An object diagram can however not describe a whole system, it is only used as the first step of an iterative process to create a complete model. During this process, our object and class diagrams provide a notation for highlighting missing or conflicting parts. Based on these imperfect object diagrams, educated guesses can be made for resulting, imperfect class diagrams, which can then be refined to a complete, formal description of the modeled system.","Incremental transformation by example, UML object diagram, Tool support, UML class diagram",MODELS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Yang Q,Xu MW,Pi C",Delegation: A Language Facility for Dynamic Software Adaptation,SIGSOFT Softw. Eng. Notes,2009,34,3,1–5,Association for Computing Machinery,"New York, NY, USA",,,,2009-05,,0163-5948,https://doi.org/10.1145/1527202.1527215;http://dx.doi.org/10.1145/1527202.1527215,10.1145/1527202.1527215,"Due to the growing complexity of computing systems, and the increasing demand for high availability and reliability of them, adapting software at runtime is becoming more and more important. However, there is not sufficient support for dynamic software adaptation at the level of programming languages. In this paper, we investigate a language feature, namely delegation, to argue that delegation is a favorite choice to deal with dynamic software adaptation. To do that, we present Φ calculus, which is an imperative object-based calculus with delegation, to model essential features of languages, with focusing on how to incorporate delegation into programming languages to support dynamic software adaptation. We give the operational semantics of Φ calculus. We also state how delegation is used in object extending and method sharing between objects. We conclude that delegation makes dynamic software adaptation simpler and more flexible.","Φ object calculus, delegate, object calculus, delegation, dynamic software adaptation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zinn D,Modeling and Optimization of Scientific Workflows,,2008,,,1–10,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 EDBT Ph.D. Workshop,"Nantes, France",2008,9781595939685,,https://doi.org/10.1145/1387150.1387152;http://dx.doi.org/10.1145/1387150.1387152,10.1145/1387150.1387152,"Simulation and computer-aided data analysis have become an integral part of many traditional sciences and have spawned virtual observatories and even entirely new disciplines, e.g. bioinformatics. Scientific workflow systems are built for modeling and automation of scientific applications, to increase scientists' productivity.In this paper, we present desiderata, which we believe scientific workflow systems should have from a scientist's point-of-view. In particular, they should support data modeling, be resilient against input data changes, should check workflow well-formedness, as well as automatically optimize workflow specifications for efficient execution.We argue that current approaches do not adequately address these desiderata, in particular, conventional workflows need to be changed radically to cope with common changes in the input data structure. Workflows built using a Collection-Oriented Modeling and Design (Comad) approach, on the other side, exhibit much greater resilience to input changes.We propose to further extend and formalize Comad by creating a separate configuration layer to gap between scientific functionality (e.g., scripts, programs, or web-services) and the high-level workflow graph. The design of this gap language and an appropriate type system is part of the proposed Ph.D. project. As an initial result we show how to adopt XML regular expression types on the workflow channels and how to characterize actor behavior by defining actor signatures. This allows us to propagate schema information through the workflow, to predict workflow output schema (well-formedness), as well as to automatically optimize data routing for less overall shippings of data as well as for an increase in workflow concurrency.",,Ph.D. '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Scherp A,Franz T,Saathoff C,Staab S",F--a Model of Events Based on the Foundational Ontology Dolce+DnS Ultralight,,2009,,,137–144,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Fifth International Conference on Knowledge Capture,"Redondo Beach, California, USA",2009,9781605586588,,https://doi.org/10.1145/1597735.1597760;http://dx.doi.org/10.1145/1597735.1597760,10.1145/1597735.1597760,"The lack of a formal model of events hinders interoperability in distributed event-based systems. In this paper, we present a formal model of events, called Event-Model-F. The model is based on the foundational ontology DOLCE+DnS Ultralight (DUL) and provides comprehensive support to represent time and space, objects and persons, as well as mereological, causal, and correlative relationships between events. In addition, the Event-Model-F provides a flexible means for event composition, modeling event causality and event correlation, and representing different interpretations of the same event. The Event-Model-F is developed following the pattern-oriented approach of DUL, is modularized in different ontologies, and can be easily extended by domain specific ontologies.","core ontology, objects, events, pattern-oriented ontology design",K-CAP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Russo CV,Join Patterns for Visual Basic,,2008,,,53–72,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd ACM SIGPLAN Conference on Object-Oriented Programming Systems Languages and Applications,"Nashville, TN, USA",2008,9781605582153,,https://doi.org/10.1145/1449764.1449770;http://dx.doi.org/10.1145/1449764.1449770,10.1145/1449764.1449770,"We describe an extension of Visual Basic 9.0 with asynchronous concurrency constructs - join patterns - based on the join calculus. Our design of Concurrent Basic (CB) builds on earlier work on Polyphonic C# and Comega. Since that work, the need for language-integrated concurrency has only grown, both due to the arrival of commodity, multi-core hardware, and the trend for Rich Internet Applications that rely on asynchronous client-server communication to hide latency. Unlike its predecessors, CB adopts an event-like syntax that should be familiar to existing VB programmers. Coupled with Generics, CB allows one to declare re-useable concurrency abstractions that were clumsy to express previously. CB removes its ancestors' inconvenient inheritance restriction, while providing new extensibility points useful in practical applications that must co-exist with or want to exploit alternative threading models available on the platform. CB is implemented as an extension of the production VB 9.0 compiler.","asynchronous message passing, join patterns, visual basic",OOPSLA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Russo CV,Join Patterns for Visual Basic,SIGPLAN Not.,2008,43,10,53–72,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,0362-1340,https://doi.org/10.1145/1449955.1449770;http://dx.doi.org/10.1145/1449955.1449770,10.1145/1449955.1449770,"We describe an extension of Visual Basic 9.0 with asynchronous concurrency constructs - join patterns - based on the join calculus. Our design of Concurrent Basic (CB) builds on earlier work on Polyphonic C# and Comega. Since that work, the need for language-integrated concurrency has only grown, both due to the arrival of commodity, multi-core hardware, and the trend for Rich Internet Applications that rely on asynchronous client-server communication to hide latency. Unlike its predecessors, CB adopts an event-like syntax that should be familiar to existing VB programmers. Coupled with Generics, CB allows one to declare re-useable concurrency abstractions that were clumsy to express previously. CB removes its ancestors' inconvenient inheritance restriction, while providing new extensibility points useful in practical applications that must co-exist with or want to exploit alternative threading models available on the platform. CB is implemented as an extension of the production VB 9.0 compiler.","asynchronous message passing, visual basic, join patterns",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Neumayr B,Schrefl M,Thalheim B",Hetero-Homogeneous Hierarchies in Data Warehouses,,2010,,,61–70,"Australian Computer Society, Inc.",AUS,,Proceedings of the Seventh Asia-Pacific Conference on Conceptual Modelling - Volume 110,"Brisbane, Australia",2010,9781920682927,,,,"Data Warehouses facilitate multi-dimensional analysis of data from various data sources. While the original data sources are often heterogeneous, current modeling and implementation techniques discard and, thus, cannot exploit these heterogeneities.In this paper we introduce Hetero-Homogeneous Hierarchies to model dimension hierarchies and cubes with inherent heterogeneities. Hetero-homogeneous hierarchies are hierarchies that are heterogeneous in regard to the schema of sub-hierarchies and homogeneous in regard to a minimal common schema shared by all sub-hierarchies.Sub-dimension-hierarchies can be specialized to contain additional levels and additional non-dimensional attributes. Sub-cubes can be specialized towards additional measures, more fine-grained facts, and differing units of measure. We show how scale differences and conflicts due to multi-dimensional inheritance can be avoided and solved. We provide a formal definition of our approach together with a query/cube algebra.","heterogeneous information, OLAP, abstraction, specialization, multidimensional conceptual modeling",APCCM '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shao J,Qin Y,Feng D,Wang W",Formal Analysis of Enhanced Authorization in the TPM 2.0,,2015,,,273–284,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 10th ACM Symposium on Information, Computer and Communications Security","Singapore, Republic of Singapore",2015,9781450332453,,https://doi.org/10.1145/2714576.2714610;http://dx.doi.org/10.1145/2714576.2714610,10.1145/2714576.2714610,"The Trusted Platform Module (TPM) is a system component that provides a hardware-based approach to establish trust in a platform by providing protected storage, robust platform integrity measurement, secure platform attestation and other secure functionalities. The access to TPM commands and TPM-resident key objects are protected via an authorization mechanism. Enhanced Authorization (EA) is a new mechanism introduced by the TPM 2.0 to provide a rich authorization model for specifying flexible access control policies for TPM-resident objects.In our paper, we conduct a formal verification of the EA mechanism. Firstly, we propose a model of the TPM 2.0 EA mechanism in a variant of the applied pi calculus. Secondly, we identify and formalize the security properties of the EA mechanism (Prop.1 and 2) in its design. We also give out a misuse problem that is easily to be neglected (Lemma 7). Thirdly, using the SAPIC tool and the tamarin prover, we have verified both the two security properties. Meanwhile, we have found 3 misuse cases and one of them leads to an attack on the application in [12].","formal verification, tpm, trusted computing, enhanced authorization",ASIA CCS '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wrigstad T,Nardelli FZ,Lebresne S,Östlund J,Vitek J",Integrating Typed and Untyped Code in a Scripting Language,,2010,,,377–388,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Madrid, Spain",2010,9781605584799,,https://doi.org/10.1145/1706299.1706343;http://dx.doi.org/10.1145/1706299.1706343,10.1145/1706299.1706343,"Many large software systems originate from untyped scripting language code. While good for initial development, the lack of static type annotations can impact code-quality and performance in the long run. We present an approach for integrating untyped code and typed code in the same system to allow an initial prototype to smoothly evolve into an efficient and robust program. We introduce like types , a novel intermediate point between dynamic and static typing. Occurrences of like types variables are checked statically within their scope but, as they may be bound to dynamic values, their usage is checked dynamically. Thus like types provide some of the benefits of static typing without decreasing the expressiveness of the language. We provide a formal account of like types in a core object calculus and evaluate their applicability in the context of a new scripting language.","semantics, compilers, types, object-orientation",POPL '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wrigstad T,Nardelli FZ,Lebresne S,Östlund J,Vitek J",Integrating Typed and Untyped Code in a Scripting Language,SIGPLAN Not.,2010,45,1,377–388,Association for Computing Machinery,"New York, NY, USA",,,,2010-01,,0362-1340,https://doi.org/10.1145/1707801.1706343;http://dx.doi.org/10.1145/1707801.1706343,10.1145/1707801.1706343,"Many large software systems originate from untyped scripting language code. While good for initial development, the lack of static type annotations can impact code-quality and performance in the long run. We present an approach for integrating untyped code and typed code in the same system to allow an initial prototype to smoothly evolve into an efficient and robust program. We introduce like types , a novel intermediate point between dynamic and static typing. Occurrences of like types variables are checked statically within their scope but, as they may be bound to dynamic values, their usage is checked dynamically. Thus like types provide some of the benefits of static typing without decreasing the expressiveness of the language. We provide a formal account of like types in a core object calculus and evaluate their applicability in the context of a new scripting language.","compilers, object-orientation, types, semantics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lau M,Ohgawara A,Mitani J,Igarashi T",Converting 3D Furniture Models to Fabricatable Parts and Connectors,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2011 Papers,"Vancouver, British Columbia, Canada",2011,9781450309431,,https://doi.org/10.1145/1964921.1964980;http://dx.doi.org/10.1145/1964921.1964980,10.1145/1964921.1964980,"Although there is an abundance of 3D models available, most of them exist only in virtual simulation and are not immediately usable as physical objects in the real world. We solve the problem of taking as input a 3D model of a man-made object, and automatically generating the parts and connectors needed to build the corresponding physical object. We focus on furniture models, and we define formal grammars for IKEA cabinets and tables. We perform lexical analysis to identify the primitive parts of the 3D model. Structural analysis then gives structural information to these parts, and generates the connectors (i.e. nails, screws) needed to attach the parts together. We demonstrate our approach with arbitrary 3D models of cabinets and tables available online.","grammar, fabrication, assembly instructions, procedural modeling, 3D modeling, exploded view illustrations",SIGGRAPH '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Lau M,Ohgawara A,Mitani J,Igarashi T",Converting 3D Furniture Models to Fabricatable Parts and Connectors,ACM Trans. Graph.,2011,30,4,,Association for Computing Machinery,"New York, NY, USA",,,,2011-07,,0730-0301,https://doi.org/10.1145/2010324.1964980;http://dx.doi.org/10.1145/2010324.1964980,10.1145/2010324.1964980,"Although there is an abundance of 3D models available, most of them exist only in virtual simulation and are not immediately usable as physical objects in the real world. We solve the problem of taking as input a 3D model of a man-made object, and automatically generating the parts and connectors needed to build the corresponding physical object. We focus on furniture models, and we define formal grammars for IKEA cabinets and tables. We perform lexical analysis to identify the primitive parts of the 3D model. Structural analysis then gives structural information to these parts, and generates the connectors (i.e. nails, screws) needed to attach the parts together. We demonstrate our approach with arbitrary 3D models of cabinets and tables available online.","assembly instructions, fabrication, exploded view illustrations, 3D modeling, grammar, procedural modeling",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Yadav A,Khan RA",Measuring Design Complexity: An Inherited Method Perspective,SIGSOFT Softw. Eng. Notes,2009,34,4,1–5,Association for Computing Machinery,"New York, NY, USA",,,,2009-07,,0163-5948,https://doi.org/10.1145/1543405.1564532;http://dx.doi.org/10.1145/1543405.1564532,10.1145/1543405.1564532,Complexity is one of the important attributes of reliability. Higher design complexity increases the probability of error occurrences and decreases reliability of software. Inheritance has been indentified as a key construct to control design complexity. This paper proposes a formula to calculate the overall complexity of design hierarchy caused by inherited methods.,"object oriented design, class hierarchy, design inheritance, error, fault, complexity, software reliability, measurement, design complexity, reliability",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hubbard S,Walkingshaw E",Formula Choice Calculus,,2016,,,49–57,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Workshop on Feature-Oriented Software Development,"Amsterdam, Netherlands",2016,9781450346474,,https://doi.org/10.1145/3001867.3001873;http://dx.doi.org/10.1145/3001867.3001873,10.1145/3001867.3001873,"The choice calculus is a simple metalanguage and associated theory that has been successfully applied to several problems of interest to the feature-oriented software development community. The formal presentation of the choice calculus essentially restricts variation points, called choices, to vary based on the inclusion or not of a single feature, while in practice variation points may depend on several features. Therefore, in both theoretical applications of the choice calculus, and in tools inspired by the choice calculus, the syntax of choices has often been generalized to depend on an arbitrary propositional formula of features. The purpose of this paper is to put this syntactic generalization on more solid footing by also generalizing the associated theory. Specifically, after defining the syntax and denotational semantics of the formula choice calculus (FCC), we define and prove the soundness of a syntactic equivalence relation on FCC expressions. This effort validates previous work which has implicitly assumed the soundness of rules in the equivalence relation, and also reveals several rules that are specific to FCC. Finally, we describe some further generalizations to FCC and their limits.","software product lines, choice calculus, program transformation, refactoring, variation",FOSD 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Fishwick PA,Learning Simulation Models through Physical Objects,,2016,,,1559–1570,IEEE Press,"Arlington, Virginia",,Proceedings of the 2016 Winter Simulation Conference,,2016,9781509044849,,,,"We traditionally learn how to model systems through texts, either online or in published form, but is it possible to learn about models by interacting directly with physical objects? Imagine taking a walk in a museum where objects reveal their modeling nature. A fossil in a science museum may indicate a process model for mineralization of bone, or the museums' cafe, although a large object, may indicate a queuing model reflecting how customers wait in line and obtain service. Such informal learning outside of the classroom augments formal learning in instructor-led, syllabus-based courses. We cover recent work in a class where students were instructed to explore museum objects through the lens of modeling and simulation. We link to an outdoor sculpture that contains physical web access to modeling information. Students are able to see models through objects rather than strictly through classroom instruction. Models become new interpretations of art objects.",,WSC '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Scott D,Mathematical Concepts in Programming Language Semantics,,1971,,,225–234,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the May 16-18, 1972, Spring Joint Computer Conference","Atlantic City, New Jersey",1971,9781450379090,,https://doi.org/10.1145/1478873.1478903;http://dx.doi.org/10.1145/1478873.1478903,10.1145/1478873.1478903,"In mathematics after some centuries of development the semantical situation is very clean. This may not be surprising, as the subject attracts people who enjoy clarity, generality, and neatness. On the one hand we have our concepts of mathematical objects (numbers, relations, functions, sets), and on the other we have various formal means of expression. The mathematical expressions are generated for the most part in a very regular manner, and every effort is made to supply all expressions with denotations. (This is not always so easy to do. The theory of distributions, for example, provided a non-obvious construction of denotations for expressions of an operational calculus. The derivative operator was well serviced, but one still cannot multiply two distributions.)",,AFIPS '72 (Spring),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Toledo R,Tanter É",Secure and Modular Access Control with Aspects,,2013,,,157–170,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Annual International Conference on Aspect-Oriented Software Development,"Fukuoka, Japan",2013,9781450317665,,https://doi.org/10.1145/2451436.2451456;http://dx.doi.org/10.1145/2451436.2451456,10.1145/2451436.2451456,"Can access control be fully modularized as an aspect? Most proposals for aspect-oriented access control are limited to factoring out access control checks, still relying on a non-modular and ad hoc infrastructure for permission checking. Recently, we proposed an approach for modular access control, called ModAC. ModAC successfully modularizes both the use of and the support for access control by means of restriction aspects and scoping strategies. However, ModAC is only informally described and therefore does not provide any formal guarantee with respect to its effectiveness. In addition, like in many other proposals for aspect-oriented access control, the presence of untrusted aspects is not at all considered, thereby jeopardizing the practical applicability of such approaches. This paper demonstrates that it is possible to fully modularize aspect control, even in the presence of untrusted aspects. It does so by describing a self-protecting aspect that secures ModAC. We validate this result by describing a core calculus for AspectScript, an aspect-oriented extension of JavaScript, and using this calculus to prove effectiveness and non-interference properties of ModAC. Beyond being an important validation for AOP itself, fully modularizing access control with aspects allows access control to be added to other aspect languages, without requiring ad hoc support.","scoping strategies, aspect-oriented programming, restriction aspects, access control",AOSD '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Graiet M,Maraoui R,Kmimech M,Bhiri MT,Gaaloul W",Towards an Approach of Formal Verification of Mediation Protocol Based on Web Services,,2010,,,75–82,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Conference on Information Integration and Web-Based Applications & Services,"Paris, France",2010,9781450304214,,https://doi.org/10.1145/1967486.1967502;http://dx.doi.org/10.1145/1967486.1967502,10.1145/1967486.1967502,"SOA (Service Oriented Architecture) defines a new Web services cooperation paradigm in order to develop distributed applications using reusable services. The handling of such collaboration has different problems that lead to many research efforts. In this paper, we address the problem of Web service composition. Indeed, various heterogeneities can arise during the composition. The resolution of these heterogeneities, called mediation, is needed to achieve a service composition. In this paper, we propose a sound approach to formalize Web services composition mediation with the ADL (Architecture Description Language) ACME. To do so, we first model the meta model of composite service manager and mediation. Then we specify semi formal properties associated with this meta model using OCL (Object Constraint Language). Afterwards, we formalize the mediation protocol using Armani, which provides a powerful predicate language in order to ensure service execution reliability.","transactional web services, web services composition, ACME/ARMANI ADL, formalization, mediation, reliability",iiWAS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Praing R,Schneider M",Modeling Historical and Future Movements of Spatio-Temporal Objects in Moving Objects Databases,,2007,,,183–192,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Sixteenth ACM Conference on Conference on Information and Knowledge Management,"Lisbon, Portugal",2007,9781595938039,,https://doi.org/10.1145/1321440.1321469;http://dx.doi.org/10.1145/1321440.1321469,10.1145/1321440.1321469,"Spatio-temporal databases deal with geometries changing over time. In general, geometries do not only change discretely but continuously; hence we are dealing with moving objects. In the past, a few moving object data models and query languages have been proposed. Each of them supports either historical movements or future movements but not both together. Consequently, queries that start in the past and extend into the future cannot be supported. To model both historical and future movements of an object, two separate concepts with different properties are required, and extra attention is necessary to avoid their conflicts. Furthermore, current definitions of moving objects are too general and vague. It is unclear how a moving object is allowed to move through space and time. For instance, the continuity or discontinuity of motion is not specified. In this paper, we propose a new moving object data model called Balloon model which provides integrated support for both historical and future movements of moving objects. As part of the model, we provide formal definitions of moving objects with respect to their past and future movements. All kinds of queries including past queries, future queries, and queries that start in the past and end in the future are supported in our model.","moving objects databases, historical movements, spatio-temporal data model, continuity of evolutions, gis, predictive movements, balloon model",CIKM '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Seifi Y,Suriadi S,Foo E,Boyd C",Analysis of Object-Specific Authorization Protocol (OSAP) Using Coloured Petri Nets,,2012,,,47–58,"Australian Computer Society, Inc.",AUS,,Proceedings of the Tenth Australasian Information Security Conference - Volume 125,"Melbourne, Australia",2012,9781921770067,,,,"The use of Trusted Platform Module (TPM) is becoming increasingly popular in many security systems. To access objects protected by TPM (such as cryptographic keys), several cryptographic protocols, such as the Object Specific Authorization Protocol (OSAP), can be used. Given the sensitivity and the importance of those objects protected by TPM, the security of this protocol is vital. Formal methods allow a precise and complete analysis of cryptographic protocols such that their security properties can be asserted with high assurance. Unfortunately, formal verification of these protocols are limited, despite the abundance of formal tools that one can use. In this paper, we demonstrate the use of Coloured Petri Nets (CPN) - a type of formal technique, to formally model the OSAP. Using this model, we then verify the authentication property of this protocol using the state space analysis technique. The results of analysis demonstrates that as reported by Chen and Ryan the authentication property of OSAP can be violated.","TPM, trusted computing, coloured petri nets, OSAP, CPN/tools, CPN, security analysis",AISC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Uddin R,Rice MN,Ravishankar CV,Tsotras VJ",Assembly Queries: Planning and Discovering Assemblies of Moving Objects Using Partial Information,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 25th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,"Redondo Beach, CA, USA",2017,9781450354905,,https://doi.org/10.1145/3139958.3139993;http://dx.doi.org/10.1145/3139958.3139993,10.1145/3139958.3139993,"Consider objects moving in a road network (e.g., groups of people or delivery vehicles), who may be free to choose routes, yet be required to arrive at certain locations at certain times. Such objects may need to assemble in groups within the network (friends meet while visiting a city, vehicles need to exchange items or information) without violating arrival constraints. Planning for such assemblies is hard when the network or the number of objects is large. Conversely, discovering actual or potential assemblies of such objects is important in many surveillance, security, and law-enforcement applications. This can be hard when object arrival observations are sparse due to inadequate sensor coverage or object countermeasures. We propose the novel class of assembly queries to model these scenarios, and present a unified scheme that addresses both of these complementary challenges. Given a set of objects and arrival constraints, we show how to first obtain the set of all possible locations visited by each moving object (the travel corridor), and then determine all possible assemblies, including the participants, locations, and durations. We present a formal model for various tracking strategies and several algorithms for using these strategies. We achieve excellent performance on these queries by preprocessing the network, using Contraction Hierarchies. Experimental results on real-world road networks show that we can efficiently and rapidly infer assembly information for very large networks and object groups.","Location-Based Services, Contraction Hierarchies, Spatio-temporal Trajectories, Shortest Paths",SIGSPATIAL '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Stenholt R,Efficient Selection of Multiple Objects on a Large Scale,,2012,,,105–112,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th ACM Symposium on Virtual Reality Software and Technology,"Toronto, Ontario, Canada",2012,9781450314695,,https://doi.org/10.1145/2407336.2407357;http://dx.doi.org/10.1145/2407336.2407357,10.1145/2407336.2407357,"The task of multiple object selection (MOS) in immersive virtual environments is important and still largely unexplored. The difficulty of efficient MOS increases with the number of objects to be selected. E.g. in small-scale MOS, only a few objects need to be simultaneously selected. This may be accomplished by serializing existing single-object selection techniques. In this paper, we explore various MOS tools for large-scale MOS. That is, when the number of objects to be selected are counted in hundreds, or even thousands. This makes serialization of single-object techniques prohibitively time consuming. Instead, we have implemented and tested two of the existing approaches to 3-D MOS, a brush and a lasso, as well as a new technique, a magic wand, which automatically selects objects based on local proximity to other objects. In a formal user evaluation, we have studied how the performance of the MOS tools are affected by the geometric configuration of the objects to be selected. Our studies demonstrate that the performance of MOS techniques is very significantly affected by the geometric scenario facing the user. Furthermore, we demonstrate that a good match between MOS tool shape and the geometric configuration is not always preferable, if the applied tool is complex to use.","virtual reality, multiple object selection, user evaluation, hmd",VRST '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kabir I,Lhoták O",κDOT: Scaling DOT with Mutation and Constructors,,2018,,,40–50,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM SIGPLAN International Symposium on Scala,"St. Louis, MO, USA",2018,9781450358361,,https://doi.org/10.1145/3241653.3241659;http://dx.doi.org/10.1145/3241653.3241659,10.1145/3241653.3241659,"Scala unifies concepts from object and module systems by allowing for objects with type members which are referenced via path-dependent types. The Dependent Object Types (DOT) calculus of Amin et al. models only this core part of Scala, but does not have many fundamental features of Scala such as strict and mutable fields. Since the most commonly used field types in Scala are strict,the correspondence between DOT and Scala is too weak for us to meaningfully prove static analyses safe for Scala by proving them safe for DOT. A DOT calculus that can support strict and mutable fields together with constructors that do field initialization would be more suitable for analysis of Scala. Toward this goal, we present κDOT, an extension of DOT that supports constructors and field mutation and can emulate the different types of fields in Scala. We have proven κDOT sound through a mechanized proof in Coq. We present the key features of κDOT and its operational semantics and discuss work-in-progress toward making κDOT fully strict.","mutation, type safety, dependent object types",Scala 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Wintner S,Towards a Linguistically Motivated Computational Grammar for Hebrew,,1998,,,82–88,Association for Computational Linguistics,USA,,Proceedings of the Workshop on Computational Approaches to Semitic Languages,"Montreal, Quebec, Canada",1998,,,,,"While the morphology of Modern Hebrew is well accounted for computationally, there are few computational grammars describing the syntax of the language. Existing grammars are scarcely based on solid linguistic grounds: they do not conform to any particular linguistic theory and do not provide a linguistically plausible analysis for the data they cover. This paper presents a first attempt towards the construction of a formal grammar for a fragment of Hebrew that is both linguistically motivated and computationally implementable. The grammar, concentrating on the structure of noun phrases, is designed in accordance with HPSG, a linguistic theory that lends itself most naturally to computational implementation. It is the first application of HPSG to any Semitic language. Several theoretical issues are addressed, including the status of the definite article, the application of the DP hypothesis to Hebrew, definiteness agreement in the noun phrase as well as definiteness inheritance in constructs. All the analyses presented in the paper were tested and their predictions were verified. This is a work in progress, and the results described herein are preliminary.",,Semitic '98,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xing Z,Zhenhai W,Bo X",Object Tracking Based on Kernelized Correlation Filter with HOG and Illumination Invariant Features,,2018,,,123–127,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 2nd International Conference on Big Data and Internet of Things,"Beijing, China",2018,9781450365192,,https://doi.org/10.1145/3289430.3289453;http://dx.doi.org/10.1145/3289430.3289453,10.1145/3289430.3289453,"In order to improve accuracy and robustness of object tracking and meet the demand of real-time tracking, this paper presents a new tracking algorithm based on kernelized correlation filter with Histogram of Oriented Gradient(HOG) and illumination invariant features. At first, we calculated locality sensitive histogram of input image and extracted the illumination invariant features. Then we calculated HOG features, put illumination invariant features into the kernel circulant matrix based on HOG features. The tracking position is obtained by the responding confidence image, which can be quickly computed in the Fourier domain. Tests of many video sequences prove that the new algorithm has a better tracking performance than the traditional kernel circulant algorithm. The average tracking error of the new algorithm is 53 pixels lower than the kernel circulant algorithm, and the tracking precision is increased by 39%. As a result, the new algorithm can adapt to the conditions of illumination changes, pose variation and object occlusion.","Kernel circulant algorithm, Histogram of Oriented Gradient, Object tracking, Illumination invariant features",BDIOT 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Burton E,Sekerinski E",The Safety of Dynamic Mixin Composition,,2015,,,1992–1999,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th Annual ACM Symposium on Applied Computing,"Salamanca, Spain",2015,9781450331968,,https://doi.org/10.1145/2695664.2695938;http://dx.doi.org/10.1145/2695664.2695938,10.1145/2695664.2695938,"Dynamic mixins are a modular means of developing features or roles that can be composed with objects at run-time. However, naive use of this construct can cause unexpected behaviour due to interference caused by the presence of an object's previously bound mixins. This work proposes a method for developing mixins that can be bound to base objects such that the mixins do not interfere with each other; the method achieves compositionally through a coupling invariant and by syntactically restricting mixins. The refinement calculus is used for formalization, as it treats implementations and specifications uniformly. The formalization relies on a new notion of mixin refinement.","refinement, mixins, compositionality, safety, modularity",SAC '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Krishna A,Pallec ML,Mateescu R,Noirie L,Salaün G",Rigorous Design and Deployment of IoT Applications,,2019,,,21–30,IEEE Press,"Montreal, Quebec, Canada",,Proceedings of the 7th International Workshop on Formal Methods in Software Engineering,,2019,,,https://doi.org/10.1109/FormaliSE.2019.00011;http://dx.doi.org/10.1109/FormaliSE.2019.00011,10.1109/FormaliSE.2019.00011,"Internet connected devices are becoming increasingly common in consumer homes. These devices combined with software entities are used to build Internet of Things (IoT) applications. As democratization of IoT takes shape, developing reliable IoT applications remains a challenge for consumers because these applications exhibit characteristics such as distribution, dynamicity, and heterogeneity, which make their design, development and maintenance difficult. In this paper, we use formal methods to ensure correct composition of objects and propose a reliable deployment mechanism in the context of an IoT application. Objects are modelled using an interface description model integrating a behavioural specification of the object functionality. We provide formal validation techniques for verifying that the composition is correct. A deployment plan is generated for automating the instantiation of all objects involved in a valid composition. All the proposals have been implemented as a prototype tool and experiments were carried out for evaluating the tool performance and usability.","formal verification, IoT, deployment, composition, behavioural modelling",FormaliSE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mattis T,Rein P,Hirschfeld R","Ambiguous, Informal, and Unsound: Metaprogramming for Naturalness",,2019,,,1–10,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th ACM SIGPLAN International Workshop on Meta-Programming Techniques and Reflection,"Athens, Greece",2019,9781450369855,,https://doi.org/10.1145/3358502.3361270;http://dx.doi.org/10.1145/3358502.3361270,10.1145/3358502.3361270,"Program code needs to be understood by both machines and programmers. While the goal of executing programs requires the unambiguity of a formal language, programmers use natural language within these formal constraints to explain implemented concepts to each other. This so called naturalness – the property of programs to resemble human communication – motivated many statistical and machine learning (ML) approaches with the goal to improve software engineering activities. The metaprogramming facilities of most programming environments model the formal elements of a program (meta-objects). If ML is used to support engineering or analysis tasks, complex infrastructure needs to bridge the gap between meta-objects and ML models, changes are not reflected in the ML model, and the mapping from an ML output back into the program’s meta-object domain is laborious. In the scope of this work, we propose to extend metaprogramming facilities to give tool developers access to the representations of program elements within an exchangeable ML model. We demonstrate the usefulness of this abstraction in two case studies on test prioritization and refactoring. We conclude that aligning ML representations with the program’s formal structure lowers the entry barrier to exploit statistical properties in tool development.","meta-objects, machine learning, metaprogramming, naturalness",META 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kamaruddin N,Maarop N,Narayana G",Fractional Active Contour Model for Edge Detector on Medical Image Segmentation,,2020,,,39–44,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2020 2nd International Conference on Image, Video and Signal Processing","Singapore, Singapore",2020,9781450376952,,https://doi.org/10.1145/3388818.3388829;http://dx.doi.org/10.1145/3388818.3388829,10.1145/3388818.3388829,"In computer terms, segmentation is a process to partition or to divide an image based on the number of objects within the image. The process of segmentation can be easy depending on the quality of the image such as the level of noise, the image contrast and etc. Segmentation on medical images has its own importance such as to extract an importance object like tumor or others, to assist the physician in making decision for surgery purposes. Currently many methods have been developed but to get accuracy in segmenting multi modalities of medical images are still remain unsuccessful. Among all methods, Active Contour Model shows good potential in medical image segmentation. But, accuracy in detecting edges along the object boundary is still remain unsuccessful. The used of fractional calculus that act as the first order integer to extract the missing pixels along the object boundary is seen to have the potential in solving the problem. This paper proposed a method called, Fractional Active Contour (FAC) model. The proposed method tends to highlight the role of fractional as an operator to detect and preserve the missing edges as well as giving the bending capability to the contour of the model. Experiments on several medical images from MRI, CT Scan and X-ray images demonstrates that the proposed FAC with the usage of the powerful fractional calculus as the edge detector model realizes an accurate boundary segmentation although under the constraint of missing edges within the environment of intensity inhomogeneity.","Active Contour Model, Boundary Value Segmentation, Fractional Calculus, Medical Image Segmentation",IVSP '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gatouillat A,Badr Y",Verifiable and Resource-Aware Component Model for IoT Devices,,2017,,,235–242,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Management of Digital EcoSystems,"Bangkok, Thailand",2017,9781450348959,,https://doi.org/10.1145/3167020.3167056;http://dx.doi.org/10.1145/3167020.3167056,10.1145/3167020.3167056,"Most connected objects feature very limited capabilities that present challenges in terms of data processing and connectivity. In addition, heterogeneity of smart Internet-of-Things devices also causes interoperability problems. These limitations lead to strong hardware and software constraints that must be considered as early as possible during the design process. In this paper, we introduce a smart object component-based model to build complex smart objects by composition mechanisms in a similar way to Web service compositions. The smart object model extends artifact types and describes its structure and behavior in terms of attribute value pair, state-based lifecycle and services. Moreover, we propose a formal specification based on the intuitive multiplicative segment of intuitionistic linear logic not only to express consumable resources but also to automate composition from logical proofs.","formal verification, Linear logic, connected objects composition",MEDES '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Wallgrün JO,Exploiting Qualitative Spatial Reasoning for Topological Adjustment of Spatial Data,,2012,,,229–238,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th International Conference on Advances in Geographic Information Systems,"Redondo Beach, California",2012,9781450316910,,https://doi.org/10.1145/2424321.2424351;http://dx.doi.org/10.1145/2424321.2424351,10.1145/2424321.2424351,"Formal models of spatial relations such as the 9-Intersection model or RCC-8 have become omnipresent in the spatial information sciences and play an important role to formulate constraints in many applications of spatial data processing. A fundamental problem in such applications is to adapt geometric data to satisfy certain relational constraints while minimizing the changes that need to be made to the data. We address the problem of adjusting geometric objects to meet the spatial relations from a qualitative spatial calculus, forming a bridge between the areas of qualitative spatial representation and reasoning (QSR) and of geometric adjustment using optimization approaches. In particular, we explore how constraint-based QSR techniques can be beneficially employed to improve the optimization process. We discuss three different ways in which QSR can be utilized and then focus on its application to reduce the complexity of the optimization problem in terms of variables and equations needed. We propose two constraint-based problem simplification algorithms and evaluate them experimentally. Our results demonstrate that exploiting QSR techniques indeed leads to a significant performance improvement.","qualitative spatial reasoning, constrained optimization, topological relations, adjustment, conflation, data cleaning",SIGSPATIAL '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Emmi M,Enea C,Hamza J",Monitoring Refinement via Symbolic Reasoning,,2015,,,260–269,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Portland, OR, USA",2015,9781450334686,,https://doi.org/10.1145/2737924.2737983;http://dx.doi.org/10.1145/2737924.2737983,10.1145/2737924.2737983,"Efficient implementations of concurrent objects such as semaphores, locks, and atomic collections are essential to modern computing. Programming such objects is error prone: in minimizing the synchronization overhead between concurrent object invocations, one risks the conformance to reference implementations — or in formal terms, one risks violating observational refinement. Precisely testing this refinement even within a single execution is intractable, limiting existing approaches to executions with very few object invocations. We develop scalable and effective algorithms for detecting refinement violations. Our algorithms are founded on incremental, symbolic reasoning, and exploit foundational insights into the refinement-checking problem. Our approach is sound, in that we detect only actual violations, and scales far beyond existing violation-detection algorithms. Empirically, we find that our approach is practically complete, in that we detect the violations arising in actual executions.","Concurrency, Refinement, Linearizability",PLDI '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Emmi M,Enea C,Hamza J",Monitoring Refinement via Symbolic Reasoning,SIGPLAN Not.,2015,50,6,260–269,Association for Computing Machinery,"New York, NY, USA",,,,2015-06,,0362-1340,https://doi.org/10.1145/2813885.2737983;http://dx.doi.org/10.1145/2813885.2737983,10.1145/2813885.2737983,"Efficient implementations of concurrent objects such as semaphores, locks, and atomic collections are essential to modern computing. Programming such objects is error prone: in minimizing the synchronization overhead between concurrent object invocations, one risks the conformance to reference implementations — or in formal terms, one risks violating observational refinement. Precisely testing this refinement even within a single execution is intractable, limiting existing approaches to executions with very few object invocations. We develop scalable and effective algorithms for detecting refinement violations. Our algorithms are founded on incremental, symbolic reasoning, and exploit foundational insights into the refinement-checking problem. Our approach is sound, in that we detect only actual violations, and scales far beyond existing violation-detection algorithms. Empirically, we find that our approach is practically complete, in that we detect the violations arising in actual executions.","Concurrency, Linearizability, Refinement",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shaowen D,Xiaohu Z,Jie W,Hongliang Z,Lijun Z",Large Scale Object Measurement Based on Data Fusion of Stereo Camera's Multi-Viewpoint Images,,2018,,,97–101,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 10th International Conference on Computer and Automation Engineering,"Brisbane, Australia",2018,9781450364102,,https://doi.org/10.1145/3192975.3192995;http://dx.doi.org/10.1145/3192975.3192995,10.1145/3192975.3192995,"Multi-view photogrammetry is a method to obtain the spatial position of the target points in the field of view by fusing image data from multi-viewpoint, it's suitable for the measurement of large scale object's surface dimension parameters, which may under the circumstance of occlusion. The multi-view photogrammetry based on single camera needs to arrange scale datum into the measurement area, image acquisition process is complex, and requires a high overlap ratio between adjacent images. In this paper, a method of multi-view photogrammetry using stereo camera is presented, this method not only inherits the advantages of large measurement range in multi-view reconstruction, but also does not need to arrange scale datum, and the image acquisition process is simpler. Firstly the internal parameters and solid connection of two cameras installed on the fixed rod are obtained according to camera calibration. Then we use the stereo camera to acquire the images of the area to be measured and get the spatial point cloud by binocular intersection. Calculate the transformation relation of the coordinate system of point cloud in adjacent viewpoint by the method of pose estimation, and transform the camera's parameters and point cloud's coordinate of each moment to the specified coordinate system. The position and pose of the camera and the coordinate of point cloud are optimized by using bundle adjustment, the size parameters and deformation information can be calculated from the point cloud coordinates. The test results show that in the range of 5 meters the measurement's error is 3mm, the average error is 1mm. This method is suitable for the measurement of large scale object and scene, the algorithm is stable and reliable.","Large scale object measurement, Multi-view photogrammetry, Stereo camera, Images data fusion",ICCAE 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bejleri A,Farrell A,Goldsack P",Cloudscape: Language Support to Coordinate and Control Distributed Applications in the Cloud,,2011,,,183–194,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Compilation of the Co-Located Workshops on DSM'11, TMC'11, AGERE! 2011, AOOPES'11, NEAT'11, & VMIL'11","Portland, Oregon, USA",2011,9781450311830,,https://doi.org/10.1145/2095050.2095080;http://dx.doi.org/10.1145/2095050.2095080,10.1145/2095050.2095080,"Cloud Computing is an innovative computing proposal, which key feature is the ease and effectiveness of providing a service. There are a number of challenges that a management system for the Cloud will need to address including: scale, reliability (fault-handling and high availability), security and service heterogeneity, to achieve effectiveness.This paper proposes an agent-oriented language, called CLOUDSCAPE, to address coordination and control of components in a distributed computation to provide reliability and scalability of service in the context of the Cloud. Agents are modeled as objects extended with transitions and dependencies to describe the lifecycle state machines of components and constraints between lifecycle states. The problem context is further extended with component failure and dynamic addition of new components. The practical utility and effectiveness of this system is illustrated through a series of real-world examples. We then define a formal model of the language and prove that the operational semantics of the language holds a linear consistent shared memory property.","linear shared memory, control and coordination, cloud",SPLASH '11 Workshops,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Backes M,Maffei M,Unruh D",Computationally Sound Verification of Source Code,,2010,,,387–398,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th ACM Conference on Computer and Communications Security,"Chicago, Illinois, USA",2010,9781450302456,,https://doi.org/10.1145/1866307.1866351;http://dx.doi.org/10.1145/1866307.1866351,10.1145/1866307.1866351,"Increasing attention has recently been given to the formal verification of the source code of cryptographic protocols. The standard approach is to use symbolic abstractions of cryptography that make the analysis amenable to automation. This leaves the possibility of attacks that exploit the mathematical properties of the cryptographic algorithms themselves. In this paper, we show how to conduct the protocol analysis on the source code level (F# in our case) in a computationally sound way, i.e., taking into account cryptographic security definitions.We build upon the prominent F7 verification framework (Bengtson et al., CSF 2008) which comprises a security type-checker for F# protocol implementations using symbolic idealizations and the concurrent lambda calculus RCF to model a core fragment of F#.To leverage this prior work, we give conditions under which symbolic security of RCF programs using cryptographic idealizations implies computational security of the same programs using cryptographic algorithms. Combined with F7, this yields a computationally sound, automated verification of F# code containing public-key encryptions and signatures.For the actual computational soundness proof, we use the CoSP framework (Backes, Hofheinz, and Unruh, CCS 2009). We thus inherit the modularity of CoSP, which allows for easily extending our proof to other cryptographic primitives.","computational soundness, source code, verification",CCS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Koulieris GA,Drettakis G,Cunningham D,Mania K",An Automated High-Level Saliency Predictor for Smart Game Balancing,ACM Trans. Appl. Percept.,2014,11,4,,Association for Computing Machinery,"New York, NY, USA",,,,2014-12,,1544-3558,https://doi.org/10.1145/2637479;http://dx.doi.org/10.1145/2637479,10.1145/2637479,"Successfully predicting visual attention can significantly improve many aspects of computer graphics: scene design, interactivity and rendering. Most previous attention models are mainly based on low-level image features, and fail to take into account high-level factors such as scene context, topology, or task. Low-level saliency has previously been combined with task maps, but only for predetermined tasks. Thus, the application of these methods to graphics (e.g., for selective rendering) has not achieved its full potential. In this article, we present the first automated high-level saliency predictor incorporating two hypotheses from perception and cognitive science that can be adapted to different tasks. The first states that a scene is comprised of objects expected to be found in a specific context as well objects out of context which are salient (scene schemata) while the other claims that viewer’s attention is captured by isolated objects (singletons). We propose a new model of attention by extending Eckstein’s Differential Weighting Model. We conducted a formal eye-tracking experiment which confirmed that object saliency guides attention to specific objects in a game scene and determined appropriate parameters for a model. We present a GPU-based system architecture that estimates the probabilities of objects to be attended in real- time. We embedded this tool in a game level editor to automatically adjust game level difficulty based on object saliency, offering a novel way to facilitate game design. We perform a study confirming that game level completion time depends on object topology as predicted by our system.","Computer graphics, game balancing, scene schemata",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Newton RR,Ağacan ÖS,Fogg P,Tobin-Hochstadt S",Parallel Type-Checking with Haskell Using Saturating LVars and Stream Generators,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming,"Barcelona, Spain",2016,9781450340922,,https://doi.org/10.1145/2851141.2851142;http://dx.doi.org/10.1145/2851141.2851142,10.1145/2851141.2851142,"Given the sophistication of recent type systems, unification-based type-checking and inference can be a time-consuming phase of compilation---especially when union types are combined with subtyping. It is natural to consider improving performance through parallelism, but these algorithms are challenging to parallelize due to complicated control structure and difficulties representing data in a way that is both efficient and supports concurrency. We provide techniques that address these problems based on the LVish approach to deterministic-by-default parallel programming. We extend LVish with Saturating LVars, the first LVars implemented to release memory during the object's lifetime. Our design allows us to achieve a parallel speedup on worst-case (exponential) inputs of Hindley-Milner inference, and on the Typed Racket type-checking algorithm, which yields up an 8.46× parallel speedup on 14 cores for type-checking examples drawn from the Racket repository.",,PPoPP '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Newton RR,Ağacan ÖS,Fogg P,Tobin-Hochstadt S",Parallel Type-Checking with Haskell Using Saturating LVars and Stream Generators,SIGPLAN Not.,2016,51,8,,Association for Computing Machinery,"New York, NY, USA",,,,2016-02,,0362-1340,https://doi.org/10.1145/3016078.2851142;http://dx.doi.org/10.1145/3016078.2851142,10.1145/3016078.2851142,"Given the sophistication of recent type systems, unification-based type-checking and inference can be a time-consuming phase of compilation---especially when union types are combined with subtyping. It is natural to consider improving performance through parallelism, but these algorithms are challenging to parallelize due to complicated control structure and difficulties representing data in a way that is both efficient and supports concurrency. We provide techniques that address these problems based on the LVish approach to deterministic-by-default parallel programming. We extend LVish with Saturating LVars, the first LVars implemented to release memory during the object's lifetime. Our design allows us to achieve a parallel speedup on worst-case (exponential) inputs of Hindley-Milner inference, and on the Typed Racket type-checking algorithm, which yields up an 8.46× parallel speedup on 14 cores for type-checking examples drawn from the Racket repository.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kitayama D,Lee R,Sumiya K",A Credibility Analyzing Method of Geographical Objects from Digital Maps,,2009,,,536–543,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Ubiquitous Information Management and Communication,"Suwon, Korea",2009,9781605584058,,https://doi.org/10.1145/1516241.1516335;http://dx.doi.org/10.1145/1516241.1516335,10.1145/1516241.1516335,"Digital maps is widely used and appears on all types of platforms for integrating content. However, map media contain a large amount of content and updates. In addition, update times are different for each supplier. Digital maps often display nonexisting geographical objects or do not display newly created geographical objects. In other words, map media has no credibility. Users who believe that a digital map is correct may encounter problems. We propose a calculating method for determining an object's existence value in displayed geographical objects in digital maps for map credibility. In particular, we extract temporal web pages of each geographical object using co-occurring geographical objects. We calculate the degree of existential support using update history of temporal web pages. Finally, we calculate an object existence value based on all degrees of support. We display map content with valid object for deciding map credibility. We developed a prototype system and evaluated our proposed method.","information credibility, digital map, spatio temporal DB, user operation",ICUIMC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Jeffery A,Dependent Object Types with Implicit Functions,,2019,,,1–11,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Tenth ACM SIGPLAN Symposium on Scala,"London, United Kingdom",2019,9781450368247,,https://doi.org/10.1145/3337932.3338811;http://dx.doi.org/10.1145/3337932.3338811,10.1145/3337932.3338811,"DOT (Dependent Object Types) is an object calculus with path-dependent types and abstract type members, developed to serve as a theoretical foundation for the Scala programming language. As yet, DOT does not model all of Scala's features, but a small subset. We present the calculus DIF (DOT with Implicit Functions), which extends the set of features modelled by DOT to include implicit functions, a feature of Scala to aid modularity of programs. We show type safety of DIF, and demonstrate that the generic programming focused use cases for implicit functions in Scala are also expressible in DIF.","Scala, implicit parameters, type classes, implicit functions, implicits, Dotty, DOT, objects, dependent object types, calculus",Scala '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Melgratti H,Padovani L",Chaperone Contracts for Higher-Order Sessions,Proc. ACM Program. Lang.,2017,1,ICFP,,Association for Computing Machinery,"New York, NY, USA",,,,2017-08,,,https://doi.org/10.1145/3110279;http://dx.doi.org/10.1145/3110279,10.1145/3110279,"Contracts have proved to be an effective mechanism that helps developers in identifying those modules of a program that violate the contracts of the functions and objects they use. In recent years, sessions have established as a key mechanism for realizing inter-module communications in concurrent programs. Just like values flow into or out of a function or object, messages are sent on, and received from, a session endpoint. Unlike conventional functions and objects, however, the kind, direction, and properties of messages exchanged in a session may vary over time, as the session progresses. This feature of sessions calls for contracts that evolve along with the session they describe. In this work, we extend to sessions the notion of chaperone contract (roughly, a contract that applies to a mutable object) and investigate the ramifications of contract monitoring in a higher-order language that features sessions. We give a characterization of correct module, one that honors the contracts of the sessions it uses, and prove a blame theorem. Guided by the calculus, we describe a lightweight implementation of monitored sessions as an OCaml module with which programmers can benefit from static session type checking and dynamic contract monitoring using an off-the-shelf version of OCaml.","sessions, Chaperone contracts, OCaml, blame soundness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bouajjani A,Emmi M,Enea C,Hamza J",Tractable Refinement Checking for Concurrent Objects,,2015,,,651–662,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 42nd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Mumbai, India",2015,9781450333009,,https://doi.org/10.1145/2676726.2677002;http://dx.doi.org/10.1145/2676726.2677002,10.1145/2676726.2677002,"Efficient implementations of concurrent objects such as semaphores, locks, and atomic collections are essential to modern computing. Yet programming such objects is error prone: in minimizing the synchronization overhead between concurrent object invocations, one risks the conformance to reference implementations --- or in formal terms, one risks violating observational refinement. Testing this refinement even within a single execution is intractable, limiting existing approaches to executions with very few object invocations.We develop a polynomial-time (per execution) approximation to refinement checking. The approximation is parameterized by an accuracy k∈N representing the degree to which refinement violations are visible. In principle, more violations are detectable as k increases, and in the limit, all are detectable. Our insight for this approximation arises from foundational properties on the partial orders characterizing the happens-before relations between object invocations: they are interval orders, with a well defined measure of complexity, i.e., their length. Approximating the happens-before relation with a possibly-weaker interval order of bounded length can be efficiently implemented by maintaining a bounded number of integer counters. In practice, we find that refinement violations can be detected with very small values of k, and that our approach scales far beyond existing refinement-checking approaches.","refinement, concurrency, linearizability",POPL '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Bouajjani A,Emmi M,Enea C,Hamza J",Tractable Refinement Checking for Concurrent Objects,SIGPLAN Not.,2015,50,1,651–662,Association for Computing Machinery,"New York, NY, USA",,,,2015-01,,0362-1340,https://doi.org/10.1145/2775051.2677002;http://dx.doi.org/10.1145/2775051.2677002,10.1145/2775051.2677002,"Efficient implementations of concurrent objects such as semaphores, locks, and atomic collections are essential to modern computing. Yet programming such objects is error prone: in minimizing the synchronization overhead between concurrent object invocations, one risks the conformance to reference implementations --- or in formal terms, one risks violating observational refinement. Testing this refinement even within a single execution is intractable, limiting existing approaches to executions with very few object invocations.We develop a polynomial-time (per execution) approximation to refinement checking. The approximation is parameterized by an accuracy k∈N representing the degree to which refinement violations are visible. In principle, more violations are detectable as k increases, and in the limit, all are detectable. Our insight for this approximation arises from foundational properties on the partial orders characterizing the happens-before relations between object invocations: they are interval orders, with a well defined measure of complexity, i.e., their length. Approximating the happens-before relation with a possibly-weaker interval order of bounded length can be efficiently implemented by maintaining a bounded number of integer counters. In practice, we find that refinement violations can be detected with very small values of k, and that our approach scales far beyond existing refinement-checking approaches.","linearizability, refinement, concurrency",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"De Giacomo G,Lespérance Y,Patrizi F,Vassos S",Progression and Verification of Situation Calculus Agents with Bounded Beliefs,,2014,,,141–148,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems,"Paris, France",2014,9781450327381,,,,"In this paper we investigate agents that have incomplete information and make decisions based on their beliefs, expressed as situation calculus bounded action theories. Such theories have an infinite object domain, but the number of objects that belong to fluents at each time point is bounded by a given constant. Recently it has been shown that verifying temporal properties over such theories is decidable. Here, we first show that we can actually check whether an arbitrary action theory maintains boundedness. Secondly, we examine progression. Progression can be thought of as capturing the notion of belief states resulting from actions in the situation calculus. In the general case, such belief states can be expressed only in second-order logic. Here, we show that for bounded action theories, progression, and hence belief states, can always be represented in first-order logic. Based on this result, we further prove decidability of temporal verification over online executions, i.e., those executions resulting from agents performing only actions that are feasible according to their beliefs.","bounded action theories, progression, verification of agents, situation calculus, online execution",AAMAS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Allen RB,"Visualization, Causation, and History",,2011,,,538–545,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 IConference,"Seattle, Washington, USA",2011,9781450301213,,https://doi.org/10.1145/1940761.1940835;http://dx.doi.org/10.1145/1940761.1940835,10.1145/1940761.1940835,"History may be seen as a tapestry of interwoven events. The discourse structure of that tapestry may be identified and used to support visualization for examining and interacting with the tapestry of history. Specifically, we propose temporally constrained causal relationships as a key for organizing that tapestry. Because Events occur at different levels of granularity and similar ones may occur with cumulative effect, we introduce Trends. Trends are first-class objects; that is, in this model Trends may be causes of Events. To facilitate interaction with a rich tapestry of complex historical events such as the American Civil War, we also introduce Threads. These are chains of Events, and presentations of them may be considered a type of narrative. We describe a panel-oriented visualization interface that shows causal Threads of Events and Trends leading up to the Civil War. This initial prototype is intended to present history at the level of an intermediate textbook. Finally, we introduce a semi-formal notation for describing Events, Threads, and Trends, and propose directions for future research to refine the prototype that may enable broader, deeper, more flexible, and more complete exploration/presentation of historical materials.","discourse, digital humanities, causation, visualization, timelines, narrative, history",iConference '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brandherm B,Prendinger H,Ishizuka M",Dynamic Bayesian Network Based Interest Estimation for Visual Attentive Presentation Agents,,2008,,,191–198,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 7th International Joint Conference on Autonomous Agents and Multiagent Systems - Volume 1,"Estoril, Portugal",2008,9780981738109,,,,"In this paper, we report on an interactive system and the results ofa formal user study that was carried out with the aim of comparing two approaches to estimating users' interest in a multimodal presentation based on their eye gaze. The scenario consists of a virtual showroom where two 3D agents present product items in an entertaining way, and adapt their performance according to users' (in)attentiveness. In order to infer users' attention and visual interest with regard to interface objects, our system analyzes eye movements in real-time. Interest detection algorithms used in previous research determine an object of interest based on the time that eye gaze dwells on that object. However, this kind of algorithm does not seem to be well suited for dynamic presentations where the goal is to assess the user's focus of attention with regard to a dynamically changing presentation. Here, the current context of the object of interest has to be considered, i.e., whether the visual object is part of (or contributes to) the current presentation content or not. Therefore, we propose to estimate the interest (or non-interest) of a user by means of dynamic Bayesian networks that may take into account the current context of the attention receiving object. In this way, the presentation agents can provide timely and appropriate response. The benefits of our approach will be demonstrated both theoretically and empirically.",,AAMAS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kerfoot E,McKeever S,Torshizi F",Deadlock Freedom through Object Ownership,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,"International Workshop on Aliasing, Confinement and Ownership in Object-Oriented Programming","Genova, Italy",2009,9781605585468,,https://doi.org/10.1145/1562154.1562157;http://dx.doi.org/10.1145/1562154.1562157,10.1145/1562154.1562157,"Active objects are an attractive method of introducing concurrency into Java-like languages by decoupling method execution from invocation. In this paper, we show how ownership is used in the Java [14] subset language CoJava [17] to prevent deadlock associated with active object method calls. This approach builds on existing type-based approaches that eliminates data races and data-based deadlock in concurrent systems. The novel addition is the use of ownership to organize active objects, thus preventing deadlock from arising when objects are allowed to block awaiting responses from others.Typechecking is used to prevent threads from sharing mutable data, thus CoJava is free of data races and data-based deadlock. Behavioural deadlock is prevented by the use of promise objects which prevent clients from blocking indefinitely while awaiting responses. Ownership imposes a hierarchy on active objects; this allows owners to safely block while waiting for responses from owned objects. The paper also discusses the implications of this approach to specification with JML, formal reasoning about programs, and the consequences to runtime assertion checking.","concurrency, active objects, CoJava, Java, deadlock, ownership, data races",IWACO '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jäkel T,Kühn T,Voigt H,Lehner W",RSQL - a Query Language for Dynamic Data Types,,2014,,,185–194,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th International Database Engineering & Applications Symposium,"Porto, Portugal",2014,9781450326278,,https://doi.org/10.1145/2628194.2628246;http://dx.doi.org/10.1145/2628194.2628246,10.1145/2628194.2628246,"Database Management Systems (DBMS) are used by software applications, to store, manipulate, and retrieve large sets of data. However, the requirements of current software systems pose various challenges to established DBMS. First, most software systems organize their data by means of objects rather than relations leading to increased maintenance, redundancy, and transformation overhead when persisting objects to relational databases. Second, complex objects are separated into several objects resulting in Object Schizophrenia and hard to persist Distributed State. Last but not least, current software systems have to cope with increased complexity and changes. These challenges have lead to a general paradigm shift in the development of software systems. Unfortunately, classical DBMS will become intractable, if they are not adapted to the new requirements imposed by these software systems. As a result, we propose an extension of DBMS with roles to represent complex objects within a relational database and support the flexibility required by current software systems. To achieve this goal, we introduces RSQL, an extension to SQL with the concept of objects playing roles when interacting with other objects. Additionally, we present a formal model for the logical representation of roles in the extended DBMS.","role persistency, dynamic data type, conceptual query language, dynamic tuple, role model",IDEAS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Serbanescu V,de Boer F",On the Nature of Cooperative Scheduling in Active Objects,,2020,,,1322–1329,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th Annual ACM Symposium on Applied Computing,"Brno, Czech Republic",2020,9781450368667,,https://doi.org/10.1145/3341105.3373896;http://dx.doi.org/10.1145/3341105.3373896,10.1145/3341105.3373896,"Active objects interact via asynchronous messages which specify method invocations. In contrast to the run to completion mode of method execution, mechanisms for suspending the execution of a method allow an active object to schedule cooperatively its methods in a co-routine manner. In this paper, we show how cooperative scheduling can be reduced to a run to completion mode of execution. We do so by a formal translation using a guarded command language for describing the execution of method bodies.","run to completion, semantics, active objects, cooperative scheduling, correctness",SAC '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liu W,Li J",Distributed LoD Algorithm for Complex Virtual Environments,,1996,,,21–25,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM Symposium on Virtual Reality Software and Technology,Hong Kong,1996,9780897918251,,https://doi.org/10.1145/3304181.3304187;http://dx.doi.org/10.1145/3304181.3304187,10.1145/3304181.3304187,"The method of level-of-detail (LoD) is effective in conquering complex models of virtual environments. In LoD each object has multiple models with different complexity. Depending on a set of decision criteria (like size and focus) an LoD algorithm analyses objects' importance and chooses a suitable LoD for each object. Here we present a distributed LoD algorithm which accurately decides the objects' importance. The algorithm uses a server to pre-display all objects and calculate their criteria by reading the image buffer. The idea behind this algorithm is to decide an object's importance according to its size, position and shape on the screen.","level-of-detail, selection criteria, virtual environment, distributed algorithm, object's importance",VRST '96,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Weninger M,Gander E,Mössenböck H",Utilizing Object Reference Graphs and Garbage Collection Roots to Detect Memory Leaks in Offline Memory Monitoring,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th International Conference on Managed Languages & Runtimes,"Linz, Austria",2018,9781450364249,,https://doi.org/10.1145/3237009.3237023;http://dx.doi.org/10.1145/3237009.3237023,10.1145/3237009.3237023,"Complex software systems often suffer from performance problems caused by memory anomalies such as memory leaks. While the proliferation of objects is rather easy to detect using state-of-the-art memory monitoring tools, extracting a leak's root cause, i.e., identifying the objects that keep the accumulating objects alive, is still poorly supported. Most state-of-the-art tools rely on the dominator tree of the object graph and thus only support single-object ownership analysis. Multi-object ownership analysis, e.g., when the leaking objects are contained in multiple collections, is not possible by merely relying on the dominator tree. We present an efficient approach to continuously collect GC root information (e.g., static fields or thread-local variables) in a trace-based memory monitoring tool, as well as algorithms that use this information to calculate the transitive closure (i.e., all reachable objects) and the GC closure (i.e., objects that are kept alive) for arbitrary heap object groups. These closures allow to derive various metrics for heap object groups that can be used to guide the user during memory leak analysis. We implemented our approach in AntTracks, an offline memory monitoring tool, and demonstrate its usefulness by comparing it with other widely used tools for memory leak detection such as the Eclipse Memory Analyzer. Our evaluation shows that collecting GC root information tracing introduces about 1% overhead, in terms of run time as well as trace file size.","graph closure, memory leak, memory monitoring, pointer analysis, garbage collection",ManLang '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Amálio N,de Lara J,Guerra E",Fragmenta: A Theory of Fragmentation for MDE,,2015,,,106–115,IEEE Press,"Ottawa, Ontario, Canada",,Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems,,2015,9781467369084,,,,"Model-Driven Engineering (MDE) promotes models throughout development. However, models may become large and unwieldy even for small to medium-sized systems. This paper tackles the MDE challenges of model complexity and scalability. It proposes Fragmenta, a theory of modular design that breaks down overall models into fragments that can be put together to build meaningful wholes, in contrast to classical MDE approaches that are essentially monolithic. The theory is based on an algebraic description of models, fragments and clusters based on graphs and morphisms. The paper's novelties include: (i) a mathematical treatment of fragments and a seaming mechanism of proxies to enable inter-fragment referencing, (ii) fragmentation strategies, which prescribe a fragmentation structure to model instances, (iii) Fragmenta's support for both top-down and bottom-up design, and (iv) our formally proved result that shows that inheritance hierarchies remain well-formed (acyclic) globally when fragments are composed provided some local fragment constraints are met.","graphs, model composition, meta-modelling, model-driven engineering, modularity, scalability",MODELS '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Katzakis N,Seki K,Kiyokawa K,Takemura H",Mesh-Grab and Arcball-3D: Ray-Based 6-DOF Object Manipulation,,2013,,,129–136,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th Asia Pacific Conference on Computer Human Interaction,"Bangalore, India",2013,9781450322539,,https://doi.org/10.1145/2525194.2525198;http://dx.doi.org/10.1145/2525194.2525198,10.1145/2525194.2525198,"Manipulation of 3D objects is important for collaboration and education, where a presenter might wish to manipulate a 3D object to present it to an audience. We present Mesh-Grab and Arcball-3D; two ray-based techniques for manipulating remote 3D objects using a handheld wand and present the results of a formal evaluation session where we compared them against the state-of-the-art in direct interaction techniques. In a 6-DOF docking task, our proposed techniques performed slightly slower than Scaled HOMER but overall, participants showed preference towards Arcball-3D and complained about fatigue and awkward arm postures on Scaled HOMER. In addition to the users' preference, as ray-based techniques do not require full-range rotation, we conclude that they are a viable alternative to direct interaction.","rotation, manipulation, interaction, translation, ray-casting, 6DOF",APCHI '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Murawski AS,Tzevelekos N",Game Semantics for Interface Middleweight Java,J. ACM,2020,68,1,,Association for Computing Machinery,"New York, NY, USA",,,,2020-12,,0004-5411,https://doi.org/10.1145/3428676;http://dx.doi.org/10.1145/3428676,10.1145/3428676,"We consider an object calculus in which open terms interact with the environment through interfaces. The calculus is intended to capture the essence of contextual interactions of Middleweight Java code. Using game semantics, we provide fully abstract models for the induced notions of contextual approximation and equivalence. These are the first denotational models of this kind.","contextual equivalence, Full abstraction, game semantics, Java",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rapoport M,Lhoták O",A Path to DOT: Formalizing Fully Path-Dependent Types,Proc. ACM Program. Lang.,2019,3,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2019-10,,,https://doi.org/10.1145/3360571;http://dx.doi.org/10.1145/3360571,10.1145/3360571,"The Dependent Object Types (DOT) calculus aims to formalize the Scala programming language with a focus on path-dependent types — types such as x.a1… an.T that depend on the runtime value of a path x.a1… an to an object. Unfortunately, existing formulations of DOT can model only types of the form x.A which depend on variables rather than general paths. This restriction makes it impossible to model nested module dependencies. Nesting small components inside larger ones is a necessary ingredient of a modular, scalable language. DOT’s variable restriction thus undermines its ability to fully formalize a variety of programming-language features including Scala’s module system, family polymorphism, and covariant specialization. This paper presents the pDOT calculus, which generalizes DOT to support types that depend on paths of arbitrary length, as well as singleton types to track path equality. We show that naive approaches to add paths to DOT make it inherently unsound, and present necessary conditions for such a calculus to be sound. We discuss the key changes necessary to adapt the techniques of the DOT soundness proofs so that they can be applied to pDOT. Our paper comes with a Coq-mechanized type-safety proof of pDOT. With support for paths of arbitrary length, pDOT can realize DOT’s full potential for formalizing Scala-like calculi.","Scala, paths, DOT, dependent types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang D,Rundensteiner E,Ellison R,Wang H",Probabilistic Inference of Object Identifications for Event Stream Analytics,,2013,,,513–524,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th International Conference on Extending Database Technology,"Genoa, Italy",2013,9781450315975,,https://doi.org/10.1145/2452376.2452436;http://dx.doi.org/10.1145/2452376.2452436,10.1145/2452376.2452436,"Recent years have witnessed the emergence of real-time object monitoring applications driven by the explosion of small inexpensive sensors. In many real-world applications, not all sensed events carry the identification of the object whose action they report on, so called \non-ID-ed\"" events. Reasons range from heterogeneous sensing devices to human's choosing to conceal their identifications. Such non-ID-ed events prevent us from performing object-based analytics",such as tracking,alerting and pattern matching. We propose a probabilistic inference framework,called FISS,to tackle this problem by inferring the missing object identification associated with an event. Specifically,as a foundation we design a time-varying graphic model to capture correspondences between sensed events and objects. Upon this formal model,we elaborate how to adapt the Forward-backward (FB) inference algorithm to continuously infer probabilistic identifications for non-ID-ed events. However,we demonstrate that FB is neither scalable nor efficient over event streams. To overcome this deficiency,we propose a suite of strategies for optimizing its performance,including the selective smoothing technique that significantly reduces the number of random variables that need to be smoothed,and the finish-flag mechanism that enables early termination of backward computations. Our experimental results,using large-volume streams of a real-world healthcare application,demonstrate the accuracy,efficiency,"and scalability of FISS. Especially FISS achieves on average 15x higher throughput than our basic FB inference.""",,EDBT '13,,,,,,,,,,,,,,,,
1,Conference Paper,"Murawski AS,Tzevelekos N",Game Semantics for Interface Middleweight Java,,2014,,,517–528,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 41st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"San Diego, California, USA",2014,9781450325448,,https://doi.org/10.1145/2535838.2535880;http://dx.doi.org/10.1145/2535838.2535880,10.1145/2535838.2535880,"We consider an object calculus in which open terms interact with the environment through interfaces. The calculus is intended to capture the essence of contextual interactions of Middleweight Java code. Using game semantics, we provide fully abstract models for the induced notions of contextual approximation and equivalence. These are the first denotational models of this kind.","game semantics, contextual equivalence, java, full abstraction",POPL '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Murawski AS,Tzevelekos N",Game Semantics for Interface Middleweight Java,SIGPLAN Not.,2014,49,1,517–528,Association for Computing Machinery,"New York, NY, USA",,,,2014-01,,0362-1340,https://doi.org/10.1145/2578855.2535880;http://dx.doi.org/10.1145/2578855.2535880,10.1145/2578855.2535880,"We consider an object calculus in which open terms interact with the environment through interfaces. The calculus is intended to capture the essence of contextual interactions of Middleweight Java code. Using game semantics, we provide fully abstract models for the induced notions of contextual approximation and equivalence. These are the first denotational models of this kind.","java, full abstraction, contextual equivalence, game semantics",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sunshine J,Naden K,Stork S,Aldrich J,Tanter É",First-Class State Change in Plaid,,2011,,,713–732,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Portland, Oregon, USA",2011,9781450309400,,https://doi.org/10.1145/2048066.2048122;http://dx.doi.org/10.1145/2048066.2048122,10.1145/2048066.2048122,"Objects model the world, and state is fundamental to a faithful modeling. Engineers use state machines to understand and reason about state transitions, but programming languages provide little support for building software based on state abstractions. We propose Plaid, a language in which objects are modeled not just in terms of classes, but in terms of changing abstract states. Each state may have its own representation, as well as methods that may transition the object into a new state. A formal model precisely defines the semantics of core Plaid constructs such as state transition and trait-like state composition. We evaluate Plaid through a series of examples taken from the Plaid compiler and the standard libraries of Smalltalk and Java. These examples show how Plaid can more closely model state-based designs, enhancing understandability, enhancing dynamic error checking, and providing reuse benefits.","state-chart, plaid, typestate",OOPSLA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Sunshine J,Naden K,Stork S,Aldrich J,Tanter É",First-Class State Change in Plaid,SIGPLAN Not.,2011,46,10,713–732,Association for Computing Machinery,"New York, NY, USA",,,,2011-10,,0362-1340,https://doi.org/10.1145/2076021.2048122;http://dx.doi.org/10.1145/2076021.2048122,10.1145/2076021.2048122,"Objects model the world, and state is fundamental to a faithful modeling. Engineers use state machines to understand and reason about state transitions, but programming languages provide little support for building software based on state abstractions. We propose Plaid, a language in which objects are modeled not just in terms of classes, but in terms of changing abstract states. Each state may have its own representation, as well as methods that may transition the object into a new state. A formal model precisely defines the semantics of core Plaid constructs such as state transition and trait-like state composition. We evaluate Plaid through a series of examples taken from the Plaid compiler and the standard libraries of Smalltalk and Java. These examples show how Plaid can more closely model state-based designs, enhancing understandability, enhancing dynamic error checking, and providing reuse benefits.","plaid, state-chart, typestate",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rahman AS,Hossain MA,Saddik AE",Spatial-Geometric Approach to Physical Mobile Interaction Based on Accelerometer and IR Sensory Data Fusion,ACM Trans. Multimedia Comput. Commun. Appl.,2010,6,4,,Association for Computing Machinery,"New York, NY, USA",,,,2010-11,,1551-6857,https://doi.org/10.1145/1865106.1865112;http://dx.doi.org/10.1145/1865106.1865112,10.1145/1865106.1865112,"Interaction with the physical environment using mobile phones has become increasingly desirable and feasible. Nowadays mobile phones are being used to control different devices and access information/services related to those devices. To facilitate such interaction, devices are usually marked with RFID tags or visual markers, which are read by a mobile phone equipped with an integrated RFID reader or camera to fetch related information about those objects and initiate further actions. This article contributes in this domain of mobile physical interaction; however, using a spatial-geometric approach for interacting with indoor physical objects and artifacts instead of RFID based solutions. Using this approach, a mobile phone can point from a distance to an annotated object or a spatial subregion of that object for the purpose of interaction. The pointing direction and location is determined based on the fusion of IR camera and accelerometer data, where the IR cameras are used to calculate the 3D position of the mobile phone users and the accelerometer in the phone provides its tilting and orientation information. The annotation of objects and their subregions with which the mobile phone interacts is performed by specifying their geometric coordinates and associating related information or services with them. We perform experiment in a technology-augmented smart space and show the applicability and potential of the proposed approach.","indoor position, multi-sensor fusion, Physical mobile interaction, multimedia objects tagging, physical browsing, orientation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bani Hashem BH,Ozeki T",Pedestrian Detection by Using FAST-HOG Features,,2015,,,277–278,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Human-Agent Interaction,"Daegu, Kyungpook, Republic of Korea",2015,9781450335270,,https://doi.org/10.1145/2814940.2814996;http://dx.doi.org/10.1145/2814940.2814996,10.1145/2814940.2814996,"Pedestrian detection is used in video surveillance systems and driver assistance systems. The purpose is to build automated vision systems for detecting pedestrians as shown in figure 1. We use Histograms of Oriented Gradients (HOG), which are one of the well-known features for object recognition. HOG features are calculated by taking orientation histograms of edge intensity in a local region [1]. In this paper we select the interesting point in the image by using FAST features detector and extracted HOG features around these strongest corners and use them as an input vector of linear Support Vector Machine (SVM) to classify the given input into pedestrian/non-pedestrian. By using FAST detector we reduce the number of features less than half without lowering the performance.","non-pedestrian, fast feature, object recognition, HOG, linear SVM, pedestrian detection, HOG feature",HAI '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liang S,Might M",Hash-Flow Taint Analysis of Higher-Order Programs,,2012,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th Workshop on Programming Languages and Analysis for Security,"Beijing, China",2012,9781450314411,,https://doi.org/10.1145/2336717.2336725;http://dx.doi.org/10.1145/2336717.2336725,10.1145/2336717.2336725,"As web applications have grown in popularity, so have attacks on such applications. Cross-site scripting and injection attacks have become particularly problematic. Both vulnerabilities stem, at their core, from improper sanitization of user input.We propose static taint analysis, which can verify the absence of unsanitized input errors at compile-time. Unfortunately, precise static analysis of modern scripting languages like Python is challenging: higher-orderness and complex control-flow collide with opaque, dynamic data structures like hash maps and objects. The interdependence of data-flow and control-flow make it hard to attain both soundness and precision.In this work, we apply abstract interpretation to sound and precise taint-style static analysis of scripting languages. We first define λH, a core calculus of modern scripting languages, with hash maps, dynamic objects, higher-order functions and first class control. Then we derive a framework of k-CFA-like CESK-style abstract machines for statically reasoning about λH, but with hash maps factored into a \Curried Object store.\"" The Curried object store---and shape analysis on this store---allows us to recover field sensitivity",even in the presence of dynamically modified fields. Lastly,atop this framework,we devise a taint-flow analysis,leveraging its field-sensitive,interprocedural and context-sensitive properties to soundly and precisely detect security vulnerabilities,like XSS attacks in web applications.We have prototyped the analytical framework for Python,"and conducted preliminary experiments with web applications. A low rate of false alarms demonstrates the promise of this approach.""","higher-order programs, abstract interpretation, taint analysis, static analysis",PLAS '12,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Wagner G,An Abstract State Machine Semantics for Discrete Event Simulation,,2017,,,,IEEE Press,"Las Vegas, Nevada",,Proceedings of the 2017 Winter Simulation Conference,,2017,9781538634271,,,,"We define an operational (transition system) semantics for the two most basic forms of Discrete Event Simulation (DES): event-based simulation (without objects) and object-event simulation. We show that under our operational semantics, DES models correspond to a certain form of abstract state machines (ASMs) such that the Future Event List (FEL) is part of the transition system state and the transition function is based on event routines. Unlike other formalisms proposed for DES (such as Petri Nets or DEVS), our ASM semantics takes all basic DES concepts (like event types and the FEL) into consideration and allows for expressive transition system states representing the objects, properties, relations and functions of the evolving possible worlds of a simulation run. As a direct formal semantics of DES, it provides a basis for comparing, and explaining design choices in, different DES approaches.",,WSC '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,de Dinechin BD,Co-Design and Abstraction of a Network-on-Chip Using Deterministic Network Calculus,,2018,,,,IEEE Press,"Torino, Italy",,Proceedings of the Twelfth IEEE/ACM International Symposium on Networks-on-Chip,,2018,9781538648933,,,,"Network-on-Chip (NoC) is the dominant paradigm for on-chip interconnects. Two approaches for architecting a NoC can be distinguished. One is the generalization of bus-based interconnects inside a SoC, where transactions are associated with memory addresses. The other is the on-chip integration of connection-oriented networks, which transport frames without addressing into the destination memory. Connection-oriented NoCs are well-suited to terminating macro-networks such as Ethernet, and to supporting quality of service (QoS) by using formal methods such as deterministic network calculus (DNC).We present the design objectives and architecture of the NoC of the 3rd-generation Kalray MPPA processor, which implements a clustered manycore architecture. The MPPA3 NoC is connected to high-speed Ethernet controllers that operate at level-2 for networking and at level-1 to extend the NoC protocol across processors. By contrast with the time-triggered approach for ensuring QoS, this NoC is designed to guarantee delays by the adequate configuration of DMA engines and traffic limiters at ingress. We discuss the abstraction of the MPPA3 NoC network elements for the purpose of bounding delays by application of a DNC formulation. Delay bounding and the associated usage domains are motivated by time-critical applications.","deterministic network calculus, network-on-chip, network guaranteed services, many-core processor",NOCS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang G,Yang S,Han Y",Mashroom: End-User Mashup Programming Using Nested Tables,,2009,,,861–870,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th International Conference on World Wide Web,"Madrid, Spain",2009,9781605584874,,https://doi.org/10.1145/1526709.1526825;http://dx.doi.org/10.1145/1526709.1526825,10.1145/1526709.1526825,"This paper presents an end-user-oriented programming environment called Mashroom. Major contributions herein include an end-user programming model with an expressive data structure as well as a set of formally-defined mashup operators. The data structure takes advantage of nested table, and maintains the intuitiveness while allowing users to express complex data objects. The mashup operators are visualized with contextual menu and formula bar and can be directly applied on the data. Experiments and case studies reveal that end users have little difficulty in effectively and efficiently using Mashroom to build mashup applications.","mashup, nested table, end-user programming, spreadsheet",WWW '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Borgstrom J,Gutkovas R,Rodhe I,Victor B",The Psi-Calculi Workbench: A Generic Tool for Applied Process Calculi,ACM Trans. Embed. Comput. Syst.,2015,14,1,,Association for Computing Machinery,"New York, NY, USA",,,,2015-01,,1539-9087,https://doi.org/10.1145/2682570;http://dx.doi.org/10.1145/2682570,10.1145/2682570,"Psi-calculi is a parametric framework for extensions of the pi-calculus with arbitrary data and logic. All instances of the framework inherit machine-checked proofs of the metatheory such as compositionality and bisimulation congruence. We present a generic analysis tool for psi-calculus instances, enabling symbolic execution and (bi)simulation checking for both unicast and broadcast communication. The tool also provides a library for implementing new psi-calculus instances. We provide examples from traditional communication protocols and wireless sensor networks. We also describe the theoretical foundations of the tool, including an improved symbolic operational semantics, with additional support for scoped broadcast communication.","symbolic semantics, Wireless sensor networks, process calculi",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Okahana Y,Gotoh Y",A Method to Reduce Processing Time by Parallelizing Generation of Voronoi Diagrams,,2018,,,53–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th International Conference on Advances in Mobile Computing and Multimedia,"Yogyakarta, Indonesia",2018,9781450364522,,https://doi.org/10.1145/3282353.3282358;http://dx.doi.org/10.1145/3282353.3282358,10.1145/3282353.3282358,"Due to the recent popularization of the Geographic Information System (GIS), spatial network environments that can display the changes of spatial axes on mobile phones are receiving great attention. In spatial network environments, since a query object that seeks location information selects several candidate target objects based on the search conditions, we often use a k-nearest neighbor (kNN) search, which seeks several target objects near the query object. However, since a kNN search needs to find the kNN by calculating the distance from the query to all the objects, the computational complexity might become too large, depending on the number of objects. To reduce this computation time in a kNN search, many researchers have proposed a search method that divides regions using a Voronoi diagram. In this method, we reduce the computational complexity by generating Voronoi regions for each object based on the positional relationships between two objects. In addition, a search method was proposed to reduce the processing time by generating Voronoi diagrams using a contact zone. However, since conventional methods generate Voronoi diagrams for objects in order, the computational complexity might become too large, depending on the number of objects. In this paper, we propose a generation method of the Voronoi diagram to the reduce processing time by parallelizing the generation of Voronoi regions using a contact zone. In our evaluation, we confirmed that the processing time under the proposed method was reduced about 15.9% more than conventional methods that are not parallelized.","Voronoi diagram, Processing time, Contact zone",MoMM2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li Y,Miao Z,Wang J",Deep Activation Feature Maps for Visual Object Tracking,,2018,,,99–106,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 International Conference on Signal Processing and Machine Learning,"Shanghai, China",2018,9781450366052,,https://doi.org/10.1145/3297067.3297088;http://dx.doi.org/10.1145/3297067.3297088,10.1145/3297067.3297088,"Video object tracking is an important task with a broad range of applications. In this paper, we propose a novel visual tracking algorithm based on deep activation feature maps in correlation filter framework. Deep activation feature maps are generated from convolution neural network feature maps, which can discover the important part of the tracking target and overcome shape deformation and heavy occlusion. In addition, the scale variation is calculated by another correlation filter with histogram of oriented gradient (HoG) features. Moreover, we integrate the final tracking result in each frame based on the appearance model and scale model to further boost the overall tracking performance. We validate the effectiveness of our approach on a challenging benchmark, where the proposed method illustrates outstanding performance compared with the state-ofthe-art tracking algorithms","activation feature maps, convolutional neural networks, correlation filter, visual tracking",SPML '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Monreale A,Pinelli F,Trasarti R,Giannotti F",WhereNext: A Location Predictor on Trajectory Pattern Mining,,2009,,,637–646,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Paris, France",2009,9781605584959,,https://doi.org/10.1145/1557019.1557091;http://dx.doi.org/10.1145/1557019.1557091,10.1145/1557019.1557091,"The pervasiveness of mobile devices and location based services is leading to an increasing volume of mobility data.This side eect provides the opportunity for innovative methods that analyse the behaviors of movements. In this paper we propose WhereNext, which is a method aimed at predicting with a certain level of accuracy the next location of a moving object. The prediction uses previously extracted movement patterns named Trajectory Patterns, which are a concise representation of behaviors of moving objects as sequences of regions frequently visited with a typical travel time. A decision tree, named T-pattern Tree, is built and evaluated with a formal training and test process. The tree is learned from the Trajectory Patterns that hold a certain area and it may be used as a predictor of the next location of a new trajectory finding the best matching path in the tree. Three dierent best matching methods to classify a new moving object are proposed and their impact on the quality of prediction is studied extensively. Using Trajectory Patterns as predictive rules has the following implications: (I) the learning depends on the movement of all available objects in a certain area instead of on the individual history of an object; (II) the prediction tree intrinsically contains the spatio-temporal properties that have emerged from the data and this allows us to define matching methods that striclty depend on the properties of such movements. In addition, we propose a set of other measures, that evaluate a priori the predictive power of a set of Trajectory Patterns. This measures were tuned on a real life case study. Finally, an exhaustive set of experiments and results on the real dataset are presented.","trajectory patterns, spatio-temporal data mining",KDD '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gómez LI,Kuijpers B,Vaisman AA",Aggregation Languages for Moving Object and Places of Interest,,2008,,,857–862,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Symposium on Applied Computing,"Fortaleza, Ceara, Brazil",2008,9781595937537,,https://doi.org/10.1145/1363686.1363885;http://dx.doi.org/10.1145/1363686.1363885,10.1145/1363686.1363885,"We address aggregate queries over GIS data and moving object data, where non-spatial information is stored in a data warehouse. We propose a formal data model and query language to express complex aggregate queries. Next, we study the compression of trajectory data, produced by moving objects, using the notions of stops and moves. We show that stops and moves are expressible in our query language and we consider a fragment of this language, consisting of regular expressions to talk about temporally ordered sequences of stops and moves. This fragment can be used not only for querying, but also for expressing data mining and pattern matching tasks over trajectory data.","OLAP, GIS, view materialization",SAC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ding X,Peng R,Yu J",Object Inflation for Artistic Augmentation in Images and Animations,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Symposium on Visual Information Communication and Interaction,"Shanghai, China",2019,9781450376266,,https://doi.org/10.1145/3356422.3356427;http://dx.doi.org/10.1145/3356422.3356427,10.1145/3356422.3356427,"We propose a method to inflate object figures for artistic augmentation in images and animations. The basic idea of our method is first to approximate normals of object surfaces by interpolating normals assigned to vertices of triangles obtained by triangulating the object region, and then deform textures inside the object region by offsetting texture coordinates with amount determined by empirical functions applied to normals. The final appearance of inflated objects is suggested by both shading calculated by use of approximated normals and deformed textures over the object region. The experimental results demonstrate that our triangle based normal interpolation approach is able to better approximate the object surface than the previous object boundary based normal interpolation did, thus, the inflation process can be speeded up significantly due to reduction in number of iterations required for obtaining a smooth inflated surface.","artistic augmentation, normal map, inflation, texture deformation",VINCI'2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bernstein PA,Jacob M,Pérez J,Rull G,Terwilliger JF",Incremental Mapping Compilation in an Object-to-Relational Mapping System,,2013,,,1269–1280,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,"New York, New York, USA",2013,9781450320375,,https://doi.org/10.1145/2463676.2465294;http://dx.doi.org/10.1145/2463676.2465294,10.1145/2463676.2465294,"In an object-to-relational mapping system (ORM), mapping expressions explain how to expose relational data as objects and how to store objects in tables. If mappings are sufficiently expressive, then it is possible to define lossy mappings. If a user updates an object, stores it in the database based on a lossy mapping, and then retrieves the object from the database, the user might get a different result than the updated state of the object; that is, the mapping might not \roundtrip.\"" To avoid this",the ORM should validate that user-defined mappings roundtrip the data. However,this problem is NP-hard,so mapping validation can be very slow for large or complex mappings.We circumvent this problem by developing an incremental compiler for OR mappings. Given a validated mapping,a modification to the object schema is compiled into incremental modifications of the mapping. We define the problem formally,present algorithms to solve it for Microsoft's Entity Framework,and report on an implementation. For some mappings,incremental compilation is over 100 times faster than a full mapping compilation,"in one case dropping from 8 hours to 50 seconds.""","object-to-relational mapping, incremental compilation",SIGMOD '13,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brandherm B,Prendinger H,Ishizuka M",Interest Estimation Based on Dynamic Bayesian Networks for Visual Attentive Presentation Agents,,2007,,,346–349,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Multimodal Interfaces,"Nagoya, Aichi, Japan",2007,9781595938176,,https://doi.org/10.1145/1322192.1322253;http://dx.doi.org/10.1145/1322192.1322253,10.1145/1322192.1322253,"In this paper, we describe an interface consisting of a virtual showroom where a team of two highly realistic 3D agents presents product items in an entertaining and attractive way. The presentation flow adapts to users' attentiveness, or lack thereof, and may thus provide a more personalized and user-attractive experience of the presentation. In order to infer users' attention and visual interest regarding interface objects, our system analyzes eye movements in real-time. Interest detection algorithms used in previous research determine an object of interest based on the time that eye gaze dwells on that object. However, this kind of algorithm is not well suited for dynamic presentations where the goal is to assess the user's focus of attention regarding a dynamically changing presentation. Here, the current context of the object of attention has to be considered, i.e., whether the visual object is part of (or contributes to) the current presentation content or not. Therefore, we propose a new approach that estimates the interest (or non-interest) of a user by means of dynamic Bayesian networks. Each of a predefined set of visual objects has a dynamic Bayesian network assigned to it, which calculates the current interest of the user in this object. The estimation takes into account (1) each new gaze point, (2) the current context of the object, and (3) preceding estimations of the object itself. Based on these estimations the presentation agents can provide timely and appropriate response.","multi-modal presentation, dynamic Bayesian network, eye tracking, interest recognition",ICMI '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nam MJ,Akritidis P,Greaves DJ",FRAMER: A Tagged-Pointer Capability System with Memory Safety Applications,,2019,,,612–626,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th Annual Computer Security Applications Conference,"San Juan, Puerto Rico, USA",2019,9781450376280,,https://doi.org/10.1145/3359789.3359799;http://dx.doi.org/10.1145/3359789.3359799,10.1145/3359789.3359799,"Security mechanisms for systems programming languages, such as fine-grained memory protection for C/C++, authorize operations at runtime using access rights associated with objects and pointers. The cost of such fine-grained capability-based security models is dominated by metadata updates and lookups, making efficient metadata management the key for minimizing performance impact. Existing approaches reduce metadata management overheads by sacrificing precision, breaking binary compatibility by changing object memory layout, or wasting space with excessive alignment or large shadow memory spaces.We propose FRAMER, a capability framework with object granularity. Its sound and deterministic per-object metadata management mechanism enables direct access to metadata by calculating their location from a tagged pointer to the object and a compact supplementary table. This may improve the performance of memory safety, type safety, thread safety and garbage collection, or any solution that needs to map pointers to metadata. FRAMER improves over previous solutions by simultaneously (1) providing a novel encoding that derives the location of per-object metadata with low memory overhead and without any assumption of objects' alignment or size, (2) offering flexibility in metadata placement and size, (3) saving space by removing any padding or re-alignment, and (4) avoiding internal object memory layout changes. We evaluate FRAMER with a use case on memory safety.","bounds checking, tagged pointers, object-capability model, memory safety, LLVM, security",ACSAC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lévêque T,Sentilles S",Refining Extra-Functional Property Values in Hierarchical Component Models,,2011,,,83–92,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th International ACM Sigsoft Symposium on Component Based Software Engineering,"Boulder, Colorado, USA",2011,9781450307239,,https://doi.org/10.1145/2000229.2000242;http://dx.doi.org/10.1145/2000229.2000242,10.1145/2000229.2000242,"It is nowadays widely accepted that extra-functional properties (EFPs) are as important as functional properties for system correctness, especially when considering systems such as safety-critical embedded systems. The criticality and resource-constrained nature of these systems necessitate to be able to predict tight and accurate extra-functional property values all along the development, from early estimations to measurements. By using a hierarchical component model that allows implementing components as an assembly of subcomponent instances, the same component can be instantiated in several assemblies, i.e. in different usage contexts. Many EFP values are sensitive to the usage context and knowing information about the enclosing assembly enables refining the values of the properties on the subcomponents. Such refinement is usually not supported and the consistency between refined values and the original ones not ensured. This paper presents the concepts and mechanisms to support EFP refinement in hierarchical component models with explicit property inheritance and refinement policies which formally define consistency constraints between refined value and the original one. These policies are interpreted and ensured for all actors and in all workspaces. The paper also describes the related experiments performed on the ProCom component model.","multiple values, virtual workspace, inheritance policy, component instance, component type, extra-functional properties",CBSE '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Luo P,Tian LP,Ruan J,Wu FX","Disease Gene Prediction by Integrating PPI Networks, Clinical RNA-Seq Data and OMIM Data",IEEE/ACM Trans. Comput. Biol. Bioinformatics,2019,16,1,222–232,IEEE Computer Society Press,"Washington, DC, USA",,,,2019-01,,1545-5963,https://doi.org/10.1109/TCBB.2017.2770120;http://dx.doi.org/10.1109/TCBB.2017.2770120,10.1109/TCBB.2017.2770120,"Disease gene prediction is a challenging task that has a variety of applications such as early diagnosis and drug development. The existing machine learning methods suffer from the imbalanced sample issue because the number of known disease genes positive samples is much less than that of unknown genes which are typically considered to be negative samples. In addition, most methods have not utilized clinical data from patients with a specific disease to predict disease genes. In this study, we propose a disease gene prediction algorithm called dgSeq by combining protein-protein interaction PPI network, clinical RNA-Seq data, and Online Mendelian Inheritance in Man OMIN data. Our dgSeq constructs differential networks based on rewiring information calculated from clinical RNA-Seq data. To select balanced sets of non-disease genes negative samples, a disease-gene network is also constructed from OMIM data. After features are extracted from the PPI networks and differential networks, the logistic regression classifiers are trained. Our dgSeq obtains AUC values of 0.88, 0.83, and 0.80 for identifying breast cancer genes, thyroid cancer genes, and Alzheimer's disease genes, respectively, which indicates its superiority to other three competing methods. Both gene set enrichment analysis and predicted results demonstrate that dgSeq can effectively predict new disease genes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Riadh TM,Le Grand B,Aufaure MA,Soto M",Conceptual and Statistical Footprints for Social Networks' Characterization,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd Workshop on Social Network Mining and Analysis,"Paris, France",2009,9781605586762,,https://doi.org/10.1145/1731011.1731019;http://dx.doi.org/10.1145/1731011.1731019,10.1145/1731011.1731019,"This article proposes a method relying on Formal Concept Analysis and Galois lattices for complex systems analysis. Statistics based on concept lattices enable the computation of the \Conceptual Distribution\"" of objects classified by the lattice. Experimentation on sample datasets extracted from three online social networks illustrates the use of these conceptual statistics for the global characterization and the automatic filtering of these systems. Moreover",compared to classical measures,these statistics offer new perspectives for object filtering and lattices simplification that would be useful for lattices visualization and interpretation. However,conceptual statistics calculation,"based on Galois lattices computation requires expensive calculations. This paper focuses on conceptual statistics contribution and optimized methods for their calculation for scalability purposes.""",,SNA-KDD '09,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Almorsy M,Grundy J,Ibrahim AS",Automated Software Architecture Security Risk Analysis Using Formalized Signatures,,2013,,,662–671,IEEE Press,"San Francisco, CA, USA",,Proceedings of the 2013 International Conference on Software Engineering,,2013,9781467330763,,,,"Reviewing software system architecture to pinpoint potential security flaws before proceeding with system development is a critical milestone in secure software development lifecycles. This includes identifying possible attacks or threat scenarios that target the system and may result in breaching of system security. Additionally we may also assess the strength of the system and its security architecture using well-known security metrics such as system attack surface, Compartmentalization, least-privilege, etc. However, existing efforts are limited to specific, predefined security properties or scenarios that are checked either manually or using limited toolsets. We introduce a new approach to support architecture security analysis using security scenarios and metrics. Our approach is based on formalizing attack scenarios and security metrics signature specification using the Object Constraint Language (OCL). Using formal signatures we analyse a target system to locate signature matches (for attack scenarios), or to take measurements (for security metrics). New scenarios and metrics can be incorporated and calculated provided that a formal signature can be specified. Our approach supports defining security metrics and scenarios at architecture, design, and code levels. We have developed a prototype software system architecture security analysis tool. To the best of our knowledge this is the first extensible architecture security risk analysis tool that supports both metric-based and scenario-based architecture security analysis. We have validated our approach by using it to capture and evaluate signatures from the NIST security principals and attack scenarios defined in the CAPEC database.",,ICSE '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Book Chapter,Sudkamp T,Nonmonotonic Logic,,2003,,,1241–1244,John Wiley and Sons Ltd.,GBR,Encyclopedia of Computer Science,,,2003,9780470864128,,,,"A major goal of artificial intelligence is the development of automated agents that are capable of making decisions, responding to the actions of others, and determining the consequences of their own actions. In order to achieve this behavior, these agents must have access to information describing the objects in the environment and the relationships of the objects to each other and to the agent itself. Much of the pioneering work in artificial intelligence used the predicate calculus as a language for representing and analyzing domain information. Unfortunately, the predicate calculus does not have the flexibility to perform many types of inference required for common sense reasoning. A fundamental property of the predicate calculus is that the acquisition of new information preserves previous conclusions. Any system in which the set of conclusions grows with the addition of information is said to be monotonic.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Janin D,Berthaut F,Desainte-Catherine M,Orlarey Y,Salvati S",The T-Calculus: Towards a Structured Programing of (Musical) Time and Space,,2013,,,23–34,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the First ACM SIGPLAN Workshop on Functional Art, Music, Modeling & Design","Boston, Massachusetts, USA",2013,9781450323864,,https://doi.org/10.1145/2505341.2505347;http://dx.doi.org/10.1145/2505341.2505347,10.1145/2505341.2505347,"In the field of music system programming, the T-calculus is a proposal for combining space modeling and time programming into a single programming feature: spatiotemporal tiled programming. Based on a solid algebraic model, it aims at decomposing every operation on musical objects into the sequence of a synchronization operation that describes how objects are positioned one with respect the other, and a fusion operation that describes how their values are then combined. A first simple version of such a tiled calculus is presented and studied in this paper.","algebra based approach, tiling semigroups, computational music",FARM '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rosenmüller M,Siegmund N,Kuhlemann M",Improving Reuse of Component Families by Generating Component Hierarchies,,2010,,,57–64,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Workshop on Feature-Oriented Software Development,"Eindhoven, The Netherlands",2010,9781450302081,,https://doi.org/10.1145/1868688.1868697;http://dx.doi.org/10.1145/1868688.1868697,10.1145/1868688.1868697,"Feature-oriented software development (FOSD) enables developers to generate families of similar components. However, current FOSD approaches degrade component reuse because they do not allow a developer to combine multiple components of the same family in a larger program. This is because individual family members cannot be distinguished from each other. We present an approach to model and generate component hierarchies that allow a programmer to combine multiple component variants. A component hierarchy structures the components of a family according to their functionality. Due to subtyping between the components of a hierarchy, client developers can write generic code that works with different component variants.",,FOSD '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sundarrajan A,Feng M,Kasbekar M,Sitaraman RK",Footprint Descriptors: Theory and Practice of Cache Provisioning in a Global CDN,,2017,,,55–67,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th International Conference on Emerging Networking EXperiments and Technologies,"Incheon, Republic of Korea",2017,9781450354226,,https://doi.org/10.1145/3143361.3143368;http://dx.doi.org/10.1145/3143361.3143368,10.1145/3143361.3143368,"Modern CDNs cache and deliver a highly-diverse set of traffic classes, including web pages, images, videos and software downloads. It is economically advantageous for a CDN to cache and deliver all traffic classes using a shared distributed cache server infrastructure. However, such sharing of cache resources across multiple traffic classes poses significant cache provisioning challenges that are the focus of this paper.Managing a vast shared caching infrastructure requires careful modeling of user request sequences for each traffic class. Using extensive traces from Akamai's CDN, we show how each traffic class has drastically different object access patterns, object size distributions, and cache resource requirements. We introduce the notion of a footprint descriptor that is a succinct representation of the cache requirements of a request sequence. Leveraging novel connections to Fourier analysis, we develop a footprint descriptor calculus that allows us to predict the cache requirements when different traffic classes are added, subtracted and scaled to within a prediction error of 2.5%. We integrated our footprint calculus in the cache provisioning operations of the production CDN and show how it is used to solve key challenges in cache sizing, traffic mixing, and cache partitioning.",,CoNEXT '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Whittaker M,Hellerstein JM","Checking Invariant Confluence, In Whole or In Parts",SIGMOD Rec.,2020,49,1,7–14,Association for Computing Machinery,"New York, NY, USA",,,,2020-09,,0163-5808,https://doi.org/10.1145/3422648.3422651;http://dx.doi.org/10.1145/3422648.3422651,10.1145/3422648.3422651,"Strongly consistent distributed systems are easy to reason about but face fundamental limitations in availability and performance. Weakly consistent systems can be implemented with very high performance but place a burden on the application developer to reason about complex interleavings of execution. Invariant confluence provides a formal framework for understanding when we can get the best of both worlds. An invariant confluent object can be efficiently replicated with no coordination needed to preserve its invariants. However, actually determining whether or not an object is invariant confluent is challenging.In this paper, we establish conditions under which a commonly used sufficient condition for invariant confluence is both necessary and sufficient, and we use this condition to design a general-purpose interactive invariant confluence decision procedure. We then take a step beyond invariant confluence and introduce a generalization of invariant confluence, called segmented invariant confluence, that allows us to replicate non-invariant confluent objects with a small amount of coordination. We implement these formalisms in a prototype called Lucy and find that our decision procedures efficiently handle common real-world workloads including foreign keys, escrow transactions, and more.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Girisha R,Murali S",Tracking Humans Using Novel Optical Flow Algorithm for Surveillance Videos,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Fourth Annual ACM Bangalore Conference,"Bangalore, India",2011,9781450307505,,https://doi.org/10.1145/1980422.1980429;http://dx.doi.org/10.1145/1980422.1980429,10.1145/1980422.1980429,"We propose an approach to track moving objects (humans) using optical flow in surveillance videos in this paper. We combine object segmentation output with optical flow algorithm while tracking object. That is, the proposed algorithm uses the object segmentation results while calculating optical flow and optical flow is only calculated in silhouette regions of motion using Two Way ANOVA. We track silhouettes (possible human torso), since these are more robust to variations in lighting conditions. The experimental results have demonstrated that our approach achieved good performance and the operating speed is relatively lower than some of the other standard optical flow techniques. We test our approach on several video surveillance sequences, both in indoor and outdoor.","object tracking, video surveillance, optical flow, two way ANOVA, object segmentation",COMPUTE '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Steenvoorden T,Naus N,Klinik M",TopHat: A Formal Foundation for Task-Oriented Programming,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st International Symposium on Principles and Practice of Declarative Programming,"Porto, Portugal",2019,9781450372497,,https://doi.org/10.1145/3354166.3354182;http://dx.doi.org/10.1145/3354166.3354182,10.1145/3354166.3354182,"Software that models how people work is omnipresent in today's society. Current languages and frameworks often focus on usability by non-programmers, sacrificing flexibility and high level abstraction. Task-oriented programming (TOP) is a programming paradigm that aims to provide the desired level of abstraction while still being expressive enough to describe real world collaboration. It prescribes a declarative programming style to specify multi-user workflows. Workflows can be higher-order. They communicate through typed values on a local and global level. Such specifications can be turned into interactive applications for different platforms, supporting collaboration during execution. TOP has been around for more than a decade, in the forms of iTasks and mTasks, which are tailored for real-world usability. So far, it has not been given a formalisation which is suitable for formal reasoning.In this paper we give a description of the TOP paradigm and then decompose its rich features into elementary language elements, which makes them suitable for formal treatment. We use the simply typed lambda-calculus, extended with pairs and references, as a base language. On top of this language, we develop TopHat, a language for modular interactive workflows. We describe TopHat by means of a layered semantics. These layers consist of multiple big-step evaluations on expressions, and two labelled transition systems, handling user inputs.With TopHat we prepare a way to formally reason about TOP languages and programs. This approach allows for comparison with other work in the field. We have implemented the semantic rules of TopHat in Haskell, and the task layer on top of the iTasks framework. This shows that our approach is feasible, and lets us demonstrate the concepts by means of illustrative case studies. TOP has been applied in projects with the Dutch coast guard, tax office, and navy. Our work matters because formal program verification is important for mission-critical software, especially for systems with concurrency.",,PPDP '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kosaka T,Hattori T,Kubo H,Morishima S",Rapid and Authentic Rendering of Translucent Materials Using Depth-Maps from Multi-Viewpoint,,2012,,,,Association for Computing Machinery,"New York, NY, USA",,SIGGRAPH Asia 2012 Posters,"Singapore, Singapore",2012,9781450319119,,https://doi.org/10.1145/2407156.2407206;http://dx.doi.org/10.1145/2407156.2407206,10.1145/2407156.2407206,"We present a real-time rendering method of translucent materials with complex shape by estimating object's thickness between light source and view point precisely. Wang et al. [2010] has already proposed a real-time rendering method treating arbitrary shapes, but it requires such huge computational costs and graphics memories that it is very difficult to implement in a practical rendering pipe-line. Inside a translucent object, the energy of incident light attenuates highly depends on the object's optical thickness. Translucent Shadow Maps (TSM) [2003] is able to compute object's thickness using depth map at light position. However, TSM is not able to calculate thickness accurately in concave objects.",,SA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang W,Xu J,Xu M,Zheng N,Ge E",Probabilistic Group Nearest Neighbors Query Based on Voronoi Diagram,,2015,,,36–41,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st International ACM SIGSPATIAL Workshop on Smart Cities and Urban Analytics,"Bellevue, WA, USA",2015,9781450339735,,https://doi.org/10.1145/2835022.2835029;http://dx.doi.org/10.1145/2835022.2835029,10.1145/2835022.2835029,"In order to solve the problem of probabilistic group nearest neighbor query on uncertain data, we present an effective method based on Voronoi diagram. Probabilistic group nearest neighbor query on uncertain data is to find out the set of uncertain objects, in which each object has a higher probability to be the nearest neighbor of query set than the threshold specified by user. In this paper, first a candidate set of target objects is got by constructing the Voronoi diagram of uncertain objects and the convex hull of the set of the query points. Then further reduce the candidate set through using the space pruning algorithm. At last, calculate the probability value of each target object in the candidate set to be GNN result exactly. The uncertain objects whose probabilities greater than or equal to the user-specified threshold are put into the result set. The theoretical analysis and experiments show the effectiveness of our algorithm, which also has good performance and less query time.","Probabilistic group nearest neighbor query, Uncertain objects, Voronoi diagram",UrbanGIS'15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,McKinley R,Proof Nets for Herbrand’s Theorem,ACM Trans. Comput. Logic,2013,14,1,,Association for Computing Machinery,"New York, NY, USA",,,,2013-02,,1529-3785,https://doi.org/10.1145/2422085.2422090;http://dx.doi.org/10.1145/2422085.2422090,10.1145/2422085.2422090,"This article explores Herbrand’s theorem as the source of a natural notion of abstract proof object for classical logic, embodying the “essence” of a sequent calculus proof. We see how to view a calculus of abstract Herbrand proofs (Herbrand nets) as an analytic proof system with syntactic cut-elimination. Herbrand nets can also be seen as a natural generalization of Miller’s expansion tree proofs to a setting including cut. We demonstrate sequentialization of Herbrand nets into a sequent calculus LKH; each net corresponds to an equivalence class of LKH proofs under natural proof transformations. A surprising property of our cut-reduction algorithm is that it is non-confluent despite not supporting the usual examples of non-confluent reduction in classical logic.","Herbrand’s theorem, proof nets, cut elimination, Classical logic",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gao K,Zhang Y,Zhang W,Lin S",Affine Stable Characteristic Based Sample Expansion for Object Detection,,2010,,,422–429,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Image and Video Retrieval,"Xi'an, China",2010,9781450301176,,https://doi.org/10.1145/1816041.1816103;http://dx.doi.org/10.1145/1816041.1816103,10.1145/1816041.1816103,"Generating better object model from automatic expanded samples is an effective approach to improve the performance of object detection. However, most existing methods either don't work well with limited relevance images in corpus, or result in redundant features and the decrease of detection speed. In this paper, we propose a novel method called Affine Stable Characteristic to generate an object feature model using only one object sample. By integrating affine simulation with stable characteristic mining, a compact and informative object model is generated with high robustness to viewpoint and scale transformations. For characteristic mining, two new notions, Global Stability and Local Stability, are introduced to calculate the robustness of each object feature from complementary hierarchies. And they are combined to generate the final object feature model. Experiments show that our novel method is capable of detecting objects in various geometric and photometric transformations, while only acquiring one sample image. In a compiled dataset composed of many famous test sets, the detection accuracy can be improved 35.8% compared with traditional methods at rapid on-line speed. The proposed approach can also be well generalized to other content analysis tasks.","sample expansion, affine stable characteristic, object detection",CIVR '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Butler Z,Bezakova I,Fluet K",Pencil Puzzles for Introductory Computer Science: An Experience- and Gender-Neutral Context,,2017,,,93–98,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2017 ACM SIGCSE Technical Symposium on Computer Science Education,"Seattle, Washington, USA",2017,9781450346986,,https://doi.org/10.1145/3017680.3017765;http://dx.doi.org/10.1145/3017680.3017765,10.1145/3017680.3017765,"The teaching of introductory computer science can benefit from the use of real-world context to ground the abstract programming concepts. We present the domain of pencil puzzles as a context for a variety of introductory CS topics. Pencil puzzles are puzzles typically found in newspapers and magazines, intended to be solved by the reader through the means of deduction, using only a pencil. A well-known example of a pencil puzzle is Sudoku, which has been widely used as a typical backtracking assignment. However, there are dozens of other well-tried and liked pencil puzzles available that naturally induce computational thinking and can be used as context for many CS topics such as arrays, loops, recursion, GUIs, inheritance and graph traversal. Our contributions in this paper are two-fold. First, we present a few pencil puzzles and map them to introductory CS concepts that the puzzles can target in an assignment, and point the reader to other puzzle repositories which provide the potential to lead to an almost limitless set of introductory CS assignments. Second, we have formally evaluated the effectiveness of such assignments used at our institution over the past three years. Students reported that they have learned the material, believe they can tackle similar problems, and have improved their coding skills. The assignments also led to a significantly higher proportion of unsolicited statements of enjoyment, as well as metacognition, when compared to a traditional assignment for the same topic. Lastly, for all but one assignment, the student's gender or prior programming experience was independent of their grade, their perceptions of and reflection on the assignment.","introductory cs concepts, computational thinking, pencil puzzles, learning in context",SIGCSE '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Miquey É,A Sequent Calculus with Dependent Types for Classical Arithmetic,,2018,,,720–729,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science,"Oxford, United Kingdom",2018,9781450355834,,https://doi.org/10.1145/3209108.3209199;http://dx.doi.org/10.1145/3209108.3209199,10.1145/3209108.3209199,"In a recent paper [11], Herbelin developed dPAω, a calculus in which constructive proofs for the axioms of countable and dependent choices could be derived via the encoding of a proof of countable universal quantification as a stream of it components. However, the property of normalization (and therefore the one of soundness) was only conjectured. The difficulty for the proof of normalization is due to the simultaneous presence of dependent types (for the constructive part of the choice), of control operators (for classical logic), of coinductive objects (to encode functions of type N→A into streams (a0, a1, ...)) and of lazy evaluation with sharing (for these coinductive objects).Elaborating on previous works, we introduce in this paper a variant of dPAω presented as a sequent calculus. On the one hand, we take advantage of a variant of Krivine classical realizability that we developed to prove the normalization of classical call-by-need [20]. On the other hand, we benefit from dLtp, a classical sequent calculus with dependent types in which type safety is ensured by using delimited continuations together with a syntactic restriction [19]. By combining the techniques developed in these papers, we manage to define a realizability interpretation à la Krivine of our calculus that allows us to prove normalization and soundness.","classical arithmetic, Curry-Howard, side effects, sequent calculus, dependent choice, dependent types, classical realizability",LICS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cooley C,Coleman S,Gardiner B,Scotney B",An Investigation of Gradient as a Feature Cue for Saliency Detection,,2019,,,13–17,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Artificial Intelligence and Pattern Recognition,"Beijing, China",2019,9781450372299,,https://doi.org/10.1145/3357254.3357281;http://dx.doi.org/10.1145/3357254.3357281,10.1145/3357254.3357281,"Salient object detection is a prominent research topic, based on a human's ability to selectively process conspicuous objects/regions within a scene. With many low-level features being adopted into saliency models, gradient is often overlooked. We investigate the effectiveness of gradient as a feature, applying and evaluating multiple image gradient operators. Scale is also addressed via the use of different sizes of convolutional masks and by varying the neighbour region to calculate gradient contrast. Finally, we present and evaluate a single scale saliency model with the respective gradient cue from each operator, for the detection of salient objects. Each model is evaluated on the publicly available MSRA10K salient object dataset.","gradient feature, saliency detection, gradient operators",AIPR '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang Z,Zhu W,Zhu Q",Mass-Spring Model for Liquid Object Collision Simulation,,2021,,,109–114,Association for Computing Machinery,"New York, NY, USA",,"2021 3rd International Conference on Image, Video and Signal Processing","Singapore, Singapore",2021,9781450388917,,https://doi.org/10.1145/3459212.3459229;http://dx.doi.org/10.1145/3459212.3459229,10.1145/3459212.3459229,"Liquid simulation is an important research direction of computer graphics, and the interaction of dynamic liquid surfaces is one of the challenges. However, traditional liquid simulation requires many calculations, especially when performing complex interactive calculations tasks such as liquid collision simulation. A large amount of calculation will lead to poor interaction of the simulation system, cause the liquid surface animation to freeze and become distorted. Mass-spring systems can be used for modeling deformable objects such as cloth, hair. But few of them are used to simulate the liquid, especially for liquid and object collision. In this research, we propose a method for simulating liquid in a container based on the mass-spring system. Especially to simulate the effects of liquid collision and objects floating or sinking on the water surface. We model the liquid surface as a connected triangular mesh based on the mass-spring system, which can improve calculation efficiency. Simulate the interaction between the liquid surface and the falling object based on physics principles and particle characteristics. Calculate the momentum transfer caused by the interaction between the force of the liquid particles and the surface to determine each particle's position in each time step. For the sinking state of an object caused by buoyancy after entering the liquid, the proton's height is used as the criterion for judging whether the object is sinking. Experiments have shown that our method has excellent efficiency and authenticity, can perform different types of liquids in the container and their interaction with objects. Our method has good application value.","Mass-spring System, Liquid Simulation, Collision simulation",IVSP 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Odersky M,Martres G,Petrashko D",Implementing Higher-Kinded Types in Dotty,,2016,,,51–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 7th ACM SIGPLAN Symposium on Scala,"Amsterdam, Netherlands",2016,9781450346481,,https://doi.org/10.1145/2998392.2998400;http://dx.doi.org/10.1145/2998392.2998400,10.1145/2998392.2998400,"dotty is a new, experimental Scala compiler based on DOT, the calculus of Dependent Object Types. Higher-kinded types are a natural extension of first-order lambda calculus, and have been a core construct of Haskell and Scala. As long as such types are just partial applications of generic classes, they can be given a meaning in DOT relatively straightforwardly. But general lambdas on the type level require extensions of the DOT calculus to be expressible. This paper is an experience report where we describe and discuss four implementation strategies that we have tried out in the last three years. Each strategy was fully implemented in the dotty compiler. We discuss the usability and expressive power of each scheme, and give some indications about the amount of implementation difficulties encountered.","higher-order genericity, dependent object types, type constructor polymorphism, dotty, DOT, higher-kinded types, Scala",SCALA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang P,Qian X",NURBS Based Molecular Force Calculation,,2009,,,361–366,Association for Computing Machinery,"New York, NY, USA",,2009 SIAM/ACM Joint Conference on Geometric and Physical Modeling,"San Francisco, California",2009,9781605587110,,https://doi.org/10.1145/1629255.1629304;http://dx.doi.org/10.1145/1629255.1629304,10.1145/1629255.1629304,"The progress of nanotechnology has made it possible to make miniature electromechanical devices of sub-micrometer scale. This means that we will be in need of design packages that can model the physical properties of objects and their interactions involved down in nanometer scale. Toward this goal, our aim in this paper is to develop a computing procedure for determining molecular interaction forces, i.e. van der Waals force, between objects of arbitrary geometry.Currently there are two types of approaches for calculating van der Waals force. The first type is analytical where analytical force equations are derived for interactions between simple geometries such as spheres and half-spaces. The second type is numerical where volume integrals or surface integrals are conducted over discretized object domains where the object boundaries are approximated by simple mesh geometries.This paper presents a numerical approach that uses non-uniform rational B-spline (NURBS) based surface integrals. The integrals are done on the parametric domains of the NURBS surfaces and Gaussian quadrature points lie exactly on the object surfaces. Salient features of this approach include: 1) Orders of magnitude in accuracy improvement is achieved over other numerical approaches; The fundamental reason for such accuracy improvement is that molecular interaction force is very sensitive to surface geometry since it falls off at the rate of inverse power of 6 7. Any geometric approximation in object discretization would lead to significant bias in the calculation result. 2) Molecular interactions between arbitrary-shaped objects can be represented and evaluated since the NURBS model can represent exactly common analytical geometries such as spheres in nano-particles and cylinders in nano-rods, and complex geometries such as corrugated sample surfaces.We demonstrate its general shape applicability by calculating van der Waals force between complex geometries such as micro-gears. Further, we give error bounds for NURBS based numerical simulation and develop an adaptive subdivision scheme to improve both calculation accuracy and efficiency.","molecular force calculation, surface formulation, NURBS surface, van der Waals forces/energies",SPM '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hasija H,Kumar D",Compression & Security in MongoDB without Affecting Efficiency,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Second International Conference on Information and Communication Technology for Competitive Strategies,"Udaipur, India",2016,9781450339629,,https://doi.org/10.1145/2905055.2905155;http://dx.doi.org/10.1145/2905055.2905155,10.1145/2905055.2905155,"Relational database are not able to deal with Big Data. Hence, to satisfy the demand of emerging Web 2.0 technologies, NOSQL databases are designed. MongoDB, is a schema free, document oriented database. But, it suffers from the problem of authorization, authentication and storing data without encryption. This drawback is overcome by entering data into a middleware before entering into the database. This transparent middleware performs encryption. But, it reduces the efficiency of MongoDB, to store and retrieve data. Instead of providing encryption, this paper came up with a compression technique, to reduce the actual amount of data to be stored. As compression is another form of encryption only. Thus this paper converts plain text into different format of compressed BSON type object. Encryption is achieved this way as data is no more entered in plain format into the database. All this is achieved, without increasing the query execution time of MongoDB. Methodology has been implemented for images also, and verified by calculating the time and number of bytes required to store data before and after compression.","Decompression, Encryption, Decryption, MongoDB, Compression, Inflater, Diflater",ICTCS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Peschanski F,Parallel Computing with the Pi-Calculus,,2011,,,45–54,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Sixth Workshop on Declarative Aspects of Multicore Programming,"Austin, Texas, USA",2011,9781450304863,,https://doi.org/10.1145/1926354.1926363;http://dx.doi.org/10.1145/1926354.1926363,10.1145/1926354.1926363,"To tackle the multi-core programming challenge, we investigate the design and implementation of concurrency-oriented programming languages. Our approach mimics the evolution from lambda-calculi to functional programming languages, but with the pi-calculus as a starting point. To fill the gap between the abstract calculus and its implementations, we introduce the pi-threads: an intermediate language and its abstract machine.The stackless architecture of the abstract machine makes the underlying algorithms both simple and naturally concurrent. The scheduling, for instance, can be operated in a completely decentralized way. Another remarkable feature of the abstract machine is its garbage collector. We adopt a reference counting scheme that can be characterized formally using only two semantic rules. Moreover, it provides original solutions to the usual shortcomings of reference counting: the overhead caused by the maintenance of the reference counts - we only track global references - and the complex issue of collecting cyclic structures - reinterpreted as the (in our case, much simpler) problem of detecting partial terminations.","parallelism, concurrency, pi-calculus",DAMP '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oyama S,Shirasuna K,Tanaka K",Identification of Time-Varying Objects on the Web,,2008,,,285–294,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM/IEEE-CS Joint Conference on Digital Libraries,"Pittsburgh PA, PA, USA",2008,9781595939982,,https://doi.org/10.1145/1378889.1378939;http://dx.doi.org/10.1145/1378889.1378939,10.1145/1378889.1378939,"We have developed a method for determining whether data found on the Web are for the same or different objects that takes into account the possibility of changes in their attribute values over time. Specifically, we estimate the probability that observed data were generated for the same object that has undergone changes in its attribute values over time and the probability that the data are for different objects, and we define similarities between observed data using these probabilities. By giving a specific form to the distributions of time-varying attributes, we can calculate the similarity between given data and identify objects by using agglomerative clustering on the basis of the similarity. Experiments in which we compared identification accuracies between our proposed method and a method that regards all attribute values as constant showed that the proposed method improves the precision and recall of object identification.","object-level search, temporal data, object identification",JCDL '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Teibrich A,Mueller S,Guimbretière F,Kovacs R,Neubert S,Baudisch P",Patching Physical Objects,,2015,,,83–91,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology,"Charlotte, NC, USA",2015,9781450337793,,https://doi.org/10.1145/2807442.2807467;http://dx.doi.org/10.1145/2807442.2807467,10.1145/2807442.2807467,"Personal fabrication is currently a one-way process: Once an object has been fabricated with a 3D printer, it cannot be changed anymore; any change requires printing a new version from scratch. The problem is that this approach ignores the nature of design iteration, i.e. that in subsequent iterations large parts of an object stay the same and only small parts change. This makes fabricating from scratch feel unnecessary and wasteful.In this paper, we propose a different approach: instead of re-printing the entire object from scratch, we suggest patching the existing object to reflect the next design iteration. We built a system on top of a 3D printer that accomplishes this: Users mount the existing object into the 3D printer, then load both the original and the modified 3D model into our software, which in turn calculates how to patch the object. After identifying which parts to remove and what to add, our system locates the existing object in the printer using the system's built-in 3D scanner. After calibrating the orientation, a mill first removes the outdated geometry, then a print head prints the new geometry in place.Since only a fraction of the entire object is refabricated, our approach reduces material consumption and plastic waste (for our example objects by 82% and 93% respectively).","sustainability, 3d printing, rapid prototyping",UIST '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sheng B,Sun H,Liu B,Wu E",GPU-Based Refraction and Caustics Rendering on Depth Textures,,2009,,,139–144,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on Virtual Reality Continuum and Its Applications in Industry,"Yokohama, Japan",2009,9781605589121,,https://doi.org/10.1145/1670252.1670282;http://dx.doi.org/10.1145/1670252.1670282,10.1145/1670252.1670282,"This paper presents a new technique for realtime rendering refraction and caustics effects. The algorithm can directly render complex objects represented by polygonal meshes without any precalculation, and allows the objects to be deformed dynamically through user interactions. Also, caustic patterns are rendered in the depth texture space. We accurately trace the photons' path and calculate the energy carried by the photons. As a result the caustic patterns are calculated without post-processing and temporal filtering over neighboring frames. Our technique can handle both the convex objects and concave objects, for the convex objects, the ray-convex-surface intersection is calculated by using a binary search algorithm; for the concave objects, the ray-concave-surface intersection is done by a linear search followed by a binary-search refinement step. The caustics can be also rendered for non-uniform deformation of both refractive object and receiver surface, allowing the interactive change of light and camera in terms of position and direction.","realtime rendering, caustics, refraction, depth textures, GPU",VRCAI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Maltseva AV,Makhnytkina OV,Shilkina NE,Soshnev AN,Evseev EA",A Multilevel Index Model of Labor Market Dysfunction,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Engineering and MIS,"Astana, Kazakhstan",2019,9781450372121,,https://doi.org/10.1145/3330431.3330448;http://dx.doi.org/10.1145/3330431.3330448,10.1145/3330431.3330448,"Index modeling is useful for evaluation of complex objects such as social institute of labor market. This institute associates different levels of the society: demographic, professional, financial and other. Formal approach to the labor market functioning assessment can be done through the calculating of system of indexes - index of possibilities, index of demanded competencies, index of intentions, and final cumulative index of labor market dysfunction. Using of the cumulative index we can outline the indicators of labor market stability and its dynamics in different regions of the country. Index calculation let us to classify three possible conditions of the labor market: normal functioning, functioning with compensation and crisis functioning. Finally, an original program application for the supporting of the indexes calculation was done.","social analysis, labor market disfunction, index model, decision making",ICEMIS '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sankoh H,Naito S,Nonaka K,Sabirin H,Chen J","Robust Billboard-Based, Free-Viewpoint Video Synthesis Algorithm to Overcome Occlusions under Challenging Outdoor Sport Scenes",,2018,,,1724–1732,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th ACM International Conference on Multimedia,"Seoul, Republic of Korea",2018,9781450356657,,https://doi.org/10.1145/3240508.3240514;http://dx.doi.org/10.1145/3240508.3240514,10.1145/3240508.3240514,"The paper proposes an algorithm to robustly reconstruct an accurate billboard model of an individual object including an occluded one in each camera. Each billboard model is utilized to synthesize high-quality, free-viewpoint video especially for outdoor sport scenes in which roughly calibrated cameras are sparsely placed. The two main contributions of the proposed algorithm are (1) robustness to occlusions caused by overlaps of multiple objects in every camera, that is one of the biggest issues for billboard-based method, and (2) applicability to challenging shooting conditions in which accurate 3D model cannot be reconstructed because of calibration errors, small number of cameras and so on. In order to achieve the contributions above, the algorithm does not try to reproduce an accurate 3D model of each object but utilize a \rough 3D model\"". The algorithm precisely extracts an individual object region in every camera by reconstructing a \""rough 3D model\"" of each object and back-projecting it to every camera. The 3D coordinate for each billboard to be located is calculated based on the position of a rough 3D model. Experimental results compare the visual quality of free-viewpoint videos synthesized with our proposed method and conventional methods and show the effectiveness of our proposed method in terms of the naturalness of positional relationships and the fineness of the surface textures of all the objects.""","occlusion, free-viewpoint video, sport, billboard",MM '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Qin X,Xiao S",Transparent-Supported Radiance Regression Function,,2014,,,197–200,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM SIGGRAPH International Conference on Virtual-Reality Continuum and Its Applications in Industry,"Shenzhen, China",2014,9781450332545,,https://doi.org/10.1145/2670473.2670498;http://dx.doi.org/10.1145/2670473.2670498,10.1145/2670473.2670498,"A modified RRF[Ren et al. 2013] rendering method called TsRRF is presented in this paper, which support global illumination in realtime for scenes with moving transparent objects. The key idea of this method is to augment the map between object and scene. There are two kinds of method to augment this map. First, we choose different attributes which can represent the true color of an object and the relationship with the whole scene in space, and at the same time in order to get these attributes, we use GPGPU to get real time information. Second we use deep learning to get the most important information from the sample data which can decrease the overfitting. In order to get more details and make full use of the sample data, we not only partition the scene by position, but also partition by object, and we will use different TsRRF to render different light effect like reflection or refraction. The network forward propagate process will also be put into the GPU and use the parallel feature to calculate quickly. As a result, the modified method works well when dealing with the transparent objects and have a real time effect.","transparent, radiance regression function, global illumination",VRCAI '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Krishnaswami NR,Birkedal L,Aldrich J",Verifying Event-Driven Programs Using Ramified Frame Properties,,2010,,,63–76,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th ACM SIGPLAN Workshop on Types in Language Design and Implementation,"Madrid, Spain",2010,9781605588919,,https://doi.org/10.1145/1708016.1708025;http://dx.doi.org/10.1145/1708016.1708025,10.1145/1708016.1708025,"Interactive programs, such as GUIs or spreadsheets, often maintain dependency information over dynamically-created networks of objects. That is, each imperative object tracks not only the objects its own invariant depends on, but also all of the objects which depend upon it, in order to notify them when it changes.These bidirectional linkages pose a serious challenge to verification, because their correctness relies upon a global invariant over the object graph.We show how to modularly verify programs written using dynamically-generated bidirectional dependency information. The critical idea is to distinguish between the footprint of a command, and the state whose invariants depends upon the footprint. To do so, we define an application-specific semantics of updates, and introduce the concept of a ramification operator to explain how local changes can alter our knowledge of the rest of the heap. We illustrate the applicability of this style of proof with a case study from functional reactive programming, and formally justify reasoning about an extremely imperative implementation as if it were pure.","functional reactive programming, separation logic, dataflow, subject-observer, frame rule, ramification problem",TLDI '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Leng C,Terpstra WW,Kemme B,Stannat W,Buchmann AP",Maintaining Replicas in Unstructured P2P Systems,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM CoNEXT Conference,"Madrid, Spain",2008,9781605582108,,https://doi.org/10.1145/1544012.1544031;http://dx.doi.org/10.1145/1544012.1544031,10.1145/1544012.1544031,"Replication is widely used in unstructured peer-to-peer systems to improve search or achieve availability. We identify and solve a subclass of replication problems where each object is associated with a maintainer node, and its replicas should only be available as long as its maintainer is part of the network. Such requirement can be found in various applications, e.g., when objects are directory lists, service lists, or subscriptions of a publish/subscribe system.We provide maintainers with proven guarantees on the number of replicas, in spite of network churn and crash failures. We also tackle the related problems of changing the number of replicas, updating replicas, balancing storage load in a heterogeneous network, and eliminating replicas left by crashing maintainers. Our algorithm is based on probabilistic methods and is simple to implement. We show by simulation and formal proof that our algorithm is correct.",,CoNEXT '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kitayama D,Lee R,Sumiya K",A Method of Analyzing Credibility Based on LOD Control of Digital Maps,,2009,,,11–18,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd Workshop on Information Credibility on the Web,"Madrid, Spain",2009,9781605584881,,https://doi.org/10.1145/1526993.1526998;http://dx.doi.org/10.1145/1526993.1526998,10.1145/1526993.1526998,"Digital maps are widely used and appear on all types of platforms for integrating content. Users can change display region and scale by panning, zooming in, and zooming out on a digital map. Level of detail (LOD) control for a given region at a given scale is decided by the designer of the digital map. Therefore, rules for displaying objects have limited credibility. For example, it is possible that equivalent objects do not display consistency, or nonequivalent objects do display consistency, even if users believe equivalent objects are displayed consistently. We propose a method to calculate the display validness on LOD-controlled regions and scales for increasing the credibility of digital maps. In particular, our method determines the equivalence of objects based on the display pattern at each scale and the size of the region determined to be the object's territory. In addition, we calculated the display validness using the equivalence of objects. In this paper, we describe our prototype system.","territory, information credibility, spatio temporal db, lod control, digital map",WICOW '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Malik T,Wang X,Little P,Chaudhary A,Thakar A",A Dynamic Data Middleware Cache for Rapidly-Growing Scientific Repositories,,2010,,,64–84,Springer-Verlag,"Berlin, Heidelberg",,Proceedings of the ACM/IFIP/USENIX 11th International Conference on Middleware,"Bangalore, India",2010,9783642169540,,,,"Modern scientific repositories are growing rapidly in size. Scientists are increasingly interested in viewing the latest data as part of query results. Current scientific middleware cache systems, however, assume repositories are static. Thus, they cannot answer scientific queries with the latest data. The queries, instead, are routed to the repository until data at the cache is refreshed. In data-intensive scientific disciplines, such as astronomy, indiscriminate query routing or data refreshing often results in runaway network costs. This severely affects the performance and scalability of the repositories and makes poor use of the cache system. We present Delta a dynamic data middleware cache system for rapidly-growing scientific repositories. Delta's key component is a decision framework that adaptively decouples data objects---choosing to keep some data object at the cache, when they are heavily queried, and keeping some data objects at the repository, when they are heavily updated. Our algorithm profiles incoming workload to search for optimal data decoupling that reduces network costs. It leverages formal concepts from the network flow problem, and is robust to evolving scientific workloads. We evaluate the efficacy of Delta, through a prototype implementation, by running query traces collected from a real astronomy survey.","robust algorithms, middleware cache, network traffic, dynamic data, vertex cover",Middleware '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sun Q,Chen Y,Zhao J",Constraint-Based Locality Analysis for X10 Programs,,2013,,,137–146,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM SIGPLAN 2013 Workshop on Partial Evaluation and Program Manipulation,"Rome, Italy",2013,9781450318426,,https://doi.org/10.1145/2426890.2426915;http://dx.doi.org/10.1145/2426890.2426915,10.1145/2426890.2426915,"X10 is a HPC (High Performance Computing) programming language proposed by IBM for supporting a PGAS (Partitioned Global Address Space) programming model offering a shared address space. The address space can be further partitioned into several logical locations where objects and activities (or threads) will be dynamically created. An analysis of locations can help to check the safety of object accesses through exploring which objects and activities may reside in which locations, while in practice the objects and activities are usually designated at runtime and their locations may also vary under different environments. In this paper, we propose a constraint-based locality analysis method called Leopard for X10. Leopard calculates the points-to relations for analyzing the objects and activities in a program and uses a place constraint graph to analyze their locations.We have developed a tool to support Leopard, and conducted an experiment to evaluate its effectiveness and efficiency. The experimental results show that Leopard can calculate the locations of objects and activities precisely.","points-to analysis, locality analysis, concurrency",PEPM '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Shangguan L,Yang Z,Liu AX,Zhou Z,Liu Y",STPP: Spatial-Temporal Phase Profiling-Based Method for Relative RFID Tag Localization,IEEE/ACM Trans. Netw.,2017,25,1,596–609,IEEE Press,,,,,2017-02,,1063-6692,https://doi.org/10.1109/TNET.2016.2590996;http://dx.doi.org/10.1109/TNET.2016.2590996,10.1109/TNET.2016.2590996,"Many object localization applications need the relative locations of a set of objects as oppose to their absolute locations. Although many schemes for object localization using radio frequency identification RFID tags have been proposed, they mostly focus on absolute object localization and are not suitable for relative object localization because of large error margins and the special hardware that they require. In this paper, we propose an approach called spatial-temporal phase profiling STPP to RFID-based relative object localization. The basic idea of STPP is that by moving a reader over a set of tags during which the reader continuously interrogating the tags, for each tag, the reader obtains a sequence of RF phase values, which we call a phase profile, from the tag’s responses over time. By analyzing the spatial-temporal dynamics in the phase profiles, STPP can calculate the spatial ordering among the tags. In comparison with prior absolute object localization schemes, STPP requires neither dedicated infrastructure nor special hardware. We implemented STPP and evaluated its performance in two real-world applications: locating misplaced books in a library and determining the baggage order in an airport. The experimental results show that STPP achieves about 84% ordering accuracy for misplaced books and 95% ordering accuracy for baggage handling. We further leverage the controllable reader antenna and upgrade STPP to infer the spacing between each pair of tags. The result shows that STPP could achieve promising performance on distance ranging.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zibin Y,Potanin A,Li P,Ali M,Ernst MD",Ownership and Immutability in Generic Java,,2010,,,598–617,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Reno/Tahoe, Nevada, USA",2010,9781450302036,,https://doi.org/10.1145/1869459.1869509;http://dx.doi.org/10.1145/1869459.1869509,10.1145/1869459.1869509,"The Java language lacks the important notions of ownership (an object owns its representation to prevent unwanted aliasing) and immutability (the division into mutable, immutable, and readonly data and references). Programmers are prone to design errors, such as representation exposure or violation of immutability contracts. This paper presents Ownership Immutability Generic Java (OIGJ), a backward-compatible purely-static language extension supporting ownership and immutability. We formally defined a core calculus for OIGJ, based on Featherweight Java, and proved it sound. We also implemented OIGJ and performed case studies on 33,000 lines of code.Creation of immutable cyclic structures requires a \cooking phase\"" in which the structure is mutated but the outside world cannot observe this mutation. OIGJ uses ownership information to facilitate creation of immutable cyclic structures",by safely prolonging the cooking phase even after the constructor finishes.OIGJ is easy for a programmer to use,and it is easy to implement (flow-insensitive,adding only 14 rules to those of Java). Yet,OIGJ is more expressive than previous ownership languages,in the sense that it can type-check more good code. OIGJ can express the factory and visitor patterns,and OIGJ can type-check Sun's java.util collections (except for the clone method) without refactoring and with only a small number of annotations. Previous work required major refactoring of existing code in order to fit its ownership restrictions. Forcing refactoring of well-designed code is undesirable because it costs programmer effort,degrades the design,"and hinders adoption in the mainstream community.""","java, immutability, ownership",OOPSLA '10,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zibin Y,Potanin A,Li P,Ali M,Ernst MD",Ownership and Immutability in Generic Java,SIGPLAN Not.,2010,45,10,598–617,Association for Computing Machinery,"New York, NY, USA",,,,2010-10,,0362-1340,https://doi.org/10.1145/1932682.1869509;http://dx.doi.org/10.1145/1932682.1869509,10.1145/1932682.1869509,"The Java language lacks the important notions of ownership (an object owns its representation to prevent unwanted aliasing) and immutability (the division into mutable, immutable, and readonly data and references). Programmers are prone to design errors, such as representation exposure or violation of immutability contracts. This paper presents Ownership Immutability Generic Java (OIGJ), a backward-compatible purely-static language extension supporting ownership and immutability. We formally defined a core calculus for OIGJ, based on Featherweight Java, and proved it sound. We also implemented OIGJ and performed case studies on 33,000 lines of code.Creation of immutable cyclic structures requires a \cooking phase\"" in which the structure is mutated but the outside world cannot observe this mutation. OIGJ uses ownership information to facilitate creation of immutable cyclic structures",by safely prolonging the cooking phase even after the constructor finishes.OIGJ is easy for a programmer to use,and it is easy to implement (flow-insensitive,adding only 14 rules to those of Java). Yet,OIGJ is more expressive than previous ownership languages,in the sense that it can type-check more good code. OIGJ can express the factory and visitor patterns,and OIGJ can type-check Sun's java.util collections (except for the clone method) without refactoring and with only a small number of annotations. Previous work required major refactoring of existing code in order to fit its ownership restrictions. Forcing refactoring of well-designed code is undesirable because it costs programmer effort,degrades the design,"and hinders adoption in the mainstream community.""","ownership, java, immutability",,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pradhan A,Joshi RK",Architecture of a Light-Weight Non-Threaded Event Oriented Workflow Engine,,2014,,,342–345,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM International Conference on Distributed Event-Based Systems,"Mumbai, India",2014,9781450327374,,https://doi.org/10.1145/2611286.2611316;http://dx.doi.org/10.1145/2611286.2611316,10.1145/2611286.2611316,"The architecture of a thin distributed event-oriented non-threaded but concurrent workflow engine is presented. The approach shows how to architecture a non-threaded workflow engine by eliminating threading through event-oriented paradigm without degrading performance. The architecture is presented formally in terms of just a handful of expressions in CCS, the Calculus of Communicating Systems. The CCS based light-weight model of the distributed engine is built keeping in mind the separation of the outer layer of events with implementation, extensibility, and also the issue of traceability into implementation. The engine with all its components has been implemented over TAO realization of CORBA utilizing its event service component. Performance results of the implementation are also provided including a comparison to a popular open-source workflow system.","CCS, workflow engine, event-oriented architecture, workflow engine architecture, petri net",DEBS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rama GM,Komondoor R,Sharma H",Refinement in Object-Sensitivity Points-to Analysis via Slicing,Proc. ACM Program. Lang.,2018,2,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2018-10,,,https://doi.org/10.1145/3276512;http://dx.doi.org/10.1145/3276512,10.1145/3276512,"Object sensitivity analysis is a well-known form of context-sensitive points-to analysis. This analysis is parameterized by a bound on the names of symbolic objects associated with each allocation site. In this paper, we propose a novel approach based on object sensitivity analysis that takes as input a set of client queries, and tries to answer them using an initial round of inexpensive object sensitivity analysis that uses a low object-name length bound at all allocation sites. For the queries that are answered unsatisfactorily, the approach then pin points \bad\"" points-to facts",which are the ones that are responsible for the imprecision. It then employs a form of program slicing to identify allocation sites that are potentially causing these bad points-to facts to be generated. The approach then runs object sensitivity analysis once again,this time using longer names for just these allocation sites,with the objective of resolving the imprecision in this round. We describe our approach formally,prove its completeness,and describe a Datalog-based implementation of it on top of the Petablox framework. Our evaluation of our approach on a set of large Java benchmarks,using two separate clients,reveals that our approach is more precise than the baseline object sensitivity approach,"by around 29% for one of the clients and by around 19% for the other client. Our approach is also more precise on most large benchmarks than a recently proposed approach that uses SAT solvers to identify allocation sites to refine.""","client-driven refinement, Precise and scalable points-to analysis, Java",,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Aghazadeh Z,Woelfel P",On the Time and Space Complexity of ABA Prevention and Detection,,2015,,,193–202,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 ACM Symposium on Principles of Distributed Computing,"Donostia-San Sebastián, Spain",2015,9781450336178,,https://doi.org/10.1145/2767386.2767403;http://dx.doi.org/10.1145/2767386.2767403,10.1145/2767386.2767403,"We investigate the time and space complexity of detecting and preventing ABAs in shared memory algorithms for systems with n processes and bounded base objects. To that end, we define ABA-detecting registers, which are similar to normal read/write registers, except that they allow a process q to detect with a read operation, whether some process wrote the register since q's last read. ABA-detecting registers can be implemented trivially from a single unbounded register, but we show that they have a high complexity if base objects are bounded: An obstruction-free implementation of an ABA-detecting single bit register cannot be implemented from fewer than n-1 bounded registers. Moreover, bounded CAS objects (or more generally, conditional read-modify-write primitives) offer little help to implement ABA-detecting single bit registers: We prove a linear time-space tradeoff for such implementations. We show that the same time-space tradeoff holds for implementations of single bit LL/SC primitives from bounded writable CAS objects. This proves that the implementations of LL/SC/VL by Anderson and Moir (1995) as well as Jayanti and Petrovic (2003) are optimal. We complement our lower bounds with tight upper bounds: We give an implementation of ABA-detecting registers from n+1 bounded registers, which has step complexity O(1). We also show that (bounded) LL/SC/VL can be implemented from a single bounded CAS object and with O(n) step complexity. Both upper bounds are asymptotically optimal with respect to their time-space product.These results give formal evidence that the ABA problem is inherently difficult, that even writable CAS objects do not provide significant benefits over registers for dealing with the ABA problem itself, and that there is no hope of finding a more efficient implementation of LL/SC/VL from bounded CAS objects and registers than the ones from Jayanti and Petrovice respectively Anderson and Moir.","load-link/store-conditional, shared memory, aba problem",PODC '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Whittaker M,Hellerstein JM",Interactive Checks for Coordination Avoidance,Proc. VLDB Endow.,2018,12,1,14–27,VLDB Endowment,,,,,2018-09,,2150-8097,https://doi.org/10.14778/3275536.3275538;http://dx.doi.org/10.14778/3275536.3275538,10.14778/3275536.3275538,"Strongly consistent distributed systems are easy to reason about but face fundamental limitations in availability and performance. Weakly consistent systems can be implemented with very high performance but place a burden on the application developer to reason about complex interleavings of execution. Invariant confluence provides a formal framework for understanding when we can get the best of both worlds. An invariant confluent object can be efficiently replicated with no coordination needed to preserve its invariants. However, actually determining whether or not an object is invariant confluent is challenging.In this paper, we establish conditions under which a commonly used sufficient condition for invariant confluence is both necessary and sufficient, and we use this condition to design (a) a general-purpose interactive invariant confluence decision procedure and (b) a novel sufficient condition that can be checked automatically. We then take a step beyond invariant confluence and introduce a generalization of invariant confluence, called segmented invariant confluence, that allows us to replicate non-invariant confluent objects with a small amount of coordination.We implemented these formalisms in a prototype called Lucy and found that our decision procedures efficiently handle common real-world workloads including foreign keys, rollups, escrow transactions, and more. We also found that segmented invariant confluent replication can deliver up to an order of magnitude more throughput than linearizable replication for low contention workloads and comparable throughput for medium to high contention workloads.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Yildiz ZC,Bulbul A,Capin T",A Framework for Applying the Principles of Depth Perception to Information Visualization,ACM Trans. Appl. Percept.,2013,10,4,,Association for Computing Machinery,"New York, NY, USA",,,,2013-10,,1544-3558,https://doi.org/10.1145/2536764.2536766;http://dx.doi.org/10.1145/2536764.2536766,10.1145/2536764.2536766,"During the visualization of 3D content, using the depth cues selectively to support the design goals and enabling a user to perceive the spatial relationships between the objects are important concerns. In this novel solution, we automate this process by proposing a framework that determines important depth cues for the input scene and the rendering methods to provide these cues. While determining the importance of the cues, we consider the user's tasks and the scene's spatial layout. The importance of each depth cue is calculated using a fuzzy logic--based decision system. Then, suitable rendering methods that provide the important cues are selected by performing a cost-profit analysis on the rendering costs of the methods and their contribution to depth perception. Possible cue conflicts are considered and handled in the system. We also provide formal experimental studies designed for several visualization tasks. A statistical analysis of the experiments verifies the success of our framework.","fuzzy logic, Depth perception, cue combination, depth cues, information visualization",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hu X,Yuan D,Sun M,Zhang H",A Slice-Based Method for Food Volume Estimation,,2019,,,1–6,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 2nd International Conference on Algorithms, Computing and Artificial Intelligence","Sanya, China",2019,9781450372619,,https://doi.org/10.1145/3377713.3377714;http://dx.doi.org/10.1145/3377713.3377714,10.1145/3377713.3377714,"Researches on self-dietary assessment have aroused interest in scientists in the field of food and health. User self-reports have long been a traditional way for individual dietary assessment. However, the consumed weight or volume from individuals is highly dependent on their subjective judgment and may lead to biased dietary analysis results. Therefore, direct estimation of food volume tends to be a more appropriate way for self-dietary assessment. 3D measurement is an effective method for object volume estimation. At present, there are some good strategies based on 3D measurement for estimation of the object volume, such as virtual reality based method and convex hull-based method. However, due to complexity and diversity of the surface of food items, traditional methods for object volume estimation often fail to achieve good results in food volume estimation. Therefore, a slice-based method is proposed in this paper, which is a calculus-based strategy that obtains an estimation of food volume via segmentation and integration of point cloud. Slice-based method is aimed to solve the difficulties caused by diverse food shapes and complex food surfaces in volume estimation and can provide a more accurate volume estimation for subsequent nutrient intake analysis.","Food volume estimation, Slice-based method, Self-dietary",ACAI 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chua FC,Lim EP",Trust Network Inference for Online Rating Data Using Generative Models,,2010,,,889–898,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Washington, DC, USA",2010,9781450300551,,https://doi.org/10.1145/1835804.1835917;http://dx.doi.org/10.1145/1835804.1835917,10.1145/1835804.1835917,"In an online rating system, raters assign ratings to objects contributed by other users. In addition, raters can develop trust and distrust on object contributors depending on a few rating and trust related factors. Previous study has shown that ratings and trust links can influence each other but there has been a lack of a formal model to relate these factors together. In this paper, we therefore propose Trust Antecedent Factor (TAF) Model, a novel probabilistic model that generate ratings based on a number of rater's and contributor's factors. We demonstrate that parameters of the model can be learnt by Collapsed Gibbs Sampling. We then apply the model to predict trust and distrust between raters and review contributors using a real data-set. Our experiments have shown that the proposed model is capable of predicting both trust and distrust in a unified way. The model can also determine user factors which otherwise cannot be observed from the rating and trust data.","probability, social network, statistics, trust prediction",KDD '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Horacek H,Generating References to Parts of Recursively Structured Objects,,2006,,,47–54,Association for Computational Linguistics,USA,,Proceedings of the Fourth International Natural Language Generation Conference,"Sydney, Australia",2006,9781932432725,,,,"Algorithms that generate expressions to identify a referent are mostly tailored towards objects which are in some sense conceived as holistic entities, describing them in terms of their properties and relations to other objects. This approach may prove not fully adequate when referring to components of structured objects, specifically for abstract objects in formal domains, where scope and relative positions are essential features. In this paper, we adapt the standard Dale and Reiter algorithm to specifics of such references as observed in a corpus about mathematical proofs. Extensions incorporated include an incremental specialization of property values for metonymic references, local and global positions reflecting group formations and implicature-based scope preferences to justify unique identification of the intended referent. The approach is primarily relevant for domains where abstract formal objects are prominent, but some of its features are also useful to extend the expressive repertoire of reference generation algorithms in other domains.",,INLG '06,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Samet H,Sankaranarayanan J,Auerbach M",Indexing Methods for Moving Object Databases: Games and Other Applications,,2013,,,169–180,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM SIGMOD International Conference on Management of Data,"New York, New York, USA",2013,9781450320375,,https://doi.org/10.1145/2463676.2465332;http://dx.doi.org/10.1145/2463676.2465332,10.1145/2463676.2465332,"Moving object databases arise in numerous applications such as traffic monitoring, crowd tracking, and games. They all require keeping track of objects that move and thus the database of objects must be constantly updated. The cover fieldtree (more commonly known as the loose quadtree and the loose octree, depending on the dimension of the underlying space) is designed to overcome the drawback of spatial data structures that associate objects with their minimum enclosing quadtree (octree) cells which is that the size of these cells depends more on the position of the objects and less on their size. In fact, the size of these cells may be as large as the entire space from which the objects are drawn. The loose quadtree (octree) overcomes this drawback by expanding the size of the space that is spanned by each quadtree (octree) cell c of width w by a cell expansion factor p (p>0) so that the expanded cell is of width (1+p)*w and an object is associated with its minimum enclosing expanded quadtree (octree) cell. It is shown that for an object o with minimum bounding hypercube box b of radius r (i.e., half the length of a side of the hypercube), the maximum possible width w of the minimum enclosing expanded quadtree cell c is just a function of r and p, and is independent of the position of o. Normalizing w via division by 2r enables calculating the range of possible expanded quadtree cell sizes as a function of p. For p >= 0.5 the range consists of just two values and usually just one value for p >= 1.This makes updating very simple and fast as for p >= 0.5, there are at most two possible new cells associated with the moved object and thus the update can be done in O(1) time. Experiments with random data showed that the update time to support motion in such an environment is minimized when p is infinitesimally less than 1, with as much as a one order of magnitude increase in the number of updates that can be handled vis-a-vis the p=0 case in a given unit of time. Similar results for updates were obtained for an N-body simulation where improved query performance and scalability were also observed. Finally, in order amplify the paper, a video tiled \Crates and Barrels\"" was produced which is an N-body simulation of 14","000 objects. The video is available from the following URL: http://www.youtube.com/watch?v=Sokq3FRGc0s. An applet to illustrate the behavior of the loose quadtree was developed and is available from http://donar.umiacs.umd. edu/quadtree/rectangles/loosequad.html.""","moving objects, loose quadtree, game databases, loose octree, game programming, cover fieldtree, spatial indexing, spatial databases, spatial data structures",SIGMOD '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Idrissa A,Aubert A,Fournel T,Fischer V",Secure Protocols for Serverless Remote Product Authentication,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th Workshop on Embedded Systems Security,"Scottsdale, Arizona",2010,9781450300780,,https://doi.org/10.1145/1873548.1873559;http://dx.doi.org/10.1145/1873548.1873559,10.1145/1873548.1873559,"Industrial companies lose large sums of money because of counterfeits and they need to efficiently protect their trademarks. Most of them implement their own anti-counterfeiting policy to deal with the menace. A number of technologies, such as holograms, smart cards, biometric markers and inks, can be employed to protect and authenticate genuine products. Instead of using markers and additional identification means, one of the recent methods use a PUF-like authentication method based on image processing. However, in order to authenticate the object (e.g. a trademark product), the method needs direct access to the database system containing the object's \fingerprint\"". The paper presents a new secure method to remotely authenticate the object without communication with the database server. In this method",an autonomous and secure embedded system called authentication device authenticates the product by extracting its morphometric fingerprint and comparing it with a signed original morphometric fingerprint printed on the object. However,we show that in order to secure the protocol,the authentication hardware needs to be authenticated,too. For this reason,"we propose security protocols that allow to authenticate the authentication device and remotely check its integrity. The proposed security protocols are shown to be sure using formal methods of security protocol evaluation.""","protocols, object authentication, remote, counterfeiting, serverless",WESS '10,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liu X,Zhang Z",3D Shape Measurement of Complex Surface by Combining Fringe Projection and Phase Measuring Deflectometry,,2019,,,10–14,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 2nd International Conference on Information Hiding and Image Processing,"London, United Kingdom",2019,9781450372879,,https://doi.org/10.1145/3383913.3383918;http://dx.doi.org/10.1145/3383913.3383918,10.1145/3383913.3383918,"There are many components having both diffused and specular surfaces together, which called as complex object. The existing fringe projection profilometry and deflectometry can only measure 3D (three-dimensional) shape of diffused and specular surfaces, respectively. This paper presents a novel method to measure 3D shape of complex objects by combining fringe projection profilometry and DPMD (direct phase measuring deflectometry) technique. The specular parts of a complex object reflect fringe pattern of two LCD (Liquid Crystal Display) screens and the other parts diffuse the projected fringe pattern from a DLP (digital light processing) projector. All the specular reflected and diffused deformed fringe patterns are simultaneously captured by multiple color channels of a color camera from a different viewpoint. The reflected and diffused fringe patterns on the measured complex object are easily extracted from the captured color images. The absolute phase information is calculated from the extracted fringe patterns. After 3D calibration to build up the relationship between phase and depth, 3D shape data of the measured complex object are obtained. An artificial complex step having diffused and specular surfaces has been manufactured to verify the proposed method. Experimental results show that this method can measure complex surfaces effectively.","complex surfaces, fringe projection, phase measuring deflectometry, system calibration",IHIP 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oliveira BC,Mu SC,You SH",Modular Reifiable Matching: A List-of-Functors Approach to Two-Level Types,,2015,,,82–93,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 ACM SIGPLAN Symposium on Haskell,"Vancouver, BC, Canada",2015,9781450338080,,https://doi.org/10.1145/2804302.2804315;http://dx.doi.org/10.1145/2804302.2804315,10.1145/2804302.2804315,"This paper presents Modular Reifiable Matching (MRM): a new approach to two level types using a fixpoint of list-of-functors representation. MRM allows the modular definition of datatypes and functions by pattern matching, using a style similar to the widely popular Datatypes a la Carte (DTC) approach. However, unlike DTC, MRM uses a fixpoint of list-of-functors approach to two-level types. This approach has advantages that help with various aspects of extensibility, modularity and reuse. Firstly, modular pattern matching definitions are collected using a list of matches that is fully reifiable. This allows for extensible pattern matching definitions to be easily reused/inherited, and particular matches to be overridden. Such flexibility is used, among other things, to implement extensible generic traversals. Secondly, the subtyping relation between lists of functors is quite simple, does not require backtracking, and is easy to model in languages like Haskell. MRM is implemented as a Haskell library, and its use and applicability are illustrated through various examples in the paper.","Modular Datatypes, Subtyping",Haskell '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Oliveira BC,Mu SC,You SH",Modular Reifiable Matching: A List-of-Functors Approach to Two-Level Types,SIGPLAN Not.,2015,50,12,82–93,Association for Computing Machinery,"New York, NY, USA",,,,2015-08,,0362-1340,https://doi.org/10.1145/2887747.2804315;http://dx.doi.org/10.1145/2887747.2804315,10.1145/2887747.2804315,"This paper presents Modular Reifiable Matching (MRM): a new approach to two level types using a fixpoint of list-of-functors representation. MRM allows the modular definition of datatypes and functions by pattern matching, using a style similar to the widely popular Datatypes a la Carte (DTC) approach. However, unlike DTC, MRM uses a fixpoint of list-of-functors approach to two-level types. This approach has advantages that help with various aspects of extensibility, modularity and reuse. Firstly, modular pattern matching definitions are collected using a list of matches that is fully reifiable. This allows for extensible pattern matching definitions to be easily reused/inherited, and particular matches to be overridden. Such flexibility is used, among other things, to implement extensible generic traversals. Secondly, the subtyping relation between lists of functors is quite simple, does not require backtracking, and is easy to model in languages like Haskell. MRM is implemented as a Haskell library, and its use and applicability are illustrated through various examples in the paper.","Modular Datatypes, Subtyping",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gao Y,Yang Y,Zhen Y,Dai Q",Depth Error Elimination for RGB-D Cameras,ACM Trans. Intell. Syst. Technol.,2015,6,2,,Association for Computing Machinery,"New York, NY, USA",,,,2015-04,,2157-6904,https://doi.org/10.1145/2735959;http://dx.doi.org/10.1145/2735959,10.1145/2735959,"The rapid spreading of RGB-D cameras has led to wide applications of 3D videos in both academia and industry, such as 3D entertainment and 3D visual understanding. Under these circumstances, extensive research efforts have been dedicated to RGB-D camera--oriented topics. In these topics, quality promotion of depth videos with the temporal characteristic is emerging and important. Due to the limited exposure time of RGB-D cameras, object movement can easily lead to motion blurs in intensive images, which can further result in obvious artifacts (holes or fake boundaries) in the corresponding depth frames. With regard to this problem, we propose a depth error elimination method based on time series analysis to remove the artifacts in depth images. In this method, we first locate the regions with erroneous depths in intensive images by using motion blur detection based on a time series analysis model. This is based on the fact that the depth image is calculated by intensive color images that are captured synchronously by RGB-D cameras. Then, the artifacts, such as holes or fake boundaries, are fixed by a depth error elimination method. To evaluate the performance of the proposed method, we conducted experiments on 250 images. Experimental results demonstrate that the proposed method can locate the error regions correctly and eliminate these artifacts effectively. The quality of depth video can be improved significantly by using the proposed method.","RGB-D cameras, depth video, time series analysis, Depth error",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pietroszek K,Wallace JR,Lank E",Tiltcasting: 3D Interaction on Large Displays Using a Mobile Device,,2015,,,57–62,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual ACM Symposium on User Interface Software & Technology,"Charlotte, NC, USA",2015,9781450337793,,https://doi.org/10.1145/2807442.2807471;http://dx.doi.org/10.1145/2807442.2807471,10.1145/2807442.2807471,"We develop and formally evaluate a metaphor for smartphone interaction with 3D environments: Tiltcasting. Under the Tiltcasting metaphor, users interact within a rotatable 2D plane that is \cast\"" from their phone's interactive display into 3D space. Through an empirical validation",we show that Tiltcasting supports efficient pointing,interaction with occluded objects,disambiguation between nearby objects,and object selection and manipulation in fully addressable 3D space. Our technique out-performs existing target agnostic pointing implementations,"and approaches the performance of physical pointing with an off-the-shelf smartphone.""","large displays, 3d interaction, 3d pointing, mobile device, design, mobile interaction",UIST '15,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tolk A,Turnitsa C",Conceptual Modeling with Processes,,2012,,,,Winter Simulation Conference,"Berlin, Germany",,Proceedings of the Winter Simulation Conference,,2012,,,,,"Western philosophy of science has been heavily influenced by the idea that substantials are the main carriers of knowledge. Objects and their attributes and their relations to other objects dominate the world of knowledge representation. Processes play a subordinated role as they are merely seen as the things that create, change, or destroy objects. A recent study has shown that this view is dominant in modeling and simulation as well. The paper presents the (semi-) formal method developed in the doctoral study and its application to conceptual modeling techniques as they are taught in M&S education. The result shows that objects and relations are well captured, but that processes can be used as an alternative viewpoint as well. Using a process driven viewpoint opens new conceptual insights. We show that using the formal method allows to extend legacy conceptual methods to address these new aspects as well.",,WSC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kong D,Feng Z,Tian J",Three-Dimensional Position Information Tracking Algorithm for Virtual Teaching Experiments,,2020,,,222–226,Association for Computing Machinery,"New York, NY, USA",,Proceedings of 2020 the 6th International Conference on Computing and Data Engineering,"Sanya, China",2020,9781450376730,,https://doi.org/10.1145/3379247.3379262;http://dx.doi.org/10.1145/3379247.3379262,10.1145/3379247.3379262,"Aiming at the problem of the difficulty of real-time accurate sensing and positioning of virtual objects in virtual experiments in middle schools, this paper designs a real-time acquisition algorithm of three-dimensional position information of virtual objects based on monocular vision. The designed target object binding can only perceive objects in a virtual scene in real time and accurately calculate its three-dimensional position information under an ordinary monocular camera. Finally, it is verified on the experimental teaching platform of fusion of reality and reality, which significantly reduces The difficulties in the interaction process enhance the user's sense of interaction and experience.","mix of virtual and actual reality, 3D position tracking, Monocular vision",ICCDE 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Bell N,Hirani AN",PyDEC: Software and Algorithms for Discretization of Exterior Calculus,ACM Trans. Math. Softw.,2012,39,1,,Association for Computing Machinery,"New York, NY, USA",,,,2012-11,,0098-3500,https://doi.org/10.1145/2382585.2382588;http://dx.doi.org/10.1145/2382585.2382588,10.1145/2382585.2382588,"This article describes the algorithms, features, and implementation of PyDEC, a Python library for computations related to the discretization of exterior calculus. PyDEC facilitates inquiry into both physical problems on manifolds as well as purely topological problems on abstract complexes. We describe efficient algorithms for constructing the operators and objects that arise in discrete exterior calculus, lowest-order finite element exterior calculus, and in related topological problems. Our algorithms are formulated in terms of high-level matrix operations which extend to arbitrary dimension. As a result, our implementations map well to the facilities of numerical libraries such as NumPy and SciPy. The availability of such libraries makes Python suitable for prototyping numerical methods. We demonstrate how PyDEC is used to solve physical and topological problems through several concise examples.","cochain, computational topology, chain, simplicial complex, boundary operator, Vietoris-Rips complex, Whitney form, Discrete exterior calculus, finite element exterior calculus, cubical complex, coboundary operator",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ramzi M,Larbi G,Lyamine G",Road Obstacle Detection,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Future Networks and Distributed Systems,"Paris, France",2019,9781450371636,,https://doi.org/10.1145/3341325.3341999;http://dx.doi.org/10.1145/3341325.3341999,10.1145/3341325.3341999,"In recent years, there has been rapid development in the research area of the car's driving assistance. Deep learning was used to solve different problems, such as object detection, visual recognition, speech recognition and handwriting recognition and was achieved a very good performance. In deep learning, Convolutional Neural Networks (ConvNets or CNNs) are found to give the most accurate results, in solving object detection problems. In this paper, we'll go into summarizing some of the most important deep learning models used for object detection tasks over this last recent year, then we present an approach where we detect roadsides, then we seek objects located on the road area to prevent driver. As the state of the driver is very important information, we try to detect driver's drowsiness. We use a camera with an algorithm to calculate the eye aspect ratio. Finally, we evaluated the three modules of proposed system using our collected data-set.","arduino, Object detection, help driving, road-edges detection",ICFNDS '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhu C,Morsi R",Formal Specification of FFHMIPv6 Using PVS,,2009,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2009 Spring Simulation Multiconference,"San Diego, California",2009,,,,,"Handover is a critical process in wireless networks, which determines the quality of communications, especially the real-time connections. Currently many protocols on handover have been proposed to meet the demand of IPv6 wireless communications, most of which have been appraised using simulation, testing, or both; few protocols have been specified and verified using Formal Methods. In this research, we apply Formal Methods to formally specify the new proposed fast handover protocol, Flow-Based Fast Handover Method for Mobile IPv6 Network (FFHMIPv6) [1]. To concentrate on the essence of the protocol, the best scenario in [1] is adopted as the object of the formal specification, and the best scenario is abstracted into a more concise structure to facilitate the specification. The formal specification provides the basis to formally verify the basic characteristics of safety and the proposed efficiency in future research. The formal specification is implemented using the Prototype Verification System (PVS) [2], which is a powerful formal specification and semi-automated verification environment.","handover, formal methods, PVS, FFHMIPv6 packets",SpringSim '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Suzuki T,Takasu A,Adachi J",Top-<i>k</i> Query Processing for Combinatorial Objects Using Euclidean Distance,,2011,,,209–213,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th Symposium on International Database Engineering & Applications,"Lisboa, Portugal",2011,9781450306270,,https://doi.org/10.1145/2076623.2076651;http://dx.doi.org/10.1145/2076623.2076651,10.1145/2076623.2076651,"Conventional search techniques are mainly designed to return a ranked list of single objects that are relevant to a given query. However, they do not meet the criteria for retrieving a combination of objects that is close to the query. This paper presents top-k query processing in which Euclidean distance is used as the scoring function for combinatorial objects. We also propose a pruning method based on clustering and efficiently select object combinations by pruning clusters that do not contain potential candidates for the top-k results. We compared the proposed method with the method that enumerates all the combinatorial objects and calculates the distance to the query. Experimental results revealed that the proposed method improves the processing efficiency to about 95% at maximum.","combinatorial search, top-k query processing, clustering, principal component analysis",IDEAS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Young H,A Categorial Grammar for Music and Its Use in Automatic Melody Generation,,2017,,,1–9,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 5th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design","Oxford, UK",2017,9781450351805,,https://doi.org/10.1145/3122938.3122939;http://dx.doi.org/10.1145/3122938.3122939,10.1145/3122938.3122939,"Like natural language, music can be described as being composed of various parts, which combine together to form a set-theoretic or logical entity. The conceptualized parts are more basic than the music seen on a page; they are the musical objects subject to music-theoretic analysis, and can be described using the language of functional programming and lambda calculus. This paper introduces the types of musical objects seen in tonal and modern music, as well as the combinators that allow them to combine to create other musical objects. We propose a method for automatically generating melodies by searching for combinations of musical objects which together produce a valid program corresponding to a melody or set of melodies.","automatic music, categorial grammar, music generation",FARM 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Neha E,Suhaib M,Mukherjee S",Grasp Force Analysis of Four-Finger Tendon Actuated Robotic Hand,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Advances in Robotics 2019,"Chennai, India",2019,9781450366502,,https://doi.org/10.1145/3352593.3352602;http://dx.doi.org/10.1145/3352593.3352602,10.1145/3352593.3352602,"Multi-finger robotic hands are designed to perform secure and stable grasping of different objects similar to human hands. It is always desirable to evaluate the grasp capabilities of any robotic hand in order to check its performance. This paper discusses about the grasp capability analysis of the four-finger tendon actuated robotic hand. For this purpose the mathematical model for cylindrical shaped objects is developed. These mathematical equations help in calculating the contact forces of every phalange of the finger on the surface of the grasped object. In this process tendon tensions and contact forces are determined theoretically for the finger and thumb separately while grasping objects of different size, weights and materials from the derived equations. Lastly, the obtained results are experimentally validated by carrying out the grasp analysis of cylindrical objects of varying diameters and materials by the four-finger tendon actuated robotic hand. Tendon tensions obtained experimentally are compared with those calculated from the derived equations and various conclusions are drawn based on the obtained results.","Grasp Analysis, contact forces, Actuation forces, Tendon tension",AIR 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Albuquerque ES,Ferreira AP,Silva JG,Barbosa JP,Carlos RL,Albuquerque DS,Barros EN",An FPGA-Based Accelerator for Multiple Real-Time Template Matching,,2017,,,,IEEE Press,"Belo Horizonte, Brazil",,Proceedings of the 29th Symposium on Integrated Circuits and Systems Design: Chip on the Mountains,,2017,9781509027361,,,,"Object tracking with multiple dense templates is a challenging problem in the context of continuous monitoring video cameras. Applications of the multiple match template technique range from tracking of multiple independent objects to several pose variations of a single object. Due to its high accuracy and tolerance to brightness and contrast changes, the zero mean normalized cross-correlation(ZNCC) was selected as similarity measure. This paper proposes an FPGA architecture that explores a full pipeline implementation and maximizes the internal data reuse to calculate several ZNCC-based template matching in an efficient approach. Experimental results shows that the proposed implementation achieves the real-time performance reaching up to 30fps running ten parallel ZNCCs in a single Stratix IV FPGA.",,SBCCI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wu C,Liu J,Wang X,Dong X",Object-Difference Attention: A Simple Relational Attention for Visual Question Answering,,2018,,,519–527,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th ACM International Conference on Multimedia,"Seoul, Republic of Korea",2018,9781450356657,,https://doi.org/10.1145/3240508.3240513;http://dx.doi.org/10.1145/3240508.3240513,10.1145/3240508.3240513,"Attention mechanism has greatly promoted the development of Visual Question Answering (VQA). Attention distribution, which weights differently on objects (such as image regions or bounding boxes) in an image according to their importance for answering a question, plays a crucial role in attention mechanism. Most of the existing work focuses on fusing image features and text features to calculate the attention distribution without comparisons between different image objects. As a major property of attention, selectivity depends on comparisons between different objects. Comparisons provide more information for assigning attentions better. For achieving this, we propose an object-difference attention (ODA) which calculates the probability of attention by implementing difference operator between different image objects in an image under the guidance of questions in hand. Experimental results on three publicly available datasets show our ODA based VQA model achieves the state-of-the-art results. Furthermore, a general form of relational attention is proposed. Besides ODA, several other relational attentions are given. Experimental results show those relational attentions have strengths on different types of questions.","visual question answering, object-difference attention, attention",MM '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Matsumoto R,Takemura K",Semantic 3D Gaze Mapping for Estimating Focused Objects,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st International Conference on Human-Computer Interaction with Mobile Devices and Services,"Taipei, Taiwan",2019,9781450368254,,https://doi.org/10.1145/3338286.3344396;http://dx.doi.org/10.1145/3338286.3344396,10.1145/3338286.3344396,"Eye-trackers are expected to be used in portable daily-use devices. However, it must register object information and define a unified coordinate system in advance for human--computer interaction and quantitative analysis. Therefore, we propose a semantic 3D gaze mapping to collect gaze information from multiple people on the unified map and detect focused objects automatically. The semantic 3D map can be reconstructed using keyframe-based semantic segmentation and structure-from-motion, and the 3D point-of-gaze can also be computed on the map. We confirmed that the fixation time of the focused object can be calculated through an experiment without prior information.","3D point-of-gaze, Semantic 3D map, Structure from Motion",MobileHCI '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Stojanovic V,Trapp M,Döllner J,Richter R",Classification of Indoor Point Clouds Using Multiviews,,2019,,,1–9,Association for Computing Machinery,"New York, NY, USA",,The 24th International Conference on 3D Web Technology,"LA, CA, USA",2019,9781450367981,,https://doi.org/10.1145/3329714.3338129;http://dx.doi.org/10.1145/3329714.3338129,10.1145/3329714.3338129,"We present an approach for classifying 3D point clouds of indoor environments using Convolutional Neural Network (CNN)-based image analysis for entropy-selected 3D views. Prior to classification, the 3D point clouds are clustered using either Density-based Spatial Clustering of Applications with Noise (DBSCAN) or k-means algorithms. We then use randomly sampled 3D point normal vectors as an entropy descriptor to calculate the direction and position of the virtual camera, which is placed around these clusters. It synthesizes 2D images of a given cluster from multiple views with positions and directions that have highest visual entropy. We then proceed to classify the images using a retrained CNN. We test our approach for classifying common office furniture items using both synthetic and actual 3D point clouds of typical indoor office spaces. The empirical results demonstrate that our approach is suited towards classifying specific indoor furniture objects. We also describe how our approach can be implemented as a lightweight component within a service-oriented system that is used for visualization and classification of 3D point clouds using a given Web3D tool. The resulting semantically-enriched 3D point clouds can further be used for digital indoor environment representations, with further use as base data for Building Information Modeling (BIM), Facility Management (FM), and Digital Twin (DT) applications.","Indoor Point Clouds, Multiview Classification, Semantic Enrichment, Viewpoint Entropy",Web3D '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Carter D,How to Debate a Border: Supporting Infrastructure Publics through Communication System Design,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 37th ACM International Conference on the Design of Communication,"Portland, Oregon",2019,9781450367905,,https://doi.org/10.1145/3328020.3353932;http://dx.doi.org/10.1145/3328020.3353932,10.1145/3328020.3353932,"While crucial infrastructures in the United States and similar countries are increasingly in conditions of crisis and decay, people living in these countries often lack a shared understanding of these systems from which to imagine the kind of radical change that theorists such as Lauren Berlant have argued is needed. As recent political controversies make clear, this lack of shared understanding extends to national infrastructures such as borders and points of entry. However, like all infrastructures, these are complex sociotechnical objects that challenge simple understanding. Collectively debating future infrastructure is complex and feels, in the present moment, insurmountable. At the same time, reimagining these systems for more equitable futures is crucial.Drawing on theories from a range of fields including anthropology and design, this paper considers the communication systems that might support broad groups with the shared understandings needed to debate the futures of infrastructures. It first describes a series of events in early 2017 related to the increased search and seizure of personal electronic devices at United States airports. It then analyzes the online comments left in response to articles about these events, arguing that the comments demonstrate both the tracing of existing infrastructures and the imagining of new infrastructures. Implications from this analysis include the potential of including speculation as a value that could be formally recognized by evaluation systems and the need to carefully consider how expert knowledge about present infrastructures is communicated alongside more future-oriented commentary.","online communication design, participatory design, speculative design, infrastructure",SIGDOC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen Z,Yang W,Xu Z,Xie X,Huang L,Null N",DCNet: Dense Correspondence Neural Network for 6DoF Object Pose Estimation in Occluded Scenes,,2020,,,3929–3937,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th ACM International Conference on Multimedia,"Seattle, WA, USA",2020,9781450379885,,https://doi.org/10.1145/3394171.3413672;http://dx.doi.org/10.1145/3394171.3413672,10.1145/3394171.3413672,"6DoF object pose estimation is essential for many real-world applications. Although great progress has been made, challenges still remain in estimating 6D pose for occluded objects. Current RGB-D approaches predict 6DoF pose directly, which is sensitive to occlusion in cluttered scenes. In this work, we propose DCNet, an end-to-end framework for estimating 6DoF object poses. DCNet first converts pixels in the image plane to point clouds in the camera coordinate system and then establishes dense correspondences between the camera coordinate system and the object coordinate system. Based on these two systems, we fuse 2D appearance and 3D geometric features by pixel-wise concatenation to construct dense correspondences, from which the pose is calculated through the least-squares fitting algorithm. Dense correspondences guarantee enough point pairs for a robust 6DoF pose estimation, even if the occlusion is heavy. Experimental results demonstrate that DCNet outperforms the state-of-the-art methods on LINEMOD, Occlusion LINEMOD and YCB-Video datasets, especially in terms of the robustness to occlusion scenes.","6d pose estimation, neural networks",MM '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liu T,Yin L,Yuan S,Lv J,Zhang F",Research On Adaptive Object Detection Method Of Kernel Correlation Filtering,,2020,,,55–61,Association for Computing Machinery,"New York, NY, USA",,2020 The 4th International Conference on Video and Image Processing,"Xi'an, China",2020,9781450389075,,https://doi.org/10.1145/3447450.3447459;http://dx.doi.org/10.1145/3447450.3447459,10.1145/3447450.3447459,"Aiming at the problem that the KCF algorithm cannot adaptively track the object and even the object may be lost when the object scale changes, this paper proposes a kernel correlation filter algorithm that can perform adaptive object detection. The KCF algorithm is adopted to calculate the center position of the object, and the object is divided into sub-blocks for applying the KCF classifier idea to each sub-block at the same time. Then the center position of each sub-block is calculated for estimating the scale change ratio of the object according to the relative change of the center position of the sub-block. And the scale information of the object is finally determined for following tracking. On this basis, the HOG feature and the CN feature are combined to make full use of the image pixel information to promote accuracy of the object prediction. Finally, public dataset is used for comparing the proposed method with multiple classic algorithms. The experimental result illustrate that the proposed method can obtain better accuracy and overlapping ratio, and the processing speed can meet the real-time requirements, which verifies the effectiveness of the proposed algorithm.","Sub-Block, Adaptive, Kernel Correlation Tracking, Combined",ICVIP 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhuang X,Zhou X,Hasegawa-Johnson MA,Huang TS",Efficient Object Localization with Gaussianized Vector Representation,,2009,,,89–96,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st International Workshop on Interactive Multimedia for Consumer Electronics,"Beijing, China",2009,9781605587585,,https://doi.org/10.1145/1631040.1631055;http://dx.doi.org/10.1145/1631040.1631055,10.1145/1631040.1631055,"Recently, the Gaussianized vector representation has been shown effective in several applications related to interactive multimedia, such as facial age estimation, image scene categorization and video event recognition. However, all these tasks are classification and regression problems based on the whole images. It is not yet explored how this representation can be efficiently applied in the object localization problem, which reveals the locations and sizes of the objects. In this paper, we present an efficient object localization approach for the Gaussianized vector representation, following a branch-and-bound search scheme introduced by Lampert et al. In particular, we design a quality bound for rectangle sets characterized by the Gaussianized vector representation for fast hierarchical search. This bound can be obtained for any rectangle set in the image, with little extra computational cost, in addition to calculating the Gaussianized vector representation for the whole image. A localization experiment on a multi-scale car dataset shows that the proposed object localization approach based on the Gaussianized vector representation outperforms previous work using the histogram-of-keywords representation.","branch and bound, efficient object localization, gaussianized vector representation",IMCE '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zheng Z,Ma L,Li Z,Chen Z",Reconstruction of Shape and Reflectance Properties Based on Visual Hull,,2009,,,29–38,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 Computer Graphics International Conference,"Victoria, British Columbia, Canada",2009,9781605586878,,https://doi.org/10.1145/1629739.1629743;http://dx.doi.org/10.1145/1629739.1629743,10.1145/1629739.1629743,"A method based on Visual Hull is proposed for simultaneously recovering an object's shape and its reflectance properties from multiple images. Here, the reflectance properties are described by the Ward BRDF model. Firstly, the shape represented by voxels is acquired by applying SFS (Shape from Silhouettes) method, and the triangular mesh of the surface is extracted by Marching Cube algorithm. Secondly, the appearance-like mesh vertices are clustered into categories, and non-linear optimization is applied to each category for calculating its reflectance model parameters. Last, diffuse parameters for each vertex are re-computed. The acquired object shape and its reflectance parameters can be used for photo-realistic rendering. The experimental results on multiple real objects images show the efficiency of the proposed method.",,CGI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Steel TB,A First Version of UNCOL,,1961,,,371–378,Association for Computing Machinery,"New York, NY, USA",,"Papers Presented at the May 9-11, 1961, Western Joint IRE-AIEE-ACM Computer Conference","Los Angeles, California",1961,9781450378727,,https://doi.org/10.1145/1460690.1460733;http://dx.doi.org/10.1145/1460690.1460733,10.1145/1460690.1460733,"UNCOL--UNiversal Computer Oriented Language--is being designed as an empirical, pragmatic aid to the solution of a fundamental problem of the digital data processing business: automated translation of programs from expressions in an ever increasing set of problem oriented languages into the machine languages of an expanding variety of digital processing devices. By application of a program called a generator, specific to a given problem language, program statements in this problem language are transformed into equivalent UNCOL statements, independent of any consideration of potential target computers. Subsequently, without regard to the identity of the original problem language, the UNCOL statement of the problem is processed by a program called a translator, which is specific to a given target computer, and the result is an expression of the original problem solution in the machine language of the desired processor. The advantage of this apparent complication over the current procedure of employing a program called a compiler for direct transformation from problem language to machine language is evident when one examines the number of languages and machines involved and the not inconsiderable expense of translation program construction. If there are M problem languages and N machines, then M+N compilers are required and only M+N generators and translators.In order to arrive at sensible specifications for UNCOL, certain limitations in its scope are essential. Accordingly, UNCOL is designed to cope with only those problem language and machine language characteristics that can reasonably be expected to enjoy general use in the next decade. Any broader approach shows promise of leading to elegant, impractical results.A glance at the preliminary specifications for UNCOL shows a language akin to a symbolic assembly language for a register-free, single address, indexed machine. The specific commands are few in number and simple in construction, depending on a special defining capability for the expression of more elaborate instructions. The data referencing scheme is complex, allowing the application of a signed index to the primary address, and permitting both the primary and index parts to be delegated to an indefinite level.Each item of data, either input or calculated, must be described as to type, range precision and the like by special data descriptive syntactical sentences in the language. These descriptions, additionally, provide information concerning ultimate storage allocation as well as indicators of contextual meaning for the explicit commands.Supplementary to the instructions and data descriptions are certain declarative sentences, inessential to the explicit statement of the problem solutions being translated, designed to provide information useful to the translator in the introduction of computational efficiency into the object program.",,IRE-AIEE-ACM '61 (Western),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"De Virgilio R,Milicchio F",RFID Data Analysis Using Tensor Calculus for Supply Chain Management,,2011,,,1743–1748,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th ACM International Conference on Information and Knowledge Management,"Glasgow, Scotland, UK",2011,9781450307178,,https://doi.org/10.1145/2063576.2063828;http://dx.doi.org/10.1145/2063576.2063828,10.1145/2063576.2063828,"In current trends of consumer products market, there is a growing significance of the role of retailers in the governance of supply chains. RFID is a promising infrastructure-less technology, allowing to connect an object with its virtual counterpart, i.e., its representation within information systems. However, the amount of RFID data in supply chain management is vast, posing significant challenges for attaining acceptable performance on their analysis. Current approaches provide hard-coded solutions, with high consumption of resources; moreover, these exhibit very limited flexibility dealing with multidimensional queries, at various levels of granularity and complexity. In this paper we propose a general model for supply chain management based on the first principles of linear algebra, in particular on tensorial calculus. Leveraging our abstract algebraic framework, our technique allows both quick decentralized on-line processing, and centralized off-line massive business logic analysis, according to needs and requirements of supply chain actors. Experimental results show that our approach, utilizing recent linear algebra techniques can process analysis efficiently, when compared to recent approaches. In particular, we are able to carry out the required computations even in high memory constrained environments, such as on mobile devices. Moreover, when dealing with massive amounts of data, we are capable of exploiting recent parallel and distributed technologies, subdividing our tensor objects into sub-blocks, and processing them independently.","supply chain, algebraic models, multidimensional analysis",CIKM '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Devanur NR,Fortnow L",A Computational Theory of Awareness and Decision Making,,2009,,,99–107,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Conference on Theoretical Aspects of Rationality and Knowledge,California,2009,9781605585604,,https://doi.org/10.1145/1562814.1562830;http://dx.doi.org/10.1145/1562814.1562830,10.1145/1562814.1562830,"We exhibit a new computational-based definition of awareness, informally that our level of unawareness of an object is the amount of time needed to generate that object within a certain environment. We give several examples to show this notion matches our intuition in scenarios where one organizes, accesses and transfers information. We also give a formal process-independent definition of awareness based on Levin's universal enumeration.We show the usefulness of computational awareness by showing how it relates to decision making, and how others can manipulate our decision making with appropriate advertising, in particular, we show connections to sponsored search and brand awareness. Understanding awareness can also help rate the effectiveness of various user interfaces designed to access information.",,TARK '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Suto G,Greenleaf GS,Bhagavatula P,Fischer HR,Soni SK,Miller BH,Hentschke RF",Declarative Language for Geometric Pattern Matching in VLSI Process Rule Modeling,,2019,,,75–82,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 International Symposium on Physical Design,"San Francisco, CA, USA",2019,9781450362535,,https://doi.org/10.1145/3299902.3309745;http://dx.doi.org/10.1145/3299902.3309745,10.1145/3299902.3309745,"This paper presents a formal (machine readable) declarative language developed for the specific reason of modeling physical design process rules of any complexity. Case studies are presented on synthetic as well as industry known design rules of simple complexity (two objects, pair-wise relationship) as well as multi-object complex rules (n-wise relationship). The building blocks of the language are presented and a comparison is drawn between declarative and imperative (general industry practice) implementation of a rule. Automatic test layout generation is presented that would not be possible on an imperative model. Advanced language concepts are also described, including patterns - that can be embedded in each other - as well as rule exceptions using the logical NOT in conjunction with patterns. Further advanced language features are presented, including grids (discretization) and sets - all crucial elements for implementing a wide variety of rules. A strong argument is made for the advantages of this language being the precise and unambiguous description of the intent of the rule with immediate access to a rule checker as well as automatic test layout generator that can test the boundaries of the process node.","formal, declarative, rule modeling, process rules",ISPD '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kang J,Zheng J,Bai H,Xue X,Zhou Y,Guo J,Gan D",A Video Analysis Method on Wanfang Dataset via Deep Neural Network,,2019,,,126–131,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Video and Image Processing,"Shanghai, China",2019,9781450376822,,https://doi.org/10.1145/3376067.3376075;http://dx.doi.org/10.1145/3376067.3376075,10.1145/3376067.3376075,"The topic of object detection has been largely improved recently, especially with the development of convolutional neural network. However, there still exist a lot of challenging cases, such as small object, compact and dense or highly overlapping object. Existing methods can detect multiple objects wonderfully, but because of the slight changes between frames, the detection effect of the model will become unstable, the detection results may result in dropping or increasing the object. In the pedestrian flow detection task, such phenomenon can not accurately calculate the flow. To solve this problem, in this paper, we describe the new function for real-time multi-object detection in sports competition and pedestrians flow detection in public based on deep learning. Our work is to extract a video clip and solve this frame of clips efficiently. More specifically, our algorithm includes two stages: judge method and optimization method. The judge can set a maximum threshold for better results under the model, the threshold value corresponds to the upper limit of the algorithm with better detection results. The optimization method to solve detection jitter problem. Because of the occurrence of frame hopping in the video, and it will result in the generation of video fragments discontinuity. We use optimization algorithm to get the key value, and then the detection result value of index is replaced by key value to stabilize the change of detection result sequence. Based on the proposed algorithm, we adopt wanfang sports competition dataset as the main test dataset and our own test dataset for YOLOv3-Abnormal Number Version(YOLOv3-ANV), which is 5.4% average improvement compared with existing methods. Also, video above the threshold value can be obtained for further analysis. Spontaneously, our work also can used for pedestrians flow detection and pedestrian alarm tasks. Further more, all the code are publicly available for further research: https://github.com/kangjinlong/yolov3_Abnormal-video.","Convolutional neural network, Single&Multi object detection, Video analysis, YOLOv3-ANV",ICVIP 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Essig K,Dornbusch D,Prinzhorn D,Ritter H,Maycock J,Schack T",Automatic Analysis of 3D Gaze Coordinates on Scene Objects Using Data from Eye-Tracking and Motion-Capture Systems,,2012,,,37–44,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Symposium on Eye Tracking Research and Applications,"Santa Barbara, California",2012,9781450312219,,https://doi.org/10.1145/2168556.2168561;http://dx.doi.org/10.1145/2168556.2168561,10.1145/2168556.2168561,"We implemented a system, called the VICON-EyeTracking Visualizer, that combines mobile eye tracking data with motion capture data to calculate and visualize the 3D gaze vector within the motion capture co-ordinate system. To ensure that both devices were temporally synchronized we used previously developed software by us. By placing reflective markers on objects in the scene, their positions are known and by spatially synchronizing both the eye tracker and the motion capture system allows us to automatically compute how many times and where fixations occur, thus overcoming the time consuming and error-prone disadvantages of the traditional manual annotation process. We evaluated our approach by comparing its outcome for a simple looking task and a more complex grasping task against the average results produced by the manual annotation process. Preliminary data reveals that the program only differed from the average manual annotation results by approximately 3 percent in the looking task with regard to the number of fixations and cumulative fixation duration on each point in the scene. In case of the more complex grasping task the results depend on the object size: for larger objects there was good agreement (less than 16 percent (or 950ms)), but this degraded for smaller objects, where there are more saccades towards object boundaries. The advantages of our approach are easy user calibration, the ability to have unrestricted body movements (due to the mobile eye-tracking system), and that it can be used with any wearable eye tracker and marker based motion tracking system. Extending existing approaches, our system is also able to monitor fixations on moving objects. The automatic analysis of gaze and movement data in complex 3D scenes can be applied to a variety of research domains, i. e., Human Computer Interaction, Virtual Reality or grasping and gesture research.","eye tracking, gaze tracking, motion tracking, 3D gaze vector",ETRA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lu W,Wu G",Salient Object Detection via Multi-Scale Neural Network,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Conference on Internet Multimedia Computing and Service,"Nanjing, China",2018,9781450365208,,https://doi.org/10.1145/3240876.3240923;http://dx.doi.org/10.1145/3240876.3240923,10.1145/3240876.3240923,"Salient object detection, a fundamental of many computer vision tasks, aims to find the most attractive objects in a given image. In this paper, we propose an end-to-end multi-scale neural network for salient object detection. Firstly, we propose heterogeneous dilated block to effectively increases the receptive field of the network, while alleviating the gridding effect problem caused by dilated convolution. Secondly, we replace the traditional interpolation up-sampling layer with a fully learnable up-sampling module to solve the blurry artifacts and improve the accuracy. Finally, we calculate the loss at three different scales, enabling the network to learn better through back-propagation. The proposed method is validated on MSRA and ECSSD datasets, and shown to outperform the state-of-the-art methods.","multi-scale loss, convolution neural networks, dilated convolution, salient object detection",ICIMCS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nishimura T,Hashimoto A,Yamakata Y,Mori S",Frame Selection for Producing Recipe with Pictures from an Execution Video of a Recipe,,2019,,,9–16,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th Workshop on Multimedia for Cooking and Eating Activities,"Ottawa ON, Canada",2019,9781450367790,,https://doi.org/10.1145/3326458.3326928;http://dx.doi.org/10.1145/3326458.3326928,10.1145/3326458.3326928,"In cooking procedure instruction, text format plays an important role in conveying quantitative information accurately, such as time and quantity. On the other hand, image format can smoothly convey qualitative information (e.g., the target food state of a procedure) at a glance. Our goal is to produce multimedia recipes, which have texts and corresponding pictures, for chefs to better understand the procedures. The system takes a procedural text and its unedited execution video as the input and outputs selected frames for instructions in the text. We assume that a frame suits to an instruction when they share key objects. Under this assumption, we extract the information of key objects using named entity recognizer from the text and object detection from the frame, and we convert them into feature vectors and calculate their cosine similarity. To enhance the measurement, we also calculate the scene importance based on the latest changes in object appearance, and aggregate it to the cosine similarity. Finally we align the instruction sequence and the frame sequence using the Viterbi algorithm referring to this suitability and get the frame selection for each instruction. We implemented our method and tested it on a dataset consisting of text recipes and their execution videos. In the experiments we compared the automatic alignment results with those by human annotators. The precision, recall, and F-measure showed that the proposed approach made a steady improvement in this challenging problem of selecting pictures from an unedited video.","execution video, frame selection, procedural text",CEA '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Lauster F,Luke DR,Tam MK",Symbolic Computation with Monotone Operators,ACM Commun. Comput. Algebra,2019,52,4,139–141,Association for Computing Machinery,"New York, NY, USA",,,,2019-05,,1932-2240,https://doi.org/10.1145/3338637.3338646;http://dx.doi.org/10.1145/3338637.3338646,10.1145/3338637.3338646,"The Fenchel conjugate, f*, and the subdifferential, ∂f, of a function f are two objects of fundamental importance in convex analysis. For this reason, software libraries or packages which have the ability to compute and manipulate such objects easily are a valuable edition to the convex analyst's toolkit. Moreover, such tools have potential pedagogical uses if one believes, as we do, that nonsmooth analysis could and should be a part of the traditional \calculus\"" cannon taught to high school and beginning Bachelor's level students.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Chlipala A,Parametric Higher-Order Abstract Syntax for Mechanized Semantics,,2008,,,143–156,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM SIGPLAN International Conference on Functional Programming,"Victoria, BC, Canada",2008,9781595939197,,https://doi.org/10.1145/1411204.1411226;http://dx.doi.org/10.1145/1411204.1411226,10.1145/1411204.1411226,"We present parametric higher-order abstract syntax (PHOAS), a new approach to formalizing the syntax of programming languages in computer proof assistants based on type theory. Like higher-order abstract syntax (HOAS), PHOAS uses the meta language's binding constructs to represent the object language's binding constructs. Unlike HOAS, PHOAS types are definable in general-purpose type theories that support traditional functional programming, like Coq's Calculus of Inductive Constructions. We walk through how Coq can be used to develop certified, executable program transformations over several statically-typed functional programming languages formalized with PHOAS; that is, each transformation has a machine-checked proof of type preservation and semantic preservation. Our examples include CPS translation and closure conversion for simply-typed lambda calculus, CPS translation for System F, and translation from a language with ML-style pattern matching to a simpler language with no variable-arity binding constructs. By avoiding the syntactic hassle associated with first-order representation techniques, we achieve a very high degree of proof automation.","type-theoretic semantics, interactive proof assistants, dependent types, compiler verification",ICFP '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Chlipala A,Parametric Higher-Order Abstract Syntax for Mechanized Semantics,SIGPLAN Not.,2008,43,9,143–156,Association for Computing Machinery,"New York, NY, USA",,,,2008-09,,0362-1340,https://doi.org/10.1145/1411203.1411226;http://dx.doi.org/10.1145/1411203.1411226,10.1145/1411203.1411226,"We present parametric higher-order abstract syntax (PHOAS), a new approach to formalizing the syntax of programming languages in computer proof assistants based on type theory. Like higher-order abstract syntax (HOAS), PHOAS uses the meta language's binding constructs to represent the object language's binding constructs. Unlike HOAS, PHOAS types are definable in general-purpose type theories that support traditional functional programming, like Coq's Calculus of Inductive Constructions. We walk through how Coq can be used to develop certified, executable program transformations over several statically-typed functional programming languages formalized with PHOAS; that is, each transformation has a machine-checked proof of type preservation and semantic preservation. Our examples include CPS translation and closure conversion for simply-typed lambda calculus, CPS translation for System F, and translation from a language with ML-style pattern matching to a simpler language with no variable-arity binding constructs. By avoiding the syntactic hassle associated with first-order representation techniques, we achieve a very high degree of proof automation.","interactive proof assistants, type-theoretic semantics, compiler verification, dependent types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Atmosukarto I,Shapiro LG",3d Object Retrieval Using Salient Views,,2010,,,73–82,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Multimedia Information Retrieval,"Philadelphia, Pennsylvania, USA",2010,9781605588155,,https://doi.org/10.1145/1743384.1743403;http://dx.doi.org/10.1145/1743384.1743403,10.1145/1743384.1743403,"This paper presents a method for selecting salient 2D views to describe 3D objects for the purpose of retrieval. The views are obtained by first identifying salient points via a learning approach that uses shape characteristics of the 3D points [4, 3]. The salient views are selected by choosing views with multiple salient points on the silhouette of the object. Silhouette-based similarity measures from [6] are then used to calculate the similarity between two 3D objects. Experimental results show that the retrieval results using the salient views are comparable to the existing light field descriptor method [6], and our method achieves a 15-fold speedup in the feature extraction computation time.","3d object retrieval, salient points, 3d object signature",MIR '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kang J,Hur CK,Mansky W,Garbuzov D,Zdancewic S,Vafeiadis V",A Formal C Memory Model Supporting Integer-Pointer Casts,,2015,,,326–335,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Portland, OR, USA",2015,9781450334686,,https://doi.org/10.1145/2737924.2738005;http://dx.doi.org/10.1145/2737924.2738005,10.1145/2737924.2738005,"The ISO C standard does not specify the semantics of many valid programs that use non-portable idioms such as integer-pointer casts. Recent efforts at formal definitions and verified implementation of the C language inherit this feature. By adopting high-level abstract memory models, they validate common optimizations. On the other hand, this prevents reasoning about much low-level code relying on the behavior of common implementations, where formal verification has many applications. We present the first formal memory model that allows many common optimizations and fully supports operations on the representation of pointers. All arithmetic operations are well-defined for pointers that have been cast to integers. Crucially, our model is also simple to understand and program with. All our results are fully formalized in Coq.","C Memory Model, Verification, Integer-Pointer Cast, Compiler, Optimization",PLDI '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kang J,Hur CK,Mansky W,Garbuzov D,Zdancewic S,Vafeiadis V",A Formal C Memory Model Supporting Integer-Pointer Casts,SIGPLAN Not.,2015,50,6,326–335,Association for Computing Machinery,"New York, NY, USA",,,,2015-06,,0362-1340,https://doi.org/10.1145/2813885.2738005;http://dx.doi.org/10.1145/2813885.2738005,10.1145/2813885.2738005,"The ISO C standard does not specify the semantics of many valid programs that use non-portable idioms such as integer-pointer casts. Recent efforts at formal definitions and verified implementation of the C language inherit this feature. By adopting high-level abstract memory models, they validate common optimizations. On the other hand, this prevents reasoning about much low-level code relying on the behavior of common implementations, where formal verification has many applications. We present the first formal memory model that allows many common optimizations and fully supports operations on the representation of pointers. All arithmetic operations are well-defined for pointers that have been cast to integers. Crucially, our model is also simple to understand and program with. All our results are fully formalized in Coq.","Integer-Pointer Cast, C Memory Model, Optimization, Compiler, Verification",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Doumane A,Baelde D,Hirschi L,Saurin A",Towards Completeness via Proof Search in the Linear Time μ-Calculus: The Case of BüChi Inclusions,,2016,,,377–386,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science,"New York, NY, USA",2016,9781450343916,,https://doi.org/10.1145/2933575.2933598;http://dx.doi.org/10.1145/2933575.2933598,10.1145/2933575.2933598,"Modal μ-calculus is one of the central languages of logic and verification, whose study involves notoriously complex objects: automata over infinite structures on the model-theoretical side; infinite proofs and proofs by (co)induction on the proof-theoretical side. Nevertheless, axiomatizations have been given for both linear and branching time μ-calculi, with quite involved completeness arguments. We come back to this central problem, considering it from a proof search viewpoint, and provide some new completeness arguments in the linear time μ-calculus. Our results only deal with restricted classes of formulas that closely correspond to (non-alternating) ω-automata but, compared to earlier proofs, our completeness arguments are direct and constructive. We first consider a natural circular proof system based on sequent calculus, and show that it is complete for inclusions of parity automata expressed as formulas, making use of Safra's construction directly in proof search. We then consider the corresponding finitary proof system, featuring (co)induction rules, and provide a partial translation result from circular to finitary proofs. This yields completeness of the finitary proof system for inclusions of sufficiently deterministic parity automata, and finally for arbitrary Büchi automata.","parity automata, (co)induction, proof-search, circular proofs, mu-calculus, safra construction, sequent calculus",LICS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Marrella A,Mecella M,Sardina S",Intelligent Process Adaptation in the SmartPM System,ACM Trans. Intell. Syst. Technol.,2016,8,2,,Association for Computing Machinery,"New York, NY, USA",,,,2016-11,,2157-6904,https://doi.org/10.1145/2948071;http://dx.doi.org/10.1145/2948071,10.1145/2948071,"The increasing application of process-oriented approaches in new challenging dynamic domains beyond business computing (e.g., healthcare, emergency management, factories of the future, home automation, etc.) has led to reconsider the level of flexibility and support required to manage complex knowledge-intensive processes in such domains. A knowledge-intensive process is influenced by user decision making and coupled with contextual data and knowledge production, and involves performing complex tasks in the “physical” real world to achieve a common goal. The physical world, however, is not entirely predictable, and knowledge-intensive processes must be robust to unexpected conditions and adaptable to unanticipated exceptions, recognizing that in real-world environments it is not adequate to assume that all possible recovery activities can be predefined for dealing with the exceptions that can ensue. To tackle this issue, in this paper we present SmartPM, a model and a prototype Process Management System featuring a set of techniques providing support for automated adaptation of knowledge-intensive processes at runtime. Such techniques are able to automatically adapt process instances when unanticipated exceptions occur, without explicitly defining policies to recover from exceptions and without the intervention of domain experts at runtime, aiming at reducing error-prone and costly manual ad-hoc changes, and thus at relieving users from complex adaptations tasks. To accomplish this, we make use of well-established techniques and frameworks from Artificial Intelligence, such as situation calculus, IndiGolog and classical planning. The approach, which is backed by a formal model, has been implemented and validated with a case study based on real knowledge-intensive processes coming from an emergency management domain.","indiGolog, knowledge-intensive processes, Classical planning, process modeling and execution, situation calculus, pervasive applications, process adaptation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sun Y,Yoshida S,Narumi T,Hirose M","PaCaPa: A Handheld VR Device for Rendering Size, Shape, and Stiffness of Virtual Objects in Tool-Based Interactions",,2019,,,1–12,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems,"Glasgow, Scotland Uk",2019,9781450359702,,https://doi.org/10.1145/3290605.3300682;http://dx.doi.org/10.1145/3290605.3300682,10.1145/3290605.3300682,"We present PaCaPa, a handheld device that renders haptics on a user's palm when the user interacts with virtual objects using virtual tools such as a stick. PaCaPa is a cuboid device with two wings that open and close. As the user's stick makes contact with a virtual object, the wings open by a specific degree to dynamically change the pressure on the palm and fingers. The open angle of the wings is calculated from the angle between the virtual stick and hand direction. As the stick bites into the target object, a large force is generated. Our device enables three kinds of renderings: size, shape, and stiffness. We conducted user studies to evaluate the performance of our device. We also evaluated our device in two application scenarios. User feedback and qualitative ratings indicated that our device can make indirect interaction with handheld tools more realistic.","tool-based interaction, virtual reality, haptics",CHI '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schwärzler M,Luksch C,Scherzer D,Wimmer M",Fast Percentage Closer Soft Shadows Using Temporal Coherence,,2013,,,79–86,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games,"Orlando, Florida",2013,9781450319560,,https://doi.org/10.1145/2448196.2448209;http://dx.doi.org/10.1145/2448196.2448209,10.1145/2448196.2448209,"We propose a novel way to efficiently calculate soft shadows in real-time applications by overcoming the high computational effort involved with the complex corresponding visibility estimation each frame: We exploit the temporal coherence prevalent in typical scene movement, making the estimation of a new shadow value only necessary whenever regions are newly disoccluded due to camera adjustment, or the shadow situation changes due to object movement. By extending the typical shadow mapping algorithm by an additional light-weight buffer for the tracking of dynamic scene objects, we can robustly and efficiently detect all screen space fragments that need to be updated, including not only the moving objects themselves, but also the soft shadows they cast. By applying this strategy to the popular Percentage Closer Soft Shadow algorithm (PCSS), we double rendering performance in scenes with both static and dynamic objects -- as prevalent in various 3D game levels -- while maintaining the visual quality of the original approach.","temporal coherence, soft shadows, real-time",I3D '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ning X,Li E,Zhang X,Wang Y",Shape Decomposition and Understanding of Point Cloud Objects Based on Perceptual Information,,2010,,,199–206,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry,"Seoul, South Korea",2010,9781450304597,,https://doi.org/10.1145/1900179.1900221;http://dx.doi.org/10.1145/1900179.1900221,10.1145/1900179.1900221,"Decomposition and segmentation of the objects represented by point cloud data become increasingly important for purposes like shape analysis and object recognition. In this paper, we propose a perception based approach to segment point cloud into distinct parts, and the decomposition is made possible of spatially close but geodetically distant parts. Curvature is a critical factor for shape representation, reflecting the convex and concave characteristics of an object, which is obtained by cubic surface fitting in our approach. To determine the number of patches, we calculate and select the critical feature points based on perception information to represent each patch. Taking the critical marker sets as a guide, each marker is spread to a meaningful region by curvature-based decomposition, and also further constraints are provided by the variation of normals. Then a skeleton extraction method is proposed and a label-driven skeleton simplification process is implemented. Further, a semantic graph is constructed according to the decomposed model and the skeletal structure. We illustrate the framework and demonstrate our approach on point cloud data to evaluate its function to decompose object shape based on human perceptions. Meanwhile, the result of decomposition is demonstrated with extracted skeletons. Performance of this algorithm is exhibited with experimental results, which proves its robustness to noise.","point cloud, skeletal point, semantic graph, perceptual information, shape decomposition",VRCAI '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang Z,Feng H,Pan S,Yi M,Lu H",Missing Frame Detection of Surveillance Videos Based on Deep Learning in Forensic Science,,2020,,,298–304,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence,"Tianjin, China",2020,9781450377089,,https://doi.org/10.1145/3404555.3404576;http://dx.doi.org/10.1145/3404555.3404576,10.1145/3404555.3404576,"The identification of road traffic accidents plays an essential role in the litigation process of complicated traffic cases. Speed appraisement is the main part among all kinds of judicial identification in the area of road traffic accident. When evaluating the speed of vehicles, video frame time is an important parameter. The situation of missing frames may cause an imprecision of speed inspection. In this paper, we propose a method to detect missing frames by the movement of objects in video based on deep learning techniques. The method is based on object detection neural network. A derived distance of target object is calculated and applied to detect missing frames. We then confirm the performance of proposed method on dataset consisted of collected surveillance videos. It can find missing frames accurately and rapidly, which effectively reduces calculation errors of vehicle speed and promotes the authenticity of forensic investigation.","deep learning, object detection, Forensic science, surveillance video",ICCAI '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang L,Shi H,Pu J",Object Recognition Based on Improved Zernike Moments and SURF,,2019,,,116–120,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 8th International Conference on Networks, Communication and Computing","Luoyang, China",2019,9781450377027,,https://doi.org/10.1145/3375998.3376042;http://dx.doi.org/10.1145/3375998.3376042,10.1145/3375998.3376042,"Since single global or local features can only describe objects partly or unilaterally that may lead to a low recognition rate, object recognition algorithm based on improved Zernike moments and Speeded-up Robust Features (SURF) is proposed. Firstly, the seven improved Zernike moments and SURF descriptor of objects are extracted, and then the two features are fused together with the weights in term of their contribution to the recognition. Secondly, Euclidean distance is calculated to determine the recognition result. Finally, the performance of algorithm is tested by some image data. Experimental results show that the proposed method is robust to scaling transformation, rotation change and noise variation. Compared with the other three ones, the results show that the proposed method has better recognition performance.","feature fusion, Recognition, SURF, Euclidean distance, improved Zernike moments",ICNCC 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Schuwerk C,Xu X,Chaudhari R,Steinbach E",Compensating the Effect of Communication Delay in Client-Server--Based Shared Haptic Virtual Environments,ACM Trans. Appl. Percept.,2015,13,1,,Association for Computing Machinery,"New York, NY, USA",,,,2015-12,,1544-3558,https://doi.org/10.1145/2835176;http://dx.doi.org/10.1145/2835176,10.1145/2835176,"Shared haptic virtual environments can be realized using a client-server architecture. In this architecture, each client maintains a local copy of the virtual environment (VE). A centralized physics simulation running on a server calculates the object states based on haptic device position information received from the clients. The object states are sent back to the clients to update the local copies of the VE, which are used to render interaction forces displayed to the user through a haptic device. Communication delay leads to delayed object state updates and increased force feedback rendered at the clients. In this article, we analyze the effect of communication delay on the magnitude of the rendered forces at the clients for cooperative multi-user interactions with rigid objects. The analysis reveals guidelines on the tolerable communication delay. If this delay is exceeded, the increased force magnitude becomes haptically perceivable. We propose an adaptive force rendering scheme to compensate for this effect, which dynamically changes the stiffness used in the force rendering at the clients. Our experimental results, including a subjective user study, verify the applicability of the analysis and the proposed scheme to compensate the effect of time-varying communication delay in a multi-user SHVE.","perceived transparency, communication delay, haptic rendering, Shared haptic virtual environment, multi-user, collaboration",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hartmann K,Schlechtweg S,Helbing R,Strothotte T",Knowledge-Supported Graphical Illustration of Texts,,2002,,,300–307,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Working Conference on Advanced Visual Interfaces,"Trento, Italy",2002,9781581135374,,https://doi.org/10.1145/1556262.1556310;http://dx.doi.org/10.1145/1556262.1556310,10.1145/1556262.1556310,"We introduce a new method to automatically and dynamically illustrate arbitrary texts from a predefined application domain. We demonstrate this method with two experimental systems (Text Illustrator and Agi3le) which are designed to illustrate anatomy textbooks.Both systems exploit a symbolic representation of the content of structured geometric models. In addition, the approach taken by the Agi3le-system is based on an ontology providing a formal representation of important concepts within the application domain as well as a thesaurus containing alternative linguistic and visual realizations for entities within the formal domain representation.The presented method is text-driven, i.e., an automated analysis of the morphologic, syntactic and semantic structures of noun phrases reveals the key concepts of a text portion to be illustrated. The specific relevance of entities within the formal representation is determined by a spreading activation approach. This allows to derive important parameters for a non-photorealistic rendering process: the selection of suitable geometric models, camera positions and presentation variables for individual geometric objects. Part-whole relations are considered to assign visual representations to elements of the formal domain representation. Presentation variables for objects in the 3D rendering are chosen to reflect the estimated relevance of their denotation.As a result, expressive non-photorealistic illustrations which are focussed on the key concepts of individually selected text passages are generated automatically. Finally, we present methods to integrate user interaction within both media, the text and the computer-generated illustration, in order to adjust the presentation to individual information seeking goals.","non-photorealistic rendering, image-text coherence, text illustration, text analysis, spreading activation, semantic networks",AVI '02,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhiming C,Jun Y,Yingjie Z,Yong L",Implicit Relationship Deduction in One/More Judgment Templates,,2009,,,322–326,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 International Conference on Hybrid Information Technology,"Daejeon, Korea",2009,9781605586625,,https://doi.org/10.1145/1644993.1645054;http://dx.doi.org/10.1145/1644993.1645054,10.1145/1644993.1645054,"The MAMG distributed selection modeling system supports experts at different sites to judge the solutions with many relationships in the visualized modeling. The implicit relationships in judgment modeling templates are hard to find by directly surveying the templates. The paper deducts the implicit relationship based on the dimensions established by AHP. Firstly, search for all the relationship-chains between any two objects; secondly, calculate the weight ratio of every relationship-chain by means of the weight of every object and every relationship. The detailed searching algorithm and calculation are given and an example with computing process in MAMG is followed. The result indicates any implicit relationship between any two objects in one/more templates can be found out and evaluated.","judgment modeling templates, implicit relationships, distributed modeling",ICHIT '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Křivánek J,Ferwerda JA,Bala K",Effects of Global Illumination Approximations on Material Appearance,ACM Trans. Graph.,2010,29,4,,Association for Computing Machinery,"New York, NY, USA",,,,2010-07,,0730-0301,https://doi.org/10.1145/1778765.1778849;http://dx.doi.org/10.1145/1778765.1778849,10.1145/1778765.1778849,"Rendering applications in design, manufacturing, ecommerce and other fields are used to simulate the appearance of objects and scenes. Fidelity with respect to appearance is often critical, and calculating global illumination (GI) is an important contributor to image fidelity; but it is expensive to compute. GI approximation methods, such as virtual point light (VPL) algorithms, are efficient, but they can induce image artifacts and distortions of object appearance. In this paper we systematically study the perceptual effects on image quality and material appearance of global illumination approximations made by VPL algorithms. In a series of psychophysical experiments we investigate the relationships between rendering parameters, object properties and image fidelity in a VPL renderer. Using the results of these experiments we analyze how VPL counts and energy clamping levels affect the visibility of image artifacts and distortions of material appearance, and show how object geometry and material properties modulate these effects. We find the ranges of these parameters that produce VPL renderings that are visually equivalent to reference renderings. Further we identify classes of shapes and materials that cannot be accurately rendered using VPL methods with limited resources. Using these findings we propose simple heuristics to guide visually equivalent and efficient rendering, and present a method for correcting energy losses in VPL renderings. This work provides a strong perceptual foundation for a popular and efficient class of GI algorithms.","material perception, perception, visual equivalence, virtual point light, global illumination, VPL, instant radiosity",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kammar O,Levy PB,Moss SK,Staton S",A Monad for Full Ground Reference Cells,,2017,,,,IEEE Press,"Reykjavík, Iceland",,Proceedings of the 32nd Annual ACM/IEEE Symposium on Logic in Computer Science,,2017,9781509030187,,,,"We present a denotational account of dynamic allocation of potentially cyclic memory cells using a monad on a functor category. We identify the collection of heaps as an object in a different functor category equipped with a monad for adding hiding/encapsulation capabilities to the heaps. We derive a monad for full ground references supporting effect masking by applying a state monad transformer to the encapsulation monad. To evaluate the monad, we present a denotational semantics for a call-by-value calculus with full ground references, and validate associated code transformations.",,LICS '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Moy Y,Gem #146: Su(per)Btypes in Ada 2012 - Part 1,Ada Lett.,2018,37,2,27–29,Association for Computing Machinery,"New York, NY, USA",,,,2018-06,,1094-3641,https://doi.org/10.1145/3232693.3232699;http://dx.doi.org/10.1145/3232693.3232699,10.1145/3232693.3232699,"Let's get started? Ada 2012 is full of features for specifying a rich set of type properties. In this series of three Gems, we describe three aspects that can be used to state invariant properties of types and subtypes. This first Gem is concerned with the Static_Predicate aspect. Static_Predicate can be specified on scalar types and subtype definitions to state a property that all objects of the subtype must respect at all times. Take for example a type Day representing the days of the week:",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Křivánek J,Ferwerda JA,Bala K",Effects of Global Illumination Approximations on Material Appearance,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2010 Papers,"Los Angeles, California",2010,9781450302104,,https://doi.org/10.1145/1833349.1778849;http://dx.doi.org/10.1145/1833349.1778849,10.1145/1833349.1778849,"Rendering applications in design, manufacturing, ecommerce and other fields are used to simulate the appearance of objects and scenes. Fidelity with respect to appearance is often critical, and calculating global illumination (GI) is an important contributor to image fidelity; but it is expensive to compute. GI approximation methods, such as virtual point light (VPL) algorithms, are efficient, but they can induce image artifacts and distortions of object appearance. In this paper we systematically study the perceptual effects on image quality and material appearance of global illumination approximations made by VPL algorithms. In a series of psychophysical experiments we investigate the relationships between rendering parameters, object properties and image fidelity in a VPL renderer. Using the results of these experiments we analyze how VPL counts and energy clamping levels affect the visibility of image artifacts and distortions of material appearance, and show how object geometry and material properties modulate these effects. We find the ranges of these parameters that produce VPL renderings that are visually equivalent to reference renderings. Further we identify classes of shapes and materials that cannot be accurately rendered using VPL methods with limited resources. Using these findings we propose simple heuristics to guide visually equivalent and efficient rendering, and present a method for correcting energy losses in VPL renderings. This work provides a strong perceptual foundation for a popular and efficient class of GI algorithms.","material perception, instant radiosity, virtual point light, perception, global illumination, VPL, visual equivalence",SIGGRAPH '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"O'Donovan S,Gain J,DeRenzi B",A Comparison of Interactive Shadows and Multi-View Layouts for Mouse-Based 3D Modelling,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Annual Conference of the South African Institute of Computer Scientists and Information Technologists,"Johannesburg, South Africa",2016,9781450348058,,https://doi.org/10.1145/2987491.2987531;http://dx.doi.org/10.1145/2987491.2987531,10.1145/2987491.2987531,"3D user interfaces allow users to view and interact with objects in a 3D scene and form a key component in many modelling applications used in engineering, medicine and design. Most mouse-based interfaces follow the same multi-view layout (three orthogonal, one perspective). This interface is difficult to understand, as it requires users to integrate all four views and build a 3D mental model. An alternative, Interactive Shadows, has been previously proposed that could improve on the multi-view's shortcomings but has never been formally tested.This paper presents the first quantitative user evaluation (n = 36) of both the multi-view and interactive shadows interfaces to compare their relative effectiveness and usability. Participants completed three types of tasks designed to be representative of object manipulation in current 3D modelling software.Interactive shadows were significantly better (p < 0,05) for tasks requiring participants to estimate distance. This suggests interactive shadows interface might better help users approximate relative object positioning.","3D User Interfaces, Direct Manipulation, Interactive Shadows, 3D Widgets, Quantitative User Studies, Human Computer Interaction",SAICSIT '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tibold R,Laczko J",The Effect of Load on Variances of Object Replacing Arm Movements,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th International Symposium on Applied Sciences in Biomedical and Communication Technologies,"Barcelona, Spain",2011,9781450309134,,https://doi.org/10.1145/2093698.2093882;http://dx.doi.org/10.1145/2093698.2093882,10.1145/2093698.2093882,"A three-dimensional (3D) dynamic upper limb model was developed to simulate muscle forces in slightly restricted point-to-point movements. Healthy subjects performed point-to-point movements repetitively with an object held in the hand. The object was either a very light (0.06kg) or a heavier one (2kg). Joint coordinates were recorded. Using joint coordinates, and muscle attachment sites taken from the literature, virtual muscle forces acted during the execution of the movement were calculated for 4 arm muscles. Variances of hand position trajectories, joint configuration trajectories and muscle activities (measured EMG and muscle forces of biceps, triceps, delta anterior and delta posterior) were calculated for both object conditions. There were no significant differences for hand position and arm configuration variances considering the two object conditions while muscle activity variances (for all muscles except deltoid posterior) increased significantly by executing the movement with heavier object. Since high muscle activity variances didn't result equally high increments in kinematic variances we suggest that the stabilization of the outer descriptors (kinematic properties) of the arm is resulted by the enhanced muscle cooperation through synergies when the motor task was performed with heavier object in the hand.","variance, motor apparatus, motion analysis",ISABEL '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Edsberg O,Hetland ML",Indexing Inexact Proximity Search with Distance Regression in Pivot Space,,2010,,,51–58,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third International Conference on SImilarity Search and APplications,"Istanbul, Turkey",2010,9781450304207,,https://doi.org/10.1145/1862344.1862353;http://dx.doi.org/10.1145/1862344.1862353,10.1145/1862344.1862353,"We introduce an inexact indexing scheme where, at index building time, training queries drawn from the database are used to fit one linear regression model for each object to be indexed. The response variable is the distance from the object to the query. The predictor variables are the distances from the query to each of a set of pivot objects. At search time, the models can provide distance estimates or probabilities of inclusion in the correct result, either of which can be used to rank the objects for an inexact search where the true distances are calculated in the resulting order, up to a halting point. To reduce storage requirements, the coefficients can be discretized at the cost of some precision in the promise values. We evaluate our scheme on synthetic and real-world data and compare it to a permutation-based scheme that has been reported to outperform other methods in the same experimental setting. We find that, in several of our experiments, the regression-based distance estimates give better query performance than the permutation-based promise values, in some cases even when the pivot set for the regression-based scheme is reduced in order to make its memory size equal to that of the permutation-based index. Limitations of our scheme include high index building cost and vulnerability to deviation from the model assumptions.",,SISAP '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Monnier S,Inductive Types Deconstructed: The Calculus of United Constructions,,2019,,,52–63,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th ACM SIGPLAN International Workshop on Type-Driven Development,"Berlin, Germany",2019,9781450368155,,https://doi.org/10.1145/3331554.3342607;http://dx.doi.org/10.1145/3331554.3342607,10.1145/3331554.3342607,"Algebraic data types and inductive types like those of the Calculus of Inductive Constructions (CIC) are the bread and butter of statically typed functional programming languages. They conveniently combine in a single package product types, sum types, recursive types, and indexed types. But this also makes them somewhat heavyweight: for example, tuples have to be defined as \degenerate\"" single constructor inductive types",and extraction of a single field becomes a laborious full case-analysis on the object. We consider this to be unsatisfactory. In this article,we develop an alternative presentation of CIC's inductive types where the various elements are provided separately,"such that inductive types are built on top of tuples and sums rather than the other way around. The resulting language is lower-level yet we show it can be translated to to a predicative version of the Calculus of Inductive Constructions in a type-preserving way. An additional benefit is that it can conveniently give a precise type to the default branch of \""case\"" statements.""","compilation, case analysis, union types, Inductive types",TyDe 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shi G,Gan Y,Shang S,Wang S,Dong Y,Yew PC",A Formally Verified Sequentializer for Lustre-like Concurrent Synchronous Data-Flow Programs,,2017,,,109–111,IEEE Press,"Buenos Aires, Argentina",,Proceedings of the 39th International Conference on Software Engineering Companion,,2017,9781538615898,,https://doi.org/10.1109/ICSE-C.2017.83;http://dx.doi.org/10.1109/ICSE-C.2017.83,10.1109/ICSE-C.2017.83,"Synchronous data-flow languages (SDFL), such as Lustre [1], is a concurrent language that has been widely used in safety-critical systems. Verified compilers for such languages are crucial in generating trustworthy object code. A good approach is to first translate a concurrent SDFL program to a sequential intermediate representation, such as a Clight [2] code, and then use an existing verified compiler such as CompCert [3] to produce executable object code for the target machine. A verified Sequentializer is crucial in such a verified compiler. It produces a sequential topological order among the program statements that preserve the program dependencies and the dynamic semantics of the original program. In this paper, we show such an approach for a SDFL language such as Lustre. The approach is general enough to be applicable to other SDFLs as well. It first gives a formal specification of the operational semantics, and proves its determinism property for a Lustre-like program. It then formally proves the equivalence of the original concurrent semantics and its target sequential semantics using the well-established proof assistant Coq ([4], [5]), and extracts the certified code for such a sequentializer by Coq.","semantics, verification, determinism, synchronous data-flow languages, sequentialization, concurrency, verified compiler",ICSE-C '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shi Y,Blackham B,Heiser G",Code Optimizations Using Formally Verified Properties,,2013,,,427–442,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages & Applications,"Indianapolis, Indiana, USA",2013,9781450323741,,https://doi.org/10.1145/2509136.2509513;http://dx.doi.org/10.1145/2509136.2509513,10.1145/2509136.2509513,"Formal program verification offers strong assurance of correctness, backed by the strength of mathematical proof. Constructing these proofs requires humans to identify program invariants, and show that they are always maintained. These invariants are then used to prove that the code adheres to its specification.In this paper, we explore the overlap between formal verification and code optimization. We propose two approaches to reuse the invariants derived in formal proofs and integrate them into compilation. The first applies invariants extracted from the proof, while the second leverages the property of program safety (i.e., the absence of bugs). We reuse this information to improve the performance of generated object code.We evaluated these methods on seL4, a real-world formally-verified microkernel, and obtained improvements in average runtime performance (up to 28%) and in worst-case execution time (up to 25%). In macro-benchmarks, we found the performance of para-virtualized Linux running on the microkernel improved by 6-16%.","optimization, micro-kernel, formal verification",OOPSLA '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Shi Y,Blackham B,Heiser G",Code Optimizations Using Formally Verified Properties,SIGPLAN Not.,2013,48,10,427–442,Association for Computing Machinery,"New York, NY, USA",,,,2013-10,,0362-1340,https://doi.org/10.1145/2544173.2509513;http://dx.doi.org/10.1145/2544173.2509513,10.1145/2544173.2509513,"Formal program verification offers strong assurance of correctness, backed by the strength of mathematical proof. Constructing these proofs requires humans to identify program invariants, and show that they are always maintained. These invariants are then used to prove that the code adheres to its specification.In this paper, we explore the overlap between formal verification and code optimization. We propose two approaches to reuse the invariants derived in formal proofs and integrate them into compilation. The first applies invariants extracted from the proof, while the second leverages the property of program safety (i.e., the absence of bugs). We reuse this information to improve the performance of generated object code.We evaluated these methods on seL4, a real-world formally-verified microkernel, and obtained improvements in average runtime performance (up to 28%) and in worst-case execution time (up to 25%). In macro-benchmarks, we found the performance of para-virtualized Linux running on the microkernel improved by 6-16%.","formal verification, optimization, micro-kernel",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chen S,Ooi BC,Zhang Z",An Adaptive Updating Protocol for Reducing Moving Object Database Workload,Proc. VLDB Endow.,2010,3,1–2,735–746,VLDB Endowment,,,,,2010-09,,2150-8097,https://doi.org/10.14778/1920841.1920935;http://dx.doi.org/10.14778/1920841.1920935,10.14778/1920841.1920935,"In the last decade, spatio-temporal database research focuses on the design of effective and efficient indexing structures in support of location-based queries such as predictive range queries and nearest neighbor queries. While a variety of indexing techniques have been proposed to accelerate the processing of updates and queries, not much attention has been paid to the updating protocol, which is another important factor affecting system performance. In this paper, we propose a generic and adaptive updating protocol for moving object databases with less number of updating messages between the objects and database server, thereby reducing the overall workload of the system. In contrast to the approach adopted by most conventional moving object database systems where the exact locations and velocities last disclosed are used to predict their motions, we propose the concept of Spatio-Temporal Safe Region to approximate possible future locations. Spatio-temporal safe regions provide larger space of tolerance for moving objects, freeing them from location and velocity updates as long as the errors remain predictable in the database. To answer predictive queries accurately, the server is allowed to probe the latest status of some moving objects when their safe regions are inadequate in returning the exact query results. Spatio-temporal safe regions are calculated and optimized by the database server with two contradictory objectives: reducing update workload while guaranteeing query accuracy and efficiency. To achieve this, we propose a cost model that estimates the composition of active and passive updates based on historical motion records and query distribution. We have conducted extensive experiments to evaluate our proposal on a variety of popular indexing structures. The results confirm the viability, robustness, accuracy and efficiency of our proposed protocol.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Coquand T,A Survey of Constructive Presheaf Models of Univalence,ACM SIGLOG News,2018,5,3,54–65,Association for Computing Machinery,"New York, NY, USA",,,,2018-07,,,https://doi.org/10.1145/3242953.3242962;http://dx.doi.org/10.1145/3242953.3242962,10.1145/3242953.3242962,"Any formal system for representing mathematics should address the two questions of how to represent collections of mathematical objects and how to decide the laws of identifications of these objects. These laws of identifications have become quite subtle. While it has been clear for a long time that it is good mathematical practice to identify isomorphic algebraic structures [11], or at least to use only notions and facts about algebraic structures that are invariant under isomorphisms, category theory extends this to the notion of categorical equivalences1, which themselves have been generalized to higher forms of equivalences [25]. Voevodsky noticed that, by extending some versions of dependent type theory with one further axiom - the univalence axiom - one obtains a formal system in which all notions and operations are automatically invariant under isomorphisms and even under higher notions of equivalence.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Phan D,Na IS,Kim SH",Local Features and Histogram Based Planar Object Recognition,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on Ubiquitous Information Management and Communication,"Siem Reap, Cambodia",2014,9781450326445,,https://doi.org/10.1145/2557977.2558075;http://dx.doi.org/10.1145/2557977.2558075,10.1145/2557977.2558075,"In this paper, we propose an approach for planar object recognition using binary local invariant feature and local histogram features, in scene image. First, the object is detected based on a homography which represents transformation of object in scene image from reference image, estimated from matching pairs of keypoints between two images. Then, local intensity histograms are computed from blocks inside scene object. In order to locate these blocks, a reference object is divided into many blocks then the corresponding blocks of the scene object are located based on the homography with assumption that object is a plane. To make the feature invariant to the illumination, the local histogram is computed from only intensity component (V) of HSV color of image. Similarity of two images is calculated from the similarity of their local histogram features and the matching ratio. The recognized object is the most similar reference object in data set. For evaluation, we experiment our method with a planar dataset from Stanford University which includes book cover, cd cover, painting, business card, etc. According to the result, our proposed method gets the higher accuracy compare to some other methods while remaining significant processing for an online application.","ORB binary local invariant feature, descriptor, planar object recognition, homography, local histogram, detector, histogram corellation",ICUIMC '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Downen P,Maurer L,Ariola ZM,Peyton Jones S",Sequent Calculus as a Compiler Intermediate Language,,2016,,,74–88,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming,"Nara, Japan",2016,9781450342193,,https://doi.org/10.1145/2951913.2951931;http://dx.doi.org/10.1145/2951913.2951931,10.1145/2951913.2951931,"The λ-calculus is popular as an intermediate language for practical compilers. But in the world of logic it has a lesser-known twin, born at the same time, called the sequent calculus. Perhaps that would make for a good intermediate language, too? To explore this question we designed Sequent Core, a practically-oriented core calculus based on the sequent calculus, and used it to re-implement a substantial chunk of the Glasgow Haskell Compiler.","Intermediate representations, Sequent calculus, Compiler optimizations, Haskell, Continuations, Natural deduction",ICFP 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Downen P,Maurer L,Ariola ZM,Peyton Jones S",Sequent Calculus as a Compiler Intermediate Language,SIGPLAN Not.,2016,51,9,74–88,Association for Computing Machinery,"New York, NY, USA",,,,2016-09,,0362-1340,https://doi.org/10.1145/3022670.2951931;http://dx.doi.org/10.1145/3022670.2951931,10.1145/3022670.2951931,"The λ-calculus is popular as an intermediate language for practical compilers. But in the world of logic it has a lesser-known twin, born at the same time, called the sequent calculus. Perhaps that would make for a good intermediate language, too? To explore this question we designed Sequent Core, a practically-oriented core calculus based on the sequent calculus, and used it to re-implement a substantial chunk of the Glasgow Haskell Compiler.","Natural deduction, Sequent calculus, Compiler optimizations, Continuations, Intermediate representations, Haskell",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Chaudhuri K,A Two-Level Logic Perspective on (Simultaneous) Substitutions,,2018,,,280–292,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th ACM SIGPLAN International Conference on Certified Programs and Proofs,"Los Angeles, CA, USA",2018,9781450355865,,https://doi.org/10.1145/3167093;http://dx.doi.org/10.1145/3167093,10.1145/3167093,"Lambda-tree syntax (λTS), also known as higher-order abstract syntax (HOAS), is a representational technique where the pure λ-calculus in a meta-language is used to represent binding constructs in an object language. A key feature of λTS is that capture-avoiding substitution in the object language is represented by β-reduction in the meta language. However, to reason about the meta-theory of (simultaneous) substitutions, it may seem that λTS gets in the way: not only does iterated β-reduction not capture simultaneity, but also β-redexes are not first-class constructs. This paper proposes a representation of (simultaneous) substitutions in the two-level logic approach (2LLA), where properties of a specification language are established in a strong reasoning meta-logic that supports inductive reasoning. A substitution, which is a partial map from variables to terms, is represented in a form similar to typing contexts, which are partial maps from variables to types; both are first-class in 2LLA. The standard typing rules for substitutions are then just a kind of context relation that are already well-known in 2LLA. This representation neither changes the reasoning kernel, nor requires any modification of existing type systems, and does not sacrifice any expressivity.","Meta-theory, two-level logic approach, Lambda Prolog, substitution, lambda calculus, Abella",CPP 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chow KH,Liu L",Robust Object Detection Fusion Against Deception,,2021,,,2703–2713,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining,"Virtual Event, Singapore",2021,9781450383325,,https://doi.org/10.1145/3447548.3467121;http://dx.doi.org/10.1145/3447548.3467121,10.1145/3447548.3467121,"Deep neural network (DNN) based object detection has become an integral part of numerous cyber-physical systems, perceiving physical environments and responding proactively to real-time events. Recent studies reveal that well-trained multi-task learners like DNN-based object detectors perform poorly in the presence of deception. This paper presents FUSE, a deception-resilient detection fusion approach with three novel contributions. First, we develop diversity-enhanced fusion teaming mechanisms, including diversity-enhanced joint training algorithms, for producing high diversity fusion detectors. Second, we introduce a three-tier detection fusion framework and a graph partitioning algorithm to construct fusion-verified detection outputs through three mutually reinforcing components: objectness fusion, bounding box fusion, and classification fusion. Third but not least, we provide a formal analysis of robustness enhancement by FUSE-protected systems. Extensive experiments are conducted on eleven detectors from three families of detection algorithms on two benchmark datasets. We show that FUSE guarantees strong robustness in mitigating the state-of-the-art deception attacks, including adversarial patches - a form of physical attacks using confined visual distortion.","ensemble defense, object detection, adversarial machine learning",KDD '21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Koide S,Takeda H",Meta-Circularity and MOP in Common Lisp for OWL Full,,2009,,,28–34,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th European Lisp Workshop,"Genova, Italy",2009,9781605585390,,https://doi.org/10.1145/1562868.1562872;http://dx.doi.org/10.1145/1562868.1562872,10.1145/1562868.1562872,"We have developed an OWL (Web Ontology Language) Full language processor, SWCLOS, for processing semantic web pages on top of the Common Lisp Object System (CLOS). To implement the OWL Full level of capability, we leveraged the dynamic and reflective features of CLOS. The metamodeling capability of CLOS is utilized to realize the metamodeling capability of Resource Description Framework (RDF) and OWL Full. The native computational model of CLOS is changed into the model of RDF and OWL by using the Meta-Object Protocol (MOP) in CLOS. Although the metamodeling specifications in CLOS are firmly established in the Common Lisp community, the semantics is not yet fully developed, since Common Lisp does not have formal semantics. In this paper, we focus on metamodeling in CLOS. We point out that the architecture of CLOS in the metamodeling is the same as in RDF and clarify the denotational semantics of CLOS in comparison with the RDF semantics.","RDF, semantic web, MOP, denotational semantics, metacircularity, OWL full, membership circularity, RDFS, metamodeling, meta-programming, CLOS, extensional semantics, OWL",ELW '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Eklund P,Wray T,Ducrou J",Web Services and Digital Ecosystem Support Using Formal Concept Analysis,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Management of Emergent Digital EcoSystems,France,2009,9781605588292,,https://doi.org/10.1145/1643823.1643868;http://dx.doi.org/10.1145/1643823.1643868,10.1145/1643823.1643868,"This paper describes a Web Services (WS) and distributed systems architecture for Formal Concept Analysis that supports information and content management in a social media system. As well as social tagging, the system includes novel approaches to document browsing and heterogeneous Web information retrieval. The Formal Concept Analysis WS architecture supports a system called the Virtual Museum of the Pacific, a content and knowledge acquisition tool that permits the machine synthesis of formal concepts and provides a Rich Internet Application in which to display and navigate them. The interface also allows the extensible association of digital objects via introducing new attributes and relationships. The WS architecture and user interface form the basis for a novel distributed content management and social media application and is to our knowledge the first implementation of Formal Concept Analysis as WS.",,MEDES '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shin SH,Lee SC,Kim SW,Lee J,Im EG",Efficient Shortest Path Finding of K-Nearest Neighbor Objects in Road Network Databases,,2010,,,1661–1665,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Symposium on Applied Computing,"Sierre, Switzerland",2010,9781605586397,,https://doi.org/10.1145/1774088.1774446;http://dx.doi.org/10.1145/1774088.1774446,10.1145/1774088.1774446,"This paper addresses an efficient path finding scheme that complements classic k-NN (Nearest Neighbor) queries for the road network. Aiming at finding both k objects and the shortest paths to them at the same time, this paper first selects candidate objects by the k-NN search scheme based on the underlying index structure and then finds the path to each of them by the modified A* algorithm. The path finding step stores the intermediary paths from the query point to all of the scanned nodes and then attempts to match the common segment with a path to a new node, instead of repeatedly running the A* algorithm for all k points. Additionally, the cost to the each object calculated in this step makes it possible to finalize the k objects from the candidate set as well as to order them by the path cost. Judging from the result, the proposed scheme can eliminate redundant node scans and provide one of the most fundamental building blocks for location-based services in the real-life road network.","road network, k-nearest neighbor query, shortest path",SAC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cordeil M,Cunningham A,Dwyer T,Thomas BH,Marriott K",ImAxes: Immersive Axes as Embodied Affordances for Interactive Multivariate Data Visualisation,,2017,,,71–83,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th Annual ACM Symposium on User Interface Software and Technology,"Québec City, QC, Canada",2017,9781450349819,,https://doi.org/10.1145/3126594.3126613;http://dx.doi.org/10.1145/3126594.3126613,10.1145/3126594.3126613,"We introduce ImAxes immersive system for exploring multivariate data using fluid, modeless interaction. The basic interface element is an embodied data axis. The user can manipulate these axes like physical objects in the immersive environment and combine them into sophisticated visualisations. The type of visualisation that appears depends on the proximity and relative orientation of the axes with respect to one another, which we describe with a formal grammar. This straight-forward composability leads to a number of emergent visualisations and interactions, which we review, and then demonstrate with a detailed multivariate data analysis use case.","immersion, immersive visualization, immersive analytics, information visualization, virtual reality, multidimensional data visualization",UIST '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Khouri S,Bellatreche L,Berkani N",MODETL: A Complete MODeling and ETL Method for Designing Data Warehouses from Semantic Databases,,2012,,,113,Computer Society of India,"Mumbai, Maharashtra, IND",,Proceedings of the 18th International Conference on Management of Data,"Pune, India",2012,,,,,"In last decades, Semantic DataBases (SDB) have emerged and the major DBMS editors provide semantic support in their products. This is mainly due to the spectacular development of ontologies in several important domains like E-commerce, Engineering, Medicine, etc. Note that ontologies can be seen as a natural continuity of conceptual models. Contrary to traditional databases, where their instances are stored in a relational layout, SDB store ontological data according to one of three main storage layouts (horizontal, vertical, binary). Actually, SDB are serious candidates for business intelligence applications built around the Data Warehouse (DW) technology. The important steps of the life-cycle warehouse design (user requirement analysis, conceptual design, logical design, ETL process, physical design) are usually managed in isolation way. This treatment is mainly due to the complexity of each phase. Actually, DW technology is quite mature for traditional data sources. As a consequence, leveraging its steps to deal with SDB becomes a necessity. In this paper, we propose a method that covers the most important steps of life-cycle of semantic DW. To fitful our needs, four main objectives have been defined:O1: leveraging the integration framework by considering ontologies: a DW can be seen as a materialized data integration system, where data are viewed in a multidimensional way. Data integration systems are formally defined by a triple: , where G is the global schema, S is a set of local schemas that describes the structure of each source participating in the integration process, and M is a set of assertions relating elements of the global schema G with elements of local schemas S. We defined an integration framework adapted to SDB specificities, where schema G is represented by a domain ontology, the set of sources S considered are SDB, and M represents the set of mapping assertions. A mathematical formalization of ontologies, SDB and semantic DW is given, based on the description logic formalism.O2: User requirements have to be expressed at the ontological level: the requirements model we proposed follows the goal oriented paradigm. After analyzing the major studies related to this paradigm, we proposed a goal model viewed as a pivot model, since it combines three widespread goal-oriented approaches: KAOS, Tropos and iStar. The goal model is then connected to the ontology meta-model in order to specify requirements at the ontological level. Requirements analysis allows the designer to construct the dictionary identifying the set of relevant concepts and properties used by the target application. The conceptual, logical and then physical model are defined based on that dictionary. The availability of the ontology allows exploiting its reasoning capabilities to correct the inconsistencies of the conceptual model, and to infer new facts.O3: The ETL process has to be defined at the ontological level and not at physical or conceptual levels: different ETL works proposed in the literature consider logical schemas of sources as inputs of the DW system, and make an implicit assumption that the DW model will be deployed using the same representation (usually using a relational representation). The third objective of our method ensures the definition of the ETL process at the ontological level independently of any implementation constraint. We defined a generic ETL algorithm, based on ten generic operators defined in the literature, that aims at populating the target DW schema, by data from SDB.O4: the deployment process needs to consider the different storage layouts of semantic DW: different deployment solutions are proposed and implemented using data access object design patterns. A prototype validating our proposal using the Lehigh University Benchmark ontology and Oracle SDB has been developed.","data warehouse design, ontology, ETL process, semantic databases",COMAD '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bagheri Hariri B,Calvanese D,De Giacomo G,Deutsch A,Montali M",Verification of Relational Data-Centric Dynamic Systems with External Services,,2013,,,163–174,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 32nd ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,"New York, New York, USA",2013,9781450320665,,https://doi.org/10.1145/2463664.2465221;http://dx.doi.org/10.1145/2463664.2465221,10.1145/2463664.2465221,"Data-centric dynamic systems are systems where both the process controlling the dynamics and the manipulation of data are equally central. We study verification of (first-order) mu-calculus variants over relational data-centric dynamic systems, where data are maintained in a relational database, and the process is described in terms of atomic actions that evolve the database. Action execution may involve calls to external services, thus inserting fresh data into the system. As a result such systems are infinite-state. We show that verification is undecidable in general, and we isolate notable cases where decidability is achieved. Specifically we start by considering service calls that return values deterministically (depending only on passed parameters). We show that in a mu-calculus variant that preserves knowledge of objects appeared along a run we get decidability under the assumption that the fresh data introduced along a run are bounded, though they might not be bounded in the overall system. In fact we tie such a result to a notion related to weak acyclicity studied in data exchange. Then, we move to nondeterministic services and we investigate decidability under the assumption that knowledge of objects is preserved only if they are continuously present. We show that if infinitely many values occur in a run but do not accumulate in the same state, then we get again decidability. We give syntactic conditions to avoid this accumulation through the novel notion of \generate-recall acyclicity\""","which ensures that every service call activation generates new values that cannot be accumulated indefinitely.""","decidable verification, business artifacts, data-centric business processes, mu-calculus",PODS '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Harjoko A,Candradewi I,Bakhtiar AA","Intelligent Traffic Monitoring Systems: Vehicles Detection, Tracking, And Counting Using Haar Cascade Classifier And Optical Flow",,2017,,,49–55,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Video and Image Processing,"Singapore, Singapore",2017,9781450353830,,https://doi.org/10.1145/3177404.3177441;http://dx.doi.org/10.1145/3177404.3177441,10.1145/3177404.3177441,"In the automation of traffic monitoring system based on video processing, vehicle detection and tracking is an important rule because it is used for further analysis such as calculating traffic flow. This research aims to implement video processing techniques to detect and track vehicle objects. Detection and tracking stage is done to calculate the number of vehicle objects using video senSor. We use Haar Cascade Classifier method for vehicle detection and Optical Flow method for tracking vehicle in Indonesian highway and for vehicle counting process. We use detection region to localize the detection process, tracking and counting the number of vehicles so all process will be done on this region. In the tracking vehicles stage is utilized by centroid from Haar Cascade Classifier detection results. We compare the area in every vehicle detection result from previous frame and current frame with certain threshold value of area to make sure a vehicle is the same object in each frame. So that, in the detection region vehicle will not be repeatedly calculated in the vehicle counting stage. Based on implementation detection test and tracking test result we obtained quite high accuracy.","Optical Flow, Haar Cascade Classifier, Tracking, Vehicles Detection",ICVIP 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Censor-Hillel K,Petrank E,Timnat S",Help!,,2015,,,241–250,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 ACM Symposium on Principles of Distributed Computing,"Donostia-San Sebastián, Spain",2015,9781450336178,,https://doi.org/10.1145/2767386.2767415;http://dx.doi.org/10.1145/2767386.2767415,10.1145/2767386.2767415,"A fundamental challenge in designing concurrent data structures is obtaining efficient wait-free implementations, in which each operation completes regardless of the behavior of other operations in the system. The most common paradigm for guaranteeing wait-freedom is to employ a helping mechanism, in which, intuitively, fast processes help slow processes complete their operations. Curiously, despite its abundant use, to date, helping has not been formally defined nor was its necessity rigorously studied. In this paper we initiate a rigorous study of the interaction between wait-freedom and helping. We start with presenting a formal definition of help, capturing the intuition of one thread helping another to make progress. Next, we present families of object types for which help is necessary in order to obtain wait-freedom. In other words, we prove that for some types there are no linearizable wait-free help-free implementations. In contrast, we show that other, simple types, can be implemented in a linearizable wait-free manner without employing help. Finally, we provide a universal strong primitive for implementing wait-free data structures without using help. Specifically, given a wait-free help-free fetch&cons object, one can implement any type in a wait-free help-free manner.","parallel algorithms, wait-freedom, progress guarantees, concurrent data structures, help",PODC '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Dai J,Lu CT",CLAM: Concurrent Location Management for Moving Objects,,2007,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th Annual ACM International Symposium on Advances in Geographic Information Systems,"Seattle, Washington",2007,9781595939142,,https://doi.org/10.1145/1341012.1341061;http://dx.doi.org/10.1145/1341012.1341061,10.1145/1341012.1341061,"Recently, with the broad usage of location-aware devices, applications with moving object management become very popular. In order to manage moving objects efficiently, many spatial/spatial-temporal data access methods have been proposed. However, most of these data access methods are designed for single-user environments. In multiple-user systems, frequent updates may cause a significant number of read-write conflicts using these data access methods. In this paper, we propose an efficient framework, Concurrent LocAtion Management (CLAM), for managing moving objects in multiple-user environments. The proposed concurrency control protocol integrates the efficiency of the link-based approach and the flexibility of the lock-coupling mechanism. Based on this protocol, concurrent location update and search algorithms are provided. We formally analyze and prove the correctness of the proposed concurrent operations. Experiment results on real datasets validate the efficiency and scalability of the proposed concurrent location management framework.","space filling curve, b-tree, spatial database, concurrency control",GIS '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bhowmick S,Kalita P,Sorathia K",A Gesture Elicitation Study for Selection of Nail Size Objects in a Dense and Occluded Dense HMD-VR,,2020,,,12–23,Association for Computing Machinery,"New York, NY, USA",,IndiaHCI '20: Proceedings of the 11th Indian Conference on Human-Computer Interaction,"Online, India",2020,9781450389440,,https://doi.org/10.1145/3429290.3429292;http://dx.doi.org/10.1145/3429290.3429292,10.1145/3429290.3429292,"Object selection is a fundamental and primary task in any Virtual Environment (VE). However, object selection in dense VEs presents challenges of inaccurate selection, higher error rates and increased task completion times. The challenges are further amplified when target objects are small as nail size, occluded and located at different distances from users. In this paper, we present a two-stage elicitation study for object selection in 4 dense VEs (2x2 selection conditions: the selection of near vs distant objects; with or without occlusion) in a Head-Mounted Display (HMD) based Virtual Reality (VR) platform. In study 1, we identified the most natural and intuitive gestures through a user-generated gesture study. In total, 737 gestures and 23, 29, 26 and 36 unique gestures were collected from 40 participants for mentioned VEs. We calculated an overall score to elucidate further a total of 3, 2, 3 and 3 gestures. In study 2, a new group of 33 participants rated these gestures on ease of performance, gesture appropriateness, body-part suitability and ranked them for user preferences and effort. Finally, we elucidate them to present one gesture each for each VE based on the results obtained from the study 2. We present and discuss the findings of preferences of upper body gestures, a strong emphasis on the confirmation, bringing targets within hands reach and non-occluded, accuracy over effort, scale manipulation of the VE and influence and adoption of WIMP and touch interfaces.A total of 40 non-paid participants (27 males, 13 females) from the age group of 18-35 (Mean= 25.42, SD= 4.07) were chosen for the study. The participants were university students. As Plaumann et al. [32] showed a strong influence of handedness, we recruited only right-handed participants for the study. All participants had prior experience in using HMD-VR platforms (e.g. Oculus Rift and/or HTC Vive). Their experiences included a minimum of 10 hours of playing games or watching movies or combined in the last six months. They were also familiar with gestural interfaces due to prior experience in using a Nintendo Wii remote or Microsoft Kinect for at least 10 hours in the last six months.","Occluded objects, Gesture elicitation study, Virtual environment, Virtual reality, Head-mounted display, Nail size virtual objects, Object selection, Dense environment",IndiaHCI 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Leelasawassuk T,Mayol-Cuevas WW",3D from Looking: Using Wearable Gaze Tracking for Hands-Free and Feedback-Free Object Modelling,,2013,,,105–112,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 International Symposium on Wearable Computers,"Zurich, Switzerland",2013,9781450321273,,https://doi.org/10.1145/2493988.2494327;http://dx.doi.org/10.1145/2493988.2494327,10.1145/2493988.2494327,"This paper presents a method for estimating the 3D shape of an object being observed using wearable gaze tracking. Starting from a sparse environment map generated by a simultaneous localization and mapping algorithm (SLAM), we use the gaze direction positioned in 3D to extract the model of the object under observation. By letting the user look at the object of interest, and without any feedback, the method determines 3D point-of-regards by back-projecting the user's gaze rays into the map. The 3D point-of-regards are then used as seed points for segmenting the object from captured images and the calculated silhouettes are used to estimate the 3D shape of the object. We explore methods to remove outlier gaze points that result from the user saccading to non object points and methods for reducing the error in the shape estimation. Being able to exploit gaze information in this way, enables the user of wearable gaze trackers to be able to do things as complex as object modelling in a hands-free and even feedback-free manner.","experimentation, algorithms",ISWC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"An K,Kuroda T,Gokhale A,Tambe S,Sorbini A",Model-Driven Generative Framework for Automated OMG DDS Performance Testing in the Cloud,,2013,,,179–182,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Conference on Generative Programming: Concepts & Experiences,"Indianapolis, Indiana, USA",2013,9781450323734,,https://doi.org/10.1145/2517208.2517216;http://dx.doi.org/10.1145/2517208.2517216,10.1145/2517208.2517216,"The Object Management Group's (OMG) Data Distribution Service (DDS) provides many configurable policies which determine end-to-end quality of service (QoS) of applications. It is challenging to predict the system's performance in terms of latencies, throughput, and resource usage because diverse combinations of QoS configurations influence QoS of applications in different ways. To overcome this problem, design-time formal methods have been applied with mixed success, but lack of sufficient accuracy in prediction, tool support, and understanding of formalism has prevented wider adoption of the formal techniques. A promising approach to address this challenge is to emulate system behavior and gather data on the QoS parameters of interest by experimentation. To realize this approach, which is preferred over formal methods due to their limitations in accurately predicting QoS, we have developed a model-based automatic performance testing framework with generative capabilities to reduce manual efforts in generating a large number of relevant QoS configurations that can be deployed and tested on a cloud platform. This paper describes our initial efforts in developing and using this technology.","model-driven engineering, publish/subscribe, performance testing, generative programming",GPCE '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"An K,Kuroda T,Gokhale A,Tambe S,Sorbini A",Model-Driven Generative Framework for Automated OMG DDS Performance Testing in the Cloud,SIGPLAN Not.,2013,49,3,179–182,Association for Computing Machinery,"New York, NY, USA",,,,2013-10,,0362-1340,https://doi.org/10.1145/2637365.2517216;http://dx.doi.org/10.1145/2637365.2517216,10.1145/2637365.2517216,"The Object Management Group's (OMG) Data Distribution Service (DDS) provides many configurable policies which determine end-to-end quality of service (QoS) of applications. It is challenging to predict the system's performance in terms of latencies, throughput, and resource usage because diverse combinations of QoS configurations influence QoS of applications in different ways. To overcome this problem, design-time formal methods have been applied with mixed success, but lack of sufficient accuracy in prediction, tool support, and understanding of formalism has prevented wider adoption of the formal techniques. A promising approach to address this challenge is to emulate system behavior and gather data on the QoS parameters of interest by experimentation. To realize this approach, which is preferred over formal methods due to their limitations in accurately predicting QoS, we have developed a model-based automatic performance testing framework with generative capabilities to reduce manual efforts in generating a large number of relevant QoS configurations that can be deployed and tested on a cloud platform. This paper describes our initial efforts in developing and using this technology.","performance testing, model-driven engineering, generative programming, publish/subscribe",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Park J,Rival X,Ryu S","Revisiting Recency Abstraction for JavaScript: Towards an Intuitive, Compositional, and Efficient Heap Abstraction",,2017,,,1–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th ACM SIGPLAN International Workshop on State Of the Art in Program Analysis,"Barcelona, Spain",2017,9781450350723,,https://doi.org/10.1145/3088515.3088516;http://dx.doi.org/10.1145/3088515.3088516,10.1145/3088515.3088516,"JavaScript is one of the most widely used programming languages. To understand the behaviors of JavaScript programs and to detect possible errors in them, researchers have developed several static analyzers based on the abstract interpretation framework. However, JavaScript provides various language features that are difficult to analyze statically and precisely such as dynamic addition and removal of object properties, first-class property names, and higher-order functions. To alleviate the problem, JavaScript static analyzers often use recency abstraction, which refines address abstraction by distinguishing recent objects from summaries of old objects. We observed that while recency abstraction enables more precise analysis results by allowing strong updates on recent objects, it is not monotone in the sense that it does not preserve the precision relationship between the underlying address abstraction techniques: for an address abstraction A and a more precise abstraction B, recency abstraction on B may not be more precise than recency abstraction on A. Such an unintuitive semantics of recency abstraction makes its composition with various analysis sensitivity techniques also unintuitive. In this paper, we propose a new singleton abstraction technique, which distinguishes singleton objects to allow strong updates on them without changing a given address abstraction. We formally define recency and singleton abstractions, and explain the unintuitive behaviors of recency abstraction. Our preliminary experiments show promising results for singleton abstraction.","address partition, recency abstraction, Address abstraction",SOAP 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xu C,Hou J",Formal Description Approach for Agent-Based Mobile Computing,,2020,,,222–229,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Artificial Intelligence and Advanced Manufacture,"Manchester, United Kingdom",2020,9781450375535,,https://doi.org/10.1145/3421766.3421822;http://dx.doi.org/10.1145/3421766.3421822,10.1145/3421766.3421822,"Aiming at the problems of architecture design and semantic feature verification during the construction of mobile cloud computing system, a formal semantic description model for agent-based mobile cloud computing system was proposed on the basis of typed category theory. Agent was depicted as the object node in category theory, and the interaction and dependency between agents are used as morphisms. The whole cloud service system is described as a typed category diagram. On this basis, agent interaction and cooperation, and architecture design and refinement, as well as agent migration and agent substitutability and application request satisfiability, were all analyzed and discussed. Application research shows that the formal description approach enhances the semantic description ability of the system architecture, and helps to analyze and verify the specifications of mobile cloud service system.","semantic verification, Formal description, category theory, mobile computing",AIAM2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li S,Zhang X,Hong W",A New Method for Knowledge Discovery of Complex Data Based on Structural Partial-Ordered Theory,,2019,,,46–55,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence","Shanghai, China",2019,9781450372985,,https://doi.org/10.1145/3366194.3366203;http://dx.doi.org/10.1145/3366194.3366203,10.1145/3366194.3366203,"In order to develop a new knowledge discovery method with higher generalization ability, this paper proposes the generalized model of partial-ordered structure diagrams. This model is based on two philosophical methodologies: the concept driven methodology and the data driven methodology. In essence, the concept driven methodology is top-down principle, that is, the attributes representing object universality are put at the top of the structural partial-ordered diagram. While the data driven methodology is bottom-up principle in which the attributes representing object specificity are put at the top of the diagram. The method is described by the mathematical partial order theory and formal concept analysis theory. Finally, three concrete data sets are used as examples to generate diagrams. The generated diagrams can clearly reveal the knowledge implied in the complex data. It is proven that the proposed generation theory and the model constructed with partial-ordered diagrams have a good ability of generalization, and they are original methods which can be used in different domains for knowledge discovery.","Partial-ordered structure principle, Attribute partial-ordered, Knowledge discovery, Complex dataset",RICAI 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Palanque P,Ladry JF,Barboni E,Navarre D,Winckler M",Une Approche Formelle Pour i'evaluation de La ToléRance Aux Interruptions Des SystèMe Interactifs,,2009,,,141–150,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st International Conference on Association Francophone d'Interaction Homme-Machine,"Grenoble, France",2009,9781605584614,,https://doi.org/10.1145/1629826.1629848;http://dx.doi.org/10.1145/1629826.1629848,10.1145/1629826.1629848,"This paper presents an approach for investigating potential disruptive effects of interruptions on task performance in a multitasking environment. The approach combines previous work in the field of interruption analysis, formal description techniques for interactive systems and stochastic processes to support performance analysis of user tasks constrained by the occurrence of interruptions in the working environment. The approach uses formal description techniques to provide a comprehensive description of user tasks, system and interruption behaviour. The detailed mechanism by which systems and interruptions behave is presented using a Petri nets-based formal description technique called Interactive Cooperative Objects (ICO). The use of a formal modeling technique for the description of these three components makes it possible to compare, analyze and integrate them. In particular, it allows us to determine which of the system states are actually affected by the occurrence of interruptions. The approach is exemplified by a case study that implements two interaction techniques for manipulating icons in a desktop environment.","formal description techniques, performance evaluation, interruptions, model-based approaches",IHM '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Schneider M,Chen T,Viswanathan G,Yuan W",Cardinal Directions between Complex Regions,ACM Trans. Database Syst.,2012,37,2,,Association for Computing Machinery,"New York, NY, USA",,,,2012-06,,0362-5915,https://doi.org/10.1145/2188349.2188350;http://dx.doi.org/10.1145/2188349.2188350,10.1145/2188349.2188350,"Besides topological relationships and approximate relationships, cardinal directions like north and southwest have turned out to be an important class of qualitative spatial relationships. They are of interdisciplinary interest in fields like cognitive science, robotics, artificial intelligence, and qualitative spatial reasoning. In spatial databases and Geographic Information Systems (GIS) they are frequently used as join and selection criteria in spatial queries. However, the available computational models of cardinal directions suffer a number of problems like the use of too coarse approximations of the two spatial operand objects in terms of single representative points or minimum bounding rectangles, the lacking property of converseness of the cardinal directions computed, and the limited applicability to simple instead of complex regions only. This article proposes and formally defines a novel two-phase model, called the Objects Interaction Matrix (OIM) model, that solves these problems, and determines cardinal directions for even complex regions. The model consists of a tiling phase and an interpretation phase. In the tiling phase, a tiling strategy first determines the zones belonging to the nine cardinal directions of each individual region object and then intersects them. The result leads to a bounded grid called objects interaction grid. For each grid cell the information about the region objects that intersect it is stored in an objects interaction matrix. In the subsequent interpretation phase, a well-defined interpretation method is applied to such a matrix and determines the cardinal direction. Spatial example queries illustrate our new cardinal direction concept that is embedded in a spatial extension of SQL and provides user-defined cardinal direction predicates.","directional relationship, Cardinal direction, spatial database",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Letessier P,Buisson O,Joly A",Scalable Mining of Small Visual Objects,,2012,,,599–608,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th ACM International Conference on Multimedia,"Nara, Japan",2012,9781450310895,,https://doi.org/10.1145/2393347.2393431;http://dx.doi.org/10.1145/2393347.2393431,10.1145/2393347.2393431,"This paper presents a scalable method for automatically discovering frequent visual objects in large multimedia collections even if their size is very small. It first formally revisits the problem of mining or discovering such objects, and then generalizes two kinds of existing methods for probing candidate object seeds: weighted adaptive sampling and hashing-based methods. The idea is that the collision frequencies obtained with hashing-based methods can actually be converted into a prior probability density function given as input to a weighted adaptive sampling algorithm. This allows for an evaluation of any hashing scheme effectiveness in a more generalized way, and a comparison with other priors, e.g. guided by visual saliency concerns. We then introduce a new hashing strategy, working first at the visual level, and then at the geometric level. This strategy allows us to integrate weak geometric constraints into the hashing phase itself and not only neighborhood constraints as in previous works. Experiments conducted on a new dataset introduced in this paper will show that using this new hashing-based prior allows a drastic reduction of the number of tentative probes required to discover small objects instantiated several times in a large dataset.","LSH, discovery, mining, computer vision, RMMH, weak geometry, scalable, small objects, hashing",MM '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wagner L,Gacek A",Automating Certification Objectives with SpeAR,Ada Lett.,2020,39,1,35–49,Association for Computing Machinery,"New York, NY, USA",,,,2020-01,,1094-3641,https://doi.org/10.1145/3379106.3379111;http://dx.doi.org/10.1145/3379106.3379111,10.1145/3379106.3379111,"The Speci cation and Analysis of Requirements (SpeAR) tool is a requirements prototyping and analysis tool based on the formal semantics of the Lustre language. It features a domain speci c language that formally captures functional requirements of systems or software. Once formalized, requirements can be analyzed to demonstrate correct- ness, consistency, and traceability using in nite-state model checking tools, such as JKind. The formal notation and analyses that SpeAR supports can be used to automate activities related to certi cation of safety critical software as suggested by DO-178C: Software Considera- tions in Airborne Systems and Equipment Certi cation. This standard de nes a rigorous software development process that ensures that soft- ware development activities produce object code that implement sys- tem requirements correctly, while introducing no additional functional- ity. Recent updates to the guidance allow for the use of formal methods to satisfy DO-178C certi cation objectives as outlined in DO-333: For- mal Methods Supplement to DO-178C and DO-278A. This paper walks through an e ort in which SpeAR is used to automate certi cation ac- tivities for production avionics software. It focuses on the use of SpeAR to address veri cation objectives related to the software design artifacts of DO-178C, replacing manual peer review activities with more rigorous formal-methods based analyses.","requirements, model checking, certification",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Wong L,A Dichotomy in the Intensional Expressive Power of Nested Relational Calculi Augmented with Aggregate Functions and a Powerset Operator,,2013,,,285–296,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 32nd ACM SIGMOD-SIGACT-SIGAI Symposium on Principles of Database Systems,"New York, New York, USA",2013,9781450320665,,https://doi.org/10.1145/2463664.2463670;http://dx.doi.org/10.1145/2463664.2463670,10.1145/2463664.2463670,"The extensional aspect of expressive power---i.e., what queries can or cannot be expressed---has been the subject of many studies of query languages. Paradoxically, although efficiency is of primary concern in computer science, the intensional aspect of expressive power---i.e., what queries can or cannot be implemented efficiently---has been much neglected. Here, we discuss the intensional expressive power of NRC(Q, +, ·, ‏, undefined, Σ, powerset), a nested relational calculus augmented with aggregate functions and a powerset operation. We show that queries on structures such as long chains, deep trees, etc. have a dichotomous behaviour: Either they are already expressible in the calculus without using the powerset operation or they require at least exponential space. This result generalizes in three significant ways several old dichotomy-like results, such as that of Suciu and Paredaens that the complex object algebra of Abiteboul and Beeri needs exponential space to implement the transitive closure of a long chain. Firstly, a more expressive query language---in particular, one that captures SQL---is considered here. Secondly, queries on a more general class of structures than a long chain are considered here. Lastly, our proof is more general and holds for all query languages exhibiting a certain normal form and possessing a locality property.","nested relational calculus, sql, conservative extension property, intensional expressive power, locality property, normal form, dichotomy",PODS '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Krishnan R,Niu J,Sandhu R,Winsborough WH",Group-Centric Secure Information-Sharing Models for Isolated Groups,ACM Trans. Inf. Syst. Secur.,2011,14,3,,Association for Computing Machinery,"New York, NY, USA",,,,2011-11,,1094-9224,https://doi.org/10.1145/2043621.2043623;http://dx.doi.org/10.1145/2043621.2043623,10.1145/2043621.2043623,"Group-Centric Secure Information Sharing (g-SIS) envisions bringing users and objects together in a group to facilitate agile sharing of information brought in from external sources as well as creation of new information within the group. We expect g-SIS to be orthogonal and complementary to authorization systems deployed within participating organizations. The metaphors “secure meeting room” and “subscription service” characterize the g-SIS approach.The focus of this article is on developing the foundations of isolated g-SIS models. Groups are isolated in the sense that membership of a user or an object in a group does not affect their authorizations in other groups. Present contributions include the following: formal specification of core properties that at once help to characterize the family of g-SIS models and provide a “sanity check” for full policy specifications; informal discussion of policy design decisions that differentiate g-SIS policies from one another with respect to the authorization semantics of group operations; formalization and verification of a specific member of the family of g-SIS models; demonstration that the core properties are logically consistent and mutually independent; and identification of several directions for future extensions.The formalized specification is highly abstract. Besides certain well-formedness requirements that specify, for instance, a user cannot leave a group unless she is a member, it constrains only whether user-level read and write operations are authorized and it does so solely in terms of the history of group operations; join and leave for users and add, create, and remove for objects. This makes temporal logic one of the few formalisms in which the specification can be clearly and concisely expressed. The specification serves as a reference point that is the first step in deriving authorization-system component specifications from which a programmer with little security expertise could implement a high-assurance enforcement system for the specified policy.","linear temporal logic, security properties, Access control, groups, information sharing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Reggelin T,Tolujew J",A Mesoscopic Approach to Modeling and Simulation of Logistics Processes,,2011,,,1513–1523,Winter Simulation Conference,"Phoenix, Arizona",,Proceedings of the Winter Simulation Conference,,2011,,,,,"Simulation models are important for planing, implementing and operating logistics systems since they can depict their dynamic system behavior. In the field of logistics, discrete-event models are widely used. Their creation and computation is often very time and labor consuming. For this reason, the paper presents a new mesoscopic modeling and simulation approach to quickly and effectively execute analysis and planning tasks related to production and logistics systems. Mesoscopic models represent logistics flow processes on an aggregated level through piecewise constant flow rates instead of modeling individual flow objects. The results are not obtained by counting individual objects but by using mathematical formulas to calculate the results as continuous quantities in every modeling time step. This leads to a fast model creation and computation. In terms of level of detail, mesoscopic simulation models fall between object based discrete-event simulation models and flow based continuous simulation models.",,WSC '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nagarakatte S,Zhao J,Martin MM,Zdancewic S",CETS: Compiler Enforced Temporal Safety for C,,2010,,,31–40,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 International Symposium on Memory Management,"Toronto, Ontario, Canada",2010,9781450300544,,https://doi.org/10.1145/1806651.1806657;http://dx.doi.org/10.1145/1806651.1806657,10.1145/1806651.1806657,"Temporal memory safety errors, such as dangling pointer dereferences and double frees, are a prevalent source of software bugs in unmanaged languages such as C. Existing schemes that attempt to retrofit temporal safety for such languages have high runtime overheads and/or are incomplete, thereby limiting their effectiveness as debugging aids. This paper presents CETS, a compile-time transformation for detecting all violations of temporal safety in C programs. Inspired by existing approaches, CETS maintains a unique identifier with each object, associates this metadata with the pointers in a disjoint metadata space to retain memory layout compatibility, and checks that the object is still allocated on pointer dereferences. A formal proof shows that this is sufficient to provide temporal safety even in the presence of arbitrary casts if the program contains no spatial safety violations. Our CETS prototype employs both temporal check removal optimizations and traditional compiler optimizations to achieve a runtime overhead of just 48% on average. When combined with a spatial-checking system, the average overall overhead is 116% for complete memory safety","memory safety, dangling pointers, temporal errors, c",ISMM '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Nagarakatte S,Zhao J,Martin MM,Zdancewic S",CETS: Compiler Enforced Temporal Safety for C,SIGPLAN Not.,2010,45,8,31–40,Association for Computing Machinery,"New York, NY, USA",,,,2010-06,,0362-1340,https://doi.org/10.1145/1837855.1806657;http://dx.doi.org/10.1145/1837855.1806657,10.1145/1837855.1806657,"Temporal memory safety errors, such as dangling pointer dereferences and double frees, are a prevalent source of software bugs in unmanaged languages such as C. Existing schemes that attempt to retrofit temporal safety for such languages have high runtime overheads and/or are incomplete, thereby limiting their effectiveness as debugging aids. This paper presents CETS, a compile-time transformation for detecting all violations of temporal safety in C programs. Inspired by existing approaches, CETS maintains a unique identifier with each object, associates this metadata with the pointers in a disjoint metadata space to retain memory layout compatibility, and checks that the object is still allocated on pointer dereferences. A formal proof shows that this is sufficient to provide temporal safety even in the presence of arbitrary casts if the program contains no spatial safety violations. Our CETS prototype employs both temporal check removal optimizations and traditional compiler optimizations to achieve a runtime overhead of just 48% on average. When combined with a spatial-checking system, the average overall overhead is 116% for complete memory safety","temporal errors, dangling pointers, c, memory safety",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gupta A,Hajiaghayi M,Nagarajan V,Ravi R",Dial a Ride from <i>k</i>-Forest,ACM Trans. Algorithms,2010,6,2,,Association for Computing Machinery,"New York, NY, USA",,,,2010-04,,1549-6325,https://doi.org/10.1145/1721837.1721857;http://dx.doi.org/10.1145/1721837.1721857,10.1145/1721837.1721857,"The k-forest problem is a common generalization of both the k-MST and the dense-k-subgraph problems. Formally, given a metric space on n vertices V, with m demand pairs ⊆ V × V and a “target” k≤ m, the goal is to find a minimum cost subgraph that connects at least k pairs. In this paper, we give an O(min√n⋅log k,√k)-approximation algorithm for k-forest, improving on the previous best ratio of O(min n2/3,√mlog n) by Segev and Segev.We then apply our algsorithm for k-forest to obtain approximation algorithms for several Dial-a-Ride problems. The basic Dial-a-Ride problem is the following: given an n point metric space with m objects each with its own source and destination, and a vehicle capable of carrying at most k objects at any time, find the minimum length tour that uses this vehicle to move each object from its source to destination. We want that the tour be non-preemptive: that is, each object, once picked up at its source, is dropped only at its destination. We prove that an α-approximation algorithm for the k-forest problem implies an O(α⋅log2n)-approximation algorithm for Dial-a-Ride. Using our results for k-forest, we get an O(min√n,√k⋅log2 n)-approximation algorithm for Dial-a-Ride. The only previous result known for Dial-a-Ride was an O(√klog n)-approximation by Charikar and Raghavachari; our results give a different proof of a similar approximation guarantee—in fact, when the vehicle capacity k is large, we give a slight improvement on their results. The reduction from Dial-a-Ride to the k-forest problem is fairly robust, and allows us to obtain approximation algorithms (with the same guarantee) for some interesting generalizations of Dial-a-Ride.","vehicle routing, network design, Approximation algorithms",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ahmadi H,Tootaghaj SZ,Mowlaei S,Hashemi MR,Shirmohammadi S",GSET Somi: A Game-Specific Eye Tracking Dataset for Somi,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Multimedia Systems,"Klagenfurt, Austria",2016,9781450342971,,https://doi.org/10.1145/2910017.2910616;http://dx.doi.org/10.1145/2910017.2910616,10.1145/2910017.2910616,"In this paper, we present an eye tracking dataset of computer game players who played the side-scrolling cloud game Somi. The game was streamed in the form of video from the cloud to the player. This dataset can be used for designing and testing game-specific visual attention models. The source code of the game is also available to facilitate further modifications and adjustments. For collecting this data, male and female candidates were asked to play the game in front of a remote eye-tracking device. For each player, we recorded gaze points, video frames of the gameplay, and mouse and keyboard commands. For each video frame, a list of its game objects with their locations and sizes was also recorded. This data, synchronized with eye-tracking data, allows one to calculate the amount of attention that each object or group of objects draw from each player. As a benchmark, we also show various attention patterns could be identified among players.","perceptual video coding, eye-tracking dataset, visual attention model, game dataset",MMSys '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Emmi M,Enea C",Symbolic Abstract Data Type Inference,,2016,,,513–525,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"St. Petersburg, FL, USA",2016,9781450335492,,https://doi.org/10.1145/2837614.2837645;http://dx.doi.org/10.1145/2837614.2837645,10.1145/2837614.2837645,"Formal specification is a vital ingredient to scalable verification of software systems. In the case of efficient implementations of concurrent objects like atomic registers, queues, and locks, symbolic formal representations of their abstract data types (ADTs) enable efficient modular reasoning, decoupling clients from implementations. Writing adequate formal specifications, however, is a complex task requiring rare expertise. In practice, programmers write reference implementations as informal specifications. In this work we demonstrate that effective symbolic ADT representations can be automatically generated from the executions of reference implementations. Our approach exploits two key features of naturally-occurring ADTs: violations can be decomposed into a small set of representative patterns, and these patterns manifest in executions with few operations. By identifying certain algebraic properties of naturally-occurring ADTs, and exhaustively sampling executions up to a small number of operations, we generate concise symbolic ADT representations which are complete in practice, enabling the application of efficient symbolic verification algorithms without the burden of manual specification. Furthermore, the concise ADT violation patterns we generate are human-readable, and can serve as useful, formal documentation.","Refinement, Linearizability, Concurrency",POPL '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Emmi M,Enea C",Symbolic Abstract Data Type Inference,SIGPLAN Not.,2016,51,1,513–525,Association for Computing Machinery,"New York, NY, USA",,,,2016-01,,0362-1340,https://doi.org/10.1145/2914770.2837645;http://dx.doi.org/10.1145/2914770.2837645,10.1145/2914770.2837645,"Formal specification is a vital ingredient to scalable verification of software systems. In the case of efficient implementations of concurrent objects like atomic registers, queues, and locks, symbolic formal representations of their abstract data types (ADTs) enable efficient modular reasoning, decoupling clients from implementations. Writing adequate formal specifications, however, is a complex task requiring rare expertise. In practice, programmers write reference implementations as informal specifications. In this work we demonstrate that effective symbolic ADT representations can be automatically generated from the executions of reference implementations. Our approach exploits two key features of naturally-occurring ADTs: violations can be decomposed into a small set of representative patterns, and these patterns manifest in executions with few operations. By identifying certain algebraic properties of naturally-occurring ADTs, and exhaustively sampling executions up to a small number of operations, we generate concise symbolic ADT representations which are complete in practice, enabling the application of efficient symbolic verification algorithms without the burden of manual specification. Furthermore, the concise ADT violation patterns we generate are human-readable, and can serve as useful, formal documentation.","Refinement, Linearizability, Concurrency",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gilpin S,Qian B,Davidson I",Efficient Hierarchical Clustering of Large High Dimensional Datasets,,2013,,,1371–1380,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 22nd ACM International Conference on Information & Knowledge Management,"San Francisco, California, USA",2013,9781450322638,,https://doi.org/10.1145/2505515.2505527;http://dx.doi.org/10.1145/2505515.2505527,10.1145/2505515.2505527,"Hierarchical clustering is extensively used to organize high dimensional objects such as documents and images into a structure which can then be used in a multitude of ways. However, existing algorithms are limited in their application since the time complexity of agglomerative style algorithms can be as much as O(n2log n) where n is the number of objects. Furthermore the computation of similarity between such objects is itself time consuming given they are high dimension and even optimized built in functions found in MATLAB take the best part of a day to handle collections of just 10,000 objects on typical machines. In this paper we explore using angular hashing to hash objects with similar angular distance to the same hash bucket. This allows us to create hierarchies of objects within each hash bucket and to hierarchically cluster the hash buckets themselves. With our formal guarantees on the similarity of objects in the same bucket this leads to an elegant agglomerative algorithm with strong performance bounds. Our experimental results show that not only is our approach thousands of times faster than regular agglomerative algorithms but surprisingly the accuracy of our results is typically as good and can sometimes be substantially better.","hierarchical clustering, binary codes",CIKM '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tauheed F,Heinis T,Ailamaki A",THERMAL-JOIN: A Scalable Spatial Join for Dynamic Workloads,,2015,,,939–950,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 ACM SIGMOD International Conference on Management of Data,"Melbourne, Victoria, Australia",2015,9781450327589,,https://doi.org/10.1145/2723372.2749434;http://dx.doi.org/10.1145/2723372.2749434,10.1145/2723372.2749434,"Simulations have become ubiquitous in many domains of science. Today scientists study natural phenomena by first building massive three-dimensional spatial models and then by simulating the models at discrete intervals of time to mimic the behavior of natural phenomena. One frequently occurring challenge during simulations is the repeated computation of spatial self-joins of the model at each simulation time step. The join is performed to access a group of neighboring spatial objects (groups of particles, molecules or cosmological objects) so that scientists can calculate the cumulative effect (like gravitational force) on an object. Computing a self-join even in memory, soon becomes a performance bottleneck in simulation applications. The problem becomes even worse as scientists continue to improve the precision of simulations by increasing the number as well as the size (3D extent) of the objects. This leads to an exponential increase in join selectivity that challenges the performance and scalability of state-of-the-art approaches.We propose THERMAL-JOIN, a novel spatial self-join algorithm for dynamic memory-resident workloads. The algorithm groups objects in spatial proximity together into hot spots. Hot spots minimize the cost of computing join as objects assigned to a hot spot are guaranteed to overlap with each other. Using a nested spatial grid, THERMAL-JOIN partitions and indexes the dataset to locate hot spots. With experiments we show that our approach provides a speedup between 8 to 12x compared to the state of the art and also scales as scientists improve the precision of their simulations.","high selectivity join, dynamic workload, spatial self-join, scientific data management",SIGMOD '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Raghunathan R,Muller SK,Acar UA,Blelloch G",Hierarchical Memory Management for Parallel Programs,,2016,,,392–406,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM SIGPLAN International Conference on Functional Programming,"Nara, Japan",2016,9781450342193,,https://doi.org/10.1145/2951913.2951935;http://dx.doi.org/10.1145/2951913.2951935,10.1145/2951913.2951935,"An important feature of functional programs is that they are parallel by default. Implementing an efficient parallel functional language, however, is a major challenge, in part because the high rate of allocation and freeing associated with functional programs requires an efficient and scalable memory manager. In this paper, we present a technique for parallel memory management for strict functional languages with nested parallelism. At the highest level of abstraction, the approach consists of a technique to organize memory as a hierarchy of heaps, and an algorithm for performing automatic memory reclamation by taking advantage of a disentanglement property of parallel functional programs. More specifically, the idea is to assign to each parallel task its own heap in memory and organize the heaps in a hierarchy/tree that mirrors the hierarchy of tasks. We present a nested-parallel calculus that specifies hierarchical heaps and prove in this calculus a disentanglement property, which prohibits a task from accessing objects allocated by another task that might execute in parallel. Leveraging the disentanglement property, we present a garbage collection technique that can operate on any subtree in the memory hierarchy concurrently as other tasks (and/or other collections) proceed in parallel. We prove the safety of this collector by formalizing it in the context of our parallel calculus. In addition, we describe how the proposed techniques can be implemented on modern shared-memory machines and present a prototype implementation as an extension to MLton, a high-performance compiler for the Standard ML language. Finally, we evaluate the performance of this implementation on a number of parallel benchmarks.","Scheduling, Memory Management, Parallelism, Languages",ICFP 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Raghunathan R,Muller SK,Acar UA,Blelloch G",Hierarchical Memory Management for Parallel Programs,SIGPLAN Not.,2016,51,9,392–406,Association for Computing Machinery,"New York, NY, USA",,,,2016-09,,0362-1340,https://doi.org/10.1145/3022670.2951935;http://dx.doi.org/10.1145/3022670.2951935,10.1145/3022670.2951935,"An important feature of functional programs is that they are parallel by default. Implementing an efficient parallel functional language, however, is a major challenge, in part because the high rate of allocation and freeing associated with functional programs requires an efficient and scalable memory manager. In this paper, we present a technique for parallel memory management for strict functional languages with nested parallelism. At the highest level of abstraction, the approach consists of a technique to organize memory as a hierarchy of heaps, and an algorithm for performing automatic memory reclamation by taking advantage of a disentanglement property of parallel functional programs. More specifically, the idea is to assign to each parallel task its own heap in memory and organize the heaps in a hierarchy/tree that mirrors the hierarchy of tasks. We present a nested-parallel calculus that specifies hierarchical heaps and prove in this calculus a disentanglement property, which prohibits a task from accessing objects allocated by another task that might execute in parallel. Leveraging the disentanglement property, we present a garbage collection technique that can operate on any subtree in the memory hierarchy concurrently as other tasks (and/or other collections) proceed in parallel. We prove the safety of this collector by formalizing it in the context of our parallel calculus. In addition, we describe how the proposed techniques can be implemented on modern shared-memory machines and present a prototype implementation as an extension to MLton, a high-performance compiler for the Standard ML language. Finally, we evaluate the performance of this implementation on a number of parallel benchmarks.","Scheduling, Languages, Memory Management, Parallelism",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sweeney B,Adams A","Virtual World Users Evaluated According to Environment Design, Task Based and Affective Attention Measures",,2009,,,381–387,BCS Learning & Development Ltd.,"Swindon, GBR",,Proceedings of the 23rd British HCI Group Annual Conference on People and Computers: Celebrating People and Technology,"Cambridge, United Kingdom",2009,,,,,"This paper presents research that engages with virtual worlds for education users to understand design of these applications for their needs. An in-depth multi-method investigation from 12 virtual worlds participants was undertaken in three stages; initially a small scale within-subjects eye-tracking comparison was made between the role playing game 'RuneScape' and the virtual social world 'Second Life', secondly an in-depth evaluation of eye-tracking data for Second Life tasks (i.e. avatar, object and world based) was conducted, finally a qualitative evaluation of Second Life tutorials in comparative 3D situations (i.e. environments that are; realistic to surreal, enclosed to open, formal to informal) was conducted. Initial findings identified increased users attention within comparable gaming and social world interactions. Further analysis identified that 3D world focused interactions increased participants' attention more than object and avatar tasks. Finally different 3D situation designs altered levels of task engagement and distraction through perceptions of comfort, fun and fear. Ultimately goal based and environment interaction tasks can increase attention and potentially immersion. However, affective perceptions of 3D situations can negatively impact on attention. An objective discussion of the limitations and benefits of virtual world immersion for student learning is presented.","immersion, attention, social worlds, MMORPG, gaming, MUVE",BCS-HCI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gatouillat A,Badr Y,Massot B",Hybrid Controller Synthesis for the IoT,,2018,,,783–790,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd Annual ACM Symposium on Applied Computing,"Pau, France",2018,9781450351911,,https://doi.org/10.1145/3167132.3167219;http://dx.doi.org/10.1145/3167132.3167219,10.1145/3167132.3167219,"The Internet-of-Things designates the interconnection of a variety of communication-enabled physical objects. IoT systems and devices must operate with a deterministic behavior and respect user-defined system goals in any situation. We thus defined hybrid controller synthesis for decentralized and critical IoT systems relying on a set of rules to handle situations with asynchronous and synchronous event processing. This framework defines a declarative rule-driven governance mechanism of locally synchronous sub-systems enabling the hybrid control of IoT systems with formal guarantees over the satisfaction of system-wide QoS requirements. In order to prove the practicality of our framework, it was applied to a critical medical Internet-of-Things use case, demonstrating its usability for safety-critical IoT applications.","hybrid controller synthesis, adaptive IoT, rule-based control",SAC '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Servetto M,Groves L",True Small-Step Reduction for Imperative Object Oriented Languages,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th Workshop on Formal Techniques for Java-like Programs,"Montpellier, France",2013,9781450320429,,https://doi.org/10.1145/2489804.2489805;http://dx.doi.org/10.1145/2489804.2489805,10.1145/2489804.2489805,"Traditionally, formal semantic models of Java-like languages use an explicit model of the store which mimics pointers and ram. These low level models hamper understanding of the semantics, and development of proofs about ownerships and other encapsulation properties, since the real (graph) structure of the data is obscured by the encoding. Such models are also inadequate for didactic purposes since they rely on run-time structures that do not exist in the source program --- in order to understand the meaning of an expression in the middle of the execution one is required to visualize the memory structure which is hard to relate to the abstract program state.We present a semantic model for Java-like languages where data is encoded as part of the program rather than as a separate resource. This means that execution can be modelled more simply by just rewriting source code terms, as in semantic models for functional programs. The major challenges that need to be addressed are aliasing, circular object graphs, exceptions and multiple return methods. In this initial proposal we use local variable declarations in order to tackle aliasing and circular object graphs.","small-step reduction, object oriented, imperative languages",FTfJP '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Magdics M,Real-Time Generation of L-System Scene Models for Rendering and Interaction,,2009,,,67–74,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 25th Spring Conference on Computer Graphics,"Budmerice, Slovakia",2009,9781450307697,,https://doi.org/10.1145/1980462.1980478;http://dx.doi.org/10.1145/1980462.1980478,10.1145/1980462.1980478,"We present a framework for generating procedural geometry described by a context-free, parametric L-system completely on the GPU in real-time. These formal grammars allow us to easily describe various types of complex objects, such as vegetation or buildings, in a great diversity. We can create large and complex parts of the scene on-the-fly, which enables us to create a potentially infinite world of such objects. To make modeling easier, we show how the grammar description can be transformed automatically to a shader code that evaluates the L-system on the GPU. Additionally, to allow interaction with the procedural geometry, we propose an algorithm to efficiently perform discrete collision detection with the procedural scene for a large number of objects.","real-time procedural modeling, discrete collision detection, L-systems",SCCG '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"El-Saber N,Boronat A",BPMN Formalization and Verification Using Maude,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2014 Workshop on Behaviour Modelling-Foundations and Applications,"York, United Kingdom",2014,9781450327916,,https://doi.org/10.1145/2630768.2630769;http://dx.doi.org/10.1145/2630768.2630769,10.1145/2630768.2630769,"OMG's Business Process Model and Notation (BPMN) standard provides an informal specification of a technology independent modelling language for designing business processes. However, BPMN models may include structural issues that hinder their design. In this paper, we propose a formal characterization and semantics specification of well-formed BPMN processes in rewriting logic using Maude with a focus on data-based decision gateways and data objects semantics. Our formal specification adheres to the BPMN standards, verified with respect to the classical workflow soundness definition, and automatically verified using the verification toolkit that Maude includes.","Formalization, Soundness, BPMN, Maude",BM-FA '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Riggs K,Formal Theory for Software Engineering Students,J. Comput. Sci. Coll.,2011,26,5,53–59,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,,2011-05,,1937-4771,,,"This paper describes the use of an automated proof assistant in an introductory, graduate level, Formal Methods of Software Engineering course. Proof is difficult and often seen as abstract but tools can be the basis for relating proofs to practice. The proof editor JAPE can animate formal proofs in various theories, providing students with a significantly self-driven exploration of theory. The existence of machine readable theory objects also presents the opportunity to automate relationships between theory and topics more familiar to the student - programming in this case. We have documented increased work and improved attitude among students toward formal methods and proof using this combined approach. Although the particular example is a graduate course, we believe the increased student involvement in a structured experience leads to better outcomes and can be well-employed in many course, even as a stand off module.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sprock T,Bock C",Incorporating Abstraction Methods into System-Analysis Integration Methodology for Discrete Event Logistics Systems,,2017,,,,IEEE Press,"Las Vegas, Nevada",,Proceedings of the 2017 Winter Simulation Conference,,2017,9781538634271,,,,"Analysis models, such as discrete event simulation models, are used to support design and operation of discrete event logistics systems (DELS). The time and expertise required to construct these analysis models can be significantly reduced by automatically generating them from formal models of the systems being analyzed. DELS analysis models can be constructed from system abstractions much more reliably when the system and analysis are specified at compatible levels of abstraction. Formal modeling languages, such as those used in object-orientation, make abstraction explicit, simplifying the mappings between system and analysis models and increasing reusability of the integration. In this paper, we propose fundamental abstractions for DELS and identify corresponding libraries of analysis models. These are used in a system-analysis integration methodology that incorporates abstraction as an explicit step, providing a path to refine and extend those abstractions and model libraries to generate analysis models.",,WSC '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Alistarh D,Guerraoui R,Kuznetsov P,Losa G",On the Cost of Composing Shared-Memory Algorithms,,2012,,,298–307,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Twenty-Fourth Annual ACM Symposium on Parallelism in Algorithms and Architectures,"Pittsburgh, Pennsylvania, USA",2012,9781450312134,,https://doi.org/10.1145/2312005.2312057;http://dx.doi.org/10.1145/2312005.2312057,10.1145/2312005.2312057,"Decades of research in distributed computing have led to a variety of perspectives on what it means for a concurrent algorithm to be efficient, depending on model assumptions, progress guarantees, and complexity metrics. It is therefore natural to ask whether one could compose algorithms that perform efficiently under different conditions, so that the composition preserves the performance of the original components when their conditions are met.In this paper, we evaluate the cost of composing shared-memory algorithms. First, we formally define the notion of safely composable algorithms and we show that every sequential type has a safely composable implementation, as long as enough state is transferred between modules. Since such generic implementations are inherently expensive, we present a more general light-weight specification that allows the designer to transfer very little state between modules, by taking advantage of the semantics of the implemented object. Using this framework, we implement a composed long-lived test-and-set object, with the property that each of its modules is asymptotically optimal with respect to the progress condition it ensures, while the entire implementation only uses objects with consensus number at most two. Thus, we show that the overhead of composition can be negligible in the case of some important shared-memory abstractions.","modularity, consensus, complexity, test-and-set, composition",SPAA '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Vastag S,Arrival and Delay Curve Estimation for SLA Calculus,,2012,,,,Winter Simulation Conference,"Berlin, Germany",,Proceedings of the Winter Simulation Conference,,2012,,,,,"An algorithm and selection method to estimate Network Calculus arrival bounds for systems with concurrent arrivals is presented. Concurrent job arrivals are common for Service-Oriented Architectures. Their performance is described in Service Level Agreements including quantitative requirements for load and response times. SLA Calculus, a variant of Network Calculus, can be used for service performance modeling and validation with SLAs. Functions called curves are used to bound job arrivals as well as their delay. Due to the concurrent nature of job arrivals curve estimation methods used for successive packet arrivals in Network Calculus cannot be applied in SLA Calculus. We present a method to estimate unknown SLA Calculus arrival and delay bounds from input and output traces. This paper introduces an algorithm for the estimation of the curves. Optimal selection of a curve model based on several fitting criteria is performed using candidates from trace sets.",,WSC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Marin MA,Lotriet H,Van Der Poll JA",Metrics for the Case Management Modeling and Notation (CMMN) Specification,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 Annual Research Conference on South African Institute of Computer Scientists and Information Technologists,"Stellenbosch, South Africa",2015,9781450336833,,https://doi.org/10.1145/2815782.2815813;http://dx.doi.org/10.1145/2815782.2815813,10.1145/2815782.2815813,"The Case Management Modeling and Notation (CMMN) specification, published by the Object Management Group (OMG) in 2014, describes a declarative style for modeling business processes. The declarative nature of CMMN is intended to supplement the procedural style of the Business Process Modeling and Notation (BPMN). Although multiple metrics have been developed and verified for BPMN, the authors are not aware of any metrics developed for CMMN. Being a relative new process specification the understanding of complexity metrics for CMMN ought to be beneficial for practitioners and researchers by providing a way to compare case management models.This study provides a formal description of CMMN and three metrics are defined, namely size, length, and complexity. The metrics are theoretically validated using the formal framework for software measurements defined by Briand et al. and the complexity metric is further validated using Weyuker's properties for software complexity measures.","Case management, Modeling complexity, Case handling, Complexity metrics, CMMN, Process modeling complexity, BPMN",SAICSIT '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Palanque P,Winckler M,Ladry JF,ter Beek MH,Faconti G,Massink M",A Formal Approach Supporting the Comparative Predictive Assessment of the Interruption-Tolerance of Interactive Systems,,2009,,,211–220,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st ACM SIGCHI Symposium on Engineering Interactive Computing Systems,"Pittsburgh, PA, USA",2009,9781605586007,,https://doi.org/10.1145/1570433.1570473;http://dx.doi.org/10.1145/1570433.1570473,10.1145/1570433.1570473,"This paper presents an approach for investigating in a predictive way potential disruptive effects of interruptions on task performance in a multitasking environment. The approach combines previous work in the field of interruption analysis, formal description techniques for interactive systems and stochastic processes to support performance analysis of user activities constrained by the occurrence of interruptions. The approach uses formal description techniques to provide a precise description of user tasks, and both system and interruptions behavior. The detailed mechanism by which systems and interruptions behave is first described using a Petri nets-based formal description technique called Interactive Cooperative Objects (ICO). The use of a formal modeling technique for the description of these three components makes it possible to compare and analyze different interaction techniques. In particular, it allows us to determine which of the system states are most affected by the occurrence of interruptions. Once composed together, models describing the system, user tasks and interruptions behavior are transformed into PEPA models (i.e. Performance Evaluation Process Algebra) that are amenable to performance analysis using the PRISM model checker. The approach is exemplified by a simple example that models two interaction techniques for manipulating icons in a desktop environment.","model-based approaches, human computer interaction, performance evaluation, interruptions, formal description techniques",EICS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lahraichi M,Housni K,Mbarki S",Particle Filter Object Tracking Based on Color Histogram and Gabor Filter Magnitude,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2nd International Conference on Big Data, Cloud and Applications","Tetouan, Morocco",2017,9781450348522,,https://doi.org/10.1145/3090354.3090434;http://dx.doi.org/10.1145/3090354.3090434,10.1145/3090354.3090434,"Object tracking is a main problem in computer vision, many tracking approaches has been proposed and tested. Color histogram based particle filtering is the most common method used for object tracking [1,2]. Particle filtering is used for its robustness in non-linear and non-Gaussian dynamic state estimation problems and performs well when clutter and occlusions are present, whereas histograms are useful because they have the property that allows changes in the object appearance while they remain the same. However it cannot give a good result if the object and background have the same color, so in order to get a better tracking performance, we introduce a new particle filter tracking method, in which the observation likelihood is calculated using color histogram of the detected object obtained from background subtraction method, combined with Gabor filter features, and we use Box--Muller transformation for state space model. The effectiveness of our approach is verified.","Object Tracking, Particle Filter, Gabor features",BDCA'17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gogolla M,Vallecillo A,Burgueño L,Hilken F",Employing Classifying Terms for Testing Model Transformations,,2015,,,312–321,IEEE Press,"Ottawa, Ontario, Canada",,Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems,,2015,9781467369084,,,,"This contribution proposes a new technique for developing test cases for UML and OCL models. The technique is based on an approach that automatically constructs object models for class models enriched by OCL constraints. By guiding the construction process through so-called classifying terms, the built test cases in form of object models are classified into equivalence classes. A classifying term can be an arbitrary OCL term on the class model that calculates for an object model a characteristic value. From each equivalence class of object models with identical characteristic values one representative is chosen. The constructed test cases behave significantly different with regard to the selected classifying term. By building few diverse object models, properties of the UML and OCL model can be explored effectively. The technique is applied for automatically constructing relevant source model test cases for model transformations between a source and target metamodel.",,MODELS '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Battell C,Felty A",The Logic of Hereditary Harrop Formulas as a Specification Logic for Hybrid,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Eleventh Workshop on Logical Frameworks and Meta-Languages: Theory and Practice,"Porto, Portugal",2016,9781450347778,,https://doi.org/10.1145/2966268.2966271;http://dx.doi.org/10.1145/2966268.2966271,10.1145/2966268.2966271,"Hybrid is a logical framework that supports the use of higher-order abstract syntax (HOAS) in representing formal systems or \object logics\"" (OLs). It is implemented in Coq and follows a two-level approach",where a specification logic (SL) is implemented as an inductive type and used to concisely and elegantly encode the inference rules of the formal systems of interest. In this paper,we develop a new higher-order specification logic for Hybrid. By increasing the expressive power of the SL beyond what was considered previously,we increase the flexibility of encoding OLs and thus extend the class of formal systems for which we can reason about efficiently. We focus on formalizing the meta-theory of the SL. We develop an abstract way in which to present an important class of meta-theorems. This class includes properties such as weakening,contraction,exchange,"and the admissibility of the cut rule. The cut admissibility theorem establishes consistency and also provides justification for substituting a formula for an assumption in a context of assumptions. It can greatly simplify reasoning about OLs in systems that provide HOAS. We present the abstraction and show how it is used to prove all of these theorems.""","cut admissibility, Coq, logical frameworks, higher-order abstract syntax, interactive theorem proving, structural rules",LFMTP '16,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li C,Wan Y,Jia S,Liu H",Salient Object Detection Based on HDCT and the Prior Boundary,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Conference on Internet Multimedia Computing and Service,"Nanjing, China",2018,9781450365208,,https://doi.org/10.1145/3240876.3240917;http://dx.doi.org/10.1145/3240876.3240917,10.1145/3240876.3240917,"It is difficult to detect the accurate boundary of the object from the frequency information of image. In order to solve this problem, a new salient object detection algorithm which is combined Hypercomplex Discrete Cosine Transform (HDCT) and the prior boundary is proposed. Firstly, we divide the images into image blocks, and the HDCT is performed on each image block. Then the features of the image block are represented by the information of low frequency energy. Finally, the saliency map is calculated according to the prior boundary. The experiments show that the performance of the proposed algorithm is much better than the other classical salient object detection algorithms. At the same time, the boundary of the detected object region is much clearer.","piror boundary, HDCT, salient object detection",ICIMCS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cave A,Pientka B",First-Class Substitutions in Contextual Type Theory,,2013,,,15–24,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Eighth ACM SIGPLAN International Workshop on Logical Frameworks & Meta-Languages: Theory & Practice,"Boston, Massachusetts, USA",2013,9781450323826,,https://doi.org/10.1145/2503887.2503889;http://dx.doi.org/10.1145/2503887.2503889,10.1145/2503887.2503889,"In this paper, we revisit the theory of first-class substitution in contextual type theory (CTT); in particular, we focus on the abstract notion of substitution variables. This forms the basis for extending Beluga, a dependently typed proof and programming language which already supports first-class contexts and contextual objects, with first-class substitutions. To illustrate the elegance and power of first-class substitution variables, we describe the implementation of a weak normalization proof for the simply-typed lambda-calculus in Beluga.","logical frameworks, higher-order abstract syntax, dependent types",LFMTP '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Guan L,Wünsche BC",An Evaluation of a Sketch-Based Model-by-Example Approach for Crowd Modelling,,2012,,,69–76,"Australian Computer Society, Inc.",AUS,,Proceedings of the Thirteenth Australasian User Interface Conference - Volume 126,"Melbourne, Australia",2012,9781921770074,,,,"An increasing number of computer applications require complex 3D environments. Examples are entertainment (games and movies), advertisement, social media technologies such as \Second Life\""",education,urban planning,landscape design,search and rescue simulations,visual impact studies and military simulations. Many virtual environments contain thousands of similar objects such as characters,trees,and buildings. Placing these objects by hand is cumbersome,whereas an automatic placement does not allow sufficient control over the desired distribution characteristics. In previous work we presented a prototype for a sketch-based model-by-example approach to generate large distributions of objects from sketched example distributions. In this paper we present an improved algorithm and we perform a formal user study demonstrating that the approach is indeed intuitive,effective,and that it works for a large number of regular,"irregular and clustered distribution patterns. Remaining limitations related to Gestalt and semantic concepts are illustrated and discussed.""","sketch-based modeling, texture synthesis, sketch-based interface, mass-spring system, crowd modeling",AUIC '12,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bader SR,Maleshkova M",Virtual Representations for an Iterative IoT Deployment,,2018,,,1887–1892,International World Wide Web Conferences Steering Committee,"Republic and Canton of Geneva, CHE",,Companion Proceedings of the The Web Conference 2018,"Lyon, France",2018,9781450356404,,https://doi.org/10.1145/3184558.3191657;http://dx.doi.org/10.1145/3184558.3191657,10.1145/3184558.3191657,"A central vision of the Internet of Things is the representation of the physical world in a consistent virtual environment. Especially in the context of smart factories the connection of the different, heterogeneous production modules through a digital shop floor promises faster conversion rates, data-driven maintenance or automated machine configurations for use cases which haven't been recognized at design time. Nevertheless, these scenarios demand IoT representations of all participating machines and components, which requires high installation efforts and hardware adjustments. We propose an incremental process for bringing the shop floor closer to the IoT vision. Currently the majority of systems, components or parts are not yet connected with the internet and might not even provide the possibility to be technically equipped with sensors. However, those could be essential parts for a realistic digital shop floor representation. We therefore propose Virtual Representations, which are capable of independently calculating a physical object's condition by dynamically collecting and interpreting already available data through RESTful Web APIs. The internal logic of such Virtual Representations are further adjustable at runtime since changes to its respective physical object, its environment or updates to the resource itself should not cause any downtime.","virtual integration, internet of things, linked data",WWW '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kuttler C,Lhoussaine C,Nebut M",Rule-Based Modeling of Transcriptional Attenuation at the Tryptophan Operon,,2009,,,920–931,Winter Simulation Conference,"Austin, Texas",,Winter Simulation Conference,,2009,9781424457717,,,,"Transcriptional attenuation at E. coli's tryptophan operon is a prime example of RNA-mediated gene regulation. In this paper, we present a discrete stochastic model of the fine-grained control of attenuation, based on chemical reactions. Stochastic simulation of our model confirms results that were previously obtained by master or differential equations. Our approach is easier to understand than master equations, although mathematically well founded. It is compact due to rule schemas that define finite sets of chemical reactions. Moreover, our model makes intense use of reaction rules with more than two reactants. As we show, such n-ary rules are essential to concisely capture the control of attenuation. Our model could not adequately be represented in object-centered modeling languages based on the pi-calculus, because these are limited to binary interactions.",,WSC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bromuri S,Stathis K",Distributed Agent Environments in the Ambient Event Calculus,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third ACM International Conference on Distributed Event-Based Systems,"Nashville, Tennessee",2009,9781605586656,,https://doi.org/10.1145/1619258.1619275;http://dx.doi.org/10.1145/1619258.1619275,10.1145/1619258.1619275,"We study the development of distributed agent environments as distributed event-based systems specified in the Ambient Event Calculus (AEC). The AEC is a logic-based formalism that is developed here to support the representation of a distributed agent environment as a persistent composite structure evolving over time. Such a complex structure supports the interaction between agents, objects, and containers, entities that have their own external observable state and can be distributed over a network. Interactions between these entities are specified in terms of events that represent actions executed by agents on objects and other agents in the environment. When events happen they are stored in containers and are notified to agent sensors that subscribe to event descriptions and as a result perceive the interactions. The AEC formalism also allows changes caused by events to be delivered across distributed containers, according to the topology of the application environment. We illustrate the use of AEC and we show how to specify interactions within the GOLEM agent platform applied to a specific agent scenario.","event calculus, distributed agent environments, research paper, MAS",DEBS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vassev E,Mokhov SA",An ASSL-Generated Architecture for Autonomic Systems,,2009,,,121–126,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd Canadian Conference on Computer Science and Software Engineering,"Montreal, Quebec, Canada",2009,9781605584010,,https://doi.org/10.1145/1557626.1557645;http://dx.doi.org/10.1145/1557626.1557645,10.1145/1557626.1557645,"The Autonomic System Specification Language (ASSL) is an initiative for the development of autonomic systems where we approach the problem of formal specification, validation, and code generation of such systems within a framework. ASSL generates an operational Java application skeleton from any valid specification where a special hierarchical multi-granular architecture composed of singleton classes is imposed.This paper presents the architecture model for autonomic systems generated with ASSL. Here we present a generic class model and a generic object model for autonomic systems. In addition, experimental results are provided to conclude the paper.","autonomic computing, architecture, code generation, ASSL",C3S2E '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Botelho RP,Pires DF",Uso de Ontologias Para a Representação SemâNtica de Objetos de Aprendizagem,,2008,,,158–160,Association for Computing Machinery,"New York, NY, USA",,Companion Proceedings of the XIV Brazilian Symposium on Multimedia and the Web,"Vila Velha, Espírito Santo, Brazil",2008,9788576691990,,https://doi.org/10.1145/1809980.1810025;http://dx.doi.org/10.1145/1809980.1810025,10.1145/1809980.1810025,"Learning Objects (LOs) retrieval and sharing are important tasks on a Web based educational system, because it allows LOs provided by different sources to be found and reused by heterogeneous systems. This enables, among others, costs reduction during the LO production proccess, as educational content development is a time consuming task. Therefore, a formal and standardized representation, like IEEE Learning Objects Metadata (LOM), is needed to describe the LOs to make the aforementioned scenario possible. However, semantic operations like LOs relationship demand an ontological representation as metadata semantics is not well defined. To this end, this paper presents an ontology that uses the IEEE LOM standard to semantically represent LOs.","objetos de aprendizagem, IEEE LOM, web semântica",WebMedia '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Buehler E,Branham S,Ali A,Chang JJ,Hofmann MK,Hurst A,Kane SK",Sharing is Caring: Assistive Technology Designs on Thingiverse,,2015,,,525–534,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd Annual ACM Conference on Human Factors in Computing Systems,"Seoul, Republic of Korea",2015,9781450331456,,https://doi.org/10.1145/2702123.2702525;http://dx.doi.org/10.1145/2702123.2702525,10.1145/2702123.2702525,"An increasing number of online communities support the open-source sharing of designs that can be built using rapid prototyping to construct physical objects. In this paper, we examine the designs and motivations for assistive technology found on Thingiverse.com, the largest of these communities at the time of this writing. We present results from a survey of all assistive technology that has been posted to Thingiverse since 2008 and a questionnaire distributed to the designers exploring their relationship with assistive technology and the motivation for creating these designs. The majority of these designs are intended to be manufactured on a 3D printer and include assistive devices and modifications for individuals with disabilities, older adults, and medication management. Many of these designs are created by the end-users themselves or on behalf of friends and loved ones. These designers frequently have no formal training or expertise in the creation of assistive technology. This paper discusses trends within this community as well as future opportunities and challenges.","disability, assistive technology, open-source, personal-scale fabrication, prototyping, design, 3d printing",CHI '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zhang Y,Chen S,Zhou Y,Odegbile OO,Fang Y",Efficient Anonymous Temporal-Spatial Joint Estimation at Category Level Over Multiple Tag Sets With Unreliable Channels,IEEE/ACM Trans. Netw.,2020,28,5,2174–2187,IEEE Press,,,,,2020-10,,1063-6692,https://doi.org/10.1109/TNET.2020.3011347;http://dx.doi.org/10.1109/TNET.2020.3011347,10.1109/TNET.2020.3011347,"Radio-frequency identification (RFID) technologies have been widely used in inventory control, object tracking and supply chain management. One of the fundamental system functions is called cardinality estimation, which is to estimate the number of tags in a covered area. In this paper, we extend the research of this function in two directions. First, we perform joint cardinality estimation among tags that appear at different geographical locations and at different times. Moreover, we target at category-level information, which is more significant in practical scenarios where we need to monitor the tagged objects of many different categories. Second, we enforce anonymity in the process of information gathering in order to preserve the privacy of the tagged objects. These capabilities will enable new applications such as tracking how products of different categories are transferred in a large, distributed supply chain. We propose and implement a novel protocol to meet the requirements of anonymous category-level joint estimation over multiple tag sets. We formally analyze the performance of our estimator and determine the optimal system parameters. Moreover, we extend our protocol to unreliable channels and consider two channel error models. Extensive simulations show that the proposed protocol can efficiently and accurately estimate joint information over multiple tag sets at category level, while preserving tags' anonymity.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Erbsen A,Gruetter S,Choi J,Wood C,Chlipala A",Integration Verification across Software and Hardware for a Simple Embedded System,,2021,,,604–619,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation,"Virtual, Canada",2021,9781450383912,,https://doi.org/10.1145/3453483.3454065;http://dx.doi.org/10.1145/3453483.3454065,10.1145/3453483.3454065,"The interfaces between layers of a system are susceptible to bugs if developers of adjacent layers proceed under subtly different assumptions. Formal verification of two layers against the same formal model of the interface between them can be used to shake out these bugs. Doing so for every interface in the system can, in principle, yield unparalleled assurance of the correctness and security of the system as a whole. However, there have been remarkably few efforts that carry out this exercise, and all of them have simplified the task by restricting interactivity of the application, inventing new simplified instruction sets, and using unrealistic input and output mechanisms. We report on the first verification of a realistic embedded system, with its application software, device drivers, compiler, and RISC-V processor represented inside the Coq proof assistant as one mathematical object, with a machine-checked proof of functional correctness. A key challenge is structuring the proof modularly, so that further refinement of the components or expansion of the system can proceed without revisiting the rest of the system.","RISC-V Instruction-Set Family, Proof Assistants, Embedded Systems, Formal Verification, Hardware-Software Interface",PLDI 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hürst W,Bilyalov T",Dynamic versus Static Peephole Navigation of VR Panoramas on Handheld Devices,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Mobile and Ubiquitous Multimedia,"Limassol, Cyprus",2010,9781450304245,,https://doi.org/10.1145/1899475.1899500;http://dx.doi.org/10.1145/1899475.1899500,10.1145/1899475.1899500,"Virtual reality panoramic images are becoming increasingly popular on handheld devices, but navigating them remains a challenge due to small screen sizes. In this paper, we present a formal evaluation and usability studies comparing two interaction concepts. In the first one, the device is seen as a static peephole and the data is moved behind it via touch screen-based scrolling. In the second one, a mobile phone's sensors are used to create a dynamic peephole that can be moved over static content. In the results of our formal analysis sensor-based dynamic peephole navigation performed twice as good in an orientation task, 75% better in an object size discrimination task, and was preferred by 80% of the users. Despite these advantages, additional usability studies indicate that if they are sitting, a majority of users resort to touch screen-based static peephole navigation when interacting. Our results therefore demonstrate benefits of dynamic peephole navigation for virtual reality panoramas but also illustrate its limitations depending on the current context of the user.","mobile interaction, VR panoramas, dynamic peephole navigation",MUM '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Campello RJ,Moulavi D,Zimek A,Sander J","Hierarchical Density Estimates for Data Clustering, Visualization, and Outlier Detection",ACM Trans. Knowl. Discov. Data,2015,10,1,,Association for Computing Machinery,"New York, NY, USA",,,,2015-07,,1556-4681,https://doi.org/10.1145/2733381;http://dx.doi.org/10.1145/2733381,10.1145/2733381,"An integrated framework for density-based cluster analysis, outlier detection, and data visualization is introduced in this article. The main module consists of an algorithm to compute hierarchical estimates of the level sets of a density, following Hartigan’s classic model of density-contour clusters and trees. Such an algorithm generalizes and improves existing density-based clustering techniques with respect to different aspects. It provides as a result a complete clustering hierarchy composed of all possible density-based clusters following the nonparametric model adopted, for an infinite range of density thresholds. The resulting hierarchy can be easily processed so as to provide multiple ways for data visualization and exploration. It can also be further postprocessed so that: (i) a normalized score of “outlierness” can be assigned to each data object, which unifies both the global and local perspectives of outliers into a single definition; and (ii) a “flat” (i.e., nonhierarchical) clustering solution composed of clusters extracted from local cuts through the cluster tree (possibly corresponding to different density thresholds) can be obtained, either in an unsupervised or in a semisupervised way. In the unsupervised scenario, the algorithm corresponding to this postprocessing module provides a global, optimal solution to the formal problem of maximizing the overall stability of the extracted clusters. If partially labeled objects or instance-level constraints are provided by the user, the algorithm can solve the problem by considering both constraints violations/satisfactions and cluster stability criteria. An asymptotic complexity analysis, both in terms of running time and memory space, is described. Experiments are reported that involve a variety of synthetic and real datasets, including comparisons with state-of-the-art, density-based clustering and (global and local) outlier detection methods.","unsupervised and semisupervised clustering, hierarchical and nonhierarchical clustering, Density-based clustering, data visualization, global/local outliers, outlier detection",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Min X,Zhai G,Gu K,Yang X",Fixation Prediction through Multimodal Analysis,ACM Trans. Multimedia Comput. Commun. Appl.,2016,13,1,,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,1551-6857,https://doi.org/10.1145/2996463;http://dx.doi.org/10.1145/2996463,10.1145/2996463,"In this article, we propose to predict human eye fixation through incorporating both audio and visual cues. Traditional visual attention models generally make the utmost of stimuli’s visual features, yet they bypass all audio information. In the real world, however, we not only direct our gaze according to visual saliency, but also are attracted by salient audio cues. Psychological experiments show that audio has an influence on visual attention, and subjects tend to be attracted by the sound sources. Therefore, we propose fusing both audio and visual information to predict eye fixation. In our proposed framework, we first localize the moving--sound-generating objects through multimodal analysis and generate an audio attention map. Then, we calculate the spatial and temporal attention maps using the visual modality. Finally, the audio, spatial, and temporal attention maps are fused to generate the final audiovisual saliency map. The proposed method is applicable to scenes containing moving--sound-generating objects. We gather a set of video sequences and collect eye-tracking data under an audiovisual test condition. Experiment results show that we can achieve better eye fixation prediction performance when taking both audio and visual cues into consideration, especially in some typical scenes in which object motion and audio are highly correlated.","saliency, attention fusion, eye fixation prediction, multimodal analysis, Audiovisual attention",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Calikli G,Law M,Bandara AK,Russo A,Dickens L,Price BA,Stuart A,Levine M,Nuseibeh B",Privacy Dynamics: Learning Privacy Norms for Social Software,,2016,,,47–56,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Symposium on Software Engineering for Adaptive and Self-Managing Systems,"Austin, Texas",2016,9781450341875,,https://doi.org/10.1145/2897053.2897063;http://dx.doi.org/10.1145/2897053.2897063,10.1145/2897053.2897063,"Privacy violations in online social networks (OSNs) often arise as a result of users sharing information with unintended audiences. One reason for this is that, although OSN capabilities for creating and managing social groups can make it easier to be selective about recipients of a given post, they do not provide enough guidance to the users to make informed sharing decisions. In this paper we present Privacy Dynamics, an adaptive architecture that learns privacy norms for different audience groups based on users' sharing behaviours. Our architecture is underpinned by a formal model inspired by social identity theory, a social psychology framework for analysing group processes and intergroup relations. Our formal model comprises two main concepts, the group membership as a Social Identity (SI) map and privacy norms as a set of conflict rules. In our approach a privacy norm is specified in terms of the information objects that should be prevented from flowing between two conflicting social identity groups. We implement our formal model by using inductive logic programming (ILP), which automatically learns privacy norms. We evaluate the performance of our learning approach using synthesised data representing the sharing behaviour of social network users.","adaptive privacy, inductive logic programming, online social networks, social identity theory",SEAMS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wittek P,Darányi S,Tan CL",Improving Text Classification by a Sense Spectrum Approach to Term Expansion,,2009,,,183–191,Association for Computational Linguistics,USA,,Proceedings of the Thirteenth Conference on Computational Natural Language Learning,"Boulder, Colorado",2009,9781932432299,,,,"Experimenting with different mathematical objects for text representation is an important step of building text classification models. In order to be efficient, such objects of a formal model, like vectors, have to reasonably reproduce language-related phenomena such as word meaning inherent in index terms. We introduce an algorithm for sense-based semantic ordering of index terms which approximates Cruse's description of a sense spectrum. Following semantic ordering, text classification by support vector machines can benefit from semantic smoothing kernels that regard semantic relations among index terms while computing document similarity. Adding expansion terms to the vector representation can also improve effectiveness. This paper proposes a new kernel which discounts less important expansion terms based on lexical relatedness.",,CoNLL '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Al-Humaimeedy AS,Fernández M",Enhancing the Specification and Verification Techniques of Multiparty Sessions in SOC,,2015,,,19–30,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th International Symposium on Principles and Practice of Declarative Programming,"Siena, Italy",2015,9781450335164,,https://doi.org/10.1145/2790449.2790515;http://dx.doi.org/10.1145/2790449.2790515,10.1145/2790449.2790515,"The Service Oriented Computing (SOC) paradigm is based on service composition, that is, loosely coupled autonomous heterogeneous services, which are collectively composed to implement a particular task. This paper presents a new calculus, called sbCSP, for SOC within the framework of CSP process algebra, showing how services can be defined, invoked, orchestrated and terminated within session hierarchies. We provide operational and denotational trace semantics for the new calculus, and discuss the relationship between the two semantics. We have implemented the extended calculus in FDR (the CSP model checker) and we have used it in a case study to illustrate the expressivity and simplicity of the session model and its reasoning techniques.","CSP, SOC calculi, service-oriented computing, SOC verification techniques, trace semantics, sessions",PPDP '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pound J,Mika P,Zaragoza H",Ad-Hoc Object Retrieval in the Web of Data,,2010,,,771–780,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th International Conference on World Wide Web,"Raleigh, North Carolina, USA",2010,9781605587998,,https://doi.org/10.1145/1772690.1772769;http://dx.doi.org/10.1145/1772690.1772769,10.1145/1772690.1772769,"Semantic Search refers to a loose set of concepts, challenges and techniques having to do with harnessing the information of the growing Web of Data (WoD) for Web search. Here we propose a formal model of one specific semantic search task: ad-hoc object retrieval. We show that this task provides a solid framework to study some of the semantic search problems currently tackled by commercial Web search engines. We connect this task to the traditional ad-hoc document retrieval and discuss appropriate evaluation metrics. Finally, we carry out a realistic evaluation of this task in the context of a Web search application.","semantic search, object retrieval, evaluation",WWW '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Book Chapter,Ralston A,Discrete Mathematics,,2003,,,587–593,John Wiley and Sons Ltd.,GBR,Encyclopedia of Computer Science,,,2003,9780470864128,,,,"Discrete mathematics encompasses those branches of mathematics that deal with discrete objects, in contrast to other branches, such as calculus and analysis, whose main concern is with continuous functions. Some branches of mathematics, such as numerical analysis and linear algebra, have both continuous and discrete components. Another, but somewhat simplistic, perspective on the contrast between discrete and continuous mathematics is that the underlying number system in continuous mathematics is usually the real numbers, while for discrete mathematics it is the integers. Because problems in discrete mathematics often involve the integers, which form an infinite set, discrete mathematics is not necessarily finite mathematics.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zarzycki A,Designing with Constraints Parametric BIM,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2011 Talks,"Vancouver, British Columbia, Canada",2011,9781450309745,,https://doi.org/10.1145/2037826.2037911;http://dx.doi.org/10.1145/2037826.2037911,10.1145/2037826.2037911,"While usually associated with the back-end of the design process (implementation), building information modeling (BIM) could also redefine the way design ideas are generated by bridging formal creativity with design and technological innovation. This is achieved through a close integration of generative tools with parametric capabilities and intelligent database-enriched digital objects.",,SIGGRAPH '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Kamran S,Dynamic Communities Formation through Semantic Tags,,2014,,,45–50,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Conference on World Wide Web,"Seoul, Korea",2014,9781450327459,,https://doi.org/10.1145/2567948.2567960;http://dx.doi.org/10.1145/2567948.2567960,10.1145/2567948.2567960,"Taggers in social tagging systems have the main role in giving identities to the objects. Tagged objects also represent perception of their taggers about them and can define identities of their taggers in return. Consequently, identities that are assigned to the objects and taggers have effect on the quality of their categorization and communities formation around them. Tags in social semantic tagging systems have formal definitions because they are mapped to the concepts that are defined in ontologies. Semantic tags are not only able to improve quality of tag assignments by solving some common tags ambiguity problems related to classic folksonomy systems (i.e., in particular polysemy and synonymy), but also to provide some meta data on top of the social relations based on contribution of taggers around semantic tags. Those meta data may be exploited to form dynamic communities which addresses the problems of lack of commonly agreed and evolving meaning of tags in social semantic tagging systems. This paper proposes an approach to form dynamic communities of related taggers around the tagged objects. Because our perceptions in each specific area of knowledge is evolving over time, the goal of our approach is also to evolve the represented knowledge in semantic tagging systems dynamically according to the latest perception of the related users.","emergent semantics, community formation, social semantic tagging systems, semantic tagging, collaborative tagging",WWW '14 Companion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Padula AD,Scott SD,Symes WW",A Software Framework for Abstract Expression of Coordinate-Free Linear Algebra and Optimization Algorithms,ACM Trans. Math. Softw.,2009,36,2,,Association for Computing Machinery,"New York, NY, USA",,,,2009-04,,0098-3500,https://doi.org/10.1145/1499096.1499097;http://dx.doi.org/10.1145/1499096.1499097,10.1145/1499096.1499097,"The Rice Vector Library is a collection of C++ classes expressing core concepts (vector, function,…) of calculus in Hilbert space with minimal implementation dependence, and providing standardized interfaces behind which to hide application-dependent implementation details (data containers, function objects). A variety of coordinate-free algorithms from linear algebra and optimization, including Krylov subspace methods and various relatives of Newton's method for nonlinear equations and constrained and unconstrained optimization, may be expressed purely in terms of this system of classes. The resulting code may be used without alteration in a wide range of control, design, and parameter estimation applications, in serial and parallel computing environments.","numerical optimization, Abstract numerical algorithms, complex simulation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Özdikiş Ö,Durak U,Oundefineduztüzün H",Tool Support for Transformation from an OWL Ontology to an HLA Object Model,,2010,,,,"ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)","Brussels, BEL",,Proceedings of the 3rd International ICST Conference on Simulation Tools and Techniques,"Torremolinos, Malaga, Spain",2010,9789639799875,,https://doi.org/10.4108/ICST.SIMUTOOLS2010.8678;http://dx.doi.org/10.4108/ICST.SIMUTOOLS2010.8678,10.4108/ICST.SIMUTOOLS2010.8678,"Designing simulation architectures based on domain models is a promising approach. Tools to support transformation of formalized domain models to design models are essential. Ontology languages offer a way of formally specifying the domain knowledge. We adopt a user-guided approach to model transformation, where the source is an OWL ontology and the target is an HLA Object Model, in particular, a federation object model (FOM). This paper presents a flexible transformation tool that enables the user to define transformations in terms of mappings from OWL constructs to HLA Object Model Template (OMT) constructs. The overall objective is to facilitate ontology-based model-driven development in distributed simulation.","model driven development, object models, high level architecture, ontology based simulation",SIMUTools '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nechitaylo I,Guzikova L",Depreciation in the Context of Pricing in Digital Economy,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Scientific Conference on Innovations in Digital Economy: SPBPU IDE-2020,"Saint, Petersburg, Russian Federation",2020,9781450388313,,https://doi.org/10.1145/3444465.3444500;http://dx.doi.org/10.1145/3444465.3444500,10.1145/3444465.3444500,"The paper studies the conditions allowing avoid generally recognized formal methods of depreciation in the long term pricing that helps to overcome the conventionality of distribution of capital expenditures by accounting periods. The paper also investigates which formal methods of depreciation have to be preferred from the standpoint of pricing when it is impossible or unreasonable to refrain from using these methods. The research methodology is based on the value-based management concept, implying the use of economic value added and market value added in management accounting. The object of the study is a hypothetical mass production company essentially similar to real companies operating in competitive markets of traditional industrial products during demand stability. Long-term price forecasts are made using double-declining balance method and annuity-based method of depreciation as well as DCF-based method where depreciation is not charged in management accounting, then statistical relations between the obtained price series are analyzed. It is shown that in demand stability, the prices obtained according to the annuity-based depreciation method have a closer relation and are more consistent with the prices based on DCF-models. It is concluded that when the carrying value of fixed assets can be appreciated based on the current market prices, the pricing using DCF-models is preferable. In this case, the formal methods of depreciation in management accounting are not necessary to be used. Otherwise, the pricing problem has to be tackled for every particular planning period and preference should be given to the annuity-based depreciation.","pricing, management accounting, market value added, economic value added, Depreciation",SPBPU IDE '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Khalidov V,Forbes F,Hansard M,Arnaud E,Horaud R",Detection and Localization of 3d Audio-Visual Objects Using Unsupervised Clustering,,2008,,,217–224,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Conference on Multimodal Interfaces,"Chania, Crete, Greece",2008,9781605581989,,https://doi.org/10.1145/1452392.1452438;http://dx.doi.org/10.1145/1452392.1452438,10.1145/1452392.1452438,"This paper addresses the issues of detecting and localizing objects in a scene that are both seen and heard. We explain the benefits of a human-like configuration of sensors (binaural and binocular) for gathering auditory and visual observations. It is shown that the detection and localization problem can be recast as the task of clustering the audio-visual observations into coherent groups. We propose a probabilistic generative model that captures the relations between audio and visual observations. This model maps the data into a common audio-visual 3D representation via a pair of mixture models. Inference is performed by a version of the expectation-maximization algorithm, which is formally derived, and which provides cooperative estimates of both the auditory activity and the 3D position of each object. We describe several experiments with single- and multiple-speaker detection and localization, in the presence of other audio sources.","audio-visual clustering, stereo vision, binaural hearing, mixture models",ICMI '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Son B,Park J",Haptic Feedback to the Palm and Fingers for Improved Tactile Perception of Large Objects,,2018,,,757–763,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology,"Berlin, Germany",2018,9781450359481,,https://doi.org/10.1145/3242587.3242656;http://dx.doi.org/10.1145/3242587.3242656,10.1145/3242587.3242656,"When one manipulates a large or bulky object, s/he utilizes tactile information at both fingers and the palm. Our goal is to efficiently convey contact information to a user's hand during interaction with a virtual object. We propose a haptic system that can provide haptic feedback to thumb/middle finger/index finger and on a palm. Our interface design utilizes a novel compact mechanism to provide haptic information to the palm. Also, we propose a haptic rendering strategy to calculate haptic feedback continuously. We demonstrate that cutaneous feedback on the palm improves the haptic perception of a large virtual object compared to when there is only kinesthetic feedback to the fingers.","haptics, global shape perception, wearable interface",UIST '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ishikawa T,Dobashi Y,Yue Y,Kakimoto M,Watanabe T,Kondo K,Iwasaki K,Nishita T",Visual Simulation of Glazed Frost,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2013 Posters,"Anaheim, California",2013,9781450323420,,https://doi.org/10.1145/2503385.2503400;http://dx.doi.org/10.1145/2503385.2503400,10.1145/2503385.2503400,"Glazed frost is a crystal clear ice and formed from supercooled raindrops that freeze when they hit object surfaces such as the ground and branches of trees. Simulation methods for formation of ice crystal, such as frost, on the surface of objects have been proposed by Kim et al. [Kim et al. 2004]. However, a supercooling state has to be considered for simulating freezing rain, and fluid simulation is required for reproducing the effect of raindrops running down on the ice surfaces. To our best knowledge, there has been no research presenting glazed frost by using a fluid simulation. We use the fluid simulation based on FLIP method [Zhu and Bridson 2005]. Hence, raindrops and obstacles are represented by particles which are used to calculate the advection term, and the update of velocity field are calculated by using grids except for advection term. We propose a method to create an animation of glazed frost formation by taking into account the heat transfer between particles and the outside grids.",,SIGGRAPH '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Silva AC,Borges MM",Hybrid Publishing Design Methods for Technical Books,,2015,,,411–417,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Technological Ecosystems for Enhancing Multiculturality,"Porto, Portugal",2015,9781450334426,,https://doi.org/10.1145/2808580.2808642;http://dx.doi.org/10.1145/2808580.2808642,10.1145/2808580.2808642,"We know that the printed book is a social, cultural and economic construction, but also an artifact (either printed or digital) that requires a deep knowledge in its production where design is key to the performance of the object.The starting point of this paper is the definition of technical books and its publishing field. Looking into their formal structures, we try to make an analysis of how technical books function today and how they are designed. We sought to characterize the program and the design methodology of a technical book in hybrid context and the possible models in terms of production, distribution and reading.","workflow, book design, publishing, technical book, E-book",TEEM '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Manh HT,Yeo J,Lee G",Saliency Detection by Tensor Voting Based Gaussian Modeling,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Ubiquitous Information Management and Communication,"Bali, Indonesia",2015,9781450333771,,https://doi.org/10.1145/2701126.2701169;http://dx.doi.org/10.1145/2701126.2701169,10.1145/2701126.2701169,"Salient object detection is a challenging task in field of object segmentation and recognition. Many works have been proposed but remaining serious limitations. The answers for question:\ How to highlight the entire salient object which has captured human eye?\"" is still unseen until now. In this paper",therefore,we propose a novel,efficient and simple saliency detection method using Gaussian Mixture Modeling based on tensor voting. At first,the color images are mapped into 2-D space in which tensor voting process is applied to find out extremes. Then,Gaussian Mixture Model (GMM) is estimated and for each pixel,the set of normalized likelihood measures to different Gaussian Models are calculated. The color saliency value measure and spatial saliency measure of each Gaussian model are evaluated based on its color distinctiveness and spatial distribution. Finally,"the final saliency map is generated by fusing color saliency map and spatial saliency map. We compare our algorithm to several states-of- the art saliency detection methods using the well-known 1000 available public images. The experimental results show that our method significantly outperforms the previous algorithm in both precision and recall. We also show the advantages of our work on object segmentation.""","segmentation, gaussian mixture model, visual saliency, object detection",IMCOM '15,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Breier J,Hudec L",Towards a Security Evaluation Model Based on Security Metrics,,2012,,,87–94,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th International Conference on Computer Systems and Technologies,"Ruse, Bulgaria",2012,9781450311939,,https://doi.org/10.1145/2383276.2383291;http://dx.doi.org/10.1145/2383276.2383291,10.1145/2383276.2383291,"Methods for risk evaluation often involve subjective criteria because this process is undertaken by a risk analyst influenced by his own knowledge and experience. The purpose of this work is to bring objectivity to this process and to provide a discrete-scale evaluation of implemented security controls. It provides results and a final score from a security attributes point of view, that is a quality ranking of confidentiality, integrity, availability, authenticity and non-repudiability within the organization. The assignment of security clauses from the ISO/IEC 27002:2005 standard to security attributes uses the Formal Concept Analysis method, which provides summarized and clear object-attribute classification.","information security, security standards, security metrics, security model, risk evaluation, formal concept analysis",CompSysTech '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Moy Y,Gem #147: Su(per)Btypes in Ada 2012 - Part 2,Ada Lett.,2018,37,2,30–31,Association for Computing Machinery,"New York, NY, USA",,,,2018-06,,1094-3641,https://doi.org/10.1145/3232693.3232700;http://dx.doi.org/10.1145/3232693.3232700,10.1145/3232693.3232700,"Let's get started? The previous Gem in this series showed how the aspect Static_Predicate can be used to state properties of scalar objects that should be respected at all times. This Gem is concerned with the Dynamic_Predicate aspect, which can be used on all type and subtype declarations (not just scalar ones). Consider for example a type Message encoding the dates when a message was sent and received, where dates are represented by strings, such as \1789-07-14\"" for the fourteenth of July 1789:""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Jacox EH,Samet H",Metric Space Similarity Joins,ACM Trans. Database Syst.,2008,33,2,,Association for Computing Machinery,"New York, NY, USA",,,,2008-06,,0362-5915,https://doi.org/10.1145/1366102.1366104;http://dx.doi.org/10.1145/1366102.1366104,10.1145/1366102.1366104,"Similarity join algorithms find pairs of objects that lie within a certain distance ϵ of each other. Algorithms that are adapted from spatial join techniques are designed primarily for data in a vector space and often employ some form of a multidimensional index. For these algorithms, when the data lies in a metric space, the usual solution is to embed the data in vector space and then make use of a multidimensional index. Such an approach has a number of drawbacks when the data is high dimensional as we must eventually find the most discriminating dimensions, which is not trivial. In addition, although the maximum distance between objects increases with dimension, the ability to discriminate between objects in each dimension does not. These drawbacks are overcome via the introduction of a new method called Quickjoin that does not require a multidimensional index and instead adapts techniques used in distance-based indexing for use in a method that is conceptually similar to the Quicksort algorithm. A formal analysis is provided of the Quickjoin method. Experiments show that the Quickjoin method significantly outperforms two existing techniques.","external memory algorithms, distance-based indexing, Similarity join, ranking, nearest neighbor queries, range queries",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lu Y,Liu RW,Chen F,Xie L",Learning a Deep Convolutional Network for Speckle Noise Reduction in Underwater Sonar Images,,2019,,,445–450,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 11th International Conference on Machine Learning and Computing,"Zhuhai, China",2019,9781450366007,,https://doi.org/10.1145/3318299.3318358;http://dx.doi.org/10.1145/3318299.3318358,10.1145/3318299.3318358,"Underwater sonar imaging system has been widely utilized to detect and identify the submerged objects of interest. However, imaging quality often suffers from the undesirable signal-dependent speckle noise during signal acquisition and transmission. The speckle noise will restrict the practical applications, such as object detection, tracking and recognition, etc. To enhance the sonar imaging performance, we propose a deep learning approach to directly estimate the speckle noise in logarithmic domain based on the convolutional neural network. Once the speckle noise is obtained, the latent sharp image can then be easily calculated according to the image degradation model. The patch-based loss function, i.e., structural similarity metric, is adopted to preserve the important geometrical structures during speckle noise reduction. Experiments have been implemented on different noise levels to demonstrate the effectiveness of the proposed deep learning approach. Experimental results have illustrated that it outperforms several widely-used speckle noise reduction methods.","deep learning, speckle noise reduction, Underwater sonar image, conventional neural network, image restoration",ICMLC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang Z,Weng D",Passive Haptics Based MR System for Geography Teaching,,2016,,,23–29,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry - Volume 1,"Zhuhai, China",2016,9781450346924,,https://doi.org/10.1145/3013971.3013995;http://dx.doi.org/10.1145/3013971.3013995,10.1145/3013971.3013995,"Passive haptics in an alternative way to provide the user with realistic haptic feedback with a low cost comparing to device-based active haptics. This paper presents a mixed reality system with passive haptics integration that supports bare-hand interaction for users to see and touch virtual objects in immersive virtual environment (IVE). With the educational potential, the purposed system is applied to geography teaching. The prototype combines feature-based visual tracking for user's head and objects in the real environment with free-hand motion detection via a depth camera, thus user can see both their hands and objects in the virtual environment. A study of virtual teaching of geography of Germany was conducted, 18 subjects participated in the formal experiments which include three different learning environments. The results showed that the participants learning in the virtual environment with passive haptics consume more time than the virtual environment with free-hand gesture in finishing geography teaching tasks which is contrary to the expected result. The reasons are discussed in detail. Furthermore, quality of memorizing geographical knowledge in the group with passive haptic feedback exceeds that in the group without.","interactive learning environments, mixed reality, geography teaching, human-computer interaction, passive haptics",VRCAI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jung Y,Behr J",Towards a New Camera Model for X3D,,2009,,,79–82,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th International Conference on 3D Web Technology,"Darmstadt, Germany",2009,9781605584324,,https://doi.org/10.1145/1559764.1559777;http://dx.doi.org/10.1145/1559764.1559777,10.1145/1559764.1559777,"Creating and setting the right parameters for the virtual camera is crucial for any content creation process. However, this is not easy since most current camera models, including the X3D Viewpoint, use a 3D position and orientation in 3D space to define the final visualized image. People use authoring tools or simple interactive navigation methods (e.g. \lookAt\"" or \""showAll\"") to ease the process but at the end they still move a 6D (translation and rotation) camera beacon to get the final image. We thus propose a new X3D camera model",the CinematographicViewpoint node,which does not force the content creator to move the camera but allows the author to directly define what objects he would like to see on the screen. We borrow established techniques from the film area (e.g. rule of thirds and line of action) that allow defining objects and object-relations,which the camera model will use to automatically calculate the final transformation in space. The new camera model includes additionally a model for global visual effects (e.g. motion blur and depth of field),which allows incorporating classical film effects to real-time scenes. Both approaches combined allow content creators building visual results and camera movements that are closer to traditional filming much easier. The proposed approach also supports automatic camera movements that are bound to interactive content,"which has not been possible before.""","effects, camera placement, cinematography, X3D",Web3D '09,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Riccobene E,Scandurra P",Formal Modeling Self-Adaptive Service-Oriented Applications,,2015,,,1704–1710,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th Annual ACM Symposium on Applied Computing,"Salamanca, Spain",2015,9781450331968,,https://doi.org/10.1145/2695664.2695772;http://dx.doi.org/10.1145/2695664.2695772,10.1145/2695664.2695772,"In the context of modern service-oriented applications, components must be able to autonomously adapt their behavior in response to rapidly changing environment and business conditions. Formal frameworks for modeling self-adaptive behavior of service-oriented components (SOCs) are critically required to assure quality properties.In this paper we show how SCA-ASM, a lightweight formal framework for modeling and executing service-oriented applications, can be used to express adaptive behavior of service components. We explain how modeling an SCAASM component able to monitor and react to environmental changes (context-awareness) and to internal changes (self-awareness), and present the operators for expressing and coordinating self-adaptive behaviors in a distributed setting.","service-oriented applications, SCA-ASM, formal modeling, self-adaptation",SAC '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wei F,Li W,Lu Q,He Y",Query-Sensitive Mutual Reinforcement Chain and Its Application in Query-Oriented Multi-Document Summarization,,2008,,,283–290,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st Annual International ACM SIGIR Conference on Research and Development in Information Retrieval,"Singapore, Singapore",2008,9781605581644,,https://doi.org/10.1145/1390334.1390384;http://dx.doi.org/10.1145/1390334.1390384,10.1145/1390334.1390384,"Sentence ranking is the issue of most concern in document summarization. Early researchers have presented the mutual reinforcement principle (MR) between sentence and term for simultaneous key phrase and salient sentence extraction in generic single-document summarization. In this work, we extend the MR to the mutual reinforcement chain (MRC) of three different text granularities, i.e., document, sentence and terms. The aim is to provide a general reinforcement framework and a formal mathematical modeling for the MRC. Going one step further, we incorporate the query influence into the MRC to cope with the need for query-oriented multi-document summarization. While the previous summarization approaches often calculate the similarity regardless of the query, we develop a query-sensitive similarity to measure the affinity between the pair of texts. When evaluated on the DUC 2005 dataset, the experimental results suggest that the proposed query-sensitive MRC (Qs-MRC) is a promising approach for summarization.","ranking algorithms, mutual reinforcement chain, query-sensitive similarity, query-oriented summarization",SIGIR '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hardin DS,Hardin SS","Efficient, Formally Verifiable Data Structures Using ACL2 Single-Threaded Objects for High-Assurance Systems",,2009,,,100–105,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Eighth International Workshop on the ACL2 Theorem Prover and Its Applications,"Boston, Massachusetts, USA",2009,9781605587424,,https://doi.org/10.1145/1637837.1637853;http://dx.doi.org/10.1145/1637837.1637853,10.1145/1637837.1637853,"Classical data structures such as stacks, queues, and double-ended queues (deques) find broad use in security-critical applications. At the highest Evaluation Assurance Level (EAL) of the Common Criteria, such data structures must be formally specified, and proven to meet their specifications. Formal verification systems can readily reason about unbounded, functional data structures. However, such data structures are in the main not appropriate for direct implementation in high-confidence software systems, both because of their unbounded nature, and also due to the complexity of the functional forms (e.g., the use of two lists, one reversed, to implement a deque). We will show how a formally verified data structure specified using the ACL2 single-threaded object facility can be much more readily translated into highassurance implementations expressed in conventional programming languages. Finally, we show how this translated data structure code can be compiled into efficient machine code for a common embedded microprocessor using a verified compiler, and executed on an EAL6+ verified operating system.","deque, data structures, theorem proving, high assurance, certification, ACL2",ACL2 '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Reutelshoefer J,Striffler A,Lemmerich F,Puppe F",Incremental Compilation of Knowledge Documents for Markup-Based Closed-World Authoring,,2011,,,81–88,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Sixth International Conference on Knowledge Capture,"Banff, Alberta, Canada",2011,9781450303965,,https://doi.org/10.1145/1999676.1999692;http://dx.doi.org/10.1145/1999676.1999692,10.1145/1999676.1999692,"Text-based authoring using knowledge markups is an increasingly popular editing paradigm in manual knowledge acquisition. Closed world authoring environments support the user to form a coherent knowledge base by checking the referenced objects against a set of declared domain objects. In this scenario, the task of efficient translation (compilation) of the text sources is non-trivial. Additionally, in real-world applications frequent small changes are performed on the source documents and instant feedback to the author is crucial. Therefore, a scalable compilation into the target knowledge representations is necessary. In this paper, we introduce a general algorithm for the incremental compilation of knowledge documents, that analyzes the current document modifications and performs minimal updates on the knowledge base. We provide a formal proof of the correctness of the algorithm and show the effectiveness of the approach in several case studies, using various kinds of knowledge representations and markups.","source compilation, knowledge acquisition, knowledge markup",K-CAP '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lee C,Chen F,Roşu G",Mining Parametric Specifications,,2011,,,591–600,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd International Conference on Software Engineering,"Waikiki, Honolulu, HI, USA",2011,9781450304450,,https://doi.org/10.1145/1985793.1985874;http://dx.doi.org/10.1145/1985793.1985874,10.1145/1985793.1985874,"Specifications carrying formal parameters that are bound to concrete data at runtime can effectively and elegantly capture multi-object behaviors or protocols. Unfortunately, parametric specifications are not easy to formulate by nonexperts and, consequently, are rarely available. This paper presents a general approach for mining parametric specifications from program executions, based on a strict separation of concerns: (1) a trace slicer first extracts sets of independent interactions from parametric execution traces; and (2) the resulting non-parametric trace slices are then passed to any conventional non-parametric property learner. The presented technique has been implemented in jMiner, which has been used to automatically mine many meaningful and non-trivial parametric properties of OpenJDK 6.","dynamic analysis, parametric specifications",ICSE '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nguyen V,Bodenreider O,Sheth A",Don't like RDF Reification? Making Statements about Statements Using Singleton Property,,2014,,,759–770,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Conference on World Wide Web,"Seoul, Korea",2014,9781450327442,,https://doi.org/10.1145/2566486.2567973;http://dx.doi.org/10.1145/2566486.2567973,10.1145/2566486.2567973,"Statements about RDF statements, or meta triples, provide additional information about individual triples, such as the source, the occurring time or place, or the certainty. Integrating such meta triples into semantic knowledge bases would enable the querying and reasoning mechanisms to be aware of provenance, time, location, or certainty of triples. However, an efficient RDF representation for such meta knowledge of triples remains challenging. The existing standard reification approach allows such meta knowledge of RDF triples to be expressed using RDF by two steps. The first step is representing the triple by a Statement instance which has subject, predicate, and object indicated separately in three different triples. The second step is creating assertions about that instance as if it is a statement. While reification is simple and intuitive, this approach does not have formal semantics and is not commonly used in practice as described in the RDF Primer. In this paper, we propose a novel approach called Singleton Property for representing statements about statements and provide a formal semantics for it. We explain how this singleton property approach fits well with the existing syntax and formal semantics of RDF, and the syntax of SPARQL query language. We also demonstrate the use of singleton property in the representation and querying of meta knowledge in two examples of Semantic Web knowledge bases: YAGO2 and BKR. Our experiments on the BKR show that the singleton property approach gives a decent performance in terms of number of triples, query length and query execution time compared to existing approaches. This approach, which is also simple and intuitive, can be easily adopted for representing and querying statements about statements in other knowledge bases.","SPARQL, meta triples, RDF, reification, semantic web, RDF singleton property",WWW '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kamina T,Aotani T",TinyCORP: A Calculus for Context-Oriented Reactive Programming,,2019,,,1–8,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Workshop on Context-Oriented Programming,"London, United Kingdom",2019,9781450368636,,https://doi.org/10.1145/3340671.3343356;http://dx.doi.org/10.1145/3340671.3343356,10.1145/3340671.3343356,"Current trend of seamless connections between computing systems and their surrounding environments requires software to be more reactive and adaptable, and reactive programming (RP) and context-oriented programming (COP) have been studied to directly support reactive behavior and dynamic adaptation. Sometimes reactive behavior and dynamic adaptation interact with each other. One issue of such interactions is how to avoid a loop of reactive behavior and dynamic adaptation when there are mutually recursive dependencies between them. This paper proposes TinyCORP, a core calculus for context-oriented reactive programming that is designed in a main-stream, general-purpose language setting. This calculus is expressive enough to represent both features of signals (i.e., time-varying values in RP) and layer-based partial methods in COP, and their interactions including the ability to specify the mutually recursive dependencies between dynamic adaptation and reactive behavior. We also demonstrate that the computation in TinyCORP do not result in the loop of reactive behavior and dynamic adaptation.","Featherweight Java, signals, context-oriented programming",COP '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Howe DJ,Higher-Order Abstract Syntax in Classical Higher-Order Logic,,2009,,,1–11,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice,"Montreal, Quebec, Canada",2009,9781605585291,,https://doi.org/10.1145/1577824.1577826;http://dx.doi.org/10.1145/1577824.1577826,10.1145/1577824.1577826,"Higher-Order Abstract Syntax, or HOAS, is a technique for using a higher-order logic as a metalanguage for an object language with binding operators. It avoids formalizing syntactic details related to variable binding. This paper gives an extension to classical higher-order logic that supports HOAS. The logic we work with is the core of the logics employed in the widely used systems HOL and Isabelle/HOL. The extension adds recursive types, and a new type constructor for parametric functions. Using these additions, we can solve, for example, the archetypal recursive type equation for a HOAS representation of the syntax of the untyped lambda-calculus: T = (T x T) + (T ↪ T), where the function type is the new parametric one. The usual HOAS induction principles can be derived. The bulk of the technical development in the paper is a semantics of the new logic, extending the usual set-theoretic semantics of classical higher-order logic.","induction, logical frameworks, higher-order abstract syntax, interactive theorem proving, name-binding",LFMTP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fileto R,Raffaetà A,Roncato A,Sacenti JA,May C,Klein D",A Semantic Model for Movement Data Warehouses,,2014,,,47–56,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th International Workshop on Data Warehousing and OLAP,"Shanghai, China",2014,9781450309998,,https://doi.org/10.1145/2666158.2666180;http://dx.doi.org/10.1145/2666158.2666180,10.1145/2666158.2666180,"Despite recent progresses in methods for processing data about the movement of objects in the geographic space, some fundamental issues remain unresolved. One of them is how to describe movement segments (e.g., semantic trajectories, episodes like stops and moves) and diverse movement patterns (e.g., moving clusters, hotel-restaurant-shop-hotel), with formal semantic descriptions. Another issue is how to arrange descriptive data and measures in a Movement Data Warehouse (MDW) for powerful information analyses and reasonable performance. This paper introduces general definitions for movement segments, movement patterns, their categories and hierarchies. The proposed constructs are semantically enriched with references to concepts (categories) and/or instances of these concepts (objects) arranged in distinct hierarchies. Based on these constructs, we propose a semantic multidimensional model for MDW. A case study illustrates the expressiveness of the proposal for analyzing movement data collected via social media and semantically enriched with Linked Open Data (LOD).","social media posts, moving object trajectories, LOD, multidimensional model, analytical queries, semantic annotations",DOLAP '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Khryashchev V,Ivanovsky L,Priorov A",Deep Learning for Real-Time Robust Facial Expression Analysis,,2018,,,66–70,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Machine Vision and Applications,"Singapore, Singapore",2018,9781450363815,,https://doi.org/10.1145/3220511.3220518;http://dx.doi.org/10.1145/3220511.3220518,10.1145/3220511.3220518,"The aim of this investigation is to classify real-life facial images into one of six types of emotions. For solving this problem, we propose to use deep machine learning algorithms and convolutional neural network (CNN). CNN is a modern type of neural network, which allows for rapid detection of various objects, as well as to make an effective object classification. For acceleration of CNN learning stage, we use supercomputer NVIDIA DGX-1. This process was implemented in parallel on a large number of independent streams on GPU. Numerical experiments for algorithms were performed on the images of Multi-Pie image database with various lighting of scene and angle rotation of head. For developed models, several metrics of quality were calculated. The designing algorithm was used in real-time video processing in human-computer interaction systems. Moreover, expression recognition can apply in such fields as retail analysis, security, video games, animations, psychiatry, automobile safety, educational software, etc.","Deep learning, real-time video analysis, facial expression analysis, convolutional neural network",ICMVA 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Riccobene E,Scandurra P",An ASM-Based Executable Formal Model of Service-Oriented Component Interactions and Orchestration,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Second International Workshop on Behaviour Modelling: Foundation and Applications,"Paris, France",2010,9781605589619,,https://doi.org/10.1145/1811147.1811152;http://dx.doi.org/10.1145/1811147.1811152,10.1145/1811147.1811152,"Formal design methods, that might serve as a basis for specifying and analyzing abstract models of service orchestrations, are needed to complement the wide range of domain-specific languages (mainly based on graphical notations) that are currently being defined for engineering service-oriented systems. This paper presents a formal and executable semantic framework for UML4SOA models of service-oriented systems. The UML4SOA language is a UML profile developed in the EU SENSORIA project for modeling services behavior focusing on service orchestration aspects. We complement the graphical model of a service orchestration scenario with a formal description that is suitable for rigorous execution-platform-independent analysis. We map the behavioral primitives of UML4SOA activity diagrams into a particular class of Abstract State Machines (ASMs) able to model notions of service interactions and orchestrations.","UML4SOA, Abstract State Machines, service behaviour modeling, service-oriented computing",BM-FA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liang AY,Low MY,Lees MH,Cai W,Zhou S",A Framework of Intelligent Environment with Smart-Active Objects (IESAO) for Flexible and Efficient Crowd Simulation,,2010,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2010 Spring Simulation Multiconference,"Orlando, Florida",2010,9781450300698,,https://doi.org/10.1145/1878537.1878557;http://dx.doi.org/10.1145/1878537.1878557,10.1145/1878537.1878557,"Agent-based crowd simulation has been widely applied in the analysis of evacuation safety under disastrous and terrorist circumstances. In crowd simulation, the virtual environment plays an important role in influencing human behavior and defining the scenario. The concepts of informed environment and smart objects have been adopted to improve the realism of the simulation by embedding semantic information in the environment. However, there is no formal approach of using these concepts in crowd simulation. In this paper, we propose a flexible and efficient framework of Intelligent Environment with Smart and Active Objects (IESAO). We properly define different types of entities and interactions, and describe the approach of modeling environment-related behavior in the intelligent environment. This framework gives a new perspective of modeling human behavior in the design phase. An implementation and a case study are discussed to show the flexibility and efficiency of this framework.","smart and active object, intelligent environment, human behavior modeling, agent-based simulation, crowd simulation",SpringSim '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zook A,Magerko B,Riedl M",Formally Modeling Pretend Object Play,,2011,,,147–156,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM Conference on Creativity and Cognition,"Atlanta, Georgia, USA",2011,9781450308205,,https://doi.org/10.1145/2069618.2069644;http://dx.doi.org/10.1145/2069618.2069644,10.1145/2069618.2069644,"We address the problem of building computational agents that are capable of play. Existing research has examined the forms, characteristics, and processes involved in various kinds of play at a high level. However, this research does not provide a unified framework at a level of detail sufficient for building computational agents that can play. As a step toward addressing this gap we synthesize diverse research on pretend play to recognize important components of pretend play agents. We also develop a formal model of one key component of pretend play, pretend object play, and present a computational implementation of this model. Our work provides initial criteria for the content and processes necessary for pretend play agents.","creativity, artificial intelligence, games, play",C&C '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lee TI,Wang MY,Hsu CY,Chen YT,Chien CY",The Backpacking Travelers' Usage Value and Experience on Tourism Efficiency by Using Travel Apps,,2019,,,332–335,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 3rd International Conference on Education and Multimedia Technology,"Nagoya, Japan",2019,9781450372107,,https://doi.org/10.1145/3345120.3345186;http://dx.doi.org/10.1145/3345120.3345186,10.1145/3345120.3345186,"This study focuses on the backpacking travelers in Taiwan as the research objects to explore the causal relationship between the usage value of the travel APP in the journey, the experience and the travel efficiency variables. In this study, the Internet questionnaire survey was used to collect and analyze the data. The objects of research were the travel APP users in Taiwan, and the samples were taken by convenience sampling. A total of 500 formal questionnaires were collected, valid samples with 305 people, the effective response rate is 61%, the data was analyzed by classical correlation analysis and multiple stepwise regression analysis. The research results show that through the factors analysis, there is a positive correlation between the usage value of Travel APP and the experience, indicated that with the higher usage value, the users had higher experience. The usage value of the Travel APP and the experience are effective on tourism efficiency.","APP, Travel, Canonical correlation",ICEMT 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cullen B,Galperin D,Collins K,Kapralos B,Hogue A",The Effects of Audio on Depth Perception in S3D Games,,2012,,,32–39,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th Audio Mostly Conference: A Conference on Interaction with Sound,"Corfu, Greece",2012,9781450315692,,https://doi.org/10.1145/2371456.2371461;http://dx.doi.org/10.1145/2371456.2371461,10.1145/2371456.2371461,"Although studies have examined sound localization or stereoscopic perception, few have investigated how these phenomena work together. Studies that examine 2D imagery and sound interaction have highlighted numerous phenomena in the temporal, spatial, and the formal domains of each medium. With the resurgence of interest in stereoscopic 3D (S3D), research into the combined effects of S3D and sound is of importance.Here we present the results of an experiment that examined the effects of sound on depth perception in relation to S3D video game imagery. Our aim was to answer the question: \can a sound's timbre and/or the addition of distance audio effects influence the user's depth perception accuracy?\"" Results suggest that depth perception is affected by sound",were sound can distort the apparent depth of audible S3D objects. Results also suggest that audio effects,specifically frequency fall-off over distance effects,"can also influence the apparent depth of S3D objects.""","S3D, multimodality, stereoscopy, depth perception, sound, audio, music, 3D, video games",AM '12,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jia S,Koh H,Pomplun M",Gaze Tracking Accuracy Maintenance Using Traffic Sign Detection,,2018,,,87–91,Association for Computing Machinery,"New York, NY, USA",,Adjunct Proceedings of the 10th International Conference on Automotive User Interfaces and Interactive Vehicular Applications,"Toronto, ON, Canada",2018,9781450359474,,https://doi.org/10.1145/3239092.3265947;http://dx.doi.org/10.1145/3239092.3265947,10.1145/3239092.3265947,"Eye tracking technology is becoming an important component of Advanced Driver Assistance Systems. Unfortunately, eye tracking systems require calibration to correctly associate pupil positions with gaze directions, and periodic calibration would be necessary because the accuracy will deteriorate overtime. This routine reduces the usability and practicability of in-vehicle eye tracking technology. We propose an approach to automatically perform real-time eye tracking calibration. We apply an object detection algorithm to continually detect objects that would likely attract the drivers' attention, such as traffic signs and lights. Those are, in turn, used as moving stimuli for the gaze accuracy maintenance procedure. The error vectors between recorded fixations and moving targets are calculated immediately and the weighted average of them is used to compensate for the offset of fixations in real-time. We evaluated our method both on laboratory data and real driving data. The results show that we can effectively reduce the gaze tracking errors.","In-vehicle eye tracking, Eye tracking calibration",AutomotiveUI '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Umar MM,De Silva LC",Fire Boundary Detection Method Using a Unique Structure from Motion for Non-Rigid Bodies Algorithm (SFM-NRBA),,2017,,,74–78,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Signal Processing Systems,"Auckland, New Zealand",2017,9781450353847,,https://doi.org/10.1145/3163080.3163100;http://dx.doi.org/10.1145/3163080.3163100,10.1145/3163080.3163100,"Image processing has been widely used in various applications of object detections based on edges, motion and color detection. However edge, motion and color detection methods alone cannot accurately detect and identify events like the onset of fire in a scene. In order to detect and identify fires by using video we propose a technique using three steps search algorithms and structure from motion (SFM). Here in this paper we introduce a unique algorithm known as SFM for non-rigid bodies (SFM-NRB) algorithm. In this algorithm, we calculate a randomness figure of an object boundary to differentiate fire from none fire event. Novelty of this proposal is its ability to detect the onset of fires in an image by using a combination of simple three step search algorithm and randomness figure of object boundaries even under complex static and dynamic background conditions.","Image Analysis, Image Processing, Motion detection, Structure from Motion, Three step search",ICSPS 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fiore M,Saville P",Coherence and Normalisation-by-Evaluation for Bicategorical Cartesian Closed Structure,,2020,,,425–439,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th Annual ACM/IEEE Symposium on Logic in Computer Science,"Saarbrücken, Germany",2020,9781450371049,,https://doi.org/10.1145/3373718.3394769;http://dx.doi.org/10.1145/3373718.3394769,10.1145/3373718.3394769,"We present two proofs of coherence for cartesian closed bicategories. Precisely, we show that in the free cartesian closed bicategory on a set of objects there is at most one structural 2-cell between any parallel pair of 1-cells. We thereby reduce the difficulty of constructing structure in arbitrary cartesian closed bicategories to the level of 1-dimensional category theory. Our first proof follows a traditional approach using the Yoneda lemma. For the second proof, we adapt Fiore's categorical analysis of normalisation-by-evaluation for the simply-typed lambda calculus. Modulo the construction of suitable bicategorical structures, the argument is not significantly more complex than its 1-categorical counterpart. It also opens the way for further proofs of coherence using (adaptations of) tools from categorical semantics.","normalisation, type theory, cartesian closure, coherence, bicategories, normalisation-by-evaluation",LICS '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Demetrescu C,Finocchi I,Ribichini A",Reactive Imperative Programming with Dataflow Constraints,ACM Trans. Program. Lang. Syst.,2014,37,1,,Association for Computing Machinery,"New York, NY, USA",,,,2014-11,,0164-0925,https://doi.org/10.1145/2623200;http://dx.doi.org/10.1145/2623200,10.1145/2623200,"Dataflow languages provide natural support for specifying constraints between objects in dynamic applications, where programs need to react efficiently to changes in their environment. In this article, we show that one-way dataflow constraints, largely explored in the context of interactive applications, can be seamlessly integrated in any imperative language and can be used as a general paradigm for writing performance-critical reactive applications that require efficient incremental computations. In our framework, programmers can define ordinary statements of the imperative host language that enforce constraints between objects stored in special memory locations designated as “reactive.” Reactive objects can be of any legal type in the host language, including primitive data types, pointers, arrays, and structures. Statements defining constraints are automatically re-executed every time their input memory locations change, letting a program behave like a spreadsheet where the values of some variables depend on the values of other variables. The constraint-solving mechanism is handled transparently by altering the semantics of elementary operations of the host language for reading and modifying objects. We provide a formal semantics and describe a concrete embodiment of our technique into C/C++, showing how to implement it efficiently in conventional platforms using off-the-shelf compilers. We discuss common coding idioms and relevant applications to reactive scenarios, including incremental computation, observer design pattern, data structure repair, and software visualization. The performance of our implementation is compared to problem-specific change propagation algorithms, as well as to language-centric approaches such as self-adjusting computation and subject/observer communication mechanisms, showing that the proposed approach is efficient in practice.","Reactive programming, imperative programming, data structure repair, software visualization, dataflow programming, constraint solving, one-way dataflow constraints, observer design pattern, incremental computation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang X,Zhou W,Shu N,Zhang H",A Fast and Efficient Local Outlier Detection in Data Streams,,2019,,,111–116,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 International Conference on Image, Video and Signal Processing","Shanghai, China",2019,9781450361750,,https://doi.org/10.1145/3317640.3317653;http://dx.doi.org/10.1145/3317640.3317653,10.1145/3317640.3317653,"Outlier detection in data streams is used in many applications, such as network flow monitoring, stock trading fluctuation detection and network intrusion detection [1]. These applications require that the algorithms finish outlier detection effectively in a limited amount of time and memory space. Local Outlier Factor (LOF) is a fundamental density-based outlier detection algorithm [2], it determines whether an object is an outlier by calculating LOF score of each observer. There are many LOF-based algorithms that have achieved excellent results with respect to outlier detection in data streams, while most of existing LOF-based algorithms have problems with excessive computation. In this paper, we propose a fast outlier detection algorithm in data streams, the algorithm effectively reduces the LOF calculation of the whole data by Z-score pruning. The algorithm consists of three phases. Firstly, generate the prediction data through the generator. Secondly, judge whether the observation object is a potential outlier by the Z-score of the residual from the origin value and the prediction value. Finally, calculate the LOF of the observation object in the current time window according to the judgment result of the previous step. It is proved by experiments that our algorithm effectively reduces the detection time consumption through Z-score pruning under the condition of ensuring the detection accuracy.","LOF-based, Outlier Detection, Data streams, Z-score Pruning",IVSP 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Lafuente AL,DisCoTec 2019: The 14th International Federated Conference on Distributed Computing Techniques,ACM SIGLOG News,2019,6,4,24–25,Association for Computing Machinery,"New York, NY, USA",,,,2019-11,,,https://doi.org/10.1145/3373394.3373398;http://dx.doi.org/10.1145/3373394.3373398,10.1145/3373394.3373398,"DisCoTec, the International Federated Conference on Distributed Computing Techniques, is one of the major annual events sponsored by the International Federation for Information Processing (IFIP). It comprises three conferences: COORDINATION, the IFIP WG6.1 International Conference on Coordination Models and Languages, DAIS, the IFIP WG6.1 International Conference on Distributed Applications and Interoperable Systems, and FORTE, the IFIP WG6.1 International Conference on Formal Techniques for Distributed Objects, Components and Systems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Carreiro F,Facchini A,Venema Y,Zanasi F",Weak MSO: Automata and Expressiveness modulo Bisimilarity,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Joint Meeting of the Twenty-Third EACSL Annual Conference on Computer Science Logic (CSL) and the Twenty-Ninth Annual ACM/IEEE Symposium on Logic in Computer Science (LICS),"Vienna, Austria",2014,9781450328869,,https://doi.org/10.1145/2603088.2603101;http://dx.doi.org/10.1145/2603088.2603101,10.1145/2603088.2603101,"We prove that the bisimulation-invariant fragment of weak monadic second-order logic (WMSO) is equivalent to the fragment of the modal μ-calculus where the application of the least fixpoint operator μp.ϕ is restricted to formulas ϕ that are continuous in p. Our proof is automata-theoretic in nature; in particular, we introduce a class of automata characterizing the expressive power of WMSO over tree models of arbitrary branching degree. The transition map of these automata is defined in terms of a logic FOE1∞ that is the extension of first-order logic with a generalized quantifier ∃∞, where ∃∞x.ϕ means that there are infinitely many objects satisfying ϕ. An important part of our work consists of a model-theoretic analysis of FOE1∞.","characterisation theorem, modal mu-calculus, automata theory, bisimulation invariance, MSO-automata, WMSO, weak monadic second-order, Janin-Walukiewicz theorem",CSL-LICS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Murray-Rust D,Robertson D",LSCitter: Building Social Machines by Augmenting Existing Social Networks with Interaction Models,,2014,,,875–880,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Conference on World Wide Web,"Seoul, Korea",2014,9781450327459,,https://doi.org/10.1145/2567948.2578832;http://dx.doi.org/10.1145/2567948.2578832,10.1145/2567948.2578832,"We present LSCitter, an implemented framework for supporting human interaction on social networks with formal models of interaction, designed as a generic tool for creating social machines on existing infrastructure. Interaction models can be used to choreograph distributed systems, providing points of coordination and communication between multiple interacting actors. While existing social networks specify how interactions happen---who messages go to and when, the effects of carrying out actions---these are typically implicit, opaque and non user-editable. Treating interaction models as first class objects allows the creation of electronic institutions, on which users can then choose the kinds of interaction they wish to engage in, with protocols which are explicit, visible and modifiable. However, there is typically a cost to users to engage with these institutions. In this paper we introduce the notion of \shadow institutions\""",where actions on existing social networks are mapped onto formal interaction protocols,allowing participants access to computational intelligence in a seamless,"zero-cost manner to carry out computation and store information.""","social machines, social networks, coordination, socio-technical systems",WWW '14 Companion,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang K,Yu Q",Accurate 3D Object Measurement and Inspection Using Structured Light Systems,,2011,,,221–227,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Conference on Computer Systems and Technologies,"Vienna, Austria",2011,9781450309172,,https://doi.org/10.1145/2023607.2023646;http://dx.doi.org/10.1145/2023607.2023646,10.1145/2023607.2023646,"A Structured Light System (SLS) is a fast and flexible optical method for measuring the 3D shape of objects. The dense point cloud resulted accurately describes the shape information of the object. The information can be used in many applications, such as generating CAD models, measuring shapes and inspecting qualities. The desired geometrical information of positions, poses, distances, angles, profiles etc. can conveniently be extracted from the measurement result. It is also possible to calculate and visualize the deviation between a measurement and a CAD model. In this paper, we present techniques, which lead to development of practical 3D machine vision systems in a different way than traditional ones. We have developed low cost and user-friendly 3D machine vision systems with off-the-shelf components based on Structured Light Systems (also known as Fringe Projection Systems) suitable for automated quality inspection and shape measurement. Two cases are presented for demonstrating the successful implementation.","optical measurement, fringe projection systems, 3D computer vision, structured light systems, quality inspection",CompSysTech '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ataullah AA,Tompa FW",Business Policy Modeling and Enforcement in Databases,Proc. VLDB Endow.,2011,4,11,921–931,VLDB Endowment,,,,,2011-08,,2150-8097,https://doi.org/10.14778/3402707.3402730;http://dx.doi.org/10.14778/3402707.3402730,10.14778/3402707.3402730,"Database systems are the central information repositories for businesses and are subject to a wide array of policies, rules and requirements. The spectrum of business level constraints implemented within database systems has expanded from classical access control to include auditing, usage control, privacy management, and records retention. The lack of a systematic mechanism of integrating and reasoning about such a diverse set of policies manifested as database level constraints makes corporate policy management a chaotic process.In this paper we propose a general purpose policy modeling and constraint management framework that can integrate numerous aspects of business level requirements within database systems. Our proposed solution relies on a finite state modeling language for business level policies, in which users can declaratively express rules related to the normal workflow of a business process as well as specifying any undesirable states of business objects contained in a database system. The proposed system is then able to translate these policies into low level temporal integrity constraints that prevent policy violations and ensure that business objects and artifacts follow their mandated lifecycles. A formal layer for reasoning allows policy makers to discover unenforceable and conflicting policies, providing the basis to guarantee compliance for a wide array of rules that may need to be enforced on complex business objects stored in relational database systems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Duan Y,Xiong Y,Zhang Y,Fu Y,Zhu Y",HSGMP: Heterogeneous Scene Graph Message Passing for Cross-Modal Retrieval,,2021,,,82–91,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2021 International Conference on Multimedia Retrieval,"Taipei, Taiwan",2021,9781450384636,,https://doi.org/10.1145/3460426.3463650;http://dx.doi.org/10.1145/3460426.3463650,10.1145/3460426.3463650,"Semantic relationship information is important to the image-text retrieval task. Existing work usually extract relationship information by calculating the relationship value pairwise, which is hardly to find out a meaningful semantic relationship. A more reasonable method is to convert the modal to a scene graph, thereby explicitly modeling the relationship. Scene graph is a kind of graph data structure modeling the scene of modality. There are two concept in a scene graph, object and relationship. In image modal, object indicates the image region and relationship represents the predicate of the image regions. In text modal, object indicates the entity and relationship represents the association between entities, also known as semantic relationship. In image-text retrieval task, both object and relationship are important, and a key challenge is to obtain semantic information. In this paper, image and text are represented as two kinds of scene graphs: visual scene graph and textual scene graph, and then they are combined into Heterogeneous Scene Graph(HSG). By explicitly modeling relationships using directed graph, the information can be passed edge-wise. To further extract semantic information, we introduce the metapath, which can extract specific semantic information on specified path. Moreover, we propose Heterogeneous Message Passing(HMP) to communicate information on the metapath. After the message passing, the similarity of two modalities can be represented as the similarity of the graphs. Experiment shows that the model achieve competitive results on Flickr30K and MSCOCO, which indicates that our approach has advantages in image-text retrieval.","attention mechanism, heterogeneous information network, deep learning, cross-modal retrieval, scene graph",ICMR '21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Arora R,Singh K",Mid-Air Drawing of Curves on 3D Surfaces in Virtual Reality,ACM Trans. Graph.,2021,40,3,,Association for Computing Machinery,"New York, NY, USA",,,,2021-07,,0730-0301,https://doi.org/10.1145/3459090;http://dx.doi.org/10.1145/3459090,10.1145/3459090,"Complex 3D curves can be created by directly drawing mid-air in immersive environments (Augmented and Virtual Realities). Drawing mid-air strokes precisely on the surface of a 3D virtual object, however, is difficult, necessitating a projection of the mid-air stroke onto the user “intended” surface curve. We present the first detailed investigation of the fundamental problem of 3D stroke projection in VR. An assessment of the design requirements of real-time drawing of curves on 3D objects in VR is followed by the definition and classification of multiple techniques for 3D stroke projection. We analyze the advantages and shortcomings of these approaches both theoretically and via practical pilot testing. We then formally evaluate the two most promising techniques spraycan and mimicry with 20 users in VR. The study shows a strong qualitative and quantitative user preference for our novel stroke mimicry projection algorithm. We further illustrate the effectiveness andutility of stroke mimicry to draw complex 3D curves on surfaces for various artistic and functional design applications.","3D sketching, AR/VR, curve on surface",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lv Y,Luo H",A New Focusing Excitation Method Based on Magnetic Induction Tomography,,2017,,,42–45,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Bioinformatics and Computational Biology,"Hong Kong, Hong Kong",2017,9781450348270,,https://doi.org/10.1145/3035012.3035025;http://dx.doi.org/10.1145/3035012.3035025,10.1145/3035012.3035025,"Magnetic induction tomography (MIT) is a new and non-invasive reconstruction method which reconstructs the conductivity distribution information within the target object by the eddy current signal. Due to the low conductivity for human, the eddy current field reflecting human conductivity is so weak. On the basis of analyzing magnetic field and excitation magnetic field, the conical spiral coil is proposed which can produce the focusing magnetic field. The measurement model with the target object whose parameters are near to the tissue is established for the focusing excitation coil. The primary field and the eddy current field produced within the target object are calculated and analyzed comparatively. The results show that the proposed focusing excitation coils that produces the excitation field and the eddy current field have the focusing effect, that is to say it can produce the focusing eddy current field, which provides an effect method for MIT from the eddy current source.","magnetic induction tomography (MIT), excitation coil, eddy current signal, conductivity, magnetic field focusing",ICBCB '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brutzman D,Flotyński J",X3D Ontology for Querying 3D Models on the Semantic Web,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,The 25th International Conference on 3D Web Technology,"Virtual Event, Republic of Korea",2020,9781450381697,,https://doi.org/10.1145/3424616.3424715;http://dx.doi.org/10.1145/3424616.3424715,10.1145/3424616.3424715,"The Semantic Web offers significant capabilities that transform the current Web into a global knowledge base including various cross-linked multimedia content with formal descriptions of its semantics understandable to humans and processable by computers. Content on the Semantic Web can be subject to reasoning and queries with standardized languages, methods and tools, which opens new opportunities for collaborative creation, use and exploration of web repositories. However, these opportunities have not been exploited so far by the available 3D formats and modeling tools, which limits the possibilities of search and reuse of 3D content as part of the Semantic Web. This work contributes a semantic development pipeline of the X3D Ontology, with corresponding conversion of X3D models into triple forms suitable for formal query. The ontology design reflects experience accompanying the development of the Extensible 3D (X3D) Graphics International Standard, in particular, the X3D Unified Object Model (X3DUOM). This approach combines semantic and syntactic elements of X3D models and metadata to support integration with the Semantic Web. The pipeline enables automatic generation of the X3D Ontology, thereby providing an up-to-date 3D representation with semantics during X3D specification development. By extending commonplace model conversions from other formats to X3D, the ontology presents the potential to enable integration of most forms of 3D content with the Semantic Web.","X3D Ontology, Web3D, Semantic Web, X3DUOM, Semantic 3D",Web3D '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lee JH,Jones MC",Thinking inside the XBox: Elements of Information Organization in Video Games,,2011,,,706–707,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 IConference,"Seattle, Washington, USA",2011,9781450301213,,https://doi.org/10.1145/1940761.1940878;http://dx.doi.org/10.1145/1940761.1940878,10.1145/1940761.1940878,"Video games are a novel and unique context in which numerous principles of information organization can be observed. In this poster, we explore the intersection of video games and formal information organization by examining several examples from popular video games. By doing so, we highlight some of the common organization principles that are applied in video game design, and perhaps discover new ways of organizing information objects and assess their application in real life contexts.","mnemonic notation, video games, inventory systems, metadata",iConference '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Soeken M,Wille R,Drechsler R",Towards Automatic Determination of Problem Bounds for Object Instantiation in Static Model Verification,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 8th International Workshop on Model-Driven Engineering, Verification and Validation","Wellington, New Zealand",2011,9781450309141,,https://doi.org/10.1145/2095654.2095657;http://dx.doi.org/10.1145/2095654.2095657,10.1145/2095654.2095657,"The application of formal methods in the detection of inconsistencies and design flaws within models has been intensely studied in recent years. Since consistency checking is in principle undecidable due to the infinite number of possible system states, problem bounds have to be defined making the analysis tractable. However, defining these problem bounds requires detailed design knowledge and, thus, impedes an automatic verification flow.In this paper, we present first ideas and results of how to automatically determine valid problem bounds for consistency checking algorithms. For this purpose, we make use of automatic proof engines for linear integer arithmetic. We describe the approach by means of class diagrams given in the Unified Modeling Language (UML) extended by constraints given in the Object Constraint Language (OCL).",,MoDeVVa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Atzenbeck C,Interview with Frank Shipman,SIGWEB Newsl.,2008,2008,Autumn,,Association for Computing Machinery,"New York, NY, USA",,,,2008-09,,1931-1745,https://doi.org/10.1145/1408940.1408943;http://dx.doi.org/10.1145/1408940.1408943,10.1145/1408940.1408943,"Frank Shipman is a Professor in the Department of Computer Science and Associate Director of the TEES Center for the Study of Digital Libraries. He has been pursuing research in the areas of hypermedia, computer-supported cooperative work, multimedia, computers and education, and intelligent user interfaces since 1987. Dr. Shipman's work at Baylor College of Medicine, the University of Colorado, Xerox PARC, and Texas A&M University investigates the design and use of media combining informal and formal representations and methods for supporting incremental formalization. This work included helping in the design and development of a number of collaborative hypermedia systems including the Virtual Notebook System, the Hyper-Object Substrate, VIKI, the Visual Knowledge Builder, Walden's Paths, and Hyper-Hitchcock.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Demetrescu C,Finocchi I,Ribichini A",Reactive Imperative Programming with Dataflow Constraints,,2011,,,407–426,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Portland, Oregon, USA",2011,9781450309400,,https://doi.org/10.1145/2048066.2048100;http://dx.doi.org/10.1145/2048066.2048100,10.1145/2048066.2048100,"Dataflow languages provide natural support for specifying constraints between objects in dynamic applications, where programs need to react efficiently to changes of their environment. Researchers have long investigated how to take advantage of dataflow constraints by embedding them into procedural languages. Previous mixed imperative/dataflow systems, however, require syntactic extensions or libraries of ad hoc data types for binding the imperative program to the dataflow solver. In this paper we propose a novel approach that smoothly combines the two paradigms without placing undue burden on the programmer. In our framework, programmers can define ordinary statements of the imperative host language that enforce constraints between objects stored in special memory locations designated as \reactive\"". Differently from previous approaches",reactive objects can be of any legal type in the host language,including primitive data types,pointers,arrays,and structures. Statements defining constraints are automatically re-executed every time their input memory locations change,letting a program behave like a spreadsheet where the values of some variables depend upon the values of other variables. The constraint solving mechanism is handled transparently by altering the semantics of elementary operations of the host language for reading and modifying objects. We provide a formal semantics and describe a concrete embodiment of our technique into C/C++,showing how to implement it efficiently in conventional platforms using off-the-shelf compilers. We discuss common coding idioms and relevant applications to reactive scenarios,including incremental computation,observer design pattern,and data structure repair. The performance of our implementation is compared to ad hoc problem-specific change propagation algorithms,as well as to language-centric approaches such as self-adjusting computation and subject/observer communication mechanisms,"showing that the proposed approach is efficient in practice.""","reactive programming, dataflow programming, imperative programming, constraint solving, observer design pattern, incremental computation, data structure repair",OOPSLA '11,,,,,,,,,,,,,,,,,,
1,Journal Article,"Demetrescu C,Finocchi I,Ribichini A",Reactive Imperative Programming with Dataflow Constraints,SIGPLAN Not.,2011,46,10,407–426,Association for Computing Machinery,"New York, NY, USA",,,,2011-10,,0362-1340,https://doi.org/10.1145/2076021.2048100;http://dx.doi.org/10.1145/2076021.2048100,10.1145/2076021.2048100,"Dataflow languages provide natural support for specifying constraints between objects in dynamic applications, where programs need to react efficiently to changes of their environment. Researchers have long investigated how to take advantage of dataflow constraints by embedding them into procedural languages. Previous mixed imperative/dataflow systems, however, require syntactic extensions or libraries of ad hoc data types for binding the imperative program to the dataflow solver. In this paper we propose a novel approach that smoothly combines the two paradigms without placing undue burden on the programmer. In our framework, programmers can define ordinary statements of the imperative host language that enforce constraints between objects stored in special memory locations designated as \reactive\"". Differently from previous approaches",reactive objects can be of any legal type in the host language,including primitive data types,pointers,arrays,and structures. Statements defining constraints are automatically re-executed every time their input memory locations change,letting a program behave like a spreadsheet where the values of some variables depend upon the values of other variables. The constraint solving mechanism is handled transparently by altering the semantics of elementary operations of the host language for reading and modifying objects. We provide a formal semantics and describe a concrete embodiment of our technique into C/C++,showing how to implement it efficiently in conventional platforms using off-the-shelf compilers. We discuss common coding idioms and relevant applications to reactive scenarios,including incremental computation,observer design pattern,and data structure repair. The performance of our implementation is compared to ad hoc problem-specific change propagation algorithms,as well as to language-centric approaches such as self-adjusting computation and subject/observer communication mechanisms,"showing that the proposed approach is efficient in practice.""","dataflow programming, constraint solving, observer design pattern, imperative programming, reactive programming, data structure repair, incremental computation",,,,,,,,,,,,,,,,,,,
1,Conference Paper,Sagiv Y,A Personal Perspective on Keyword Search over Data Graphs,,2013,,,21–32,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th International Conference on Database Theory,"Genoa, Italy",2013,9781450315982,,https://doi.org/10.1145/2448496.2448500;http://dx.doi.org/10.1145/2448496.2448500,10.1145/2448496.2448500,"Theoretical and practical issues pertaining to keyword search over data graphs are discussed. A formal model and algorithms for enumerating answers (by operating directly on the data graph) are described. Various aspects of a system are explained, including the object-connector-property data model, how it is used to construct a data graph from an XML document, how to deal with redundancies in the source data, what are duplicate answers, implementation and GUI. An approach to ranking that combines textual relevance with semantic considerations is described. It is argued that search over data graphs is inherently a two-dimensional process, where the goal is not just to find particular content but also to collect information on how the desired data may be semantically connected.","graph search, data graph, information retrieval, keyword search, enumeration algorithm",ICDT '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kundu A,Atallah MJ,Bertino E",Leakage-Free Redactable Signatures,,2012,,,307–316,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Second ACM Conference on Data and Application Security and Privacy,"San Antonio, Texas, USA",2012,9781450310918,,https://doi.org/10.1145/2133601.2133639;http://dx.doi.org/10.1145/2133601.2133639,10.1145/2133601.2133639,"Redactable signatures for linear-structured data such as strings have already been studied in the literature. In this paper, we propose a formal security model for leakage-free redactable signatures (LFRS) that is general enough to address authentication of not only trees but also graphs and forests. LFRS schemes have several applications, especially in enabling secure data management in the emerging cloud computing paradigm as well as in healthcare, finance and biological applications. We have also formally defined the notion of secure names. Such secure names facilitate leakage-free verification of ordering between siblings/nodes. The paper also proposes a construction for secure names, and a construction for leakagefree redactable signatures based on the secure naming scheme. The proposed construction computes a linear number of signatures with respect to the size of the data object, and outputs only one signature that is stored, transmitted and used for authentication of any tree, graph and forest.","redactable signatures, cloud computing, trees, leakages, authenticity, graphs, privacy, integrity",CODASPY '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cohen JM,Tariq S,Green S",Interactive Fluid-Particle Simulation Using Translating Eulerian Grids,,2010,,,15–22,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games,"Washington, D.C.",2010,9781605589398,,https://doi.org/10.1145/1730804.1730807;http://dx.doi.org/10.1145/1730804.1730807,10.1145/1730804.1730807,"We describe an interactive system featuring fluid-driven animation that responds to moving objects. Our system includes a GPU-accelerated Eulerian fluid solver that is suited for real-time use because it is unconditionally stable, takes constant calculation time per frame, and provides good visual fidelity. We dynamically translate the fluid simulation domain to track a user-controlled object. The fluid motion is visualized via its effects on particles which respond to the calculated fluid velocity field, but which are not constrained to stay within the bounds of the simulation domain. As particles leave the simulation domain, they seamlessly transition to purely particle-based motion, obscuring the point at which the fluid simulation ends. We additionally describe a hardware-accelerated volume rendering system that treats the particles as participating media and can render effects such as smoke, dust, or mist. Taken together, these components can be used to add fluid-driven effects to an interactive system without enforcing constraints on user motion, and without visual artifacts resulting from the finite extents of Eulerian fluid simulation methods.","particle simulation, GPU computing, fluid simulation",I3D '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fremont DJ,Dreossi T,Ghosh S,Yue X,Sangiovanni-Vincentelli AL,Seshia SA",Scenic: A Language for Scenario Specification and Scene Generation,,2019,,,63–78,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Phoenix, AZ, USA",2019,9781450367127,,https://doi.org/10.1145/3314221.3314633;http://dx.doi.org/10.1145/3314221.3314633,10.1145/3314221.3314633,"We propose a new probabilistic programming language for the design and analysis of perception systems, especially those based on machine learning. Specifically, we consider the problems of training a perception system to handle rare events, testing its performance under different conditions, and debugging failures. We show how a probabilistic programming language can help address these problems by specifying distributions encoding interesting types of inputs and sampling these to generate specialized training and test sets. More generally, such languages can be used for cyber-physical systems and robotics to write environment models, an essential prerequisite to any formal analysis. In this paper, we focus on systems like autonomous cars and robots, whose environment is a scene, a configuration of physical objects and agents. We design a domain-specific language, Scenic, for describing scenarios that are distributions over scenes. As a probabilistic programming language, Scenic allows assigning distributions to features of the scene, as well as declaratively imposing hard and soft constraints over the scene. We develop specialized techniques for sampling from the resulting distribution, taking advantage of the structure provided by Scenic's domain-specific syntax. Finally, we apply Scenic in a case study on a convolutional neural network designed to detect cars in road images, improving its performance beyond that achieved by state-of-the-art synthetic data generation methods.","automatic test generation, scenario description language, probabilistic programming, fuzz testing, deep learning, synthetic data",PLDI 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shin K,Kuboyama T",A Generalization of Haussler's Convolution Kernel: Mapping Kernel,,2008,,,944–951,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 25th International Conference on Machine Learning,"Helsinki, Finland",2008,9781605582054,,https://doi.org/10.1145/1390156.1390275;http://dx.doi.org/10.1145/1390156.1390275,10.1145/1390156.1390275,"Haussler's convolution kernel provides a successful framework for engineering new positive semidefinite kernels, and has been applied to a wide range of data types and applications. In the framework, each data object represents a finite set of finer grained components. Then, Haussler's convolution kernel takes a pair of data objects as input, and returns the sum of the return values of the predetermined primitive positive semidefinite kernel calculated for all the possible pairs of the components of the input data objects. On the other hand, the mapping kernel that we introduce in this paper is a natural generalization of Haussler's convolution kernel, in that the input to the primitive kernel moves over a predetermined subset rather than the entire cross product. Although we have plural instances of the mapping kernel in the literature, their positive semidefiniteness was investigated in case-by-case manners, and worse yet, was sometimes incorrectly concluded. In fact, there exists a simple and easily checkable necessary and sufficient condition, which is generic in the sense that it enables us to investigate the positive semidefiniteness of an arbitrary instance of the mapping kernel. This is the first paper that presents and proves the validity of the condition. In addition, we introduce two important instances of the mapping kernel, which we refer to as the size-of-index-structure-distribution kernel and the editcost-distribution kernel. Both of them are naturally derived from well known (dis)similarity measurements in the literature (e.g. the maximum agreement tree, the edit distance), and are reasonably expected to improve the performance of the existing measures by evaluating their distributional features rather than their peak (maximum/minimum) features.",,ICML '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Perin G,Matthews L",Slicing Perspective,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Digital and Interactive Arts,"Braga, Portugal",2019,9781450372503,,https://doi.org/10.1145/3359852.3359875;http://dx.doi.org/10.1145/3359852.3359875,10.1145/3359852.3359875,"Despite the proliferation of the many new digital technologies capable of representing space and form, disciplinary modes of delineating architectural objects nevertheless remain dependent upon the line. The continuing avoidance of new digital methods to envisage and create architectural form, coupled with a disciplinary commitment to descriptive and projective geometry, means that, broadly speaking, Architecture remains focused on objects. As a consequence, drawing and design ignore the atmospherics provided by the interaction between colour and time.The paper argues that video-sequencing software provides a new perspectival model by which to render spatial depth through the foregrounding of temporal variations in colour. Taking into account the disciplinary impact on the issue of precedent, the paper speculates upon how subtle shifts in the conditions of viewing produces a new set of formal techniques to design and render architectural space and form. It reveals how temporal variations of colour can replace the fixity of the line in the delineation of spatial depth to provide a new atmospheric model for the interpretation and design of space.","representation, Digital architecture, image stack, temporal, atmospherics",ARTECH 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Barbieri P,Dagnino F,Zucca E",An Inductive Abstract Semantics for CoFJ,,2020,,,4–9,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 22nd ACM SIGPLAN International Workshop on Formal Techniques for Java-Like Programs,"Virtual, USA",2020,9781450381864,,https://doi.org/10.1145/3427761.3428342;http://dx.doi.org/10.1145/3427761.3428342,10.1145/3427761.3428342,"We describe an inductive abstract semantics for coFJ, a Java-like calculus where, when the same method call is encountered twice, non-termination is avoided, and the programmer can decide the behaviour in this case, by writing a codefinition. The proposed semantics is abstract in the sense that evaluation is non-deterministic, and objects are possibly infinite. However, differently from typical coinductive handling of infinite values, the semantics is inductive, since it relies on detection of cyclic calls. Whereas soundness with respect to the reference coinductive semantics has already been proved, we conjecture that completeness with respect to the regular subset of such semantics holds as well. This relies on the fact that in the proposed semantics detection of cycles is non-deterministic, that is, does not necessarily happens the first time a cycle is found.","programming paradigms, coinduction, Operational semantics, regular terms",FTfJP 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Widlöcher A,Mathet Y",The Glozz Platform: A Corpus Annotation and Mining Tool,,2012,,,171–180,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2012 ACM Symposium on Document Engineering,"Paris, France",2012,9781450311168,,https://doi.org/10.1145/2361354.2361394;http://dx.doi.org/10.1145/2361354.2361394,10.1145/2361354.2361394,"Corpus linguistics and Natural Language Processing make it necessary to produce and share reference annotations to which linguistic and computational models can be compared. Creating such resources requires a formal framework supporting description of heterogeneous linguistic objects and structures, appropriate representation formats, and adequate manual annotation tools, making it possible to locate, identify and describe linguistic phenomena in textual documents. The Glozz platform addresses all these needs, and provides a highly versatile corpus annotation tool with advanced visualization, querying and evaluation possibilities.","natural language processing, annotation formats and tools, corpus linguistics",DocEng '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Cherrier P,Software Engineering for Pervasive Services,,2008,,,27–28,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd ACM Workshop on Software Engineering for Pervasive Services,"Sorrento, Italy",2008,9781605582146,,https://doi.org/10.1145/1387229.1387236;http://dx.doi.org/10.1145/1387229.1387236,10.1145/1387229.1387236,"This short article provides a reflexion about the domains covered by the workshop SEPS at ICPS. The worskhop \Software Engineering for Pervasive Services\"" was first created in 2006 to become a meeting place for researchers interested in formal methods and pervasive computing. The term \""pervasive\"" was understood in a wide sense",connected to ambient intelligence,ubiquitous systems,"smart objects and multimodal human-system interaction. The terms \""software engineering\"" were also understood as covering a large area","in a \""curiosity-driven research\"" spirit as would probably say Osterweil [16]. Things have progressed in such a way that we now find it interesting to draw on SEPS a \""once and future focus\""",as Taylor and Hoek [19] seem to argue that time has come to consider software engineering from the design point of view. As we are convinced that software engineering could benefit a lot from an increasing interest from designers,"we would also appreciate to see in the next future ideas and works which would be based on a mathematical approach and could help to create a convergence between ad-hoc networks and formal approaches to software engineering. We believe that percolation theory could bring many interesting new horizons.""","pervasive service, software engineering",SEPS '08,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Saraiji MY,Sasaki T,Kunze K,Minamizawa K,Inami M",MetaArms: Body Remapping Using Feet-Controlled Artificial Arms,,2018,,,65–74,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st Annual ACM Symposium on User Interface Software and Technology,"Berlin, Germany",2018,9781450359481,,https://doi.org/10.1145/3242587.3242665;http://dx.doi.org/10.1145/3242587.3242665,10.1145/3242587.3242665,"We introduce MetaArms, wearable anthropomorphic robotic arms and hands with six degrees of freedom operated by the user's legs and feet. Our overall research goal is to re-imagine what our bodies can do with the aid of wearable robotics using a body-remapping approach. To this end, we present an initial exploratory case study. MetaArms' two robotic arms are controlled by the user's feet motion, and the robotic hands can grip objects according to the user's toes bending. Haptic feedback is also presented on the user's feet that correlate with the touched objects on the robotic hands, creating a closed-loop system. We present formal and informal evaluations of the system, the former using a 2D pointing task according to Fitts' Law. The overall throughput for 12 users of the system is reported as 1.01 bits/s (std 0.39). We also present informal feedback from over 230 users. We find that MetaArms demonstrate the feasibility of body-remapping approach in designing robotic limbs that may help us re-imagine what the human body could do.","body remapping, human enhancement, augmented arms, artificial limbs, fitts' law, feet interactions, body schema",UIST '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wilke G,Frank AU",Tolerance Geometry: Euclid's First Postulate for Points and Lines with Extension,,2010,,,162–171,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th SIGSPATIAL International Conference on Advances in Geographic Information Systems,"San Jose, California",2010,9781450304283,,https://doi.org/10.1145/1869790.1869816;http://dx.doi.org/10.1145/1869790.1869816,10.1145/1869790.1869816,"Object representation and reasoning in vector based geographic information systems (GIS) is based on Euclidean geometry. Euclidean geometry is built upon Euclid's first postulate, stating that two points uniquely determine a line. This postulate makes geometric constructions unambiguous and thereby provides the foundation for consistent geometric reasoning. It holds for exact coordinate points and lines, but is violated, if points and lines are allowed to have extension. As an example for a point that has extension consider a point feature that represents the city of Vienna in a small scale GIS map representation. Geometric constructions with such a point feature easily produce inconsistencies in the data. The present paper addresses the issue of consistency by formalizing Euclid's first postulate for geometric primitives that have extension.We identify a list of six consequences from introducing extension: These are 'new qualities' that are not present in exact geometric reasoning, but must be taken into account when formalizing Euclid's first postulate for extended primitives. One important consequence is the positional tolerance of the incidence relation (\on\""-relation). As another consequence",equality of geometric primitives becomes a matter of degree. To account for this fact,we propose a formalization of Euclid's first postulate in Łukasiewicz t-norm fuzzy logic. A model of the proposed formalization is given in the projective plane with elliptic metric. This is not a restriction,since the elliptic metric is locally Euclidean. We introduce graduated geometric reasoning with Rational Pavelka Logic as a means of approximating and propagating positional tolerance through the steps of a geometric construction process. Since the axioms (postulates) of geometry built upon one another,"the proposed formalization of Euclid's first postulate provides one building block of a geometric calculus that accounts for positional tolerance in a consistent way.The novel contribution of the paper is to define geometric reasoning with extended primitives as a calculus that propagates positional tolerance. Also new is the axiomatic approach to positional uncertainty and the associated consistency issue.""","error propagation, positional tolerance, axiomatic geometry, geometric reasoning, GIS, approximate reasoning",GIS '10,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang M,Zhang H,Li H",Convolution Kernel over Packed Parse Forest,,2010,,,875–885,Association for Computational Linguistics,USA,,Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,"Uppsala, Sweden",2010,,,,,"This paper proposes a convolution forest kernel to effectively explore rich structured features embedded in a packed parse forest. As opposed to the convolution tree kernel, the proposed forest kernel does not have to commit to a single best parse tree, is thus able to explore very large object spaces and much more structured features embedded in a forest. This makes the proposed kernel more robust against parsing errors and data sparseness issues than the convolution tree kernel. The paper presents the formal definition of convolution forest kernel and also illustrates the computing algorithm to fast compute the proposed convolution forest kernel. Experimental results on two NLP applications, relation extraction and semantic role labeling, show that the proposed forest kernel significantly outperforms the baseline of the convolution tree kernel.",,ACL '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kell S,Mulligan DP,Sewell P","The Missing Link: Explaining ELF Static Linking, Semantically",,2016,,,607–623,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2016 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Amsterdam, Netherlands",2016,9781450344449,,https://doi.org/10.1145/2983990.2983996;http://dx.doi.org/10.1145/2983990.2983996,10.1145/2983990.2983996,"Beneath the surface, software usually depends on complex linker behaviour to work as intended. Even linking hello_world.c is surprisingly involved, and systems software such as libc and operating system kernels rely on a host of linker features. But linking is poorly understood by working programmers and has largely been neglected by language researchers. In this paper we survey the many use-cases that linkers support and the poorly specified linker speak by which they are controlled: metadata in object files, command-line options, and linker-script language. We provide the first validated formalisation of a realistic executable and linkable format (ELF), and capture aspects of the Application Binary Interfaces for four mainstream platforms (AArch64, AMD64, Power64, and IA32). Using these, we develop an executable specification of static linking, covering (among other things) enough to link small C programs (we use the example of bzip2) into a correctly running executable. We provide our specification in Lem and Isabelle/HOL forms. This is the first formal specification of mainstream linking. We have used the Isabelle/HOL version to prove a sample correctness property for one case of AMD64 ABI relocation, demonstrating that the specification supports formal proof, and as a first step towards the much more ambitious goal of verified linking. Our work should enable several novel strands of research, including linker-aware verified compilation and program analysis, and better languages for controlling linking.","Executable and Linkable Format (ELF), theorem-proving, Linking, formal specification",OOPSLA 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kell S,Mulligan DP,Sewell P","The Missing Link: Explaining ELF Static Linking, Semantically",SIGPLAN Not.,2016,51,10,607–623,Association for Computing Machinery,"New York, NY, USA",,,,2016-10,,0362-1340,https://doi.org/10.1145/3022671.2983996;http://dx.doi.org/10.1145/3022671.2983996,10.1145/3022671.2983996,"Beneath the surface, software usually depends on complex linker behaviour to work as intended. Even linking hello_world.c is surprisingly involved, and systems software such as libc and operating system kernels rely on a host of linker features. But linking is poorly understood by working programmers and has largely been neglected by language researchers. In this paper we survey the many use-cases that linkers support and the poorly specified linker speak by which they are controlled: metadata in object files, command-line options, and linker-script language. We provide the first validated formalisation of a realistic executable and linkable format (ELF), and capture aspects of the Application Binary Interfaces for four mainstream platforms (AArch64, AMD64, Power64, and IA32). Using these, we develop an executable specification of static linking, covering (among other things) enough to link small C programs (we use the example of bzip2) into a correctly running executable. We provide our specification in Lem and Isabelle/HOL forms. This is the first formal specification of mainstream linking. We have used the Isabelle/HOL version to prove a sample correctness property for one case of AMD64 ABI relocation, demonstrating that the specification supports formal proof, and as a first step towards the much more ambitious goal of verified linking. Our work should enable several novel strands of research, including linker-aware verified compilation and program analysis, and better languages for controlling linking.","Executable and Linkable Format (ELF), Linking, theorem-proving, formal specification",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liang Y,Wang Z",Video Object Detection Based on Deformable Convolution,,2020,,,1–4,Association for Computing Machinery,"New York, NY, USA",,2020 3rd Artificial Intelligence and Cloud Computing Conference,"Kyoto, Japan",2020,9781450388832,,https://doi.org/10.1145/3442536.3442537;http://dx.doi.org/10.1145/3442536.3442537,10.1145/3442536.3442537,"Video object detection is one of the important research directions in the field of computer vision with applications in various domains, e.g. public security, traffic management, etc. Nevertheless, it is very challenging to extend the image-based object detection method to video object detection. In the existing methods, the feature information of multiple adjacent frames is aggregated into the current frame to improve the detection result. However, these methods only sample the information of adjacent frames on the sampling points obtained by prior knowledge or by calculating explicit motion references. Therefore, the feature information obtained by this sampling method is often insufficient. Furthermore, if the selected sampling points are inaccurate, the original feature information may be lost. In this paper, we use modulation-based deformable convolution for feature sampling, and the sampling positions and weight are generated through additional convolutional layers. This not only enriches the sampling information but also minimizes the intervention of prior knowledge. According to experiments on the Image VID dataset, the proposed method significantly improve detection accuracy compared with existing methods.","video object detection, feature aggregation, deformable convolution",AICCC 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liang Q,Mei L,Wu W,Sun W,Wang Y,Zhang D",Automatic Basketball Detection in Sport Video Based on R-FCN and Soft-NMS,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 4th International Conference on Automation, Control and Robotics Engineering","Shenzhen, China",2019,9781450371865,,https://doi.org/10.1145/3351917.3351970;http://dx.doi.org/10.1145/3351917.3351970,10.1145/3351917.3351970,"In basketball videos, the ball is always so small in the camera that its appearance feature is hard to be extracted. In this paper, we introduce a deep-learning technology to detect the basketball. Specifically, we train our basketball detection model based on the Region-based Fully Convolutional Networks (R-FCN) which uses the fully convolutional Residual Network (ResNet) as the backbone network. What's more, we apply some new techniques including Online Hard Example Mining (OHEM), Soft-NMS and multi-scale training strategy to achieve higher detection accuracy. In detail, the OHEM method can reduce the cost of fine-tuning during training by calculating the loss of the RoIs. Soft-NMS can reduce the false positive rate by decreasing the object detection score between the overlap object. And the multi-scale training can improve the detection performance by receiving the good feature from the object with different scale. Finally, we achieve a mean average precision (mAP) value of 89.7% on a public basketball dataset. It proves that applying the deep-learning approach to basketball detection is effective.","Region-based Fully Convolutional Networks, Ball detection, Object recognition",CACRE2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Blažević M,Légaré J",Packrats Parse in Packs,,2017,,,14–25,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th ACM SIGPLAN International Symposium on Haskell,"Oxford, UK",2017,9781450351829,,https://doi.org/10.1145/3122955.3122958;http://dx.doi.org/10.1145/3122955.3122958,10.1145/3122955.3122958,"We present a novel but remarkably simple formulation of formal language grammars in Haskell as functions mapping a record of pro- duction parsers to itself. Thus formulated grammars are first-class objects, composable and reusable. We also provide a simple parser implementation for them, based on an improved packrat algorithm. In order to make the grammar manipulation code reusable, we introduce a set of type classes mirroring the existing type classes from Haskell base library, but whose methods have rank-2 types.","rank-2 types, packrat, Haskell, parser combinators, memoizing",Haskell 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Blažević M,Légaré J",Packrats Parse in Packs,SIGPLAN Not.,2017,52,10,14–25,Association for Computing Machinery,"New York, NY, USA",,,,2017-09,,0362-1340,https://doi.org/10.1145/3156695.3122958;http://dx.doi.org/10.1145/3156695.3122958,10.1145/3156695.3122958,"We present a novel but remarkably simple formulation of formal language grammars in Haskell as functions mapping a record of pro- duction parsers to itself. Thus formulated grammars are first-class objects, composable and reusable. We also provide a simple parser implementation for them, based on an improved packrat algorithm. In order to make the grammar manipulation code reusable, we introduce a set of type classes mirroring the existing type classes from Haskell base library, but whose methods have rank-2 types.","parser combinators, memoizing, packrat, Haskell, rank-2 types",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Arcaini P,Riccobene E,Scandurra P",Modeling and Validating Self-Adaptive Service-Oriented Applications,SIGAPP Appl. Comput. Rev.,2015,15,3,35–48,Association for Computing Machinery,"New York, NY, USA",,,,2015-10,,1559-6915,https://doi.org/10.1145/2835260.2835262;http://dx.doi.org/10.1145/2835260.2835262,10.1145/2835260.2835262,"Self-adaptive and autonomous behaviors are becoming more and more important in the context of service-oriented applications, and formal modeling self-adaptive service-oriented components is highly required to assure quality properties.This paper enhances the formal framework SCA-ASM for modeling and validating distributed self-adaptive service-oriented applications. We explain how modeling an SCA-ASM component able to monitor and react to environmental changes (context-awareness) and to internal changes (self-awareness), and present the operators for expressing and coordinating self-adaptive behaviors in a distributed setting. We also support techniques for validating adaptation scenarios, and getting feedback of the correctness of the adaptation logic as implemented by the managing SCA-ASM components over the managed ones. As a proof-of-concepts, we use self-adaptive SCA-ASMs for modeling and validating a decentralized traffic monitoring system.","self-adaptation, formal modeling, validation, service-oriented applications, SCA-ASM",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Nami MR,Hassani F","A Comparative Evaluation of the Z, CSP, RSL, and VDM Languages",SIGSOFT Softw. Eng. Notes,2009,34,3,1–4,Association for Computing Machinery,"New York, NY, USA",,,,2009-05,,0163-5948,https://doi.org/10.1145/1527202.1527211;http://dx.doi.org/10.1145/1527202.1527211,10.1145/1527202.1527211,"The software engineering process has been described in many ways. Today, few of these deal specifically with the use of formal methods in software engineering. New software engineering uses formal specification languages in system analysis, requirement analysis, and system design to develop software for critical-safety systems. Formal specification languages describe the system at a much higher level than a programming language. They are catego-rized into model-oriented, constructive, algebraic, process model, hybrid, and logical. This paper describes the properties and types of formal specification languages in software engineering. It then compares the Z, VDM, RSL, and CSP formal specification lan-guages from different point of views.","RAISE, formal specification languages, software engineering, verification, VDM, method, CSP language, the Z language",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Dube MP,Egenhofer MJ",Partitions to Improve Spatial Reasoning,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st ACM SIGSPATIAL PhD Workshop,"Dallas/Fort Worth, Texas",2014,9781450331586,,https://doi.org/10.1145/2694859.2694864;http://dx.doi.org/10.1145/2694859.2694864,10.1145/2694859.2694864,"The field of spatial reasoning has provided a litany of formal models and reasoning systems aimed at providing users with information about spatial tasks and concepts, ranging from point-to-point distance measurements coming from sensors all the way to topological information coming from the interaction of multiple sensor readings. In this short paper, the concept of using topology to augment partitions is addressed. Future work within the dissertation includes other partition-based relation theories, including digital topological relations and surrounds configurations within a collection of objects.","spatial partitions, topology, spatial reasoning, discrete space",SIGSPATIAL PhD '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Valiev I,Voloboy A,Galaktionov V",Improved Model of IBL Sunlight Simulation,,2008,,,27–32,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th Spring Conference on Computer Graphics,"Budmerice, Slovakia",2008,9781605589572,,https://doi.org/10.1145/1921264.1921274;http://dx.doi.org/10.1145/1921264.1921274,10.1145/1921264.1921274,"This paper considers the use of high dynamic range images as a source of natural daylight illumination in virtual scenes containing objects with complex optical properties (such as automotive multilayer paints). Physically justified algorithms for calculating the luminance of an object point and recognition of the sun to replace it by separate light source are outlined. An analysis of the correctness of the available high dynamic range images is performed, and their drawbacks are discussed. Two algorithms that allow to compensate the drawbacks of the representation of the visible sun in the high dynamic range images and thus perform a more accurate illumination simulation are proposed and elaborated. The correction of sun representation is based on the sky models adopted by the International Commission on Illumination (CIE). The modified illumination simulation algorithms make it possible to produce more accurate images. The algorithms are semi- automatic and robust with respect to errors in high dynamic range images. These algorithms are used in our computer graphics system for generating realistic images.","HDRI, physically accurate rendering, sunlight, Monte-Carlo ray tracing, IBL, BRDF",SCCG '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Abdelaal M,Sekar S,Dürr F,Rothermel K,Becker S,Fritsch D",MapSense: Grammar-Supported Inference of Indoor Objects from Crowd-Sourced 3D Point Clouds,ACM Trans. Internet Things,2020,1,2,,Association for Computing Machinery,"New York, NY, USA",,,,2020-04,,2691-1914,https://doi.org/10.1145/3379342;http://dx.doi.org/10.1145/3379342,10.1145/3379342,"Recently, indoor modeling has gained increased attention, thanks to the immense need for realizing efficient indoor location-based services. Indoor environments differ from outdoor spaces in two aspects: spaces are smaller and there are many structural objects such as walls, doors, and furniture. To model the indoor environments in a proper manner, novel data acquisition concepts and data modeling algorithms have been devised to meet the requirements of indoor spatial applications. In this realm, several research efforts have been exerted. Nevertheless, these efforts mostly suffer either from adopting impractical data acquisition methods or from being limited to 2D modeling.To overcome these limitations, we introduce the MapSense approach, which automatically derives indoor models from 3D point clouds collected by individuals using mobile devices, such as Google Tango, Apple ARKit, and Microsoft HoloLens. To this end, MapSense leverages several computer vision and machine learning algorithms for precisely inferring the structural objects. In MapSense, we mainly focus on improving the modeling accuracy through adopting formal grammars that encode design-time knowledge, i.e., structural information about the building. In addition to modeling accuracy, MapSense considers the energy overhead on the mobile devices via developing a probabilistic quality model through which the mobile devices solely upload high-quality point clouds to the crowd-sensing servers. To demonstrate the performance of MapSense, we implemented a crowd-sensing Android App to collect 3D point clouds from two different buildings by six volunteers. The results showed that MapSense can accurately infer the various structural objects while drastically reducing the energy overhead on the mobile devices.","machine learning, crowd-sensing, formal grammars, Indoor mapping, QoS-aware sensing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shapkin P,Marenkov A,Shumsky L,Roslovtsev V,Wolfengagen V",Towards the Automated Business Process Building by Means of Type Theory,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Subject-Oriented Business Process Management,"Kiel, Germany",2015,9781450333122,,https://doi.org/10.1145/2723839.2723847;http://dx.doi.org/10.1145/2723839.2723847,10.1145/2723839.2723847,An approach to automated construction of executable business process models based on formal goal description is proposed. The methodology is founded on the type theory notions which on the one hand give means for logical goal description and its refinement and on the other hand enable to bind this description to the executable program expressed as a composition of computational objects. The proposed methodology covers the whole procedure of the business process construction and enables to minimize the need to involve the IT workforce.,"business-process, business process modelling, business-goal, business process management, type theory, business process semantics",S-BPM ONE '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brucker AD,Herzberg M",A Formal Semantics of the Core DOM in Isabelle/HOL,,2018,,,741–749,International World Wide Web Conferences Steering Committee,"Republic and Canton of Geneva, CHE",,Companion Proceedings of the The Web Conference 2018,"Lyon, France",2018,9781450356404,,https://doi.org/10.1145/3184558.3185980;http://dx.doi.org/10.1145/3184558.3185980,10.1145/3184558.3185980,"At its core, the Document Object Model (DOM) defines a tree-like data structure for representing documents in general and HTML documents in particular. It is the heart of any modern web browser. Formalizing the key concepts of the DOM is a prerequisite for the formal reasoning over client-side JavaScript programs and for the analysis of security concepts in modern web browsers. We present a formalization of the core DOM, with focus on the node-tree and the operations defined on node-trees, in Isabelle/HOL. We use the formalization to verify the functional correctness of the most important functions defined in the DOM standard. Moreover, our formalization is extensible, i.e., can be extended without the need of re-proving already proven properties and executable, i.e., we can generate executable code from our specification.","formal semantics, isabelle/hol, dom, document object model",WWW '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Codd EF,A Data Base Sublanguage Founded on the Relational Calculus,,1971,,,35–68,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 1971 ACM SIGFIDET (Now SIGMOD) Workshop on Data Description, Access and Control","San Diego, California",1971,9781450373005,,https://doi.org/10.1145/1734714.1734718;http://dx.doi.org/10.1145/1734714.1734718,10.1145/1734714.1734718,"Three principal types of language for data base manipulation are identified: the low-level, procedure-oriented (typified by the CODASYL-proposed DML), the intermediate level, algebraic (typified by the Project MAC MacAIMS language), and the high level, relational calculus-based data sublanguage, an example of which is described in this paper. The language description is informal and stresses concepts and principles. Following this, arguments are presented for the superiority of the calculus-based type of data base sub-language over the algebraic, and for the algebraic over the low-level procedural. These arguments are particularly relevant to the questions of inter-system compatibility and standardization.",,SIGFIDET '71,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang S,Traoré MK",DEVS-Based Case Management (Wip),,2014,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the Symposium on Theory of Modeling & Simulation - DEVS Integrative,"Tampa, Florida",2014,,,,,"The Object Management Group (OMG) defined Case Management Model and Notation (CMMN), a modeling specification for case management, in January 2013. However, to this novel concept no supporting tools exist until now, and the capability of simulation is not taken into account either. For this reason, in this paper we present a DEVS-based case management system, with which case workers are able to manipulate with case models, verify and validate case models using formal methods, and, run the simulation to predict the performance.. These capabilities are enabled through a model-to-model transformation, in which the source model is CMMN models, and the target model is DDML (DEVS-Driven Modeling Language) models, where DDML is a high level modeling language for the simulation of discrete event systems. A case study is given to demonstrate the essential principles of CMMN to DDML transformation.","case management, model-to-model transformation, CMMN, DDML",DEVS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ryssel U,Ploennigs J,Kabitzsch K",Reasoning of Feature Models from Derived Features,,2012,,,21–30,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Generative Programming and Component Engineering,"Dresden, Germany",2012,9781450311298,,https://doi.org/10.1145/2371401.2371405;http://dx.doi.org/10.1145/2371401.2371405,10.1145/2371401.2371405,"When using product lines, whose variability models are based on derived features, e.g., Simulink variant objects, the dependencies among the features are only described implicitly. This makes it difficult to verify the mapping of the features to the solution space and to create a comprehensive overview of the feature dependencies like in a feature model. In this paper, an OWL-based approach is presented, which permits the automatic verification of the feature mapping and an automatic feature model synthesis for derived features using OWL reasoning and formal concept analysis.","OWL, variant object, formal concept analysis, feature model synthesis, reasoning, derived feature",GPCE '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ryssel U,Ploennigs J,Kabitzsch K",Reasoning of Feature Models from Derived Features,SIGPLAN Not.,2012,48,3,21–30,Association for Computing Machinery,"New York, NY, USA",,,,2012-09,,0362-1340,https://doi.org/10.1145/2480361.2371405;http://dx.doi.org/10.1145/2480361.2371405,10.1145/2480361.2371405,"When using product lines, whose variability models are based on derived features, e.g., Simulink variant objects, the dependencies among the features are only described implicitly. This makes it difficult to verify the mapping of the features to the solution space and to create a comprehensive overview of the feature dependencies like in a feature model. In this paper, an OWL-based approach is presented, which permits the automatic verification of the feature mapping and an automatic feature model synthesis for derived features using OWL reasoning and formal concept analysis.","derived feature, reasoning, OWL, feature model synthesis, variant object, formal concept analysis",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Raji A,Dhaussy P",Improving Formal Verification Practicability through User Oriented Models and Context-Awareness,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 8th International Workshop on Model-Driven Engineering, Verification and Validation","Wellington, New Zealand",2011,9781450309141,,https://doi.org/10.1145/2095654.2095659;http://dx.doi.org/10.1145/2095654.2095659,10.1145/2095654.2095659,"Formal methods are effective techniques for automating software verifications to satisfy quality and reliability. However, the application of these techniques within industrial settings remains limited due to the (i) complexity of the models that have to be checked and (ii) the difficulty to produce formal artifacts required by existing formal verification tools. Context-aware verification can circumvent (i) by reducing the scope of the verification to some specific environmental conditions (contexts). Model driven development can help to handle (ii) thanks to model transformations and formal code generators. In this paper, we propose a methodological approach to help engineers to apply formal verifications in industrial settings. In our approach we propose a set of user oriented models to ease the capture and formalization of requirements and contexts to generate required formal artifacts directly from high level user models.","use cases, property patterns, constrained natural language, formal verifications, requirement engineering, context-aware",MoDeVVa,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Petricek T,Syme D",Collecting Hollywood's Garbage: Avoiding Space-Leaks in Composite Events,,2010,,,53–62,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 International Symposium on Memory Management,"Toronto, Ontario, Canada",2010,9781450300544,,https://doi.org/10.1145/1806651.1806662;http://dx.doi.org/10.1145/1806651.1806662,10.1145/1806651.1806662,"The reactive programming model is largely different to what we're used to as we don't have full control over the application's control flow. If we mix the declarative and imperative programming style, which is usual in the ML family of languages, the situation is even more complex. It becomes easy to introduce patterns where the usual garbage collector for objects cannot automatically dispose all components that we intuitively consider garbage.In this paper we discuss a duality between the definitions of garbage for objects and events. We combine them into a single one, to specify the notion of garbage for reactive programming model in a mixed functional/imperative language and we present a formal algorithm for collecting garbage in this environment.Building on top of the theoretical model, we implement a library for reactive programming that does not cause leaks when used in the mixed declarative/imperative model. The library allows us to safely combine both of the reactive programming patterns. As a result, we can take advantage of the clarity and simplicity of the declarative approach as well as the expressivity of the imperative model.","inversion of control, garbage collection, event-driven, reactive programming, duality, combinator libraries",ISMM '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Petricek T,Syme D",Collecting Hollywood's Garbage: Avoiding Space-Leaks in Composite Events,SIGPLAN Not.,2010,45,8,53–62,Association for Computing Machinery,"New York, NY, USA",,,,2010-06,,0362-1340,https://doi.org/10.1145/1837855.1806662;http://dx.doi.org/10.1145/1837855.1806662,10.1145/1837855.1806662,"The reactive programming model is largely different to what we're used to as we don't have full control over the application's control flow. If we mix the declarative and imperative programming style, which is usual in the ML family of languages, the situation is even more complex. It becomes easy to introduce patterns where the usual garbage collector for objects cannot automatically dispose all components that we intuitively consider garbage.In this paper we discuss a duality between the definitions of garbage for objects and events. We combine them into a single one, to specify the notion of garbage for reactive programming model in a mixed functional/imperative language and we present a formal algorithm for collecting garbage in this environment.Building on top of the theoretical model, we implement a library for reactive programming that does not cause leaks when used in the mixed declarative/imperative model. The library allows us to safely combine both of the reactive programming patterns. As a result, we can take advantage of the clarity and simplicity of the declarative approach as well as the expressivity of the imperative model.","inversion of control, event-driven, garbage collection, reactive programming, duality, combinator libraries",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ilčík M,Fiedler S,Purgathofer W,Wimmer M",Procedural Skeletons: Kinematic Extensions to CGA-Shape Grammars,,2010,,,157–164,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th Spring Conference on Computer Graphics,"Budmerice, Slovakia",2010,9781450305587,,https://doi.org/10.1145/1925059.1925087;http://dx.doi.org/10.1145/1925059.1925087,10.1145/1925059.1925087,"Procedural modeling for architectural scenes was as yet limited to static objects only. We introduce a novel extension layer for shape grammars which creates a skeletal system for posing and interactive manipulation of generated models. Various models can be derived with the same set of parametrized rules for geometric operations. Separation of geometry generation and pose synthesis improves design efficiency and reusability. Moreover, by formal analysis of production rules we show how to efficiently update complex kinematic hierarchies created by the skeletons, allowing state-of-the-art interactive visual rule editing.","architecture, skeletal animation, shape grammars, procedural modeling",SCCG '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Vastag S,Modeling Quantitative Requirements in SLAs with Network Calculus,,2011,,,391–398,"ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)","Brussels, BEL",,Proceedings of the 5th International ICST Conference on Performance Evaluation Methodologies and Tools,"Paris, France",2011,9781936968091,,,,"When planning Service-Oriented Architectures requirements declared in Service Level Agreements (SLAs) have to be considered. SLAs cover functional as well as quantitative requirements like load levels, services rates and delay times. As external factors can influence distributed systems, SLAs have to include tolerances for quantitative requirements.Early design phases of SOA use analytic models to check functional properties. However, formalization of quantitative requirements in SLAs and their validation in analytic models is still a field of research. A challenge is the description of soft deadlines and the way delay times grow under different load levels.Network Calculus system theory can give bounds on delay times in systems. It has already been used to validate hard deadlines in networks and embedded systems. For its use in SOA models, soft deadlines and other aspects derived from SLAs have to be included. This paper introduces a new method to control delay times in Network Calculus models in order to specify quantitative requirements. The basic Network Calculus concept of arrival and service curves is extended with delay curves and their relationship is discussed.",,VALUETOOLS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Lv Q,Josephson W,Wang Z,Charikar M,Li K",Intelligent Probing for Locality Sensitive Hashing: Multi-Probe LSH and Beyond,Proc. VLDB Endow.,2017,10,12,2021–2024,VLDB Endowment,,,,,2017-08,,2150-8097,https://doi.org/10.14778/3137765.3137836;http://dx.doi.org/10.14778/3137765.3137836,10.14778/3137765.3137836,"The past decade has been marked by the (continued) explosion of diverse data content and the fast development of intelligent data analytics techniques. One problem we identified in the mid-2000s was similarity search of feature-rich data. The challenge here was achieving both high accuracy and high efficiency in high-dimensional spaces. Locality sensitive hashing (LSH), which uses certain random space partitions and hash table lookups to find approximate nearest neighbors, was a promising approach with theoretical guarantees. But LSH alone was insufficient since a large number of hash tables were required to achieve good search quality. Building on an idea of Panigrahy, our multi-probe LSH method introduced the idea of intelligent probing. Given a query object, we strategically probe its neighboring hash buckets (in a query-dependent fashion) by calculating the statistical probabilities of similar objects falling into each bucket. Such intelligent probing can significantly reduce the number of hash tables while achieving high quality. In this paper, we revisit the problem motivation, the challenges, the key design considerations of multi-probe LSH, as well as discuss recent developments in this space and some questions for further research.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Nagaraj SV,Review of Market Design: A Linear Programming Approach to Auctions and Matching,SIGACT News,2020,51,2,11–14,Association for Computing Machinery,"New York, NY, USA",,,,2020-06,,0163-5700,https://doi.org/10.1145/3406678.3406683;http://dx.doi.org/10.1145/3406678.3406683,10.1145/3406678.3406683,"Nowadays, supply has to be matched with demand for various types of goods and services. For designing real-world markets, the study of market design becomes essential, which is the focus of this book. The book comprises four parts and consists of twelve chapters. A brief introductory chapter provides an outline of the book. The first part focuses on microeconomic fundamentals. The second part is on multi-object auction design. The third part looks at approximation and matching markets. The fourth part has appendices on linear optimization, and algorithms and complexity At the end of the book, there are references to the literature and a helpful index. Many chapters include questions for comprehension and problems for practice. The book is intended to be a textbook for a single semester course on market design. The prerequisites for the book include familiarity with linear programming, integer linear programming, rudimentary calculus and probability theory. The intended audience comprises students with backgrounds in computer science, information systems, mathematics, and management science. The book is available in hardcover and eBook formats. The ISBN/price are 9781107173187 / US $ 64.99 and 9781316805350 / US $ 52 for the hardback and eBook respectively.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kuijpers B,Miller HJ,Othman W",Kinetic Space-Time Prisms,,2011,,,162–170,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,"Chicago, Illinois",2011,9781450310314,,https://doi.org/10.1145/2093973.2093996;http://dx.doi.org/10.1145/2093973.2093996,10.1145/2093973.2093996,"The space-time path and prism demarcate the estimated and potential locations (respectively) of a moving object with respect to time. The path is typically formed through linear interpolation between sampled locations of a moving object, while the prism is the envelope of all possible paths between two locations given the maximum speed of travel. The classic path and prism, however, are not physically realistic since they imply the ability of the object to make instantaneous changes in direction and speed without acceleration and deceleration. This is not acceptable in applications where kinetics is vital for scientific understanding such as animal ecology, vehicles moving through media such as ships through water and planes through air, human-powered movement such as bicycling and walking and environmental applications of transportation such as energy consumption and emissions modeling. In this paper we demonstrate how imposing an upper bound on acceleration, as well as information such as the initial speed and heading, affects the geometry of the space-time prism. We discuss how to calculate kinetic paths and prisms in one-dimensional and two dimensional space, and provide examples comparing the kinetic prisms and classical prisms.","space-time prism, GIS",GIS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Momeni A,McNamara D",MOD: A Portable Instrument for Mixing Analog and Digital Drawing for Live Cinema,,2018,,,460–469,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Twelfth International Conference on Tangible, Embedded, and Embodied Interaction","Stockholm, Sweden",2018,9781450355681,,https://doi.org/10.1145/3173225.3173254;http://dx.doi.org/10.1145/3173225.3173254,10.1145/3173225.3173254,"This paper describes the design and fabrication of MOD (Mo- bile Object for Drawing)-a portable instrument for combining analog and digital drawing. MOD is intended for live performance and content creation efforts that mix common analog drawing interfaces (i.e. paper, transparency, pencil, marker) with digital cameras (webcams, scientific imaging cameras, digital magnifiers and microscopes), custom software (for keying, thresholding, looping, layer) and digital projectors. The iteration of the instrument described here combines all of these components into a single portable battery powered pack- age that embeds the computation on a small linux computer, includes a small laser projector, and integrates custom tac- tile controllers. The intended uses of this instrument include experimental performance and rapid content creation; the instrument is intended to be suitable for formal (concert hall, theater) and informal (street performance, busking, parade, protest) settings, classrooms and maker spaces.","live cinema, performance, drawing, mobile, interactive, project, portable, instrument, intervention, projection mapping, animation",TEI '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Marinescu MC,Sánchez C",Fusing Statecharts and Java,ACM Trans. Embed. Comput. Syst.,2013,12,1s,,Association for Computing Machinery,"New York, NY, USA",,,,2013-03,,1539-9087,https://doi.org/10.1145/2435227.2435241;http://dx.doi.org/10.1145/2435227.2435241,10.1145/2435227.2435241,"This article presents FUSE, an approach for modeling and implementing embedded software components which starts from a main-stream programming language and brings some of the key concepts of Statecharts as first-class elements within this language. Our approach provides a unified programming environment which not only preserves some of the advantages of Statecharts' formal foundation but also directly supports features of object-orientation and strong typing. By specifying Statecharts directly in FUSE we eliminate the out-of-synch between the model and the generated code and we allow the tuning and debugging to be done within the same programming model. This article describes the main language constructs of FUSE and presents its semantics by translation into the Java programming language. We conclude by discussing extensions to the base language which enable the efficient static checking of program properties.","modeling, state-charts, programming languages, Embedded systems",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Klein C,Flatt M,Findler RB","Random Testing for Higher-Order, Stateful Programs",,2010,,,555–566,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Object Oriented Programming Systems Languages and Applications,"Reno/Tahoe, Nevada, USA",2010,9781450302036,,https://doi.org/10.1145/1869459.1869505;http://dx.doi.org/10.1145/1869459.1869505,10.1145/1869459.1869505,"Testing is among the most effective tools available for finding bugs. Still, we know of no automatic technique for generating test cases that expose bugs involving a combination of mutable state and callbacks, even though objects and method overriding set up exactly that combination. For such cases, a test generator must create callbacks or subclasses that aggressively exercise side-effecting operations using combinations of generated objects.This paper presents a new algorithm for randomly testing programs that use state and callbacks. Our algorithm exploits a combination of contracts and environment bindings to guide the test-case generator toward interesting inputs. Our prototype implementation for Racket (formerly PLT Scheme) - which has a Java-like class system, but with first-class classes as well as gbeta-like augmentable methods - uncovered dozens of bugs in a well-tested and widely used text-editor library.We describe our approach in a precise, formal notation, borrowing the techniques used to describe operational semantics and type systems. The formalism enables us to provide a compact and self-contained explanation of the core of our technique without the ambiguity usually present in pseudo-code descriptions.","racket, automated test generation, software testing, random testing",OOPSLA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Klein C,Flatt M,Findler RB","Random Testing for Higher-Order, Stateful Programs",SIGPLAN Not.,2010,45,10,555–566,Association for Computing Machinery,"New York, NY, USA",,,,2010-10,,0362-1340,https://doi.org/10.1145/1932682.1869505;http://dx.doi.org/10.1145/1932682.1869505,10.1145/1932682.1869505,"Testing is among the most effective tools available for finding bugs. Still, we know of no automatic technique for generating test cases that expose bugs involving a combination of mutable state and callbacks, even though objects and method overriding set up exactly that combination. For such cases, a test generator must create callbacks or subclasses that aggressively exercise side-effecting operations using combinations of generated objects.This paper presents a new algorithm for randomly testing programs that use state and callbacks. Our algorithm exploits a combination of contracts and environment bindings to guide the test-case generator toward interesting inputs. Our prototype implementation for Racket (formerly PLT Scheme) - which has a Java-like class system, but with first-class classes as well as gbeta-like augmentable methods - uncovered dozens of bugs in a well-tested and widely used text-editor library.We describe our approach in a precise, formal notation, borrowing the techniques used to describe operational semantics and type systems. The formalism enables us to provide a compact and self-contained explanation of the core of our technique without the ambiguity usually present in pseudo-code descriptions.","racket, random testing, automated test generation, software testing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Di Giusto C,Pérez JA",Disciplined Structured Communications with Consistent Runtime Adaptation,,2013,,,1913–1918,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual ACM Symposium on Applied Computing,"Coimbra, Portugal",2013,9781450316569,,https://doi.org/10.1145/2480362.2480716;http://dx.doi.org/10.1145/2480362.2480716,10.1145/2480362.2480716,"Session types offer a powerful type-theoretic foundation for the analysis of structured communications, as commonly found in service-oriented systems. They are defined upon core programming calculi which offer only limited support for expressing adaptation and evolvability requirements. This is unfortunate, as service-oriented systems are increasingly being deployed upon highly dynamic infrastructures in which such requirements are central concerns. In previous work, we developed a process calculi framework of adaptable processes, in which concurrent processes can be replaced, suspended, or discarded at runtime. In this paper, we propose a session types discipline for a calculus with adaptable processes. Our framework offers an alternative for integrating runtime adaptation mechanisms in the analysis of structured communications. We show that well-typed processes enjoy consistency: communicating behavior is never interrupted by evolvability actions.",,SAC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Uskenbayeva RK,Mukhanov SB",Contour Analysis of External Images,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th International Conference on Engineering & MIS 2020,"Almaty, Kazakhstan",2020,9781450377362,,https://doi.org/10.1145/3410352.3410811;http://dx.doi.org/10.1145/3410352.3410811,10.1145/3410352.3410811,"Image recognition occupies a special place in the science of computer vision. Contour analysis particular important in pattern recognition. In this paper, we consider the structure of the contour analysis of external images. Active contour method shows the possibilities of using the minimum energy curve. The energy function that defines boundaries without first isolating the boundaries of an image object. Therefore, the Canny Boundary Detector algorithm is used to detect the contours of an object in an image. This algorithm smooths out image blur and eliminates noise, eliminates errors or interference in the picture. The path tracking method crosses out the boundaries between the subject and the background. Algorithms such as machine learning are needed in order to reflect its performance and the need for recognition. Clustering is used as a machine learning method to find the nearest neighbor criteria. The mathematical model of clustering has its own uniqueness and application for identifying borders or contours in the image. The contour detection and linking approach uses graph analysis, which works and does not lose efficiency in the presence of noise. The convexity defects contour analysis algorithm is able to determine the size of borders, and also uses the search for contour recesses and the introduction of key features when calculating object parameters.","OpenCV, Contour analysis, c++, active contour, recognition, canny",ICEMIS'20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Deng AW,Gwo CY",A Stable Algorithm Computing High-Order 3D Zernike Moments and Shape Reconstructions,,2020,,,38–42,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 4th International Conference on Digital Signal Processing,"Chengdu, China",2020,9781450376877,,https://doi.org/10.1145/3408127.3408130;http://dx.doi.org/10.1145/3408127.3408130,10.1145/3408127.3408130,"3D Zernike moments are used as the 3D object shape descriptors. In this paper, we introduce a series of stable algorithms for calculating high-order the 3D Zernike moments. A kind of recurrence formula among 3D Zernike radial polynomials is presented. A voxel-based algorithm is hereby developed. The proposed method provides an accurate reconstruction image. When our algorithms are applied to the 3D object 'Einstein bust' with 100x100x100 voxels, the error rate for the shape reconstruction attains its value 0.000012 and 0 for computing all moments up to order 350 (390 respectively).","Spherical harmonics, 3D Zernike polynomials, 3D Zernike moments, recurrence formula, 3D Zernike radial polynomials",ICDSP 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Balakrishnan N,Bytheway T,Sohan R,Hopper A",OPUS: A Lightweight System for Observational Provenance in User Space,,2013,,,,USENIX Association,USA,,Proceedings of the 5th USENIX Workshop on the Theory and Practice of Provenance,"Lombard, Illinois",2013,,,,,"A variety of current provenance systems address the challenges of provenance capture, storage and query. However they require special setup and configuration, do not capture all I/O operations and limit themselves to specific specialised platforms. In this paper we propose the design of a data provenance capture and query tool called OPUS. OPUS works entirely in user space, is light-weight and requires minimum user intervention. OPUS is based on a formal model for versioning provenance objects that enables the succinct, complete representation of I/O operations in a manner that abstracts it from the details of the underlying operating system.",,TaPP '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kim J,Choi JY,Kang I,Lee I",Generating Composite Behavior of Embedded Software Components Based on UML Behavioral Model and Process Algebra,SIGSOFT Softw. Eng. Notes,2011,36,1,1–9,Association for Computing Machinery,"New York, NY, USA",,,,2011-01,,0163-5948,https://doi.org/10.1145/1921532.1921562;http://dx.doi.org/10.1145/1921532.1921562,10.1145/1921532.1921562,"This paper defines formally the composite behavior of two main embedded software components; application software and platform. The two typical embedded software components interact with one another continuously to achieve the purpose of system, but they have different computation characteristics; application software is oriented to data-flow for implementing software's functionalities, whereas the platform is oriented to control-ow for the control of software's executions. Hence, it is not easy to represent those capabilities in one behavioral model to analyze their composite behaviors. Thus, this paper presents a formal modeling framework, in which application software and platforms are defined in appropriate specification language suited to their own characteristics, and their behaviors in models are composed to capture their interactive and composite behaviors in their composite executions. In particular, we focus here on defining their composite behaviors in formal way.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Aotani T,Kamina T,Masuhara H",Featherweight EventCJ: A Core Calculus for a Context-Oriented Language with Event-Based per-Instance Layer Transition,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Workshop on Context-Oriented Programming,"Lancaster, United Kingdom",2011,9781450308915,,https://doi.org/10.1145/2068736.2068737;http://dx.doi.org/10.1145/2068736.2068737,10.1145/2068736.2068737,"We propose Featherweight EventCJ, which is a small calculus for context-oriented languages with event-based per-instance layer controls like EventCJ. It extends ContextFJ with stores, labels and transitions for modeling the per-instance layer management, events and declarative layer transition rules, respectively.","layer transition, EventCJ, context-oriented programming",COP '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Guo HF,Zheng W,Subramaniam M",L2C2: Logic-Based LSC Consistency Checking,,2009,,,183–194,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th ACM SIGPLAN Conference on Principles and Practice of Declarative Programming,"Coimbra, Portugal",2009,9781605585680,,https://doi.org/10.1145/1599410.1599433;http://dx.doi.org/10.1145/1599410.1599433,10.1145/1599410.1599433,"Live sequence charts (LSCs) have been proposed as an inter-object scenario-based specification and visual programming language for reactive systems. In this paper, we introduce a logic-based framework to check the consistency of an LSC specification. An LSC simulator has been implemented in logic programming, utilizing a memoized depth-first search strategy, to show how a reactive system in LSCs would response to a set of external event sequences. A formal notation is defined to specify external event sequences, extending the regular expression with a parallel operator and a testing control. The parallel operator allows interleaved parallel external events to be tested in LSCs simultaneously; while the testing control provides users to a new approach to specify and test certain temporal properties (e.g., CTL formula) in a form of LSC. Our framework further provides either a state transition graph or a failure trace to justify the consistency checking results.","memoization, scenario-based programming, logic programming, play-tree, live sequence chart (lsc)",PPDP '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Becker B,Giese H",Modeling of Correct Self-Adaptive Systems: A Graph Transformation System Based Approach,,2008,,,508–516,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology,"Cergy-Pontoise, France",2008,9781605580463,,https://doi.org/10.1145/1456223.1456326;http://dx.doi.org/10.1145/1456223.1456326,10.1145/1456223.1456326,Software is always embedded in a social and technical context which change over time and therefore also the software has to be adjusted over time to preserve its value. Self-adaptive systems provide a vision how the systems can become capable of doing a large fraction of the required adaptations autonomously. In this paper we first discuss what is required to model correct self-adaptive systems. We then present the formal model of graph transformation systems which serves most of the identified needs. Based on this findings we outline how UML class and object diagrams as well as extensions for the modeling of behavior based upon graph transformation systems can be employed to model correct self-adaptive system. An application example is used to present how the approach can be employed to model self-adaptive systems at a high level of abstraction and means to ensure its correctness are discussed.,"invariant checking, self-adaptive systems, graph transformations, modeling, correctness",CSTST '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rinaldi AM,Russo C",A Semantic-Based Model to Represent Multimedia Big Data,,2018,,,31–38,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Conference on Management of Digital EcoSystems,"Tokyo, Japan",2018,9781450356220,,https://doi.org/10.1145/3281375.3281386;http://dx.doi.org/10.1145/3281375.3281386,10.1145/3281375.3281386,"The use of formal representation is a key task in the era of big data. In the context of multimedia big data this issue is stressed due to the intrinsic complexity nature of this kind of data. Moreover, the relations among objects should be clearly expressed and formalized to give the right meaning of data correlation. For this reason the design of formal models to represent and manage information is a necessary task to implement intelligent information systems. In this latter some approaches related to the semantic web could be used to improve the data models which underlie the implementation of big data applications. Using these models the visualization of data and information become an intrinsic and strategic task for the analysis and exploration of multimedia BigData. In this paper we propose the use of a semantic approach to formalize the model structure of multimedia BigData. In addition, the recognition of multimodal features to represent concepts and linguistic properties to relate them are an effective way to bridge the gap between the target semantic classes and the available low-level multimedia descriptors. The proposed model has been implemented in a NoSQL graph database populated from different knowledge sources and a visualization of this very large knowledge base has been presented and discussed as a case study.","semantics, multimedia ontologies, semantic bigdata",MEDES '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sarmento WW,Paula PS,Filho PT,Pallard GA,Souza JN,Barroso GC,Pequeno MC",U-Lab: A Ubiquitous Computing Based Architecture to Labs Works Using Wireless Sensor Network and Radio-Frequency Identification,,2012,,,260–266,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th Euro American Conference on Telematics and Information Systems,"Valencia, Spain",2012,9781450310123,,https://doi.org/10.1145/2261605.2261644;http://dx.doi.org/10.1145/2261605.2261644,10.1145/2261605.2261644,"Wireless Sensor Networks and Radio Frequency Identification are two technologies that are being used together to monitor and identify objects and people. Their application may cover from a supermarket storage section to a forest monitoring process, having to face a diversity of problems within the scope of Computer Science and Engineering. The present work proposes the use of these technologies in the scope of Education - more specifically in the area of laboratory practice, using a formal modeling technique called Coloured Petri Networks for creating the initial models that would form the architecture of the proposed solution.","ubiquitous learning, RFID, WSN, lab works",EATIS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Balbiani P,Fernández-Duque D,Lorini E",A Logical Theory of Belief Dynamics for Resource-Bounded Agents,,2016,,,644–652,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems,"Singapore, Singapore",2016,9781450342391,,,,"The paper presents a new logic for reasoning about the formation of beliefs through perception or through inference in non-omniscient resource-bounded agents. The logic distinguishes the concept of explicit belief from the concept of background knowledge. This distinction is reflected in its formal semantics and axiomatics: (i) we use a non-standard semantics putting together a neighbourhood semantics for explicit beliefs and relational semantics for background knowledge, and (ii) we have specific axioms in the logic highlighting the relationship between the two concepts. Mental operations of perceptive type and inferential type, having effects on epistemic states of agents, are primitives in the object language of the logic. At the semantic level, they are modelled as special kinds of model-update operations, in the style of dynamic epistemic logic (DEL). Results about axiomatization, decidability and complexity for the logic are given in the paper.","cognitive agents, epistemic logic, resoure-bounded reasoning",AAMAS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Niemann P,Hilken F,Gogolla M,Wille R",Assisted Generation of Frame Conditions for Formal Models,,2015,,,309–312,EDA Consortium,"San Jose, CA, USA",,"Proceedings of the 2015 Design, Automation & Test in Europe Conference & Exhibition","Grenoble, France",2015,9783981537048,,,,"Modeling languages such as UML or SysML allow for the validation and verification of the structure and the behavior of designs even in the absence of a specific implementation. However, formal models inherit a severe drawback: Most of them hardly provide a comprehensive and determinate description of transitions from one system state to another. This problem can be addressed by additionally specifying so-called frame conditions. However, only naive \workarounds\"" based on trivial heuristics or completely relying on a manual creation have been proposed for their generation thus far. In this work",we aim for a solution which neither leaves the burden of generating frame conditions entirely on the designer (avoiding the introduction of another time-consuming and expensive design step) nor is completely automatic (which,due to ambiguities,is not possible anyway). For this purpose,"a systematic design methodology for the assisted generation of frame conditions is proposed.""",,DATE '15,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Larson JA,Wallick JB",An Interface for Novice and Infrequent Database Management System Users,,1984,,,523–529,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the July 9-12, 1984, National Computer Conference and Exposition","Las Vegas, Nevada",1984,9780882830438,,https://doi.org/10.1145/1499310.1499379;http://dx.doi.org/10.1145/1499310.1499379,10.1145/1499310.1499379,"Special interfaces are needed for novice and infrequent users of database management systems. Such interfaces must remind users of the structure and names of database objects as they guide users in formulating syntactically valid database commands. A prototype system developed at the Honeywell Corporate Technology Center provides such an interface by integrating schema displays depicting the contents and structure of the database and syntax diagrams representing the valid syntactic options of a database query language. By traversing these graphs, novice and infrequent database management system users can easily formulate syntactically valid database management system commands while learning the formal syntax of the database management system command language.",,AFIPS '84,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Deng J,Lu Y,Ke J",An Accurate Neural Network for Cytologic Whole-Slide Image Analysis,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Australasian Computer Science Week Multiconference,"Melbourne, VIC, Australia",2020,9781450376976,,https://doi.org/10.1145/3373017.3373039;http://dx.doi.org/10.1145/3373017.3373039,10.1145/3373017.3373039,"Typically, high accuracy in deep learning is achieved by large dataset in pixel-wise labeling for segmentation or image-level labeling for classification. However, in biomedical domain, the challenge is not only the availability of image data itself, but also the acquisition of relevant annotations for these images from clinicians. In this work, we propose a novel two-stage architecture to jointly perform the tasks of detection, segmentation and classification of abnormal cells and cancer. Compared with one-step detection for all the catalogues, we combine the advantage of image-level and pixel-level labeling in our deep learning based framework. We use the detection of lesions in cervical clinical dataset as a case study for performance evaluation. In the first stage, a hybrid ResNet and U-Net architecture is designed to predict three catalogues of nuclei, cytoplasm and background with pixel-wise labeled segmentation map. In the second stage, a residual learning based model is applied to the identified nuclei for subtype classification. Confirmed with cytotechnologist, the proposed model is estimated to efficiently deduct more than 90% annotation burden compared with pixel-wise labeling approach. Moreover, the proposed two-stage approach model outperforms one-stage neural network in segmentation and classification for objects with high similarities in appearance. Our collected real-life clinical cytology images and the source code in the experiments are provided in https://github.com/SJTU-AI-GPU/TwoStageCellSegmentation.1","segmentation and classification, two-stage deep learning, detection, pixel-wise and image-level labeling, cervical cancer",ACSW '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Volkmann T,Wessel D,Caliebe TO,Jochems N",What You See Isn't Necessarily What You Get: Testing the Influence of Polygon Count on Physical and Self-Presence in Virtual Environments,,2020,,,119–128,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Conference on Mensch Und Computer,"Magdeburg, Germany",2020,9781450375405,,https://doi.org/10.1145/3404983.3405590;http://dx.doi.org/10.1145/3404983.3405590,10.1145/3404983.3405590,"A key characteristic for the effectiveness of Virtual Reality Environments is a high sense of presence - the feeling of being in that virtual place, even though being physically in another location. For a more differentiated perspective on presence, the term can be defined by subtypes, such as physical, social and self-presence. The Multimodal Presence Scale (MPS) by Makransky and colleagues deals with these dimensions, was translated into German, and evaluated regarding the sensitivity and specificity of the social presence subscale. The results raise the question how well differences in physical and self-presence can be detected by the scale. We conducted an experiment by constructing two virtual worlds, manipulating the polygon count of objects in each world, and measuring presence. Additionally, we assessed the correlation of the MPS with the Igroup Presence Questionnaire (IPQ). No significant differences in physical or self-presence were found. However, when examining an item that closely matches the manipulation of the self-presence world (the user's virtual hands), a statistically significant difference was found. We provide three possible explanations for these results: 1) an insufficient impact of the abstraction levels, e.g., due to insufficient time and attention to the manipulation, or too little difference between the abstraction levels, 2) a lack of sensitivity of the used MPS and IPQ, or 3) the polygon count not being important for physical or self-presence. We conclude that high polygon count might not be that crucial for presence and provide suggestions for future research.","scale, presence, measurement, HMD, virtual reality, virtual characters",MuC '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Abiteboul S,Bourhis P,Vianu V",Highly Expressive Query Languages for Unordered Data Trees,,2012,,,46–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th International Conference on Database Theory,"Berlin, Germany",2012,9781450307918,,https://doi.org/10.1145/2274576.2274583;http://dx.doi.org/10.1145/2274576.2274583,10.1145/2274576.2274583,"We study highly expressive query languages for unordered data trees, using as formal vehicles Active XML and extensions of languages in the while family. All languages may be seen as adding some form of control on top of a set of basic pattern queries. The results highlight the impact and interplay of different factors: the expressive power of basic queries, the embedding of computation into data (as in Active XML), and the use of deterministic vs. nondeterministic control. All languages are Turing complete, but not necessarily query complete in the sense of Chandra and Harel. Indeed, we show that some combinations of features yield serious limitations, analogous to FOk definability in the relational context. On the other hand, the limitations come with benefits such as the existence of powerful normal forms. Other languages are \almost\"" complete","but fall short because of subtle limitations reminiscent of the copy elimination problem in object databases.""","XML, expressiveness, data trees",ICDT '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Edwards C,Gruner S",A New Tool for URDAD to Java EE EJB Transformations,,2013,,,144–153,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the South African Institute for Computer Scientists and Information Technologists Conference,"East London, South Africa",2013,9781450321129,,https://doi.org/10.1145/2513456.2513459;http://dx.doi.org/10.1145/2513456.2513459,10.1145/2513456.2513459,"Following the Object Management Group's (OMG) Model-Driven Architecture (MDA) approach, the semi-formal, service-orientated \Use Case","Responsibility Driven Analysis and Design\"" (URDAD) method is used by requirements engineers to specify a software system's functional properties in a Platform Independent Model (PIM). PIMs are represented using the URDAD Domain Specific Language (DSL)",and thus conform to the URDAD MOF meta model. As a result,they can be transformed into Platform-Specific Models (PSM) for frameworks such as Java Platform Enterprise Edition (JEE) Enterprise Java Beans (EJB). This paper describes the semi-automatic transformation of a URDAD PIM into a EJB PSM,which is the basis for the further generation of EJB program code. For this purpose,a new prototype CASE tool was implemented to facilitate such transformations. The tool was evaluated using a non-trivial example project,"with results indicating that it produces the PSM and template code that constitutes the static Java EE EJB structural representation of the example PIM.""","JaMoPP, EJB, URDAD, model transformation, CASE tool, QVT, MOF, MDA",SAICSIT '13,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Jianqiang Y,Research on the Narrative Design of Human-Computer Interaction in Network Virtual Museum,,2021,,,182–187,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2021 International Conference on Control and Intelligent Robotics,"Guangzhou, China",2021,9781450390231,,https://doi.org/10.1145/3473714.3473744;http://dx.doi.org/10.1145/3473714.3473744,10.1145/3473714.3473744,"The content of this article is the design of the narrative content of the network virtual museum based on digital media technology. The research method of this article is based on the theory of narratology. It introduces the interactive relationship between virtual museums and narratology from the perspective of human-computer interface technology. Through case analysis, bibliometrics, questionnaire surveys and, other methods, the Forbidden City is selected. The virtual museum project launched by the museum is the object of analysis. It discusses the design and application of narrative thinking and emotional experience in virtual museums and extends the research on interactive narrative structures in games and film art. It finds similarities and differences and chooses the essence of it, which solves the current virtual museum. The shortcomings of the interactive narrative content, such as selectivity, unity and, participation, create a new formal language and provide strong practical support for the interactive narrative method of the virtual museum.","Post-epidemic era, narratology, interactivity, virtual museum",ICCIR 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Buchholtz U,Rijke E",The Real Projective Spaces in Homotopy Type Theory,,2017,,,,IEEE Press,"Reykjavík, Iceland",,Proceedings of the 32nd Annual ACM/IEEE Symposium on Logic in Computer Science,,2017,9781509030187,,,,"Homotopy type theory is a version of Martin-Löf type theory taking advantage of its homotopical models. In particular, we can use and construct objects of homotopy theory and reason about them using higher inductive types. In this article, we construct the real projective spaces, key players in homotopy theory, as certain higher inductive types in homotopy type theory. The classical definition of RPn, as the quotient space identifying antipodal points of the n-sphere, does not translate directly to homotopy type theory. Instead, we define RPn by induction on n simultaneously with its tautological bundle of 2-element sets. As the base case, we take RP-1 to be the empty type. In the inductive step, we take RPn+1 to be the mapping cone of the projection map of the tautological bundle of RPn, and we use its universal property and the univalence axiom to define the tautological bundle on RPn+1.By showing that the total space of the tautological bundle of RPn is the n-sphere Sn, we retrieve the classical description of RPn+1 as RPn with an (n + 1)-disk attached to it. The infinite dimensional real projective space RP∞, defined as the sequential colimit of RPn with the canonical inclusion maps, is equivalent to the Eilenberg-MacLane space K(Z/2Z, 1), which here arises as the subtype of the universe consisting of 2-element types. Indeed, the infinite dimensional projective space classifies the 0-sphere bundles, which one can think of as synthetic line bundles.These constructions in homotopy type theory further illustrate the utility of homotopy type theory, including the interplay of type theoretic and homotopy theoretic ideas.","real projective spaces, higher inductive types, univalence axiom, homotopy type theory",LICS '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pollock J,Roesch J,Woos D,Tatlock Z",Theia: Automatically Generating Correct Program State Visualizations,,2019,,,46–56,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 ACM SIGPLAN Symposium on SPLASH-E,"Athens, Greece",2019,9781450369893,,https://doi.org/10.1145/3358711.3361625;http://dx.doi.org/10.1145/3358711.3361625,10.1145/3358711.3361625,"Program state visualizations (PSVs) help programmers understand hidden program state like objects, references, and closures. Unfortunately, existing PSV tools do not support custom language semantics, which educators often use to introduce programming languages gradually. They also fail to visualize key pieces of program state, which can lead to incorrect and confusing visualizations. Theia, a generic PSV framework, uses formal abstract machine definitions to produce complete, continuous, and consistent (CCC) PSVs. To produce CCC visualizations with Theia, an educator only needs to specify an abstract machine and optionally customize the resulting web page, allowing her to visualize custom language semantics without developing a language-specific tool.","operational semantics, CS2, notional machine, CS1, abstract machine, program visualization",SPLASH-E 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kuznetcov Y,Fomin M,Vinogradov A","Multidimensional Information Systems Metadata Repository Development with a Data Warehouse Structure Using \Data Vault\"" Methodology""",,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the XI International Scientific Conference Communicative Strategies of the Information Society,"St. Petersburg, Russian Federation",2019,9781450376709,,https://doi.org/10.1145/3373722.3373777;http://dx.doi.org/10.1145/3373722.3373777,10.1145/3373722.3373777,"When organizing automated data collection in a data warehouse under the conditions of increasing data volume and complicating the business model of an enterprise, an information system data model control becomes one of the priority tasks. The article discusses a method of metadata repository developing in terms of metadata responsible for describing business objects and the relationships between them. The choice of \Data vault\"" determines the construction of a data warehouse within the framework of an information system based on the classical design approach with a 3-level data presentation architecture",which includes a data preparation area,or an online data warehouse,data warehouse and thematic data marts. The proposed approach allows organizing data storage within the data warehouse using a metadata repository based on the multidimensional organization principle. The metadata repository is responsible for the data collection process,the data storage process,and the presentation of data for analysis. The metadata repository is presented in the form of a metamodel that is semantically related to the domain of the system,is easily reconstructed in case of changes in the business model of the domain,and allows data marts to be created with the structure of a multidimensional data model based on the Star relational scheme. This allows you to organize the human-computer interaction when describing a metamodel,using mainly knowledge about the structure of the subject area. When describing a metamodel,the first-order predicate calculus language is used,"which makes it possible to control the metamodel using a declarative programming style - the \""Prolog\"" language. The key point in the structure of the information system is the way of transition from the \""Data vault\"" model to a multidimensional data representation model based on associative rules of dependence between information objects.""","OLAP, data mart, data vault, Data warehouse, multidimensional data model",CSIS'2019,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hoelz BW,Ralha CG",A Framework for Semantic Annotation of Digital Evidence,,2013,,,1966–1971,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual ACM Symposium on Applied Computing,"Coimbra, Portugal",2013,9781450316569,,https://doi.org/10.1145/2480362.2480729;http://dx.doi.org/10.1145/2480362.2480729,10.1145/2480362.2480729,"Most tools used during the forensic examination process emphasize data and metadata extraction without a formal definition of the concepts used in their outputs. These vary not only in the terminology used, but also in the way values are represented. These differences hinder the adoption of computer-assisted analysis, since the elements to be analyzed are not well-defined, requiring ad hoc parsers to process and interpret the output of each tool. A framework for semantic annotation of digital evidence is presented in this work. Semantic annotations use concepts that are defined in an ontology to describe the annotated object. They can replace raw metadata, user-defined labels and tool-specific analysis results with computer-readable, formally defined terms that can be used in semantically advanced queries. The framework's components provide means to extract, analyze and index the contents of the digital evidence. The framework allows the augmentation of a base ontology, by adding domain and case-specific concepts to it. A prototype implementation is described and a case study is conducted to illustrate its potential uses and improvements to the forensic examination process.","semantic annotation, ontology, metadata, digital evidence",SAC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rusev H,Buliev I,Kolev J",Identification of Deformations on Smooth Surfaces,,2012,,,282–289,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th International Conference on Computer Systems and Technologies,"Ruse, Bulgaria",2012,9781450311939,,https://doi.org/10.1145/2383276.2383318;http://dx.doi.org/10.1145/2383276.2383318,10.1145/2383276.2383318,The work is dedicated to the discovering and estimation of local deformations on smooth surfaces of unknown shape. Stereo vision principle is used. The analyzed surface is illuminated by a structured light from a laser projector and an image of the surface is acquired by a photo camera. A 3D approximated object surface is computed and used to determine the corrections of the camera image perspective distortions. Another light pattern of stripes is next projected over the object and the local deformations of its surface are estimated by calculating the Euclidian distances between the contours of the stripes and their low-order polynomial approximations on the acquired image. The experimental results confirm the feasibility of the proposed approach.,"structured light, deformation identification, stereo vision",CompSysTech '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Baxter R,Crumley Z,Neeser R,Gain J",Automatic Addition of Physics Components to Procedural Content,,2010,,,101–110,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 7th International Conference on Computer Graphics, Virtual Reality, Visualisation and Interaction in Africa","Franschhoek, South Africa",2010,9781450301183,,https://doi.org/10.1145/1811158.1811175;http://dx.doi.org/10.1145/1811158.1811175,10.1145/1811158.1811175,"While the field of procedural content generation is growing, there has been somewhat less work on developing procedural methods to animate these models. We present a technique for generating procedural models of trees and buildings via formal grammars (L-Systems and wall grammars) that are ready to be animated using physical simulation. The grammars and their interpretations are augmented to provide direct control over the physical animation, by, for example, specifying object mass and the joint stiffness. Example animations produced by our system include trees swaying in a gentle wind or being rocked by a gale, and buildings collapsing, imploding or exploding. In user testing, we had test subjects (n = 20) compare our animations with video of trees and buildings undergoing similar effects, as well as with animations in games that they have played. Results show that our animations appear physically accurate with a few minor instances of unrealistic behaviour. Users considered the animations to be more realistic than those used in current video games.","L-systems, shape grammars, wall grammars, descriptive grammars, dynamic animation, physics, procedural generation",AFRIGRAPH '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lin Y,Zhang B,Xu J,Li J,Zhao C,Yu D",Hierarchical Building Extraction from High-Resolution Remote Sensing Imagery Based on Multi-Feature and Multi-Scale Method,,2018,,,17–23,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Multimedia and Image Processing,"Guiyang, China",2018,9781450364683,,https://doi.org/10.1145/3195588.3195601;http://dx.doi.org/10.1145/3195588.3195601,10.1145/3195588.3195601,"In this paper, according to the building characteristics in high-resolution remote sensing imagery, a multi-feature and multi-scale method is proposed. First, based on imagery processing, the building index is constructed by multi-scale and multi-direction gradient operators, and some rectangle buildings are extracted by the building index, the morphology open operation and the shape features. Subsequently, the voting matrix is calculated by the number of pixels included in the intersection of the expansion results and the shadow to determine the light direction. The initial extraction of the building is completed after removing open spaces and other disturbances by shadow feature and light direction. Next, the texture feature vector of the initial extraction results is clustered and pixel-level building extraction is obtained by the probability model, which is established by utilizing the textural feature vector of the cluster results. The object-level building extraction results are achieved with the combination of the pixel-level results and image segmentation. Finally, the final extraction results are obtained based on the binary decision tree. Experimental results show that the proposed method can make full use of the feature information, effectively combines the advantages of different scales, and can also extract building objects with high accuracy and great applicability.","Gaussian model, high resolution remote sensing imagery, building extraction, multi-scale, multi-feature",ICMIP 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Koch C,Incremental Query Evaluation in a Ring of Databases,,2010,,,87–98,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Twenty-Ninth ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,"Indianapolis, Indiana, USA",2010,9781450300339,,https://doi.org/10.1145/1807085.1807100;http://dx.doi.org/10.1145/1807085.1807100,10.1145/1807085.1807100,"This paper approaches the incremental view maintenance problem from an algebraic perspective. We construct the algebraic structure of a ring of databases and use it as the foundation of the design of a query calculus that allows to express powerful aggregate queries. The query calculus inherits key properties of the ring, such as having a normal form of polynomials and being closed under computing inverses and delta queries. The k-th delta of a polynomial query of degree k without nesting is purely a function of the update, not of the database. This gives rise to a method of eliminating expensive query operators such as joins from programs that perform incremental view maintenance. The main result is that, for non-nested queries, each individual aggregate value can be incrementally maintained using a constant amount of work. This is not possible for nonincremental evaluation.","incremental view maintenance, algebra",PODS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Laird J,Game Semantics for a Polymorphic Programming Language,J. ACM,2013,60,4,,Association for Computing Machinery,"New York, NY, USA",,,,2013-09,,0004-5411,https://doi.org/10.1145/2508028.2505986;http://dx.doi.org/10.1145/2508028.2505986,10.1145/2508028.2505986,"This article presents a game semantics for higher-rank polymorphism, leading to a new model of the calculus System F, and a programming language which extends it with mutable variables. In contrast to previous game models of polymorphism, it is quite concrete, extending existing categories of games by a simple development of the notion of question/answer labelling and the associated bracketing condition to represent “copycat links” between positive and negative occurrences of type variables. Some well-known System F encodings of type constructors correspond in our model to simple constructions on games, such as the lifted sum.We characterize the generic types of our model (those for which instantiation reflects denotational equivalence), and show how to construct an interpretation in which all types are generic. We show how mutable variables (à la Scheme) may be interpreted in our model, allowing the definition of polymorphic objects with local state. By proving definability of finitary elements in this model using a decomposition argument, we establish a full abstraction result.","references, genericity, System F, Polymorphism, game semantics, full abstraction",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ghalem SK,Kechar B,Bounceur A,Euler R,Hammoudeh M,Lalem F",A Copula Based Approach for Measurement Validity Verification in Wireless Sensor Networks,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing","Cambridge, United Kingdom",2017,9781450347747,,https://doi.org/10.1145/3018896.3065829;http://dx.doi.org/10.1145/3018896.3065829,10.1145/3018896.3065829,"Outlier detection is the process of identifying the data objects that do not comply with the normal behavior of the defined data model. Used in automated data analysis, it ensures the desired data quality and reliability. This field has attracted increasing attention in the wireless sensor network domain, using methods from machine learning, data mining, and statistics. In this paper, we propose a novel outlier detection approach based on Copula theory. This powerful theory allows to model the dependency between data measurements in a formal and statistical way. We have evaluated our proposed approach with a real world dataset. Our results show a detection rate of 85.90% and an error rate of 0.87%.","outlier, WSN, copula, reliability, statistical, dependency",ICC '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Atoum I,A Scalable Operational Framework for Requirements Validation Using Semantic and Functional Models,,2019,,,1–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Software Engineering and Information Management,"Bali, Indonesia",2019,9781450366427,,https://doi.org/10.1145/3305160.3305166;http://dx.doi.org/10.1145/3305160.3305166,10.1145/3305160.3305166,"A successful operational software depends on adequacy and degrees of freedom in requirements definitions. The software developer in conjunction with the customer validates requirements to ensure the completion of the intended use and the capability of the target application. Notwithstanding, requirements validation is time-consuming, effortless and expensive, and many times involves error-prone manual activities. The difficulty of the problem increases with an increase in the application size, the application domain, and inherit textual requirements constructs. Current approaches to the problem are considered as passive-defect aggregations, domain-specific, or rather fine-grained with formal specifications. We propose a scalable operational framework to learn, predict, and recognize requirements defects using semantic similarity models and the Integration Functional Definition methods. The proposed framework automates the validation process and increases the productivity of software engineers online with customer needs. A proof of concept shows the applicability of our solution to requirements inconsistency defects.","semantic similarity, software requirements, deep learning, ISO 29148, functional models, requirements validation",ICSIM 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sinha SK,Benameur A",A Formal Solution to Rewriting Attacks on SOAP Messages,,2008,,,53–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Workshop on Secure Web Services,"Alexandria, Virginia, USA",2008,9781605582924,,https://doi.org/10.1145/1456492.1456501;http://dx.doi.org/10.1145/1456492.1456501,10.1145/1456492.1456501,"In Service Oriented Architecture Web Services, communication among services is banking on XML-Based messages, called SOAP messages. These messages are prone to attacks that are classified in literature as XML rewriting attacks. Since rewriting is a formal mechanism used in formal language theory, and the rewriting attack problem is designed under the framework of formal language theory, the solution also lies under the same framework. In this paper we propose a formal solution to XML rewriting attacks on SOAP messages using regular tree grammar. To the best of our knowledge this is the first formal solution to this problem. We define current XML signatures used in a SOAP message as context-free signature. The formal solution proposed here is a context-sensitive XML signature. To address the additional requirements of SOAP extensibility model, where a SOAP message can pass through several intermediaries before reaching the final receiver, an adaptive variant of context-sensitive signature is also proposed. The solution addresses different forms of XML rewriting attacks. An analysis of the solution is also given in the paper.","security, regular tree grammar, soap, xml rewriting attacks, context-free signature, context-sensitive signature, formal methods",SWS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mu N,Xu X,Zhang X",Estimation of Local and Global Superpixel Covariance for Salient Object Detection in Low Contrast Images,,2017,,,314–319,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Machine Learning and Computing,"Singapore, Singapore",2017,9781450348171,,https://doi.org/10.1145/3055635.3056574;http://dx.doi.org/10.1145/3055635.3056574,10.1145/3055635.3056574,"Salient object detection has become a hot topic in computer vision as it can substantially facilitate a wide range of applications. Conventional salient object detection models primarily rely on low-level image features, which may face great difficulties in low lighting scenarios. This paper proposes to estimate the saliency of low contrast images via covariance features. The input image is firstly decomposed into superpixel regions to estimate their covariances. Then, the local and global image saliency can be calculated using the covariance features respectively. Finally, a graph-based diffusion process is performed to refine the saliency maps. Extensive experiments have been conducted to evaluate the performance of the proposed model against eleven state-of-the-art models on five benchmark datasets and a nighttime image dataset.","covariance, Salient object detection, low contrast, superpixel",ICMLC 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xin Z,Lu T,Li X",Detection of Train Bottom Parts Based on XIoU,,2019,,,91–96,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 International Conference on Robotics Systems and Vehicle Technology,"Wuhan, China",2019,9781450362429,,https://doi.org/10.1145/3366715.3366742;http://dx.doi.org/10.1145/3366715.3366742,10.1145/3366715.3366742,"Due to the complexity, diversity, or even small size of train bottom parts, the current object detection algorithm cannot identify it accurately. We propose a new method to solve the above problem. This method changes the computational way of loss based on Darknet-yolov3 for specific train bottom parts and improves the situation that the object detection network has low accuracy in detecting. IoU(Intersection over Union) can be directly used as a regression loss. However, IoU has a plateau making it infeasible to optimize in the case of nonoverlapping bounding boxes. We put forward XIoU to calculate the loss function. XIoU calculates the case when IoU is equal to zero and increases the amount of prediction sample for regression loss. The test set used the No.2 camera pictures provided by railway administration. Compared with Mobile-Net, Yolov3 and Yolov3-giou, the experimental results showed that the training results of XIoU were 10% higher than Mobile-Net and Yolov3 on mAP, and 0.2% higher than Yolov3-giou.","Darknet-yolov3, IoU, XIoU, Train-Bottom-Parts",RSVT '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen H,Yin H,Wang W,Wang H,Nguyen QV,Li X",PME: Projected Metric Embedding on Heterogeneous Networks for Link Prediction,,2018,,,1177–1186,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining,"London, United Kingdom",2018,9781450355520,,https://doi.org/10.1145/3219819.3219986;http://dx.doi.org/10.1145/3219819.3219986,10.1145/3219819.3219986,"Heterogenous information network embedding aims to embed heterogenous information networks (HINs) into low dimensional spaces, in which each vertex is represented as a low-dimensional vector, and both global and local network structures in the original space are preserved. However, most of existing heterogenous information network embedding models adopt the dot product to measure the proximity in the low dimensional space, and thus they can only preserve the first-order proximity and are insufficient to capture the global structure. Compared with homogenous information networks, there are multiple types of links (i.e., multiple relations) in HINs, and the link distribution w.r.t relations is highly skewed. To address the above challenging issues, we propose a novel heterogenous information network embedding model PME based on the metric learning to capture both first-order and second-order proximities in a unified way. To alleviate the potential geometrical inflexibility of existing metric learning approaches, we propose to build object and relation embeddings in separate object space and relation spaces rather than in a common space. Afterwards, we learn embeddings by firstly projecting vertices from object space to corresponding relation space and then calculate the proximity between projected vertices. To overcome the heavy skewness of the link distribution w.r.t relations and avoid \over-sampling'' or \""under-sampling'' for each relation",we propose a novel loss-aware adaptive sampling approach for the model optimization. Extensive experiments have been conducted on a large-scale HIN dataset,"and the experimental results show superiority of our proposed PME model in terms of prediction accuracy and scalability.""","heterogenous network embedding, link prediction",KDD '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wu J,Claramunt C,Deng M",An Integrated Qualitative and Boundary-Based Formal Model for a Semantic Representation of Trajectories,SIGSPATIAL Special,2015,7,1,35–42,Association for Computing Machinery,"New York, NY, USA",,,,2015-05,,,https://doi.org/10.1145/2782759.2782766;http://dx.doi.org/10.1145/2782759.2782766,10.1145/2782759.2782766,"Nowadays, the tracking, representation and analysis of moving objects and trajectories have attracted several research efforts at the formal level. The work presented in this paper introduces a spatial qualitative approach for enriching semantic trajectories with movement predicates. The model developed integrates topological relations and qualitative distances between a trajectory and a region of interest. Such a spatio-temporal framework supports the derivation of the basic movement configurations derived from moving and static entities. The approach is flexible enough to reconstruct the trajectory as a sequence of highly-correlated episodes according to the underlying topological properties such as the dimension and cardinality of the intersections that emerge between the trajectory and the given region.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pashev G,Totkov G,Kostadinova H,Indzhov H",Personalized Educational Paths through Self-Modifying Learning Objects,,2016,,,437–444,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th International Conference on Computer Systems and Technologies 2016,"Palermo, Italy",2016,9781450341820,,https://doi.org/10.1145/2983468.2983516;http://dx.doi.org/10.1145/2983468.2983516,10.1145/2983468.2983516,"The paper presents a formal model for generation of personalized learning paths. The paths consist of self-modifying learning activities suitable for the achievement of course goals. The course goals (as defined by the teacher) are a list of functions/predicates with specific slots and include obligatory activities required for the automatized construction of learning paths. Further, the problems related to automatized learning path construction are identified and solved with the use of an original approach. The approach includes (but is not limited to): introduction of different points of view (aspects) for learning objects; automatized gathering/accumulation of metadata for learning activities; generation of personalized learning paths using set of student achievements, etc.","self-modifying learning objects, automatized metadata gathering, generation of e-learning paths, adaptive e-learning, revised Bloom taxonomy",CompSysTech '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Magro D,Goy A",The Business Knowledge for Customer Relationship Management: An Ontological Perspective,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the First International Workshop on Ontology-Supported Business Intelligence,"Karlsruhe, Germany",2008,9781605582191,,https://doi.org/10.1145/1452567.1452571;http://dx.doi.org/10.1145/1452567.1452571,10.1145/1452567.1452571,"This paper presents some results of an ongoing ontological analysis of the CRM field. In particular, it describes a fragment of O-CREAM, an ontology for CRM based on DOLCE and on other three DOLCE-based modules, i.e. DnS (for the representation of roles and for handling reification), OIO (for modeling information objects, the key concept for representing business knowledge), and OoP (whose notions are used to express the derivation of new business knowledge). Since the business knowledge plays a major role within CRM activities, a significant fragment of O-CREAM is devoted to the formal characterization of notions related to business knowledge; such a fragment is the focus of this paper.","enterprise ontology, customer relationship, management",OBI '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Greenfeld NR,Quantification in a Relational Data System,,1974,,,71–75,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the May 6-10, 1974, National Computer Conference and Exposition","Chicago, Illinois",1974,9781450379205,,https://doi.org/10.1145/1500175.1500189;http://dx.doi.org/10.1145/1500175.1500189,10.1145/1500175.1500189,"The desire to express interrelationships between symbolic objects has been with us for some time, along with exploration of relationship systems which are operational in a computer. These systems coalesced under the term relational data systems (RDS), and a technology for dealing with this kind of data evolved. Relational systems have been through feasibility tests, experimental usage and should become generally available to the computing community in the near future. The advantages which account for the expanding use of RDSs are a simple, formal definition which allows associative processing, extreme flexibility in both structure and use, an ability to be efficiently implemented, and a notation and conception which is not dependent upon any particular physical data representation.",,AFIPS '74,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Arenas M,Demirci H,Lenzini G",Cholesteric Spherical Reflectors as Physical Unclonable Identifiers in Anti-Counterfeiting,,2021,,,,Association for Computing Machinery,"New York, NY, USA",,"The 16th International Conference on Availability, Reliability and Security","Vienna, Austria",2021,9781450390514,,https://doi.org/10.1145/3465481.3465766;http://dx.doi.org/10.1145/3465481.3465766,10.1145/3465481.3465766,"Cholesteric Spherical Reflectors (CSRs) are made of droplets of cholesteric liquid crystals (the same material under the screen of our mobile phones) but molded in a spherical shape and hardened into a solid. CSRs have a peculiar behavior when illuminated: they reflect light and produce unique optical patterns whose full display is hardly predictable. They have been argued to behave like an optical Physical Unclonable Function (PUF), therefore finding application in anti-counterfeiting, in particular for object authentication. However, a fundamental challenge remains open: to understand what makes each optical response unique and how to extract this identifying information reliably and repeatedly. We study the problem, and we design and discuss two pivotal procedures to build authentication protocols for objects coated with CSRs. We test the quality of our procedures against large data sets of pattern images: images from CSRs are used to calculate inter- and intra-distance; simulated patterns created artificially are used to measure security in terms of false positive ratio. Our procedures successfully cluster images coming from the same CSR, distinguishing them from images of different CSRs and decoys. Our work is one of the few that has studied procedures of information extraction for materials derived from CSRs. It advances the state of the art in this area, closing the gap between the research on optical PUFs and practical applications.","Physical unclonable function, authentication, anti-counterfeiting Cholesteric Spherical Reflectors",ARES 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wei S,Jianxin R",Real-Time Tracking of Non-Rigid Objects,,2016,,,11–15,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 International Conference on Communication and Information Systems,"Bangkok, Thailand",2016,9781450347914,,https://doi.org/10.1145/3023924.3023944;http://dx.doi.org/10.1145/3023924.3023944,10.1145/3023924.3023944,"Currently, pose variations and irregular movements are the main constraints in the tracking of the non-rigid object. In order to avoid the inaccurate location or the failure of tracking the non-rigid object, a novel tracking method combining particle filter and Mean Shift algorithm is proposed. The motion segmentation is used to correct particle filter's estimation error of the non-rigid target, which improves the efficiency, as well as the robustness of the algorithm against noises. The normalized correlation coefficient is calculated to determine whether to update the template of Mean Shift algorithm. We also test the algorithm on the open popular datasets. Results prove that the algorithm presented in this work shows better results in both aspects of effectiveness and efficiency than the method combining CAMShift algorithm with Kalman filter.","Normalized correlation coefficient, Mean Shift algorithm, Particle filter, Motion segmentation",ICCIS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hamlen KW,Jones M",Aspect-Oriented in-Lined Reference Monitors,,2008,,,11–20,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third ACM SIGPLAN Workshop on Programming Languages and Analysis for Security,"Tucson, AZ, USA",2008,9781595939364,,https://doi.org/10.1145/1375696.1375699;http://dx.doi.org/10.1145/1375696.1375699,10.1145/1375696.1375699,"An Aspect-Oriented, declarative, security policy specification language is presented, for enforcement by In-lined Reference Monitors. The semantics of the language establishes a formal connection between Aspect-Oriented Programming and In-lined Reference Monitoring wherein policy specifications denote Aspect-Oriented security automata---security automata whose edge labels are encoded as pointcut expressions. The prototype language implementation enforces these security policies by automatically rewriting Java bytecode programs so as to detect and prevent policy violations at runtime.","runtime verification, in-lined reference monitors, security automata, object-oriented programming, aspect-oriented programming",PLAS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li G,Wang W,Du Z",Research on Robotic Arm Recognition and Grasping Based on RGB-D Sensor,,2019,,,7–11,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 2nd International Conference on Service Robotics Technologies,"Beijing, China",2019,9781450362467,,https://doi.org/10.1145/3325693.3325697;http://dx.doi.org/10.1145/3325693.3325697,10.1145/3325693.3325697,"As people's demand for service robots continues to grow, how to solve the problem of robot interaction with the physical world, especially solving the problem of robot crawling, has become a hot issue in the world. In this paper, the algorithm of target recognition and 6D pose estimation is studied based on RGB-D sensor Kinect. The target recognition, which The object to be captured is determined in a complex environment, is performed by ORB algorithm and template matching. The point cloud registration is performed by LM-ICP algorithm to calculate the position and attitude of the object relative to the robot. Finally, the feasibility of the capture experiment verification algorithm in the Gazebo physics simulation environment is carried out.","Service robot, Target recognition, Pose estimation, Machine vision",ICSRT 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Z,Wang H,Zhan N",Refinement of Models of Software Components,,2010,,,2311–2318,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Symposium on Applied Computing,"Sierre, Switzerland",2010,9781605586397,,https://doi.org/10.1145/1774088.1774567;http://dx.doi.org/10.1145/1774088.1774567,10.1145/1774088.1774567,"Models of software components at different levels of abstraction, component interfaces, contracts, implementations and publications are important for component-based design. Refinement relations among models at the same level and between different levels are essential for model-driven development of components. Classical refinement theories mainly focus on verification and put little attention on design. Therefore, most of them are not suitable for component-based model-driven development (CB-MDD). To address this issue, in this paper, we propose two refinement relations for CB-MDD, that is a trace-based refinement and a state-based refinement. Both are discussed in the framework of rCOS, which is a formal model of component and object systems. These refinement relations provide different granularity of abstraction and can capture the intuition that a refined component provides \more\"" and \""better\"" services to the environment. We also show how to extend these refinement relations to allow us to compare contracts",components and publications with different interfaces by exploiting the primitive operator internalizing over contracts,"components and publications.""","data refinement, CB-MDD, trace refinement, rCOS",SAC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen Y,Liao S",Message Family Propagation for Ising Mean Field Based on Iteration Tree,,2009,,,345–354,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th ACM Conference on Information and Knowledge Management,"Hong Kong, China",2009,9781605585123,,https://doi.org/10.1145/1645953.1645999;http://dx.doi.org/10.1145/1645953.1645999,10.1145/1645953.1645999,"Ising mean field is a basic variational inference method for Ising model, which can provide an effective approximate solution for large-scale inference problem. The main idea is to transform a probabilistic inference problem into a functional extremum problem by variational calculus, and solve the functional extremum problem to obtain approximate marginal distributions. The process of solving the functional extremum is an important step and a computational core for variational inference. But the traditional full variational iteration methods make the variable information intercross with each other deeply. From the view of incomplete variational iterations, we propose a message family propagation method for Ising mean field to compute a marginal distribution family of object variable.First we define the concepts of iteration tree and pruning iteration tree to describe the iteration computation process of Ising mean field inference. Then we design the message family propagation method based on the iteration trees. The method propagates mean field message families and belief message families from bottom to top of the iteration tree, and presents a marginal distribution family of variable in root node. Finally we prove the marginal distribution bound theorem, which shows that the marginal distribution family computed by the method in the pruning iteration tree contains the exact marginal stribution. Theoretical and experimental results illustrate that the message family propagation method is valid and the marginal distribution bounds are tight.","Ising mean field, iteration tree, message family propagation",CIKM '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Seewoonauth K,Rukzio E,Hardy R,Holleis P",Touch & Connect and Touch & Select: Interacting with a Computer by Touching It with a Mobile Phone,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Human-Computer Interaction with Mobile Devices and Services,"Bonn, Germany",2009,9781605582818,,https://doi.org/10.1145/1613858.1613905;http://dx.doi.org/10.1145/1613858.1613905,10.1145/1613858.1613905,"Exchanging data between a mobile phone and a computer such as a laptop is still a very cumbersome process. This paper presents two different techniques, touch & connect and touch & select, designed help to overcome this problem and facilitate and speed up spontaneous interactions between such devices. Using touch & connect, the user can physically touch a computer in order to pair a Bluetooth connection and initiate a file transfer between these two devices. Touch & select extends this concept in that users can select a specific object or location on the computer screen by simply touching it with the mobile phone. We report the implementation of these interaction techniques based on Near Field Communication (NFC) tags and present a formal, comparative study focusing on transferring images. The results provide clear evidence of the advantages of touch & connect and touch & select when compared with current Bluetooth-based implementations. Considering task completion time for uploading and downloading pictures, touch & select was 43% and touch & connect 31% faster than the conventional Bluetooth-based approach.","picture sharing, mobile, touch, interaction, display",MobileHCI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Z,Sun L,Yang S",Efficient Relative Camera Orientation Detection for Mobile Applications,,2011,,,53–62,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st International Workshop on Mobile Location-Based Service,"Beijing, China",2011,9781450309288,,https://doi.org/10.1145/2025876.2025888;http://dx.doi.org/10.1145/2025876.2025888,10.1145/2025876.2025888,"Nowadays, an intelligent mobile phone is required to have at least a camera and be able to process images with multiple sensors. However, when people take a photo at a random place, it is hard to build a whole pipeline to calculate everything accurately and efficiently. Therefore, basic and efficient algorithms are needed for both program developers and terminal users. In this paper, we will focus on a basic but important problem - relative camera orientation calculation, which is part of camera calibration. We introduce an efficient algorithm to tell the relative angle between the main object in the image and the camera. While no training data is used other than the test image itself, line segments are extracted by a Hough Transformation, based on Canny's edge detection algorithm. By extracting the focal length from the EXIF information and calculating the pixel lengths of some critical segment lines, the algorithm will give an accurate orientation for the main object (building) in the image. With the advantage of real time processing, our work can be further used for image location detection and other cute applications on intelligent mobile phones. Experiments show its effectiveness and efficiency on both experimental data of the campus and web data of some famous buildings.","relative camera orientation, hough transformation, efficiency",MLBS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lioma C,Larsen B,Schuetze H,Ingwersen P",A Subjective Logic Formalisation of the Principle of Polyrepresentation for Information Needs,,2010,,,125–134,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third Symposium on Information Interaction in Context,"New Brunswick, New Jersey, USA",2010,9781450302470,,https://doi.org/10.1145/1840784.1840804;http://dx.doi.org/10.1145/1840784.1840804,10.1145/1840784.1840804,"Interactive Information Retrieval refers to the branch of Information Retrieval that considers the retrieval process with respect to a wide range of contexts, which may affect the user's information seeking experience. The identification and representation of such contexts has been the object of the principle of Polyrepresentation, a theoretical framework for reasoning about different representations arising from interactive information retrieval in a given context. Although the principle of Polyrepresentation has received attention from many researchers, not much empirical work has been done based on it. One reason may be that it has not yet been formalised mathematically.In this paper we propose an up-to-date and flexible mathematical formalisation of the principle of Polyrepresentation for information needs. Specifically, we apply Subjective Logic to model different representations of information needs as beliefs marked by degrees of uncertainty. We combine such beliefs using different logical operators, and we discuss these combinations with respect to different retrieval scenarios and situations. A formal model is introduced and discussed, with illustrative applications to the modelling of information needs.","polyrepresentation, subjective logic, information needs",IIiX '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shah SM,Anastasakis K,Bordbar B",From UML to Alloy and Back Again,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 6th International Workshop on Model-Driven Engineering, Verification and Validation","Denver, Colorado, USA",2009,9781605588766,,https://doi.org/10.1145/1656485.1656489;http://dx.doi.org/10.1145/1656485.1656489,10.1145/1656485.1656489,"Model Transformations can be used to bridge the gap between design and analysis technical spaces by creating tools that allow a model produced by a designer to be transformed to a model suitable for conducting automated analysis. Such model transformations aim at allowing the designer to benefit from the capabilities provided by analysis tools and languages. If the designer who is not a formal method expert is to benefit from such tools, the outcome of the analysis should also be transformed to the language used in the design domain.This paper presents a study involving UML2Alloy, a tool for transforming UML models in form of UML class diagrams which are augmented with OCL constraints, to Alloy. The conversion allows analysis of UML models via Alloy, to identify consistencies in those UML models. We present a method of automatically creating a model transformation based on the original UML2Alloy transformation. The new transformation converts Alloy instances into the UML equivalent object diagram. The current technique is presented with the help of an example, along with a prototype implementation using the QVT standard.",,MoDeVVa '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Haller H,Abecker A",IMapping: A Zooming User Interface Approach for Personal and Semantic Knowledge Management,,2010,,,119–128,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM Conference on Hypertext and Hypermedia,"Toronto, Ontario, Canada",2010,9781450300414,,https://doi.org/10.1145/1810617.1810638;http://dx.doi.org/10.1145/1810617.1810638,10.1145/1810617.1810638,"We present iMapping, a zooming based approach for visually organizing information objects. It was developed on top of semantic desktop technologies and especially targets the support of personal knowledge management. iMapping has been designed to combine the advantages of spatial hypertext and other proven visual mapping approaches like mind-mapping and concept mapping, which are incompatible in their original form. We describe the design and prototypical implementation of iMapping -- which is fundamentally based on deep zooming and nesting. iMapping bridges the gap between unstructured content like informal text notes and semantic models by allowing annotations with the whole range from vague associations to formal relations. First experimental evaluation of the iMapping user-interface approach indicates favorable user experience and functionality, compared with state-of-the-art Mind-Mapping software.","personal knowledge management, human- computer interaction, semantic desktop, interaction design, spatial hypertext, visual knowledge mapping",HT '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jaya A,Uma GV",An Intelligent System for Semi-Automatic Story Generation for Kids Using Ontology,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third Annual ACM Bangalore Conference,"Bangalore, India",2010,9781450300018,,https://doi.org/10.1145/1754288.1754296;http://dx.doi.org/10.1145/1754288.1754296,10.1145/1754288.1754296,"Story grabs the attention of all sorts of people like young, old, children etc. Everyone is always having a special interest in either reading or listening stories. Readers may have different taste and interests and also they have their own choice of stories. Some may be fond of mystic ones or science fiction, or mythology, or romantic stories but in common people love to read stories. Creative people may land their footsteps in the art of writing stories with their own creativity and imagination. They will produce interesting themes for the stories with their innovative thoughts. A writer has the responsibility to make the readers visualize the story in their mind in order to make the story as vivid and lively. The art of writing attractive stories requires a lot of creativity and intelligence to lead the story in a right way. This Automatic story generation system provides an environment for the user to construct or rewrite the story as per their desire, through user interaction. The most attractive feature of this system is that it allows the user to select the characters, objects and location for the story in which they are constructed. Ontology helps to provide the attributes of the characters, objects and locations to the generated story. As a result, ontology preserves the meaning of system generated story in an interesting way. Ontology is a formal explicit specification of shared conceptualization. This intelligent automatic story generation system helps for dynamic construction of stories using ontology in a neat fashion.","story generation, ontology, characters, conception of themes, interaction, semantic ordering",COMPUTE '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Katterfeldt ES,Schelhowe H",A Modelling Tool to Support Children Making Their Ideas Work,,2008,,,218–225,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Interaction Design and Children,"Chicago, Illinois",2008,9781595939944,,https://doi.org/10.1145/1463689.1463759;http://dx.doi.org/10.1145/1463689.1463759,10.1145/1463689.1463759,"Children can be considered as innovative thinkers and as contributors to novel creations in emerging fields of science and technology, e.g. robotics or smart textiles. How can we support them in making their ideas for future society work?Based on a constructionist learning approach, this paper proposes a modelling tool---a software application which enables children to implement running prototypes even of their intricate ideas. It supports them in abstracting their concrete ideas gradually into rather formal programs for their prototypes.The tool follows a novel approach by combining reverse storyboarding with diagrammatic representation techniques, while holding a strong connection to concrete construction objects. Children's first tests imply that they succeed in modelling their ideas with the tool, and that it can support the implementation of own ideas along with the modelling and abstraction process.",,IDC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Guo W,Xu C,Ma S,Huang S",Hausdorff Matching Based SVD-Covariance Descriptor for Object Tracking,,2011,,,41–44,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Second International Conference on Internet Multimedia Computing and Service,"Harbin, China",2011,9781450304603,,https://doi.org/10.1145/1937728.1937738;http://dx.doi.org/10.1145/1937728.1937738,10.1145/1937728.1937738,"In this paper we propose a Hausdorff matching based SVD-covariance descriptor for object tracking. Object tracking is one of the most important tasks in computer vision and covariance descriptor for visual tracking has attracted many researchers in the field. The main issues we want to address in this paper consist of the difficulty brought by the non-Euclidean space elements choice of covariance matrices and the large expenditure caused by the measurement between different models calculated on Riemannian manifolds. We have designed an efficient and discriminative SVD-covariance representation feature. The measurement between the target and candidates can be realized through Hausdorff distance. Theoretically, this reduces the computational cost compared with the original measurement on Riemannian manifolds. The experimental results show that the proposed approach is able to generate the promising feature for visual tracking.","covariance, tracking, SVD, Hausdorff",ICIMCS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Guessi M,Moreira DA,Abdalla G,Oquendo F,Nakagawa EY",OntolAD: A Formal Ontology for Architectural Descriptions,,2015,,,1417–1424,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th Annual ACM Symposium on Applied Computing,"Salamanca, Spain",2015,9781450331968,,https://doi.org/10.1145/2695664.2695739;http://dx.doi.org/10.1145/2695664.2695739,10.1145/2695664.2695739,"Architecture descriptions have been the focus of several studies in which they contribute for the design, evaluation, and evolution of software systems. In parallel, ontologies have been proposed for sharing and disseminating knowledge on a particular domain. In this scenario, the ontology proposed in the ISO/IEC/IEEE 42010 standard for architecture descriptions represents an important effort towards improving architecture descriptions as it establishes a common vocabulary. Nonetheless, a formal ontology for this standard could also support automatic conformance validation and enhance architectural descriptions reuse. However, a formal ontology for this standard is not available yet. Therefore, the main contribution of this paper is the proposal of OntolAD, a formal ontology expressed in OWL 2 for the ISO/IEC/IEEE 42010 standard. We demonstrate the feasibility of our formal ontology by applying it for describing the service-oriented architecture style (SOA). We conclude this study with interesting perspectives of using this ontology in future work.","formal ontology, architecture description",SAC '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gao J,Yang Z,Liu W",Template Attentional Siamese Network for Object Tracking,,2018,,,218–221,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 the 2nd International Conference on Video and Image Processing,"Hong Kong, Hong Kong",2018,9781450366137,,https://doi.org/10.1145/3301506.3301544;http://dx.doi.org/10.1145/3301506.3301544,10.1145/3301506.3301544,"Recent years, visual object tracking has attracted more and more attention as a fundamental topic. Many deep based trackers, especially Siamese Network based trackers, have achieved state-of-the-art performance on multiple benchmarks. However, most of these trackers applied with the first frame as template throughout the tracking process. We propose a Template Attentional Siamese Network called TASNet. The core of TASNet is combining the detection results of two template frames, where the first frame extracting discriminative features and the latest frame capturing the motion changes, to enhance model tracking effect. Template-wise weights are calculated from attention mechanism to integrate the detecting results of two templates in current frame tracking. The proposed architecture is trained from end to end on the ILSVRC2015 video dataset. Our tracker operates at frame-rates real-time and achieves state-of-the-art tracking accuracy while large deformation of the object is appeared.","attention mechanism, object tracking, discriminative features, motion change, Siamese network",ICVIP 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Hense AV,CSPm Models for the ATM Case Study,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Subject-Oriented Business Process Management,"Kiel, Germany",2015,9781450333122,,https://doi.org/10.1145/2723839.2723866;http://dx.doi.org/10.1145/2723839.2723866,10.1145/2723839.2723866,"Communicating Sequential Processes (CSP) [7] is a calculus for concurrent systems that has been the basis of subject-oriented business process management (S-BPM) [4]. We use CSPm -- a machine readable dialect of CSP -- to create a sequence of models for a case study on an \Automated Teller Machine\"" [1]. We use the refinement checker FDR2 to prove that certain models are correct implementations of specifications.""",,S-BPM ONE '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Haller H,Abecker A",IMapping: A Zooming User Interface Approach for Personal and Semantic Knowledge Management,SIGWEB Newsl.,2010,,Autumn,,Association for Computing Machinery,"New York, NY, USA",,,,2010-09,,1931-1745,https://doi.org/10.1145/1850770.1836295;http://dx.doi.org/10.1145/1850770.1836295,10.1145/1850770.1836295,"We present iMapping, a zooming based approach for visually organizing information objects. It was developed on top of semantic desktop technologies and especially targets the support of personal knowledge management. iMapping has been designed to combine the advantages of spatial hypertext and other proven visual mapping approaches like mind-mapping and concept mapping, which are incompatible in their original form. We describe the design and prototypical implementation of iMapping -- which is fundamentally based on deep zooming and nesting. iMapping bridges the gap between unstructured content like informal text notes and semantic models by allowing annotations with the whole range from vague associations to formal relations. First experimental evaluation of the iMapping user-interface approach indicates favorable user experience and functionality, compared with state-of-the-art Mind-Mapping software.","interaction design, spatial hypertext, semantic desktop, human-computer interaction, personal knowledge management, visual knowledge mapping",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Rabe F,A Modular Type Reconstruction Algorithm,ACM Trans. Comput. Logic,2018,19,4,,Association for Computing Machinery,"New York, NY, USA",,,,2018-12,,1529-3785,https://doi.org/10.1145/3234693;http://dx.doi.org/10.1145/3234693,10.1145/3234693,"Mmt is a framework for designing and implementing formal systems in a way that systematically abstracts from theoretical and practical aspects of their type of theoretical and logical foundations. Thus, definitions, theorems, and algorithms can be stated independently of the foundation, and language designers can focus on the essentials of a particular foundation and inherit a large-scale implementation from Mmt at low cost. Going beyond the similarly motivated approach of meta-logical frameworks, Mmt does not even commit to a particular meta-logic—that makes Mmt level results harder to obtain but also more general.We present one such result: a type reconstruction algorithm that realizes the foundation-independent aspects generically relative to a set of rules that supply the foundation-specific knowledge. Maybe surprisingly, we see that the former covers most of the algorithm, including the most difficult details. Thus, we can easily instantiate our algorithm with rule sets for several important language features including, e.g., dependent function types. Moreover, our design is modular such that we obtain a type reconstruction algorithm for any combination of these features.","Type reconstruction, dependent types, logical framework, MMT, modularity",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Papakostopoulos V,Nathanael D,Marmaras N",An Explorative Study of Visual Scanning Strategies of Motorcyclists in Urban Environment,,2010,,,157–160,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual European Conference on Cognitive Ergonomics,"Delft, Netherlands",2010,9781605589466,,https://doi.org/10.1145/1962300.1962332;http://dx.doi.org/10.1145/1962300.1962332,10.1145/1962300.1962332,"Motivation --- To identify the objects/entities that determine the ontology of the motorcyclist's visual exploration activity, when driving in urban arterials. This ontology may form the basis for modelling the motorcyclists' visual activity in urban traffic as well as shed light in their interaction with automobile drivers.Research approach --- An explorative naturalistic field study was conducted, using the eye-tracking method, in which three experienced motorcyclists were asked to drive normally in a predefined route consisting of three road sections: motorway, avenue, local urban two way street. Immediately after driving an interview of each participant was conducted using the video assisted autoconfrontation method.Findings/Design --- The results suggest that (i) visual scan patterns of motorcyclists in urban arterials are much more vivid compared to those in motorway and extend well beyond formal signals, (ii) to minimize the cognitive effort of scanning motrocyclists seek for specific cues to monitor the future intentions of the other road users (iii) motorcyclists feel more vulnerable than car drivers, which leads them to recurring visual checks of the points of concern.Research limitations/Implications --- The results presented are based on a small sample of motorcyclists. In the near future we intend to extend our sample of participants and to perform formal protocol analysis of the a-posteriory, verbalizations.Originality/Value --- One of the very few naturalistic field studies of motorcyclist visual exploration activity in urban environment using eye tracking and autoconfrontation. Promises to offer fresh insights to safety measures for motorcyclists.Take away message --- Urban driving scan patterns of motorcyclists are very systematic and recurring across situations and participants. Fixation points are rarely directed to road elements as such. Fixations tend to be clearly directed at specific points (e.g. side mirrors, car wheels, rear edge of car roofs) that convey information about the other road users' state and intentions.","driving activity, motorcyclist, urban environment, eye-tracking, scan patterns",ECCE '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Juntang Y,Weidong X,Qingkai Q,Yang Q",Research on Camouflage Effect Evaluation Method of Moving Object Based on Video,,2016,,,441–446,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th ACM SIGGRAPH Conference on Virtual-Reality Continuum and Its Applications in Industry - Volume 1,"Zhuhai, China",2016,9781450346924,,https://doi.org/10.1145/3013971.3013976;http://dx.doi.org/10.1145/3013971.3013976,10.1145/3013971.3013976,"At present, the detection and evaluation method of camouflage effect is mainly aimed at the static target, it cannot objectively reflect the effectiveness of the camouflage effect of the moving target in the operational action. In this paper, the moving object detection technology is combined with the principle of camouflage was comprehensively used. Using Hausdorff distance and color difference minimum principal color similarity vector algorithm to calculate the degree of distortion, target and center background similarity. In order to check the camouflage effect under the condition of moving target, dynamic distortion frame ratio, dynamic similarity frame ratio are proposed based on video stream. In this paper, the experiment is carried out with the step vehicle as the moving object, calculating the deformation degree to achieve the goal of dynamic deformation of 0.4 frame rate ratios were 70.5% and 0% under the two kinds of camouflage methods, The similarity reaches the target frame rate of dynamic similarity ratio of 0.36 were 89.8% and 0%, This shows that the dynamic camouflage effect of the target after digital camouflage painting is better than the target which used green painting. When the target deformation degree and the target and background similarity reaches a value of dynamic deformation of frame frequency ratio and dynamic similarity frame rate ratio are bigger, indicating that the better the dynamic camouflage effect is.","camouflage effect, effect evaluation, moving object, hausdorff distance",VRCAI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Carvalho NR,An Ontology Toolkit for Problem Domain Concept Location in Program Comprehension,,2013,,,1415–1418,IEEE Press,"San Francisco, CA, USA",,Proceedings of the 2013 International Conference on Software Engineering,,2013,9781467330763,,,,"Programmers are able to understand source code because they are able to relate program elements (e.g. modules, objects, or functions), with the real world concepts these elements are addressing. The main goal of this work is to enhance current program comprehension by systematically creating bidirectional mappings between domain concepts and source code. To achieve this, semantic bridges are required between natural language terms used in the problem domain and program elements written using formal programming languages. These bridges are created by an inference engine over a multi-ontology environment, including an ontological representation of the program, the problem domain, and the real world effects program execution produces. These ontologies are populated with data collected from both domains, and enriched using available Natural Language Processing and Information Retrieval techniques.",,ICSE '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Dekker MA,Crampton J,Etalle S",RBAC Administration in Distributed Systems,,2008,,,93–102,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM Symposium on Access Control Models and Technologies,"Estes Park, CO, USA",2008,9781605581293,,https://doi.org/10.1145/1377836.1377852;http://dx.doi.org/10.1145/1377836.1377852,10.1145/1377836.1377852,"Large and distributed access control systems are increasingly common, for example in health care. In such settings, access control policies may become very complex, thus complicating correct and efficient adminstration of the access control system. Despite being one of the most widely used access control standards, RBAC does not include an administration model for distributed systems. In this paper we fill this gap. We present a model for the administration of RBAC in a distributed system and propose an administration procedure supporting the principle that different systems protect different sets of objects. We demonstrate that our procedure fulfills the formal requirements deriving from safety and availability, and we show how it can be translated to a practical implementation. Finally, we show how our model can be extended with multiple decentralized administrative systems.","RBAC, access control, distributed system, administration",SACMAT '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bothwell J,Yuan M",A Kinematics-Based GIS Methodology to Represent and Analyze Spatiotemporal Patterns of Precipitation Change in IPCC A2 Scenario,,2011,,,152–161,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,"Chicago, Illinois",2011,9781450310314,,https://doi.org/10.1145/2093973.2093995;http://dx.doi.org/10.1145/2093973.2093995,10.1145/2093973.2093995,"A kinematics-based GIS methodology is applied to represent and analyze spatiotemporal patterns and pattern transitions in very large data sets. The study demonstrates that the kinematics approach is able to discern transitional patterns from a continuous field of geographic properties over time by defining objects through thresholds and analyzing the object's internal and external movement patterns in space and time. The kinematics approach quantifies divergence, rotation, and deformation about changes to precipitation patterns and enables the search for precipitation regions influenced primarily by local conditions or by general circulation patterns of water vapour transport.A use case is built from two precipitation data products projected for the A2 scenario by the International Panel for Climate Change (IPCC). The study takes a predefined threshold to delineate regions of interest, calculates shifts of the regions between years, and characterizes the pattern change. The study uses precipitation over 213 cm/year in 2001 and 2048 to illustrate the kinematics approach to comparing precipitation patterns predicted from the CCSM3 and CM3. Even though the precipitation data in 2001 and 2048 cannot be considered temporally continuous, the differential used here was to identify the patterns of precipitation shifts between the two years under the assumption that changes to spatial patterns of precipitation for 213 cm/year were gradual from 2001 to 2048. The 213 cm/year precipitation threshold is only met by a large number of precipitation events during the years of interest. Hence, this threshold appears stable from year to year although lesser thresholds would be discontinuous.","space-time objects, geographic kinematics, motion, geographic information science, internal change, temporal GIS",GIS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yamashita S,Mujibiya A",POVeye: Enhancing e-Commerce Product Visualization by Providing Realistic Image Based Point-of-View,,2015,,,199–200,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th Augmented Human International Conference,"Singapore, Singapore",2015,9781450333498,,https://doi.org/10.1145/2735711.2735807;http://dx.doi.org/10.1145/2735711.2735807,10.1145/2735711.2735807,"We present POVeye, a method to help users in capturing and creating visualization of products for extensive representation of the product's material color and texture. POVeye achieve this by providing realistic images captured from various angles, which are positioned correctly based on the calculated geometrical centroid. As input, users simply provide a video or multiple images of the product taken by any camera from arbitrary angles, without requiring any pre-calibration. POVeye provides an interface that shows object-centric camera positions alongside with image taken from respective camera angle. Users are able to either manually browse through automatically detected camera positions, or visualize the product by automatically detected view-angle path. POVeye leverages Structure-from-Motion (SfM) approach to obtain camera-object map. Our approach is unique from other solutions by preserving realistic imaging condition. We observe that visualization of products from different angles that provide information of light reflection and refraction potentially helps users to identify materials, and further perceive quality of a product.","view angle, visualization, e-commerce, material texture",AH '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oliveira N,Barbosa LS",On the Reconfiguration of Software Connectors,,2013,,,1885–1892,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual ACM Symposium on Applied Computing,"Coimbra, Portugal",2013,9781450316569,,https://doi.org/10.1145/2480362.2480712;http://dx.doi.org/10.1145/2480362.2480712,10.1145/2480362.2480712,"Software connectors encapsulate interaction patterns between services in complex, distributed service-oriented applications. Such patterns evolve over time, in response to faults, changes in the expected QoS levels, emergent requirements or the reassessment of contextual conditions. This paper builds up on a model for connector reconfiguration to introduce notions of reconfiguration equivalence and refinement allowing for reasoning about them. This paves the way towards a (still missing) calculus of connector reconfigurations.","software connectors, reconfiguration, software architecture, architectural reconfiguration",SAC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shaikh A,Clarisó R,Wiil UK,Memon N",Verification-Driven Slicing of UML/OCL Models,,2010,,,185–194,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the IEEE/ACM International Conference on Automated Software Engineering,"Antwerp, Belgium",2010,9781450301169,,https://doi.org/10.1145/1858996.1859038;http://dx.doi.org/10.1145/1858996.1859038,10.1145/1858996.1859038,"Model defects are a significant concern in the Model-Driven Development (MDD) paradigm, as model transformations and code generation may propagate errors to other notations where they are harder to detect and trace. Formal verification techniques can check the correctness of a model, but their high computational complexity can limit their scalability. In this paper, we consider a specific static model (UML class diagrams annotated with unrestricted OCL constraints) and a specific property to verify (satisfiability, i.e., \is it possible to create objects without violating any constraint?\""). Current approaches to this problem have an exponential worst-case runtime. We propose a technique to improve their scalability by partitioning the original model into submodels (slices) which can be verified independently and where irrelevant information has been abstracted. The definition of the slicing procedure ensures that the property under verification is preserved after partitioning.""","mdd, model slicing, uml, ocl, formal verification",ASE '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Steichen B,Lawless S,O'Connor A,Wade V",Dynamic Hypertext Generation for Reusing Open Corpus Content,,2009,,,119–128,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th ACM Conference on Hypertext and Hypermedia,"Torino, Italy",2009,9781605584867,,https://doi.org/10.1145/1557914.1557937;http://dx.doi.org/10.1145/1557914.1557937,10.1145/1557914.1557937,"Adaptive hypermedia systems traditionally focus on providing personalised learning services for formal or informal learners. The learning material is typically sourced from a proprietary set of closed corpus content. A fundamental problem with this type of architecture is the need for handcrafted learning objects, enriched with considerable amounts of metadata. The challenge of generating adaptive and personalised hypertext presentations from open source content promises a dramatic improvement of the choice of information shown to the learner. This paper proposes an architecture of such a dynamic hypertext generation system and its use in an authentic learning environment. The system is evaluated in terms of educational benefit, as well as the satisfaction of the users testing the system. Concluding from this evaluation, the paper will explore the future work necessary to further enhance the system performance and learning experience.","hypertext generation, open corpus content, metadata generation, personalisation, adaptation",HT '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fernández M,Thuraisingham B",A Category-Based Model for ABAC,,2018,,,32–34,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third ACM Workshop on Attribute-Based Access Control,"Tempe, AZ, USA",2018,9781450356336,,https://doi.org/10.1145/3180457.3183326;http://dx.doi.org/10.1145/3180457.3183326,10.1145/3180457.3183326,"In Attribute-Based Access Control (ABAC) systems, access to resources is controlled by evaluating rules against the attributes of the user and the object involved in the access request, as well as the values of the relevant attributes from the environment. This is a powerful concept: ABAC is able to enforce DAC and RBAC policies, as well as more general, dynamic access control policies, where the decision to grant or deny an access request is based on the system's state. However, in its current definition, ABAC does not lend itself well to some operations, such as review queries, and it is in general more costly to specify and maintain than simpler systems such as RBAC. To address these issues, in this paper we propose a formal model of ABAC based on the notion of a category that underlies the general category-based metamodel of access control (CBAC). Our proposed approach adds structure to ABAC, so that policies are easier to design and understand, review queries become easy to evaluate, and simple systems such as RBAC can be implemented as instances of ABAC without additional costs.","access control, ABAC, CBAC, security policies",ABAC'18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liang J,Luo J,Drayton M,Nishtala R,Liu R,Hammer N,Taylor J,Jia B",Storage and Performance Optimization of Long Tail Key Access in a Social Network,,2013,,,1–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Workshop on Cloud Data and Platforms,"Prague, Czech Republic",2013,9781450320757,,https://doi.org/10.1145/2460756.2460757;http://dx.doi.org/10.1145/2460756.2460757,10.1145/2460756.2460757,"In a social network, it is natural to have hot objects such as a celebrity's Facebook page. Duplicating hot object data in each cluster provides quick cache access and avoids stressing a single server's network or CPU resources. But duplicating cold data in each cache cluster consumes significant RAM. A more storage efficient way is to separate hot data from cold data and duplicate only hot data in each cache cluster within a data center. The cold data, or the long tail data, which is accessed much less frequently, has only one copy at a regional cache cluster.In this paper, a new sampling technique to capture all accesses to the same sampled keys is created. We then calculate the working set size for each key family for estimating the memory footprint. We introduce an important metric, duplication factor, as the ratio between the sum of each individual cluster's working set size and the regional working set size. We analyze why some key families have a higher duplication factor.It is important to separate hot keys and cold keys from the same key family with minimal overhead. We present a novel cache promotion algorithm based on key access probability. We also proposed a probability model based on the binomial distribution to predict the promotion probability with various promotion thresholds.Our experiment shows by shrinking the cluster level cache layer and having a fat regional level cache for cold data, we are able to achieve a higher combined cache hit ratio.","key-value store, cache optimization, workload analysis",CloudDP '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Huang Y,Zheng H,Yang H,Wen T",Infrared Target Recognition Modeling and Simulation (WIP),,2014,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2014 Summer Simulation Multiconference,"Monterey, California",2014,,,,,"The aircraft often deploys countermeasures to avoid the attack of infrared guided missile, such as flares. The new type missile should have the ability to eliminate the effects of flares. According to this requirement, we first build the kinematics model of flare by force analysis and calculate its ballistic trajectory in the three-dimensional space under given conditions. Then, we analyzed the imaging principal of optic system and obtained a relation that the square of object's real area over its projected area equals the ratio of object-missile real distance and their projected distance. This relationship should be satisfied by target and flare simultaneously. According to the difference of speed between target and flare, which is the rule that change of target's projected area is less than the change of flare's projected area is derived and based on this; the target recognition technique is deduced. Finally, the efficiency of this technique is verified by the simulation results.","projection, countermeasure, target recognition, infrared imaging",SummerSim '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang F,Ma ZM,Cheng J,Meng X",Fuzzy Semantic Web Ontology Learning from Fuzzy UML Model,,2009,,,1007–1016,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th ACM Conference on Information and Knowledge Management,"Hong Kong, China",2009,9781605585123,,https://doi.org/10.1145/1645953.1646082;http://dx.doi.org/10.1145/1645953.1646082,10.1145/1645953.1646082,"How to quickly and cheaply construct Web ontologies has become a key technology to enable the Semantic Web. Classical ontologies are not sufficient for handling imprecise and uncertain information that is commonly found in many application domains. In this paper, we propose an approach for constructing fuzzy ontologies from fuzzy UML models, in which the fuzzy ontology consists of fuzzy ontology structure and instances. Firstly, the fuzzy UML model is investigated in detail, and a kind of formal definition of fuzzy UML models is proposed. Then, a kind of fuzzy ontology called fuzzy OWL DL ontology is introduced. Furthermore, we consider the fuzzy UML model and the corresponding fuzzy UML instantiations (i.e., object diagrams) simultaneously, and translate them into the fuzzy ontology structure and the fuzzy ontology instances, respectively. In addition, since a fuzzy OWL DL ontology is equivalent to a fuzzy Description Logic f-SHOIN(D) knowledge base, how the reasoning problems of fuzzy UML models (e.g., consistency, subsumption, equivalence, and redundancy) may be reasoned through reasoning mechanism of f-SHOIN(D) is investigated, which can help to construct fuzzy ontologies more exactly.","ontology learning, fuzzy ontology, fuzzy UML model",CIKM '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Banerjee A,Dasgupta P,Chakrabarti PP",Auxiliary State Machines + Context-Triggered Properties in Verification,ACM Trans. Des. Autom. Electron. Syst.,2008,13,4,,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,1084-4309,https://doi.org/10.1145/1391962.1391970;http://dx.doi.org/10.1145/1391962.1391970,10.1145/1391962.1391970,"Formal specifications of interface protocols between a design-under-test and its environment mostly consist of two types of correctness requirements, namely (a) a set of invariants that applies throughout the protocol execution and (b) a set of context-triggered properties that applies only when the protocol state belongs to a specific set of contexts. To model such requirements, an increasingly popular design choice in the assertion IP design community has been the use of abstract context state machines and state-oriented properties. In this paper, we formalize this modeling style and present algorithms for verifying such specifications. Specifically, we present a purely formal approach and a semi-formal approach for verifying such specifications. We demonstrate the use of this design style in modeling some of the industry standard protocol descriptions and present encouraging results.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Porta AO,The Use of Formal Language Models in the Typology of the Morphology of Amerindian Languages,,2010,,,109–113,Association for Computational Linguistics,USA,,Proceedings of the ACL 2010 Student Research Workshop,"Uppsala, Sweden",2010,,,,,"The aim of this work is to present some preliminary results of an investigation in course on the typology of the morphology of the native South American languages from the point of view of the formal language theory. With this object, we give two contrasting examples of descriptions of two Aboriginal languages finite verb forms morphology: Argentinean Quechua (quichua santiagueño) and Toba. The description of the morphology of the finite verb forms of Argentinean quechua, uses finite automata and finite transducers. In this case the construction is straight forward using two level morphology and then, describes in a very natural way the Argentinean Quechua morphology using a regular language. On the contrary, the Toba verbs morphology, with a system that simultaneously uses prefixes and suffixes, has not a natural description as regular language. Toba has a complex system of causative suffixes, whose successive applications determinate the use of prefixes belonging different person marking prefix sets. We adopt the solution of Creider et al. (1995) to naturally deal with this and other similar morphological processes which involve interactions between prefixes and suffixes and then we describe the toba morphology using linear context-free languages.",,ACLstudent '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Guerraoui R,Kapalka M",On the Correctness of Transactional Memory,,2008,,,175–184,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming,"Salt Lake City, UT, USA",2008,9781595937957,,https://doi.org/10.1145/1345206.1345233;http://dx.doi.org/10.1145/1345206.1345233,10.1145/1345206.1345233,"Transactional memory (TM) is perceived as an appealing alternative to critical sections for general purpose concurrent programming. Despite the large amount of recent work on TM implementations, however, very little effort has been devoted to precisely defining what guarantees these implementations should provide. A formal description of such guarantees is necessary in order to check the correctness of TM systems, as well as to establish TM optimality results and inherent trade-offs.This paper presents opacity, a candidate correctness criterion for TM implementations. We define opacity as a property of concurrent transaction histories and give its graph theoretical interpretation. Opacity captures precisely the correctness requirements that have been intuitively described by many TM designers. Most TM systems we know of do ensure opacity.At a very first approximation, opacity can be viewed as an extension of the classical database serializability property with the additional requirement that even non-committed transactions are prevented from accessing inconsistent states. Capturing this requirement precisely, in the context of general objects, and without precluding pragmatic strategies that are often used by modern TM implementations, such as versioning, invisible reads, lazy updates, and open nesting, is not trivial.As a use case of opacity, we prove the first lower bound on the complexity of TM implementations. Basically, we show that every single-version TM system that uses invisible reads and does not abort non-conflicting transactions requires, in the worst case, ?(k) steps for an operation to terminate, where k is the total number of objects shared by transactions. This (tight) bound precisely captures an inherent trade-off in the design of TM systems. The bound also highlights a fundamental gap between systems in which transactions can be fully isolated from the outside environment, e.g., databases or certain specialized transactional languages, and systems that lack such isolation capabilities, e.g., general TM frameworks.","transactional memory, correctness, model, lower bound",PPoPP '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gotsch D,Zhang X,Merritt T,Vertegaal R",TeleHuman2: A Cylindrical Light Field Teleconferencing System for Life-Size 3D Human Telepresence,,2018,,,1–10,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems,"Montreal QC, Canada",2018,9781450356206,,https://doi.org/10.1145/3173574.3174096;http://dx.doi.org/10.1145/3173574.3174096,10.1145/3173574.3174096,"For telepresence to support the richness of multiparty conversations, it is important to convey motion parallax and stereoscopy without head-worn apparatus. TeleHuman2 is a \hologrammatic\"" telepresence system that conveys full-body 3D video of interlocutors using a human-sized cylindrical light field display. For rendering",the system uses an array of projectors mounted above the heads of participants in a ring around a retroreflective cylinder. Unique angular renditions are calculated from streaming depth video captured at the remote location. Projected images are retro-reflected into the eyes of local participants,at 1.3º intervals providing angular renditions simultaneously for left and right eyes of all onlookers,which conveys motion parallax and stereoscopy without head-worn apparatus or head tracking. Our technical evaluation of the angular accuracy of the system demonstrates that the error in judging the angle of a remote arrow object represented in TeleHuman2 is within 1 degree,"and not significantly different from similar judgments of a collocated arrow object.""","videoconference, telepresence, 3d video, motion parallax, hologram, cylindrical display, light field",CHI '18,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schütte S,Sonnenschein M",Mosaik: Scalable Smart Grid Scenario Specification,,2012,,,,Winter Simulation Conference,"Berlin, Germany",,Proceedings of the Winter Simulation Conference,,2012,,,,,"The development of control strategies for the Smart Grid, the future electricity grid, relies heavily on modeling and simulation for being able to evaluate and optimize these strategies in a cost efficient, secure and timely way. To generate sound simulation results, validated and established simulation models have to be used. If these models are not implemented using the same technology, the composition of simulation models is an interesting approach. We developed a composition framework called mosaik, which allows to specify, compose and simulate Smart Grid scenarios based on the reuse of such heterogeneous simulation models. In its current version, it is suitable for the analysis of Smart Grid issues that can be observed using discrete-time or discrete-event based models. In this paper we focus on the presentation of a scalable (in terms of simulated objects) scenario definition concept based on a formal simulator description presented in earlier publications.",,WSC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Angiulli F,Fassetti F",Toward Generalizing the Unification with Statistical Outliers: The Gradient Outlier Factor Measure,ACM Trans. Knowl. Discov. Data,2016,10,3,,Association for Computing Machinery,"New York, NY, USA",,,,2016-01,,1556-4681,https://doi.org/10.1145/2829956;http://dx.doi.org/10.1145/2829956,10.1145/2829956,"In this work, we introduce a novel definition of outlier, namely the Gradient Outlier Factor (or GOF), with the aim to provide a definition that unifies with the statistical one on some standard distributions but has a different behavior in the presence of mixture distributions. Intuitively, the GOF score measures the probability to stay in the neighborhood of a certain object. It is directly proportional to the density and inversely proportional to the variation of the density. We derive formal properties under which the GOF definition unifies the statistical outlier definition and show that the unification holds for some standard distributions, while the GOF is able to capture tails in the presence of different distributions even if their densities sensibly differ. Moreover, we provide a probabilistic interpretation of the GOF score, by means of the notion of density of the data density. Experimental results confirm that there are scenarios in which the novel definition can be profitably employed. To the best of our knowledge, except for distance-based outlier, no other data mining outlier definition has a so clearly established relationship with statistical outliers.","unification between outlier definitions, statistical outliers, Outlier detection",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chimisliu V,Wotawa F",Abstracting Timing Information in UML State Charts via Temporal Ordering and LOTOS,,2011,,,8–14,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th International Workshop on Automation of Software Test,"Waikiki, Honolulu, HI, USA",2011,9781450305921,,https://doi.org/10.1145/1982595.1982598;http://dx.doi.org/10.1145/1982595.1982598,10.1145/1982595.1982598,"As testing of software systems becomes more and more important and expensive, there is a trend to automate as much as possible of this task. This article is intended as an attempt to breach the gap between academic model-based testing tools and their usage in industry. This is done by allowing the specification of a system in a widely accepted industry notation (UML state charts) and via a behind the scene transformation providing a formal representation of the system using the formal language LOTOS. As a byproduct of the transformation a formal semantics of UML state charts is given. An interesting class of software systems well suited for the application are distributed timed control oriented systems. As LOTOS contains no timing constructs, the timing information in the system is automatically abstracted by preserving the execution order of the timeout transitions.","lotos, timing abstraction, uml state charts",AST '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen H,Ku WS,Wang H,Sun MT",Leveraging Spatio-Temporal Redundancy for RFID Data Cleansing,,2010,,,51–62,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM SIGMOD International Conference on Management of Data,"Indianapolis, Indiana, USA",2010,9781450300322,,https://doi.org/10.1145/1807167.1807176;http://dx.doi.org/10.1145/1807167.1807176,10.1145/1807167.1807176,"Radio Frequency Identification (RFID) technologies are used in many applications for data collection. However, raw RFID readings are usually of low quality and may contain many anomalies. An ideal solution for RFID data cleansing should address the following issues. First, in many applications, duplicate readings (by multiple readers simultaneously or by a single reader over a period of time) of the same object are very common. The solution should take advantage of the resulting data redundancy for data cleaning. Second, prior knowledge about the readers and the environment (e.g., prior data distribution, false negative rates of readers) may help improve data quality and remove data anomalies, and a desired solution must be able to quantify the degree of uncertainty based on such knowledge. Third, the solution should take advantage of given constraints in target applications (e.g., the number of objects in a same location cannot exceed a given value) to elevate the accuracy of data cleansing. There are a number of existing RFID data cleansing techniques. However, none of them support all the aforementioned features. In this paper we propose a Bayesian inference based approach for cleaning RFID raw data. Our approach takes full advantage of data redundancy. To capture the likelihood, we design an n-state detection model and formally prove that the 3-state model can maximize the system performance. Moreover, in order to sample from the posterior, we devise a Metropolis-Hastings sampler with Constraints (MH-C), which incorporates constraint management to clean RFID raw data with high efficiency and accuracy. We validate our solution with a common RFID application and demonstrate the advantages of our approach through extensive simulations.","uncertainty, spatio-temporal databases, probabilistic algorithms, data cleaning",SIGMOD '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Carniel AC,Schneider M,Ciferri RR,de Aguiar Ciferri CD",Modeling Fuzzy Topological Predicates for Fuzzy Regions,,2014,,,529–532,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 22nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems,"Dallas, Texas",2014,9781450331319,,https://doi.org/10.1145/2666310.2666497;http://dx.doi.org/10.1145/2666310.2666497,10.1145/2666310.2666497,"Spatial database systems and Geographical Information Systems (GIS) are currently only able to handle crisp spatial objects, i.e., objects whose extent, shape, and boundary are precisely determined. However, GIS applications are also interested in managing vague or fuzzy spatial objects. Spatial fuzziness captures the inherent property of many spatial objects in reality that do not have sharp boundaries and interiors or whose boundaries and interiors cannot be precisely determined. While topological relationships have been broadly explored for crisp spatial objects, this is not the case for fuzzy spatial objects. In this paper, we propose a novel model to formally define fuzzy topological predicates for simple and complex fuzzy regions. The model encompasses six fuzzy predicates (overlap, disjoint, inside, contains, equal and meet), wherein here we focus on the fuzzy overlap and the fuzzy disjoint predicates only. For their computation we consider two low-level measures, the degree of membership and the degree of coverage, and map them to high-level fuzzy modifiers and linguistic values respectively that are deployed in spatial queries by end-users.","spatial vagueness, fuzzy region, fuzzy topological predicate",SIGSPATIAL '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Niemann K,Schmitz HC,Kirschenmann U,Wolpers M,Schmidt A,Krones T",Clustering by Usage: Higher Order Co-Occurrences of Learning Objects,,2012,,,238–247,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Learning Analytics and Knowledge,"Vancouver, British Columbia, Canada",2012,9781450311113,,https://doi.org/10.1145/2330601.2330659;http://dx.doi.org/10.1145/2330601.2330659,10.1145/2330601.2330659,"In this paper, we introduce a new way of detecting semantic similarities between learning objects by analyzing their usage in a web portal. Our approach does not rely on the content of the learning objects or on the relations between the users and the learning objects but on usage-based relations between the objects themselves. The technique we apply for calculating higher order co-occurrences to create semantically homogenous clusters of data objects is taken from corpus driven lexicology where it is used to cluster words. We expect the members of a higher order co-occurrence class to be similar according to their content and present the evaluations of that assumption using two teaching and learning systems.","higher-order co-occurrences, learning objects, clustering, usage data, attention metadata, learning analytics",LAK '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Rachuri S,Science Based Information Metrology for Engineering Informatics,,2007,,,263–266,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2007 Workshop on Performance Metrics for Intelligent Systems,"Washington, D.C.",2007,9781595938541,,https://doi.org/10.1145/1660877.1660915;http://dx.doi.org/10.1145/1660877.1660915,10.1145/1660877.1660915,"Engineering informatics is the discipline of creating, codifying (structure and behavior that is syntax and semantics), exchanging (interactions and sharing), processing (decision making), storing and retrieving (archive and access) the digital objects that characterize the cross-disciplinary domains of engineering discourse. It is absolutely critical that a sharing mechanism should preserve correctness (semantics), be efficient (for example, representation, storage and retrieval, interface), inexpensive (for example, resources, cost, time), and secure. In order to create such a sharing mechanism, we need a science-based approach for understanding significant relationships among the concepts and consistent standards, measurements, and specifications. To develop this science, it is essential to understand the interactions among the theory of languages, representation theory, and domain theory. Creating the science of information metrology will require a fundamental and formal approach to metrology, measurement methods and testing and validation similar to the physical sciences.","standards, product lifecycle, engineering informatics, interoperability, semantics, metrics",PerMIS '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ardeshiricham A,Takashima Y,Gao S,Kastner R",VeriSketch: Synthesizing Secure Hardware Designs with Timing-Sensitive Information Flow Properties,,2019,,,1623–1638,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security,"London, United Kingdom",2019,9781450367479,,https://doi.org/10.1145/3319535.3354246;http://dx.doi.org/10.1145/3319535.3354246,10.1145/3319535.3354246,"We present VeriSketch, a security-oriented program synthesis framework for developing hardware designs with formal guarantee of functional and security specifications. VeriSketch defines a synthesis language, a code instrumentation framework for specifying and inferring timing-sensitive information flow properties, and uses specialized constraint-based synthesis for generating HDL code that enforces the specifications. We show the power of VeriSketch through security-critical hardware design examples, including cache controllers, thread schedulers, and system-on-chip arbiters, with formal guarantee of security properties such as absence of timing side-channels, confidentiality, and isolation.","security verification, program synthesis, hardware security, timing side channel, information flow tracking",CCS '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Aotani T,Kamina T,Masuhara H",Context Holders: Realizing Multiple Layer Activation Mechanisms in a Single Context-Oriented Language,,2014,,,3–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th Workshop on Foundations of Aspect-Oriented Languages,"Lugano, Switzerland",2014,9781450327985,,https://doi.org/10.1145/2588548.2588552;http://dx.doi.org/10.1145/2588548.2588552,10.1145/2588548.2588552,"We propose LamFJ, a calculus for expressing various layer activation mechanisms in context-oriented programming languages. LamFJ extends FeatherweightJava with context holders which are the abstraction of dynamic layer activation. By encoding programs with different layer activation mechanisms into a program manipulating context holders, LamFJ serves as a foundation to reason about interactions between different mechanisms. This paper presents a sketch of the context holders and encodings of existing layer activation mechanisms.","context-oriented programming, layer activation mechanisms",FOAL '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Doore K,Fishwick P",Prototyping an Analog Computing Representation of Predator Prey Dynamics,,2014,,,3561–3571a,IEEE Press,"Savannah, Georgia",,Proceedings of the 2014 Winter Simulation Conference,,2014,,,,,"Analyzing systems can be a complex task especially when there is feedback across several variables in the model. Formal mathematical notation makes it difficult to understand the influences of feedback and cause/effect. Forrester created the System Dynamics methodology as a means to assist in this understanding by employing a hydraulic analogy. In this methodology, variables become simulated objects such as water valves or tanks. A variety of implementations allow users to construct and simulate these models. The problem is that for many implementations, the intuitive nature of water flow, intended by the methodology, is not as clear as it could be. For instance, the rate of flow or level in a tank may not be visualized. For novices, we suggest that this issue, as well the ability to understand relationships and linking across multiple representations can be problematic. We designed and describe a web-based interface that solves these problems.",,WSC '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Boulanger F,Famelis M,Fondement F,Lúcio L,Weißleder S",MoDeVVa 2012 Workshop Summary,,2012,,,3–4,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Workshop on Model-Driven Engineering, Verification and Validation","Innsbruck, Austria",2012,9781450318013,,https://doi.org/10.1145/2427376.2427377;http://dx.doi.org/10.1145/2427376.2427377,10.1145/2427376.2427377,"The MoDeVVa workshop series is dedicated to the interaction between advancements in the field of Model-Driven Engineering (MDE) and in the field of Verification and Validation (V&V). During the eight previous editions, it became evident that this interaction works in both directions. On the one hand, the use of models facilitates the deployment of formal V&V tools and techniques by providing high-level abstractions of systems. Indicative of the research community's interest in MDE as a method for facilitating and popularizing formal methods for verification was the focus on MDE of the 12th International School on Formal Methods in Bertinoro, Italy in June 2012 [2]. On the other hand, the models and transformations in the context of MDE are becoming ever more complex, accentuating the need for formal V&V techniques to help manage this complexity. Growing academic maturity in this area is demonstrated by the establishment of new topic-specific workshops, such as VOLT'12, which is specificically oriented towards the challenges of the verification of model transformations, and was held in April 2012 in Montréal Canada [1].",,MoDeVVa '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Z,Herkersdorf A,Haberl W,Wechs M",SysCOLA: A Framework for Co-Development of Automotive Software and System Platform,,2009,,,37–42,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 46th Annual Design Automation Conference,"San Francisco, California",2009,9781605584973,,https://doi.org/10.1145/1629911.1629924;http://dx.doi.org/10.1145/1629911.1629924,10.1145/1629911.1629924,"A modeling language with formal semantics is able to capture a system's functionality unambiguously, without concerning implementation details. Such a formal language is well-suited for a design process that employs formal techniques and supports hardware/software synthesis. On the other hand, SystemC is a widely used system level design language with hardware-oriented modeling features. It provides a desirable simulation framework for system architecture design and exploration. This paper presents a design framework, called SysCOLA, that makes use of the unique advantages of both a new formal modeling language, COLA, and SystemC, and allows for parallel development of application software and system platform. In SysCOLA, function design and architecture exploration are done in the COLA based modeling environment and the SystemC based virtual prototyping environment, respectively. Our concepts of abstract platform and virtual platform abstraction layer facilitate the orthogonalization of functionality and architecture by means of mapping and integration in the respective environments. As SysCOLA is targeted at the automotive domain, the whole design approach is showcased using a case study of designing an automotive system.","COLA, system modeling, SystemC, virtual prototyping",DAC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Arroyo I,Micciollo M,Casano J,Ottmar E,Hulse T,Rodrigo MM",Wearable Learning: Multiplayer Embodied Games for Math,,2017,,,205–216,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Annual Symposium on Computer-Human Interaction in Play,"Amsterdam, The Netherlands",2017,9781450348980,,https://doi.org/10.1145/3116595.3116637;http://dx.doi.org/10.1145/3116595.3116637,10.1145/3116595.3116637,"We present a new technology-based paradigm to support embodied mathematics educational games, using wearable devices in the form of SmartPhones and SmartWatches for math learning, for full classes of students in formal in-school education settings. The Wearable Learning Games Engine is web based infrastructure that enables students to carry one mobile device per child, as they embark on math team-based activities that require physical engagement with the environment. These Wearable Tutors serve as guides and assistants while students manipulate, measure, estimate, discern, discard and find mathematical objects that satisfy specified constraints. Multi-player math games that use this infrastructure have yielded both cognitive and affective benefits. Beyond math game play, the Wearable Games Engine Authoring Tool enables students to create games themselves for other students to play; in this process, students engage in computational thinking and learn about finite-state machines. We present the infrastructure, games, and results for a series of experiments on both game play and game creation.","wearable learning, tutoring systems, mathematics, embodied cognition, educational games, computational thinking",CHI PLAY '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sun C,Wen H,Fan H",Operational Transformation for Orthogonal Conflict Resolution in Real-Time Collaborative 2d Editing Systems,,2012,,,1391–1400,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM 2012 Conference on Computer Supported Cooperative Work,"Seattle, Washington, USA",2012,9781450310864,,https://doi.org/10.1145/2145204.2145411;http://dx.doi.org/10.1145/2145204.2145411,10.1145/2145204.2145411,"Operational Transformation (OT) is commonly used for conflict resolution in real-time collaborative applications, but none of existing OT techniques is able to solve a special type of conflict - orthogonal conflict, which may occur when concurrent operations are inserting/deleting an arbitrary number of objects in different dimensions of a two-dimensional (2D) workspace, such as spreadsheet documents. This paper is the first to identify and solve the orthogonal conflict problem by extending OT with a new capability of resolving 2D conflicts. Extending OT from one- to two-dimensional conflict resolution is fundamental to the theory and application of OT, and technically challenging as well because 2D orthogonal conflict is different from but intimately related to the one-dimensional positional shifting conflict and necessitates new and integral solutions for multi-dimensional conflicts. In this paper, we present formal definitions of orthogonal conflict, pseudo-code description, design rationale analysis, and correctness verification and complexity analysis of the 2DOT solution.","real-time collaborative spreadsheet and table editing, conflict resolution, operational transformation",CSCW '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Huang B,Cheng X,Cheng W",Meet-Fog for Accurate Distribution of Negative Messages in VANET,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Workshop on Smart Internet of Things,"San Jose, California",2017,9781450355285,,https://doi.org/10.1145/3132479.3132483;http://dx.doi.org/10.1145/3132479.3132483,10.1145/3132479.3132483,"Negative messages, such as CRL (Certificate Revocation List), describe negative attributes of objects in VANET (Vehicular Ad hoc Network), so accurately distributing negative messages is an essential task to make VANET secure. We had proposed a scheme based on Meet-Table and Cloud Computing to realize it. In this paper, we propose Meet-Fog, a scheme based on Meet-Table and Fog Computing, to distribute negative messages in VANET with more efficiency, for Fog Computing can be used to optimize computing, communication and storage between edge and cloud. The architecture and formal model of Meet-Fog are given, and related algorithms are described in detail. The analysis results show that Meet-Fog is a good scheme for negative message distribution as it has high coverage percentage and high accurate coverage percentage at the same time. Meet-Fog can also sharply reduce bandwidth and storage requirements of cloud, and completely move computing requirements from cloud to the edge.","meet-table, negative message, cloud computing, VANET, fog computing",SmartIoT '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Tabareau N,Aspect Oriented Programming: A Language for 2-Categories,,2011,,,13–17,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Workshop on Foundations of Aspect-Oriented Languages,"Porto de Galinhas, Brazil",2011,9781450306447,,https://doi.org/10.1145/1960510.1960514;http://dx.doi.org/10.1145/1960510.1960514,10.1145/1960510.1960514,"Aspect-Oriented Programming (AOP) started ten years ago with the remark that modularization of so-called crosscutting functionalities is a fundamental problem for the engineering of large-scale applications. Originating at Xerox PARC, this observation has sparked the development of a new style of programming featured that is gradually gaining traction, as it is the case for the related concept of code injection, in the guise of frameworks such as Swing and Google Guice. However, AOP lacks theoretical foundations to clarify this new idea. This paper proposes to put a bridge between AOP and the notion of 2-category to enhance the conceptual understanding of AOP. Starting from the connection between the !-calculus and the theory of categories, we propose to see an aspect as a morphism between morphisms'that is as a program that transforms the execution of a program. To make this connection precise, we develop an advised !-calculus that provides an internal language for 2-categories and show how it can be used as a base for the definition of the weaving mechanism of a realistic functional AOP language, called MinAML","2-category, AOP",FOAL '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liu B,Guo Y,Chen X",WealthAdapt: A General Network Adaptation Framework for Small Data Tasks,,2019,,,2179–2187,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th ACM International Conference on Multimedia,"Nice, France",2019,9781450368896,,https://doi.org/10.1145/3343031.3351035;http://dx.doi.org/10.1145/3343031.3351035,10.1145/3343031.3351035,"In this paper, we propose a general network adaptation framework, namely WealthAdapt, to effectively adapt a large network for small data tasks, with the assistance of a wealth of related data. While many existing algorithms have proposed network adaptation techniques for resource-constrained systems, they typically implement network adaptation based on a large dataset and do not perform well when facing small data tasks. Because small data have poor feature expression ability, it may result in incorrect filter selection and overfitting during fine-tuning in the network adaptation process. In WealthAdapt, we first expand the target small data task with the wealth of big data, before we perform network adaptation, in order to enrich the features and improve the fine-tuning performance during adaptation. We formally establish network adaptation for small data tasks as an optimization problem and solve it through two main techniques:model-based fast selection andwealth-incorporated iteration adaptation. Experimental results demonstrate that our framework is applicable to both the vanilla convolutional network VGG-16 and more complex modern architecture ResNet-50, outperforming several state-of-the-art network adaptation pipelines on multiple visual classification tasks includinggeneral object recognition, fine-grained object recognition andscene recognition.","incorporation, selection, big data, small data tasks, network adaptation",MM '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Cámara J,HaiQ: Synthesis of Software Design Spaces with Structural and Probabilistic Guarantees,,2020,,,22–33,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on Formal Methods in Software Engineering,"Seoul, Republic of Korea",2020,9781450370714,,https://doi.org/10.1145/3372020.3391562;http://dx.doi.org/10.1145/3372020.3391562,10.1145/3372020.3391562,"Formal methods used to validate software designs, like Alloy, OCL, and B, are powerful tools to analyze complex structures (e.g., architectures, object-relational mappings) captured as sets of relational constraints. However, their applicability is limited when software is subject to uncertainty (derived, e.g., from lack of control over third-party components, interaction with physical elements). In contrast, quantitative verification has emerged as a powerful way of providing quantitative guarantees about the performance, cost, and reliability of systems operating under uncertainty. However, quantitative verification methods do not retain thefl exibility of relational modeling in describing structures, forcing engineers to trade structural exploration for analytic capabilities that concern probabilistic and other quantitative guarantees. This paper contributes a method (HaiQ) that enhances structural modeling/synthesis with quantitative guarantees in the style provided by quantitative verification. It includes a language for describing structure and (stochastic) behavior of systems, and a temporal logic that allows checking probability and reward-based properties over sets of feasible design alternatives implicitly described by the relational constraints in a HaiQ model. We report the results of applying a prototype tool in two domains, on which we show the feasibility of synthesizing structural designs that optimize probabilistic and other quantitative guarantees.","Alloy, PRISM, probabilistic model checking, quantitative verification, Uncertainty, HaiQ, relational modeling, guarantees, M-PCTL",FormaliSE '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang Y,Li X,Liu Z,Ke W",RM2PT: A Tool for Automated Prototype Generation from Requirements Model,,2019,,,59–62,IEEE Press,"Montreal, Quebec, Canada",,Proceedings of the 41st International Conference on Software Engineering: Companion Proceedings,,2019,,,https://doi.org/10.1109/ICSE-Companion.2019.00038;http://dx.doi.org/10.1109/ICSE-Companion.2019.00038,10.1109/ICSE-Companion.2019.00038,"Prototyping is an effective and efficient way of requirement validation to avoid introducing errors in the early stage of software development. However, manually developing a prototype of a software system requires additional efforts, which would increase the overall cost of software development. Based on our proposed approach, we develop RM2PT: a tool for generating prototypes from requirements models automatically. A requirements model consists of a use case diagram, a conceptual class diagram, system sequence diagrams for use cases, and the formal contracts of their system operations in OCL (Object Constraint Language). RM2PT can generate executable MVC (Model View Controller) prototypes from requirements models automatically. We evaluate the tool with four case studies. 93.65% of requirement specifications can be generated to the executable Java source code successfully, and only 6.35% are non-executable for our current provided generation algorithm such as sorting and event-call, which can be implemented by developers manually or invoking the APIs of advanced algorithms in Java library. The tool is efficient that the one second generated prototype of a case study requires approximate nine hours manual implementation by skilled programmers.The tool can be downloaded at http://rm2pt.mydreamy.net, and a demo video casting its features is at https://youtu.be/rDdpXsjSq8A","prototype, requirements validation, UML, OCL, code generation, requirements model",ICSE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yi J,Robby,Deng X,Roychoudhury A",Past Expression: Encapsulating Pre-States at Post-Conditions by Means of AOP,,2013,,,133–144,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Annual International Conference on Aspect-Oriented Software Development,"Fukuoka, Japan",2013,9781450317665,,https://doi.org/10.1145/2451436.2451453;http://dx.doi.org/10.1145/2451436.2451453,10.1145/2451436.2451453,"Providing a pair of pre and post-condition for a method or a procedure is a typical way of program specification. When specifying a post-condition, it is often necessary to compare the post-state value of a variable with its pre-state value. To access a pre-sate value at a post-condition, most contract languages such as Eiffel and JML provide an old expression; old(x) returns a pre-state value of variable x. However, old expressions pose several problems, most notably the lack of encapsulation; old(x) does not encapsulate an object graph rooted from the pre-state value of x. Thus, method-call expressions like x.equals(old(x)) should generally not be used, and instead each field of x should be compared individually as in x.f1==old(x.f1) & x.f2==old(x.f2). In this paper, we first describe this lack of encapsulation and other problems of old expressions in more detail. Then, to address those problems, we propose our novel past expression along with its formal semantics. We also describe how our past expression can be supported during runtime assertion checking. We explain the involved problems, and show how we solve them. We implement our solution by means of AOP where we exploit various primitive pointcuts including our custom branch pointcut.","past expression, runtime assertion checking (RAC), old expression, branch pointcut, contract, encapsulation",AOSD '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Venetis P,Koutrika G,Garcia-Molina H",On the Selection of Tags for Tag Clouds,,2011,,,835–844,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Fourth ACM International Conference on Web Search and Data Mining,"Hong Kong, China",2011,9781450304931,,https://doi.org/10.1145/1935826.1935855;http://dx.doi.org/10.1145/1935826.1935855,10.1145/1935826.1935855,"We examine the creation of a tag cloud for exploring and understanding a set of objects (e.g., web pages, documents). In the first part of our work, we present a formal system model for reasoning about tag clouds. We then present metrics that capture the structural properties of a tag cloud, and we briefly present a set of tag selection algorithms that are used in current sites (e.g., del.icio.us, Flickr, Technorati) or that have been described in recent work. In order to evaluate the results of these algorithms, we devise a novel synthetic user model. This user model is specifically tailored for tag cloud evaluation and assumes an \ideal\"" user. We evaluate the algorithms under this user model",as well as the model itself,"using two datasets: CourseRank (a Stanford social tool containing information about courses) and del.icio.us (a social bookmarking site). The results yield insights as to when and why certain selection schemes work best.""","tags, tag clouds, tag selection",WSDM '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hong P,Sheng C,Luo X,Jin Y,Rao R",OACV: OCL-Based Avionics Component Verification,,2020,,,129–134,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2020 4th International Conference on High Performance Compilation, Computing and Communications","Guangzhou, China",2020,9781450376914,,https://doi.org/10.1145/3407947.3407958;http://dx.doi.org/10.1145/3407947.3407958,10.1145/3407947.3407958,"Modern avionics system, especially those developed for modern aircraft, require extremely high portability, interoperability, standardization and accuracy. But during the model integration of avionics component models based on the multi-team development method, component models developed by different teams, especially component data models, may exists some problems during interoperation, including message semantic ambiguities, mismatched metrics, missing information, as well as inaccurate and non-standard model definitions. Therefore, this paper analyzes the key attributes such as portability, interoperability, standardization, and accuracy of data models, including abstract data models, logical data models, and platform data models in the data architecture of avionics-based model-driven development. Based on the definition of standardized software component, an Object Constraint Language (OCL)-based avionics component model verification method (OACV) is proposed. OCL is used to perform constraint validation on the data model to ensure semantic and syntactic consistency and standardization of interoperable data. In order to verify the correctness of the constraint verification of data models using OCL, this paper further proposes a formal description of verification of these data models based on OCL. Based on this, this article designs and implements OACV System. Finally, the actual project requirements of avionics were extracted, and a verification case was developed. The verification result shows that OACV is feasible and effective.","Avionics component model verification, OCL, Avionics software system",HP3C 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xiao Q,Chen M,Chen S,Zhou Y",Temporally or Spatially Dispersed Joint RFID Estimation Using Snapshots of Variable Lengths,,2015,,,247–256,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th ACM International Symposium on Mobile Ad Hoc Networking and Computing,"Hangzhou, China",2015,9781450334891,,https://doi.org/10.1145/2746285.2746289;http://dx.doi.org/10.1145/2746285.2746289,10.1145/2746285.2746289,"Radio-frequency identification (RFID) technology has been widely used in applications such as inventory control, object tracking, supply chain management. An important research is to estimate the number of tags in a certain area covered by readers. This paper extends the research in both temporal and spatial dimensions to provide much richer information for monitoring the dynamics of distributed RFID systems. More specifically, we are interested in estimating the joint properties of any two snapshots taken at arbitrary locations and arbitrary times in a system. With many practical applications, there is however little prior work on this problem. We propose a joint RFID estimation protocol based on a simple yet versatile snapshot construction. Given the snapshots of any two tag sets, although their sizes may be very different, we design a way to combine their information and more importantly derive formulas to extract the joint properties of the two tag sets from the combined information, with an accuracy that can be arbitrarily set. Through formal analysis, we determine the optimal system parameters that minimize the execution time of taking snapshots, under the constraints of a given accuracy requirement. Our simulation results show that the proposed protocol can reduce the execution time by multifold when comparing with the best alternative approach in the literature.","cardinality estimation, random hashing, rfid",MobiHoc '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wickett KM,Renear AH,Urban RJ",Rule Categories for Collection/Item Metadata Relationships,,2010,,,,American Society for Information Science,USA,,Proceedings of the 73rd ASIS&T Annual Meeting on Navigating Streams in an Information Ecosystem - Volume 47,"Pittsburgh, Pennsylvania",2010,,,,,"Collections of artifacts, images, texts, and other cultural objects are not arbitrary aggregations, but are designed to support specific research and scholarly activities. Collection-level metadata directly supports this objective, providing critical contextual information. However, exploiting this information, especially in a semantic web environment of linked data, requires a precise formalization of the rules that characterize collection/item metadata relationships. Toward this end we are developing a logic-based framework of relationship rule categories for collection/item metadata. This framework will support metadata specification developers, metadata catalogers, and system designers. In earlier work we described three example rule categories for propagation of information from collections to items. Further reflection, and examination of metadata in an RDF testbed, has revealed eighteen categories, which form an interrelated system with three levels of specificity and formal constraints differentiating categories. This paper summarizes the results of a three year effort, part of the IMLS Digital Collections and Content project.","digital libraries, collections, metadata, ontologies, information organization",ASIS&T '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Elstermann M,Heuser T",Automatic Tool Support Possibilities for the Text-Based S-BPM Process Modelling Methodology,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on Subject-Oriented Business Process Management,"Erlangen, Germany",2016,9781450340717,,https://doi.org/10.1145/2882879.2882882;http://dx.doi.org/10.1145/2882879.2882882,10.1145/2882879.2882882,"In the sister paper to this work1 we proposed a method for using natural language text as the working basis of business process management efforts, especially incorporating the subject-oriented business process management and modeling (S-BPM) paradigm. The texts then would function as the basis to derive formal process models from. The methodology alone, especially when executed manually, may not have enough advantages over classical direct description-to-formal-model approaches. Consequently, in this paper we examine the possibilities, but also the limitations, of using state of the art computer linguistic tools to automate and support the derivation process.","natural language text, process analysis methodology, subject-orientation, S-BPM",S-BPM '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gjondrekaj E,Loreti M,Pugliese R,Tiezzi F",Modeling Adaptation with a Tuple-Based Coordination Language,,2012,,,1522–1527,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th Annual ACM Symposium on Applied Computing,"Trento, Italy",2012,9781450308571,,https://doi.org/10.1145/2245276.2232019;http://dx.doi.org/10.1145/2245276.2232019,10.1145/2245276.2232019,"In recent years, it has been argued that systems and applications, in order to deal with their increasing complexity, should be able to adapt their behavior according to new requirements or environment conditions. In this paper, we present a preliminary investigation aiming at studying how coordination languages and formal methods can contribute to a better understanding, implementation and usage of the mechanisms and techniques for adaptation currently proposed in the literature. Our study relies on the formal coordination language Klaim as a common framework for modeling some adaptation techniques, namely the MAPE-K loop, aspect- and context-oriented programming.","autonomic computing, adaptive systems, coordination languages, aspect- and context-oriented programming",SAC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gianni D,Bocciarelli P,D'Ambrogio A",Temporal Capabilities in Support of Conceptual Process Modeling Using Object-Role Modeling,,2014,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the Symposium on Theory of Modeling & Simulation - DEVS Integrative,"Tampa, Florida",2014,,,,,"Conceptual data modeling languages must be provided with temporal capabilities to support the data evolution throughout the execution of a conceptual process model. Asides from supporting the storage of historical data, temporal capabilities must also provide the means for verifying the consistency between the data temporal properties and the data modification resulting from the process execution. The Object-Role Modeling (ORM) language is a conceptual data modeling language that is based on the concepts of Fact (i.e. true statements on the represented world), Fact Type, and Fact Base (i.e. the set of all the Facts). Currently, the ORM language does not address the specification of Facts temporal properties, and therefore does not also support the verification of Facts variations during a process execution. The paper introduces an initial ORM overlay methodology that aims to laying the foundation of the conceptual modeling structures that can support the verification of temporal evolution of conceptual data models (i.e., whether a Fact can be asserted or retracted, depending on its temporal properties). Moreover, the overlay methodology also defines a temporal visual notation and an initial semi-formal temporal verbalization that eases the use of the methodology to the ORM modelers. A simple example illustrates the potential application of the overlay methodology.","process modeling, conceptual data modeling, temporal modeling, object-role modeling",DEVS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Malik A,Salcic Z,Chong C,Javed S",System-Level Approach to the Design of a Smart Distributed Surveillance System Using Systemj,ACM Trans. Embed. Comput. Syst.,2013,11,4,,Association for Computing Machinery,"New York, NY, USA",,,,2013-01,,1539-9087,https://doi.org/10.1145/2362336.2362344;http://dx.doi.org/10.1145/2362336.2362344,10.1145/2362336.2362344,"Distributed surveillance systems represent a class of sensor networks used for object location and tracking, road traffic monitoring, security, and other purposes. They are very complex to describe, design, and run. Because of their sensitivity, they need to be carefully designed and validated. We present a system-level approach to modeling and designing such systems using a new system-level programming language, SystemJ, which enables designers to describe computational and communication parts of such applications in a highly abstract manner. The designed system can be modeled and validated even before deployment and in that way contribute to the overall reliability and trustworthiness of such systems. As an additional tool, the design environment for specification of the surveillance system topology, physical and communication properties, selected sensors and their interconnectivity with the computing resources was developed. This tool enables easy composition of multiple sensors and their respective controllers, capturing changes of configuration of the system and underlying communication, and automatic generation of the formal description of the surveillance system. This description is then used for the generation of executable code and/or the templates for detailed SystemJ application-specific code, as well as for generation of the operator GUI in a surveillance system.","GALS, SystemJ, distributed system, System-level design, concurrency",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wolski A,Borgert S,Heuser L",An Extended Subject-Oriented Business Process Management Execution Semantics,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Subject-Oriented Business Process Management,"Seville, Spain",2019,9781450362504,,https://doi.org/10.1145/3329007.3332706;http://dx.doi.org/10.1145/3329007.3332706,10.1145/3329007.3332706,The Subject-oriented Business Process Management (S-BPM) paradigm provides concepts and methods to support the development of in- and inter-organizational parallel and distributed processes. S-BPM Process Models are directly executable and formal execution semantics enable different software development teams to develop S-BPM engines with equivalent execution behavior. We did a state of the art analysis of existing formal S-BPM execution semantics and analyzed the required language elements of an advanced smart energy grid Process Model. We extended an existing Abstract State Machines (ASM) specification to close the identified specification gaps.,"subject-oriented business process management, abstract state machines",S-BPM ONE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Bak S,Huang Z,Abad FA,Caccamo M",Safety and Progress for Distributed Cyber-Physical Systems with Unreliable Communication,ACM Trans. Embed. Comput. Syst.,2015,14,4,,Association for Computing Machinery,"New York, NY, USA",,,,2015-09,,1539-9087,https://doi.org/10.1145/2739046;http://dx.doi.org/10.1145/2739046,10.1145/2739046,"Cyber-physical systems (CPSs) may interact and manipulate objects in the physical world, and therefore formal guarantees about their behavior are strongly desired. Static-time proofs of safety invariants, however, may be intractable for systems with distributed physical-world interactions. This is further complicated when realistic communication models are considered, for which there may not be bounds on message delays, or even when considering that messages will eventually reach their destination.In this work, we address the challenge of proving safety and progress in distributed CPSs communicating over an unreliable communication layer. We show that for this type of communication model, system safety is closely related to the results of a hybrid system’s reachability computation, which can be computed at runtime. However, since computing reachability at runtime may be computationally intensive, we provide an approach that moves significant parts of the computation to design time. This approach is demonstrated with a case study of a simulation of multiple vehicles moving within a shared environment.","Hybrid automata, cyber-physical systems, runtime verification, reachability computation, distributed system design",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ripon KS,Khan KN,Glette K,Hovin M,Torresen J",Using Pareto-Optimality for Solving Multi-Objective Unequal Area Facility Layout Problem,,2011,,,681–688,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th Annual Conference on Genetic and Evolutionary Computation,"Dublin, Ireland",2011,9781450305570,,https://doi.org/10.1145/2001576.2001670;http://dx.doi.org/10.1145/2001576.2001670,10.1145/2001576.2001670,"A lot of optimal and heuristic algorithms for solving facility layout problem (FLP) have been developed in the past few decades. The majority of these approaches adopt a problem formulation known as the quadratic assignment problem (QAP) that is particularly suitable for equal area facilities. Unequal area FLP comprises a class of extremely difficult and widely applicable optimization problems arising in many diverse areas to meet the requirements for real-world applications. Unfortunately, most of these approaches are based on a single objective. While, the real-world FLPs are multi-objective by nature. Only very recently have meta-heuristics been designed and used in multi-objective FLP. They most often use the weighted sum method to combine the different objectives and thus, inherit the well-known problems of this method. As of now, there is no formal approach published for the unequal area multi-objective FLP to consider several objectives simultaneously. This paper presents an evolutionary approach for solving multi-objective unequal area FLP using multi-objective genetic algorithm that presents the layout as a set of Pareto-optimal solutions optimizing multiple objectives simultaneously. The experimental results show that the proposed approach performs well in dealing with multi-objective unequal area FLPs which better reflects the real-world scenario.","qualitative objective, multi-objective optimization, pareto-optimal solutions, unequal area flp, quantitative objective",GECCO '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Song H,Guimbretière F,Lipson H",The ModelCraft Framework: Capturing Freehand Annotations and Edits to Facilitate the 3D Model Design Process Using a Digital Pen,ACM Trans. Comput. -Hum. Interact.,2009,16,3,,Association for Computing Machinery,"New York, NY, USA",,,,2009-09,,1073-0516,https://doi.org/10.1145/1592440.1592443;http://dx.doi.org/10.1145/1592440.1592443,10.1145/1592440.1592443,"Recent advancements in rapid prototyping techniques such as 3D printing and laser cutting are changing the perception of physical 3D models in architecture and industrial design. Physical models are frequently created not only to finalize a project but also to demonstrate an idea in early design stages. For such tasks, models can easily be annotated to capture comments, edits, and other forms of feedback. Unfortunately, these annotations remain in the physical world and cannot easily be transferred back to the digital world. Our system, ModelCraft, addresses this problem by augmenting the surface of a model with a traceable pattern. Any sketch drawn on the surface of the model using a digital pen is recovered as part of a digital representation. Sketches can also be interpreted as edit marks that trigger the corresponding operations on the CAD model. ModelCraft supports a wide range of operations on complex models, from editing a model to assembling multiple models, and offers physical tools to capture free-space input. Several interviews and a formal study with the potential users of our system proved the ModelCraft system useful. Our system is inexpensive, requires no tracking infrastructure or per object calibration, and we show how it could be extended seamlessly to use current 3D printing technology.","Pen-based interactions, tangible interactions, rapid prototyping",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Baker E,May B",Design Goal-Oriented Level Design,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2011 Posters,"Vancouver, British Columbia, Canada",2011,9781450309714,,https://doi.org/10.1145/2037715.2037737;http://dx.doi.org/10.1145/2037715.2037737,10.1145/2037715.2037737,"Design Goal-Oriented Level Design is our new process for linking mechanics, narrative and environment design into one streamlined document for use by level designers. The most significant innovation of this research is the creation of a formal grammar of level design terms. This work is influenced by the previous work [Björk et al. 2003] on a formal grammar for all aspects of game design. It was also influenced by [Vick etal. 2010], from which we adopted the process of abstracting any gameplay mechanic and categorizing it as a subset of a larger categorization of mechanics.",,SIGGRAPH '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zelle D,Lauser T,Kern D,Krauß C",Analyzing and Securing SOME/IP Automotive Services with Formal and Practical Methods,,2021,,,,Association for Computing Machinery,"New York, NY, USA",,"The 16th International Conference on Availability, Reliability and Security","Vienna, Austria",2021,9781450390514,,https://doi.org/10.1145/3465481.3465748;http://dx.doi.org/10.1145/3465481.3465748,10.1145/3465481.3465748,"Automotive Ethernet is increasingly used in modern vehicles and complements or replaces legacy bus systems such as CAN. Ethernet also enables service-oriented communication with the Scalable service-Oriented MiddlewarE over IP (SOME/IP) middleware. In this paper, we present a formal and practical security analysis of Scalable service-Oriented MiddlewarE over IP (SOME/IP), the identified Man-in-the-Middle (MITM) attacks, and propose two security extensions. The attacks are possible even if SOME/IP is used in combination with link layer security mechanisms. The attacker can impersonate a service offering server and a service consuming client. The two most common communication methods, request/response and publish/subscribe, are both vulnerable. In most communication scenarios, we are able to route all messages over the attacker. Our security extensions for authentication and authorization of service provisioning and usage protect against these attacks. We formally analyze the security and evaluate the overhead with practical implementations.","SOME/IP, Automotive Security, Man-in-the-Middle Attack",ARES 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xiuping M,Gongbing S,Qiming W,Huiyong Z,Langjia Y",A Fast Forecast Method of Chromatic Aberration Based on Color Luminosity,,2017,,,81–85,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2017 International Conference on Deep Learning Technologies,"Chengdu, China",2017,9781450352321,,https://doi.org/10.1145/3094243.3094248;http://dx.doi.org/10.1145/3094243.3094248,10.1145/3094243.3094248,"In CIELAB color space, color chromatic aberration[1-3] is the result of a combination of luminosity difference, chroma difference and hue difference, this three differences played individual weight value[4-5] roles on different color valuation objects[6-8]. A fast forecast method of chromatic aberration which is based on color luminosity[9-10] is presented in this paper. Taken ten groups of dyeing fabrics with different concentration and ratio as study object, and CS-650 colorimeter was adopt to measure data which include the value of luminosity difference, chroma difference, hue difference. The chromatic aberration value was calculated by CIEDE CMC(l:c)[11] formula which is well suit for textile and dyeing industry[12]. In this experiment, one hundred evenly spaced sampling points which were chosen from each group were needed to measure and record. The final data of each group were verified by simulation with MATLAB and displayed by 2D diagram one by one. In these diagrams, the data of luminosity difference, chroma difference, hue difference were taken as horizontal axis and chromatic aberration value as the vertical axis. From the ten groups of 2D data chart, it is obvious that the function of luminosity difference and chromatic aberration value is linear, then taken that function into linear fitting by least-squares[13] method. Compared to the actual chromatic aberration value, the fitting function showed that the average error is no more than 0.05 and the maximum error is no more than 0.2. Therefore, within the range of chromatic aberration precision, it is possible to make color-difference formula simplified, and the method of forecasting chromatic aberration based on color luminosity is practicable and will provide new ideas and ways for evenness detection of color chromatic aberration as well.","CIEDE CMC(l:c), chromatic aberration, least-squares method, luminosity, MATLAB",ICDLT '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chikhaoui A,Lemarchand L,Boukhalfa K,Boukhobza J",Multi-Objective Optimization of Data Placement in a Storage-as-a-Service Federated Cloud,ACM Trans. Storage,2021,17,3,,Association for Computing Machinery,"New York, NY, USA",,,,2021-08,,1553-3077,https://doi.org/10.1145/3452741;http://dx.doi.org/10.1145/3452741,10.1145/3452741,"Cloud federation enables service providers to collaborate to provide better services to customers. For cloud storage services, optimizing customer object placement for a member of a federation is a real challenge. Storage, migration, and latency costs need to be considered. These costs are contradictory in some cases. In this article, we modeled object placement as a multi-objective optimization problem. The proposed model takes into account parameters related to the local infrastructure, the federated environment, customer workloads, and their SLAs. For resolving this problem, we propose CDP-NSGAIIIR, a Constraint Data Placement matheuristic based on NSGAII with Injection and Repair functions. The injection function aims to enhance the solutions’ quality. It consists to calculate some solutions using an exact method then inject them into the initial population of NSGAII. The repair function ensures that the solutions obey the problem constraints and so prevents from exploring large sets of unfeasible solutions. It reduces drastically the execution time of NSGAII. Experimental results show that the injection function improves the HV of NSGAII and the exact method by up to 94% and 60%, respectively, while the repair function reduces the execution time by an average of 68%.","cloud, optimization, NSGAII, cloud federation, Data placement",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Arntzen IM,Borch NT",Data-Independent Sequencing with the Timing Object: A JavaScript Sequencer for Single-Device and Multi-Device Web Media,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Multimedia Systems,"Klagenfurt, Austria",2016,9781450342971,,https://doi.org/10.1145/2910017.2910614;http://dx.doi.org/10.1145/2910017.2910614,10.1145/2910017.2910614,"Media players and frameworks all depend on the ability to produce correctly timed audiovisual effects. More formally, sequencing is the process of translating timed data into correctly timed presentation. Though sequencing logic is a central part of all multimedia applications, it tends to be tightly integrated with specific media formats, authoring models, timing/control primitives and/or predefined UI elements. In this paper, we present the Sequencer, a generic sequencing tool cleanly separated from data, timing/control and UI. Data-independent sequencing implies broad utility as well as simple integration of different data types and delivery methods in multimedia applications. UI-independent sequencing simplifies integration of new data types into visual and interactive components. Integration with an external timing object [7] ensures that media components based on the Sequencer may trivially be synchronized and remote controlled, both in single-page media presentations as well as global, multi-device media applications [5, 6, 7, 16]. A JavaScript implementation for the Sequencer is provided based on setTimeout, ensuring precise timing and reduced energy consumption. The implementation is open sourced as part of timingsrc [2, 3], a new programming model for precisely timed Web applications. The timing object and the Sequencer are proposed for standardization by the W3C Multi-device Timing Community Group [20].","timing object, inter-destination media synchronization, distributed, timed visualization, timed data, sequencing, multimedia, multi-device, media synchronization, web, intra-destination media synchronization",MMSys '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schoolderman M,Smetsers S,van Eekelen M",Is Deductive Program Verification Mature Enough to Be Taught to Software Engineers?,,2019,,,50–57,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th Computer Science Education Research Conference,"Larnaca, Cyprus",2019,9781450377171,,https://doi.org/10.1145/3375258.3375265;http://dx.doi.org/10.1145/3375258.3375265,10.1145/3375258.3375265,"Software engineers working in industry seldom try to apply formal methods to solve problems. There are various reasons for this. Sometimes these reasons are understandable---the cost of using formal methods does not make economic sense in many contexts.However, formal methods are also often greeted with scepticism. Formal methods are assumed to take too much time, require tools that are too academic, or to be too mathematical to be understood by practice-oriented software engineers.We tested these assumptions by designing a small course around a framework for program verification, aimed at regular computer science students enrolled in a Master's programme. After four lectures and associated exercises, students were given a small verification task where they had to model and verify a real, non-trivial, C function in Why3.A significant majority of students managed to prove a non-trivial functional specification of this C function in the time allotted, and many also pointed out inherent flaws of this function discovered during formalization. Participants reported no major difficulties or mental hurdles in learning Why3, and considered its approach to be appropriate for selected components of safety-critical software.While formal verification tools such as Why3 still have lots of room for improvement, this experience shows that in a short amount of time, software engineers can be taught to use a program verification tool, and obtain usable results without being fully proficient in it. We further recommend that courses on formal methods should also let students explore these as techniques to be applied, instead of only focusing on the theory behind them, as we expect this to gradually lower the barrier to wider acceptance.","formal verification, Why3, teaching",CSERC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sunkle S,Kholkar D,Kulkarni V","Model-Driven Regulatory Compliance: A Case Study of \Know Your Customer\"" Regulations""",,2015,,,436–445,IEEE Press,"Ottawa, Ontario, Canada",,Proceedings of the 18th International Conference on Model Driven Engineering Languages and Systems,,2015,9781467369084,,,,"Modern enterprises face an unprecedented regulatory regime. Industry governance, risk, and compliance (GRC) solutions are document-oriented and expert-driven. Formal compliance checking techniques in contrast attempt to provide ways for rigorous modeling and analysis of regulatory compliance but miss out on holistic GRC perspective due to missing integration between diverse set of (semi-) formal models. We show that streamlining regulatory compliance using multiple purposive models of various aspects of regulations, it is possible to leverage both the rigor of formal techniques and the holistic enterprise GRC perspective. Our contributions are twofold. First, we present a model-driven architecture based on a conceptual model of integrated GRC that is capable of addressing key challenges of regulatory compliance. Second, using Know Your Customer regulations in Indian context as a case study, we demonstrate the utility of this architecture. Initial results with KYC regulations are promising and point to further work in model-driven regulatory compliance.",,MODELS '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Strothoff S,Valkov D,Hinrichs K",Triangle Cursor: Interactions with Objects above the Tabletop,,2011,,,111–119,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM International Conference on Interactive Tabletops and Surfaces,"Kobe, Japan",2011,9781450308717,,https://doi.org/10.1145/2076354.2076377;http://dx.doi.org/10.1145/2076354.2076377,10.1145/2076354.2076377,"Extending the tabletop display to the third dimension using a stereoscopic projection offers the possibility to improve applications by using the volume above the table surface. The combination of multi-touch input and stereoscopic projection usually requires an indirect technique to interact with objects above the tabletop, as touches can only be detected on the surface. Triangle Cursor is a 3D interaction technique that allows specification of a 3D position and yaw rotation above the interactive tabletop. It was designed to avoid occlusions that disturb the stereoscopic perception. While Triangle Cursor uses an indirect approach, the position, the height above the surface and the yaw rotation can be controlled simultaneously, resulting in a 4 DOF manipulation technique. We have evaluated Triangle Cursor in an initial user study and compared it to a related existing technique in a formal user study. Our experiments show that users were able to perform all tasks significantly faster with our technique without loosing any precision. Most of the subjects considered the technique easy to use and satisfying.","3D interaction, selection technique, multi-touch interaction, stereoscopic displays, tabletop displays",ITS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"O’dwyer N,Zerman E,Young GW,Smolic A,Dunne S,Shenton H",Volumetric Video in Augmented Reality Applications for Museological Narratives: A User Study for the Long Room in the Library of Trinity College Dublin,J. Comput. Cult. Herit.,2021,14,2,,Association for Computing Machinery,"New York, NY, USA",,,,2021-05,,1556-4673,https://doi.org/10.1145/3425400;http://dx.doi.org/10.1145/3425400,10.1145/3425400,"Cross-reality technologies are quickly establishing themselves as commonplace platforms for presenting objects of historical, scientific, artistic, and cultural interest to the public. In this space, augmented reality (AR) is notably successful in delivering cultural heritage applications, including architectural and environmental heritage reconstruction, exhibition data management and representation, storytelling, and exhibition curation. Generally, it has been observed that the nature of information delivery in applications created for narrating exhibitions tends to be informative and formal. Here we report on the assessment of a pilot scene for a prototype AR application that attempts to break this mold by employing a humorous and playful mode of communication. This bespoke AR experience harnessed the cutting-edge live-action capture technique of volumetric video to create a digital tour guide that playfully embellished the museological experience of the museum visitors. This applied research article consists of measuring, presenting, and discussing the appeal, interest, and ease of use of this ludic AR storytelling strategy mediated via AR technology in a cultural heritage context.","museology, cultural heritage, user study, playfulness, Mixed reality, ludic interfaces, augmented reality",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Soldano H,Santini G,Bouthinon D,Bary S,Lazega E",Bi-Pattern Mining of Two Mode and Directed Networks,,2018,,,1287–1294,International World Wide Web Conferences Steering Committee,"Republic and Canton of Geneva, CHE",,Companion Proceedings of the The Web Conference 2018,"Lyon, France",2018,9781450356404,,https://doi.org/10.1145/3184558.3191568;http://dx.doi.org/10.1145/3184558.3191568,10.1145/3184558.3191568,"In two-mode networks there are two kinds of vertices, i.e objects, each being possibly described with a proper attribute set. This means that to select a subnetwork according to vertex descriptions we have to consider a pair of vertex subsets. A common technique is to extract from a network an essential subnetwork, the core subgraph of the network. Formal Concept Analysis and closed pattern mining were previously applied to networks with the purpose of reducing extensions of patterns to be core subgraphs. To apply this methodology to two-mode networks, we need to consider the two vertex subsets of two-mode cores and define accordingly abstract closed bi-patterns. Each component of a bi-pattern is then associated to one mode. We also show that the same methodology applies to hub-authority cores of directed networks in which each vertex subset is associated to a role (in or out). We illustrate the methodology both on a two-mode network of epistemological data and on a directed advice network of lawyers.","closed pattern mining, attributed network, two-mode network, directed network, core subnetwork",WWW '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Schwitter R,Controlled Natural Languages for Knowledge Representation,,2010,,,1113–1121,Association for Computational Linguistics,USA,,Proceedings of the 23rd International Conference on Computational Linguistics: Posters,"Beijing, China",2010,,,,,"This paper presents a survey of research in controlled natural languages that can be used as high-level knowledge representation languages. Over the past 10 years or so, a number of machine-oriented controlled natural languages have emerged that can be used as high-level interface languages to various kinds of knowledge systems. These languages are relevant to the area of computational linguistics since they have two very interesting properties: firstly, they look informal like natural languages and are therefore easier to write and understand by humans than formal languages; secondly, they are precisely defined subsets of natural languages and can be translated automatically (and often deterministically) into a formal target language and then be used for automated reasoning. We present and compare the most mature of these novel languages, show how they can balance the disadvantages of natural languages and formal languages for knowledge representation, and discuss how domain specialists can be supported writing specifications in controlled natural language.",,COLING '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schott E,Kulik A,Froehlich B",Virtual Projection Planes for the Visual Comparison of Photogrammetric 3D Reconstructions with Photo Footage,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,26th ACM Symposium on Virtual Reality Software and Technology,"Virtual Event, Canada",2020,9781450376198,,https://doi.org/10.1145/3385956.3418956;http://dx.doi.org/10.1145/3385956.3418956,10.1145/3385956.3418956,"Image-based 3D reconstructions and their visualization in virtual reality promise novel opportunities to explore and analyze 3D reconstructions of real objects, buildings and places. However, the faithfulness of the presented data is not always obvious and, in most cases, a 3D reconstruction cannot be compared directly to its corresponding real world instance. However, in case of reconstruction methods based on structure from motion (SFM), a large number of raw photos is available. This motivated us to develop a novel interaction technique for the visual comparison of details of 3D models with projections of the corresponding image sections, e.g. in order to rapidly verify the authenticity of perceived features. The results of a formal user study (n=18) demonstrate the general usability of such visual provenance information as well as benefits of the comparison in vicinity of the features in question over a separate image gallery. Further observations informed our iterative design process and led to the development of an improved interactive visualization. Our final implementation provides a spatial and content-related overview while retaining the efficiency of the original approach.","magic lenses, spatially registered images, visual comparison, interaction design, image browsing, virtual reality",VRST '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Baudart G,Mandel L,Tardieu O,Vaziri M",A Reactive Language for Analyzing Cloud Logs,,2018,,,61–70,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th ACM SIGPLAN International Workshop on Reactive and Event-Based Languages and Systems,"Boston, MA, USA",2018,9781450360708,,https://doi.org/10.1145/3281278.3281280;http://dx.doi.org/10.1145/3281278.3281280,10.1145/3281278.3281280,"Log analysis is required in many domains, and especially in the emerging field of cloud computing. Cloud applications are often built by composing diverse services. When something goes wrong, finding the root cause of the problem can be difficult. Many services are only reachable through their Application Programming Interfaces (APIs) with no possibility for live introspection. In this context, logs become an essential tool for monitoring and debugging. Cloud services typically generate very large quantities of log messages, with formats that may not be well specified and may vary over time. In this paper, we present CloudLens, a language for the analysis of semi-structured textual data as found in logs, and specify its formal semantics. CloudLens is a reactive language and views logs as streams of objects. Our objective is to facilitate exploring the contents of logs interactively and to write reusable analyses succinctly, using familiar constructs. We implemented an interpreter for the Apache Zeppelin notebook to provide an interactive IDE. Our prototype implementation is open source and we report on a detailed case study using logs from the Apache OpenWhisk project.","Log analysis, Programming language, Reactive programming",REBLS 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Toffoli TO,Kozievitch NP,Gonçalves MA,Torres RS",A Formal Approach for the Specification of Digital Complex Objects,,2013,,,125–132,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 19th Brazilian Symposium on Multimedia and the Web,"Salvador, Brazil",2013,9781450325592,,https://doi.org/10.1145/2526188.2526199;http://dx.doi.org/10.1145/2526188.2526199,10.1145/2526188.2526199,"Complex objects (COs) have surged as a way to integrate different digital resources under a same logical unit in order to facilitate aggregation and reuse. However, there is still a lack of consensus on precise theoretical foundations for COs, especially regarding design and specification, which compromise their utility and integration with existing software tools. Moreover, there has been little investigation on aspects related to the modeling of COs by the end user, much due to the lack of appropriate tools for this goal. In this work, we present a new Digital Library (DL) metamodel specially designed for the CO modeling which is grounded in formal theoretical specification for COs. More specifically, our goal is two-fold: (i) to indirectly validate our CO formalization by instantiating it within a DL modeling tool -- 5SGraph; and (ii) to investigate the difficulties of CO modeling and specification by real users using the specified metamodel. Experiments with real users indicate that the use of the metamodel and the graphical tool facilitates the understanding of the COs structure and the modeling process.","content-based image retrieval, digital libraries, 5s framework, complex object",WebMedia '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zheng S,GrainPlane: Intuitive Tactile Interface for Granular Synthesis,,2016,,,34–38,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Audio Mostly 2016,"Norrköping, Sweden",2016,9781450348225,,https://doi.org/10.1145/2986416.2986419;http://dx.doi.org/10.1145/2986416.2986419,10.1145/2986416.2986419,"GrainPlane is a prototype design build of a highly intuitive tactile interface for granular synthesis. The granular synthesis software engine's parameters are modulated by the manipulation of small, physical objects. The sound of the grains as they interact with a resonant surface and with each other is analyzed, from which audio grain triggering, grain duration, amplitude, and sample position can be calculated. This provides a flexible platform upon which the musician can easily and intuitively modulate the granular synthesis in real time through a direct link between the tactile and auditory manipulation of the grains.","Granular synthesis, haptic feedback, multisensory",AM '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jarrar A,Gadi T,Balouki Y",Modeling the Internet of Things System Using Complex Adaptive System Concepts,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Computing and Wireless Communication Systems,"Larache, Morocco",2017,9781450353069,,https://doi.org/10.1145/3167486.3167508;http://dx.doi.org/10.1145/3167486.3167508,10.1145/3167486.3167508,"Internet-of-Things (IoT) envisions a future in which digital and physical entities can be linked, by means of appropriate information and communication technologies, to enable a whole new class of applications and services. The Rapid growth in the Internet of Things has resulted in a massive growth of data generated by these entities. However, the heterogeneity of the \Things\"" makes interoperability",mobility,addressing and routing among them a challenging problem.To overcome this problem,we proposed specifying the internet of things network. The specification errors can be origin of some failures that can be introduced during development process. The use of formal methods in the design process of IoT system is explicitly required.In this paper,we present a model of the IoT network that allows objects to interact,communicate,and can share experience to adapt and evolve. For this purpose,"we based our model on the architecture of Complex Adaptive systems. This model will present a well-structured start for any future work in this domain.1""","IoT, platform RODIN, refinement patterns, Event-B, Formal method",ICCWCS'17,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Belussi A,Migliorini S,Negri M,Pelagatti G",Validation of Spatial Integrity Constraints in City Models,,2015,,,70–79,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Fourth ACM SIGSPATIAL International Workshop on Mobile Geographic Information Systems,"Bellevue, Washington",2015,9781450339773,,https://doi.org/10.1145/2834126.2834137;http://dx.doi.org/10.1145/2834126.2834137,10.1145/2834126.2834137,"Several different models have been defined in literature for the definition of 3D city models, from CityGML [14] to Inspire [8]. Such models include a geometrical representation of features together with a semantical classification of them. The semantical characterization of objects encapsulates important meaning and relations which are defined only implicitly or through natural language, such as a window surface shall be contained in the building boundary. The problem of ensuring the coherence between geometric and semantic information is well known in literature. Many attempts exist which try to extent the OCL language in order to represent spatial constraints for an UML model. However, this approach requires a deep knowledge of the OCL language and the implementation of ad-hoc procedures for the validation of the defined constraints. The aim of this paper is the development of a set of templates for expressing spatial 3D constraints between features which does not require any particular knowledge of a formal language. Moreover, the constraints instantiated from these templates can be automatically translated into validation procedures.","spatial constraints, validation, conceptual modeling",MobiGIS '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nygard KE,Xu D,Pikalek J,Lundell M",Multi-Agent Designs for Ambient Systems,,2008,,,,"ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)","Brussels, BEL",,Proceedings of the 1st International Conference on Ambient Media and Systems,"Quebec, Canada",2008,9789639799165,,,,"Designing and developing software for an ambient intelligence (AmI) system involves difficult challenges related to the varied roles of many heterogeneous devices and communication channels, and intelligent user interfaces. Because ambient systems have unpredictable requirements and are context-aware, software designs must support dynamic and sustainable change. We argue that such designs should utilize formal methods and aspect-oriented techniques, to help in supporting model validation and verification. Features of an aspect-oriented, multi-agent, architectural description language are presented as a mechanism for reasoning about cross-cutting concerns.",architecture description languages,Ambi-Sys '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Felty AP,Momigliano A",Reasoning with Hypothetical Judgments and Open Terms in Hybrid,,2009,,,83–92,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th ACM SIGPLAN Conference on Principles and Practice of Declarative Programming,"Coimbra, Portugal",2009,9781605585680,,https://doi.org/10.1145/1599410.1599422;http://dx.doi.org/10.1145/1599410.1599422,10.1145/1599410.1599422,"Hybrid is a system developed to specify and reason about logics, programming languages, and other formal systems expressed in higher-order abstract syntax (HOAS). An important goal of Hybrid is to exploit the advantages of HOAS within the well-understood setting of higher-order logic as implemented by systems such as Isabelle and Coq. In this paper, we add new capabilities for reasoning by induction on encodings of object-level inference rules. Elegant and succinct specifications of such inference rules can often be given using hypothetical and parametric judgments, which are represented by embedded implication and universal quantification. Induction over such judgments is well-known to be problematic. In previous work, we showed how to express this kind of judgment using a two-level approach, but reasoning by induction on such judgments was restricted to closed terms. The new capabilities we add include techniques for adding arbitrary \new\"" variables to contexts and inductively reasoning about open terms. Very little overhead is required",namely a small library of definitions and lemmas,yet the reasoning power of the system and the class of properties that can be proved is significantly increased. We illustrate the approach using PCF,a simple programming language that serves as the core of a variety of functional languages. We encode the typing judgment,"and prove by induction on this judgment that well-typed PCF terms have unique types.""","logical frameworks, higher-order abstract syntax, name-binding, induction, interactive theorem proving",PPDP '09,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sarray I,Ressouche A,Gaffé D,Tigli JY,Lavirotte S",Safe Composition in Middleware for the Internet of Things,,2015,,,7–12,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd Workshop on Middleware for Context-Aware Applications in the IoT,"Vancouver, BC, Canada",2015,9781450337311,,https://doi.org/10.1145/2836127.2836131;http://dx.doi.org/10.1145/2836127.2836131,10.1145/2836127.2836131,"The Internet of Things (IoT) connects sensors, actuators and autonomous objects interacting with each other. These devices are represented by web services. Web services composition often involves conflicts between systems having access to shared devices. In our component-based middleware, our solution allows managing access to shared devices, by generating specific constraint components which guarantee the respect of some predefined composition and adaptation constraints. IoT environments are dynamic; our solution ensures adaptation to its changes by using new generated constraint components and inhibitors to deal with the appearance and disappearance of devices/applications. The main contribution in this work is the definition of a new language DCL (Description Constraint Language) that helps to generate our constraint components by describing generic constraints that must be verified on accesses to shared devices. The whole approach and its associated tools rely on the synchronous paradigm, since it has a well-established formal foundation allowing automatic proofs, and interface with most model-checkers. We can then prove and guarantee a safe composition at runtime for our IoT applications.","Middleware, Validation, Composition, Synchronous modeling",M4IoT 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Y,Xu D,Wang H,Ye K,Gao S",Agent-Oriented Ontology for Monitoring and Detecting Money Laundering Process,,2007,,,,"ICST (Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering)","Brussels, BEL",,Proceedings of the 2nd International Conference on Scalable Information Systems,"Suzhou, China",2007,9781595937575,,,,"Criminal elements in today's technology-driven society are using every means available at their disposal to launder the proceeds from their illegal activities. To effectively and efficiently prevent and detect such diverse and complex activity, an Anti-Money Laundering (AML) solution should establish comprehensive, solid and fundamental knowledge framework of the monitoring and detecting process. This paper proposed an agent-oriented ontology for monitoring and detecting money laundering process (MDMLP). It provides explicit formal presentation of fundamental components of certain knowledge and relationships among them. Agent-oriented methodology is applied to deal with the dynamic, complex, and distributed MDMLP.","anti-money laundering, money laundering, agent-oriented ontology, intelligent agent",InfoScale '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ma W,Xie H",Research on Prediction Algorithm of Vehicle Trajectory in Front Based on Driving Intention Classification,,2021,,,361–367,Association for Computing Machinery,"New York, NY, USA",,2021 4th International Conference on Data Science and Information Technology,"Shanghai, China",2021,9781450390248,,https://doi.org/10.1145/3478905.3478977;http://dx.doi.org/10.1145/3478905.3478977,10.1145/3478905.3478977,"Predicting the trajectory of surrounding vehicles has an essential impact on the vehicle's future decision-making and path planning and helps to improve the driving safety, fuel consumption, and traffic efficiency of the vehicle. However, due to the uncertainty of its driving intention, the interaction between the predicted object and the surrounding environment, its trajectory prediction faces enormous challenges. In this paper, based on the Fuzzy C-means algorithm, the automatic recognition of driving intention is realized through offline training by using the information about the rate of change of the heading angle. Combined with vehicle speed information, a trajectory prediction algorithm based on Long short-term memory is developed, and the results of prediction models trained for different driving intentions are merged to obtain the future trajectory of the vehicle. The artificial potential field method is used to calculate the target vehicle's longitudinal and lateral safety distance to summarize the potential field of the road boundary and the surrounding vehicles of the predicted object to achieve the effect of correcting the trajectory prediction result. The 1s rolling prediction is carried out by the iterative method. Among the horizontal distances, 94.52% of the prediction errors are less than 0.1m, and the maximum distance prediction error is 0.23m. In the longitudinal distance, 92.91% of the prediction errors are less than 0.5m, and the maximum distance prediction error is 0.87m.","Fuzzy C-means, Long short-term memory, Trajectory prediction, Driving intention recognition",DSIT 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Berz M,Makino K",Rigorous Global Search Using Taylor Models,,2009,,,11–20,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 Conference on Symbolic Numeric Computation,"Kyoto, Japan",2009,9781605586649,,https://doi.org/10.1145/1577190.1577198;http://dx.doi.org/10.1145/1577190.1577198,10.1145/1577190.1577198,"A Taylor model of a smooth function f over a sufficiently small domain D is a pair (P,I) where P is the Taylor polynomial of f at a point d in D, and I is an interval such that f differs from P by not more than I over D. As such, they represent a hybrid between numerical techniques for the interval and the coefficients of P and algebraic techniques for the manipulation of polynomials. A calculus including addition, multiplication and differentiation/integration is developed to compute Taylor models for code lists, resulting in a method to compute rigorous enclosures of arbitrary computer functions in terms of Taylor models. The methods combine the advantages of numeric methods, namely finite size of representation, speed, and no limitations on the objects on which operations can be carried out with those of symbolic methods, namely the ability to treat functions instead of points and making rigorous statements.We show how the methods can be used for the problem of rigorous global search based on a branch and bound approach, where Taylor models are used to prune the search space and resolve constraints to high order. Compared to other rigorous global optimizers based on intervals and linearizations, the methods allow the treatment of complicated functions with long code lists and with large amounts of dependency. Furthermore, the underlying polynomial form allows the use of other efficient bounding and pruning techniques, including the linear dominated bounder (LDB) and the quadratic fast bounder (QFB).","beale function, taylor model, henon attractor, interval arithmetic, henon map, dynamical system, taylor polynomial, error bound, rigorous global optimization",SNC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Merkouris A,Chorianopoulos K,Kameas A",Teaching Programming in Secondary Education Through Embodied Computing Platforms: Robotics and Wearables,ACM Trans. Comput. Educ.,2017,17,2,,Association for Computing Machinery,"New York, NY, USA",,,,2017-05,,,https://doi.org/10.1145/3025013;http://dx.doi.org/10.1145/3025013,10.1145/3025013,"Pedagogy has emphasized that physical representations and tangible interactive objects benefit learning especially for young students. There are many tangible hardware platforms for introducing computer programming to children, but there is limited comparative evaluation of them in the context of a formal classroom. In this work, we explore the benefits of learning to code for tangible computers, such as robots and wearable computers, in comparison to programming for the desktop computer. For this purpose, 36 students participated in a within-groups study that involved three types of target computer platform tangibility: (1) desktop, (2) wearable, and (3) robotic. We employed similar blocks-based visual programming environments, and we measured emotional engagement, attitudes, and computer programming performance. We found that students were more engaged by and had a higher intention of learning programming with the robotic rather than the desktop computer. Furthermore, tangible computing platforms, either robot or wearable, did not affect the students’ performance in learning basic computational concepts (e.g., sequence, repeat, and decision). Our findings suggest that computer programming should be introduced through multiple target platforms (e.g., robots, smartphones, wearables) to engage children.","Ubiquitous computing, learning, robot, wearable, children, experiment, embodiment",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Basu Roy S,Chakrabarti K",Location-Aware Type Ahead Search on Spatial Databases: Semantics and Efficiency,,2011,,,361–372,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM SIGMOD International Conference on Management of Data,"Athens, Greece",2011,9781450306614,,https://doi.org/10.1145/1989323.1989362;http://dx.doi.org/10.1145/1989323.1989362,10.1145/1989323.1989362,"Users often search spatial databases like yellow page data using keywords to find businesses near their current location. Typing the entire query is cumbersome and prone to errors, especially from mobile phones. We address this problem by introducing type-ahead search functionality on spatial databases. Like keyword search on spatial data, type-ahead search needs to be location-aware, i.e., with every letter being typed, it needs to return spatial objects whose names (or descriptions) are valid completions of the query string typed so far, and which rank highest in terms of proximity to the user's location and other static scores. Existing solutions for type-ahead search cannot be used directly as they are not location-aware. We show that a straight-forward combination of existing techniques for performing type-ahead search with those for performing proximity search perform poorly. We propose a formal model for query processing cost and develop novel techniques that optimize that cost. Our empirical evaluations on real and synthetic datasets demonstrate the effectiveness of our techniques. To the best of our knowledge, this is the first work on location-aware type-ahead search.",type ahead search,SIGMOD '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zheng Q,Improving the Teaching of Biostatistics in an Online Master Degree Program in Epidemiology,,2020,,,89–93,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Distance Education and Learning,"Beijing, China",2020,9781450377546,,https://doi.org/10.1145/3402569.3402582;http://dx.doi.org/10.1145/3402569.3402582,10.1145/3402569.3402582,"Master of public health (MPH) students generally lack calculus-based mathematical training before embarking on an MPH degree. As a result, some biostatistics instructors balk at the idea of teaching conceptual knowledge to MPH students, often content with imparting procedural skills. Teaching a concept-oriented biostatistics course for online MPH students would seem doubly challenging. The author cites concrete examples from a categorical data analysis course to show how a novel teaching approach can render the online environment fertile ground for teaching conceptual knowledge of biostatistics to MPH students. Central to the new approach is a large set of carefully designed computing exercises that concretize abstract statistical concepts. Students use a small data set to compute a puzzling quantity such as the deviance according to the quantity's theoretical definition and then compare their results with that generated by a reputable statistical package. Students derive intellectual satisfaction from these concept-oriented computing exercises, as suggested by end-of-semester course survey data.","Master of public health student, Poisson regression, biostatistics, log-likelihood function, active learning",ICDEL 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Echtler F,Klinker G,Butz A",Towards a Unified Gesture Description Language,,2010,,,177–182,University of Aizu Press,"Fukushima-ken, JPN",,Proceedings of the 13th International Conference on Humans and Computers,"Aizu-Wakamatsu, Japan",2010,,,,,"Proliferation of novel types of gesture-based user interfaces has led to considerable fragmentation, both in terms of program code and in terms of the gestures themselves. Consequently, it is difficult for developers to build on previous work, thereby consuming valuable development time. Moreover, the flexibility of the resulting user interface is limited, particularly in respect to users wishing to customize the interface. To address this problem, we present a generic and extensible formal language to describe gestures. This language is applicable to a wide variety of input devices, such as multi-touch surfaces, pen-based input, tangible objects and even free-hand gestures. It enables the development of a generic gesture recognition engine which can serve as a backend to a wide variety of user interfaces. Moreover, rapid customization of the interface becomes possible by simply swapping gesture definitions - an aspect which has considerable advantages when conducting UI research or porting an existing application to a new type of input device. Developers will be able to benefit from the reduced amount of code, while users will be able to benefit from the increased flexibility through customization afforded by this approach.","gestures, formal specification, classification, recognition",HC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Naus N,Steenvoorden T,Klinik M",A Symbolic Execution Semantics for TopHat,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st Symposium on Implementation and Application of Functional Languages,"Singapore, Singapore",2019,9781450375627,,https://doi.org/10.1145/3412932.3412933;http://dx.doi.org/10.1145/3412932.3412933,10.1145/3412932.3412933,"Task-Oriented Programming (TOP) is a programming paradigm that allows declarative specification of workflows. TOP is typically used in domains where functional correctness is essential, and where failure can have financial or strategical consequences. In this paper we aim to make formal verification of software written in TOP easier. Currently, only testing is used to verify that programs behave as intended. We use symbolic execution to guarantee that no aberrant behaviour can occur. In previous work we presented TopHat, a formal language that implements the core aspects of TOP. In this paper we develop a symbolic execution semantics for TopHat. Symbolic execution allows to prove that a given property holds for all possible execution paths of TopHat programs.We show that the symbolic execution semantics is consistent with the original TopHat semantics, by proving soundness and completeness. We present an implementation of the symbolic execution semantics in Haskell. By running example programs, we validate our approach. This work represents a step forward in the formal verification of TOP software.",,IFL '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chikhaoui A,Lemarchand L,Boukhalfa K,Boukhobza J","<i>StorNIR</i>, a Multi-Objective Replica Placement Strategy for Cloud Federations",,2021,,,50–59,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 36th Annual ACM Symposium on Applied Computing,"Virtual Event, Republic of Korea",2021,9781450381048,,https://doi.org/10.1145/3412841.3441886;http://dx.doi.org/10.1145/3412841.3441886,10.1145/3412841.3441886,"Federation of clouds makes it possible to transparently extend the resources of Cloud Service Providers (CSPs). For storage services several metrics need to be considered to satisfy customers QoS, that is storage performance, network latency and data availability. Data replication is a key strategy to optimize such metrics. For a CSP, member of a Federation, an effective placement of customers data object replicas is crucial to satisfy QoS demands. In this paper, we modeled the replica placement problem as a multi-objective optimization problem (MOOP) taking into account the local storage classes, other federation CSPs (external) storage services, and customers requirements. To solve this problem, we propose StorNIR a cost-efficient data object Storing scheme based on NSGAII upgraded with Injection and Reparation operators. StorNIR is a matheuristic that consists in hybridizing an exact method with NSGAII meta-heuristic. A repair operator was designed to make the solutions feasible with regards to the system constraints (storage volume, IOPs, etc). StorNIR performed better than both NSGAII meta-heuristic and the exact method in terms of quality of solutions and scalability. The repair function improves the NSGAII meta-heuristic up to 7 times with 7.4% more extra time execution. On average, StorNIR enhances by 17 times the quality of the initial solutions calculated by CPLEX in terms of Hypervolume. In addition, the designed matheuristic approach can be generalized to other meta-heuristics than NSGAII such as MOPSO meta-heuristic.",,SAC '21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ferrari M,Fiorentini C,Fiorino G",An Evaluation-Driven Decision Procedure for G3i,ACM Trans. Comput. Logic,2015,16,1,,Association for Computing Machinery,"New York, NY, USA",,,,2015-03,,1529-3785,https://doi.org/10.1145/2660770;http://dx.doi.org/10.1145/2660770,10.1145/2660770,"It is well known that G3i, the sequent calculus for intuitionistic propositional logic where weakening and contraction are absorbed into the rules, is not terminating. Indeed, due to the contraction in the rule for left implication, the naïve goal-oriented proof-search strategy, consisting in applying the rules of the calculus bottom up until possible, can generate branches of infinite length. The usual solution to this problem is to support the proof-search procedure with a loop checking mechanism that prevents the generation of infinite branches by storing and analyzing some information regarding the branch under development.In this article, we propose a new technique based on evaluation functions. An evaluation function is a lightweight computational mechanism that, analyzing only the current goal of the proof search, allows one to drive the application of rules to guarantee termination and to avoid useless backtracking. We describe an evaluation-driven proof-search procedure that given a sequent σ returns either a G3i-derivation of σ or a countermodel for σ. We prove that such a procedure is terminating and correct, and that the depth of the G3i-trees generated during proof search is quadratic in the size of σ. Finally, we discuss the overhead time introduced by evaluation functions in the proof-search procedure.","Proof-search procedures, intuitionistic propositional logic, sequent calculi",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hildebrandt T,Mukkamala RR,Slaats T,Zanitti F",Modular Context-Sensitive and Aspect-Oriented Processes with Dynamic Condition Response Graphs,,2013,,,19–24,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th Workshop on Foundations of Aspect-Oriented Languages,"Fukuoka, Japan",2013,9781450318655,,https://doi.org/10.1145/2451598.2451604;http://dx.doi.org/10.1145/2451598.2451604,10.1145/2451598.2451604,"We propose the recently introduced declarative and event-based Dynamic Condition Response (DCR) Graphs process model as a formal basis for modular implementation of context-sensitive and aspect-oriented processes. The proposal is supported by a new join operator allowing modular composition and refinement of DCR Graphs. We give small illustrative examples of DCR Graphs defining context-sensitive processes where context-events dynamically enable and disable the need for authentication and the join operator is used to add authentication to a process. Finally, we discuss the use of formal verification to ensure that processes satisfy safety and liveness properties, and define two liveness properties (deadlock freedom and liveness) that can be verified directly on the state graph for DCR Graphs.","DCR graphs, context-sensitivity, aspects",FOAL '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ma W,Kim HK,Wang Y,Gao W,Oh WG",Binocular Stereopsis of Traditional Chinese Paintings,,2011,,,411–414,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Conference on Virtual Reality Continuum and Its Applications in Industry,"Hong Kong, China",2011,9781450310604,,https://doi.org/10.1145/2087756.2087831;http://dx.doi.org/10.1145/2087756.2087831,10.1145/2087756.2087831,"This paper presents an interactive technique for generating stereoscopic images from traditional Chinese paintings. The technique exploits a traditional way of moving focus based spatial composition used by classical Chinese painters. According to the moving focus rules of depicting objects of a painting, each non-ground pixel has the same depth with its corresponding pixel on the ground. Therefore, the depth map computation of the painting is decomposed into two steps. Firstly, the depth map of the ground is computed based on the moving focus rules of expressing spatial depth variation, with line-shape cues given through a user interface. Secondly, in order to calculate the depth of pixels belonging to the non-ground objects, the user interface provides a tool to sketch the objects and their occupying regions in the ground part. After that, each pixel of the non-ground objects is automatically matched to a pixel in the occupying ground regions by linear interpolation and takes the depth of the ground pixel as its depth. Finally, an anaglyph is computed by the obtained depth map. Experimental results demonstrate that the method presented in this paper can generate convincing binocular stereo images with easy user interaction.","e-heritage, traditional Chinese paintings, exhibition of paintings, stereopsis",VRCAI '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Xiao Q,Chen S,Chen M,Zhou Y,Cai Z,Luo J,Xiao Q,Chen S,Chen M,Zhou Y,Cai Z,Luo J",Adaptive Joint Estimation Protocol for Arbitrary Pair of Tag Sets in a Distributed RFID System,IEEE/ACM Trans. Netw.,2017,25,5,2670–2685,IEEE Press,,,,,2017-10,,1063-6692,https://doi.org/10.1109/TNET.2017.2709979;http://dx.doi.org/10.1109/TNET.2017.2709979,10.1109/TNET.2017.2709979,"Radio frequency identification RFID technology has been widely used in Applications, such as inventory control, object tracking, and supply chain management. In this domain, an important research problem is called RFID cardinality estimation, which focuses on estimating the number of tags in a certain area covered by one or multiple readers. This paper extends the research in both temporal and spatial dimensions to provide much richer information about the dynamics of distributed RFID systems. Specifically, we focus on estimating the cardinalities of the intersection/differences/union of two arbitrary tag sets called joint properties for short that exist in different spatial or temporal domains. With many practical applications, there is, however, little prior work on this problem. We will propose a joint RFID estimation protocol that supports adaptive snapshot construction. Given the snapshots of any two tag sets, although their lengths may be very different depending on the sizes of tag sets they encode, we design a way to combine their information and more importantly, derive closed-form formulas to use the combined information and estimate the joint properties of the two tag sets, with an accuracy that can be arbitrarily set. By formal analysis, we also determine the optimal system parameters that minimize the execution time of taking snapshots, under the constraints of a given accuracy requirement. We have performed extensive simulations, and the results show that our protocol can reduce the execution time by multiple folds, as compared with the best alternative approach in literature.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Muntasa A,Yusuf M",Three Channels for Gray Level Co-Occurrence Matrix (GLCM) to Detect Acute Lymphoblastic Leukemia (ALL) Images,,2020,,,26–33,Association for Computing Machinery,"New York, NY, USA",,2020 the 3rd International Conference on Control and Computer Vision,"Macau, China",2020,9781450388023,,https://doi.org/10.1145/3425577.3425583;http://dx.doi.org/10.1145/3425577.3425583,10.1145/3425577.3425583,"Leukemia is one of the dangerous diseases causing the death of people. Based on our literature review, numerous methods have been utilized for leukemia detection with various performances. Therefore, this research aims to employ the three channels for GLCM to detect ALL based on the Lymphoblastic Leukemia Image Database (ALL-IDB2) dataset. This research has some novelties. Firstly, the proposed method related to segmentation has separated the main object and background and removed the noises. Secondly, Feature extraction of the proposed method has depicted the object in three-dimensional form, so that the object can be visualized in more details than one-dimensional. Therefore, this research contributes by proposing a novel method of GLCM to detect ALL. We have employed 260 images of ALL-IDB2 and conducted twenty experiments for each scenario. Our proposed method has proven that three channels of GLCM and testing sets using Manhattan and Euclidean Distance achieved 91.54% of maximum accuracy. It has better accuracy than a combination of the GLCMshape-based feature-SVM classifier method. Furthermore, we have demonstrated that the quantity of training sets has given an impact on accuracy performance. Our experiments show higher numbers of the training sets obtained higher accuracy. Besides accuracy, we also calculated the false-negative and false-positive. The average of the false-negative results contributes to stability. It means that the difference of the results among scenarios is insignificant and almost similar. Meanwhile, false-negative tends to decrease in percentage. This is inversely proportional to the increase in the amount of the training set used. Additionally, the use of large amounts of training sets can reduce misclassification for the false-negative rate.Additionally, we have measured the classification results using the Euclidean method, as shown in Figures 9, 10, and 11. In Figure 11, we have found several accuracies from the different number of training sets. Similar to the Manhattan method results have been obtained from 240 experimental of twelve scenarios. The accuracy results have a trend to move up in proportion to the number of training sets. It demonstrated that the number of training sets employed had influenced the accuracy results. Our proposed method obtained the maximum accuracy equal to the maximum accuracy of the Manhattan method, which is 91.54%, as demonstrated in Figure 9. Moreover, we have obtained 86.2% as the maximum of the average accuracy. The result shows that the maximum of the accuracy has produced higher than the Manhattan method.Meanwhile, false-negative tends to decrease in percentage. This is inversely proportional to the increase in the amount of the training set used. Based the Figure 11, we can conclude that the use of large amounts of training sets can reduce misclassification for false-negative rate.","Three channels, Gray Level Co-Occurance Matrix (GLCM), Acute Lymphoblastic Leukemia (ALL)",ICCCV'20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cahalane C,McCarthy T,McElhinney CP",MIMIC: Mobile Mapping Point Density Calculator,,2012,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Computing for Geospatial Research and Applications,"Washington, D.C., USA",2012,9781450311137,,https://doi.org/10.1145/2345316.2345335;http://dx.doi.org/10.1145/2345316.2345335,10.1145/2345316.2345335,"The current generation of Mobile Mapping Systems (MMSs) capture increasingly larger amounts of data in a short time frame. Due to the relative novelty of this technology there is no concrete understanding of the point density that different hardware configurations and operating parameters will exhibit on objects at specific distances. Depending on the project requirements, obtaining the required point density impacts on survey time, processing time, data storage and is the underlying limit of automated algorithms. A limited understanding of the capabilities of these systems means that defining point density in project specifications is a complicated process. We are in the process of developing a method for determining the quantitative resolution of point clouds collected by a MMS with respect to known objects at specified distances. We have previously demonstrated the capabilities of our system for calculating point spacing, profile angle and profile spacing individually. Each of these elements are a major factor in calculating point density on arbitrary objects, such as road signs, poles or buildings -all important features in asset management surveys. This paper will introduce the current version of the MobIle Mapping point densIty Calculator (MIMIC), MIMIC's visualisation module and finally discuss the methods employed to validate our work.","mobile mapping, LiDAR, point density",COM.Geo '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"MacLachlan L,Jowers I",Formalising Flexible Multi-Material Surfaces as Weighted Shapes,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,SIGGRAPH Asia 2014 Creative Shape Modeling and Design,"Shenzhen, China",2014,9781450331821,,https://doi.org/10.1145/2669043.2669046;http://dx.doi.org/10.1145/2669043.2669046,10.1145/2669043.2669046,"The introduction of multi-material additive manufacturing makes it possible to fabricate objects with varying material properties, leading to new types of designs that exhibit interesting and complicated behaviours. But, computational design methods typically focus on the structure and geometry of designed objects, and do not incorporate material properties or behaviour. This paper explores how material properties can be included in computational design, by formally modelling them as weights in shape computations. Shape computations, such as shape grammars, formalise the description and manipulations of pictorial representation in creative design processes. The paper explores different ways that material properties can be formally modelled as weights, and presents examples in which multi-material surfaces are modelled as weighted planes, giving rise to flexible behaviours.","additive manufacturing, shape computation, design",SA '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brandauer S,Clarke D,Wrigstad T",Disjointness Domains for Fine-Grained Aliasing,,2015,,,898–916,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2015 ACM SIGPLAN International Conference on Object-Oriented Programming, Systems, Languages, and Applications","Pittsburgh, PA, USA",2015,9781450336895,,https://doi.org/10.1145/2814270.2814280;http://dx.doi.org/10.1145/2814270.2814280,10.1145/2814270.2814280,"Aliasing is crucial for supporting useful implementation patterns, but it makes reasoning about programs difficult. To deal with this problem, numerous type-based aliasing control mechanisms have been proposed, expressing properties such as uniqueness. Uniqueness, however, is black-and-white: either a reference is unique or it can be arbitrarily aliased; and global: excluding aliases throughout the entire system, making code brittle to changing requirements. Disjointness domains, a new approach to alias control, address this problem by enabling more graduations between uniqueness and arbitrary reference sharing. They allow expressing aliasing constraints local to a certain set of variables (either stack variables or fields) for instance that no aliasing occurs between variables within some set of variables but between such sets or the opposite, that aliasing occurs within that set but not between different sets. A hierarchy of disjointness domains controls the flow of references through a program, helping the programmer reason about disjointness and enforce local alias invariants. The resulting system supports fine-grained control of aliasing between both variables and objects, making aliasing explicit to programmers, compilers, and tooling. This paper presents a formal account of disjointness domains along with examples. Disjointness domains provide novel means of expressing may-alias kinds of constraints, which may prove useful in compiler optimisation and verification.","uniqueness, linear types, type systems, Aliasing, mutable state",OOPSLA 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Brandauer S,Clarke D,Wrigstad T",Disjointness Domains for Fine-Grained Aliasing,SIGPLAN Not.,2015,50,10,898–916,Association for Computing Machinery,"New York, NY, USA",,,,2015-10,,0362-1340,https://doi.org/10.1145/2858965.2814280;http://dx.doi.org/10.1145/2858965.2814280,10.1145/2858965.2814280,"Aliasing is crucial for supporting useful implementation patterns, but it makes reasoning about programs difficult. To deal with this problem, numerous type-based aliasing control mechanisms have been proposed, expressing properties such as uniqueness. Uniqueness, however, is black-and-white: either a reference is unique or it can be arbitrarily aliased; and global: excluding aliases throughout the entire system, making code brittle to changing requirements. Disjointness domains, a new approach to alias control, address this problem by enabling more graduations between uniqueness and arbitrary reference sharing. They allow expressing aliasing constraints local to a certain set of variables (either stack variables or fields) for instance that no aliasing occurs between variables within some set of variables but between such sets or the opposite, that aliasing occurs within that set but not between different sets. A hierarchy of disjointness domains controls the flow of references through a program, helping the programmer reason about disjointness and enforce local alias invariants. The resulting system supports fine-grained control of aliasing between both variables and objects, making aliasing explicit to programmers, compilers, and tooling. This paper presents a formal account of disjointness domains along with examples. Disjointness domains provide novel means of expressing may-alias kinds of constraints, which may prove useful in compiler optimisation and verification.","linear types, uniqueness, type systems, Aliasing, mutable state",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Al-Shaer E,Duan Q,Al-Haj S,Youssef M",SensorChecker: Reachability Verification in Mission-Oriented Sensor Networks,,2013,,,51–56,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd ACM Annual International Workshop on Mission-Oriented Wireless Sensor Networking,"Miami, Florida, USA",2013,9781450323673,,https://doi.org/10.1145/2509338.2509344;http://dx.doi.org/10.1145/2509338.2509344,10.1145/2509338.2509344,"This paper presents novel techniques to verify the global reachability in mission-oriented wireless sensor networks (Mission-Oriented WSN). The global reachability verification considers configurations such as forwarding information and awake/dormant schedule as generated by WSN protocols and algorithms. Our contribution is two-fold. First, we create a scalable model that represents the end-to-end reachability of WSN based on node configuration using Binary Decision Diagrams (BDDs) and Symbolic Model Checking, and then define generic reachability properties using Computational Tree Logic (CTL). Second, we encode the Mission-Oriented WSN topological information using Boolean functions to verify constraint-based reachability properties for WSN, and show soundness and completeness.We implement this in a tool called SensorChecker. The scalability and performance of SensorChecker is validated with very large WSN networks (10s of thousand of nodes) and wake-up scheduling parameters. To the best of our knowledge, this is the first formal approach for verifying large-scale WSN network configuration.","reachability, formal methods, sensor network",MiSeNet '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oliveira EW,Siqueira SW,Braz MH",Using OWL to Represent Metadata of Multimedia Learning Objects,,2008,,,226–233,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th Brazilian Symposium on Multimedia and the Web,"Vila Velha, Brazil",2008,9781605581705,,https://doi.org/10.1145/1666091.1666129;http://dx.doi.org/10.1145/1666091.1666129,10.1145/1666091.1666129,"The continuous development of the information and communication technologies makes possible the use of new strategies to support learning processes. In addition, there is an increasingly large number of worldwide available content, which could be used as learning materials. However, in spite of offering an inexhaustible source for search processes, this large number of content makes difficult to find a specific material, appropriated to a particular need. So, the work presented in this paper aims at providing a formal and more comprehensive description of the content embedded in Multimedia Learning Objects (MLOs) through complementary groups of metadata with focus in educational and multimedia properties. Thus, parts of the LOM and MPEG-7 metadata standards, both of them represented in OWL, were used in an architecture of multimedia LO description. This paper argues that through these standards it is possible to describe MLOs in a more appropriate way, increasing the retrieval effectiveness of users' searches and improving the reuse potential of these materials. Moreover, through OWL it is possible to build conceptual links between different multimedia resources as well as perform inference tasks and automatically discovering relationships between them. A prototype and a case study present the functionality of the proposed architecture.","metadata, methodology, multimedia learning objects description; authoring tools, standards",WebMedia '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Belussi A,Migliorini S,Negri M,Pelagatti G",Robustness of Spatial Relation Evaluation in Data Exchange,,2012,,,446–449,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th International Conference on Advances in Geographic Information Systems,"Redondo Beach, California",2012,9781450316910,,https://doi.org/10.1145/2424321.2424386;http://dx.doi.org/10.1145/2424321.2424386,10.1145/2424321.2424386,"Topological relationships between geometric objects are important in several spatial applications, like spatial query evaluation, spatial integrity constraints checking, and spatial reasoning. Although the conceptual aspects of topological relationships between geometric objects embedded in the Euclidean space have been extensively studied, the problems arising when topological relationships are evaluated on real data have been much less explored. In particular, robustness problems arise in the evaluation of topological relationships between geometric objects implemented as vectors in a discrete space. A lack of robustness is characterized by the fact that different systems can produce different evaluations of topological relationships on the same data, and it is caused by the fact that coordinates are represented as finite numbers. The goal of this paper is to formally analyze some rules for increasing the robustness of a topological relationship evaluation and to give some examples w.r.t. a specific topological relationship.","spatial data, topological relations, robustness of computation",SIGSPATIAL '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Memarian K,Matthiesen J,Lingard J,Nienhuis K,Chisnall D,Watson RN,Sewell P",Into the Depths of C: Elaborating the de Facto Standards,,2016,,,1–15,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 37th ACM SIGPLAN Conference on Programming Language Design and Implementation,"Santa Barbara, CA, USA",2016,9781450342612,,https://doi.org/10.1145/2908080.2908081;http://dx.doi.org/10.1145/2908080.2908081,10.1145/2908080.2908081,"C remains central to our computing infrastructure. It is notionally defined by ISO standards, but in reality the properties of C assumed by systems code and those implemented by compilers have diverged, both from the ISO standards and from each other, and none of these are clearly understood. We make two contributions to help improve this error-prone situation. First, we describe an in-depth analysis of the design space for the semantics of pointers and memory in C as it is used in practice. We articulate many specific questions, build a suite of semantic test cases, gather experimental data from multiple implementations, and survey what C experts believe about the de facto standards. We identify questions where there is a consensus (either following ISO or differing) and where there are conflicts. We apply all this to an experimental C implemented above capability hardware. Second, we describe a formal model, Cerberus, for large parts of C. Cerberus is parameterised on its memory model; it is linkable either with a candidate de facto memory object model, under construction, or with an operational C11 concurrency model; it is defined by elaboration to a much simpler Core language for accessibility, and it is executable as a test oracle on small examples. This should provide a solid basis for discussion of what mainstream C is now: what programmers and analysis tools can assume and what compilers aim to implement. Ultimately we hope it will be a step towards clear, consistent, and accepted semantics for the various use-cases of C.",C,PLDI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Memarian K,Matthiesen J,Lingard J,Nienhuis K,Chisnall D,Watson RN,Sewell P",Into the Depths of C: Elaborating the de Facto Standards,SIGPLAN Not.,2016,51,6,1–15,Association for Computing Machinery,"New York, NY, USA",,,,2016-06,,0362-1340,https://doi.org/10.1145/2980983.2908081;http://dx.doi.org/10.1145/2980983.2908081,10.1145/2980983.2908081,"C remains central to our computing infrastructure. It is notionally defined by ISO standards, but in reality the properties of C assumed by systems code and those implemented by compilers have diverged, both from the ISO standards and from each other, and none of these are clearly understood. We make two contributions to help improve this error-prone situation. First, we describe an in-depth analysis of the design space for the semantics of pointers and memory in C as it is used in practice. We articulate many specific questions, build a suite of semantic test cases, gather experimental data from multiple implementations, and survey what C experts believe about the de facto standards. We identify questions where there is a consensus (either following ISO or differing) and where there are conflicts. We apply all this to an experimental C implemented above capability hardware. Second, we describe a formal model, Cerberus, for large parts of C. Cerberus is parameterised on its memory model; it is linkable either with a candidate de facto memory object model, under construction, or with an operational C11 concurrency model; it is defined by elaboration to a much simpler Core language for accessibility, and it is executable as a test oracle on small examples. This should provide a solid basis for discussion of what mainstream C is now: what programmers and analysis tools can assume and what compilers aim to implement. Ultimately we hope it will be a step towards clear, consistent, and accepted semantics for the various use-cases of C.",C,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wu J,Huang L,Wang D",ASM-Based Model of Dynamic Service Update in OSGi,SIGSOFT Softw. Eng. Notes,2008,33,2,,Association for Computing Machinery,"New York, NY, USA",,,,2008-03,,0163-5948,https://doi.org/10.1145/1350802.1350815;http://dx.doi.org/10.1145/1350802.1350815,10.1145/1350802.1350815,"An ASM-based high level semantical model for service-oriented systems based on OSGi and supporting service dynamic updating is provided in this paper. The model not only provides the refinement methods but also gives the final model that specifies the constraint of OSGi. The resulting formal model can be applied in several ways. First, it enables checking or comparing existing systems based on OSGi to determine if they satisfy the dynamic updating demands and provide the necessary functionalities. Furthermore, it can serve as a basis for high level specification of a new system or components or updating constraint. Finally, the model is also useful in reasoning about the properties of service-oriented dynamic updating system based on OSGi.","ASM, dynamic updating, OSGi, verification, component",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wolski A,Borgert S,Heuser L",A CoreASM Based Reference Implementation for Subject-Oriented Business Process Management Execution Semantics,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Subject-Oriented Business Process Management,"Seville, Spain",2019,9781450362504,,https://doi.org/10.1145/3329007.3329018;http://dx.doi.org/10.1145/3329007.3329018,10.1145/3329007.3329018,"The Subject-oriented Business Process Management (S-BPM) paradigm provides concepts and methods to support the development of in- and inter-organizational parallel and distributed processes. S-BPM Process Models are directly executable and formal execution semantics enable different software development teams to develop S-BPM engines with equivalent execution behavior. We did a state of the art analysis of existing formal S-BPM execution semantics and analyzed the required language elements of an advanced smart energy grid Process Model. We extended an existing Abstract State Machines (ASM) specification to close the identified specification gaps. To foster the understanding of the specification details, we developed a specification conform reference implementation by using the executable CoreASM language and execution tool, developed a console application as CoreASM user interface, designed test models and used them to evaluate the contribution.","reference implementation, abstract state machines, CoreASM, subject-oriented business process management",S-BPM ONE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gjondrekaj E,Loreti M,Pugliese R,Tiezzi F",Modeling Adaptation with Klaim,SIGAPP Appl. Comput. Rev.,2012,12,4,21–35,Association for Computing Machinery,"New York, NY, USA",,,,2012-12,,1559-6915,https://doi.org/10.1145/2432546.2432548;http://dx.doi.org/10.1145/2432546.2432548,10.1145/2432546.2432548,"In recent years, it has been argued that systems and applications, in order to deal with their increasing complexity, should be able to adapt their behavior according to new requirements or environment conditions. In this paper, we present an investigation aiming at studying how coordination languages and formal methods can contribute to a better understanding, implementation and use of the mechanisms and techniques for adaptation currently proposed in the literature. Our study relies on the formal coordination language Klaim as a common framework for modeling some well-known adaptation techniques: the IBM MAPE-K loop, the Accord component-based framework for architectural adaptation, and the aspect- and context-oriented programming paradigms. We illustrate our approach through a simple example concerning a data repository equipped with an automated cache mechanism.","autonomic computing, coordination languages, adaptive systems, aspect- and context-oriented programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Keller C,Bluteau J,Blanch R,Coquillart S",PseudoWeight: Making Tabletop Interaction with Virtual Objects More Tangible,,2012,,,201–204,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2012 ACM International Conference on Interactive Tabletops and Surfaces,"Cambridge, Massachusetts, USA",2012,9781450312097,,https://doi.org/10.1145/2396636.2451335;http://dx.doi.org/10.1145/2396636.2451335,10.1145/2396636.2451335,"In this paper we show that virtual objects manipulated on a tabletop interaction device can be augmented to provide the illusion they have a weight. This weight offers a supplemental channel to provide information about graphical objects without cluttering the visual display. To create such a pseudo-weight illusion on a passive device, the pressure applied with the fingers during the interaction has to be captured. We show that this pressure can be estimated without hardware modification on some touch sensitive tabletop setups (e.g., MERL's DiamondTouch). Two controlled experiments show that pseudo-weight is perceived effectively. The first one demonstrates that users, without training and without previous knowledge of the system, can accurately rank virtual objects according to their pseudo-weights, provided they are sufficiently distinct. The second controlled experiment investigates more formally the relation between the pseudo-weight and the actual perception of the users.","pseudo-weight, Tabletop interaction",ITS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cheun DW,Lee JY,Kim SD",A Comprehensive Architecture for Autonomic Service Management,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th International Conference on Uniquitous Information Management and Communication,"Suwon, Republic of Korea",2010,9781605588933,,https://doi.org/10.1145/2108616.2108703;http://dx.doi.org/10.1145/2108616.2108703,10.1145/2108616.2108703,"Service-Oriented Computing reveals features which are not commonly found in conventional computing paradigms; loose coupling, dynamism, black box, evolvability, and heterogeneity. These features make diagnosing and healing faults found in deployed services and service-related elements more challenging than managing conventional systems. Hence, service-oriented systems management often results in problems of increased cost/effort, decreased effectiveness, and irresolvable service faults. Applying key disciplines of autonomic computing to services management would effectively resolve these problems and automate the task. This paper presents a comprehensive framework, for managing service faults in autonomous manner, called Symptom-Cause-Actuator Framework (SCAF). We first present a 5-phase process for autonomic service management. Then, we define functionality of SCAF and present the system architecture of the framework. Then, we propose formal reasoning system to diagnose services faults and actuate causes for the framework. The framework is not limited to providing a theoretical basis for service management, but it can be practically applied with current service-oriented architecture standards.","service management, service-oriented architecture, autonomic computing",ICUIMC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ziat G,Mullier O,Sandretto JA,Garion C,Chapoutot A,Thirioux X",Abstract Domains for Constraint Programming with Differential Equations,,2020,,,2–11,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM SIGPLAN International Workshop on Numerical and Symbolic Abstract Domains,"Virtual, USA",2020,9781450381871,,https://doi.org/10.1145/3427762.3429453;http://dx.doi.org/10.1145/3427762.3429453,10.1145/3427762.3429453,"Cyber-physical systems (CPSs), as cruise control systems, involve life-critical or mission critical functions that must be validated. Formal verification techniques can bring high assurance level but have to be extended to embrace all the components of CPSs. Physical part models of CPSs are usually defined from ordinary differential equations (ODEs) and reachability methods can be used to compute safe over-approximation of the solution set of ODEs. However, additional constraints, as obstacle avoidance have also to be considered to validate CPSs. To meet this need, we propose in this paper a framework, based on abstract domains, for solving constraint satisfaction problems where the objects manipulated are described by ODEs. We use a form of disjunctive completion for which we provide a split operator and an efficient constraint filtering mechanism that takes advantage of the continuity aspect of ODEs. We illustrate the benefits of our method on a real-world application of trajectory validation of a swarm of drones, for which the main property we aim to prove is the absence of collisions between drone trajectories. Our work has been concretized in the form of a cooperation between the DynIbex library, used for the abstraction of ODEs, and the AbSolute constraint solver, used for the constraint resolution. Experiments show promising results.","Ordinary Differential Equations, Constraint Programming, Cyber-physical systems, Abstract Interpretation, Abstract Domains",NSAD 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tounsi I,Kacem MH,Kacem AH,Drira K,Mezghani E",Towards an Approach for Modeling and Formalizing SOA Design Patterns with Event-B,,2013,,,1937–1938,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Annual ACM Symposium on Applied Computing,"Coimbra, Portugal",2013,9781450316569,,https://doi.org/10.1145/2480362.2480721;http://dx.doi.org/10.1145/2480362.2480721,10.1145/2480362.2480721,"This paper introduces a formal architecture-centric approach, which allows first to model message-oriented SOA design patterns with the SoaML standard language, and second to formally specify these patterns at a high level of abstraction using the Event-B method. These two steps are performed before undertaking the effective coding of a design pattern providing correct by construction pattern-based software architectures. We implement our approach under the Rodin platform which we use to prove model consistency.","SoaML modeling, SOA design patterns, event-B method",SAC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Li Y,Fang Y,Cheng R,Zhang W",Spatial Pattern Matching: A New Direction for Finding Spatial Objects,SIGSPATIAL Special,2019,11,1,3–12,Association for Computing Machinery,"New York, NY, USA",,,,2019-08,,,https://doi.org/10.1145/3355491.3355493;http://dx.doi.org/10.1145/3355491.3355493,10.1145/3355491.3355493,"In this paper, we study the spatial pattern matching (SPM) query. Given a set D of spatial objects (e.g., houses and shops), each with a textual description, we aim at finding all combinations of objects from D that match a user-defined spatial pattern P. A pattern P is a graph whose vertices represent spatial objects, and edges denote distance relationships between them. The SPM query returns the instances that satisfy P. An example of P can be \a house within 10-minute walk from a school","which is at least 2km away from a hospital\"". The SPM query can benefit users such as house buyers",urban planners,and archaeologists. We first formally formulate the SPM problem,and then propose efficient query algorithms. We also develop an online system,called SpaceKey,which is based on the SPM query,to support some real applications such as property searching. Finally,"we point out a list of possible research directions for future work.""",,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ibrahim MH,Missaoui R,Messaoudi A",Detecting Communities in Social Networks Using Concept Interestingness,,2018,,,81–90,IBM Corp.,USA,,Proceedings of the 28th Annual International Conference on Computer Science and Software Engineering,"Markham, Ontario, Canada",2018,,,,,"One key challenge in Social Network Analysis is to design an efficient and accurate community detection procedure as a means to discover intrinsic structures and extract relevant information. In this paper, we introduce a novel strategy called (COIN), which exploits COncept INterestingness measures to detect communities based on the concept lattice construction of the network. Thus, unlike off-the-shelf community detection algorithms, COIN leverages relevant conceptual characteristics inherited from Formal Concept Analysis to discover substantial local structures. On the first stage of COIN, we extract the formal concepts that capture all the cliques and bridges in the social network. On the second stage, we use the stability index to remove noisy bridges between communities and then percolate (merge) relevant adjacent cliques. Our experiments on several real-world social networks show that COIN can quickly detect communities more accurately than existing prominent algorithms such as Edge betweenness, Fast greedy modularity, and Infomap.","social network analysis, community detection, formal concept analysis, formal concept interestingness",CASCON '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Tanimoto SL,Towards a Shared Language for Problem-Solving in Design,,2007,,,19–21,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2007 Symposium on Science of Design,"Arcata, California, USA",2007,9781605584362,,https://doi.org/10.1145/1496630.1496641;http://dx.doi.org/10.1145/1496630.1496641,10.1145/1496630.1496641,"As tools for design get increasingly complex and powerful, it is increasingly important that their users have a solid grounding in what it is these tools do and how they do it. When these tools are software engineering tools, we can assume that their users have formal training in computing. However, when the tools are for designing art or multimedia objects, the artists using the tools typically don't have much background in the computing technology they are using. While interdisciplinary design teams can work around the shortcomings of individual team members, they might be more effective teams if they shared a common language and understanding of certain key aspects of the design process. At the University of Washington we have begun a project to study the use of the theory of problem solving as shared knowledge by design teams engaged in creating of multimedia games. The theory we used is derived from early work in artificial intelligence. The concepts of state space, search, operators and evaluation functions are key components of the shared knowledge. The theory is embodied in a software system called T-STAR (Transparent STate-spaces search ARchitecture) which supports a collaborative interface for problem-solving. A key question for the project is \to what extent will interdisciplinary design teams adopt and exploit the theory of problem solving when given an opportunity to do so?\""""","design process methodology, statespace search, language of design, collaborative learning, human-centered computing, user interfaces, tree visualization",SoD '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Duval T,Fleury C",An Asymmetric 2D Pointer/3D Ray for 3D Interaction within Collaborative Virtual Environments,,2009,,,33–41,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th International Conference on 3D Web Technology,"Darmstadt, Germany",2009,9781605584324,,https://doi.org/10.1145/1559764.1559769;http://dx.doi.org/10.1145/1559764.1559769,10.1145/1559764.1559769,"In this paper we present a new metaphor for interaction within Collaborative Virtual Environments (CVE). This metaphor is dedicated to non-immersive or semi-immersive 3D interactions, for which users cannot afford to buy expensive devices neither for 3D visualization of their virtual environment nor for interaction. With these low-cost restrictions, we think that it is more effective to use basic 2D metaphors rather than to try to adapt 3D virtual metaphors which would be more difficult to use because of the poor immersion level offered by such systems.The problem that will arise within a CVE is that it is difficult to make a user aware of the 2D metaphors used by another user, because they are not associated with a 3D virtual object of the shared universe. So our idea is to provide to a user a 3D virtual ray (using ray-casting for object selection) that would act like a 2D pointer on the screen, allowing the user to only control the 2D position of the closest ray end, and calculating the orientation of the ray so that its projection on the screen would always be a point. This way, since the user is controlling a 3D virtual ray, the other users can be made aware of his activity.To test the efficiency of this 2D Pointer / 3D Ray, we have made some experiments making users compare different devices to realize some simple selection and manipulation tasks. The results show that this kind of 2D solution is efficient and allows 3D interaction within Virtual Environments by people who cannot afford expensive immersive hardware. This new metaphor allows more users to collaborate within CVE.","2D pointer, 3D interaction, 3D ray, collaborative virtual environments, ray-casting",Web3D '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kamahara J,Nagamatsu T,Tanaka N",Conjunctive Ranking Function Using Geographic Distance and Image Distance for Geotagged Image Retrieval,,2012,,,9–14,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM Multimedia 2012 Workshop on Geotagging and Its Applications in Multimedia,"Nara, Japan",2012,9781450315906,,https://doi.org/10.1145/2390790.2390795;http://dx.doi.org/10.1145/2390790.2390795,10.1145/2390790.2390795,"Nowadays, an enormous number of photographic images are uploaded on the Internet by casual users. In this study, we consider the concept of embedding geographical identification of locations as geotags in images. We attempt to retrieve images having certain similarities (or identical objects) from a geotagged image dataset. We then define the images having identical objects as orthologous images. Using content-based image retrieval (CBIR), we propose a ranking function--orthologous identity function (OIF)--to estimate the degree to which two images contain similarities in the form of identical objects; OIF is a similarity rating function that uses the geographic distance and image distance of photographs. Further, we evaluate the OIF as a ranking function by calculating the mean reciprocal rank (MRR) using our experimental dataset. The results reveal that the OIF can improve the efficiency of retrieving orthologous images as compared to using only geographic distance or image distance.","content based image retrieval (CBIR), geo-tagged image retrieval, orthologous images",GeoMM '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"GînscĂ AL,Boroş E,Iftene A,TrandabĂţ D,Toader M,Corîci M,Perez CA,Cristea D",Sentimatrix: Multilingual Sentiment Analysis Service,,2011,,,189–195,Association for Computational Linguistics,USA,,Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis,"Portland, Oregon",2011,9781937284060,,,,"This paper describes the preliminary results of a system for extracting sentiments opinioned with regard with named entities. It also combines rule-based classification, statistics and machine learning in a new method. The accuracy and speed of extraction and classification are crucial. The service oriented architecture permits the end-user to work with a flexible interface in order to produce applications that range from aggregating consumer feedback on commercial products to measuring public opinion on political issues from blog and forums. The experiment has two versions available for testing, one with concrete extraction results and sentiment calculus and the other with internal metrics validation results.",,WASSA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Carniel AC,Spatial Information Retrieval in Digital Ecosystems: A Comprehensive Survey,,2020,,,10–17,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Conference on Management of Digital EcoSystems,"Virtual Event, United Arab Emirates",2020,9781450381154,,https://doi.org/10.1145/3415958.3433038;http://dx.doi.org/10.1145/3415958.3433038,10.1145/3415958.3433038,"Spatial information retrieval is a common task of digital ecosystems due to the popularity of collecting and storing spatial information and phenomena in the world of the Internet of Things (IoT). Spatial relationships play an important role in this context by specifying how two or more spatial objects are related or connected. Examples of spatial relationships include topological relationships (e.g., intersect, overlap, contains), metric relationships (e.g., nearest neighbors), and direction relationships (e.g., cardinal directions like north and south). Many works in the literature have proposed definitions and implementations of spatial queries based on specific types of spatial relationships. Hence, a holistic view of these works is important to understand their applicability and relations. This paper advances in the literature by providing a comprehensive survey of the implementations and types of spatial queries that can be used by digital ecosystems. We present a novel characterization based on spatial relationships to define topological-based, metric-based, and direction-based spatial queries. For each type of spatial query, we present its intuitive and formal definitions together with possible strategies of implementation. Further, we identify hybrid spatial queries as combinations of two or more spatial relationships, and spatial joins as generalization cases. In addition, we present some equivalences between some types of queries. As a result, we point out future research topics in spatial information retrieval.","Direction relationship, IoT, Spatial relationship, Hybrid spatial queries, Spatial information retrieval, Topological relationship, Metric relationship, Spatial join",MEDES '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Stampoulis A,Shao Z",VeriML: Typed Computation of Logical Terms inside a Language with Effects,,2010,,,333–344,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th ACM SIGPLAN International Conference on Functional Programming,"Baltimore, Maryland, USA",2010,9781605587943,,https://doi.org/10.1145/1863543.1863591;http://dx.doi.org/10.1145/1863543.1863591,10.1145/1863543.1863591,"Modern proof assistants such as Coq and Isabelle provide high degrees of expressiveness and assurance because they support formal reasoning in higher-order logic and supply explicit machine-checkable proof objects. Unfortunately, large scale proof development in these proof assistants is still an extremely difficult and time-consuming task. One major weakness of these proof assistants is the lack of a single language where users can develop complex tactics and decision procedures using a rich programming model and in a typeful manner. This limits the scalability of the proof development process, as users avoid developing domain-specific tactics and decision procedures.In this paper, we present VeriML - a novel language design that couples a type-safe effectful computational language with first-class support for manipulating logical terms such as propositions and proofs. The main idea behind our design is to integrate a rich logical framework - similar to the one supported by Coq - inside a computational language inspired by ML. The language design is such that the added features are orthogonal to the rest of the computational language, and also do not require significant additions to the logic language, so soundness is guaranteed. We have built a prototype implementation of VeriML including both its type-checker and an interpreter. We demonstrate the effectiveness of our design by showing a number of type-safe tactics and decision procedures written in VeriML.","proof assistants, type theory, dependent types, logical frameworks",ICFP '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Stampoulis A,Shao Z",VeriML: Typed Computation of Logical Terms inside a Language with Effects,SIGPLAN Not.,2010,45,9,333–344,Association for Computing Machinery,"New York, NY, USA",,,,2010-09,,0362-1340,https://doi.org/10.1145/1932681.1863591;http://dx.doi.org/10.1145/1932681.1863591,10.1145/1932681.1863591,"Modern proof assistants such as Coq and Isabelle provide high degrees of expressiveness and assurance because they support formal reasoning in higher-order logic and supply explicit machine-checkable proof objects. Unfortunately, large scale proof development in these proof assistants is still an extremely difficult and time-consuming task. One major weakness of these proof assistants is the lack of a single language where users can develop complex tactics and decision procedures using a rich programming model and in a typeful manner. This limits the scalability of the proof development process, as users avoid developing domain-specific tactics and decision procedures.In this paper, we present VeriML - a novel language design that couples a type-safe effectful computational language with first-class support for manipulating logical terms such as propositions and proofs. The main idea behind our design is to integrate a rich logical framework - similar to the one supported by Coq - inside a computational language inspired by ML. The language design is such that the added features are orthogonal to the rest of the computational language, and also do not require significant additions to the logic language, so soundness is guaranteed. We have built a prototype implementation of VeriML including both its type-checker and an interpreter. We demonstrate the effectiveness of our design by showing a number of type-safe tactics and decision procedures written in VeriML.","proof assistants, logical frameworks, dependent types, type theory",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhan Y,Yu J,Yu Z,Zhang R,Tao D,Tian Q",Comprehensive Distance-Preserving Autoencoders for Cross-Modal Retrieval,,2018,,,1137–1145,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th ACM International Conference on Multimedia,"Seoul, Republic of Korea",2018,9781450356657,,https://doi.org/10.1145/3240508.3240607;http://dx.doi.org/10.1145/3240508.3240607,10.1145/3240508.3240607,"In this paper, we propose a novel method with comprehensive distance-preserving autoencoders (CDPAE) to address the problem of unsupervised cross-modal retrieval. Previous unsupervised methods rely primarily on pairwise distances of representations extracted from cross media spaces that co-occur and belong to the same objects. However, besides pairwise distances, the CDPAE also considers heterogeneous distances of representations extracted from cross media spaces as well as homogeneous distances of representations extracted from single media spaces that belong to different objects. The CDPAE consists of four components. First, denoising autoencoders are used to retain the information from the representations and to reduce the negative influence of redundant noises. Second, a comprehensive distance-preserving common space is proposed to explore the correlations among different representations. This aims to preserve the respective distances between the representations within the common space so that they are consistent with the distances in their original media spaces. Third, a novel joint loss function is defined to simultaneously calculate the reconstruction loss of the denoising autoencoders and the correlation loss of the comprehensive distance-preserving common space. Finally, an unsupervised cross-modal similarity measurement is proposed to further improve the retrieval performance. This is carried out by calculating the marginal probability of two media objects based on a kNN classifier. The CDPAE is tested on four public datasets with two cross-modal retrieval tasks: \query images by texts\"" and \""query texts by images\"". Compared with eight state-of-the-art cross-modal retrieval methods","the experimental results demonstrate that the CDPAE outperforms all the unsupervised methods and performs competitively with the supervised methods.""","cross-modal retrieval, unsupervised, autoencoder, similarity measurement, comprehensive distancepreserving",MM '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Merchán-Sánchez-Jara J,García JA,Díaz RG",Towards a Hypermedia Model for Digital Scholarly Edition of Musical Texts Based on MEI (Music Encoding Initiative) Standard: Integration of Hidden Traditions within Social Editing Paradigm,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Technological Ecosystems for Enhancing Multiculturality,"Cádiz, Spain",2017,9781450353861,,https://doi.org/10.1145/3144826.3145446;http://dx.doi.org/10.1145/3144826.3145446,10.1145/3144826.3145446,"Digital scholarly editions are substantially modifying the way musical editions has been thought and conceptualized over long periods of time. It's hypermedia capabilities, and its multi-layered structure makes it possible to put in context different sources and testimonies in a virtual space where all objects are semantically related, as well as to take into account explicit distinctions about original sources, related historical information, or editorial interventions. Music digital scholarly editions embodied an interactive nature allowing users to choose from different outputs or reading paths on the bias of different purposes; namely musicological study, learning/teaching activities or performing.In this context, this Ph.D. dissertation aims to develop a theoretical model for the integration of performing variants (technical and/or expressive) that are transmitted orally or through informal channels (marks, notes or text annotations), and usually from teacher to student, within a particular stylistic or interpretive school. The new standards for encoding musical documents like MEI, allow incorporating this information as superposed layers, explicitly differentiated, to the original sources and testimonies. The proposed model is developed within the so-called social editing paradigm, which postulates the integration of some of the 2.0 Web characteristics as the collaborative production of knowledge within the academic editing processes. These new editing practices allow the integration of work's related knowledge, that circulates outside the formal editing and publication circuits, within the scholarly edition.","critical editing of music, performing editions, hidden traditions, social editing, Digital scholarly editions, music encoding initiative",TEEM 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Spasova G,A Method for Contour Detection of Water Areas,,2019,,,175–179,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th International Conference on Computer Systems and Technologies,"Ruse, Bulgaria",2019,9781450371490,,https://doi.org/10.1145/3345252.3345259;http://dx.doi.org/10.1145/3345252.3345259,10.1145/3345252.3345259,"Contour pixels distinguish objects from the background. Tracing and extracting contour pixels are widely used for smart/wearable image sensor devices, because these are simple and useful for detecting objects. This article provides an algorithm for detecting contours in an image and calculating the contour area. Edge detection method Canny is used for segmenting the image.","Image Segmentation, Contour, Edge detection",CompSysTech '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gilbert P,McLellan WG",Compiler Generation Using Formal Specification of Procedure-Oriented and Machine Languages,,1967,,,447–455,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the April 18-20, 1967, Spring Joint Computer Conference","Atlantic City, New Jersey",1967,9781450378956,,https://doi.org/10.1145/1465482.1465553;http://dx.doi.org/10.1145/1465482.1465553,10.1145/1465482.1465553,"This paper reports on a recently developed compiler generation system which is rigorously based, and which allows formal specification both of source (procedure-oriented) languages (POLs) and of machine languages (MLs). Concepts underlying the system are discussed, an example correlating source language specification with system operation is given, and the status and potentialities of the system are discussed.",,AFIPS '67 (Spring),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lai M,Shan C,de With PH",Hand-Eye Camera Calibration with an Optical Tracking System,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Conference on Distributed Smart Cameras,"Eindhoven, Netherlands",2018,9781450365116,,https://doi.org/10.1145/3243394.3243700;http://dx.doi.org/10.1145/3243394.3243700,10.1145/3243394.3243700,"This paper presents a method for hand-eye camera calibration via an optical tracking system (OTS) faciltating robotic applications. The camera pose cannot be directly tracked via the OTS. Because of this, a transformation matrix between a marker-plate pose, tracked via the OTS, and the camera pose needs to be estimated. To this end, we evaluate two different approaches for hand-eye calibration. In the first approach, the camera is in a fixed position and a 2D calibration plate is displaced. In the second approach, the camera is also fixed, but now a 3D calibration object is moved. The first step of our method consists of collecting N views of the marker-plate pose and the calibration plates, acquired via OTS. This is achieved by keeping the camera fixed and moving the calibration plate, while taking a picture of the calibration plate using the camera. A dataset is constructed that contains marker-plate poses and the relative camera poses. Afterwards, the transformation matrix is then computed, following a least-squares minimization. Accuracy in hand-eye calibration is computed in terms of re-projection error, calculated based on camera homography transformations. For both approaches, we measure the changes in accuracy as a function of the number of poses used for each calibration, while we define the minimum number of poses required to obtain a good camera calibration. Results of the experiments show similar performances for the two evaluated methods, achieving a median value of the re-projection error at N = 25 poses of 0.76 mm for the 2D calibration plate and 0.70 mm for the 3D calibration object. Also, we have found that minimally 15 poses are required to achieve a good camera calibration.","neurosurgery, tracking, Hand-eye calibration, optical tracking system, augmented reality, endoscope",ICDSC '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Arceri V,Mastroeni I",Analyzing Dynamic Code: A Sound Abstract Interpreter for <i>Evil</i> Eval,ACM Trans. Priv. Secur.,2021,24,2,,Association for Computing Machinery,"New York, NY, USA",,,,2021-01,,2471-2566,https://doi.org/10.1145/3426470;http://dx.doi.org/10.1145/3426470,10.1145/3426470,"Dynamic languages, such as JavaScript, employ string-to-code primitives to turn dynamically generated text into executable code at run-time. These features make standard static analysis extremely hard if not impossible, because its essential data structures, i.e., the control-flow graph and the system of recursive equations associated with the program to analyze, are themselves dynamically mutating objects. Nevertheless, assembling code at run-time by manipulating strings, such as by eval in JavaScript, has been always strongly discouraged, since it is often recognized that “eval is evil,” leading static analyzers to not consider such statements or ignoring their effects. Unfortunately, the lack of formal approaches to analyze string-to-code statements pose a perfect habitat for malicious code, that is surely evil and do not respect good practice rules, allowing them to hide malicious intents as strings to be converted to code and making static analyses blind to the real malicious aim of the code. Hence, the need to handle string-to-code statements approximating what they can execute, and therefore allowing the analysis to continue (even in the presence of dynamically generated program statements) with an acceptable degree of precision, should be clear. To reach this goal, we propose a static analysis allowing us to collect string values and to soundly over-approximate and analyze the code potentially executed by a string-to-code statement.","static analysis, Abstract interpretation, dynamic languages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Weirich S,Yorgey BA,Sheard T",Binders Unbound,,2011,,,333–345,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th ACM SIGPLAN International Conference on Functional Programming,"Tokyo, Japan",2011,9781450308656,,https://doi.org/10.1145/2034773.2034818;http://dx.doi.org/10.1145/2034773.2034818,10.1145/2034773.2034818,"Implementors of compilers, program refactorers, theorem provers, proof checkers, and other systems that manipulate syntax know that dealing with name binding is difficult to do well. Operations such as α-equivalence and capture-avoiding substitution seem simple, yet subtle bugs often go undetected. Furthermore, their implementations are tedious, requiring \boilerplate\"" code that must be updated whenever the object language definition changes.Many researchers have therefore sought to specify binding syntax declaratively",so that tools can correctly handle the details behind the scenes. This idea has been the inspiration for many new systems (such as Beluga,Delphin,FreshML,FreshOCaml,Cαml,FreshLib,and Ott) but there is still room for improvement in expressivity,simplicity and convenience.In this paper,we present a new domain-specific language,Unbound,for specifying binding structure. Our language is particularly expressive - it supports multiple atom types,pattern binders,type annotations,recursive binders,and nested binding (necessary for telescopes,a feature found in dependently-typed languages). However,our specification language is also simple,consisting of just five basic combinators. We provide a formal semantics for this language derived from a locally nameless representation and prove that it satisfies a number of desirable properties.We also present an implementation of our binding specification language as a GHC Haskell library implementing an embedded domain specific language (EDSL). By using Haskell type constructors to represent binding combinators,we implement the EDSL succinctly using datatype-generic programming. Our implementation supports a number of features necessary for practical programming,including flexibility in the treatment of user-defined types,best-effort name preservation (for error messages),"and integration with Haskell's monad transformer library.""","haskell, patterns, name binding, generic programming",ICFP '11,,,,,,,,
1,Journal Article,"Weirich S,Yorgey BA,Sheard T",Binders Unbound,SIGPLAN Not.,2011,46,9,333–345,Association for Computing Machinery,"New York, NY, USA",,,,2011-09,,0362-1340,https://doi.org/10.1145/2034574.2034818;http://dx.doi.org/10.1145/2034574.2034818,10.1145/2034574.2034818,"Implementors of compilers, program refactorers, theorem provers, proof checkers, and other systems that manipulate syntax know that dealing with name binding is difficult to do well. Operations such as α-equivalence and capture-avoiding substitution seem simple, yet subtle bugs often go undetected. Furthermore, their implementations are tedious, requiring \boilerplate\"" code that must be updated whenever the object language definition changes.Many researchers have therefore sought to specify binding syntax declaratively",so that tools can correctly handle the details behind the scenes. This idea has been the inspiration for many new systems (such as Beluga,Delphin,FreshML,FreshOCaml,Cαml,FreshLib,and Ott) but there is still room for improvement in expressivity,simplicity and convenience.In this paper,we present a new domain-specific language,Unbound,for specifying binding structure. Our language is particularly expressive - it supports multiple atom types,pattern binders,type annotations,recursive binders,and nested binding (necessary for telescopes,a feature found in dependently-typed languages). However,our specification language is also simple,consisting of just five basic combinators. We provide a formal semantics for this language derived from a locally nameless representation and prove that it satisfies a number of desirable properties.We also present an implementation of our binding specification language as a GHC Haskell library implementing an embedded domain specific language (EDSL). By using Haskell type constructors to represent binding combinators,we implement the EDSL succinctly using datatype-generic programming. Our implementation supports a number of features necessary for practical programming,including flexibility in the treatment of user-defined types,best-effort name preservation (for error messages),"and integration with Haskell's monad transformer library.""","name binding, haskell, patterns, generic programming",,,,,,,,,
1,Conference Paper,"ter Beek MH,Gnesi S,Koch N,Mazzanti F",Formal Verification of an Automotive Scenario in Service-Oriented Computing,,2008,,,613–622,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th International Conference on Software Engineering,"Leipzig, Germany",2008,9781605580791,,https://doi.org/10.1145/1368088.1368173;http://dx.doi.org/10.1145/1368088.1368173,10.1145/1368088.1368173,"We report on the successful application of academic experience with formal modelling and verification techniques to an automotive scenario from the service-oriented computing domain. The aim of this industrial case study is to verify a priori, thus before implementation, certain design issues. The specific scenario is a simplified version of one of possible new services for car drivers to be provided by the in-vehicle computers.","model checking, service-oriented computing, automotive systems",ICSE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nuernberger B,Ofek E,Benko H,Wilson AD",SnapToReality: Aligning Augmented Reality to the Real World,,2016,,,1233–1244,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems,"San Jose, California, USA",2016,9781450333627,,https://doi.org/10.1145/2858036.2858250;http://dx.doi.org/10.1145/2858036.2858250,10.1145/2858036.2858250,"Augmented Reality (AR) applications may require the precise alignment of virtual objects to the real world. We propose automatic alignment of virtual objects to physical constraints calculated from the real world in real time (\snapping to reality\""). We demonstrate SnapToReality alignment techniques that allow users to position",rotate,and scale virtual content to dynamic,real world scenes. Our proof-of-concept prototype extracts 3D edge and planar surface constraints. We furthermore discuss the unique design challenges of snapping in AR,including the user's limited field of view,noise in constraint extraction,issues with changing the view in AR,visualizing constraints,and more. We also report the results of a user study evaluating SnapToReality,confirming that aligning objects to the real world is significantly faster when assisted by snapping to dynamically extracted constraints. Perhaps more importantly,"we also found that snapping in AR enables a fresh and expressive form of AR content creation.""","user studies, augmented reality, 3D user interaction, snapping, interaction techniques",CHI '16,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kakhki AM,Jero S,Choffnes D,Nita-Rotaru C,Mislove A",Taking a Long Look at QUIC: An Approach for Rigorous Evaluation of Rapidly Evolving Transport Protocols,Commun. ACM,2019,62,7,86–94,Association for Computing Machinery,"New York, NY, USA",,,,2019-06,,0001-0782,https://doi.org/10.1145/3330336;http://dx.doi.org/10.1145/3330336,10.1145/3330336,"Google's Quick UDP Internet Connections (QUIC) protocol, which implements TCP-like properties at the application layer atop a UDP transport, is now used by the vast majority of Chrome clients accessing Google properties but has no formal state machine specification, limited analysis, and ad-hoc evaluations based on snapshots of the protocol implementation in a small number of environ-merits. Further frustrating attempts to evaluate QUIC is the fact that the protocol is under rapid development, with extensive rewriting of the protocol occurring over the scale of months, making individual studies of the protocol obsolete before publication.Given this unique scenario, there is a need for alternative techniques for understanding and evaluating QUIC when compared with previous transport-layer protocols. First, we develop an approach that allows us to conduct analysis across multiple versions of QUIC to understand how code changes impact protocol effectiveness. Next, we instrument the source code to infer QUIC's state machine from execution traces. With this model, we run QUIC in a large number of environments that include desktop and mobile, wired and wireless environments and use the state machine to understand differences in transport-and application-layer performance across multiple versions of QUIC and in different environments. QUIC generally outperforms TCP, but we also identified performance issues related to window sizes, re-ordered packets, and multiplexing large number of small objects; further, we identify that QUIC's performance diminishes on mobile devices and over cellular networks.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li M,Chen Y,Wang L,Xu G",Dynamically Validating Static Memory Leak Warnings,,2013,,,112–122,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 International Symposium on Software Testing and Analysis,"Lugano, Switzerland",2013,9781450321594,,https://doi.org/10.1145/2483760.2483778;http://dx.doi.org/10.1145/2483760.2483778,10.1145/2483760.2483778,"File Edit Options Buffers Tools TeX Help Memory leaks have significant impact on software availability, performance, and security. Static analysis has been widely used to find memory leaks in C/C++ programs. Although a static analysis is able to find all potential leaks in a program, it often reports a great number of false warnings. Manually validating these warnings is a daunting task, which significantly limits the practicality of the analysis. In this paper, we develop a novel dynamic technique that automatically validates and categorizes such warnings to unleash the power of static memory leak detectors. Our technique analyzes each warning that contains information regarding the leaking allocation site and the leaking path, generates test cases to cover the leaking path, and tracks objects created by the leaking allocation site. Eventually, warnings are classified into four categories: MUST-LEAK, LIKELY-NOT-LEAK, BLOAT, and MAY-LEAK. Warnings in MUST-LEAK are guaranteed by our analysis to be true leaks. Warnings in LIKELY-NOT-LEAK are highly likely to be false warnings. Although we cannot provide any formal guarantee that they are not leaks, we have high confidence that this is the case. Warnings in BLOAT are also not likely to be leaks but they should be fixed to improve performance. Using our approach, the developer's manual validation effort needs to be focused only on warnings in the category MAY-LEAK, which is often much smaller than the original set.","Concolic Testing, Memory Leaks, Warning Classification",ISSTA 2013,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pereira J,Schmidt F,Contreras P,Murtagh F,Astudillo H",Clustering and Semantics Preservation in Cultural Heritage Information Spaces,,2010,,,100–105,LE CENTRE DE HAUTES ETUDES INTERNATIONALES D'INFORMATIQUE DOCUMENTAIRE,"Paris, FRA",,"Adaptivity, Personalization and Fusion of Heterogeneous Information","Paris, France",2010,,,,,"In this paper, we analyze the preservation of original semantic similarity among objects when dimensional reduction is applied on the original data source and a further clustering process is performed on dimensionally reduced data. An experiment is designed to test Baire, or longest common prefix ultrametric, and K-Means when prior random projection is applied. A data matrix extracted from a cultural heritage database has been prepared for the experiment. Given that the random projection produces a vector with components ranging on the interval [0, 1], clusters are obtained at different precision levels. Next, the mean semantic similarity of clusters is calculated using a modified version of the Jaccard index. Our findings show that semantics is difficult to preserve by these methods. However, a Student's hypothesis test on mean similarity indicates that Baire clusters objects are semantically better than K-Means when we increase the digit precision, but paying an increasing cost for orphan clustered objects. Despite this cost, it is argued that the ultrametric technique provides an efficient process to detect semantic homogeneity on the original data space.",,RIAO '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Eckstein R,Henrich A,Weber N",LFRP-Search: Multi-Layer Ranked Visual Faceted Search: An Approach to Cope with Complex Search Situations,,2010,,,1713–1717,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Symposium on Applied Computing,"Sierre, Switzerland",2010,9781605586397,,https://doi.org/10.1145/1774088.1774455;http://dx.doi.org/10.1145/1774088.1774455,10.1145/1774088.1774455,"In enterprise search scenarios information needs are quite diverse. If users know exactly which items they are looking for, they need support in known-item searches. But often information needs are vague and unclear, which means that users cannot explicitly define the search criteria that specify their search request. In these cases, exploratory search approaches are necessary to support users in interactively refining their search queries. Our approach for a retrieval system for complex search situations can be characterized by its four constituent parts: The approach deals with the heterogeneity of potential target objects when performing a search considering multiple artifact layers (e. g. projects, products, persons, and documents). The basic search paradigm applied is faceted search which is well-suited for exploratory interactive retrieval. To cope with result sets of different granularity, we include ranking facilities based on facet values as well as Query-by-Example (QbE) functionalities. Users can easily state their priorities visually by using preference functions. Finally, parallel coordinates (PC) are used to visualize the characteristics and dependencies of (intermediate) results in order to provide users with a deeper understanding of the data under investigation. These four cornerstones of our approach are reflected in the acronym LFRP-search (Multi-Layer Faceted Search with Ranking using Parallel Coordinates). The main contribution of this paper is the semi-formal description of the query options.","information retrieval, parallel coordinates, faceted search, multi-criteria, visualization, retrieval model",SAC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kakhki AM,Jero S,Choffnes D,Nita-Rotaru C,Mislove A",Taking a Long Look at QUIC: An Approach for Rigorous Evaluation of Rapidly Evolving Transport Protocols,,2017,,,290–303,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2017 Internet Measurement Conference,"London, United Kingdom",2017,9781450351188,,https://doi.org/10.1145/3131365.3131368;http://dx.doi.org/10.1145/3131365.3131368,10.1145/3131365.3131368,"Google's QUIC protocol, which implements TCP-like properties at the application layer atop a UDP transport, is now used by the vast majority of Chrome clients accessing Google properties but has no formal state machine specification, limited analysis, and ad-hoc evaluations based on snapshots of the protocol implementation in a small number of environments. Further frustrating attempts to evaluate QUIC is the fact that the protocol is under rapid development, with extensive rewriting of the protocol occurring over the scale of months, making individual studies of the protocol obsolete before publication.Given this unique scenario, there is a need for alternative techniques for understanding and evaluating QUIC when compared with previous transport-layer protocols. First, we develop an approach that allows us to conduct analysis across multiple versions of QUIC to understand how code changes impact protocol effectiveness. Next, we instrument the source code to infer QUIC's state machine from execution traces. With this model, we run QUIC in a large number of environments that include desktop and mobile, wired and wireless environments and use the state machine to understand differences in transport- and application-layer performance across multiple versions of QUIC and in different environments. QUIC generally outperforms TCP, but we also identified performance issues related to window sizes, re-ordered packets, and multiplexing large number of small objects; further, we identify that QUIC's performance diminishes on mobile devices and over cellular networks.","transport-layer performance, QUIC",IMC '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Karaenke P,Kirn S",Towards Model Checking & Simulation of a Multi-Tier Negotiation Protocol for Service Chains,,2010,,,1559–1560,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: Volume 1 - Volume 1,"Toronto, Canada",2010,9780982657119,,,,"The object of our research is resource allocation which considers contractual dependencies across service chain tiers to avoid overcommitment and overpurchasing. We propose a multi-tier negotiation protocol for solving this problem. The proposed artifact is developed from an interaction protocol engineering perspective and a protocol specification is given. Besides basic safety properties like the absence of deadlock, we formally verify that the protocol prevents overcommitments and overpurchasing by means of the model checker Spin.","resource allocation, multiagent systems, negotiation",AAMAS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Johnson P,Lagerström R,Ekstedt M",A Meta Language for Threat Modeling and Attack Simulations,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 13th International Conference on Availability, Reliability and Security","Hamburg, Germany",2018,9781450364485,,https://doi.org/10.1145/3230833.3232799;http://dx.doi.org/10.1145/3230833.3232799,10.1145/3230833.3232799,"Attack simulations may be used to assess the cyber security of systems. In such simulations, the steps taken by an attacker in order to compromise sensitive system assets are traced, and a time estimate may be computed from the initial step to the compromise of assets of interest. Attack graphs constitute a suitable formalism for the modeling of attack steps and their dependencies, allowing the subsequent simulation.To avoid the costly proposition of building new attack graphs for each system of a given type, domain-specific attack languages may be used. These languages codify the generic attack logic of the considered domain, thus facilitating the modeling, or instantiation, of a specific system in the domain. Examples of possible cyber security domains suitable for domain-specific attack languages are generic types such as cloud systems or embedded systems but may also be highly specialized kinds, e.g. Ubuntu installations; the objects of interest as well as the attack logic will differ significantly between such domains.In this paper, we present the Meta Attack Language (MAL), which may be used to design domain-specific attack languages such as the aforementioned. The MAL provides a formalism that allows the semi-automated generation as well as the efficient computation of very large attack graphs. We declare the formal background to MAL, define its syntax and semantics, exemplify its use with a small domain-specific language and instance model, and report on the computational performance.","Cyber Security, Threat Modeling, Attack Graphs, Domain Specific Language",ARES 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kasinathan P,Cuellar J",Securing the Integrity of Workflows in IoT,,2018,,,252–257,Junction Publishing,USA,,Proceedings of the 2018 International Conference on Embedded Wireless Systems and Networks,"Madrid, Spain",2018,9780994988621,,,,"In a multi-tenant, self-configuring IoT system, entities -- devices, services or \things\"" -- might know each other or might be complete strangers. The different owners will probably have different security goals and will want to impose their own security policy rules on their own entities. Thus",there is a need to negotiate a compromise and to interoperate the security policies of the different components. How will other devices react if a particular event arises? In this paper we propose a framework to specify and manage workflows to be performed in a cyber-physical system,without assuming the availability of a centralized management system. Further,the method provides a formal background to guarantee the integrity of such processes and to enforce a least privilege principle for the authorizations required to execute the tasks in the workflow. More precisely,the proposed method a) supports the declaration of workflows to be executed in a given context,"b) allow parties to propose and accept (or reject) \""contracts\"" that describe the workflows in which they will participate",c) constrain an IoT application to obey a prescribed workflow,and d) restrict the access rights of subjects to secured objects for the execution of their tasks in the workflow,"but not more. We propose to use Petri Nets and Smart Contracts to specify and enforce workflows. This concept can also be applied to other application areas not restricted to IoT.""","Internet of Things, Integrity, Workflow, Security",EWSN ’18,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mello R,Uchôa A,Oliveira R,Oliveira D,Oizumi W,Souza J,Fonseca B,Garcia A",Investigating the Social Representations of the Identification of Code Smells by Practitioners and Students from Brazil,,2019,,,457–466,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the XXXIII Brazilian Symposium on Software Engineering,"Salvador, Brazil",2019,9781450376518,,https://doi.org/10.1145/3350768.3351794;http://dx.doi.org/10.1145/3350768.3351794,10.1145/3350768.3351794,"Context: The identification of code smells is one of the most subjective tasks in software engineering. A key reason is the influence of collective aspects of communities working on this task, such as their beliefs regarding the relevance of certain smells. However, collective aspects are often neglected in the context of smell identification. For this purpose, we can use the social representations theory. Social representations comprise the set of values, behaviors, and practices of communities associated with a social object, such as the task of identifying smells. Aim: To characterize the social representations behind smell identification. Method: We conducted an empirical study on the social representations of smell identification by two communities. One community is composed of postgraduate students from different Brazilian universities. The other community is composed of practitioners located in Brazilian companies, having different levels of experience in code reviews. We analyzed the associations made by the study participants about smell identification, i.e., what immediately comes to their minds when they think about this task. Results: One of the key findings is that the community of students and practitioners have stronger associations with different types of code smells. Students share a strong belief that smell identification is a matter of measurement, while practitioners focus on the structure of the source code and its semantics. Besides, we found that only practitioners frequently associate the task with individual skills. This finding suggests research directions on code smells may be revisited. Conclusion: We found evidence that social representations theory allows identifying research gaps and opportunities by looking beyond the borders of formal knowledge and individual opinions. Therefore, this theory can be considered an important resource for conducting qualitative studies in software engineering.","code smells, Social representations, qualitative research",SBES 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Singh MP,Semantics and Verification of Information-Based Protocols,,2012,,,1149–1156,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 2,"Valencia, Spain",2012,9780981738123,,,,"Information-Based Interaction-Oriented Programming, specifically as epitomized by the Blindingly Simple Protocol Language (BSPL), is a promising new approach for declaratively expressing multiagent protocols. BSPL eschews traditional control flow operators and instead emphasizes causality and integrity based solely on the information models of the messages exchanged. BSPL has been shown to support a rich variety of practical protocols and can be realized in a distributed asynchronous architecture wherein the agents participating in a protocol act based on local knowledge alone. The flexibility and generality of BSPL mean that it needs a strong formal semantics to ensure correctness as well as automated tools to help develop protocol specifications.We provide a formal semantics for BSPL and formulate important technical properties, namely, enactability, safety, and liveness. We further describe our declarative implementation of the BSPL semantics as well as of verifiers for the above properties using a temporal reasoner. We have validated our implementation by verifying the correctness of several protocols of practical interest.","agent communication, business protocols",AAMAS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lee S,Wysk RA,Shin D",Formal Models for Alternative Representations of Manufacturing Systems of Systems,,2013,,,2698–2709,IEEE Press,"Washington, D.C.",,Proceedings of the 2013 Winter Simulation Conference: Simulation: Making Decisions in a Complex World,,2013,9781479920778,,,,"Two separate approaches have been pursued to model manufacturing systems: a periodic process-oriented planning view and a discrete event-based operational view. It is desired to integrate both approaches. To meet this requirement, this paper presents formal descriptive models for a manufacturing supply chain system which can be assembled to unite heterogeneous system views. These models can be used to coordinate complex hierarchical manufacturing systems. The formal description of a system model consists of: (1) a Discrete Event System (DES)-based operational model of the physical system processes for system flows, (2) a periodic review-based planning model for decision-making processes for system coordination, and (3) an interaction and a temporal model for enabling the communication between the two above models. The model presented in this paper can be used to implement more realistic and seamless manufacturing system control mechanisms with consideration of logical planning and physical operational aspects at the same time.",,WSC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nikodem J,Klempous R",Novel Force Feedback Interface for Improving Human Perception in Laparoscopic Surgical Trainer,,2015,,,41–46,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the Symposium on Modeling and Simulation in Medicine,"Alexandria, Virginia",2015,9781510801028,,,,"This paper considers interaction of the laparoscopic instrument with virtual objects simulated in minimally invasive surgery trainer, which is a complex device which requires a synthesis between visual and haptic information. To compute the point-to-point interaction forces between the laparoscopic instrument and human internal organs, the software graphic data processing algorithms can be implemented. Inspired by the idea of Haptic Virtual Objects and virtual reality architecture, incorporated visual and haptic feedback, we employ virtual reality (VR) software for detection of collision between soft and rigid body, and soft body deformation. VR physics engine apply a force to each vertex of a triangle tessellated mesh, so as a result we obtain from VR physics rendering engine ready to use force vectors. To obtain that, first we create computer-generated Haptic Virtual Objects (HVO), which can be touched and manipulated with laparoscopic instruments. Next, we employ specific rendering engine working on physical interactions. In proposed software (written in C++) we employ HVO and OGRE 3D graphic rendering and Bullet Physics engines. It calculates a force feedback for yaw, pitch and insertion axes of motion. Force rendering algorithm considers point-based interactions, and the force rendering loop update rate is about 100Hz.","force feedback, haptic virtual object, haptic interface, virtual reality, laparoscopic surgical trainer, human computer interaction",MSM '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Tasaka S,Causal Structures of Multidimensional QoE in Haptic-Audiovisual Communications: Bayesian Modeling,ACM Trans. Multimedia Comput. Commun. Appl.,2020,16,1,,Association for Computing Machinery,"New York, NY, USA",,,,2020-02,,1551-6857,https://doi.org/10.1145/3375922;http://dx.doi.org/10.1145/3375922,10.1145/3375922,"This article proposes a methodology for building and verifying plausible models that can express causation in multidimensional QoE for haptic-audiovisual interactive communications. For the modeling, we utilize subjective experimental data of five-point scores collected in a previous study where a pair of subjects carry out two kinds of interactive tasks (castanets hitting and object movement) in real space (not in virtual space). The multidimensional QoE is composed of 15 measures for the castanets hitting and 14 measures for the object movement. To reduce the dimension, we classify the QoE measures into three groups as indicators of three constructs (latent variables or factors): AVQ (AudioVisual Quality), HQ (Haptic Quality), and UXQ (User eXperience Quality). We then build two models: (1) a structural equation model in which AVQ and HQ correlated with each other give causal effects on UXQ, and (2) a confirmatory factor analysis model in which the three constructs are only correlated with each other. We refer to the former as 3C-SEM and the latter as 3C-CFA. We further introduce a CFA model with a single construct for which all QoE measures are its indicators (1C-CFA). We perform Bayesian analysis of the three models by means of Markov chain Monte Carlo simulation; in each model, the deviance information criterion is obtained for model comparison, and the posterior predictive p-value is calculated for model checking. As a result, we find that 3C-SEM is the most plausible and that HQ has a stronger causal effect on UXQ than AVQ. We also learn that the correlation between AVQ and UXQ is much higher than the direct causal effect and that the increase in the association as correlation is due to the causal effect of HQ on UXQ through the correlation of AVQ with HQ. Thus, it is suggested that improving haptic performance is more effective in enhancement of QoE than improving audiovisual performance.","correlation, causation, QoE, latent variables, CFA, SEM, OpenBUGS, Bayesian modeling, haptic-audiovisual interactive communications, Quality of experience, MCMC",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lee Y,Moon C,Ko H,Lee SH,Yoo B",Unified Representation for XR Content and Its Rendering Method,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,The 25th International Conference on 3D Web Technology,"Virtual Event, Republic of Korea",2020,9781450381697,,https://doi.org/10.1145/3424616.3424695;http://dx.doi.org/10.1145/3424616.3424695,10.1145/3424616.3424695,"Virtual Reality (VR) and Augmented Reality (AR) have become familiar technologies with related markets growing rapidly every year. Moreover, the idea of considering VR and AR as one eXtended reality (XR) has broken the border between virtual space and real space. However, there is no formal way to create such XR content except through existing VR or AR content development platforms. These platforms require the content author to perform additional tasks such as duplicating content for a specific user interaction environment (VR or AR) and associating them as one. Also, describing the content in an existing markup language (e.g., X3D, X3DOM, A-frame) has limitations of that the content author should predefine the user interaction environment (i.e., either of VR and AR). In this study, a unified XR representation is defined for describing XR content, and the method to render it has been proposed. The unified XR representation extends the HTML so that content authored with this representation can be harmoniously incorporated into existing web documents and can exploit resources on the World Wide Web. The XR renderer, which draws XR content on the screen, follows different procedures for both VR and AR situations. Consequently, the XR content works in both user interaction environment (VR and AR). Hence, this study provides a straightforward XR content authoring method that users access anywhere through a web browser regardless of their situational contexts, such as VR or AR. It facilitates XR collaboration with real objects by providing both VR and AR users with accessing an identical content.","Content, Augmented Reality, Unified Representation, XR, Virtual Reality, Extended Reality, Collaboration",Web3D '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yasugi M,Komiya T,Hiraishi T,Umatani S",Managing Continuations for Proper Tail Recursion,,2010,,,65–72,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 International Conference on Lisp,"Reno/Tahoe, Nevada, USA",2010,9781450304702,,https://doi.org/10.1145/1869643.1869651;http://dx.doi.org/10.1145/1869643.1869651,10.1145/1869643.1869651,"Implementations of Scheme are required to be properly tailrecursive and to support an unbounded number of active tail calls. Clinger proposed a formal definition of proper tail recursion based on space efficiency. This definition encompasses systematic tail call optimization, where every tail call is converted to a jump (with an optional trampoline), as well as Baker's implementation of Scheme in the C language with CPS (continuation-passing style) conversion. Baker's implementation is space-efficient, since no new continuation is created on a CPS-converted tail call and garbage is collected even on C's execution stack.In our work, we discovered that an abstract machine that runs CPS-converted programs cannot be considered properly tailrecursive according to Clinger's definition if continuation closures are simply created with the lexical environments for all variables. Furthermore, an abstract machine that employs neither explicit environments nor continuations is also improperly tail-recursive.This paper discusses the above issue and also proposes new techniques to implement a properly tail-recursive Scheme interpreter in an extended C language by following space-efficiency based definitions of proper tail recursion. In our approach, a program is not converted into CPS. The primary concept is to avoid stack overflow by creating a space-efficient first-class continuation represented as a list containing only the \Frame\"" objects necessary for the rest of the computation and immediately invoking the continuation. We use a language mechanism called \""L-closures\"" to access the contents of the execution stack as values of legal data structures and variables for implementing garbage collection and capturing continuations.""","proper tail recursion, continuations, extended c languages",ILC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wattamwar SS,Ghosh H",Spatio-Temporal Query for Multimedia Databases,,2008,,,48–55,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd ACM Workshop on Multimedia Semantics,"Vancouver, British Columbia, Canada",2008,9781605583167,,https://doi.org/10.1145/1460676.1460686;http://dx.doi.org/10.1145/1460676.1460686,10.1145/1460676.1460686,"Complex media events are often characterized by spatio-temporal relations between its constituent media objects. A multimedia query language should support specification of such relations for semantic retrieval. We propose a method for formally defining 3D spatio-temporal relations between elementary media objects in this paper. To support soft decision making for multimedia data interpretation and to provide graded ranking, we define these relations using a set of fuzzy membership functions. It is possible to define fuzzy 3D extensions of Allen's relations as well as arbitrary new relations using our method. This method can be incorporated with upcoming multimedia query languages, such as MP7QF.","spatio-temporal relation, multimedia database, multimedia query language, fuzzy logic",MS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Devaraj R,Sarkar A,Biswas S",Fault-Tolerant Preemptive Aperiodic RT Scheduling by Supervisory Control of TDES on Multiprocessors,ACM Trans. Embed. Comput. Syst.,2017,16,3,,Association for Computing Machinery,"New York, NY, USA",,,,2017-04,,1539-9087,https://doi.org/10.1145/3012278;http://dx.doi.org/10.1145/3012278,10.1145/3012278,"Safety-critical real-time systems must meet stringent timing and fault-tolerance requirements. This article proposes a methodology for synthesizing an optimal preemptive multiprocessor aperiodic task scheduler using a formal supervisory control framework. The scheduler can tolerate single/multiple permanent processor faults. Further, the synthesis framework has been empowered with a novel BDD-based symbolic computation mechanism to control the exponential state-space complexity of the optimal exhaustive enumeration-oriented synthesis methodology.","supervisory control, Formal methods, fault-tolerance, discrete event systems, preemptive scheduling, multiprocessors",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Turner TA,Thomas L,Owen C",Living the Indie Life: Mapping Creative Teams in a 48 Hour Game Jam and Playing with Data,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of The 9th Australasian Conference on Interactive Entertainment: Matters of Life and Death,"Melbourne, Australia",2013,9781450322546,,https://doi.org/10.1145/2513002.2513039;http://dx.doi.org/10.1145/2513002.2513039,10.1145/2513002.2513039,"In contemporary game development circles the 'game making jam' has become an important rite of passage and baptism event, an exploration space and a central indie lifestyle affirmation and community event. Game jams have recently become a focus for design researchers interested in the creative process. In this paper we tell the story of an established local game jam and our various documentation and data collection methods. We present the beginnings of the current project, which seeks to map the creative teams and their process in the space of the challenge, and which aims to enable participants to be more than the objects of the data collection. A perceived issue is that typical documentation approaches are 'about' the event as opposed to 'made by' the participants and are thus both at odds with the spirit of the jam as a phenomenon and do not really access the rich playful potential of participant experience. In the data collection and visualisation projects described here, we focus on using collected data to re-include the participants in telling stories about their experiences of the event as a place-based experience. Our goal is to find a means to encourage production of 'anecdata' - data based on individual story telling that is subjective, malleable, and resists collection via formal mechanisms - and to enable mimesis, or active narrating, on the part of the participants. We present a concept design for data as game based on the logic of early medieval maps and we reflect on how we could enable participation in the data collection itself.","spatiality, creative process, narrative, mapping, visualising information, anecdata, game jams, game design",IE '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Neto AJ,Borges MM,Roque L",A Preliminary Study of Proof of Concept Practices and Their Connection with Information Systems and Information Science,,2018,,,270–275,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Sixth International Conference on Technological Ecosystems for Enhancing Multiculturality,"Salamanca, Spain",2018,9781450365185,,https://doi.org/10.1145/3284179.3284226;http://dx.doi.org/10.1145/3284179.3284226,10.1145/3284179.3284226,"In this study, we have identified that a Proof of Concept can be characterized as a research practice and instrument of knowledge creation, based on a set of activities that are applied to the study and understanding of certain objects by the actors involved. In Information Systems Development, we have characterized a Proof of Concept as a system that creates socio-technical phenomena and, with the aim of understanding these phenomena, we use the Context Engineering approach. Context Engineering represents the relationship between a set of essential movements in a new framework of activities of Information Systems Development. Furthermore, we highlight Information Science, which allows us to study in formal and rigorous ways the processes, techniques, conditions, and effects that are entailed in improving the efficacy of information, which is used for a range of purposes related to individual, social and organizational needs, as well as new methods of scientific communication. To our knowledge, and following a review of the literature, there is a lack of studies combined with gaps in the knowledge of Proof of Concept practices. The misunderstanding of these practices may strengthen the probability of compromising the reliability, reproducibility, and reusability of the knowledge consumed or constructed in a Proof of Concept, which may affect its appropriate utilization by the organizations, their actors, or communities of practice. In this context, this paper aims to promote a preliminary study of the state-of-the-art scientific knowledge and to contribute to the body of published literature on Proof of Concept practices.","information science, context engineering, Proof of concept, information systems development",TEEM'18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Alvarado FH,Chen YS",Gamification for Informal Terms Lexicon Building,,2016,,,1372–1373,IEEE Press,"Davis, California",,Proceedings of the 2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining,,2016,9781509028467,,,,"Image tagging approaches have gained popularity in recent years. Advances in social computing research have enabled a faster completion of this task which before was known to be tedious. Most of which focus on the image-label relationship, leading to a vast amount of image repositories with corresponding text descriptors. There are several other collections such as dictionaries, lexicons or ontologies that aid different tasks the domains of text mining, Natural Language Processing and the different applications that come with it. Many of the research in this area is oriented towards social network analysis. These collections are based on formal ways of expression and unfortunately social networks content is not always formal. There is an increasing use of informal, many times regional language popularly called slang. We propose a Game With a Purpose (GWAP) system to facilitate the collection of informal terms. Leveraging on social interactions we seek to obtain a lexicon that is more suitable for social media related analysis.",,ASONAM '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kucerova J,Varhanikova I,Cernekova Z",Best View Methods Suitability for Different Types of Objects,,2012,,,55–61,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th Spring Conference on Computer Graphics,"Budmerice, Slovakia",2012,9781450319775,,https://doi.org/10.1145/2448531.2448538;http://dx.doi.org/10.1145/2448531.2448538,10.1145/2448531.2448538,"In this paper, we present three approaches to the best view selection for 3D objects, in order to find the proper combination. The first method is based on geometry and uses the maximum amount of visible vertices. The second method uses the visual attention model and the third one calculates the amount of information in a scene after projecting the 3D scene to the 2D image using entropy. Several 3D models from Blender are used in the experiment. We compare these different approaches and explore their suitability on various objects. An online questionnaire is made to find out which of the tested images fits better to the human tastes.","entropy, visual perception, best view, view quality, gestalt psychology, watershed",SCCG '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Popova V,Sharpanskykh A",Constraint-Based Modelling and Analysis of Organisations,,2009,,,283–284,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 ACM Symposium on Applied Computing,"Honolulu, Hawaii",2009,9781605581668,,https://doi.org/10.1145/1529282.1529343;http://dx.doi.org/10.1145/1529282.1529343,10.1145/1529282.1529343,"Modern organisations are characterised by a great variety of forms and often involve many actors with diverse goals, performing a wide range of tasks in changing environmental conditions. Due to high complexity, mistakes and inconsistencies are not rare in organisations. To provide better insights into the organisational operation and to identify different types of organisational problems explicit specification of relations and rules, on which the structure and behaviour of an organisation are based, is required. Before it is used, the specification of an organisation should be checked for internal consistency and validity w.r.t. the domain. To this end, the paper introduces a framework for formal specification of constraints that ensure the consistency and validity of organisational specifications. To verify the satisfaction of constraints, efficient and scalable algorithms have been developed and implemented. The framework presented here is based on the organisation modelling framework from [2] which defines four interrelated organisational views (or perspective) with their dedicated predicate logic-based languages: performance-oriented, process-oriented, organisation-oriented and agent-oriented. To express temporal relations, the dedicated languages of the views are embedded into the Temporal Trace Language (TTL) [2], which is a variant of the order-sorted predicate logic. Some of the examples given in the paper are from a case study in the air traffic domain.","organisation design, validity of a specification, organisation modeling, constraints, consistency of a specification",SAC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Park G,Fellir F,Hong JE,Garrido JL,Noguera M,Chung L",Deriving Use Cases from Business Processes: A Goal-Oriented Transformational Approach,,2017,,,1288–1295,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Symposium on Applied Computing,"Marrakech, Morocco",2017,9781450344869,,https://doi.org/10.1145/3019612.3019789;http://dx.doi.org/10.1145/3019612.3019789,10.1145/3019612.3019789,"Many software systems are being developed to help with business processes, which typically involve a number of (human) tasks in achieving organizational goals. However, aligning a software system well with its intended business process has been challenging, since the tasks in a business process usually lacks formal definitions and can be performed via multiple different allocations of resources. In this paper, we propose a goal-oriented transformational approach to deriving use cases, as requirements on the software system, from a business process which is modeled in BPMN (Business Process Model and Notation). In this approach, a business process is modeled not only in terms of the functionally-oriented BPMN but also non-functional business goals, and the target software requirements are also modeled in terms of functionally-oriented use cases together with non-functional requirements. Those tasks to be performed by a software system are transformed into use cases, in consideration of multiple alternative interpretations of business tasks, different allocations of software functionality and the granularity of the target requirements guided via similarity and granularity. Additionally, an intermediate model is utilized in the 2-step transformation process to deal with the ontological gap and the many-to-many relationships between the source and the target. This process is facilitated by context-aware transformation rules and a supporting tool. A study of a quote flow business process shows that our goal-oriented transformational approach helps produce more cohesive, correct and comprehensive use cases.","non-functional requirements, business process, goal-oriented transformation, use case, BPMN",SAC '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Viyanon W,Songsuittipong T,Piyapaisarn P,Sudchid S",AR Furniture: Integrating Augmented Reality Technology to Enhance Interior Design Using Marker and Markerless Tracking,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Intelligent Information Processing,"Bangkok, Thailand",2017,9781450352871,,https://doi.org/10.1145/3144789.3144825;http://dx.doi.org/10.1145/3144789.3144825,10.1145/3144789.3144825,"Purchasing products for interior design always has a problem that the purchased products may not satisfy customers because they cannot put them in their own place before buying. The purpose of this research is to study and develop an android application called 'AR Furniture' with the use of Augmented Reality technology for design and decoration that will help customers visualize how furniture pieces will look and fit (to scale) in their homes and also can provide details of products to support customer decision. This application is a prototype to find out factors affecting the design and tracking of AR applications. This paper presents three factors that are important for designing and tracking AR applications.The principle of the application is started with analyzing images from the rear camera of a smartphone or tablet using marker tracking technique for displaying product's details and markerless tracking technique for displaying 3D models, performing feature tracking, and calculating positions to display a 3D model over the real world image. The implementation of the application can be split into 2 parts: Part 1 Creating 3D Models using Autodesk 3Ds Max and Part 2 Developing the application using Unity3D and Kudan Augmented Reality SDK as an engine for image analysis, image processing and 3D model rendering. Then we performed three experiments to test the application, 1) Image analysis with marker tracking 2) Image analysis with markerless tracking and 3) User's satisfaction of using the application.The results show that image analysis with marker tracking works well using markers which their size should not be less than 200 x 200 pixels, the distance between the camera and the marker should not be far more than 60 cm. Image analysis with markerless tracking works well with surfaces having a lot of features and at light levels of 100--300 lux (indoor light levels) with 70% accuracy. The user experience evaluation shows that the weakness (2.86 out of 5 points) of the application is when a user found a problem in the application they would need time to solve it. The user experience evaluation shows that the strength (3.93 out of 5 points) of the application is the application can show 3D Object that meet user satisfaction. And the average overall user's satisfaction come up with 3.93 out of 5 point evaluation score.From the experiments, the application should be modified for better performance such as develop various maker patterns using QR code or barcode, distinguish walls and ceilings so that the application would show 3D objects on them properly, improve light robustness and make 3D models more realistic.","interaction, tracking, AR application, Augmented reality, AR display",IIP'17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cacciagrano D,Corradini F,Culmone R,Tesei L,Vito L",A Model-Prover for Constrained Dynamic Conversations,,2008,,,630–633,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Conference on Information Integration and Web-Based Applications & Services,"Linz, Austria",2008,9781605583495,,https://doi.org/10.1145/1497308.1497428;http://dx.doi.org/10.1145/1497308.1497428,10.1145/1497308.1497428,"In a service-oriented architecture, systems communicate by exchanging messages. In this work, we propose a formal model based on OCL-constrained UML Class diagrams and a methodology based on Alloy Analyzer respectively for describing and verifying any first-order constrained client-server conversations. This framework allows us to verify conversation protocol designs at a fairly detailed level and to check first-order logic constraints on both message flows and message contents.","conversations, OCL, alloy, WSDL, web service, UML",iiWAS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Castro R,Kofman E,Wainer G",A Formal Framework for Stochastic DEVS Modeling and Simulation,,2008,,,421–428,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2008 Spring Simulation Multiconference,"Ottawa, Canada",2008,9781565553194,,,,"We introduce an extension of the classic Discrete Event System Specification (DEVS) formalism that includes stochastic features. Based on the use of Probability Spaces, the STochastic DEVS specification (STDEVS) provides a formal framework for modeling and simulation of general non deterministic discrete event systems. The main theoretical properties of STDEVS are shown. We illustrate its use in a stochastic-oriented simulation example with the main purpose of performance analysis in computer systems and data networks.","stochastic systems, DEVS, discrete event simulation",SpringSim '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Guerraoui R,Kapalka M",The Semantics of Progress in Lock-Based Transactional Memory,,2009,,,404–415,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 36th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"Savannah, GA, USA",2009,9781605583792,,https://doi.org/10.1145/1480881.1480931;http://dx.doi.org/10.1145/1480881.1480931,10.1145/1480881.1480931,"Transactional memory (TM) is a promising paradigm for concurrent programming. Whereas the number of TM implementations is growing, however, little research has been conducted to precisely define TM semantics, especially their progress guarantees. This paper is the first to formally define the progress semantics of lockbased TMs, which are considered the most effective in practice.We use our semantics to reduce the problems of reasoning about the correctness and computability power of lock-based TMs to those of simple try-lock objects. More specifically, we prove that checking the progress of any set of transactions accessing an arbitrarily large set of shared variables can be reduced to verifying a simple property of each individual (logical) try-lock used by those transactions. We use this theorem to determine the correctness of state-of-the-art lock-based TMs and highlight various configuration ambiguities. We also prove that lock-based TMs have consensus number 2. This means that, on the one hand, a lock-based TM cannot be implemented using only read-write memory, but, on the other hand, it does not need very powerful instructions such as the commonly used compare-and-swap.We finally use our semantics to formally capture an inherent trade-off in the performance of lock-based TM implementations. Namely, we show that the space complexity of every lock-based software TM implementation that uses invisible reads is at least exponential in the number of objects accessible to transactions.","consensus number, reduction, lower bound, impossibility, try-lock, semantics, transactional memory, lock",POPL '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Guerraoui R,Kapalka M",The Semantics of Progress in Lock-Based Transactional Memory,SIGPLAN Not.,2009,44,1,404–415,Association for Computing Machinery,"New York, NY, USA",,,,2009-01,,0362-1340,https://doi.org/10.1145/1594834.1480931;http://dx.doi.org/10.1145/1594834.1480931,10.1145/1594834.1480931,"Transactional memory (TM) is a promising paradigm for concurrent programming. Whereas the number of TM implementations is growing, however, little research has been conducted to precisely define TM semantics, especially their progress guarantees. This paper is the first to formally define the progress semantics of lockbased TMs, which are considered the most effective in practice.We use our semantics to reduce the problems of reasoning about the correctness and computability power of lock-based TMs to those of simple try-lock objects. More specifically, we prove that checking the progress of any set of transactions accessing an arbitrarily large set of shared variables can be reduced to verifying a simple property of each individual (logical) try-lock used by those transactions. We use this theorem to determine the correctness of state-of-the-art lock-based TMs and highlight various configuration ambiguities. We also prove that lock-based TMs have consensus number 2. This means that, on the one hand, a lock-based TM cannot be implemented using only read-write memory, but, on the other hand, it does not need very powerful instructions such as the commonly used compare-and-swap.We finally use our semantics to formally capture an inherent trade-off in the performance of lock-based TM implementations. Namely, we show that the space complexity of every lock-based software TM implementation that uses invisible reads is at least exponential in the number of objects accessible to transactions.","impossibility, consensus number, transactional memory, lower bound, lock, semantics, try-lock, reduction",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zhang Z,Porter J,Kottenstette N,Koutsoukos X,Sztipanovits J",High Confidence Embedded Software Design: A Quadrotor Helicopter Case Study,SIGBED Rev.,2011,8,2,44–47,Association for Computing Machinery,"New York, NY, USA",,,,2011-06,,,https://doi.org/10.1145/2000367.2000377;http://dx.doi.org/10.1145/2000367.2000377,10.1145/2000367.2000377,"Traditional design methodology is not suitable for high-confidence embedded software due to the lack of a formal semantic model for software analysis, automatic code generation, and often designed embedded software is hard to reuse. In order to automatically generate high-confidence and reusable embedded software, we propose a TLM-centric, platform-based, time-triggered and component-oriented method. We use this new method to generate the control software for a quadrotor helicopter.","graphical models, embedded software, digital control, real-time systems, computer aided software engineering",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Späth J,Ali K,Bodden E","Context-, Flow-, and Field-Sensitive Data-Flow Analysis Using Synchronized Pushdown Systems",Proc. ACM Program. Lang.,2019,3,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-01,,,https://doi.org/10.1145/3290361;http://dx.doi.org/10.1145/3290361,10.1145/3290361,"Precise static analyses are context-, field- and flow-sensitive. Context- and field-sensitivity are both expressible as context-free language (CFL) reachability problems. Solving both CFL problems along the same data-flow path is undecidable, which is why most flow-sensitive data-flow analyses over-approximate field-sensitivity through k-limited access-path, or through access graphs. Unfortunately, as our experience and this paper show, both representations do not scale very well when used to analyze programs with recursive data structures. Any single CFL-reachability problem is efficiently solvable, by means of a pushdown system. This work thus introduces the concept of synchronized pushdown systems (SPDS). SPDS encode both procedure calls/returns and field stores/loads as separate but “synchronized” CFL reachability problems. An SPDS solves both individual problems precisely, and approximation occurs only in corner cases that are apparently rare in practice: at statements where both problems are satisfied but not along the same data-flow path. SPDS are also efficient: formal complexity analysis shows that SPDS shift the complexity from |F|3k under k-limiting to |S||F|2, where F is the set of fields and S the set of statements involved in a data-flow. Our evaluation using DaCapo shows this shift to pay off in practice: SPDS are almost as efficient as k-limiting with k=1 although their precision equals k=∞. For a typestate analysis SPDS accelerate the analysis up to 83× for data-flows of objects that involve many field accesses but span rather few methods. We conclude that SPDS can provide high precision and further improve scalability, in particularly when used in analyses that expose rather local data flows.","pushdown system, static analysis, aliasing, access paths, data-flow",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liu H,Gluch DP",Formal Verification of AADL Behavior Models: A Feasibility Investigation,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 47th Annual Southeast Regional Conference,"Clemson, South Carolina",2009,9781605584218,,https://doi.org/10.1145/1566445.1566495;http://dx.doi.org/10.1145/1566445.1566495,10.1145/1566445.1566495,"OSATE is an open source platform and toolset built upon Eclipse plug-in technology that supports the modeling and analysis of real-time reactive systems. OSATE implements the Society Automotive Engineers (SAE) standard Architecture Analysis & Design Language (AADL). Because many real-time reactive systems are safety-critical and mission-oriented, the behaviors of these systems are typically subtle and intricate such that even an experienced designer faces significant challenges in their correct design. An AADL Behavior Annex is being developed to help engineers in addressing these challenges. Since several formal model-checking tools have shown the capability of tracing and verifying temporal logic properties of reactive systems, it is desirable to integrate these tools into the OSATE toolset. This will enable the formal verification of the behavior of AADL models. In this paper, we present two case studies that explore the feasibility of extending model-checking tools to the OSATE toolset. The preliminary work and case studies in this paper address several important questions relating to a tool integration project.","tool integration, model checking, computational tree logic, architecture analysis & design language",ACM-SE 47,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang J,Rahardja S,Fränti P",Outlier Detection: How to Threshold Outlier Scores?,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the International Conference on Artificial Intelligence, Information Processing and Cloud Computing","Sanya, China",2019,9781450376334,,https://doi.org/10.1145/3371425.3371427;http://dx.doi.org/10.1145/3371425.3371427,10.1145/3371425.3371427,"Outlier detection is a fundamental issue in data mining and machine learning. Most methods calculate outlier score for each object and then threshold the scores to detect outliers. Most widely used thresholding techniques are based on statistics like standard deviation around mean, median absolute deviation and interquartile range. Unfortunately, these statistics can be significantly biased because of the presence of outliers when calculating these statistics. This makes their use inaccurate. To overcome this problem, we propose a two-stage thresholding method (2T). Most obvious outliers are first removed by using a more conservative threshold, and the same process is then repeated for the processed scores. Experiments show that this two-stage approach significantly improves the results of all the three existing thresholding techniques.","SD, two-stage threshold, standard deviation, interquartile range, MAD, anomaly detection, outlier detection, error detection, IQR, novelty detection, median absolute deviation",AIIPCC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kakuta T,Vinh LB,Kawakami R,Oishi T,Ikeuchi K",Detection of Moving Objects and Cast Shadows Using a Spherical Vision Camera for Outdoor Mixed Reality,,2008,,,219–222,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Symposium on Virtual Reality Software and Technology,"Bordeaux, France",2008,9781595939517,,https://doi.org/10.1145/1450579.1450626;http://dx.doi.org/10.1145/1450579.1450626,10.1145/1450579.1450626,"This paper presents a method to detect moving objects and remove their shadows for superimposing them on Mixed Reality (MR) systems. We cut out the foreground from a real image using a probability-based segmentation method. Using color, spatial, and temporal priors, we can improve the accuracy of the segmentation. Energy minimization is executed by graph cuts. Then we remove the shadow region from the foreground with F-value calculated from the pixel value and the spectral sensitivity characteristic of the camera. Finally we superimpose virtual objects using the stencil buffer, which is used to limit the area of rendering for each pixel. Synthesized images of an outdoor scene show the efficiency of the proposed method.","foreground extraction, shadow removal, augmented reality, mixed reality",VRST '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lee J,Hong S,Oh H",MemFix: Static Analysis-Based Repair of Memory Deallocation Errors for C,,2018,,,95–106,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering,"Lake Buena Vista, FL, USA",2018,9781450355735,,https://doi.org/10.1145/3236024.3236079;http://dx.doi.org/10.1145/3236024.3236079,10.1145/3236024.3236079,"We present MemFix, an automated technique for fixing memory deallocation errors in C programs. MemFix aims to fix memory-leak, double-free, and use-after-free errors, which occur when developers fail to properly deallocate memory objects. MemFix attempts to fix these errors by finding a set of free-statements that correctly deallocate all allocated objects without causing double-frees and use-after-frees. The key insight behind MemFix is that finding such a set of deallocation statements corresponds to solving an exact cover problem derived from a variant of typestate static analysis. We formally present the technique and experimentally show that MemFix is able to fix real errors found in open-source programs. Because MemFix is based on a sound static analysis, the generated patches guarantee to fix the original errors without introducing new errors.","Program Repair, Program Analysis, Debugging",ESEC/FSE 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"He Z,Liang X",A Novel Simplification Algorithm Based on MLS and Splats for Point Models,,2009,,,45–52,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 Computer Graphics International Conference,"Victoria, British Columbia, Canada",2009,9781605586878,,https://doi.org/10.1145/1629739.1629745;http://dx.doi.org/10.1145/1629739.1629745,10.1145/1629739.1629745,"The simplification of point models is important in point-based processing technology because of the increasing of data complexity. Many researches focus on getting the subset from the initial point set, which can not represent the whole object properly. In this paper, we present a novel simplification algorithm based on Moving Least Square (MLS) and Splats for point models. The algorithm uses MLS to represent the point models and can get the minimum error point which is used to deputize its neighborhood. This approach can get new proper agent points instead of subset. Then we calculate the error based on the rendering results, which means considering the geometry of splat when calculating the error of simplification. Experiment results show that this algorithm is not only efficient, but also has good quality.",,CGI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang C,Cao L,Wang M,Li J,Wei W,Ou Y",Coupled Nominal Similarity in Unsupervised Learning,,2011,,,973–978,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th ACM International Conference on Information and Knowledge Management,"Glasgow, Scotland, UK",2011,9781450307178,,https://doi.org/10.1145/2063576.2063715;http://dx.doi.org/10.1145/2063576.2063715,10.1145/2063576.2063715,"The similarity between nominal objects is not straightforward, especially in unsupervised learning. This paper proposes coupled similarity metrics for nominal objects, which consider not only intra-coupled similarity within an attribute (i.e., value frequency distribution) but also inter-coupled similarity between attributes (i.e. feature dependency aggregation). Four metrics are designed to calculate the inter-coupled similarity between two categorical values by considering their relationships with other attributes. The theoretical analysis reveals their equivalent accuracy and superior efficiency based on intersection against others, in particular for large-scale data. Substantial experiments on extensive UCI data sets verify the theoretical conclusions. In addition, experiments of clustering based on the derived dissimilarity metrics show a significant performance improvement.","accuracy, complexity, similarity measure",CIKM '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brandt C,Kracht M","Syntax, Semantics and Pragmatics in Communication",,2011,,,195–202,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Semantic Systems,"Graz, Austria",2011,9781450306218,,https://doi.org/10.1145/2063518.2063549;http://dx.doi.org/10.1145/2063518.2063549,10.1145/2063518.2063549,"We develop a conceptual and formal understanding of syntax, semantics and pragmatics in communication from the point of view of (theoretical) computer science as well as (computational) linguistics. We motivate our understanding with the help of a real-world application scenario, apply it to a concrete example related to (business) dialogues in service oriented landscapes and finally point out how our results are related to the Semantic Web ecosystem in a way that is providing basic concepts for an emerging Pragmatic Web.","pragmatics, communication, syntax, protocols, semantics, computational linguistics, pragmatics in communication",I-Semantics '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,,Some Abstracts from The Computer Science Conference,SIGACT News,1973,5,2,24–25,Association for Computing Machinery,"New York, NY, USA",,,,1973-04,,0163-5700,https://doi.org/10.1145/1811123.1811126;http://dx.doi.org/10.1145/1811123.1811126,10.1145/1811123.1811126,"The Computer Science Conference in Columbus, Ohio, February 20--22, 1973, was an experiment in organizing a broad education-and-research-oriented meeting analogous to some of the more industry-and-profession-oriented meetings that occur on a regular basis. In terms of bringing together many people from the appropriate communities, we think the meeting must be judged a success and the organizers congratulated. We found the unrefereed research presentations--as expected-- of very uneven quality. (One in formal language theory consisted of a result often given as an exercise in the first portion of a standard course. It is not reproduced here.) We will include some of the relevant abstracts in the next issue or two of SIGACT News as research notices. Interested persons may want to correspond with the authors; but it should be remembered that these are not abstracts of papers, and may involve research in progress. --Ed.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zhu H,Bayley I",An Algebra of Design Patterns,ACM Trans. Softw. Eng. Methodol.,2013,22,3,,Association for Computing Machinery,"New York, NY, USA",,,,2013-07,,1049-331X,https://doi.org/10.1145/2491509.2491517;http://dx.doi.org/10.1145/2491509.2491517,10.1145/2491509.2491517,"In a pattern-oriented software design process, design decisions are made by selecting and instantiating appropriate patterns, and composing them together. In our previous work, we enabled these decisions to be formalized by defining a set of operators on patterns with which instantiations and compositions can be represented. In this article, we investigate the algebraic properties of these operators. We provide and prove a complete set of algebraic laws so that equivalence between pattern expressions can be proven. Furthermore, we define an always-terminating normalization of pattern expression to a canonical form which is unique modulo equivalence in first-order logic.By a case study, the pattern-oriented design of an extensible request-handling framework, we demonstrate two practical applications of the algebraic framework. First, we can prove the correctness of a finished design with respect to the design decisions made and the formal specification of the patterns. Second, we can even derive the design from these components.","formal method, Design patterns, equational reasoning, algebra, software design methodology, pattern composition",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vázquez-Salceda J,Vasconcelos WW,Padget J,Dignum F,Clarke S,Roig MP",ALIVE: An Agent-Based Framework for Dynamic and Robust Service-Oriented Applications,,2010,,,1637–1638,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 9th International Conference on Autonomous Agents and Multiagent Systems: Volume 1 - Volume 1,"Toronto, Canada",2010,9780982657119,,,,"Service-oriented systems are becoming more and more nodes in a digital, dynamic ecosystem requiring the identification and establishment of flexible, spontaneous collaboration activities between services. This requires new engineering approaches that can integrate new functionalities and behaviours into existing running systems of active, distributed and interdependent processes. Here, we present the approach of the FP7 Alive project to the use of formal models of coordination and organisation mechanisms to deliver a flexible, high-level means to describe the structure of interactions between services in the environment. We propose to build on the current activities in service-oriented engineering by defining three levels: (i) An organisational level models the organisational structure of executing and interlinked services and the context around them. (ii) A coordination level provides flexible ways to model interaction between the services. (iii) These two levels connect with existing (semantic) Web services, which contain semantic descriptions to make components aware of their social context and of the rules of engagement with other services.","environments, social and organisational structure, organisations and institutions, normative systems",AAMAS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zhan Q,Algorithm of Attribute Reduction in Dominance Based Rough Sets Combined with Dominance Discernibility Matrix,,2016,,,66–71,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Internet Multimedia Computing and Service,"Xi'an, China",2016,9781450348508,,https://doi.org/10.1145/3007669.3007676;http://dx.doi.org/10.1145/3007669.3007676,10.1145/3007669.3007676,"Dominance based rough set approach is a useful extension of the classical rough set approach and it has been successfully applied into multi-criteria decision analysis problems. This paper proposes the concept of dominance discernibility matrix and a novel attribute reduction algorithm based on dominance discernibility matrix. First, we employ dominance relation to detect the objects in the decision table, and get the dominance and subordinance classes according to condition attributes. Next, similarly, we apply dominance relation again to the decision table, and get upward and downward unions of decision classes according to decision attribute. Then we use dominance consistence method to calculate the objects in the decision table to generate the lower and upper approximations and discernibility matrix. Finally, we utilize discernibility matrix and its corresponding attribute reduction method to generate core of the decision table. A numerical example is employed to substantiate the conceptual arguments.","discernibility matrix, Dominance Relation, Dominance Consistence, Rough Set",ICIMCS'16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Weigl DM,Guastavino C",Applying the Stratified Model of Relevance Interactions to Music Information Retrieval,,2013,,,,American Society for Information Science,USA,,Proceedings of the 76th ASIS&T Annual Meeting: Beyond the Cloud: Rethinking Information Boundaries,"Montreal, Quebec, Canada",2013,9780877155454,,,,"While research on the notion of relevance has a long and rich history in information retrieval for textual documents, formal considerations of relevance concepts in Music Information Retrieval (MIR) remain scarce. We discuss the application of Saracevic's stratified model of relevance interactions to the music information domain. This model offers a tool for deliberation on the development of user-oriented MIR systems, and a framework for the aggregation of findings on the music information needs and behaviours of potential users.","relevance, music information users, music information retrieval, interaction, conceptual framework",ASIST '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Iannacci F,Turnquist E,Avrahami D,Patel SN",The Haptic Laser: Multi-Sensation Tactile Feedback for at-a-Distance Physical Space Perception and Interaction,,2011,,,2047–2050,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,"Vancouver, BC, Canada",2011,9781450302289,,https://doi.org/10.1145/1978942.1979239;http://dx.doi.org/10.1145/1978942.1979239,10.1145/1978942.1979239,"We present the Haptic Laser, a system for providing a range of tactile sensations to represent a physical environment at-a-distance. The Haptic Laser is a handheld device that simulates interaction with physical surfaces as a user targets objects of interest (e.g., a light switch, TV, etc). Using simple computer vision techniques for scene analysis and laser range finding for calculating distance, the Haptic Laser extracts information about the physical environment and conveys it haptically through a collection of hardware actuators. Pointing the Haptic Laser around a room, for example, presents the user with information about the presence of objects, transitions, and edges through touch rather than, or in addition to, vision. The Haptic Laser extends current work on haptic touch screens and pens, and is designed to allow for haptic feedback from a distance using multiple feedback channels.","ubiquitous computing, haptic feedback, at-a-distance interaction, motor control, computer vision",CHI '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xueting L,Ogawa T",An Estimation Method for Blurring Effect in Augmented Reality,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2013 Posters,"Anaheim, California",2013,9781450323420,,https://doi.org/10.1145/2503385.2503461;http://dx.doi.org/10.1145/2503385.2503461,10.1145/2503385.2503461,"The perceptual issues in Augmented Reality (AR) systems, is drawing more and more attention these days. Among the perceptual issues, the incorrect depth interpretations degrade user experience significantly. One way to improve the depth interpretations in AR systems is to improve the consistency of the real scene and the virtual objects by using the depth cue method based on blurring effect. In the research of [Okumura 2006], a blur rendering method based on measuring the defocusing on the AR marker from the captured real scene has been proposed. However, the blur effect could only be rendered on the marker position where the blur in the real scene is measured. This limits the practicality of the system since in many applications the virtual objects are out of the marker's range or even moving. In our work, a new method to estimate the degree of blur is proposed. This method makes it possible to calculate the degree of blur that varies spatially with the scene.",,SIGGRAPH '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wu Y,Ye Z,Wang Y",A Damage Identification System Based on Deep Learning,,2019,,,13–17,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 7th International Conference on Information Technology: IoT and Smart City,"Shanghai, China",2019,9781450376631,,https://doi.org/10.1145/3377170.3377252;http://dx.doi.org/10.1145/3377170.3377252,10.1145/3377170.3377252,"Deep Learning has achieved good results in many tasks, especially computer vision tasks such as image classification, object detection and semantic segmentation. And these tasks are usually part of a practical application such as automatic driving and face payment. In this paper, we propose an architecture and implementation of vehicle damage identification system based on deep learning. The system consists of damage identification module, mponent segmentation module and image alignment module. With this system, we only need to provide the the close and long view photos of the car, and the system will automatically identify damage and calculate the claim amount.","Deep learning, semantic segmentation, damage identification",ICIT 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Egstad J,Davis M,Lacewell D",Improved Deep Image Compositing Using Subpixel Masks,,2015,,,21–27,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 Symposium on Digital Production,"Los Angeles, California",2015,9781450337182,,https://doi.org/10.1145/2791261.2791266;http://dx.doi.org/10.1145/2791261.2791266,10.1145/2791261.2791266,"We present an improved method of producing and manipulating deep pixel data which retains important surface information calculated during the execution of the rendering algorithm for later use during compositing, allowing operations normally performed in the renderer to be deferred until compositing. These include pixel-coverage calculation, pixel filtering, hard-surface blending, and matte object handling. Current methodologies for representing and transmitting deep pixel data work well for combining volumetric and hard-surface renders but are not very successful at combining hard-surfaces. By retaining additional surface information a renderer's final integration steps can be reconstructed later in compositing.","subpixel masks, rendering, deep compositing, compositing",DigiPro '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Huang Q,Hua Y",A Study of Student Learning Status Classification Based on the Detection of Key Objects within the Visual Field,,2020,,,33–40,Association for Computing Machinery,"New York, NY, USA",,2020 The 4th International Conference on Video and Image Processing,"Xi'an, China",2020,9781450389075,,https://doi.org/10.1145/3447450.3447456;http://dx.doi.org/10.1145/3447450.3447456,10.1145/3447450.3447456,"In order to improve students' concentration in solitary learning, this paper proposes a method to detect students' learning status. The students are first photographed, and then a Faster RCNN model is used to classify the learning status of the students in the photos. In order to improve the classification accuracy, the system detects the 2D face key points and matches them with the 3D face model to calculate the head angle based on the conversion between coordinates to determine the visual field of the eyes. Based on the visual field, it is possible to detect key objects that students may be focusing on, such as books, computers, cell phones. Based on these key objects, it can improve the accuracy of classifying students' learning status. The system can better identify learning status and help guardians to manage the students.","Learning status classification, Visual field, Face key points, Head angle",ICVIP 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Rao H,Huang SW,Fu WT",Leveraging Human Computations to Improve Schematization of Spatial Relations from Imagery,ACM Trans. Intell. Syst. Technol.,2016,7,4,,Association for Computing Machinery,"New York, NY, USA",,,,2016-03,,2157-6904,https://doi.org/10.1145/2873065;http://dx.doi.org/10.1145/2873065,10.1145/2873065,"The process of generating schematic maps of salient objects from a set of pictures of an indoor environment is challenging. It has been an active area of research as it is crucial to a wide range of context- and location-aware services, as well as for general scene understanding. Although many automated systems have been developed to solve the problem, most of them either require predefining labels or expensive equipment, such as RGBD sensors or lasers, to scan the environment. In this article, we introduce a prototype system to show how human computations can be utilized to generate schematic maps from a set of pictures, without making strong assumptions or demanding extra devices. The system requires humans (crowd workers from Amazon Mechanical Turks) to do simple spatial mapping tasks in various conditions, and their data are aggregated by filtering and clustering techniques that allow salient cues to be identified in the pictures and their spatial relations to be inferred and projected on a two-dimensional map. In particular, we tested and demonstrated the effectiveness of two methods that improved the quality of the generated schematic map: (1) We encouraged humans to adopt an allocentric representations of salient objects by guiding them to perform mental rotations of these objects and (2) we sensitized human perception by guided arrows superimposed on the imagery to improve the accuracy of depth and width estimation. We demonstrated the feasibility of our system by evaluating the results of schematic maps generated from indoor pictures taken from an office building. By calculating Riemannian shape distances between the generated maps to the ground truth, we found that the generated schematic maps captured the spatial relations well. Our results showed that the combination of human computations and machine clustering could lead to more-accurate schematized maps from imagery. We also discuss how our approach may have important insights on methods that leverage human computations in other areas.","picture schematization, crowdsourcing, Human computations, spatial cognition",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mega KW,Yu X,Li J",Comparative Analysis of Color Edge Detection for Image Segmentation,,2018,,,93–101,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 International Conference on Computing and Pattern Recognition,"Shenzhen, China",2018,9781450364713,,https://doi.org/10.1145/3232829.3232845;http://dx.doi.org/10.1145/3232829.3232845,10.1145/3232829.3232845,"Nowadays understanding of image processing and pattern recognition is the great focus to develop an application of image segmentation. Edge detection is the fundamental technique that can provide information of the boundaries in different objects in an image. Selecting a suitable edge detection algorithm is important to obtain the best performance of segmentation. This paper presents an analysis of implementation for various edge detection techniques on color spaces. We implement Sobel, Prewitt, Robert, and Laplacian edge detection on Hue, Saturation, Value (HSV) and YUV color space by using threshold = 65. We calculated the mean square error (MSE), root mean square error (RMSE), peak signal to noise ratio (PSNR) and execution time as a comparison. This paper tested images from Berkeley Segmentation Dataset (BSDS). The results showed that Robert edge detection in HSV color space especially hue channel can be utilized to obtain more precise boundaries in different objects and it is also quick to compute.","Color Edge Detection, YUV, Edge Detection, HSV",ICCPR '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Welch PH,Pedersen JB",Santa Claus: Formal Analysis of a Process-Oriented Solution,ACM Trans. Program. Lang. Syst.,2010,32,4,,Association for Computing Machinery,"New York, NY, USA",,,,2010-04,,0164-0925,https://doi.org/10.1145/1734206.1734211;http://dx.doi.org/10.1145/1734206.1734211,10.1145/1734206.1734211,"With the commercial development of multicore processors, the challenges of writing multithreaded programs to take advantage of these new hardware architectures are becoming more and more pertinent. Concurrent programming is necessary to achieve the performance that the hardware offers. Traditional approaches present concurrency as an advanced topic: they have proven difficult to use, reason about with confidence, and scale up to high levels of concurrency. This article reviews process-oriented design, based on Hoare's algebra of Communicating Sequential Processes (CSP), and proposes that this approach to concurrency leads to solutions that are manageable by novice programmers; that is, they are easy to design and maintain, that they are scalable for complexity, obviously correct, and relatively easy to verify using formal reasoning and/or model checkers. These solutions can be developed in conventional programming languages (through CSP libraries) or specialized ones (such as occam-π) in a manner that directly reflects their formal expression. Systems can be developed without needing specialist knowledge of the CSP formalism, since the supporting mathematics is burnt into the tools and languages supporting it. We illustrate these concepts with the Santa Claus problem, which has been used as a challenge for concurrency mechanisms since 1994. We consider this problem as an example control system, producing external signals reporting changes of internal state (that model the external world). We claim our occam-π solution is correct-by-design, but follow this up with formal verification (using the FDR model checker for CSP) that the system is free from deadlock and livelock, that the produced control signals obey crucial ordering constraints, and that the system has key liveness properties.","verification, deadlock, novice programmer, event ordering, Process orientation, CSP, concurrency, occam-pi, liveness",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Norta A,Othman AB,Taveter K",Conflict-Resolution Lifecycles for Governed Decentralized Autonomous Organization Collaboration,,2015,,,244–257,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 2nd International Conference on Electronic Governance and Open Society: Challenges in Eurasia,"St. Petersburg, Russian Federation",2015,9781450340700,,https://doi.org/10.1145/2846012.2846052;http://dx.doi.org/10.1145/2846012.2846052,10.1145/2846012.2846052,"Recent blockchain-technology related innovations enable the governance of collaborating decentralized autonomous organizations (DAO) to engage in agile business-network collaborations that are based on the novel concept of smart contracting. DAOs utilize service-oriented cloud computing in a loosely coupled collaboration lifecycle with the main steps of setup, enactment, possible rollbacks and finally, an orderly termination. This lifecycle supports the selection of services provided and used by DAOs, smart contract negotiations, and behavior monitoring during enactment with the potential for breach management. Based on a sound understanding of the collaboration lifecycle in a Governance- as-a-Service (GaaS)-platform, a new type of conflict management must safeguard business-semantics induced consistency rules. This conflict management involves breach detection with recovery aspects. To fill the detected gap, we employ a formal design-notation that comprises the definition of structural and behavioral properties for exploring conflict-related exception- and compensation management during a decentralized collaboration. With the formal approach, we generate a highly dependable DAO-GaaS conflict model that does not collapse under left-behind clutter such as orphaned processes and exponentially growing database entries that require an unacceptable periodic GaaS reset.","Industry 4.0, service orientation, e-governance, Decentralized autonomous organization, open cloud ecosystem, conflict resolution, business process, smart contract",EGOSE '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ryssel U,Ploennigs J,Kabitzsch K",Extraction of Feature Models from Formal Contexts,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 15th International Software Product Line Conference, Volume 2","Munich, Germany",2011,9781450307895,,https://doi.org/10.1145/2019136.2019141;http://dx.doi.org/10.1145/2019136.2019141,10.1145/2019136.2019141,"For economical reasons, the creation of feature oriented software should include previously created products and should not be done from scratch. To speed up this migration process, feature models have to be generated automatically from existing product variants. This work presents an approach based on formal concept analysis that analyzes incidence matrices containing matching relations as input and creates feature models as output. The resulting feature models describe exactly the given input variants. The introduced novel optimized approach performs this transformation in reasonable time even for large product libraries.","feature models, formal concept analysis",SPLC '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Metzer G,Hanocka R,Zorin D,Giryes R,Panozzo D,Cohen-Or D",Orienting Point Clouds with Dipole Propagation,ACM Trans. Graph.,2021,40,4,,Association for Computing Machinery,"New York, NY, USA",,,,2021-07,,0730-0301,https://doi.org/10.1145/3450626.3459835;http://dx.doi.org/10.1145/3450626.3459835,10.1145/3450626.3459835,"Establishing a consistent normal orientation for point clouds is a notoriously difficult problem in geometry processing, requiring attention to both local and global shape characteristics. The normal direction of a point is a function of the local surface neighborhood; yet, point clouds do not disclose the full underlying surface structure. Even assuming known geodesic proximity, calculating a consistent normal orientation requires the global context. In this work, we introduce a novel approach for establishing a globally consistent normal orientation for point clouds. Our solution separates the local and global components into two different sub-problems. In the local phase, we train a neural network to learn a coherent normal direction per patch (i.e., consistently oriented normals within a single patch). In the global phase, we propagate the orientation across all coherent patches using a dipole propagation. Our dipole propagation decides to orient each patch using the electric field defined by all previously orientated patches. This gives rise to a global propagation that is stable, as well as being robust to nearby surfaces, holes, sharp features and noise.","surface reconstruction, point clouds, geometric deep learning",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Pedersen JB,Chalmers K",Verifying Channel Communication Correctness for a Multi-Core Cooperatively Scheduled Runtime Using CSP,,2019,,,65–74,IEEE Press,"Montreal, Quebec, Canada",,Proceedings of the 7th International Workshop on Formal Methods in Software Engineering,,2019,,,https://doi.org/10.1109/FormaliSE.2019.00016;http://dx.doi.org/10.1109/FormaliSE.2019.00016,10.1109/FormaliSE.2019.00016,"In this paper we use the process algebra CSP and the formal model-checker FDR to show that the implementation of one-to-one channel communication in the process-oriented language ProcessJ is correct. ProcessJ is a new process-oriented language with Java-like syntax and CSP-based communication using synchronous channels. ProcessJ allows for hundreds of millions of processes to be executed on a single processor core. ProcessJ generates Java code which eventually runs concurrently on the JVM using a cooperative scheduler. We use the translation from the ProcessJ code generator to translate ProcessJ to Java and further into CSP. We then utilize the FDR model-checker to show that the generated Java code behaves like a generic synchronous, blocking, non-buffered one-to-one channel used previously to show correctness of channel communication in JCSP - a Java library that supports JVM thread-based concurrency. Finally, we highlight a lesson from verifying our behaviour using FDR - the ability to simplify our approach and show the implementation still meets our specification.",,FormaliSE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Suñé AE,Formalization and Analysis of Quantitative Attributes of Distributed Systems,,2020,,,210–213,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM/IEEE 42nd International Conference on Software Engineering: Companion Proceedings,"Seoul, South Korea",2020,9781450371223,,https://doi.org/10.1145/3377812.3381387;http://dx.doi.org/10.1145/3377812.3381387,10.1145/3377812.3381387,"While there is not much discussion on the importance of formally describing and analyzing quantitative requirements in the process of software construction; in the paradigm of API-based software systems, it could be vital. Quantitative attributes can be thought of as attributes determining the Quality of Service - QoS provided by a software component published as a service. In this sense, they play a determinant role in classifying software artifacts according to specific needs stated as requirements.In this work, we present a research program consisting of the development of formal languages and tools to characterize and analyze the Quality of Service attributes of software components in the context of distributed systems. More specifically, our main motivational scenario lays on the execution of a service-oriented architecture.",,ICSE '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Steinhardt SB,Jackson SJ",Anticipation Work: Cultivating Vision in Collective Practice,,2015,,,443–453,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing,"Vancouver, BC, Canada",2015,9781450329224,,https://doi.org/10.1145/2675133.2675298;http://dx.doi.org/10.1145/2675133.2675298,10.1145/2675133.2675298,"Problems of temporality in distributed cooperative work have emerged as an important theme of CSCW and HCI work. This paper draws on ethnographic fieldwork into large-scale infrastructure development in ecology and ocean science and analyses of futurism in science and technology studies to call attention to \anticipation work\"": the practices that cultivate and channel expectations of the future",design pathways into those imaginations,and maintain those visions in the face of a dynamic world. We advance three basic claims: first,that long term technological development and sustainability in science is guided by complex and distributed forms of futurism; second,that all actors (both individual and collective) orient towards the future (at both temporally close and distant scales); and third,that actors engage in complex and skilled forms of anticipation work -- individual and collective,"formal and informal -- that guide and shape the present character and experience of collaborative life.""","time, ecology, anticipation, oceanography, temporality, futurism, infrastructure, futures, collaboration",CSCW '15,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Ivanov R,RSNAVI: An RFID-Based Context-Aware Indoor Navigation System for the Blind,,2012,,,313–320,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th International Conference on Computer Systems and Technologies,"Ruse, Bulgaria",2012,9781450311939,,https://doi.org/10.1145/2383276.2383322;http://dx.doi.org/10.1145/2383276.2383322,10.1145/2383276.2383322,"Most of the existing indoor navigation systems for the blind do not take into account their specific needs related to orientation and movement in an unfamiliar buildings. This paper presents an indoor blind navigation system called RSNAVI that has the following strengths: First, the system uses 4D modelling of buildings - 3D building and objects geometry and status of all sensors in time. To improve the navigation process we use semantic-rich interior model to describe not only the position and shape of all objects but also their characteristics. Second, the algorithm for route planning uses multi-parametric optimization to obtain the optimal route for the blind users. The system allows automatic re-routing when the blind user deviated from the route or if it detects a change of status of the sensors, for example blocking access to the room due to fire alarm. Finally, only algebraic expressions to calculate optimal route waypoints and to detour obstacles are used.","NFC-enabled phones, visual impairment, context-aware applications, indoor navigation",CompSysTech '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Lin M,Li W,Song LJ,Nguyen CT,Wang X,Lu S",SAKE: Estimating Katz Centrality Based on Sampling for Large-Scale Social Networks,ACM Trans. Knowl. Discov. Data,2021,15,4,,Association for Computing Machinery,"New York, NY, USA",,,,2021-04,,1556-4681,https://doi.org/10.1145/3441646;http://dx.doi.org/10.1145/3441646,10.1145/3441646,"Katz centrality is a fundamental concept to measure the influence of a vertex in a social network. However, existing approaches to calculating Katz centrality in a large-scale network are unpractical and computationally expensive. In this article, we propose a novel method to estimate Katz centrality based on graph sampling techniques, which object to achieve comparable estimation accuracy of the state-of-the-arts with much lower computational complexity. Specifically, we develop a Horvitz–Thompson estimate for Katz centrality by using a multi-round sampling approach and deriving an unbiased mean value estimator. We further propose SAKE, a Sampling-based Algorithm for fast Katz centrality Estimation. We prove that the estimator calculated by SAKE is probabilistically guaranteed to be within an additive error from the exact value. Extensive evaluation experiments based on four real-world networks show that the proposed algorithm can estimate Katz centralities for partial vertices with low sampling rate, low computation time, and it works well in identifying high influence vertices in social networks.","Social network, graph sampling, Katz centrality",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Chakrabarti A,Satuluri V,Srivathsan A,Parthasarathy S",A Bayesian Perspective on Locality Sensitive Hashing with Extensions for Kernel Methods,ACM Trans. Knowl. Discov. Data,2015,10,2,,Association for Computing Machinery,"New York, NY, USA",,,,2015-10,,1556-4681,https://doi.org/10.1145/2778990;http://dx.doi.org/10.1145/2778990,10.1145/2778990,"Given a collection of objects and an associated similarity measure, the all-pairs similarity search problem asks us to find all pairs of objects with similarity greater than a certain user-specified threshold. In order to reduce the number of candidates to search, locality-sensitive hashing (LSH) based indexing methods are very effective. However, most such methods only use LSH for the first phase of similarity search—that is, efficient indexing for candidate generation. In this article, we present BayesLSH, a principled Bayesian algorithm for the subsequent phase of similarity search—performing candidate pruning and similarity estimation using LSH. A simpler variant, BayesLSH-Lite, which calculates similarities exactly, is also presented. Our algorithms are able to quickly prune away a large majority of the false positive candidate pairs, leading to significant speedups over baseline approaches. For BayesLSH, we also provide probabilistic guarantees on the quality of the output, both in terms of accuracy and recall. Finally, the quality of BayesLSH’s output can be easily tuned and does not require any manual setting of the number of hashes to use for similarity estimation, unlike standard approaches. For two state-of-the-art candidate generation algorithms, AllPairs and LSH, BayesLSH enables significant speedups, typically in the range 2 × --20 × for a wide variety of datasets.We also extend the BayesLSH algorithm for kernel methods—in which the similarity between two data objects is defined by a kernel function. Since the embedding of data points in the transformed kernel space is unknown, algorithms such as AllPairs which rely on building inverted index structure for fast similarity search do not work with kernel functions. Exhaustive search across all possible pairs is also not an option since the dataset can be huge and computing the kernel values for each pair can be prohibitive. We propose K-BayesLSH an all-pairs similarity search problem for kernel functions. K-BayesLSH leverages a recently proposed idea—kernelized locality sensitive hashing (KLSH)—for hash bit computation and candidate generation, and uses the aforementioned BayesLSH idea for candidate pruning and similarity estimation. We ran a broad spectrum of experiments on a variety of datasets drawn from different domains and with distinct kernels and find a speedup of 2 × --7 × over vanilla KLSH.","Locality-sensitive hashing, bayesian inference, all-pairs similarity search, kernel similarity measure",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lu J,Hu D,Wang T,Zhang Z",GASDL: Geometric Algebra-Based Spatial Data Description Language,,2018,,,261–265,Association for Computing Machinery,"New York, NY, USA",,Proceedings of Computer Graphics International 2018,"Bintan, Island, Indonesia",2018,9781450364010,,https://doi.org/10.1145/3208159.3208191;http://dx.doi.org/10.1145/3208159.3208191,10.1145/3208159.3208191,"Spatial data model is a key factor in GIS research. Traditional spatial data models based on Euclidean geometry frameworks are limited in terms of unifying space-time and different objects of different dimensions owing to the complexity associated with calculating topological relationships. Thus, a new spatial data model based on geometric algebra (GA-based spatial data model) is developed, which introduces GA into the spatial data model by using multidimensional vectors to unify space-time and multidimensional objects. To link traditional spatial data models and GA-based spatial data models, in this paper, a GA-based spatial data description language (GASDL) is proposed. GASDL is based on the Extensible Markup Language (XML), and it mainly describes data in terms of geometry, topological relationships and properties. GASDL considers the characteristics of both the traditional spatial data model and the GA-based spatial data model. By using GASDL, data can be imported and exported between traditional spatial data models and GA-based spatial data models. Thus, GIS software applications that use traditional spatial data models and GA-based data models can be connected.","Spatial data model, Multidimensional vector, XML, Data exchange, Geometric algebra",CGI 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tang J,Zhou XM,Li CP",Target Detection Technology Based on Object Model Optimization Neural Network Learning,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2018 International Conference on Algorithms, Computing and Artificial Intelligence","Sanya, China",2018,9781450366250,,https://doi.org/10.1145/3302425.3302463;http://dx.doi.org/10.1145/3302425.3302463,10.1145/3302425.3302463,"Remote sensing images often contain large ground range. A large number of targets, irregular distribution rules and large scale transformation are included in an image, so the target detection is difficult and it takes a lot of time to calculate. The traditional target detection can locate the target in the image by multi-scale sliding window, but the selection speed, quantity and quality of the candidate frame not only affect the time efficiency of the target detection, but also affect the accuracy of the target detection. The sliding window method thinks that the possibility of each position in the image is the same. Therefore, it traverses every position in the image into a candidate frame window, and exhaustion of the search images with violent exhaustion, resulting in a large number of redundant and low quality redundant windows.WEI [1] proposes a target intention recognition model based on radial basis function neural network; YU [2] proposes a joint supervised recognition method based on dense convolution neural network, which combines local and global features, and obtains image features based on dense convolution neural network. ZHANG [3] proposed a fine target recognition method for color image under complex background, and used Bayesian model to distinguish skin color and background color in color image; ZHANG [4] aiming at the problems of tedious process and difficult feature extraction in traditional image recognition algorithm, an image adaptive target recognition algorithm based on depth feature learning is proposed; WANG [5] simply processes the original data and inputs it directly as input data into the convolution neural network. The convolution neural network is used to analyze the local features.The calculation process is very time-consuming and violates the human visual mechanism. In order to solve the limitation of the selection speed, quantity and quality of the target candidate frame in the traditional sliding window detection technology, the detection efficiency and accuracy of the target detection are improved. In this paper, a candidate frame screening preprocessing algorithm is proposed to tell the detection network which areas should be paid attention to, and can be combined with the actual features of remote sensing images to target specific targets. The initial candidate box is selected to reduce the false alarm rate. On this basis, the object feature sharing can reduce the calculation cost of the target area discovery based on the object character, avoid the full graph search, reduce the time consuming and improve the correct rate of the candidate region discovery. This detection technology greatly improves the recognition rate of remote sensing image targets, reduces the computation time and has practical promotion and application.","Target Recognition, Neural Network, Object Model",ACAI 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rudinac M,Lenseigne B,Jonker PP",Empirical Mode Decomposition for Saliency Detection,,2012,,,365–368,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th Annual Conference Companion on Genetic and Evolutionary Computation,"Philadelphia, Pennsylvania, USA",2012,9781450311786,,https://doi.org/10.1145/2330784.2330839;http://dx.doi.org/10.1145/2330784.2330839,10.1145/2330784.2330839,"We propose a novel method for saliency detection and attention selection inspired by processes in the human visual cortex. To mimic the varying spatial resolution of the human eye as well as the constant eye movements (saccades) and to model the effect of temporal adaptiveness, we use empirical mode decomposition and corresponding intrinsic mode functions (IMFs), instead of applying standard multi-scale framework as suggested in the state of the art. We derive IMFs between scales to calculate data driven center surround maps which locally reflect amount of information in the scene and we combine opposition color channels, luminosity information and orientation maps into a single saliency map calculated on IMFs. To equalize influence of different components contributing to the final saliency map, normalization steps are proposed. Finally, the MSER regions are calculated directly on the saliency map in order to obtain the most dominant points. We present results on both artificially generated images used in psychological experiments, natural images and application of our method for unknown object detection in robotics.","visual attention selection, saliency detection, robotic application, empirical mode decomposition",GECCO '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Worsley M,Multimodal Learning Analytics: Enabling the Future of Learning through Multimodal Data Analysis and Interfaces,,2012,,,353–356,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th ACM International Conference on Multimodal Interaction,"Santa Monica, California, USA",2012,9781450314671,,https://doi.org/10.1145/2388676.2388755;http://dx.doi.org/10.1145/2388676.2388755,10.1145/2388676.2388755,"Project-based learning has found its way into a range of formal and informal learning environments. However, systematically assessing these environments remains a significant challenge. Traditional assessments, which focus on learning outcomes, seem incongruent with the process-oriented goals of project-based learning. Multimodal interfaces and multimodal learning analytics hold significant promise for assessing learning in open-ended learning environments. With its rich integration of a multitude of data streams and naturalistic interfaces, this area of research may help usher in a new wave of education reform by supporting alternative modes of learning.","probabilistic modeling, learning, constructionism, data mining",ICMI '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Abdeslam WO,Tabii Y,El Kadiri KE",Adaptive Appearance Model in Particle Filter Based Visual Tracking,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2nd International Conference on Big Data, Cloud and Applications","Tetouan, Morocco",2017,9781450348522,,https://doi.org/10.1145/3090354.3090441;http://dx.doi.org/10.1145/3090354.3090441,10.1145/3090354.3090441,"Visual Tracking methods based on particle filter framework uses frequently the state space information of the target object to calculate the observation model, However this often gives a poor estimate if unexpected motions happen, or under conditions of cluttered backgrounds illumination changes, because the model explores the state space without any additional information of current state. In order to avoid the tracking failure, we address in this paper, Particle filter based visual tracking, in which the target appearance model is represented through an adaptive conjunction of color histogram, and space based appearance combining with velocity parameters, then the appearance models is estimated using particles whose weights, are incrementally updated for dynamic adaptation of the cue parametrization.","Particle Filter, Tracking object, Computer vision, Detecion, Appearance model",BDCA'17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang B,Myung J,Lee SG,Lee D",A MapReduce-Based Filtering Algorithm for Vector Similarity Join,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Ubiquitous Information Management and Communication,"Kota Kinabalu, Malaysia",2013,9781450319584,,https://doi.org/10.1145/2448556.2448627;http://dx.doi.org/10.1145/2448556.2448627,10.1145/2448556.2448627,"Vector Similarity Join is a fundamental operation that is utilized in data cleaning and analysis. Since most objects can be represented as feature vectors, finding similar pairs of objects is quite an important task. However, Vector Similarity Join is a heavy computational job, because its complexity is proportional to the square of the number of vectors. In order to diminish its computational load, many filtering techniques have been proposed so far. In addition to that, algorithms for distributed systems also have been researched to manage large datasets. But, the state-of-the-art studies also suffer from voluminous computations. In this paper, we propose a MapReduce algorithm that efficiently executes Vector Similarity Join. In the first stage of our algorithm, we use prefix filtering to reduce the number of candidate pairs. The second stage calculates similarities from candidate pairs of the first stage. We present candidates quantity prediction formulas to demonstrate the effectiveness of our algorithm. Experimental results show that our algorithm outperforms state-of-the-art MapReduce algorithms.","prefix filtering, vector similarity join, mapreduce algorithm",ICUIMC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Dittert N,Schelhowe H",TechSportiv: Using a Smart Textile Toolkit to Approach Young People's Physical Education,,2010,,,186–189,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Interaction Design and Children,"Barcelona, Spain",2010,9781605589510,,https://doi.org/10.1145/1810543.1810567;http://dx.doi.org/10.1145/1810543.1810567,10.1145/1810543.1810567,"Physical Education as a school subject is usually not connected to theoretical analysis and cognitive skills, even though the formal description of movements can support good performance. In this paper, we present an approach whereby construction of new and technologically enhanced equipment for sports allows young people to gain an insight into the theoretical side of specific body movements.The following describes an activity-oriented approach to investigate one's own movement and to explore formalized models of physical exercise through construction of tangible materials and computer programs. Experience with a toolkit for constructing technologically enhanced sports wear and accessories are presented.","children, physical education, construction kits, constructionism, education",IDC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhao G,Taniar D,Rahayu W,Safar M,Srinivasan B",Path Branch Points in Mobile Navigation,,2010,,,337–344,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on Advances in Mobile Computing and Multimedia,"Paris, France",2010,9781450304405,,https://doi.org/10.1145/1971519.1971574;http://dx.doi.org/10.1145/1971519.1971574,10.1145/1971519.1971574,"Most query searches on road networks are either to find objects within a certain range (range search) or to find k nearest neighbors (kNN) on the actual road network map. In this paper, we propose a novel query, that is, path branch point (PBP). PBP can be defined as given a set of candidate interest objects and a pre-defined path starts from S and end at E, find a path which starts from S, via an interest point P and ends at E. This path should overlap with the user's ad hoc (pre-defined) path as much as possible with an acceptable distance increment. This is a novel query which is motivated by users' common requirements because most users have an ad hoc path in their daily travel and can tolerate a longer driving distance to some extent if they can drive on a familiar path. In this proposed approach, an Adjust Score is calculated for each path which is determined by overlapping distance and increased distance cost. Our experiment verifies the applicability of the proposed approach to solve the queries, which involves finding the optimal path branch points.","branch point, pre-defined path, road network, nearest neighbor, path",MoMM '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhao A,Lai Y,Liu Y,Leng H",Key Frame Extraction Algorithm for Surveillance Video Based on Golden Section,,2019,,,78–81,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 International Symposium on Signal Processing Systems,"Beijing, China",2019,9781450362412,,https://doi.org/10.1145/3364908.3365296;http://dx.doi.org/10.1145/3364908.3365296,10.1145/3364908.3365296,"The traditional key frame extraction algorithm can't effectively segment the surveillance video, and it can't focus on the moving objects in the surveillance video data. In this paper, a key frame extraction algorithm based on golden section is proposed. The method first detects and tracks the moving target in the surveillance video, and calculates the entropy value of the foreground image. Secondly, the golden section in mathematical calculation is introduced to divide the sub-segment of the surveillance video, and the standard deviation of the foreground image entropy is used to measure the intra-frame similarity of the video sub-segments. If the intra-frame similarity is low, the frame at the golden section point is selected as the video key frame;if the difference within the video segment is large, golden section is continued until there is no significant difference in the video frames in all video sub-segments. in all the video sub-segments. Through experimental tests on a variety of surveillance video data and comparison with traditional algorithms, the experimental results show that the proposed algorithm effectively compresses the original surveillance video, and can extract the moving objects in the surveillance video more completely.","key frame, golden section, Surveillance video",SSPS 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hinze A,Michel Y,Eschner L",Event-Based Communication for Location-Based Service Collaboration,,2009,,,125–134,"Australian Computer Society, Inc.",AUS,,Proceedings of the Twentieth Australasian Conference on Australasian Database - Volume 92,"Wellington, New Zealand",2009,9781920682736,,,,Location-based context-aware services for mobile users need to collaborate in disparate networks. Services come and go as the user moves and no central repository is available. The user's personal information and service usage statistics need to be protected. To support service collaboration we propose a service infrastructure that relies on an event-based service-oriented architecture. We implemented a basic version of the architecture and used it for a tourism information system. An advanced version has been modelled using formal methods to evaluate privacy aspects. This paper reports about both architectures and our experiences of their application to tourism-related services.,,ADC '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Basile D,Di Giandomenico F,Gnesi S,Degano P,Ferrari GL",Specifying Variability in Service Contracts,,2017,,,20–27,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Eleventh International Workshop on Variability Modelling of Software-Intensive Systems,"Eindhoven, Netherlands",2017,9781450348119,,https://doi.org/10.1145/3023956.3023965;http://dx.doi.org/10.1145/3023956.3023965,10.1145/3023956.3023965,In Service Oriented Computing (SOC) contracts characterise the behavioural conformance of a composition of services and guarantee that the composition does not lead to spurious results. Variability features can enable services to adapt to customer requirements and to changes in the context in which they execute.We extend a recently introduced formal model of service contracts to specify variability mechanisms in a composition of services. Necessary and permitted service requests can be defined and triggered to increase adaptability. The compositional rules of the original formalism are enriched to fulfil all necessary requirements and the maximal number of permitted ones.,"services, variability, control theory",VAMOS '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Okimoto T,Schwind N,Clement M,Ribeiro T,Inoue K,Marquis P",How to Form a Task-Oriented Robust Team,,2015,,,395–403,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 2015 International Conference on Autonomous Agents and Multiagent Systems,"Istanbul, Turkey",2015,9781450334136,,,,"How to form a team for achieving a given set of tasks is an important issue in multi-agent systems. Task-oriented team formation is the problem of selecting a group of agents, where each agent is characterized by a set of capabilities; the objective is to achieve a given set of tasks, where each task is made precise by a set of capabilities necessary for managing it. Robustness (i.e., the ability to reach the goal even if some agents break down) is an expected property of a team. In this paper, the focus is laid on the Task-Oriented Robust Team Formation (TORTF) problem. A formal framework is defined and some decision and optimization problems for TORTF are pointed out. The computational complexity of TORTF is then identified. Interestingly, TORTF does not prove more computationally demanding than the task-efficient team formation problem, i.e., robustness is in some sense \for free\"". In order to solve these TORTF problems",two algorithms,ART (Algorithm for Robust Team) for the decision problem and AORT (Algorithm for Optimal Robust Team) for bi-objective constraint optimization problems,"are presented and evaluated on a number of benchmarks.""","complexity analysis, robustness, team formation, bi-objective constraint optimization",AAMAS '15,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Han C,Oh C,Shin E,Choi B",Comparing Two Methods for Acquiring 3D Data of Motion Capture System by Using PSD Camera and CCD Camera,,2009,,,558–563,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2009 International Conference on Hybrid Information Technology,"Daejeon, Korea",2009,9781605586625,,https://doi.org/10.1145/1644993.1645097;http://dx.doi.org/10.1145/1644993.1645097,10.1145/1644993.1645097,"This paper presents a monocular PSD-based motion capture system and CCD camera based system. The first system includes a PSD (Position Sensitive Detector) and active infrared (IR) LED markers that are placed on the object to be tracked. The PSD sensor is placed in the focal plane of a wide-angle lens. The microcontroller calculates the 3D position of the markers using only the measured intensity and the 2D position on the PSD. The second system includes two CCD camera and LED markers that are in hand and draw any motion trace. From the experimental results we see that the two kinds of methods for acquiring 3d data will be compare in accuracy, speed, process, methods, experimental circumstance.","disparity, PSD, motion capture, calibration, CCD",ICHIT '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Stoia L,Byron DK,Shockley DM,Fosler-Lussier E",Sentence Planning for Realtime Navigational Instructions,,2006,,,157–160,Association for Computational Linguistics,USA,,"Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers","New York, New York",2006,,,,,"In the current work, we focus on systems that provide incremental directions and monitor the progress of mobile users following those directions. Such directions are based on dynamic quantities like the visibility of reference points and their distance from the user. An intelligent navigation assistant might take advantage of the user's mobility within the setting to achieve communicative goals, for example, by repositioning him to a point from which a description of the target is easier to produce. Calculating spatial variables over a corpus of human-human data developed for this study, we trained a classifier to detect contexts in which a target object can be felicitously described. Our algorithm matched the human subjects with 86% precision.",,NAACL-Short '06,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lula P,Paliwoda-Pundefinedkosz G",An Ontology-Based Cluster Analysis Framework,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the First International Workshop on Ontology-Supported Business Intelligence,"Karlsruhe, Germany",2008,9781605582191,,https://doi.org/10.1145/1452567.1452574;http://dx.doi.org/10.1145/1452567.1452574,10.1145/1452567.1452574,"The main objectives of this paper is to propose a conceptual and software environment in which different aspects of cluster analysis of ontology-based data could be studied. The ontology-based dataset has two core components: description of categories and description of objects and relationships between them. Similarity between objects is defined as an amalgamation function of taxonomic, relationship and attribute similarity. The different measures to calculate similarity can be used. Further research is needed in order to evaluate these measures. The creation of a software tool which allows for classification of ontology-based data and comprehensive analysis of results is essential for the research in the area of ontology-based data mining. Such a tool should be universal, extensible and open. The universality manifests itself in the possibility of processing any data sets described by OWL tailored to meet individual requirements. The system extensibility means that it can be enriched with new elements without the necessity of making changes in its main elements. The openness enables the communications with other data analysis systems. In the paper theoretical aspects of cluster analysis of ontology-based data sets are presented. Next, a framework of cluster analysis system is outlined. Finally, some technical details of the system implementation are discussed.","cluster analysis, similarity measures, ontology, data analysis, data mining",OBI '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vargas S,Castells P,Vallet D",Explicit Relevance Models in Intent-Oriented Information Retrieval Diversification,,2012,,,75–84,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 35th International ACM SIGIR Conference on Research and Development in Information Retrieval,"Portland, Oregon, USA",2012,9781450314725,,https://doi.org/10.1145/2348283.2348297;http://dx.doi.org/10.1145/2348283.2348297,10.1145/2348283.2348297,"The intent-oriented search diversification methods developed in the field so far tend to build on generative views of the retrieval system to be diversified. Core algorithm components in particular redundancy assessment are expressed in terms of the probability to observe documents, rather than the probability that the documents be relevant. This has been sometimes described as a view considering the selection of a single document in the underlying task model. In this paper we propose an alternative formulation of aspect-based diversification algorithms which explicitly includes a formal relevance model. We develop means for the effective computation of the new formulation, and we test the resulting algorithm empirically. We report experiments on search and recommendation tasks showing competitive or better performance than the original diversification algorithms. The relevance-based formulation has further interesting properties, such as unifying two well-known state of the art algorithms into a single version. The relevance-based approach opens alternative possibilities for further formal connections and developments as natural extensions of the framework. We illustrate this by modeling tolerance to redundancy as an explicit configurable parameter, which can be set to better suit the characteristics of the IR task, or the evaluation metrics, as we illustrate empirically.","language models, generative models, relevance models, diversity",SIGIR '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Koo D,Rho YH,Lo H,Ames N,Wang Y,Raiti J",Methods of Identifying Touched Areas Have Been Wiped Properly,,2021,,,115–116,Association for Computing Machinery,"New York, NY, USA",,The 14th PErvasive Technologies Related to Assistive Environments Conference,"Corfu, Greece",2021,9781450387927,,https://doi.org/10.1145/3453892.3464896;http://dx.doi.org/10.1145/3453892.3464896,10.1145/3453892.3464896,"According to the CDC, COVID-19 most commonly spreads during close contact. Although the cleaners are disinfecting the public places where they are expected to have been contacted, it is still difficult to know exactly which areas have been touched and wiped out. We devised combined methods of detecting touched and wiped areas by people, using both thermal and imaging cameras. It detects the changes of temperature when people touched or wiped in about 3 seconds. To improve the accuracy, we utilize object recognition for humans from imaging cameras as a method of filtering. All marks are tracked and calculated, to disclose which areas are still remaining as touched areas, revealing the information to anyone who wants to know.","Object detection, Thermal image processing, Image recognition",PETRA 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mohamed HH,Belaid S,Naanaa W,Romdhane LB",Deep Sparse Dictionary-Based Representation for 3D Non-Rigid Shape Retrieval,,2021,,,1070–1077,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 36th Annual ACM Symposium on Applied Computing,"Virtual Event, Republic of Korea",2021,9781450381048,,https://doi.org/10.1145/3412841.3441984;http://dx.doi.org/10.1145/3412841.3441984,10.1145/3412841.3441984,"In this paper, we address the problem of non-rigid 3D shape retrieval. The proposed method extract high-level features that are invariant to non-rigid shape deformations by integrating deep dictionary learning and a sparse coding approach. A stacked sparse coding network is constructed to achieve a multiple layers dictionary learning instead of a single level dictionary learning. Then, for a given 3D query, a 3D shape descriptor is calculated, providing a multi-scale shape representations. This descriptor is, therefore, used to access deep learned dictionary. The proposed method is validated on two benchmarks, namely Shrec'11 and Shrec'15, for 3D non-rigid object retrieval and compared with existing deep learning-based approaches.","non-rigid 3D shape retrieval, sparse coding, deep learning, deep sparse descriptor, dictionary leaning",SAC '21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Feng L,Wei L,Yang L,He X,Zhou J",Modeling and Simulation of Spectrometer Based on Prism,,2019,,,132–135,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 8th International Conference on Software and Information Engineering,"Cairo, Egypt",2019,9781450361057,,https://doi.org/10.1145/3328833.3328880;http://dx.doi.org/10.1145/3328833.3328880,10.1145/3328833.3328880,"An imaging spectrometer is an optical device that can simultaneously acquire the spectral and spatial characteristics of the target. The dispersive spectrometer based on prism is one of the most widely used techniques in remote sensing because of its structural stability and low cost. Based on optical theory, the imaging characteristics of curved prism are deduced. The numerical modeling of system is constructed by Fermat's principle and ray tracing. By calculating the intersection position of ray with the surface of each element, the intersection position with the image plane is finally obtained. Thus, the implicit function relationship between image points and object points of the system is established, which has certain significance for the theoretical simulation.","simulation, Spectrometer, curved prism",ICSIE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kreitzberg CB,Swanson L",A Cognitive Model for Structuring an Introductory Programming Curriculum,,1974,,,307–311,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the May 6-10, 1974, National Computer Conference and Exposition","Chicago, Illinois",1974,9781450379205,,https://doi.org/10.1145/1500175.1500240;http://dx.doi.org/10.1145/1500175.1500240,10.1145/1500175.1500240,"From its inception the electronic digital computer has been involved in education, although its role has been the subject of some debate. Academically, the computer has been used as a device for conducting or augmenting instruction, as a calculating device adjunctive to courses in engineering and the sciences, and most recently as an object for study in its own right. Increasing attention is now being focused on undergraduate training in computer use, partly as a result of the recommendation of the President's Science Advisory Committee that computing education be provided to all college undergraduates. We can expect that the number of students who undertake incidental study of programming as a part of their undergraduate curricula will continue to increase rapidly.",,AFIPS '74,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Feng J,Gu X",Based on Community Discovery and Community Similarity Research on Evolution of Deep Learning,,2019,,,314–319,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 International Conference on Artificial Intelligence and Computer Science,"Wuhan, Hubei, China",2019,9781450371506,,https://doi.org/10.1145/3349341.3349423;http://dx.doi.org/10.1145/3349341.3349423,10.1145/3349341.3349423,"In recent years, the emerging discipline of deep learning has been widely applied in various fields such as driverless, image processing and so on. Clearing up the development context and research status of the domestic deep learning field will help the researcher to indicate the future research direction and improve the domestic deep learning discipline structure. This paper takes 11652 deep learning literatures collected by CNKI in the past fifteen years as the research object, and uses the Fast Unfolding community discovery algorithm to divide the community of the common word network which composed of keywords in the literature, calculate the Z-Value value of the nodes in the community, and find the community theme, and proposed a community similarity method combined with core nodes. Finally, it determined the evolution relationship by calculating the similarity between communities in different time slices. The analysis of community evolution relationship maps summarizes that the current research focus of deep learning is mainly on the application of deep learning to other fields and the improvement of deep learning algorithms and the introduction of new neural network models.","community similarity, deep learning, discipline topics evolution, community discovery algorithm",AICS 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Swamy N,Hriţcu C,Keller C,Rastogi A,Delignat-Lavaud A,Forest S,Bhargavan K,Fournet C,Strub PY,Kohlweiss M,Zinzindohoue JK,Zanella-Béguelin S",Dependent Types and Multi-Monadic Effects in F*,,2016,,,256–270,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"St. Petersburg, FL, USA",2016,9781450335492,,https://doi.org/10.1145/2837614.2837655;http://dx.doi.org/10.1145/2837614.2837655,10.1145/2837614.2837655,"We present a new, completely redesigned, version of F*, a language that works both as a proof assistant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F* is a dependently typed, higher-order, call-by-value language with _primitive_ effects including state, exceptions, divergence and IO. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F* uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of SMT solving and manual proofs. Isolated from the effects, the core of F* is a language of pure functions used to write specifications and proof terms---its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F* we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F* is programmed (but not verified) in F*, and bootstraps in both OCaml and F#. Our experience confirms F*'s pay-as-you-go cost model: writing idiomatic ML-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F* is in verifying several key modules in an implementation of the TLS-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F* than in a prior verified implementation of TLS-1.2. Finally, as a proof assistant, we discuss our use of F* in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to System F-omega and even micro-F*, a sizeable fragment of F* itself---these proofs make essential use of F*'s flexible combination of SMT automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.","effectful programming, verification, proof assistants",POPL '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Swamy N,Hriţcu C,Keller C,Rastogi A,Delignat-Lavaud A,Forest S,Bhargavan K,Fournet C,Strub PY,Kohlweiss M,Zinzindohoue JK,Zanella-Béguelin S",Dependent Types and Multi-Monadic Effects in F*,SIGPLAN Not.,2016,51,1,256–270,Association for Computing Machinery,"New York, NY, USA",,,,2016-01,,0362-1340,https://doi.org/10.1145/2914770.2837655;http://dx.doi.org/10.1145/2914770.2837655,10.1145/2914770.2837655,"We present a new, completely redesigned, version of F*, a language that works both as a proof assistant as well as a general-purpose, verification-oriented, effectful programming language. In support of these complementary roles, F* is a dependently typed, higher-order, call-by-value language with _primitive_ effects including state, exceptions, divergence and IO. Although primitive, programmers choose the granularity at which to specify effects by equipping each effect with a monadic, predicate transformer semantics. F* uses this to efficiently compute weakest preconditions and discharges the resulting proof obligations using a combination of SMT solving and manual proofs. Isolated from the effects, the core of F* is a language of pure functions used to write specifications and proof terms---its consistency is maintained by a semantic termination check based on a well-founded order. We evaluate our design on more than 55,000 lines of F* we have authored in the last year, focusing on three main case studies. Showcasing its use as a general-purpose programming language, F* is programmed (but not verified) in F*, and bootstraps in both OCaml and F#. Our experience confirms F*'s pay-as-you-go cost model: writing idiomatic ML-like code with no finer specifications imposes no user burden. As a verification-oriented language, our most significant evaluation of F* is in verifying several key modules in an implementation of the TLS-1.2 protocol standard. For the modules we considered, we are able to prove more properties, with fewer annotations using F* than in a prior verified implementation of TLS-1.2. Finally, as a proof assistant, we discuss our use of F* in mechanizing the metatheory of a range of lambda calculi, starting from the simply typed lambda calculus to System F-omega and even micro-F*, a sizeable fragment of F* itself---these proofs make essential use of F*'s flexible combination of SMT automation and constructive proofs, enabling a tactic-free style of programming and proving at a relatively large scale.","effectful programming, proof assistants, verification",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Amro B,Saygin Y,Levi A",PA-CTM: Privacy Aware Collaborative Traffic Monitoring System Using Autonomous Location Update Mechanism,,2011,,,1–8,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th ACM SIGSPATIAL International Workshop on Security and Privacy in GIS and LBS,"Chicago, Illinois",2011,9781450310321,,https://doi.org/10.1145/2071880.2071882;http://dx.doi.org/10.1145/2071880.2071882,10.1145/2071880.2071882,"Collaborative Traffic Monitoring (CTM) systems exploit the location information continuously collected from vehicles. Users collaborate by providing their location information to have a global picture of the current traffic in real-time. However, location information is very sensitive information that made privacy a major obstacle for the widespread usage of CTM systems. Some of these systems depend on periodic location updates, where a vehicle updates location periodically [1]; other systems trigger update at particular regions [2], or with random time periods [3]. For privacy issues, these systems rely on a trusted third party for enforcing a predetermined privacy level. They may also generate low quality data because of the low precision in both time and space [4]. In this paper, we present a privacy aware collaborative traffic monitoring system, PA-CTM, where moving objects send their location updates to a traffic server, the latter then processes current data and provides its users with current traffic status. Users authenticate themselves to traffic server using pseudonyms that are changed according to user's privacy preferences. PA-CTM deploys two mechanisms for enhancing privacy, the first mechanism is the use of pseudonyms (to authenticate to the traffic server) to hide real identities, and changing these pseudonyms to hide trajectory information from the traffic server. Users can control their privacy by frequently changing their pseudonyms and hence become anonymous to traffic server. The second privacy enhancement technique in PA-CTM is the use of a novel autonomous location update mechanism, ALUM. In ALUM, location update is performed according to moving objects' behavior (change in speed or direction) without the need to a trusted third party. Unlike state-of-the art techniques, ALUM does not require a trusted third-party for triggering vehicles to update their locations. We utilized the existence of location prediction errors to calculate the region where a particular vehicle is expected to be in and hence to calculate anonymity level at that region. We compared ALUM against periodic and random silent period update mechanisms and it showed better privacy results in terms of k-anonymity metric.","anonymity, location based services, privacy, collaborative traffic monitoring systems, precision error, traffic monitoring",SPRINGL '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Endo AT,Bernardino M,Rodrigues EM,Simao A,de Oliveira FM,Zorzo AF,Saad R",An Industrial Experience on Using Models to Test Web Service-Oriented Applications,,2013,,,240–249,Association for Computing Machinery,"New York, NY, USA",,Proceedings of International Conference on Information Integration and Web-Based Applications & Services,"Vienna, Austria",2013,9781450321136,,https://doi.org/10.1145/2539150.2539188;http://dx.doi.org/10.1145/2539150.2539188,10.1145/2539150.2539188,"Service-oriented architectures and Web services have been widely adopted by enterprises to pervade integration among software systems. As reliable services are essential to assure that these systems work correctly, formal and systematic testing should be performed. This paper reports the application of a model-based approach to test Web services in the context of real-world applications of a multinational computer technology corporation. The employed approach is called ESG4WSC, in which an event-driven model is provided to support modeling and test case generation, as well as an environment to support the concretization and test execution.","model based testing, event sequence graph, service composition, experience report",IIWAS '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Deng F,Siersdorfer S,Zerr S",Efficient Jaccard-Based Diversity Analysis of Large Document Collections,,2012,,,1402–1411,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Maui, Hawaii, USA",2012,9781450311564,,https://doi.org/10.1145/2396761.2398445;http://dx.doi.org/10.1145/2396761.2398445,10.1145/2396761.2398445,"We propose two efficient algorithms for exploring topic diversity in large document corpora such as user generated content on the social web, bibliographic data, or other web repositories. Analyzing diversity is useful for obtaining insights into knowledge evolution, trends, periodicities, and topic heterogeneity of such collections. Calculating diversity statistics requires averaging over the similarity of all object pairs, which, for large corpora, is prohibitive from a computational point of view. Our proposed algorithms overcome the quadratic complexity of the average pair-wise similarity computation, and allow for constant time (depending on dataset properties) or linear time approximation with probabilistic guarantees. We show examples of diversity-based studies on large samples from corpora such as the social photo sharing site Flickr, the DBLP bibliography, and US Census data.","clustering, jaccard, diversity",CIKM '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mao D,Jie L",Streak Image Compression,,2020,,,450–454,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 International Conference on Aviation Safety and Information Technology,"Weihai City, China",2020,9781450375764,,https://doi.org/10.1145/3434581.3434632;http://dx.doi.org/10.1145/3434581.3434632,10.1145/3434581.3434632,"This Streak image contains a lot of noise signals and it is not easy to accurately detect the target signal position. This article gives a method of determining target signal region and achieving streak image compression, which uses multi-resolution wavelet denoising and detecting target signal considering its overall continuous distribution as a rule and using the stepped-like piecewise function of range as the detection object. In target signal region, convolution filtering is used to detect the peaks, and then the three-dimensional image is calculated. Experiments show that the method can reduce the scale of data for computing, improve the quality of generating point cloud data and reconstruct 3D images more accurately.","stepped-like piecewise function, target signal, Streak image compression, overall continuous distribution",ICASIT 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Khryashchev VV,Stepanova OA,Lebedev AA,Kashin SV,Kuvaev RO",Deep Learning for Gastric Pathology Detection in Endoscopic Images,,2019,,,90–94,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 3rd International Conference on Graphics and Signal Processing,"Hong Kong, Hong Kong",2019,9781450371469,,https://doi.org/10.1145/3338472.3338492;http://dx.doi.org/10.1145/3338472.3338492,10.1145/3338472.3338492,"Computer-aided diagnosis of cancer based on endoscopic image analysis is a promising area in the field of computer vision and machine learning. Convolutional neural networks are one of the most popular approaches in endoscopic image analysis. This paper presents the algorithm of pathology detection in endoscopic images of gastric lesions based on convolutional neural network. Training and testing of the algorithm was carried out on the NVIDIA DGX-1 supercomputer using endoscopic images from the test base, assembled together with the Yaroslavl Regional Cancer Hospital. As a result of experiments, the mAP metric was calculated and the value was 0.875, which is a high result for the task of object detection in images.","convolution neural network, gastric cancer, Machine learning, endoscopic image analysis",ICGSP '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gao K,Zhang P,Liu Y,Zhou Z,Yang G,Lu H",Deep Mutual Learning for Visual Tracking,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM Turing Celebration Conference - China,"Chengdu, China",2019,9781450371582,,https://doi.org/10.1145/3321408.3323927;http://dx.doi.org/10.1145/3321408.3323927,10.1145/3321408.3323927,"In this work, we propose a novel deep learning method to improve the accuracy and the speed of particle filter based object trackers. The main contributions include two aspects. First, to enhance the discrimination of feature representations, we propose two identical CNNs, each of which shares information from the other by introducing the Kullback-Leibler (KL) loss. Second, in order to boost the speed of trackers, we introduce the region of interest (ROI) align, and optimize the structure-identical networks with knowledge distillation and deep mutual learning. It makes the forward propagation only calculate once instead of hundreds of iterations. Experimental results on the OTB2015 and VOT2015 benchmarks demonstrate that our method performs better than several state-of-the-art algorithms.","knowledge distillation, particle filter object tracking, deep mutual learning",ACM TURC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Batory D,Höfner P,Kim J","Feature Interactions, Products, and Composition",,2011,,,13–22,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th ACM International Conference on Generative Programming and Component Engineering,"Portland, Oregon, USA",2011,9781450306898,,https://doi.org/10.1145/2047862.2047867;http://dx.doi.org/10.1145/2047862.2047867,10.1145/2047862.2047867,"The relationship between feature modules and feature interactions is not well-understood. To explain classic examples of feature interaction, we show that features are not only composed sequentially, but also by cross-product and interaction operations that heretofore were implicit in the literature. Using the Colored IDE (CIDE) tool as our starting point, we (a) present a formal model of these operations, (b) show how it connects and explains previously unrelated results in Feature Oriented Software Development (FOSD), and (c) describe a tool, based on our formalism, that demonstrates how changes in composed documents can be back-propagated to their original feature module definitions, thereby improving FOSD tooling.","fosd, back-propagation, feature interaction, cide, feature products",GPCE '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Batory D,Höfner P,Kim J","Feature Interactions, Products, and Composition",SIGPLAN Not.,2011,47,3,13–22,Association for Computing Machinery,"New York, NY, USA",,,,2011-10,,0362-1340,https://doi.org/10.1145/2189751.2047867;http://dx.doi.org/10.1145/2189751.2047867,10.1145/2189751.2047867,"The relationship between feature modules and feature interactions is not well-understood. To explain classic examples of feature interaction, we show that features are not only composed sequentially, but also by cross-product and interaction operations that heretofore were implicit in the literature. Using the Colored IDE (CIDE) tool as our starting point, we (a) present a formal model of these operations, (b) show how it connects and explains previously unrelated results in Feature Oriented Software Development (FOSD), and (c) describe a tool, based on our formalism, that demonstrates how changes in composed documents can be back-propagated to their original feature module definitions, thereby improving FOSD tooling.","feature interaction, feature products, back-propagation, fosd, cide",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Constantin C,Amann B",Usage-Based Ranking of Distributed XML Data,,2008,,,1008–1012,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Symposium on Applied Computing,"Fortaleza, Ceara, Brazil",2008,9781595937537,,https://doi.org/10.1145/1363686.1363920;http://dx.doi.org/10.1145/1363686.1363920,10.1145/1363686.1363920,"In this article we consider the issue of ranking XML data and data sources in a distributed XML data warehouse. Our ranking model applies to service-oriented data management applications where web services store and exchange XML fragments. Each service publishes a set of operations implemented as parameterized queries on a local XML data warehouse integrating locally generated data and query results received from other services. We propose a new way for ranking distributed data and data sources taking into consideration their usage for the evaluation of queries. The main results are a formal ranking model of data, queries and services and an implementation on a data warehouse.","XML, query, ranking",SAC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Satuluri V,Parthasarathy S",Bayesian Locality Sensitive Hashing for Fast Similarity Search,Proc. VLDB Endow.,2012,5,5,430–441,VLDB Endowment,,,,,2012-01,,2150-8097,https://doi.org/10.14778/2140436.2140440;http://dx.doi.org/10.14778/2140436.2140440,10.14778/2140436.2140440,"Given a collection of objects and an associated similarity measure, the all-pairs similarity search problem asks us to find all pairs of objects with similarity greater than a certain user-specified threshold. Locality-sensitive hashing (LSH) based methods have become a very popular approach for this problem. However, most such methods only use LSH for the first phase of similarity search - i.e. efficient indexing for candidate generation. In this paper, we present BayesLSH, a principled Bayesian algorithm for the subsequent phase of similarity search - performing candidate pruning and similarity estimation using LSH. A simpler variant, BayesLSH-Lite, which calculates similarities exactly, is also presented. Our algorithms are able to quickly prune away a large majority of the false positive candidate pairs, leading to significant speedups over baseline approaches. For BayesLSH, we also provide probabilistic guarantees on the quality of the output, both in terms of accuracy and recall. Finally, the quality of BayesLSH's output can be easily tuned and does not require any manual setting of the number of hashes to use for similarity estimation, unlike standard approaches. For two state-of-the-art candidate generation algorithms, AllPairs and LSH, BayesLSH enables significant speedups, typically in the range 2x-20x for a wide variety of datasets.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Fang Y,Zou C,Chien AA",Accelerating Raw Data Analysis with the ACCORDA Software and Hardware Architecture,Proc. VLDB Endow.,2019,12,11,1568–1582,VLDB Endowment,,,,,2019-07,,2150-8097,https://doi.org/10.14778/3342263.3342634;http://dx.doi.org/10.14778/3342263.3342634,10.14778/3342263.3342634,"The data science revolution and growing popularity of data lakes make efficient processing of raw data increasingly important. To address this, we propose the ACCelerated Operators for Raw Data Analysis (ACCORDA) architecture. By extending the operator interface (subtype with encoding) and employing a uniform runtime worker model, ACCORDA integrates data transformation acceleration seamlessly, enabling a new class of encoding optimizations and robust high-performance raw data processing. Together, these key features preserve the software system architecture, empowering state-of-art heuristic optimizations to drive flexible data encoding for performance. ACCORDA derives performance from its software architecture, but depends critically on the acceleration of the Unstructured Data Processor (UDP) that is integrated into the memory-hierarchy, and accelerates data transformation tasks by 16x-21x (parsing, decompression) to as much as 160x (deserialization) compared to an x86 core.We evaluate ACCORDA using TPC-H queries on tabular data formats, exercising raw data properties such as parsing and data conversion. The ACCORDA system achieves 2.9x-13.2x speedups when compared to SparkSQL, reducing raw data processing overhead to a geomean of 1.2x (20%). In doing so, ACCORDA robustly matches or outperforms prior systems that depend on caching loaded data, while computing on raw, unloaded data. This performance benefit is robust across format complexity, query predicates, and selectivity (data statistics). ACCORDA's encoding-extended operator interface unlocks aggressive encoding-oriented optimizations that deliver 80% average performance increase over the 7 affected TPC-H queries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gestwicki P,McNely B",Interdisciplinary Projects in the Academic Studio,ACM Trans. Comput. Educ.,2016,16,2,,Association for Computing Machinery,"New York, NY, USA",,,,2016-03,,,https://doi.org/10.1145/2732157;http://dx.doi.org/10.1145/2732157,10.1145/2732157,"We define and describe the academic studio model for interdisciplinary, undergraduate, project-oriented education. This model brings faculty, students, and community partners together to investigate an open-ended academic question, and their collaboration yields an original product that represents their inquiry. The academic studio integrates agile software development practice, project-oriented pedagogy, and sociocultural cognition theories. Scrum provides the framework in which self-organizing, cross-functional teams define their methodology, and Scrum practices facilitate assessment of student learning outcomes.This model emerged from design-based research across six studio instances, each of which investigated the relationship of fun, games, and learning through the development of educational video games. Formal and informal analysis of these instances gives rise to several themes, including the importance of a formalized process to encourage learning and productivity, the critical role of an expert faculty mentor, the need to combine academic and industrial practice to manage the inherent challenges of collaborative software development, and the unique characteristics of learning outcomes arising from this model. We conclude that the academic studio model is beneficial to student learning and faculty development, and we encourage the adoption, adaptation, and evaluation of the model.","Higher education, sociocultural cognition theory, design-based research, computer science education, interdisciplinary education, Scrum, project-based learning",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Truong QT,Salah A,Lauw HW",Bilateral Variational Autoencoder for Collaborative Filtering,,2021,,,292–300,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th ACM International Conference on Web Search and Data Mining,"Virtual Event, Israel",2021,9781450382977,,https://doi.org/10.1145/3437963.3441759;http://dx.doi.org/10.1145/3437963.3441759,10.1145/3437963.3441759,"Preference data is a form of dyadic data, with measurements associated with pairs of elements arising from two discrete sets of objects. These are users and items, as well as their interactions, e.g., ratings. We are interested in learning representations for both sets of objects, i.e., users and items, to predict unknown pairwise interactions. Motivated by the recent successes of deep latent variable models, we propose Bilateral Variational Autoencoder (BiVAE), which arises from a combination of a generative model of dyadic data with two inference models, user- and item-based, parameterized by neural networks. Interestingly, our model can take the form of a Bayesian variational autoencoder either on the user or item side. As opposed to the vanilla VAE model, BiVAE is \bilateral''",in that users and items are treated similarly,making it more apt for two-way or dyadic data. While theoretically sound,we formally show that,similarly to VAE,our model might suffer from an over-regularized latent space. This issue,known as posterior collapse in the VAE literature,may appear due to assuming an over-simplified prior (isotropic Gaussian) over the latent space. Hence,we further propose a mitigation of this issue by introducing constrained adaptive prior (CAP) for learning user- and item-dependent prior distributions. Empirical results on several real-world datasets show that the proposed model outperforms conventional VAE and other comparative collaborative filtering models in terms of item recommendation. Moreover,"the proposed CAP further boosts the performance of BiVAE. An implementation of BiVAE is available on Cornac recommender library.""","collaborative filtering, dyadic data, variational autoencoder",WSDM '21,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Abeywickrama DB,Ramakrishnan S","Context-Aware Services Engineering: Models, Transformations, and Verification",ACM Trans. Internet Technol.,2012,11,3,,Association for Computing Machinery,"New York, NY, USA",,,,2012-02,,1533-5399,https://doi.org/10.1145/2078316.2078318;http://dx.doi.org/10.1145/2078316.2078318,10.1145/2078316.2078318,"Context-aware Web services are identified as an important technology to support new applications on the future Internet. Context information has several qualities that make the development of these services challenging, compared to conventional, Web services. Therefore, sound software engineering practices are needed during their development and execution. This article discusses a novel software engineering-based approach, which leverages the benefits of model-driven architecture, aspect-oriented modeling, and formal model checking, for modeling and verifying context-aware services. The approach is explored using a real-world case study in intelligent transport. An evaluation framework is established to validate the main methods and tools employed.","software engineering, software architecture, context-aware services, model-driven development, Aspect-oriented modeling, model checking",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Barkaoui K,Eslamichalandar M,Kaabachi M",A Structural Verification of Web Services Composition Compatibility,,2010,,,30–41,CEUR-WS.org,"Aachen, DEU",,Proceedings of the 6th International Workshop on Enterprise & Organizational Modeling and Simulation,"Hammamet, Tunisia",2010,9781450304634,,,,"A fundamental feature of service oriented computing is that simple services need to be composed for generating complex services. This work focuses on the analysis and verification of behavior models of web services composition. In particular, we have to check that neither deadlock nor livelock occurs in this composition. Usually, the verification of such integration, with or without mediators, is achieved by using techniques based on state space exploration of a given service formal model. In this paper, we present an approach based on structure theory of Petri nets allowing the recognition of necessary and/or sufficient conditions ensuring compatible composition and a better understanding of the incompatibility sources.","structure theory of Petri nets, compatibility, web service composition",EOMAS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lee CY,Kao TL,Wang KS",Implementation of a Robotic Arm with 3D Vision for Shoes Glue Spraying System,,2018,,,562–565,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 2nd International Conference on Computer Science and Artificial Intelligence,"Shenzhen, China",2018,9781450366069,,https://doi.org/10.1145/3297156.3297171;http://dx.doi.org/10.1145/3297156.3297171,10.1145/3297156.3297171,"Traditionally, the 3D vision guidance and robotic arm are integrated for a stationary object recognition and grasping. In the paper, an automatic glue spray system of shoes is developed for the cementing process. The system consists of a structured light module and a glue spray robot. In the beginning, the structured light scans a shoe from different angles to obtain the partial 3D model. And, a whole shoe model is created. On the other hand, a camera takes pictures of a shoe from different angles to detect the target area. In the target area, the normal vector is calculated by 3D point cloud data. And, the normal vector provides the information to the glue spray robot. Then, the path planning is given and the cementing process is well done.","Vision guidance, Robotic arm, Structured light",CSAI '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Du T,Qu S,Hua Z",A Novel Timing Series Calculation Algorithm Based on Statistical Extremum for Process Object,,2017,,,94–98,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th International Conference on Computer and Automation Engineering,"Sydney, Australia",2017,9781450348096,,https://doi.org/10.1145/3057039.3057058;http://dx.doi.org/10.1145/3057039.3057058,10.1145/3057039.3057058,"In this paper, an algorithm for computing timing series among process objects is proposed. The algorithm is designed based on statistical time distance among extremum points of sampling data set which is collected from process industry, and the delay time between any two production links can be calculated, and then the timing series between any two links can be obtained. By a series of experiments, the validity of this algorithm is proved that the algorithm can obtain the delay time interval among production links and the timing series of these links can be calculated.","Statistical Extremum, Timing series calculation, Process Object",ICCAE '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gardner PA,Smith GD,Wheelhouse MJ,Zarfaty UD",Local Hoare Reasoning about DOM,,2008,,,261–270,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Twenty-Seventh ACM SIGMOD-SIGACT-SIGART Symposium on Principles of Database Systems,"Vancouver, Canada",2008,9781605581521,,https://doi.org/10.1145/1376916.1376953;http://dx.doi.org/10.1145/1376916.1376953,10.1145/1376916.1376953,"The W3C Document Object Model (DOM) specifies an XML update library. DOM is written in English, and is therefore not compositional and not complete. We provide a first step towards a compositional specification of DOM. Unlike DOM, we are able to work with a minimal set of commands and obtain a complete reasoning for straight-line code. Our work transfers O'Hearn, Reynolds and Yang's local Hoare reasoning for analysing heaps to XML, viewing XML as an in-place memory store as does DOM. In particular, we apply recent work by Calcagno, Gardner and Zarfaty on local Hoare reasoning about simple tree update to this real-world DOM application. Our reasoning not only formally specifies a significant subset of DOM Core Level 1, but can also be used to verify, for example, invariant properties of simple Javascript programs.","xml, dom, local hoare reasoning, context logic",PODS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Khan A,Mordatch I,Fitzmaurice G,Matejka J,Kurtenbach G",ViewCube: A 3D Orientation Indicator and Controller,,2008,,,17–25,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 Symposium on Interactive 3D Graphics and Games,"Redwood City, California",2008,9781595939838,,https://doi.org/10.1145/1342250.1342253;http://dx.doi.org/10.1145/1342250.1342253,10.1145/1342250.1342253,"Literally hundreds of thousands of users of 2D computer-aided design (CAD) tools are in the difficult process of transitioning to 3D CAD tools. A common problem for these users is disorientation in the abstract virtual 3D environments that occur while developing new 3D scenes. To help address this problem, we present a novel in-scene 3D widget called the ViewCube as a 3D orientation indicator and controller. The ViewCube is a cube-shaped widget placed in a corner of the window. When acting as an orientation indicator, the ViewCube turns to reflect the current view direction as the user re-orients the scene using other tools. When used as an orientation controller, the ViewCube can be dragged, or the faces, edges, or corners can be clicked on, to easily orient the scene to the corresponding view. We conducted a formal experiment to measure the performance of the ViewCube comparing: (1) ArcBall-style dragging using the ViewCube for manual view switching, (2) clicking on face/edge/corner elements of the ViewCube for automated view switching and (3) clicking on a dedicated row of buttons for automated view switching. The results indicate that users prefer and are almost twice as fast at using the ViewCube with dragging compared to clicking techniques, independent of a number of ViewCube representations that we examined.","desktop 3D environments, 3D navigation, 3D widgets, virtual camera",I3D '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Akram H,Pascal B,Thierry G",Controlled Stochastic Petri Net Model for End-to-End Network QoS Provisioning in Middleware-Based Multimedia and Real-Time Systems,,2011,,,111–118,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 44th Annual Simulation Symposium,"Boston, Massachusetts",2011,9781930638563,,,,"End-to-end quality of service (QoS) is central to the objectives of the today's networks requirements of middleware based distributed real-time and embedded (DRE) systems. Any middleware based QoS system should be totally oriented to this goal, and in the scope of this purpose several mechanisms, components and approaches were, are being and will be developed in order to achieve it. In this paper, we show how controlled behavior of such QoS-aware systems can be developed based on stochastic Petri Nets. Afterwards, We show how to obtain, using such an interpreted formal model, powerful numerical analysis for the management of the network QoS.","quality of service, heterogeneous networks, controlled SPN, multimedia system",ANSS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Muthusamy V,Jacobsen HA",SLA-Driven Distributed Application Development,,2008,,,31–36,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd Workshop on Middleware for Service Oriented Computing,"Leuven, Belgium",2008,9781605583686,,https://doi.org/10.1145/1462802.1462808;http://dx.doi.org/10.1145/1462802.1462808,10.1145/1462802.1462808,"The management of Service Level Agreements (SLA) in the development of business processes in a Service Oriented Architecture (SOA) often requires much manual and errorprone effort by all parties throughout the lifecycle of the processes. The formal specification of SLAs into development tools can simplify some of this effort. In particular, the runtime provisioning and monitoring of processes can be achieved by an autonomic system that adapts to changing conditions to maintain the SLA's goals. A cost model allows the efficient execution and monitoring of processes, based on a declarative, user-specified optimality function. Experiments demonstrate that the system can indeed adapt to changing workload conditions, saving roughly 70% of the network bandwidth in one particular experiment.","service oriented architecture, service level agreement",MW4SOC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Apvrille L,de Saqui-Sannes P",Adding a Methodological Assistant to a Protocol Modeling Environment,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on New Technologies in Distributed Systems,"Lyon, France",2008,9781595939371,,https://doi.org/10.1145/1416729.1416745;http://dx.doi.org/10.1145/1416729.1416745,10.1145/1416729.1416745,"The use of protocol design toolkits based on UML profiles has been hampered by the lack of methodological support. Indeed, those toolkits should include an assistant based on patterns and dedicated to driving the designer step by step through a well defined methodology. Thus, the TURTLE UML profile is extended with widely accepted service and protocol-oriented patterns. These patterns are built upon UML analysis diagrams i.e. use case, interaction overview and sequence diagrams. Moreover, all these patterns and diagrams have a formal semantics. Finally, they have been implemented in TTool, the open-source toolkit supporting TURTLE. The proposed approach remains general and may be applied to various modeling languages and use-case analysis driven processes.","scenarios, protocols, UML, patterns, use cases, formal verification",NOTERE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li X,Parsons J",Ontological Semantics for the Use of UML in Conceptual Modeling,,2007,,,179–184,"Australian Computer Society, Inc.",AUS,,"Tutorials, Posters, Panels and Industrial Contributions at the 26th International Conference on Conceptual Modeling - Volume 83","Auckland, New Zealand",2007,9781920682644,,,,"Despite its origins in software modeling, there has been growing interest in using the Unified Modeling Language (UML) for conceptual modeling of application domains. However, the UML has many constructs that are purely software oriented. Consequently, the suitability of the UML for modeling \real world\"" phenomena has been questioned. This research aims to assign real-world semantics to a core set of UML constructs by proposing a set of principles for mapping these constructs to the formal ontology of Mario Bunge","which has been widely used in information systems modeling contexts. We conclude by outlining how the proposed principles can be evaluated in terms of their effectiveness in supporting conceptual modeling using UML.""","conceptual modeling, ontology, UML",ER '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vaiapury K,Aksay A,Izquierdo E",GrabcutD: Improved Grabcut Using Depth Information,,2010,,,57–62,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ACM Workshop on Surreal Media and Virtual Cloning,"Firenze, Italy",2010,9781450301756,,https://doi.org/10.1145/1878083.1878099;http://dx.doi.org/10.1145/1878083.1878099,10.1145/1878083.1878099,"Popular state of the art segmentation methods such as Grab cut include a matting technique to calculate the alpha values for boundaries of segmented regions. Conventional Grabcut relies only on color information to achieve segmentation. Recently, there have been attempts to improve Grabcut using motion in video sequences. However, in stereo or multi-view analysis, there is additional information that could be also used to improve segmentation. Clearly, depth based approaches bear the potential discriminative power of ascertaining whether the object is nearer of farer. In this work, we propose and evaluate a Grabcut segmentation technique based on combination of color and depth information. We show the usefulness of the approach when stereo information is available and evaluate it using standard datasets against state of the art results.","improved grabcut, depth, silhouette, segmentation",SMVC '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tan M,Song Y",Research on the Topic Mining of Learners' Interest Based on the Mongolian MOOC Platform Course Discussion Text,,2021,,,1563–1567,Association for Computing Machinery,"New York, NY, USA",,"2021 2nd International Conference on Computers, Information Processing and Advanced Education","Ottawa, ON, Canada",2021,9781450389969,,https://doi.org/10.1145/3456887.3459721;http://dx.doi.org/10.1145/3456887.3459721,10.1145/3456887.3459721,"At present, one of the key directions of MOOC research is to meet the individual learning needs of learners, while the focus of personalized learning is to model learners’ interest in learning, and whether the model can accurately reflect learners’ interest and admiration plays a central role in the lesson recommendation mechanism. This research takes \Introduction to Computer\"" course of the Mongolian MOOC platform as the research object",and discovers the topics of interest of the learners by digging the content of the course discussion area. First,after crawling the content of the discussion area,the text needs to be preprocessed,including encoding conversion,text proofreading,removing stop words,and removing affixes; secondly,the discussion text is described by the vector space model,and the keywords and their weights are calculated by the TF-IDF algorithm; finally,the semantic similarity of keywords is calculated through the cosine formula,and after clustering,the topics of interest of the learners are obtained. The experimental results show that the learner's reason for choosing a course is related to three themes,namely the content of the course,"the teaching method and the learning experience.""","Mongolian, Interest modeling, topic mining, similarity calculation",CIPAE 2021,,,,,,,,,,,,,,,,
1,Conference Paper,"Woop S,Áfra AT,Benthin C",STBVH: A Spatial-Temporal BVH for Efficient Multi-Segment Motion Blur,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of High Performance Graphics,"Los Angeles, California",2017,9781450351010,,https://doi.org/10.1145/3105762.3105779;http://dx.doi.org/10.1145/3105762.3105779,10.1145/3105762.3105779,"We present the STBVH, a new approach for rendering multi-segment motion blur using a bounding volume hierarchy (BVH) that stores both spatial linearly interpolated bounds and temporal bounds. The approach is designed for different number of time steps per mesh or object. While separating the individual meshes using standard partitioning techniques, it performs temporal splits for locations with large or curved motion inside the meshes. Our approach uses a modified motion blur surface area heuristic (MBSAH) that calculates probabilities in the presence of spatial-temporal bounds and works on linear motion segments of primitives rather than on full motion curves. We show that our approach is able to handle challenging scenes with varying degrees of motion blur per mesh, using significantly less memory and having competitive rendering performance compared to building separate linear motion blur BVHs per global time segment.","multi-segment motion blur, BVH, ray tracing",HPG '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Singer R,Agent-Based Business Process Modeling and Execution: Steps Towards a Compiler-Virtual Machine Architecture,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on Subject-Oriented Business Process Management,"Erlangen, Germany",2016,9781450340717,,https://doi.org/10.1145/2882879.2882880;http://dx.doi.org/10.1145/2882879.2882880,10.1145/2882879.2882880,"In this paper, we propose to rethink the dominant logic of how to model and execute business processes. We think that an actor or agent, respectively Subject-oriented, based approach supports in a much better way the fundamental nature of business processes. We present a proposal for a compiler architecture to model and execute business processes without the need for a dedicated business process management system. Instead, we propose to use a general purpose virtual machine to host the processes. We also propose a concrete path for realization based on the Erlang/Elixir solution system. We also discuss a method to define business processes as a set of formal natural language sentences.","Compiler, BPM, Virtual Machine, Metaprogramming",S-BPM '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rouvoet A,Bach Poulsen C,Krebbers R,Visser E","Intrinsically-Typed Definitional Interpreters for Linear, Session-Typed Languages",,2020,,,284–298,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM SIGPLAN International Conference on Certified Programs and Proofs,"New Orleans, LA, USA",2020,9781450370974,,https://doi.org/10.1145/3372885.3373818;http://dx.doi.org/10.1145/3372885.3373818,10.1145/3372885.3373818,"An intrinsically-typed definitional interpreter is a concise specification of dynamic semantics, that is executable and type safe by construction. Unfortunately, scaling intrinsically-typed definitional interpreters to more complicated object languages often results in definitions that are cluttered with manual proof work. For linearly-typed languages (including session-typed languages) one has to prove that the interpreter, as well as all the operations on semantic components, treat values linearly. We present new methods and tools that make it possible to implement intrinsically-typed definitional interpreters for linearly-typed languages in a way that hides the majority of the manual proof work. Inspired by separation logic, we develop reusable and composable abstractions for programming with linear operations using dependent types. Using these abstractions, we define interpreters for linear lambda calculi with strong references, concurrency, and session-typed communication in Agda.","separation logic, mechanized semantics, type safety, Agda, linear types, dependent types, session types, definitional interpreters",CPP 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Niu N,Easterbrook S",Concept Analysis for Product Line Requirements,,2009,,,137–148,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM International Conference on Aspect-Oriented Software Development,"Charlottesville, Virginia, USA",2009,9781605584423,,https://doi.org/10.1145/1509239.1509259;http://dx.doi.org/10.1145/1509239.1509259,10.1145/1509239.1509259,"Traditional methods characterize a software product line's requirements using either functional or quality criteria. This appears to be inadequate to assess modularity, detect interferences, and analyze trade-offs. We take advantage of both symmetric and asymmetric views of aspects, and perform formal concept analysis to examine the functional and quality requirements of an evolving product line. The resulting concept lattice provides a rich notion which allows remarkable insights into the modularity and interactions of requirements. We formulate a number of problems that aspect-oriented product line requirements engineering should address, and present our solutions according to the concept lattice. We describe a case study applying our approach to analyze a mobile game product line's requirements, and review lessons learned.","quality attribute scenarios, product line engineering, functional requirements profiles, formal concept analysis",AOSD '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bai Y,Khan KM",A Modal Logic for Information System Security,,2011,,,51–56,"Australian Computer Society, Inc.",AUS,,Proceedings of the Ninth Australasian Information Security Conference - Volume 116,"Perth, Australia",2011,9781920682965,,,,"As a security mechanism, authorization or access control ensures that all accesses to the system resources occur exclusively according to the access polices and rules specified by the system security agent. Authorization specification has been extensively studied and a variety of approaches have been investigated. In this paper, we propose a knowledge oriented formal language to specify the system security policies and their reasoning in response to system resource access request. The semantics of our language is provided by translating our language into epistemic logic program in which knowledge related modal operators are employed to represent agents' knowledge in reasoning. We demonstrate how our authorization language handles the situation where the security agent's knowledge on access decision is incomplete.","intelligent systems, formal language, authorization, access control",AISC '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Florence SP,Fetscher B,Flatt M,Temps WH,St-Amour V,Kiguradze T,West DP,Niznik C,Yarnold PR,Findler RB,Belknap SM",POP-PL: A Patient-Oriented Prescription Programming Language,ACM Trans. Program. Lang. Syst.,2018,40,3,,Association for Computing Machinery,"New York, NY, USA",,,,2018-07,,0164-0925,https://doi.org/10.1145/3210256;http://dx.doi.org/10.1145/3210256,10.1145/3210256,"A medical prescription is a set of health care instructions that govern the plan of care for an individual patient, which may include orders for drug therapy, diet, clinical assessment, and laboratory testing. Clinicians have long used algorithmic thinking to describe and implement prescriptions but without the benefit of a formal programming language. Instead, medical algorithms are expressed using a natural language patois, flowcharts, or as structured data in an electronic medical record system. The lack of a prescription programming language inhibits expressiveness; results in prescriptions that are difficult to understand, hard to debug, and awkward to reuse; and increases the risk of fatal medical error.This article reports on the design and evaluation of Patient-Oriented Prescription Programming Language (POP-PL), a domain-specific programming language designed for expressing prescriptions. The language is based around the idea that programs and humans have complementary strengths that, when combined properly, can make for safer, more accurate performance of prescriptions. Use of POP-PL facilitates automation of certain low-level vigilance tasks, freeing up human cognition for abstract thinking, compassion, and human communication.We implemented this language and evaluated its design attempting to write prescriptions in the new language and evaluated its usability by assessing whether clinicians can understand and modify prescriptions written in the language. We found that some medical prescriptions can be expressed in a formal domain-specific programming language, and we determined that medical professionals can understand and correctly modify programs written in POP-PL. We also discuss opportunities for refining and further developing POP-PL.","medical prescriptions, empirical evaluation, DSL design, medical programming languages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Marincic J,Mader A,Wupper H,Wieringa R",Non-Monotonic Modelling from Initial Requirements: A Proposal and Comparison with Monotonic Modelling Methods,,2008,,,67–73,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Workshop on Applications and Advances of Problem Frames,"Leipzig, Germany",2008,9781605580203,,https://doi.org/10.1145/1370811.1370825;http://dx.doi.org/10.1145/1370811.1370825,10.1145/1370811.1370825,"Researchers make a significant effort to develop new modelling languages and tools. However, they spend less effort developing methods for constructing models using these languages and tools. We are developing a method for building an embedded system model for formal verification. Our method provides guidelines to build a model and to construct a correctness argument. We start from a high-level formula stating that a plant (a device that performs a task) and its control should satisfy requirements. As our knowledge about the system grows, we refine this formula and the model gradually, in a stepwise non-monotonic process, until we have a description that can be formally verified. In this paper we explain our method on a simple example and compare it briefly with two other methods: requirements progression and the goal-oriented KAOS approach. The requirements progression is an extension of a problem frames approach. The KAOS method is also based on problem frames, but introduces new concepts for describing a system.","nonmonotonicity, modelling method, correctness argument",IWAAPF '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schützel J,Peng D,Uhrmacher AM,Perrone LF",Perspectives on Languages for Specifying Simulation Experiments,,2014,,,2836–2847,IEEE Press,"Savannah, Georgia",,Proceedings of the 2014 Winter Simulation Conference,,2014,,,,,"Domain specific languages have been used in modeling and simulation as tools for model description. In recent years, the efforts toward enabling simulation reproducibility have motivated the use of domain specific languages also as the means with which to express experiment specifications. In simulation areas ranging from computational biology to computer networks, the emerging trend is to treat the experimentation process as a first class object. Domain specific languages serve to specify individual sub-tasks in this process, such as configuration, observation, analysis, and evaluation of experimental results. Additionally, they can be used in a broader scope, for instance, to describe formally the experiment's goals. The research and development of domain specific languages for experiment specification explores all of these and additional possible applications. In this paper, we discuss various existing approaches for defining this type of domain specific languages and present a critical analysis of our findings.",,WSC '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Korovin I,Khisamutdinov M,Ivanov D",Improvement of a Video Sequence Singular Image,,2018,,,12–15,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Advances in Artificial Intelligence,"Barcelona, Spain",2018,9781450365833,,https://doi.org/10.1145/3292448.3292454;http://dx.doi.org/10.1145/3292448.3292454,10.1145/3292448.3292454,"In the paper a method of preliminary improvement of video sequence images is suggested. The aim of further processing of the improved images is search and recognition of objects on a complex background. Originality of the method consists in analysis of a contribution coefficient, calculated for the single images of the video sequence.","video images improvement, Video sequences processing, objects recognition on a complex background",ICAAI 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chrszon P,Baier C,Dubslaff C,Klüppelholz S",From Features to Roles,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A,"Montreal, Quebec, Canada",2020,9781450375696,,https://doi.org/10.1145/3382025.3414962;http://dx.doi.org/10.1145/3382025.3414962,10.1145/3382025.3414962,"The detection of interactions is a challenging task present in almost all stages of software development. In feature-oriented system design, this task is mainly investigated for interactions of features within a single system, detected by their emergent behaviors. We propose a formalism to describe interactions in hierarchies of feature-oriented systems (hierarchical interactions) and the actual situations where features interact (active interplays). Based on the observation that such interactions are also crucial in role-based systems, we introduce a compositional modeling framework based on concepts and notions of roles, comprising role-based automata (RBAs). To describe RBAs, we present a modeling language that is close to the input language of the probabilistic model checker Prism. To exemplify the use of RBAs, we implemented a tool that translates RBA models into Prism and thus enables the formal analysis of functional and non-functional properties including system dynamics, contextual changes, and interactions. We carry out two case studies as a proof of concept of such analyses: First, a peer-to-peer protocol case study illustrates how undesired hierarchical interactions can be discovered automatically. Second, a case study on a self-adaptive production cell demonstrates how undesired interactions influence quality-of-service measures such as reliability and throughput.","feature-oriented systems, roles, formal methods, verification",SPLC '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zeng J,Yang LT,Ma J",A System-Level Modeling and Design for Cyber-Physical-Social Systems,ACM Trans. Embed. Comput. Syst.,2016,15,2,,Association for Computing Machinery,"New York, NY, USA",,,,2016-05,,1539-9087,https://doi.org/10.1145/2834119;http://dx.doi.org/10.1145/2834119,10.1145/2834119,"The design of cyber-physical-social systems (CPSS) is a novel and challenging research field due that it emphasizes the deep fusion of cyberspace, physical space, and social space. In this article, we extend our previously proposed system-level design framework [Zeng et al. 2015] to tailor it to the needs of social scenario of multiple users. A hierarchical Petri net-based model and social flow are presented to extend the control flow and formally describe the social interactions of multiple users, respectively. By using the extended model, the system-level optimization for CPSS can be achieved by the improved design flow. Specifically, object emplacement and user satisfaction are further extended into the social environment. Also maximal power estimation algorithm is improved, leveraging the extended intermediate representation model. Finally, we use a smart office case to demonstrate the feasibility and effectiveness of our improved design approach for multiple users.","Cyber-physical-social systems, system-level design, multi-objective optimization, IoT, pervasive computing",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ide N,Bunt H",Anatomy of Annotation Schemes: Mapping to GrAF,,2010,,,247–255,Association for Computational Linguistics,USA,,Proceedings of the Fourth Linguistic Annotation Workshop,"Uppsala, Sweden",2010,9781932432725,,,,"In this paper, we apply the annotation scheme design methodology defined in (Bunt, 2010) and demonstrate its use for generating a mapping from an existing annotation scheme to a representation in GrAF format. The most important features of this methodology are (1) the distinction of the abstract and concrete syntax of an annotation language; (2) the specification of a formal semantics for the abstract syntax; and (3) the formalization of the relation between abstract and concrete syntax, which guarantees that any concrete syntax inherits the semantics of the abstract syntax, and thus guarantees meaning-preserving mappings between representation formats. By way of illustration, we apply this mapping strategy to annotations from ISO-TimeML, PropBank, and FrameNet.",,LAW IV '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Banerjee S,Sarkar A",A Requirements Analysis Framework for Development of Service Oriented Systems,SIGSOFT Softw. Eng. Notes,2017,42,3,1–12,Association for Computing Machinery,"New York, NY, USA",,,,2017-09,,0163-5948,https://doi.org/10.1145/3127360.3127366;http://dx.doi.org/10.1145/3127360.3127366,10.1145/3127360.3127366,"In Service Oriented Systems (SOS), implementation of business processes is accomplished through services in distributed, loosely coupled manner based on business process requirements of the users. Consequently, importance of businessprocess requirements analysis for development of SOS is strongly highlighted in both academia and industry. Usually, traditional requirements engineering is competent enough to specify and analysis business requirements for development of software systems efficiently. However, Service Oriented Requirement Engineering (SORE) emerging for SOS development is differed from traditional requirement engineering due to complex nature of services. Yet, a serious gap is still exist between early and detailed specification of business process requirements in SORE and further mapping towards design of SOS from set of business processes. To address this issue, in this paper, a requirements analysis framework is proposed for development of SOS systems. The contribution of the proposed work is formal representation of business process requirements for SOS based on business scenario and Cause-Effect-Dependency (CED) graph in dimensions of six aspects of services -- What, Why, How, Who, When and Where (5W1H). Both early and detailed level requirements analysis in the context of SORE is facilitated by the proposed approach. Beside, traceability of proposed approach towards design of business processes for development of SOS is also exhibited in this paper. Moreover, the practical utility of the proposed approach is demonstrated using a suitable case study.","Consumer Viewpoint, Business Process Requirement, Provider Viewpoint, Requirements Analysis Framework, Service Oriented Requirement Engineering",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Du X,Zhu S,Li J",Skeleton Extraction via Structure-Adaptive Anisotropic Filtering,,2014,,,340–344,Association for Computing Machinery,"New York, NY, USA",,Proceedings of International Conference on Internet Multimedia Computing and Service,"Xiamen, China",2014,9781450328104,,https://doi.org/10.1145/2632856.2632897;http://dx.doi.org/10.1145/2632856.2632897,10.1145/2632856.2632897,"Skeletonization of gray-scale images is a challenging problem in computer vision due to the non-uniform width of shape and the clutter background. This paper presents a novel approach of skeletonization for gray-scale images directly from original image based on anisotropic Gaussian filter. To deal with the non-uniform width of natural object parts, we adapt the shape of filter kernel to local gradient feature. The orientation of filter is firstly estimated based on local structure tensor, and then the scale is calculated based on gradient vector flux. After that, the anisotropic Gaussian filter is performed on the image. The skeleton strength map is defined by the gradient vector flux measure. Finally, thin and binary skeleton is obtained by non-maximum suppression the skeleton strength map. Our method performs well on both binary and gray image in skeleton extraction even for clutter image.","Skeleton Strength Map, Skeletonization, Anisotropic Filter",ICIMCS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Baier P,Dürr F,Rothermel K",Opportunistic Position Update Protocols for Mobile Devices,,2013,,,787–796,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2013 ACM International Joint Conference on Pervasive and Ubiquitous Computing,"Zurich, Switzerland",2013,9781450317702,,https://doi.org/10.1145/2493432.2493439;http://dx.doi.org/10.1145/2493432.2493439,10.1145/2493432.2493439,"Many location-based applications such as geo-social networks rely on location services storing mobile object positions. To update positions on location servers, position update protocols are used. On the one hand, these protocols decide when an update has to be sent to ensure a certain quality of position information. On the other hand, they try to minimize the energy consumption of the mobile device by reducing communication to a minimum.In this paper, we show how to improve the energy efficiency of different update protocols by taking the energy characteristics of the mobile network interface into account. In particular, we show that the energy consumption can be reduced on average by 70% using an opportunistic update strategy sending position updates together with messages of other applications. We present a Markov model to predict the arrival of messages and an online optimization algorithm calculating an optimized schedule to send position updates.","location-based applications, energy efficiency, online optimization, position update protocols",UbiComp '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bernardi G,Hennessy M",Modelling Session Types Using Contracts,,2012,,,1941–1946,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th Annual ACM Symposium on Applied Computing,"Trento, Italy",2012,9781450308571,,https://doi.org/10.1145/2245276.2232097;http://dx.doi.org/10.1145/2245276.2232097,10.1145/2245276.2232097,"Web services are one of the most widely used technologies for service oriented computing. In particular, they support client-server protocols whose specifications are written in XML languages as such as WSCL or WSDL. Notwithstanding the wide adoption of web services, it is not yet clear which formalism should be used to reason about the protocols they support. Session types and contracts are two formalisms used to study client-server protocols, both promoted as good formal methods for web services. In this paper we study the relationship between contracts and session types. The main result is the existence of a fully abstract model of session types; this model is based on a natural interpretation of these types into a subset of contracts.",,SAC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Solms F,Edwards C,Paar A,Gruner S",A Domain-Specific Language for URDAD Based Requirements Elicitation,,2011,,,224–230,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the South African Institute of Computer Scientists and Information Technologists Conference on Knowledge, Innovation and Leadership in a Diverse, Multidisciplinary Environment","Cape Town, South Africa",2011,9781450308786,,https://doi.org/10.1145/2072221.2072247;http://dx.doi.org/10.1145/2072221.2072247,10.1145/2072221.2072247,"Use-Case Responsibility-Driven Analysis and Design (URDAD) is a service-oriented software analysis and design methodology. It is used by requirements engineers to develop technology-neutral, semi-formal platform-independent models (PIM) within the OMG's MDA. In the past, URDAD models were denoted in UML. However, that was tedious and error-prone. The resulting models were often of rather poor quality. In this paper we introduce and discuss a new Domain-Specific Language (DSL) for URDAD. Its meta model is consistent and satisfiable. We show that URDAD DSL specifications are simpler and allow for more complete service contract specifications than their corresponding UML expressions. They also enable traceability and test case generation.","domain specific language, service orientation, requirements engineering, platform independent model, meta model, model driven development",SAICSIT '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zielinski A,Bock J",A Case Study on the Use of Semantic Web Technologies for Learner Guidance,,2015,,,1425–1430,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th International Conference on World Wide Web,"Florence, Italy",2015,9781450334730,,https://doi.org/10.1145/2740908.2743047;http://dx.doi.org/10.1145/2740908.2743047,10.1145/2740908.2743047,"Personalized learning pathways have been advocated by didactic experts to overcome the problem of disorientation and information overload in technology enhanced learning (TEL). They are not only relevant for providing user-adaptive navigational support, but can also be used for composing learning objects into new personalized courses (sequencing and assembly). In this paper we investigate, how Semantic Web technologies can effectively support these tasks, based on a proper representation of learning objects and courses according to didactic requirements. We claim that both eLearning tasks, adaptive navigation and course assembly, call for a representational model that can capture the syntax and semantics of learning pathways adequately. In particular: (1) a new type of navigation that takes into account ordering information and the hierarchical structure of an eLearning course complemented with adaptive constraints; (2) closely tied to it, a semantic layer to guarantee interoperability and validation of the correctness of the learning pathway descriptions. We investigate to what extend Semantic Web Languages like RDF/S and OWL are expressive enough to handle different aspects of learning pathways. While both share a structural similarity with DAGs, only OWL ontologies - formally underpinned by description logics (DLs) - are expressive enough to validate the correctness of the data and infer semantically related learning resources on the pathway. For tasks that are more related to the syntax of learning pathways, in particular navigation similar to a guided tour, we test the time efficiency on various synthetic OWL ontologies using the HermiT reasoner. Experimental results show that the course structure and the density of the knowledge graph impact on the performance. We claim that in a dynamically changing environment, where the computation of reachability of a vertex is computed on demand at run-time, OWL-based reasoning does not scale up well. Using a real-world case study from the eLearning domain, we compare an OWL 2 DL implementation with an equivalent graph algorithm implementation with respect to time efficiency.","user guidance, guided tour, semantic web, adaptive navigation, ontologies, adaptive learning pathways",WWW '15 Companion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Majumdar D,Kanjilal A,Bhattacharya S",Separation of Scattered Concerns: A Graph Based Approach for Aspect Mining,SIGSOFT Softw. Eng. Notes,2011,36,2,1–11,Association for Computing Machinery,"New York, NY, USA",,,,2011-03,,0163-5948,https://doi.org/10.1145/1943371.1943387;http://dx.doi.org/10.1145/1943371.1943387,10.1145/1943371.1943387,"Aspect Mining is a dynamic area of research in the field of Software Engineering. Aspects are concerns that are intermingled with other concerns thereby reducing the understandability, maintainability and scalability of the code. The concept of Separation of Concerns (SoC) is often achieved untill the Design Phase, but gets difficult in the later phases of the software development life cycle (SDLC). During program maintenance the maintenance team is left with an aggregation of procedures and variables, both of which may be generically called user-defined tokens. This paper proposes a graph-based approach to address the problem of SoC during program maintenance. This is done by the removal of some source code elements (e.g., user-defined-tokens), which can be responsible for tangled concerns and complex code. These user-definedtokens can be treated separately under the Aspect Oriented Programming paradigm. The paper proposes a graphical-model, which represents a procedural program and defines a mathematical- model to identify and remove the tangled and interleaving code-fragments. Thereafter these code fragments are traced back to the requirements engineering level through a formal traceability model. This process yields the corresponding user requirements that are associated with these scattered code fragments. These identified user requirements are put forward as Aspects, to be handled or re-engineered under the Aspect Oriented Programming paradigm.","aspect mining, separation-of-concerns, relational algebra, user-defined tokens",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Schwarz C,Zöbel D,Wagner M",Formal Verification of Service-Oriented Adaptive Driver Assistance Systems,SIGBED Rev.,2013,10,4,49–52,Association for Computing Machinery,"New York, NY, USA",,,,2013-12,,,https://doi.org/10.1145/2583687.2583699;http://dx.doi.org/10.1145/2583687.2583699,10.1145/2583687.2583699,"Many future Driver-Assistance-Systems (DAS) will use components not permanently mounted to the vehicle. Unlike state-of-the-art DAS with static configurations, the system and software architecture changes at runtime. To handle configuration changes, Service Oriented Architecture (SOA) and automatic orchestration is a promising approach. Whenever systems are set up automatically, they have to be validated. This paper presents an approach based on formal methods. Existing component models are annotated with Quality-of-Service parameters and transformed automatically to Hybrid Automata. These automata are then composed to an overall system model and model checking is used to check safety properties. The complete transformation-orchestration-validation process is executed without user interaction and thus can be performed at runtime.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sarjoughian HS,Muqsith M,Huang D,Yau SS",Validation of Service Oriented Computing DEVS Simulation Models,,2012,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2012 Symposium on Theory of Modeling and Simulation - DEVS Integrative M&S Symposium,"Orlando, Florida",2012,9781618397867,,,,"In the simulation based design and development of Service Based Software Systems (SBS), it is important to analyze the models for correctness and improve confidence in the validity of the model. Of particular interest is the SBS simulation where models are used towards evaluation of time dependent QoS metrics (e.g., service delay, throughput etc.). In this paper, an experiment based validation of Service Based Software Systems using SOC-DEVS (i.e. Service Oriented Computing DEVS) framework is presented. As formal basis towards validation, the real system under consideration is abstracted as a DEVS I/O System model and experiments are developed to observe its time-based I/O trajectories. An exemplar Voice Communication System is simulated and results are analyzed towards model validation w.r.t. a real system prototype.","SOC-DEVS, SOA-complaint DEVS, verification & validation, co-design, service based software system",TMS/DEVS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Perelman V,Somekh J,Dori D",Model Verification Framework with Application to Molecular Biology (Work-in-Progress),,2011,,,140–145,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2011 Symposium on Theory of Modeling & Simulation: DEVS Integrative M&S Symposium,"Boston, Massachusetts",2011,,,,,"A myriad of detailed pieces of knowledge regarding the structure and function of the living cell have been accumulating at an alarmingly increasing rate. Emphasis is shifting from the study of a single molecular process to cellular pathways, cycles, and the entire cell as a system.Object-Process Methodology (OPM) is a holistic graphical modeling methodology that combines the behavioral and structural aspects of a system in a single model. The OPM methodology includes OPM-based development process, OPM Case Tool (OPCAT), and a modeling language.A framework for supporting the biological researcher for hypotheses modeling and verification is proposed. The framework consists of (1) OPM modeling of complex molecular biological systems intuitively yet formally and (2) a set of translation rules from OPM to a finite-state transition system (FTS) to enable model verification. An example from the mRNA transcription subsystem of gene expression demonstrates OPM-based modeling and its translation into FTS.","finite-state transition systems, formal verification, systems biology",TMS-DEVS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ha J,Eun J,Ahn P,Shin DH,Kim J",Learning Convolutional Neural Network Using Data from Other Domains in Case of Insufficient Data,,2018,,,122–126,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 International Conference on Information Science and System,"Jeju, Republic of Korea",2018,9781450364218,,https://doi.org/10.1145/3209914.3209927;http://dx.doi.org/10.1145/3209914.3209927,10.1145/3209914.3209927,"In this paper, we describe a training methodology of convolutional neural networks(CNNs) using data from a different domain when the number of training data in the test domain is small. Training a CNN for classification without enough data might lead to serious problems of overfitting and thus fail to generalize. In this case, if large data of the same object categories is available in another domain, this problem can be alleviated. We propose a method to train a CNN with small data in the test domain and large data in another. Since training a single network using data from different domains could lead to performance degradation, we consider this problem as cross-domain image similarity learning. In our experiment, we train a Siamese network to compute similarity between a pair of images from different domains, which are natural photos and 3D model projections. We design the network to output the probability that the input image pair belongs to the same category. Thus, the network can calculate similarity between the input pair and also classify a natural photo by comparing it with each images in the 3D model database. Since the network output represents similarity, we can greatly reduce testing time for classification compared to other methods (such as NN classification) in which distances between feature vectors must be calculated for every pair of images.","Neural Network, Image Retrieval, Multi-domain Data, Binary Classification, Siamese Network",ICISS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Habibullah M,Islam MA,Alam NB,Ahmed F",Player Performance Profiling for Penalty Shootouts in Football Using Video Analysis,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Computing Advancements,"Dhaka, Bangladesh",2020,9781450377782,,https://doi.org/10.1145/3377049.3377093;http://dx.doi.org/10.1145/3377049.3377093,10.1145/3377049.3377093,"The purpose of this research is to detect and track football, kick taker and goalkeeper in a penalty shoot and use their tracking data to check whether the shot ends up as goal or not with the innate intention of creating a player profile. YOLOv2, a state-of-the-art real time object detection system was used to detect ball, kick taker and goalkeeper. OpenCV was used to track the trajectory of the ball then calculate the probability of goal by statistically using these data of goalkeeper, kick taker and ball. In the end the application performed well tracking the ball and extracts goalkeeper and kick takers data. The application also finds out whether the shot was goal or not. This data can also be used to find out a players strong shooting area it can also find a goalkeeper's weak point as well.","YOLO, ball tracking, Object detection, BSV, football, Football player profiling, Tensor Flow, Broadcast Soccer Video, player tracking, Video Analysis",ICCA 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Qaroush AM,Hanani A,Jaber B,Karmi M,Qamhiyeh B",Automatic Spoken Customer Query Identification for Arabic Language,,2016,,,41–46,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 8th International Conference on Information Management and Engineering,"Istanbul, Turkey",2016,9781450347617,,https://doi.org/10.1145/3012258.3012261;http://dx.doi.org/10.1145/3012258.3012261,10.1145/3012258.3012261,"In this paper we propose an approach that aims to build an automated task-oriented Arabic dialogue system which is capable to determine the topic of spoken question asked by telecom provider customers. The system is based on an Arabic adapted CMU sphinx ASR. In addition to formal Arabic speech, our implemented Arabic ASR is capable to recognize some Palestinian Arabic dialectal words. The recognized text is used to determine the question category using supervised machine learning techniques in order to take desired action such as routing customer call to the appropriate destination. The best performance of proposed overall system is 76.4% accuracy with random forest classifier provided by Weka toolkit tested on 750 questions recorded by 30 speakers with Palestinian dialect.","automated dialogue system, automatic call routing, Arabic ASR, Palestinian Arabic dialect, speech recognition",ICIME 2016,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Špakov O,Comparison of Gaze-to-Objects Mapping Algorithms,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st Conference on Novel Gaze-Controlled Applications,"Karlskrona, Sweden",2011,9781450306805,,https://doi.org/10.1145/1983302.1983308;http://dx.doi.org/10.1145/1983302.1983308,10.1145/1983302.1983308,"Gaze data processing is an important and necessary step in gaze-based applications. This study focuses on the comparison of several gaze-to-object mapping algorithms using various dwell times for selection and presenting targets of several types and sizes. Seven algorithms found in literature were compared against two newly designed algorithms. The study revealed that a fractional mapping algorithm (known) has produced the highest rate of correct selections and fastest selection times, but also the highest rate of incorrect selections. The dynamic competing algorithm (designed) has shown the next best result, but also high rate of incorrect selections. A small impact on the type of target to the calculated statistics has been observed. A strictly centered gazing has helped to increase the rate of correct selections for all algorithms and types of targets. The directions for further mapping algorithms improvement and future investigation have been explained.","gaze controlled applications, algorithm design, gaze to object mapping, eye gaze pointing and selection",NGCA '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,van den Berghe A,Towards a Practical Security Analysis Methodology,,2015,,,883–886,IEEE Press,"Florence, Italy",,Proceedings of the 37th International Conference on Software Engineering - Volume 2,,2015,,,,,"The research community has proposed numerous techniques to perform security-oriented analyses based on a software design model. Such a formal analysis can provide precise security guarantees to the software designer, and facilitate the discovery of subtle flaws. Nevertheless, using such techniques in practice poses a big challenge for the average software designer, due to the narrow scope of each technique, the heterogeneous set of modelling languages that are required, and the analysis results that are often hard to interpret. Within the course of our research, we intend to provide practitioners with an integrated, easy-to-use modelling and analysis environment that enables them to work on a broad range of common security concerns without leaving the software design's level of abstraction.",,ICSE '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Muthusamy V,Jacobsen HA,Chau T,Chan A,Coulthard P",SLA-Driven Business Process Management in SOA,,2009,,,86–100,IBM Corp.,USA,,Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research,"Ontario, Canada",2009,,,https://doi.org/10.1145/1723028.1723040;http://dx.doi.org/10.1145/1723028.1723040,10.1145/1723028.1723040,"The management of non-functional goals, or Service Level Agreements (SLA), in the development of business processes in a Service Oriented Architecture (SOA) often requires much manual and error-prone effort by all parties throughout the entire lifecycle of the processes. The formal specification of SLAs into development tools can simplify some of this effort. In particular, the runtime provisioning and monitoring of processes can be achieved by an autonomic system that adapts to changing conditions to maintain the SLA's goals. SOA supports partitioning a system into services that are running in a distributed execution environment. When coupled with an associated cost model, a process can be both executed and monitored in an optimal manner, based on a declarative, user-specified optimality function.",,CASCON '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yeh JH,Huang XM",BKOntoVR: A Virtual Reality Exhibition System for Biographic Ontology-Based Semantic Structure,,2018,,,69–73,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 2nd International Conference on Software and E-Business,"Zhuhai, China",2018,9781450361279,,https://doi.org/10.1145/3301761.3301775;http://dx.doi.org/10.1145/3301761.3301775,10.1145/3301761.3301775,"In this article, we illustrate some of the semantic web-related technologies and design a virtual exhibition system for a set of ontology knowledge structures based on biographical history, which we call BKOntoVR. This is an official framework for processing and presenting biographical history-related messages on the semantic web with virtual-reality technology, including biographical events, time and space relationships, related personal messages, and more. We elaborate on this ontology knowledge architecture and explain how to use our ontological structure called BKOnto as a basis for domain-specific knowledge to support virtual presentation. Information management is becoming an important part of cultural collections related technologies, from the management of personal collections to the establishment of large, decentralized \semantic\"" databases. These semantic databases can be used to a certain extent using semantic web technology to process and construct a machine-understandable data network. Such a data network can be linked to the referenced knowledge structure to give a concept and a relationship form specification associated with a set of descriptive objects in the definition domain (person",thing,place,etc.) - that is,link to its meaning. Biographical history of the specific characters is through the life and other areas of a systematic description of the introduction of a text that form. In this paper,we overview some of the Semantic Web-related technologies and describe a cognitive knowledge structure for biographical knowledge representation based on OWL markup language,we call it BKOnto. This is a formal framework for dealing with information about biographical history on the semantic web,including biographical events,temporal and spatial relationships,related information of persons,and so on. We describe this ontology knowledge structure and explain how BKOnto can act as a basis for more domain-specific knowledge representation. In this study,we further present such cultural collections in a virtual reality form,by transforming the ontology cognitive architecture data into a virtual reality exhibition space,allowing users to present the semantic structure in the form of multimedia in a three-dimensional space more easily. Such a form of presentation can be used in the virtual exhibition of the museum,making it easier for museums to organize cultural collections of semantic structures and exert their influence through the Internet. The empirical study also uses the Mackay Digital Archives Project (http://dlm.csie.au.edu.tw/) as a source of information to demonstrate the ontology knowledge building process of Mackay's biographical stories,"as well as related Digital collection of information.""","ontology, virtual reality, semantic web, museum exhibition, temporal event, Biographical knowledge",ICSEB '18,,,,,,,,,,,,,,,
1,Conference Paper,Lunetta LF,The Role of a Formal Training Program in Attracting and Developing Computer Professionals,,1977,,,487–491,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the June 13-16, 1977, National Computer Conference","Dallas, Texas",1977,9781450379144,,https://doi.org/10.1145/1499402.1499489;http://dx.doi.org/10.1145/1499402.1499489,10.1145/1499402.1499489,"Because of the wide range of career choices that face computer-oriented graduates at the bachelor's level, a formal training program is often an effective mechanism to attract and maintain a high-powered technical staff. Often the fundamental choice for the new graduate is between full-time graduate school or full-time work. An explanation is given of how a training program can combine work experience and graduate school, and the impact that these development opportunities have on the organization's recruiting, development and planning efforts. Honeywell Information Systems' Advanced Engineering Program is used to illustrate a successful training program, and its constituent parts are highlighted: rotating work assignments, graduate education, and practical problems and seminars. Also, the importance of permanent placement for program graduates, and the net result of program training, are discussed.",,AFIPS '77,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fiorentino M,Radkowski R,Boccaccio A,Uva AE",Magic Mirror Interface for Augmented Reality Maintenance: An Automotive Case Study,,2016,,,160–167,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Working Conference on Advanced Visual Interfaces,"Bari, Italy",2016,9781450341318,,https://doi.org/10.1145/2909132.2909268;http://dx.doi.org/10.1145/2909132.2909268,10.1145/2909132.2909268,"We present a novel interaction method for augmented industrial maintenance based on a \magic mirror\"" interface and virtual motion buttons. The system includes a video camera for object tracking",a videodepth camera for capturing user gestures,a projector for displaying technical instruction to the operator and a LCD monitor providing feedback of the virtual buttons. The operator can trigger maintenance commands by directional swift of the hands in regions sensitive to motion speed and direction. The main advantage of the presented interface is that it can work in realistic industrial conditions: (i) operators wearing gloves,(ii) operators handling tools,(iii) presence of moving machinery and personnel in the background. We measured the performances of the system with a laboratory test and we proved the feasibility with an automotive inspection test case. We calculated an average interaction time below 2 seconds and an error rate lower than 5%. However,"we found some performances limitations if the operator is handling tools.""","human computer interfaces, motion buttons, Computer assisted maintenance, augmented reality",AVI '16,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xing N,Ahmad IS",Shape-Based Image Retrieval,,2009,,,545–549,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Advances in Mobile Computing and Multimedia,"Kuala Lumpur, Malaysia",2009,9781605586595,,https://doi.org/10.1145/1821748.1821853;http://dx.doi.org/10.1145/1821748.1821853,10.1145/1821748.1821853,"Shape is one of the most important image features for retrieval of images in a Content-Based Image Retrieval system. However, due to inherent difficulties and limitations of processes to describe a shape, this feature is fairly less commonly used. We propose a neural network-based shape retrieval system in which moment invariants and/or Zernike moments form a feature vector to describe the shape of an object. Fuzzy k-means clustering groups similar images in an image collection into k-clusters whereas neural network facilitates efficient retrieval of similar images. Neural network is trained by the clustering results of all of the images in the data collection such that its input is the feature vector obtained through the calculated moments and its output dictates the degree of membership among the k-clusters. Retrieval results and performance of the proposed system is compared and analyzed against an earlier proposed system.","moment invariants, shape-based retrieval, image retrieval, fuzzy k-means clustering, Zernik moments",MoMM '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Melkanoff MA,Another Attempt to Define Computer Science,,1973,,,563,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the June 4-8, 1973, National Computer Conference and Exposition","New York, New York",1973,9781450379168,,https://doi.org/10.1145/1499586.1499726;http://dx.doi.org/10.1145/1499586.1499726,10.1145/1499586.1499726,"There are equally important scientific and engineering aspects to computer science; they may be described as follows:SCIENTIFIC ASPECTS OF COMPUTER SCIENCEThe unique aim of the inductive sciences is to predict the future. This has been accomplished in the physical sciences by means of mathematico-symbolic models; the method has been much less successful in the behavioral and life sciences due to the difficulties of constructing soluble models which are valid over a sufficiently large domain. The advent of the computer has made it possible to construct and resolve models sufficiently complex to be interesting although their domain of validity is still limited: The program is here the model. To a large extent, the utility of the mathematical models (or theories) developed in the physical sciences is predicated on the possibility of developing mathematically generalized analytic solutions which permit predictions of very general types of events. This becomes proportionally more difficult as the model becomes more complicated. Thus even though the computer permits resolution of individual cases which otherwise would not be practically feasible, it cannot provide the power of an analytic solution. Thus the scientific aspects of computer science are similar to those of mathematics: they deal with all facets of the construction and especially the resolution of models embodied in this case by programs. The most fundamental problem is still to obtain (if at all possible) general analytic solutions to classes of algorithmic interactions described by programs and this may be considered as one of the most important long-range goals of computer science. In view of the enormous difficulties expected of such an endeavor, secondary goals must also be pursued; these include theoretical studies of program's schema, development and formal analysis of programming languages, development of more powerful computer systems, etc.ENGINEERING ASPECTS OF COMPUTER SCIENCEThe engineering aspects of computer science are directly related to system design. Defining recursively a system as a collection of interacting objects or systems, we are particularly concerned with systems whose components interact through procedures embodied in computer programs. The aim of engineering is to design a system in such a fashion as to optimize a given criterion function subject to certain given constraints. Thus the design of complex systems where the computer plays a major part requires both extensive knowledge of computer science and of the discipline where the system is utilized. Since a computer system is itself a system of hardware and/or software, computer science design is doubly related to computer science: as the discipline wherein the system is utilized and as the discipline necessary to carry out the design.",,AFIPS '73,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fujii T,Orihara R,Sei Y,Tahara Y,Ohsuga A",Generating Cooking Recipes from Cooking Videos Using Deep Learning Considering Previous Process with Video Encoding,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Applications of Intelligent Systems,"Las Palmas de Gran Canaria, Spain",2020,9781450376303,,https://doi.org/10.1145/3378184.3378217;http://dx.doi.org/10.1145/3378184.3378217,10.1145/3378184.3378217,"Research on generating natural language captions to visual data such as images and videos has produced considerable results with deep learning methods and attracted attention in recent years. In this research, we aim to generate recipe sentences from cooking videos acquired from YouTube. We treat the task as image captioning. There are two aspects to be considered in order to do so. We believe that the semantics of each process should be taken into account to improve the captioning ' s accuracy. Furthermore, data processing, that is obtaining images from each process using several visual processing methods such as object detection should be important. We propose a captioning model where a sentence vector is embedded to consider the consistency of the recipe. From differences between generated recipes and the reference recipe, we can calculate recipe scores. We use three metrics that are used in previous studies to evaluate the image captioning model. We compare the scores to with ones from baseline models.","Captioning, Object Detection, Sentence Vector, Deep Learning, Video Encoding, Recipe Generation",APPIS 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Murvay PS,Groza B",A Brief Look at the Security of DeviceNet Communication in Industrial Control Systems,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Central European Cybersecurity Conference 2018,"Ljubljana, Slovenia",2018,9781450365154,,https://doi.org/10.1145/3277570.3277575;http://dx.doi.org/10.1145/3277570.3277575,10.1145/3277570.3277575,"Security is a vital aspect of industrial control systems since they are used in critical infrastructures and manufacturing processes. As demonstrated by the increasing number of emerging exploits, securing such systems is still a challenge as the employed fieldbus technologies do not offer intrinsic support for basic security objectives. In this work we discuss some security aspects of DeviceNet, a communication protocol widely used for control applications especially in the North American industrial sector. Having the Controller Area Network (CAN) protocol at its base, DeviceNet inherits all the vulnerabilities that were already illustrated on CAN in-vehicle communication. We discuss how the lack of security in DeviceNet can be exploited and point on the fact that these vulnerabilities can be modelled by existing formal verification tools and countermeasures can be put in place.","attacks, industrial control systems, DeviceNet, security",CECC 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xie H,Lu X,Tang Z,Huang X",Detect Incorrect Triples in Knowledge Base Based on Triple Confidence Evaluation,,2017,,,93–101,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Industrial and Business Engineering,"Sapporo, Japan",2017,9781450353519,,https://doi.org/10.1145/3133811.3133829;http://dx.doi.org/10.1145/3133811.3133829,10.1145/3133811.3133829,"The knowledge base is an important form of data storage and organization in the fields of knowledge service, and it is the basis of knowledge representation learning. The accuracy of the contents in the knowledge base determines the effectiveness of knowledge service applications. This study proposes a generic computational methodology to evaluate the confidence level of triples in knowledge bases and detect potentially incorrect ones for further verification. In our methodology, the confidence of a triple is evaluated based on weighted feature words that are able to characterize the subject-object relation embedded in the triple, and the feature words are extracted from a corpus of natural language sentences using statistical and natural language processing techniques. Based on the calculated confidence values of triples, incorrect triples are detected using machine-learning-based classification. An experiment on a data set of industry applications has been conducted to demonstrate the workflow of evaluating triple confidence and detecting in-correct triples using our methodology.","Confidence Evaluation, Knowledge Service, Triple, Knowledge Base, Relation Extraction",ICIBE 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Yanfei Y,Comparison of Radar Chart Creation Methods for Risk Evaluation Data,,2018,,,51–55,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 International Conference on Big Data Engineering and Technology,"Chengdu, China",2018,9781450365826,,https://doi.org/10.1145/3297730.3297738;http://dx.doi.org/10.1145/3297730.3297738,10.1145/3297730.3297738,"Risk evaluation is the scientific process to examine risk situations of objects (such as buildings, companies, districts, regions etc.) under management, and establish the whole risk map in jurisdiction of related departments. Risks are assessed and calculated with many aspects under consideration. Risk expressed in multiple dimensions can be visualized in radar charts generally. This paper gives demonstrations of five different creation methods of radar charts in the mainstream and makes comparisons on them.","Radar chart, Fire protection, Risk evaluation, Data visualization",BDET 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Patri OP,Sorathia VS,Panangadan AV,Prasanna VK",The Process-Oriented Event Model (PoEM): A Conceptual Model for Industrial Events,,2014,,,154–165,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM International Conference on Distributed Event-Based Systems,"Mumbai, India",2014,9781450327374,,https://doi.org/10.1145/2611286.2611291;http://dx.doi.org/10.1145/2611286.2611291,10.1145/2611286.2611291,"The paper presents a comprehensive theoretical framework for modeling events and semantics of event processing at a level of abstraction that captures the different processes in industrial applications but is not limited to a specific application domain. The model, called Process-oriented Event Model (PoEM), provides a formal approach to model real-world entities and their interrelationships, and specifies the process of moving from data streams to event detection to event-based goal planning. The model links event detection to states, actions, and roles, enabling event notification, filtering, context awareness and escalation. PoEM defines event and non-event concepts and combines information from them to build an event processing workflow. Usage of the PoEM model is illustrated in case studies from the oil and gas industry and maritime piracy events.","complex event processing, event ontology, event escalation, data streams, semantic web",DEBS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tahara Y,Ohsuga A,Honiden S",Formal Verification of Dynamic Evolution Processes of UML Models Using Aspects,,2017,,,152–162,IEEE Press,"Buenos Aires, Argentina",,Proceedings of the 12th International Symposium on Software Engineering for Adaptive and Self-Managing Systems,,2017,9781538615508,,https://doi.org/10.1109/SEAMS.2017.4;http://dx.doi.org/10.1109/SEAMS.2017.4,10.1109/SEAMS.2017.4,"The rapidly changing requirements and environments of system operation demand dynamic changes to systems with as short downtimes as possible. System availability is a relevant feature for such dynamic changes, which we call dynamic evolution. One of the most promising approaches to highly available dynamic evolution is dynamic aspect weaving, a technique of aspect-oriented programming technology. It enables part of a program to dynamically change without stopping its execution. Another feature relevant to dynamic evolution is the assurance of correctness of evolution. However, this is not easy for dynamic evolution, mainly because the evolution process is rather complicated. Formal modeling and verification (specifically, model checking) are other promising technologies. Many researchers have proposed various approaches to model and verify dynamic evolution. However, highly available dynamic evolution processes tend to be too complicated to verify with existing techniques because such processes need to be simultaneously controlled with system functionalities and the operations for evolution that include dynamic aspect weaving. We propose a formal verification tool called CAMPer that analyzes the unified modeling language (UML) models of dynamic evolution processes that consist of multiple steps with sophisticated control that includes dynamic aspect weaving. This tool is able to verify functional requirements for the processes that would be complicated to attain high availability. Our approach uses the Maude specification language to systematically express dynamic evolution and dynamic aspect weaving by using reflection. We also used a model checker for Maude to verify the evolution processes. We conducted experiments using an example Tele Assistance System (TAS) to demonstrate the advantages of our approach and evaluate its feasibility.",,SEAMS '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ferrante M,Ferro N,Maistro M",Towards a Formal Framework for Utility-Oriented Measurements of Retrieval Effectiveness,,2015,,,21–30,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 International Conference on The Theory of Information Retrieval,"Northampton, Massachusetts, USA",2015,9781450338332,,https://doi.org/10.1145/2808194.2809452;http://dx.doi.org/10.1145/2808194.2809452,10.1145/2808194.2809452,"In this paper we present a formal framework to define and study the properties of utility-oriented measurements of retrieval effectiveness, like AP, RBP, ERR and many other popular IR evaluation measures. The proposed framework is laid in the wake of the representational theory of measurement, which provides the foundations of the modern theory of measurement in both physical and social sciences, thus contributing to explicitly link IR evaluation to a broader context. The proposed framework is minimal, in the sense that it relies on just one axiom, from which other properties are derived. Finally, it contributes to a better understanding and a clear separation of what issues are due to the inherent problems in comparing systems in terms of retrieval effectiveness and what others are due to the expected numerical properties of a measurement.","replacement, representational theory of measurement, balancing index, swap, omomorphism",ICTIR '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Bangaru SP,Michel J,Mu K,Bernstein G,Li TM,Ragan-Kelley J",Systematically Differentiating Parametric Discontinuities,ACM Trans. Graph.,2021,40,4,,Association for Computing Machinery,"New York, NY, USA",,,,2021-07,,0730-0301,https://doi.org/10.1145/3450626.3459775;http://dx.doi.org/10.1145/3450626.3459775,10.1145/3450626.3459775,"Emerging research in computer graphics, inverse problems, and machine learning requires us to differentiate and optimize parametric discontinuities. These discontinuities appear in object boundaries, occlusion, contact, and sudden change over time. In many domains, such as rendering and physics simulation, we differentiate the parameters of models that are expressed as integrals over discontinuous functions. Ignoring the discontinuities during differentiation often has a significant impact on the optimization process. Previous approaches either apply specialized hand-derived solutions, smooth out the discontinuities, or rely on incorrect automatic differentiation.We propose a systematic approach to differentiating integrals with discontinuous integrands, by developing a new differentiable programming language. We introduce integration as a language primitive and account for the Dirac delta contribution from differentiating parametric discontinuities in the integrand. We formally define the language semantics and prove the correctness and closure under the differentiation, allowing the generation of gradients and higher-order derivatives. We also build a system, Teg, implementing these semantics. Our approach is widely applicable to a variety of tasks, including image stylization, fitting shader parameters, trajectory optimization, and optimizing physical designs.","differentiable programming, differentiable physics, domain-specific language, differentiable rendering, differentiable graphics, automatic differentiation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Yu Q,Bouguettaya A",Framework for Web Service Query Algebra and Optimization,ACM Trans. Web,2008,2,1,,Association for Computing Machinery,"New York, NY, USA",,,,2008-03,,1559-1131,https://doi.org/10.1145/1326561.1326567;http://dx.doi.org/10.1145/1326561.1326567,10.1145/1326561.1326567,We present a query algebra that supports optimized access of Web services through service-oriented queries. The service query algebra is defined based on a formal service model that provides a high-level abstraction of Web services across an application domain. The algebra defines a set of algebraic operators. Algebraic service queries can be formulated using these operators. This allows users to query their desired services based on both functionality and quality. We provide the implementation of each algebraic operator. This enables the generation of Service Execution Plans (SEPs) that can be used by users to directly access services. We present an optimization algorithm by extending the Dynamic Programming (DP) approach to efficiently select the SEPs with the best user-desired quality. The experimental study validates the proposed algorithm by demonstrating significant performance improvement compared with the traditional DP approach.,"service query, service oriented computing, query optimization, Web service",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Tabareau N,A Monadic Interpretation of Execution Levels and Exceptions for AOP,,2012,,,71–82,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th Annual International Conference on Aspect-Oriented Software Development,"Potsdam, Germany",2012,9781450310925,,https://doi.org/10.1145/2162049.2162059;http://dx.doi.org/10.1145/2162049.2162059,10.1145/2162049.2162059,"Aspect-Oriented Programming (AOP) started fifteen years ago with the remark that modularization of so-called crosscutting functionalities is a fundamental problem for the engineering of large-scale applications. Originating at Xerox PARC, this observation has sparked the development of a new style of programming features that is gradually gaining traction. However, theoretical foundations of AOP have been much less studied than its applicability. This paper proposes to put a bridge between AOP and the notion of 2-category to enhance the conceptual understanding of AOP. Starting from the connection between the λ-calculus and the theory of categories, we provide an internal language for 2-categories and show how it can be used to define the first categorical semantics for a realistic functional AOP language, called MinAML. We then take advantage of this new categorical framework to introduce the notion of computational 2-monads for AOP. We illustrate their conceptual power by defining a 2-monad for Éric Tanter's execution levels---which constitutes the first algebraic semantics for execution levels---and then introducing the first exception monad transformer specific to AOP that gives rise to a non-flat semantics for exceptions by taking levels into account.","monads, execution levels, category theory, AOP",AOSD '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sroka J,Włodarczyk P,Krupa Ł,Hidders J",DFL Designer: Collection-Oriented Scientific Workflows with Petri Nets and Nested Relational Calculus,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st International Workshop on Workflow Approaches to New Data-Centric Science,"Indianapolis, Indiana",2010,9781450301886,,https://doi.org/10.1145/1833398.1833403;http://dx.doi.org/10.1145/1833398.1833403,10.1145/1833398.1833403,"In this paper we present DFL designer --- a collection-oriented scientific workflow (COSW) tool based on the DFL notation which combines established formalisms from workflow modeling and databases, namely Petri nets and the nested relational calculus (NRC). COSW tools are used in applied sciences like bioinformatics where structured data is processed with the use of specialized services which are made available online by scientific institutions. They make such data processing experiments easier to conduct by the experimentators and easier to comprehend and repeat by the reviewers. The notations, models and techniques used for the construction of COSW tools are similar to the ones known from workflow modeling, but additional emphasis is put on the data manipulation aspects, e.g., the processing of nested collections of data. DFL designer not only allows design and enactment of complicated COSWs with the use of a huge library of supported bioinformatics services, but also provides a set of features for testing and analyzing workflow specifications that is unique for COSWs, including but not limited to interactive firing of transitions, hierarchical analysis of COSWs and translation of side-effect free COSWs to a query language like NRC.",,Wands '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jahrmann K,Wimmer M",Responsive Real-Time Grass Rendering for General 3D Scenes,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games,"San Francisco, California",2017,9781450348867,,https://doi.org/10.1145/3023368.3023380;http://dx.doi.org/10.1145/3023368.3023380,10.1145/3023368.3023380,"Grass plays an important role in most natural environments. Most interactive applications use image-based techniques to approximate fields of grass due to the high geometrical complexity, leading to visual artifacts. In this paper, we propose a grass-rendering technique that is capable of drawing each blade of grass as geometrical object in real time. Accurate culling methods together with an adaptable rendering pipeline ensure that only the blades of grass that are important for the visual appearance of the field of grass are rendered. In addition, we introduce a physical model that is evaluated for each blade of grass. This enables that a blade of grass can react to its environment by calculating the influence of gravity, wind and collisions. A major advantage of our approach is that it can render fields of grass of arbitrary shape and spatial alignment. Thus, in contrast to previous work, the blades of grass can be placed on any 3D model, which is not required to be a flat surface or a height map.","hardware tessellation, real-time rendering, vegetation",I3D '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Shen B,Kernel-Based Relocation Siamese Network for Real-Time Visual Object Tracking,,2020,,,188–192,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence,"Tianjin, China",2020,9781450377089,,https://doi.org/10.1145/3404555.3404596;http://dx.doi.org/10.1145/3404555.3404596,10.1145/3404555.3404596,"Siamese networks have been paid more attention to video tracking due to its superiority in balance accuracy and speed. Based on the convolutional feature cross-correlation between the target template and the search region, trackers with Siamese network can search for the best result in the candidate box to get the tracking result. However, existing Siamese tracking algorithms are often affected by motion blurring, low resolution, distortion and other issues that blur search region in solving video object tracking problems. This paper presents a candidate box area generation method based on kernel density function to relocate the search region when track failed. Specifically, the tracker proposed in this paper fuses deep feature and color feature to generate candidate boxes from which more accurate tracking results can be obtained, moreover, the color feature is easily to calculate to reach real-time speed. Finally, by improving the candidate box generation algorithm, the problem of tracking missing due to fast motion, blurring and other factors is effectively solved with less time consuming.","kernel density, tracking relocation, Siamese network, video object tracking",ICCAI '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chaudhary S,Sadanand R,Roy SD,Chaudhury S",Pose Estimation of a Tilted Pellet Using Single View from Robot Mounted Camera,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2015 Conference on Advances In Robotics,"Goa, India",2015,9781450333566,,https://doi.org/10.1145/2783449.2783502;http://dx.doi.org/10.1145/2783449.2783502,10.1145/2783449.2783502,"This paper proposes a novel approach for finding the orientation of the tilted pellet using a single view of the pellet. This is important for the automation of pick and place problem. A texture less isolated cylindrical object is used for the pick and place operation. In this approach the isolated pellets are segmented from the background, following which, its contour is estimated. Then based on the assumption that length and diameter of the pellet remains constant, the mathematical formulation of the pose estimation of the pellet is given, and using which the orientation of the tilted pellet is computed using just single view. This is then experimentally verified for the different orientations of the pellet and the results are within the acceptable levels of accuracy A brief overview of the error estimation has been included. This error in orientation of the pellet is due to the variance in the actual height of the pellet. Error Jacobian for the above inaccuracy was calculated, and was found to be within required limits.","computer vision, pose, monocular vision, curve based matching, robotics",AIR '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Oi R,Yamamoto K,Mishina T,Senoh T,Kurita T",Electronic Holography Generated from Integral Photography,,2009,,,70–73,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Universal Communication Symposium,"Tokyo, Japan",2009,9781605586410,,https://doi.org/10.1145/1667780.1667794;http://dx.doi.org/10.1145/1667780.1667794,10.1145/1667780.1667794,"In this paper, we describe an electronic holography for non-coherent lighting environment. We used and integral photography (IP) to obtain 3D information of the scene. This method demands neither laser beams nor a darkroom at the recording. Therefore living or moving objects may be captured onto a hologram. The converter hardware calculates fringe patterns according to the IP at 30 frames per second by using our former proposed conversion algorithm. In our experiment, 3840x2160 pixels of color holograms are generated in real-time.","integral photography, electronic holography, holography, FFT",IUCS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Galuščáková P,Batko M,Čech J,Matas J,Novák D,Pecina P",Visual Descriptors in Methods for Video Hyperlinking,,2017,,,294–300,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2017 ACM on International Conference on Multimedia Retrieval,"Bucharest, Romania",2017,9781450347013,,https://doi.org/10.1145/3078971.3079026;http://dx.doi.org/10.1145/3078971.3079026,10.1145/3078971.3079026,"In this paper, we survey different state-of-the-art visual processing methods and utilize them in hyperlinking. Visual information, calculated using Features Signatures, SIMILE descriptors and convolutional neural networks (CNN), is utilized as similarity between video frames and used to find similar faces, objects and setting. Visual concepts in frames are also automatically recognized and textual output of the recognition is combined with search based on subtitles and transcripts. All presented experiments were performed in the Search and Hyperlinking 2014 MediaEval task and Video Hyperlinking 2015 TRECVid task.","information retrieval, image processing, hyperlinking, video retrieval",ICMR '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Legunsen O,Marinov D,Roşu G",Evolution-Aware Monitoring-Oriented Programming,,2015,,,615–618,IEEE Press,"Florence, Italy",,Proceedings of the 37th International Conference on Software Engineering - Volume 2,,2015,,,,,"Monitoring-Oriented Programming (MOP) helps develop more reliable software by means of monitoring against formal specifications. While MOP showed promising results, all prior research has focused on checking a single version of software. We propose to extend MOP to support multiple software versions and thus be more relevant in the context of rapid software evolution. Our approach, called eMOP, is inspired by regression test selection---a well studied, evolution-centered technique. The key idea in eMOP is to monitor only the parts of code that changed between versions. We illustrate eMOP by means of a running example, and show the results of preliminary experiments. eMOP opens up a new line of research on MOP---it can significantly improve usability and performance when applied across multiple versions of software and is complementary to algorithmic MOP advances on a single version.",,ICSE '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Silva PA,Ribeiro CM,Schiel U",Formalizing Ontology Reconciliation Techniques as a Basis for Meaningful Mediation in Service-Related Tasks,,2007,,,147–154,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM First Ph.D. Workshop in CIKM,"Lisbon, Portugal",2007,9781595938329,,https://doi.org/10.1145/1316874.1316898;http://dx.doi.org/10.1145/1316874.1316898,10.1145/1316874.1316898,"With the advent of Semantic Web, the fast dissemination of ontologies to represent and share information causes a deep impact on knowledge retrieval, as a whole. In this context, the use of different ontologies to express meaning on the same application domain leads to a kind of \Tower of Babel Effect\"" on the Web",bringing new problems to the communication among different applications. This problem still remains in service-oriented architectures,considering that a same service can be described by the use of different ontologies and standards. Therefore,the urge of an ontology reconciliation approach arises in order to enable communication despite the differences. This paper focuses on providing a formal description of ontology reconciliation techniques,such as merging,alignment and integration,"to provide better understanding of how these techniques can be used on the scope of Semantic Web Services Architecture.""","service discovery, formal methods, ontology reconciliation, service selection, semantic web, Z notation",PIKM '07,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bagherzadeh M,Rajan H",Panini: A Concurrent Programming Model for Solving Pervasive and Oblivious Interference,,2015,,,93–108,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th International Conference on Modularity,"Fort Collins, CO, USA",2015,9781450332491,,https://doi.org/10.1145/2724525.2724568;http://dx.doi.org/10.1145/2724525.2724568,10.1145/2724525.2724568,"Modular reasoning about concurrent programs is complicated by the possibility of interferences happening between any two instructions of a task (pervasive interference), and these interferences not giving out any information about the behaviors of potentially interfering concurrent tasks (oblivious interference). Reasoning about a concurrent program would be easier if a programmer modularly and statically (1) knows precisely the program points at which interferences may happen (sparse interference), and (2) has some insights into behaviors of potentially interfering tasks at these points (cognizant interference). In this work we present Panini, a core concurrent calculus which guarantees sparse interference, by controlling sharing among concurrent tasks, and cognizant interference, by controlling dynamic name bindings and accessibility of states of tasks. Panini promotes capsule-oriented programming whose concurrently running capsules own their states, communicate by asynchronous invocations of their procedures and dynamically transfer ownership. Panini limits sharing among two capsules to other capsules and futures, limits accessibility of a capsule states to only through its procedures and dispatches a procedure invocation on the static type of its receiver capsule. We formalize Panini, present its semantics and illustrate how its interference model, using behavioral contracts, enables Hoare-style modular reasoning about concurrent programs with interference.","message passing, modular reasoning, Pervasive interference, oblivious interference, capsule-oriented programming",MODULARITY 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Singh MP,"Information-Driven Interaction-Oriented Programming: BSPL, the Blindingly Simple Protocol Language",,2011,,,491–498,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 2,"Taipei, Taiwan",2011,9780982657164,,,,"We present a novel approach to interaction-oriented programming based on declaratively representing communication protocols. Our approach exhibits the following distinguishing features. First, it treats a protocol as an engineering abstraction in its own right. Second, it models a protocol in terms of the information that the protocol needs to proceed (so agents enact it properly) and the information the protocol would produce (when it is enacted). Third, it naturally maps traditional operational constraints to the information needs of protocols, thereby obtaining the desired interactions without additional effort or reasoning. Fourth, our approach naturally supports shared nothing enactments: everything of relevance is included in the communications and no separate global state need be maintained. Fifth, our approach accommodates, but does not require, formal representations of the meanings of the protocols. We evaluate this approach via examples from the literature.","business protocols, business process modeling",AAMAS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kato K,Kitani KM,Nojima T",Ego-Motion Analysis Using Average Image Data Intensity,,2011,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd Augmented Human International Conference,"Tokyo, Japan",2011,9781450304269,,https://doi.org/10.1145/1959826.1959835;http://dx.doi.org/10.1145/1959826.1959835,10.1145/1959826.1959835,"In this paper, we present a new method to perform ego-motion analysis using intensity averaging of image data. The method can estimate general motions from two sequential images on pixel plane by calculating cross correlations. With distance information between camera and objects, this method also enables estimates of camera motion. This method is sufficiently robust even for out of focus image and the calculational overhead is quite low because it uses a simple averaging method. In the future, this method could be used to measure fast motions such as human head tracking, or robot movement. We present a detailed description of the proposed method, and experimental results demonstrating its basic capability. With these results, we verify that our proposed system can detect camera motion even with blurred images. Furthermore, we confirm that it can operate at up to 714 FPS in calculating one dimensional translation motion.","averaging image, image processing, correlation, ego-motion estimation",AH '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang G,Wu S,Xiao G",CARNet: Context Attention Refine Network for Semantic Segmentation,,2020,,,127–132,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2020 2nd International Conference on Image, Video and Signal Processing","Singapore, Singapore",2020,9781450376952,,https://doi.org/10.1145/3388818.3389157;http://dx.doi.org/10.1145/3388818.3389157,10.1145/3388818.3389157,"Recent works in semantic segmentation have focused on exploiting richer context through attention mechanisms or multi-scale fusion. Most of them ignore the low-level details, which greatly improve the recognition of pixels in the edge of the object. In this paper, we improve the quality of feature maps from two aspects: muti-level features fusion and global context encoding. A Context Attention Unit (CAU) is proposed to aggregate context information. The CAU utilizes self-attention model to enhance the semantic representation of high-level features. To make effective use of the different characteristics of multi-level feature maps, we further present a Gated Fuse Unit (GFU). A gate is calculated to control the information transfer of the feature maps of the adjacent layers. Base on these two units, a network with encoder-decoder structure is designed to gradually refine the feature map. Then the refined feature map generates the final segmentation prediction. We conduct extensive experiments on popular semantic segmentation benchmarks including Cityscapes and PASCAL VOC, which shows the effectiveness of our method.","attention, semantic segmentation, gate mechanism, enconder-decoder",IVSP '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wu X,Wang Y,Zhang Z",A Salient Object Detection Model Based on Local-Region Contrast for Night Security and Assurance,,2019,,,64–69,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 International Conference on Video, Signal and Image Processing","Wuhan, China",2019,9781450371483,,https://doi.org/10.1145/3369318.3369327;http://dx.doi.org/10.1145/3369318.3369327,10.1145/3369318.3369327,"Nowadays, night security and assurance are necessary and monitoring systems have been set up all over China. However, it is difficult to analyze the monitoring area because of the dark night light. In order to further maintain peace and ensure the safety and security of our study focused on the design of a more effective and robust approach to identify the salient area in a nighttime image. Therefore, this paper proposed an optimized salient object detection (SOD) model for night security and assurance. Firstly, enhance the image, then simple linear iterative clustering optimization (SLICO) method was used to divide the image into superpixel regions. Constructed the covariance matrix (CM) of the image based on various features, local saliency was calculated by non-linear fusion of these salient information. After this, integrated local saliency with the saliency of color space (CS) contrast. Finally, the regularization of the image was utilized to refine the salient graph. Experiments show that our method outperforms state of the art in the popular evaluation metrics.","local-region contrast, salient object detection, nighttime image",VSIP 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bistarelli S,Campli P,Santini F",Finding Partitions of Arguments with Dung's Properties via SCSPs,,2011,,,913–919,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM Symposium on Applied Computing,"TaiChung, Taiwan",2011,9781450301138,,https://doi.org/10.1145/1982185.1982384;http://dx.doi.org/10.1145/1982185.1982384,10.1145/1982185.1982384,"Forming coalition structures allows agents to join their forces with the aim to achieve a common task. We suggest it would be interesting to look for homogeneous groups which follow distinct lines of thought. For this reason, we extend the Dung Argumentation Framework in order to deal with coalitions of arguments. The initial set of arguments is partitioned into subsets (or coalitions). Each coalition represents a different line of thought, but all the found coalitions show the same property inherited by Dung, e.g. all the coalitions in the partition are admissible (or conflict-free, complete, stable). Some problems in weighted argumentation are NP complete; we use (soft) constraints as a formal approach to reason about coalitions and to model all these problems in the same framework. Semiring algebraic structures can be used to model different optimization criteria for the obtained coalitions. To implement this mapping and practically find its solutions we use JaCoP, a Java constraint solver, and we test the code over a small-world network.","weighted argumentation frameworks, coalition formation, soft constraint satisfaction problems",SAC '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Abhishek A,Sood H,Jeannin JB",Formal Verification of Braking While Swerving in Automobiles,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Conference on Hybrid Systems: Computation and Control,"Sydney, New South Wales, Australia",2020,9781450370189,,https://doi.org/10.1145/3365365.3382217;http://dx.doi.org/10.1145/3365365.3382217,10.1145/3365365.3382217,"Many vehicle accidents result from collision with foreign objects. Automatic and provably safe collision avoidance systems are thus of prime importance to the automobile industry. Previous work on formally verifying car collision avoidance maneuvers typically only focuses on braking-only or swerving-only maneuvers. In this work, we study combined braking and swerving maneuvers and establish formally verified conditions under which safety from collision is ensured. One major constrain in performing such joint maneuvers is that a vehicle's tires have limited traction which can be used either for braking or swerving. So in essence, a combined maneuver can trade off braking ability for turning when it is advantageous to do so and vice-versa. In this work, we study the full continuous range of combined maneuvers, from maximal turning with little braking to maximal braking with little turning.We use a unicycle model with Ackermann's steering for the car's motion, and the circle of traction forces to model the trade-off between braking and swerving. Resulting vehicle kinematics are formulated as a hybrid program in differential dynamic logic dL. We use the automated theorem prover KeYmaera X to formally verify the correctness of the collision avoidance property. This verification provides a mathematical guarantee that a given maneuver can prevent the car from collision with obstacles under certain conditions. The employed method is generic with a purely symbolic model and, thus, can be applied to verify other types of collision avoidance systems exhibiting richer behaviour.","formal verification, collision avoidance, non-linear hybrid systems, automotive control",HSCC '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Krishnan R,Niu J,Sandhu R,Winsborough WH",Stale-Safe Security Properties for Group-Based Secure Information Sharing,,2008,,,53–62,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th ACM Workshop on Formal Methods in Security Engineering,"Alexandria, Virginia, USA",2008,9781605582887,,https://doi.org/10.1145/1456396.1456402;http://dx.doi.org/10.1145/1456396.1456402,10.1145/1456396.1456402,"Attribute staleness arises due to the physical distribution of authorization information, decision and enforcement points. This is a fundamental problem in virtually any secure distributed system in which the management and representation of authorization state are not globally synchronized. This problem is so intrinsic, it is inevitable that access decision will be based on attribute values that are stale. While it may not be practical to eliminate staleness, we can limit unsafe access decisions made based on stale subject and object attributes. In this paper, we propose and formally specify four stale-safe security properties of varying strength which limit such incorrect access decisions. We use Linear Temporal Logic (LTL) to formalize these properties making them suitable to be verified, for example, using model checking. We show how these properties can be applied in the specific context of group-based Secure Information Sharing (g-SIS) as defined in this paper. We specify the authorization decision/enforcement points of the g-SIS system as a Finite State Machine (FSM) and show how this FSM can be modified so as to satisfy one of the stale-safe properties.","security properties, stale attributes, information sharing",FMSE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Han H,Kuai K,Fei G",Player Experience Information Evaluation in 3D Virtual Environments,,2018,,,23–26,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st International Conference on Computer Animation and Social Agents,"Beijing, China",2018,9781450363761,,https://doi.org/10.1145/3205326.3205349;http://dx.doi.org/10.1145/3205326.3205349,10.1145/3205326.3205349,A method to evaluate the amount of information a player can get during the process of exploring in a virtual scene is proposed. A novel perception probability estimation method is used to decide the probability distribution among task-related objects in the scene. The perception probability is then used into Shannon entropy equation to calculate the experience information amount. A user study is conducted to verify the effectiveness of the method proposed. The potential use of the method in the application of player type classification is presented in a game scene along with a questionnaire system.,"player modeling, game analytics, Shannon entropy, experience evaluation",CASA 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Herbst S,Pollner N,Tenschert J,Lauterwald F,Endler G,Meyer-Wegener K","An Algebra for Pattern Matching, Time-Aware Aggregates and Partitions on Relational Data Streams",,2015,,,140–149,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM International Conference on Distributed Event-Based Systems,"Oslo, Norway",2015,9781450332866,,https://doi.org/10.1145/2675743.2771830;http://dx.doi.org/10.1145/2675743.2771830,10.1145/2675743.2771830,"Many interesting applications of continuous-query processing are concerned with pattern matching or complex temporal aggregation of events. Real-world queries that rely on these operations are difficult to implement in current stream-processing systems. The reason seems to be a gap between two types of existing query languages: Some languages (e. g. CQL) offer a small set of simple operators that can be combined in order to create complex queries. While these languages provide sound and comprehensible semantics, they lack the expressiveness required for many real-world applications. Other approaches (e. g. Aurora) provide powerful operators but lack semantic strictness, which is required for reasoning about query results. Such reasoning is a prerequisite for safe query optimization.We try to bridge this gap by integrating operators for pattern matching and time-aware aggregates into a general-purpose stream model featuring stream partitioning. These operators can answer several questions that we have found to be relevant in a real-world object-tracking scenario. Moreover, they are formally defined, allowing expressive and efficient queries to be written in CQL-like languages, while remaining understandable and easy to use.","disjoint union, complex event processing, time-aware aggregates, stream algebra, stream partitioning, animal tracking, object tracking, continuous queries, pattern matching, data stream processing",DEBS '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Z,Yang D,Tong Q",A Method of Workpiece Coherent Line Detection Based on Progressive Probabilistic Hough Transform,,2020,,,141–146,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 9th International Conference on Software and Computer Applications,"Langkawi, Malaysia",2020,9781450376655,,https://doi.org/10.1145/3384544.3384580;http://dx.doi.org/10.1145/3384544.3384580,10.1145/3384544.3384580,"The detection and extraction of workpiece lines is the basis and key in the industrial production practice. In order to solve the discontinuity and disconnection problem during the line detection and extraction of a workpiece, we propose a coherent line detection method, which is Improved Progressive Probabilistic Hough Transform line detection(PPHT). Improved PPHT first performs edge detection combine with original PPHT algorithm to find lines of workpiece object. After discarding noise lines, this method divide the detected lines into several groups by finding collinear candidates. Then we calculate the supporting pixels of every group with foreground image, and apply Least Square Regression to achieve final line results. In this paper, we performed an experiment on thirty images of three different rectangular workpieces.The results indicate that, comparing to the PPHT, Improved PPHT decreased the relative error rate of the linear detection accuracy p by 62.06% on average, and the relative error rate of the recall rate R has decreased by 43.6% on average, thereby significantly mitigate the discontinuity existing in PPHT.","Probabilistic Hough Transform, Coherent line detection, Least Square Regression, workpiece quality detection",ICSCA 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xu A,Wang F,Ying P",Xiaomi Brand Appraisal Research Based on Zhihu by Text Mining Technology,,2019,,,221–225,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 4th International Conference on Big Data and Computing,"Guangzhou, China",2019,9781450362788,,https://doi.org/10.1145/3335484.3335515;http://dx.doi.org/10.1145/3335484.3335515,10.1145/3335484.3335515,"As the largest knowledge social platform on the Chinese Internet, Zhihu has gradually become an important resource for merchants to improve publicity and optimize products, and the public to understand the brand image. The topic of \Xiaomi Technology\"" remains hot on Zhihu. In this context","this paper takes the essences of the \""Xiaomi Technology\"" topic on Zhihu as the research object. First we carry on the data collection and preprocessing. Then by extracting feature based on word segmentation results",we build a corpus and construct an LDA topic model for text mining. Besides,by calculating and comparing the perplexity index,we select 20 as the number of topics. According to the results,the relationship between document-topic and topic-term is analyzed to form a topic description of the text,"which shows that Xiaomi products have received great attention from consumers and are often used for comparison with other brands in the same industry; Xiaomi product launches have received much attention and had a direct impact on product sales; Xiaomi is widely recognized as one of the representatives of China's future technology.""","text mining, LDA topic model, Xiaomi, Gibbs sampling",ICBDC 2019,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sharma K,Sekhon GS",Design and Development of an Effective Ball Catching Robotic Arm with 3DOF,,2012,,,770–777,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Second International Conference on Computational Science, Engineering and Information Technology","Coimbatore UNK, India",2012,9781450313100,,https://doi.org/10.1145/2393216.2393345;http://dx.doi.org/10.1145/2393216.2393345,10.1145/2393216.2393345,"This paper presents a ball catching robotic arm system with 3DOF assembled from the commercially available parts. In the previous research work complex system were designed. We have designed a very simple arm and take the results of catching ball at different angles i.e we throw the ball towards robotic arm at different angles (40°,45°,50° and 60°) and get the results in our analysis we observed that the proposed system given its best results when the ball is thrown towards it at 40°. In this system, camera system is use to perceive the trajectory of the ball, the system detects the ball with the help of a fast mean shift algorithm. It calculates the shift of the mean of the identified color intensity and according to that it sends the control commands over the serial port to the robotic arm. The basic objective to catch the flying object at the expected location. After the analysis it is observed that the catcher robotic arm can catch the ball thrown to it from 5--6 meter with an average success rate of 70--75% when throw at 40° towards the arm.","robotic vision, ball catching robotic arm, robotics",CCSEIT '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen YJ,Shen ZN,Chen YC,Chang CF,Chuang YY,Hsiang J",Extensions to Inverse Displacement Mapping: Towards More Accurate Silhouette and Dynamic Displacement,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 Symposium on Interactive 3D Graphics and Games,"Redwood City, California",2008,9781595939838,,https://doi.org/10.1145/1342250.1357014;http://dx.doi.org/10.1145/1342250.1357014,10.1145/1342250.1357014,"This paper presents two extensions to inverse displacement mapping, methods which attempt to render effects offered by displacement mapping, motion parallax, self-occlusion, self-shadowing and silhouette, without actually perturbing the surface geometry. The first extension, Normal-Based Curved Silhouette (NCS), allows better rendering for object's silhouette. At each step of intersection finding, NCS continuously bends the viewing ray according to the current local tangent space associated with the surface. Thus, it allows mapping a displacement map onto an arbitrary curved surface with more accurate silhouette. For the second extension, we propose a hierarchical adaptive preprocessing method that is around 10 times faster than conventional methods, allowing our space leaping approach to be used for rendering dynamic displacement maps. In addition, we propose an extension to cone step mapping. The extension, Anisotropic Cone Mapping (ACM), provides a more efficient and accurate way for calculating intersections. Anisotropic cones are used as the bounding volume for the empty space above texels, allowing faster convergence and rendering speed. Both proposed methods are suited for many realtime 3D applications because of their low memory cost and good performance in both rendering quality and speed.",,I3D '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hussain SR,Echeverria M,Karim I,Chowdhury O,Bertino E",5GReasoner: A Property-Directed Security and Privacy Analysis Framework for 5G Cellular Network Protocol,,2019,,,669–684,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security,"London, United Kingdom",2019,9781450367479,,https://doi.org/10.1145/3319535.3354263;http://dx.doi.org/10.1145/3319535.3354263,10.1145/3319535.3354263,"The paper proposes 5GReasoner, a framework for property-guided formal verification of control-plane protocols spanning across multiple layers of the 5G protocol stack. The underlying analysis carried out by 5GReasoner can be viewed as an instance of the model checking problem with respect to an adversarial environment. Due to an effective use of behavior-specific abstraction in our manually extracted 5G protocol, 5GReasoner's analysis generalizes prior analyses of cellular protocols by reasoning about properties not only regarding packet payload but also multi-layer protocol interactions. We instantiated 5GReasoner with two model checkers and a cryptographic protocol verifier, lazily combining them through the use of abstraction-refinement principle. Our analysis of the extracted 5G protocol model covering 6 key control-layer protocols spanning across two layers of the 5G protocol stack with 5GReasoner has identified 11 design weaknesses resulting in attacks having both security and privacy implications. Our analysis also discovered 5 previous design weaknesses that 5G inherits from 4G, and can be exploited to violate its security and privacy guarantees.","attacks, 5G, model checking, vulnerabilities, cellular network",CCS '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Parker J,Vazou N,Hicks M",LWeb: Information Flow Security for Multi-Tier Web Applications,Proc. ACM Program. Lang.,2019,3,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-01,,,https://doi.org/10.1145/3290388;http://dx.doi.org/10.1145/3290388,10.1145/3290388,"This paper presents LWeb, a framework for enforcing label-based, information flow policies in database-using web applications. In a nutshell, LWeb marries the LIO Haskell IFC enforcement library with the Yesod web programming framework. The implementation has two parts. First, we extract the core of LIO into a monad transformer (LMonad) and then apply it to Yesod’s core monad. Second, we extend Yesod’s table definition DSL and query functionality to permit defining and enforcing label-based policies on tables and enforcing them during query processing. LWeb’s policy language is expressive, permitting dynamic per-table and per-row policies. We formalize the essence of LWeb in the λLWeb calculus and mechanize the proof of noninterference in Liquid Haskell. This mechanization constitutes the first metatheoretic proof carried out in Liquid Haskell. We also used LWeb to build a substantial web site hosting the Build it, Break it, Fix it security-oriented programming contest. The site involves 40 data tables and sophisticated policies. Compared to manually checking security policies, LWeb imposes a modest runtime overhead of between 2% to 21%. It reduces the trusted code base from the whole application to just 1% of the application code, and 21% of the code overall (when counting LWeb too).","Haskell, metatheory, security, Liquid Haskell, information flow control",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Khan MU,Gotoh Y",Describing Video Contents in Natural Language,,2012,,,27–35,Association for Computational Linguistics,USA,,Proceedings of the Workshop on Innovative Hybrid Approaches to the Processing of Textual Data,"Avignon, France",2012,,,,,"This contribution addresses generation of natural language descriptions for human actions, behaviour and their relations with other objects observed in video streams. The work starts with implementation of conventional image processing techniques to extract high level features from video. These features are converted into natural language descriptions using context free grammar. Although feature extraction processes are erroneous at various levels, we explore approaches to putting them together to produce a coherent description. Evaluation is made by calculating ROUGE scores between human annotated and machine generated descriptions. Further we introduce a task based evaluation by human subjects which provides qualitative evaluation of generated descriptions.",,HYBRID '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Terada T,Suzuki Y,Tsukamoto M",A Distance Estimation Method Using Intra-Frame Optical Flow with Interlace Camera,,2010,,,378–381,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Conference on Advances in Mobile Computing and Multimedia,"Paris, France",2010,9781450304405,,https://doi.org/10.1145/1971519.1971583;http://dx.doi.org/10.1145/1971519.1971583,10.1145/1971519.1971583,"There has recently been much research on estimates of location using optical flow, which is a well-known for estimating distances. However, since high computational power is needed to calculate optical flow, it cannot be adapted to high-speed movement. This paper proposes an intra-frame optical flow, which is a new method of estimating distances using an interlace camera. It estimates high-speed moving objects accurately because it uses two successive images with a very short scanning interval extracted from one image captured by an interlace camera. The result obtained from evaluation confirmed the effectiveness of our method.","interlace camera, distance estimation",MoMM '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rebanal J,Combitsis J,Tang Y,Chen Xanthony",XAlgo: A Design Probe of Explaining Algorithms’ Internal States via Question-Answering,,2021,,,329–339,Association for Computing Machinery,"New York, NY, USA",,26th International Conference on Intelligent User Interfaces,"College Station, TX, USA",2021,9781450380171,,https://doi.org/10.1145/3397481.3450676;http://dx.doi.org/10.1145/3397481.3450676,10.1145/3397481.3450676,"Algorithms often appear as ’black boxes’ to non-expert users. While prior work focuses on explainable representations and expert-oriented exploration, we propose and study an interactive approach using question answering to explain deterministic algorithms to non-expert users who need to understand the algorithms’ internal states (students learning algorithms, operators monitoring robots, admins troubleshooting network routing). We construct XAlgo—a formal model that first classifies the type of question based on a taxonomy and generates an answer based on a set of rules that extract information from representations of an algorithm’s internal states, the pseudocode. A design probe based on an algorithm learning scenario with 18 participants (9 for a Wizard-of-Oz XAlgo and 9 as a control group) reports findings and design implications based on what kinds of questions people ask, how well XAlgo responds, and what remain as challenges to bridge users’ gulf of algorithm understanding.","Question Answering, Algorithm, Design Probe, Explainable AI",IUI '21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vlasov AI,Demin AA",Visual Methods of Formalization of Knowledge in the Conditions of the Synchronous Technologies of System Engineering,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 13th Central & Eastern European Software Engineering Conference in Russia,"St. Petersburg, Russia",2017,9781450363969,,https://doi.org/10.1145/3166094.3166098;http://dx.doi.org/10.1145/3166094.3166098,10.1145/3166094.3166098,"The work is devoted to the analysis of complex systems visual modelling methods. A set of graphical models usage (graphical notation) methods and formal text description (text notation) methods is used. The conceptual, structure-functional, logical and physical levels of modelling are distinguished. In general the lower level of visual modelling reflects specific abstractions. The problem of encapsulation is also considered, which is caused by the fragmented nature of visual analysis and the isolation of available tools from application during different stages of the life cycle modelling. A method for solving these problems is proposed based on the creation of the VI-XML metalanguage (Visual Intelligence XML), which includes a description of rules, concepts and opinions, oriented to presenting components of visual models of different hierarchy levels. Based on the universal language of synchronous visual models VI-XML, a universal visual diagram editor VI (Visual Intelligence) has been created.","VI-XML metalanguage, knowledge processing, metadata management, synchronous technologies, visual modelling",CEE-SECR '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chbeir R,Laurent D",Towards a Novel Approach to Multimedia Data Mixed Fragmentation,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Management of Emergent Digital EcoSystems,France,2009,9781605588292,,https://doi.org/10.1145/1643823.1643860;http://dx.doi.org/10.1145/1643823.1643860,10.1145/1643823.1643860,"Distributed multimedia applications have emerged at an increasing rate during the last decade in several domains (video conferencing, e-health, virtual meeting rooms, etc). This has created several new challenging problems related to the data integration and fragmentation, user-oriented and adaptive interfaces, real time and network performances, etc.In this paper, we focus on the problem of data(base) fragmentation in a multimedia context. We recall in this respect that data fragmentation consists of reducing irrelevant data accesses by grouping data frequently accessed together in dedicated segments. We mainly address the issue of query and predicate implication required in current fragmentation algorithms, and provide a formal approach to identify such implications, in order to partition multimedia data efficiently. Our approach is capable of considering multimedia-based as well as semantic comparisons, both ignored in current studies but required when multimedia data come to play.","query implication, functional dependency, multimedia distance, data partition, pre-ordering, multimedia fragmentation",MEDES '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nacke L,Lindley CA",Flow and Immersion in First-Person Shooters: Measuring the Player's Gameplay Experience,,2008,,,81–88,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2008 Conference on Future Play: Research, Play, Share","Toronto, Ontario, Canada",2008,9781605582184,,https://doi.org/10.1145/1496984.1496998;http://dx.doi.org/10.1145/1496984.1496998,10.1145/1496984.1496998,"Researching experiential phenomena is a challenging undertaking, given the sheer variety of experiences that are described by gamers and missing a formal taxonomy: flow, immersion, boredom, excitement, challenge, and fun. These informal terms require scientific explanation, which amounts to providing measurable criteria for different experiential states. This paper reports the results of an experimental psychophysiological study investigating different traits of gameplay experience using subjective and objective measures. Participants played three Half-Life 2 game modifications while being measured with electroencephalography, electrocardiography, electromyography, galvanic skin response and eye tracking equipment. In addition, questionnaire responses were collected after each play session. A level designed for combat-oriented flow experience demonstrated measurable high-arousal positive affect emotions. The positive correlation between subjective and objective indicators of gameplay experience shows the great potential of the method presented here for providing real-time emotional profiles of gameplay that may be correlated with self-reported subjective descriptions.","game design, immersion, gameplay experience, psychophysiology, flow",Future Play '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Siersdorfer S,Sizov S",Meta Methods for Model Sharing in Personal Information Systems,ACM Trans. Inf. Syst.,2008,26,4,,Association for Computing Machinery,"New York, NY, USA",,,,2008-10,,1046-8188,https://doi.org/10.1145/1402256.1402261;http://dx.doi.org/10.1145/1402256.1402261,10.1145/1402256.1402261,"This article introduces a methodology for automatically organizing document collections into thematic categories for Personal Information Management (PIM) through collaborative sharing of machine learning models in an efficient and privacy-preserving way. Our objective is to combine multiple independently learned models from several users to construct an advanced ensemble-based decision model by taking the knowledge of multiple users into account in a decentralized manner, for example, in a peer-to-peer overlay network. High accuracy of the corresponding supervised (classification) and unsupervised (clustering) methods is achieved by restrictively leaving out uncertain documents rather than assigning them to inappropriate topics or clusters with low confidence. We introduce a formal probabilistic model for the resulting ensemble based meta methods and explain how it can be used for constructing estimators and for goal-oriented tuning. Comprehensive evaluation results on different reference data sets illustrate the viability of our approach.","clustering, restrictive methods, personal information management, Classification, peer-to-peer, meta methods",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Geng L,Yin C,Xiao Z,Zhang F,Wu J",Cutting Piece and CAD Matching Method Based on Feature Retrieval and Shape Segmentation,,2020,,,198–203,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 6th International Conference on Computing and Artificial Intelligence,"Tianjin, China",2020,9781450377089,,https://doi.org/10.1145/3404555.3404611;http://dx.doi.org/10.1145/3404555.3404611,10.1145/3404555.3404611,"In order to accurately measure the deviation between car seat cutting pieces and CAD templates, and then evaluate the production quality of car seat cutting pieces, this paper proposes a matching algorithm of car seat cutting pieces and CAD based on feature retrieval and shape segmentation. The processing object of this algorithm is the cutting piece images collected by the acquisition system that combines the backlight board and CCD camera. Firstly, according to the geometric characteristics of CAD, a CAD retrieval method based on image edge shape features was proposed. Then, in view of the flexible characteristics of car seat cutting piece, a matching algorithm of car seat cutting piece and CAD based on shape segmentation was proposed. Finally, the coordinate system of the cutting piece and CAD is unified by affine transformation, and the deviation between the two is calculated. A large number of experiments are performed in a field of view of 700x 500mm, and the results show that the method proposed in this paper can effectively improve the matching accuracy of the cutting piece and CAD. Experimental results verify the effectiveness of the proposed method.","Cutting piece, shape segmentation, template matching, CAD retrieval",ICCAI '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jiang B,Zhao X",An Image Dehazing Algorithm Based on Sky Region Detection,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Computer Science and Application Engineering,"Hohhot, China",2018,9781450365123,,https://doi.org/10.1145/3207677.3278066;http://dx.doi.org/10.1145/3207677.3278066,10.1145/3207677.3278066,"Images1 obtained in foggy days are degraded because the scatting of the atmosphere. The scatting of the atmosphere makes the image blurred, lowers the color contrast and makes the object features hard to distinguish. To address the problem that dark channel prior out of work to the sky area of images and atmospheric light misjudgment. We propose the fog removal algorithm combined with sky region detection. Firstly, we convert input image into a greyscale image. From the greyscale image, we calculate its corresponding edge image with the canny operator. Then, we define a function of sky boundary position and the preliminary sky region estimated. We estimate atmospheric light in the detected sky area. Finally, we use a fusion of ideas to estimate the transmission map, which based on the luminance and dark channel prior model with the adaptive weights. Meanwhile, we also quote fast guided filter, which saves computation time and is faster. The results of study show that the method effectively removes fog and has good time efficiency compared to other algorithms. In terms of visual effect, the texture of the sky area well restored and the fogless image recovered real and natural.","fast guided filter, luminance model, Dark channel prior, atmospheric light, sky region detection, transmission fusion",CSAE '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Li F,Qian Y,Wang J,Dang C,Liu B",Cluster’s Quality Evaluation and Selective Clustering Ensemble,ACM Trans. Knowl. Discov. Data,2018,12,5,,Association for Computing Machinery,"New York, NY, USA",,,,2018-06,,1556-4681,https://doi.org/10.1145/3211872;http://dx.doi.org/10.1145/3211872,10.1145/3211872,"Clustering ensemble has drawn much attention in recent years due to its ability to generate a high quality and robust partition result. Weighted clustering ensemble and selective clustering ensemble are two general ways to further improve the performance of a clustering ensemble method. Existing weighted clustering ensemble methods assign the same weight to each cluster in a partition of the ensemble. Since the qualities of the clusters in a partition are different, the clusters should be weighted differently. To address this issue, this article proposes a new measure to calculate the similarity between a cluster and a partition. Theoretically, this measure is effective in handling two problems in measuring the quality of a cluster, which are defined as the symmetric problem and the context meaning problem. In addition, some properties of the proposed measure are analyzed. This measure can be easily expanded to a clustering performance measure that calculates the similarity between two partitions. As a result of this measure, we propose a novel selective clustering ensemble framework, which considers the differences between the objective of the ensemble selection stage and the object of the ensemble integration stage in the selective clustering ensemble. To verify the performance of the new measure, we compare the performance of the measure with the two existing measures in weighting clusters. The experiments show that the proposed measure is more effective. To verify the performance of the novel framework, four existing state-of-the-art selective clustering ensemble frameworks are employed as references. The experiments show that the proposed framework is statistically better than the others on 17 UCI benchmark datasets, 8 document datasets, and the Olivetti Face Database.","Clustering ensemble, selective clustering ensemble, weighted clustering ensemble, cluster quality",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Fantechi A,Gnesi S,Lapadula A,Mazzanti F,Pugliese R,Tiezzi F",A Logical Verification Methodology for Service-Oriented Computing,ACM Trans. Softw. Eng. Methodol.,2012,21,3,,Association for Computing Machinery,"New York, NY, USA",,,,2012-07,,1049-331X,https://doi.org/10.1145/2211616.2211619;http://dx.doi.org/10.1145/2211616.2211619,10.1145/2211616.2211619,"We introduce a logical verification methodology for checking behavioral properties of service-oriented computing systems. Service properties are described by means of SocL, a branching-time temporal logic that we have specifically designed for expressing in an effective way distinctive aspects of services, such as, acceptance of a request, provision of a response, correlation among service requests and responses, etc. Our approach allows service properties to be expressed in such a way that they can be independent of service domains and specifications. We show an instantiation of our general methodology that uses the formal language COWS to conveniently specify services and the expressly developed software tool CMC to assist the user in the task of verifying SocL formulas over service specifications. We demonstrate the feasibility and effectiveness of our methodology by means of the specification and analysis of a case study in the automotive domain.","temporal logic, formal methods, Web services, model checking, Service-oriented computing, process calculi",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Y,Huang B,Yan X,Lin W,Wang G,Liu Z",Study on Characteristic Internal Resistance of Lithium Batteries Based on Double Pulse Test,,2019,,,258–262,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2019 International Conference on Robotics, Intelligent Control and Artificial Intelligence","Shanghai, China",2019,9781450372985,,https://doi.org/10.1145/3366194.3366239;http://dx.doi.org/10.1145/3366194.3366239,10.1145/3366194.3366239,"In this paper, our study takes lithium iron phosphate battery as the research object. In order to solve the problem of deviation in HPPC test, we propose a double pulse test method which is suitable for the calculation of characteristic internal resistance(CIR). Secondly, three lithium iron phosphate 18650 batteries were selected for the whole life cycle accelerated aging experiment, and the CIR was calculated according to the above method. The change rule of CIR in the whole life cycle was obtained. The relationship between CIR and SOH was divided into three stages in the whole life cycle: SOH=1 0.5, SOH=0.5 0.35, SOH < 0.35. Among them, there is a linear relationship between the CIR and SOH in the first stage, according to this relationship, a 280s double pulse test can be added to the charging process to estimate the SOH in practical application. In the second stage CIR increases rapidly and reaches the peak in a short time, wobbles near the peak after SOH<0.35. This phenomenon provides a reference for the utilization of second-use lithium-ion battery. It is recommended that second-use batteries retired when the SOH=0.35.","state of health SOH, whole life cycle, double pulse test, characteristic internal resistance(CIR), second-use",RICAI 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Benton L,Vasalou A,Berkling K,Barendregt W,Mavrikis M",A Critical Examination of Feedback in Early Reading Games,,2018,,,1–12,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems,"Montreal QC, Canada",2018,9781450356206,,https://doi.org/10.1145/3173574.3173947;http://dx.doi.org/10.1145/3173574.3173947,10.1145/3173574.3173947,"Learning games now play a role in both formal and informal learning, including foundational skills such as literacy. While feedback is recognised as a key pedagogical dimension of these games, particularly in early learning, there has been no research on how commercial games available to schools and parents reify learning theory into feedback. Using a systematic content analysis, we examine how evidence-based feedback principles manifest in five widely-used learning games designed to foster young children's reading skills. Our findings highlight strengths in how games deliver feedback when players succeed. Many of the games, however, were inconsistent and not proactive when providing error feedback, often promoting trial and error strategies. Furthermore, there was a lack of support for learning the game mechanics and a preference for task-oriented rewards less deeply embedded in the gameplay. Our research provides a design and research agenda for the inclusion of feedback in early learning games.","feedback, reading, children, learning games",CHI '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hardey K,Corapcioglu E,Mattis M,Goadrich M,Jadud M",Exploring and Evolving Process-Oriented Control for Real and Virtual Fire Fighting Robots,,2012,,,105–112,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th Annual Conference on Genetic and Evolutionary Computation,"Philadelphia, Pennsylvania, USA",2012,9781450311779,,https://doi.org/10.1145/2330163.2330179;http://dx.doi.org/10.1145/2330163.2330179,10.1145/2330163.2330179,"Current research in evolutionary robotics is largely focused on creating controllers by either evolving neural networks or refining genetic programs based on grammar trees. We propose the use of the parallel, dataflow languages for the construction of effective robotic controllers and the evolution of new controllers using genetic programming techniques. These languages have the advantages of being built on concurrent execution frameworks that lend themselves to formal verification along with being visualized as a dataflow graph. In this paper, we compare and contrast the development and subsequent evolution of one such process-oriented control algorithm. Our control software was built from composable, communicating processes executing in parallel, and we tested our solution in an annual fire-fighting robotics competition. Subsequently, we evolved new controllers in a virtual simulation of this parallel dataflow domain, and in doing so discovered and quantified more efficient solutions. This research demonstrates the effectiveness of using process networks as the basis for evolutionary robotics.","concurrency, occam-pi, csp, evolutionary robotics",GECCO '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Noorian Z,Fleming M,Marsh S",Preference-Oriented QoS-Based Service Discovery with Dynamic Trust and Reputation Management,,2012,,,2014–2021,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th Annual ACM Symposium on Applied Computing,"Trento, Italy",2012,9781450308571,,https://doi.org/10.1145/2245276.2232111;http://dx.doi.org/10.1145/2245276.2232111,10.1145/2245276.2232111,"In the presence of a variety of service providers that offer web services with overlapping or identical functionality, service consumers need a mechanism to distinguish one service from another based on their own subjective quality of service (QoS) preferences. Typical approaches in this field rely on trusted third parties to monitor the behaviour of service providers and endorse their performance based on their delivered services to different users. However, the issue of evaluating the credibility of user reports is one of the essential problems yet to be solved in the e-Business application area. In this paper we propose a two-layered preference-oriented service selection framework that integrates trust and reputation management techniques with an advanced procurement auction model in order to choose the most pertinent service provider that meets a consumer's QoS requirements. We will give a formal description of our approach and validate it with experiments demonstrating that our solution yields high-quality results under various realistic circumstances.","electronic auction model, QoS-based service selection, trust, consumer's preferences, reputation management",SAC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bylieva D,Lobatyuk V,Ershova N",Computer Technology in Art (Venice Biennale 2019),,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the XI International Scientific Conference Communicative Strategies of the Information Society,"St. Petersburg, Russian Federation",2019,9781450376709,,https://doi.org/10.1145/3373722.3373785;http://dx.doi.org/10.1145/3373722.3373785,10.1145/3373722.3373785,"Computer technology has penetrated all spheres of human life and firmly settled in fine art, music, and theater. Research that is presented in this article is aimed at analysis of the digital and multimedia technology used in creations by the video and media artists shown at the 2019 Biennale. The main objective stated by the authors is to trace the inner trends in visual arts developed due to the new possibilities both substantially and formally. Though the tendency of art digitalization was traced long enough the Venice Biennale has not yet been studied from this point of view while its importance is hard to overestimate. This research is based upon analysis of more than 200 artistic works with the use of a multidisciplinary approach to investigate computer technology in art as a complicated social phenomenon in the sociology of culture and communication. Authors suggest a classifying of multimedia technology used in the context of meaning and according to growing complexity: background/comments, space widening, attaching other meanings to an art object, immersion of the spectator into the video flow. Thus authors underline an influence of technological progress on the artistic thought leading to the creation of the total environment surrounding spectators and involving them into a certain kind of a new reality.","video, digital art, Venice Biennale, Art, computer technologies",CSIS'2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Matos AA,Santos JF",Typing Illegal Information Flows as Program Effects,,2012,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th Workshop on Programming Languages and Analysis for Security,"Beijing, China",2012,9781450314411,,https://doi.org/10.1145/2336717.2336718;http://dx.doi.org/10.1145/2336717.2336718,10.1145/2336717.2336718,"Specification of information flow policies is classically based on a security labeling and a lattice of security levels that establishes how information can flow between security levels. We present a type and effect system for determining the least permissive relaxation of a given confidentiality policy that allows to type a program, given a fixed security labeling. To this end, sets of illegal information flows are represented as downward closure operators (here referred to as flow kernels) on a given lattice of security levels. Illegal information flows can then be seen as program effects, and their representation as flow kernels subsumes in granularity previous lattice-oriented representations of information flow policies. Effect soundness, optimality and preservation results are presented for the proposed type and effect system, for programs written in a concurrent higher-order imperative lambda-calculus with reference creation.Our type and effect system provides a mechanism for deriving the flow kernel that characterizes the illegal flows that occur within a program, and which can be used to support runtime decisions of compliance to other policies. This point is illustrated by means of an application to a setting where local programs run under the control of a dynamic allowed flow policy.",,PLAS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Achtaich A,Roudies O,Souissi N,Salinesi C,Mazo R",Evaluation of the State-Constraint Transition Modelling Language: A Goal Question Metric Approach,,2019,,,106–113,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Systems and Software Product Line Conference - Volume B,"Paris, France",2019,9781450366687,,https://doi.org/10.1145/3307630.3342417;http://dx.doi.org/10.1145/3307630.3342417,10.1145/3307630.3342417,"Self-adaptive systems (SAS) are exceptional systems, on account of their versatile composition, dynamic behavior and evolutive nature. Existing formal languages for the specification of SAS focus on adapting system elements to achieve a target goal, following specific rules, without much attention on the adaptation of requirements themselves. The State-Constraint Transition (SCT) modeling language enables the specification of dynamic requirements, both at the domain and application level, as a result of space or time variability. This language, evaluated in this paper, enables the specification of a variety of requirement types, for SASs from different domains, while generating a configuration, all configurations, and number of possible configurations, in milliseconds. This paper presents these results, namely; expressiveness, domain independence and scalability, from the viewpoint of designers and domain engineers, following a goal-question-metric approach. However, being primarily based on constraint programming (CP), the language suffers from drawbacks inherited from this paradigm, specifically time related requirements, like (e.g. order, frequency and staged requirements).","constraint programming, dynamic software product lines, modeling language, state machine, IoT",SPLC '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Singal R,Besbes O,Desir A,Goyal V,Iyengar G",Shapley Meets Uniform: An Axiomatic Framework for Attribution in Online Advertising,,2019,,,1713–1723,Association for Computing Machinery,"New York, NY, USA",,The World Wide Web Conference,"San Francisco, CA, USA",2019,9781450366748,,https://doi.org/10.1145/3308558.3313731;http://dx.doi.org/10.1145/3308558.3313731,10.1145/3308558.3313731,"One of the central challenges in online advertising is attribution, namely, assessing the contribution of individual advertiser actions including emails, display ads and search ads to eventual conversion. Several heuristics are used for attribution in practice; however, there is no formal justification for them and many of these fail even in simple canonical settings. The main contribution in this work is to develop an axiomatic framework for attribution in online advertising. In particular, we consider a Markovian model for the user journey through the conversion funnel, in which ad actions may have disparate impacts at different stages. We propose a novel attribution metric, that we refer to as counterfactual adjusted Shapley value, which inherits the desirable properties of the traditional Shapley value. Furthermore, we establish that this metric coincides with an adjusted “unique-uniform” attribution scheme. This scheme is efficiently computable and implementable and can be interpreted as a correction to the commonly used uniform attribution scheme.","Markov chain, attribution, Digital economy, online advertising, Shapley value, causality",WWW '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Teraguchi T,Yamashita H,Masamune K,Dohi T,Liao H",Three-Dimensional Auto-Stereoscopic Animated Image with a Long Viewing Distance Using High-Precision Image Correction,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,SIGGRAPH '09: Posters,"New Orleans, Louisiana",2009,9781450379281,,https://doi.org/10.1145/1599301.1599323;http://dx.doi.org/10.1145/1599301.1599323,10.1145/1599301.1599323,"Three-dimensional (3-D) displays have got a lot of attention because they have a much higher sense of realism and are more intuitive than 2-D displays. In particular, autostereoscopic displays are suitable for everyday use because they can be observed from an arbitrary viewpoint without supplementary glasses or tracking devices. Integral Videography (IV) is one of the methods for autostereoscopic animated images that extends Integral Photography (IP) to animation. IP/IV uses a combination of a lens array and a number of calculated elemental images with different perspectives. In particular, IV with a depth of several meters can be applied in many areas. However, most IV reports have an image depth of only several centimeters. Only a small deviation of a lens from its designed position would result in several degrees of deviation of the light ray from the back of the lens. We have developed the static autostereoscopic image by projecting the light sources from an object onto a photographic film through the lens-array [Liao et al. 2005]. In this study, we obtained animated IV of 1 m image depth with less distortion using our method to correct IV images. The method is technically unique.",,SIGGRAPH '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shraga R,Roitman H,Feigenblat G,Cannim M",Web Table Retrieval Using Multimodal Deep Learning,,2020,,,1399–1408,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval,"Virtual Event, China",2020,9781450380164,,https://doi.org/10.1145/3397271.3401120;http://dx.doi.org/10.1145/3397271.3401120,10.1145/3397271.3401120,"We address the web table retrieval task, aiming to retrieve and rank web tables as whole answers to a given information need. To this end, we formally define web tables as multimodal objects. We then suggest a neural ranking model, termed MTR, which makes a novel use of Gated Multimodal Units (GMUs) to learn a joint-representation of the query and the different table modalities. We further enhance this model with a co-learning approach which utilizes automatically learned query-independent and query-dependent \helper'' labels. We evaluate the proposed solution using both ad hoc queries (WikiTables) and natural language questions (GNQtables). Overall","we demonstrate that our approach surpasses the performance of previously studied state-of-the-art baselines.""","multimodal deep-learning, experimentation, table retrieval",SIGIR '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wu Z,Lu Z,Ho SY",Community Detection with Topological Structure and Attributes in Information Networks,ACM Trans. Intell. Syst. Technol.,2016,8,2,,Association for Computing Machinery,"New York, NY, USA",,,,2016-11,,2157-6904,https://doi.org/10.1145/2979681;http://dx.doi.org/10.1145/2979681,10.1145/2979681,"Information networks contain objects connected by multiple links and described by rich attributes. Detecting community for these networks is a challenging research problem, because there is a scarcity of effective approaches that balance the features of the network structure and the characteristics of the nodes. Some methods detect communities by considering topological structures while ignoring the contributions of attributes. Other methods have considered both topological structure and attributes but pay a high price in time complexity. We establish a new community detection algorithm which explores both topological Structure and Attributes using Global structure and Local neighborhood features (SAGL) which also has low computational complexity. The first step of SAGL evaluates the global importance of every node and calculates the similarity of each node pair by combining edge strength and node attribute similarity. The second step of SAGL uses a clustering algorithm that identifies communities by measuring the similarity of two nodes, calculated by the distance of their neighbors. Experimental results on three real-world datasets show the effectiveness of SAGL, particularly its fast convergence compared to current state-of-the-art attributed graph clustering methods.","global importance, attribute similarity, Community detection, topological structure",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tsitsulin A,Mottin D,Karras P,Bronstein A,Müller E",NetLSD: Hearing the Shape of a Graph,,2018,,,2347–2356,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining,"London, United Kingdom",2018,9781450355520,,https://doi.org/10.1145/3219819.3219991;http://dx.doi.org/10.1145/3219819.3219991,10.1145/3219819.3219991,"Comparison among graphs is ubiquitous in graph analytics. However, it is a hard task in terms of the expressiveness of the employed similarity measure and the efficiency of its computation. Ideally, graph comparison should be invariant to the order of nodes and the sizes of compared graphs, adaptive to the scale of graph patterns, and scalable. Unfortunately, these properties have not been addressed together. Graph comparisons still rely on direct approaches, graph kernels, or representation-based methods, which are all inefficient and impractical for large graph collections. In this paper, we propose the Network Laplacian Spectral Descriptor (NetLSD): the first, to our knowledge, permutation- and size-invariant, scale-adaptive, and efficiently computable graph representation method that allows for straightforward comparisons of large graphs. NetLSD extracts a compact signature that inherits the formal properties of the Laplacian spectrum, specifically its heat or wave kernel; thus, it em hears the shape of a graph. Our evaluation on a variety of real-world graphs demonstrates that it outperforms previous works in both expressiveness and efficiency.","graph signature, graph similarity, graph theory, graph comparison, heat kernel, graph topology, graph geometry, heat kernel analysis, graph representation, data mining",KDD '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Lavaee R,The Hardness of Data Packing,,2016,,,232–242,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 43rd Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages,"St. Petersburg, FL, USA",2016,9781450335492,,https://doi.org/10.1145/2837614.2837669;http://dx.doi.org/10.1145/2837614.2837669,10.1145/2837614.2837669,"A program can benefit from improved cache block utilization when contemporaneously accessed data elements are placed in the same memory block. This can reduce the program's memory block working set and thereby, reduce the capacity miss rate. We formally define the problem of data packing for arbitrary number of blocks in the cache and packing factor (the number of data objects fitting in a cache block) and study how well the optimal solution can be approximated for two dual problems. On the one hand, we show that the cache hit maximization problem is approximable within a constant factor, for every fixed number of blocks in the cache. On the other hand, we show that unless P=NP, the cache miss minimization problem cannot be efficiently approximated.","cache block utilization, Data packing, proximity hyper- graph, block reuse interval",POPL '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Lavaee R,The Hardness of Data Packing,SIGPLAN Not.,2016,51,1,232–242,Association for Computing Machinery,"New York, NY, USA",,,,2016-01,,0362-1340,https://doi.org/10.1145/2914770.2837669;http://dx.doi.org/10.1145/2914770.2837669,10.1145/2914770.2837669,"A program can benefit from improved cache block utilization when contemporaneously accessed data elements are placed in the same memory block. This can reduce the program's memory block working set and thereby, reduce the capacity miss rate. We formally define the problem of data packing for arbitrary number of blocks in the cache and packing factor (the number of data objects fitting in a cache block) and study how well the optimal solution can be approximated for two dual problems. On the one hand, we show that the cache hit maximization problem is approximable within a constant factor, for every fixed number of blocks in the cache. On the other hand, we show that unless P=NP, the cache miss minimization problem cannot be efficiently approximated.","Data packing, block reuse interval, proximity hyper- graph, cache block utilization",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lu R,Lin X,Liang X,Shen Xsherman",Secure Provenance: The Essential of Bread and Butter of Data Forensics in Cloud Computing,,2010,,,282–292,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 5th ACM Symposium on Information, Computer and Communications Security","Beijing, China",2010,9781605589367,,https://doi.org/10.1145/1755688.1755723;http://dx.doi.org/10.1145/1755688.1755723,10.1145/1755688.1755723,"Secure provenance that records ownership and process history of data objects is vital to the success of data forensics in cloud computing, yet it is still a challenging issue today. In this paper, to tackle this unexplored area in cloud computing, we proposed a new secure provenance scheme based on the bilinear pairing techniques. As the essential bread and butter of data forensics and post investigation in cloud computing, the proposed scheme is characterized by providing the information confidentiality on sensitive documents stored in cloud, anonymous authentication on user access, and provenance tracking on disputed documents. With the provable security techniques, we formally demonstrate the proposed scheme is secure in the standard model.","standard model, data forensics, provable security, privacy, cloud computing, secure provenance",ASIACCS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Nikolov S,Nikolov V,Antonov A",A Constraint-Based Approach for Analysing Financial Market Operations,,2013,,,231–238,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th International Conference on Computer Systems and Technologies,"Ruse, Bulgaria",2013,9781450320214,,https://doi.org/10.1145/2516775.2516780;http://dx.doi.org/10.1145/2516775.2516780,10.1145/2516775.2516780,The article describes a framework for modelling and verification of constraint rules on operations with financial instruments. These constraints are applied on certain attributes of domains of financial objects. A methodology and implementation of automatic constraint analysis in two steps is presented. The first step involves preparation of constraints on specified domains and creation of formulas defining them. The other step consists in waiting for real time transactions and responding to them by alerting the user on newly occurred constraint violations. Computation reduction method is proposed. A satisfaction coefficient is calculated that aids the end user in taking consecutive actions on their portfolio.,"financial systems, constraint satisfaction problems, expert systems, programming approaches, finance",CompSysTech '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lu L,Ye W,Tao J",The Research of Amplitude Threshold Method in Ultrasound-Based Indoor Distance-Measurement System,,2020,,,323–327,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 4th International Conference on Electronic Information Technology and Computer Engineering,"Xiamen, China",2020,9781450387811,,https://doi.org/10.1145/3443467.3443776;http://dx.doi.org/10.1145/3443467.3443776,10.1145/3443467.3443776,"In this paper, an amplitude threshold algorithm (ATA) is proposed to estimate time of flight (ToF) of ultrasound signal (US) under high signal noise ratio (SNR) in ultrasound-based indoor distance-measurement system. The purpose of the research is to accurately measure ToF of US and further calculate the distance between ultrasound transceiver. ATA determines ToF based on the time when the monitored signal amplitude first goes above a corresponding threshold. ATA can achieve accurate ToF estimation under high SNR. Furthermore, compared to other ToF estimation algorithms, ATA has the lower algorithm complexity leading to shorter processing time, therefore, ATA is appropriate for the real-time dynamic measurement. In this research, an ultrasound-based indoor distance-measurement system was generated to synchronize the input and output of analog signal and provide high-quality signal. ATA estimated the distance between ultrasound transceiver in the range of 5 meters. The experimental result shows that ATA has relatively high accuracy under high SNR and fast processing speed. Based on the distance-measurement system, an ultrasound-based indoor localization system which aims to localize a static object on two dimensions could be established in the future, some preparatory works has been done and the architecture of the localization system is presented.","Signal noise ratio (SNR), Ultrasound signal (US), Amplitude threshold algorithm (ATA), Time of flight (ToF)",EITCE 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Hanocka R,Metzer G,Giryes R,Cohen-Or D",Point2Mesh: A Self-Prior for Deformable Meshes,ACM Trans. Graph.,2020,39,4,,Association for Computing Machinery,"New York, NY, USA",,,,2020-07,,0730-0301,https://doi.org/10.1145/3386569.3392415;http://dx.doi.org/10.1145/3386569.3392415,10.1145/3386569.3392415,"In this paper, we introduce Point2Mesh, a technique for reconstructing a surface mesh from an input point cloud. Instead of explicitly specifying a prior that encodes the expected shape properties, the prior is defined automatically using the input point cloud, which we refer to as a self-prior. The self-prior encapsulates reoccurring geometric repetitions from a single shape within the weights of a deep neural network. We optimize the network weights to deform an initial mesh to shrink-wrap a single input point cloud. This explicitly considers the entire reconstructed shape, since shared local kernels are calculated to fit the overall object. The convolutional kernels are optimized globally across the entire shape, which inherently encourages local-scale geometric self-similarity across the shape surface. We show that shrink-wrapping a point cloud with a self-prior converges to a desirable solution; compared to a prescribed smoothness prior, which often becomes trapped in undesirable local minima. While the performance of traditional reconstruction approaches degrades in non-ideal conditions that are often present in real world scanning, i.e., unoriented normals, noise and missing (low density) parts, Point2Mesh is robust to non-ideal conditions. We demonstrate the performance of Point2Mesh on a large variety of shapes with varying complexity.","surface reconstruction, geometric deep learning, shape analysis",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Lavaee R,The Hardness of Data Packing,SIGPLAN Not.,2016,51,1,232–242,Association for Computing Machinery,"New York, NY, USA",,,,2016-01,,0362-1340,https://doi.org/10.1145/2914770.2837669;http://dx.doi.org/10.1145/2914770.2837669,10.1145/2914770.2837669,"A program can benefit from improved cache block utilization when contemporaneously accessed data elements are placed in the same memory block. This can reduce the program's memory block working set and thereby, reduce the capacity miss rate. We formally define the problem of data packing for arbitrary number of blocks in the cache and packing factor (the number of data objects fitting in a cache block) and study how well the optimal solution can be approximated for two dual problems. On the one hand, we show that the cache hit maximization problem is approximable within a constant factor, for every fixed number of blocks in the cache. On the other hand, we show that unless P=NP, the cache miss minimization problem cannot be efficiently approximated.","block reuse interval, proximity hyper- graph, Data packing, cache block utilization",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang Y,Li T,Qian F,Zhang T",Analysis on Real-World Emissions Data of CNG-Gasoline Bi-Fuel Taxi,,2018,,,183–186,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Asia-Pacific Conference on Intelligent Medical 2018 & International Conference on Transportation and Traffic Engineering 2018,"Beijing, China",2018,9781450366045,,https://doi.org/10.1145/3321619.3321677;http://dx.doi.org/10.1145/3321619.3321677,10.1145/3321619.3321677,"The rapid growth of motor vehicles not only brings tremendous pressure on urban transportation, but also has a harmful effect on the urban environment. In order to alleviate the problems of air pollution, taxis in many Chinese cities have been converted to CNG-gasoline bi-fuel vehicles in recent years. However, data supporting on the change of the real-world emission of converted taxi using different fuels are missing. In the study, a typical Bi-fuel taxi was chosen as the test object, the second by second emission data was obtained by SEMTECH-DS vehicle test instrument, then the emission characteristics and differences of the taxi using two different fuels were analyzed. The results show that the instantaneous emission rates of bi-fuel taxi using CNG or gasoline have reached the maximum and minimum values in acceleration and idle condition, respectively; pollutant contribution rates of taxi all reach maximum values in acceleration condition; nevertheless, in the other driving patterns, different fuels show different changing tendency. The findings also could provide the appropriate data for calculating environmental benefits of the alternatives fuel and offer theoretical support for the decision makers.","Driving patterns, Bi-fuel vehicles, SEMTECH-DS, Vehicle emissions",APCIM & ICTTE 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Abdelhafidh M,Fourati M,Fourati LC,Mnaouer AB,Zid M",Cognitive Internet of Things for Smart Water Pipeline Monitoring System,,2018,,,212–219,IEEE Press,"Madrid, Spain",,Proceedings of the 22nd International Symposium on Distributed Simulation and Real Time Applications,,2018,9781538650486,,,,"Water Pipeline Monitoring System (WPMS) is extremely important considering the several pipeline damages and the various hydraulic failures that cause a critical water loss. In this context, Cognitive Water Distribution System integrates Internet of Things (IoT) technology, based on smart sensors, actuators and connected objects, with a reliable Big Data processing for smart and robust Structural Health Monitoring (SHM) of pipelines. In this paper, we propose a cognitive IoT-based architecture where we used Apache Spark framework to maintain a real time processing of the large amount of collected data. This efficient processing of measured data and its correspondent calculated values simplify the transient simulations and leak detection and make it faster and easier.","water monitoring system, big data, simulation, cognitive IoT",DS-RT '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jin J,Ji P,Liu Y",Product Characteristic Weighting for Designer from Online Reviews: An Ordinal Classification Approach,,2012,,,33–40,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2012 Joint EDBT/ICDT Workshops,"Berlin, Germany",2012,9781450311434,,https://doi.org/10.1145/2320765.2320784;http://dx.doi.org/10.1145/2320765.2320784,10.1145/2320765.2320784,"Online product reviews are a reliable source of customers' sentiments. Directly connecting with customers and designers, online reviews can shorten product development life cycles. The problem arising is, although different techniques for processing online reviews are developed, the techniques are rarely seen on accelerating the design work flows. This paper proposes a two stage framework to learn the importance of characteristics from online reviews which could benefit product design. The first stage is a supervised learning routine to identify product characteristics. This procedure calculates the surrounding words' posterior probability. A linear weight learning algorithm is subsequently shown to reach the product characteristics identification. The second stage focus on meeting customers' needs. Distinct from existing classification and rank algorithms, this stage informs an ordinal classification algorithm to balance the weight of product characteristics. This algorithm depicts a pairwise approach to achieve ordinal classification. Furthermore, an integer none linear programming model is advised, which targets at recovering pairwise results to the original class for each object. Four brands of printer reviews from Amazon and real analysis from two experienced product designers are employed in this experimental study. The results validate the feasibility of the two stage framework, and the possibility to explore targeted models from online reviews for product designers.","review analysis, product review, opinion mining",EDBT-ICDT '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Detorakis Z,Tambouratzis G",Discovery of Underlying Morphological Relations Using an Agglomerative Clustering Algorithm,,2008,,,198–204,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology,"Cergy-Pontoise, France",2008,9781605580463,,https://doi.org/10.1145/1456223.1456267;http://dx.doi.org/10.1145/1456223.1456267,10.1145/1456223.1456267,"This paper presents a hierarchical clustering algorithm aimed at creating groups of stems with similar characteristics. The resulting groups (clusters) are expected to comprise stems belonging to the same inflectional paradigm (e.g. verbs in passive voice) which will aid the creation of a morphological lexicon. A new metric for calculating the distance between the data objects is proposed, that better suits the specific application by addressing problems that may occur due to the limited amount of information from the data. A series of experimental results are also provided, that demonstrate the performance of the algorithm, compare different distance metrics in terms of their effectiveness and assist in choosing appropriate approaches for a number of parameters.","inflectional paradigm, hamming distance, cluster validity, cluster proximity, agglomerative clustering",CSTST '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Almahmoud AA,E-Services Integration Framework Based on SOA,,2020,,,1–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 12th International Conference on Information Management and Engineering,"Amsterdam, Netherlands",2020,9781450387521,,https://doi.org/10.1145/3430279.3430280;http://dx.doi.org/10.1145/3430279.3430280,10.1145/3430279.3430280,"A group of governmental agencies is connected over a virtual private network (VPN), and uses variant computing systems to perform the daily tasks, they need to exchange formal data electronically, at the same time, and they cannot replace their legacy systems. In this research, I will study this case and propose a suitable solution based on service-oriented architecture (SOA), which has proven highly efficiency within the integration of distributed systems. The research has developed e-services to extract data from the legacy systems as per each agency policy, designed and developed a framework, which will conduct data exchanging between e-services, monitor e-services consuming, notify providers by the recent activities and apply the security policy. In addition, the research has tested the performance of the solution over variable loads, scanned the security gaps and proposed a load balancing method to maintain the stability of the system on subscribers increase in number.","Service Oriented Architecture, Web Services Description Language, Enterprise Service Bus, WS-Security, Simple Object Access Protocol, Virtual Private Network",ICIME 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Belardinelli F,Verification of Non-Uniform and Unbounded Artifact-Centric Systems: Decidability through Abstraction,,2014,,,717–724,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 2014 International Conference on Autonomous Agents and Multi-Agent Systems,"Paris, France",2014,9781450327381,,,,"The formal verification of Artifact-centric (AC) systems is a subject of growing interest in the Service Oriented Computing (SOC) community, which can benefit from techniques developed for Multi-agent systems and knowledge reasoning and representation. In the present contribution we consider the verification of AC systems that do not necessarily satisfy boundedness and uniformity, the typical assumptions used to prove decidability of the model checking problem in this setting. We provide a partial model checking procedure for agent-based AC systems against a first-order temporal logic that includes modal operators for agent knowledge. Interestingly, we obtain this result by introducing a counterpart semantics for first-order modal logic, and by defining notions of simulation and abstraction for this setting. This allows us to generate finite abstractions of infinite-state AC systems, even when these are not bounded nor uniform, thus enabling us to perform verification also in cases not covered by the current state-of-the-art.","verification of agent-based systems, temporal epistemic logic",AAMAS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"ter Beek MH,Lafuente AL,Petrocchi M",Combining Declarative and Procedural Views in the Specification and Analysis of Product Families,,2013,,,10–17,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th International Software Product Line Conference Co-Located Workshops,"Tokyo, Japan",2013,9781450323253,,https://doi.org/10.1145/2499777.2500722;http://dx.doi.org/10.1145/2499777.2500722,10.1145/2499777.2500722,"We introduce the feature-oriented language FLan as a proof of concept for specifying both declarative aspects of product families, namely constraints on their features, and procedural aspects, namely feature configuration and run-time behaviour. FLan is inspired by the concurrent constraint programming paradigm. A store of constraints allows one to specify in a declarative way all common constraints on features, including inter-feature constraints. A standard yet rich set of process-algebraic operators allows one to specify in a procedural way the configuration and behaviour of products. There is a close interaction between both views: (i) the execution of a process is constrained by its store to forbid undesired configurations; (ii) a process can query a store to resolve design and behavioural choices; (iii) a process can update the store by adding new features. An implementation in the Maude framework allows for a variety of formal automated analyses of product families specified in FLan, ranging from consistency checking to model checking.","product families, process algebra, concurrent constraint programming, variability, behavioural analyses, Maude",SPLC '13 Workshops,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Elstermann M,Fleischmann A",Modeling Complex Process Systems with Subject-Oriented Means,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Subject-Oriented Business Process Management,"Seville, Spain",2019,9781450362504,,https://doi.org/10.1145/3329007.3329008;http://dx.doi.org/10.1145/3329007.3329008,10.1145/3329007.3329008,"In an organization more or less all business processes are interconnected forming a large network or ecosystem of related activities. To describe (model) such complex process systems a formal language must offer the possibility to structure the according models. It must allow to describe the environment of a considered process and illustrates its relationships to other process models. Furthermore, it should not require that all connected models are created at the same time by the same persons with the same knowledge about all other process models and their constraints. In this article we describe a method to model business process model systems with an arbitrary number of abstraction levels. We introduce the structuring concept in the subject-oriented language PASS and show how the concept can be also applied in BPMN models. Furthermore, we present a fundamental discussion and disagreement about extends and choice of vocabulary that is derived from this concept.","process architecture, S-BPM. PASS, complex business processes",S-BPM ONE '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Joshi M,Joshi T,Rangaswamy N",Scaling Classroom IT Skill Tutoring: A Case Study from India,,2018,,,1–12,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems,"Montreal QC, Canada",2018,9781450356206,,https://doi.org/10.1145/3173574.3174204;http://dx.doi.org/10.1145/3173574.3174204,10.1145/3173574.3174204,"India is home to the largest under-25 demographic profile in the world, but lacks a job-ready educational system. It requires a wide-spread, skill-oriented educational model, equipping youth to thrive in highly dynamic job markets. As a response to the huge demand for technical education, a large private skill-tutoring ecosystem has sprung up in In-dia but remains geographically limited. This paper, drawn from a three-month ethnographic research conducted in Ameerpet (arguably India's largest IT skilling hub), probes the pedagogic style and characteristics of tutoring, and of-fers reasons why learners prefer to enroll into a physical model of classroom teaching over online courses. We make design suggestions for online learning platforms to attract students who are marginalized in the more formal and com-petitive education system, and opt for Ameerpet-like skill-hubs. Our primary offering is to suggest a shift in perspec-tive of online education platforms to include job readiness and accompanying changes in course content and delivery.","ethnography, india, technical education, it skills, blended learning",CHI '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fan J,Zhang AX",Digital Juries: A Civics-Oriented Approach to Platform Governance,,2020,,,1–14,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems,"Honolulu, HI, USA",2020,9781450367080,,https://doi.org/10.1145/3313831.3376293;http://dx.doi.org/10.1145/3313831.3376293,10.1145/3313831.3376293,"As concerns have grown regarding harmful content spread on social media, platform mechanisms for content moderation have become increasingly significant. However, many existing platform governance structures lack formal processes for democratic participation by users of the platform. Drawing inspiration from constitutional jury trials in many legal systems, this paper proposes digital juries as a civics-oriented approach for adjudicating content moderation cases. Building on existing theoretical models of jury decision-making, we outline a 5-stage model characterizing the space of design considerations in a digital jury process. We implement two examples of jury designs involving blind-voting and deliberation. From users who participate in our jury implementations, we gather informed judgments of the democratic legitimacy of a jury process for content moderation. We find that digital juries are perceived as more procedurally just than existing common platform moderation practices, but also find disagreement over whether jury decisions should be enforced or used as recommendations.","content moderation, social media, governance, online speech, civics, democracy, juries, institutional design, platforms",CHI '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Barnickel N,Fluegge M",Towards a Conceptual Framework for Semantic Interoperability in Service Oriented Architectures,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st International Conference on Intelligent Semantic Web-Services and Applications,"Amman, Jordan",2010,9781450304757,,https://doi.org/10.1145/1874590.1874602;http://dx.doi.org/10.1145/1874590.1874602,10.1145/1874590.1874602,"The application of Semantic Web technologies to service-oriented architectures (SOA) has promised to mitigate the problem of achieving semantic interoperability as the formal definition of semantics paves the way for higher automation in the mediation process between heterogeneous services. Recently, many ontology-based approaches for semantic interoperability have been developed. However, it remains difficult to compare the various approaches because only domain-specific conceptual frameworks for semantic interoperability exist. Moreover, in SOA practice ontology-based approaches are not widely adopted but still XML-based solutions are dominant. This paper targets to fill this gap and presents ongoing work towards a general conceptual framework for semantic interoperability in SOA as a foundation for comparative reflection. Based on the framework selected approaches both academic and industry-driven are compared. Furthermore, an inherent trade-off between efficiency and effectiveness in achieving semantic interoperability is identified and a potential alleviation based on semantic mediation on domain level is outlined.","semantic interoperability, conceptual framework, ontology mapping, semantic mediation, semantic web technologies, service-oriented architectures",ISWSA '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jia C,Kong F,Jia C",Saliency Detection Based on Weighted Color Contrast of Image Patch,,2020,,,90–94,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 the 4th International Conference on Innovation in Artificial Intelligence,"Xiamen, China",2020,9781450376587,,https://doi.org/10.1145/3390557.3394125;http://dx.doi.org/10.1145/3390557.3394125,10.1145/3390557.3394125,"Image saliency analysis is an important research content in the field of computer vision. At present, the main method of saliency analysis is to measure the saliency of single pixel or regular image patch. It is easy to be affected by image texture, noise and other factors, and some important information is lost in the process of segmentation, which makes it difficult to extract salient objects from the image. Therefore, a saliency detection algorithm based on weighted color contrast of image patch is proposed. Firstly, the original image is divided into different size and non-overlapping image patch structure. Then, the color contrast of the image patch, the number of pixels included and the spatial distance between the two image patches are calculated. Considering the influence of spatial distance between image patches on saliency value, the weighted color contrast model of image patch is used to detect salient region. Finally, considering the influence of spatial distance between pixels on saliency value, the salient region is enhanced by calculating the distance between each pixel and the center of the salient region. In order to evaluate this algorithm, we use the largest publicly available data set in the world for testing. Experimental results show that the proposed method has better precision and recall rate, can significantly suppress the influence of complex texture and noise.","Visual Attention Mechanism, Image Salient Region, Image Patch Structure, Weighted Color Contrast",ICIAI 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li H,Ahn M,Lim J,Bok K,Choi H,Yoo J",An Efficient Mobile Social Search Method,,2014,,,82–85,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2014 Conference on Research in Adaptive and Convergent Systems,"Towson, Maryland",2014,9781450330602,,https://doi.org/10.1145/2663761.2664238;http://dx.doi.org/10.1145/2663761.2664238,10.1145/2663761.2664238,"With the rapid development of internet technology, social networks and social searches are becoming popularly. Unlike traditional web searches, the social search provides optimal search results according to user preferences. In this paper, we propose a mobile social search method based on popularities and user preferences. The popularity is calculated by collecting the visiting records of users. The user preferences are generated by the actual visiting information among the search results. We process a skyline query to extract the meaningful information from the candidate objects with multiple features. The proposed method ranks social search results by combining user preferences and popularity with the skyline query processing mechanism. To show the superiority of the proposed method, we compare it with the existing method through performance evaluation.","social network, popularity, social search, location based service, user preference",RACS '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Brandt J,Schneider K,Shukla SK",Translating Concurrent Action Oriented Specifications to Synchronous Guarded Actions,,2010,,,47–56,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the ACM SIGPLAN/SIGBED 2010 Conference on Languages, Compilers, and Tools for Embedded Systems","Stockholm, Sweden",2010,9781605589534,,https://doi.org/10.1145/1755888.1755896;http://dx.doi.org/10.1145/1755888.1755896,10.1145/1755888.1755896,"Concurrent Action-Oriented Specifications (CAOS) model the be- havior of a synchronous hardware circuit as asynchronous guarded actions at an abstraction level higher than the Register Transfer Level (RTL). Previous approaches always considered the compilation of CAOS, which includes a transformation of the under-lying model of computation and the scheduling of guarded actions per clock cycle, as a tightly integrated step. In this paper, we present a new compilation procedure, which separates these two tasks and translates CAOS models to synchronous guarded actions with an explicit interface to a scheduler. This separation of con- cerns has many advantages, including better analyses and integration of custom schedulers. Our method also generates assertions that each scheduler must obey that can be fulfilled by algorithms for scheduler synthesis like those developed in supervisory control. We present our translation procedure in detail and illustrate it by various examples. We also show that our method simplifies for- mal verification of hardware synthesized from CAOS specifications over previously known formal verification approaches.","synchronous languages, code generation, guarded commands, concurrent action-oriented specifications",LCTES '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Brandt J,Schneider K,Shukla SK",Translating Concurrent Action Oriented Specifications to Synchronous Guarded Actions,SIGPLAN Not.,2010,45,4,47–56,Association for Computing Machinery,"New York, NY, USA",,,,2010-04,,0362-1340,https://doi.org/10.1145/1755951.1755896;http://dx.doi.org/10.1145/1755951.1755896,10.1145/1755951.1755896,"Concurrent Action-Oriented Specifications (CAOS) model the be- havior of a synchronous hardware circuit as asynchronous guarded actions at an abstraction level higher than the Register Transfer Level (RTL). Previous approaches always considered the compilation of CAOS, which includes a transformation of the under-lying model of computation and the scheduling of guarded actions per clock cycle, as a tightly integrated step. In this paper, we present a new compilation procedure, which separates these two tasks and translates CAOS models to synchronous guarded actions with an explicit interface to a scheduler. This separation of con- cerns has many advantages, including better analyses and integration of custom schedulers. Our method also generates assertions that each scheduler must obey that can be fulfilled by algorithms for scheduler synthesis like those developed in supervisory control. We present our translation procedure in detail and illustrate it by various examples. We also show that our method simplifies for- mal verification of hardware synthesized from CAOS specifications over previously known formal verification approaches.","concurrent action-oriented specifications, code generation, guarded commands, synchronous languages",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gudzius P,Kurasova O,Filatovas E",Convolutional Neural Network Hyperparameters Designed for Highest Object Recognition Accuracy in Satellite Imagery,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Second International Conference on Data Science, E-Learning and Information Systems","Dubai, United Arab Emirates",2019,9781450372848,,https://doi.org/10.1145/3368691.3368695;http://dx.doi.org/10.1145/3368691.3368695,10.1145/3368691.3368695,"Geospatial data follows Moore's law. On the back of satellite hardware improvements and reduced costs of rocket launch there were more nanosatellites deployed to Lower Earth Orbit (LEO) in 2018 than in the previous 10 years combined allowing exponential satellite imagery data growth. Machine Learning tools enable us to process high resolution, multi-spectral satellite imagery data to recognize objects at large scale and generates insights with practical industry applications. It enables us to calculate global oil reserves, track tanker ships, forecast wheat yields or estimate retail revenue based on the car traffic, all exceptionally valuable financial information. In this paper, we research various computer vision techniques to develop and optimal technique for this unique type of the dataset: multi-spectral satellite imagery.","big data, computer vision, convolutional neural networks, geospatial data, neural networks, object recognition, satellite imagery, U-net",DATA '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Carter M,Velloso E,Downs J,Sellen A,O'Hara K,Vetere F",PathSync: Multi-User Gestural Interaction with Touchless Rhythmic Path Mimicry,,2016,,,3415–3427,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems,"San Jose, California, USA",2016,9781450333627,,https://doi.org/10.1145/2858036.2858284;http://dx.doi.org/10.1145/2858036.2858284,10.1145/2858036.2858284,"In this paper, we present PathSync, a novel, distal and multi-user mid-air gestural technique based on the principle of rhythmic path mimicry; by replicating the movement of a screen-represented pattern with their hand, users can intuitively interact with digital objects quickly, and with a high level of accuracy. We present three studies that each contribute (1) improvements to how correlation is calculated in path-mimicry techniques necessary for touchless interaction, (2) a validation of its efficiency in comparison to existing techniques, and (3) a demonstration of its intuitiveness and multi-user capacity 'in the wild'. Our studies consequently demonstrate PathSync's potential as an immediately legitimate alternative to existing techniques, with key advantages for public display and multi-user applications.","kinect, pathsync, touchless interaction",CHI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yi Z,Shanru L,Chongwen W",Research on Product Detection Algorithm for Intelligent Refrigerator,,2020,,,84–88,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 9th International Conference on Software and Computer Applications,"Langkawi, Malaysia",2020,9781450376655,,https://doi.org/10.1145/3384544.3384581;http://dx.doi.org/10.1145/3384544.3384581,10.1145/3384544.3384581,"In this paper, we designed a pure visual static identification scheme for the intelligent freezer system. The camera is added to each layer in the freezer to detect and identify the product images before and after the user switches the freezer door. The difference in the quantity of the product is calculated as the amount of consumption. In order to solve the problem of real-time detection of many types of products, this project designed a lightweight network structure IceboxNet suitable for product detection and recognition. In the visual intelligent freezer scene, this structure can not only achieve high accuracy recognition of hundreds of commodities. Moreover, the detector based on the SSD algorithm can greatly reduce the depth model size and improve the algorithm speed without loss of precision. In the improved scheme of SSD algorithm, considering the computing power of the device, IceboxNet is used as the basic network to simplify the multi-layer feature fusion mechanism. In order to further improve the accuracy of product detection, this paper sets the size and length of the default proposal for the product dataset. The width ratio and the model parameters in the hundred kinds of product identification are used to initialize the parameters of the object detector. Finally, the model designed in this paper has a mAP of 99.15% in the product data set and a detection speed of 74FPS.","object detection, product classification, neural network",ICSCA 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ito T,Yamaguchi T,Yoshikawa H",High Resolution Computer-Generated Cylindrical Hologram,,2009,,,335–338,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Universal Communication Symposium,"Tokyo, Japan",2009,9781605586410,,https://doi.org/10.1145/1667780.1667850;http://dx.doi.org/10.1145/1667780.1667850,10.1145/1667780.1667850,"We investigate the computer-generated cylindrical hologram. Since the general flat format hologram has a limited viewable area, we usually cannot see the other side of the reconstructed object. There are some holograms to solve this problem. A cylindrical-type hologram is well known as the 360-deg viewable hologram. There are two kinds of cylindrical holograms, a multiplex hologram and a laser reconstruction 360-deg hologram. Since the multiplex hologram consists of many 2-D pictures, the reconstructed image is not truly 3-D. In contrast, a laser reconstruction 360-deg hologram has a true 3-D effect. In our previous study, the computer-generated cylindrical hologram was realized as a Fresnel hologram. However, since the spatial resolution and pitch of the output device is not enough. Its panel size 14.5mm x 10.9mm, resolution 1,400 x 1,050pixel, pixel pitch 10.4μm of Liquid Crystal on Silicon use reduced to 1/12 and made a hologram. In this report, panel size 13.8mm x 7.56mm, resolution 1,920 x 1,080 pixel, pixel pitch 7μm of Liquid Crystal on Silicon use reduced to 1/16 and made a hologram. To scale up reconstructed image size, we calculated high resolution computer-generated cylindrical hologram. Then, we print these fringes with the improved output device. As a result, we obtain a good reconstructed image from a computer-generated cylindrical hologram.","cylindrical hologram, computer-generated hologram, holography, fringe printer",IUCS '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Costa G,Gasti P,Merlo A,Yu SH",FLEX: A Flexible Code Authentication Framework for Delegating Mobile App Customization,,2016,,,389–400,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security,"Xi'an, China",2016,9781450342339,,https://doi.org/10.1145/2897845.2897887;http://dx.doi.org/10.1145/2897845.2897887,10.1145/2897845.2897887,"Mobile code distribution relies on digital signatures to guarantee code authenticity. Unfortunately, standard signature schemes are not well suited for use in conjunction with program transformation techniques, such as aspect-oriented programming. With these techniques, code development is performed in sequence by multiple teams of programmers. This is fundamentally different from traditional single-developer/ single-user models, where users can verify end-to-end (i.e., developer-to-user) authenticity of the code using digital signatures. To address this limitation, we introduce FLEX, a flexible code authentication framework for mobile applications. FLEX allows semi-trusted intermediaries to modify mobile code without invalidating the developer's signature, as long as the modification complies with a \contract\"" issued by the developer. We introduce formal definitions for secure code modification",and show that our instantiation of FLEX is secure under these definitions. Although FLEX can be instantiated using any language,"we design AMJ--a novel programming language that supports code annotations--and implement a FLEX prototype based on our new language.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Disenfeld C,Katz S",Compositional Verification of Events and Observers: (Summary),,2011,,,1–5,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International Workshop on Foundations of Aspect-Oriented Languages,"Porto de Galinhas, Brazil",2011,9781450306447,,https://doi.org/10.1145/1960510.1960512;http://dx.doi.org/10.1145/1960510.1960512,10.1145/1960510.1960512,"By distinguishing between events and aspects, it is possible to separate the problem of identifying when an aspect should be applied, from what it must do. Observers (aspects that do not affect the state of the base system) are already part of aspect-oriented programming and language support is emerging for events that gather information and announce occurrence. The goal of compositional verification of events and observers is to prove that they are correct so that their guarantees may be used by other events or aspects. Moreover, a compositional verification model allows applying formal verification techniques in smaller models, and also building a library of events, in which for any base system that satisfies certain assumptions, the event detection will satisfy its guarantees. In this work compositional verification of events and observers will be defined to aid in the design of a framework that allows users to verify events, providing as well flexibility in the input language of the specification","events, composition, verification, observer aspects",FOAL '11,"Security and privacy Digital signatures, Software and its engineering Object oriented languages, Security and privacy Formal security models",ASIA CCS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Georgiev I,Křivánek J,Davidovič T,Slusallek P",Light Transport Simulation with Vertex Connection and Merging,ACM Trans. Graph.,2012,31,6,,Association for Computing Machinery,"New York, NY, USA",,,,2012-11,,0730-0301,https://doi.org/10.1145/2366145.2366211;http://dx.doi.org/10.1145/2366145.2366211,10.1145/2366145.2366211,"Developing robust light transport simulation algorithms that are capable of dealing with arbitrary input scenes remains an elusive challenge. Although efficient global illumination algorithms exist, an acceptable approximation error in a reasonable amount of time is usually only achieved for specific types of input scenes. To address this problem, we present a reformulation of photon mapping as a bidirectional path sampling technique for Monte Carlo light transport simulation. The benefit of our new formulation is twofold. First, it makes it possible, for the first time, to explain in a formal manner the relative efficiency of photon mapping and bidirectional path tracing, which have so far been considered conceptually incompatible solutions to the light transport problem. Second, it allows for a seamless integration of the two methods into a more robust combined rendering algorithm via multiple importance sampling. A progressive version of this algorithm is consistent and efficiently handles a wide variety of lighting conditions, ranging from direct illumination, diffuse and glossy inter-reflections, to specular-diffuse-specular light transport. Our analysis shows that this algorithm inherits the high asymptotic performance from bidirectional path tracing for most light path types, while benefiting from the efficiency of photon mapping for specular-diffuse-specular lighting effects.","photon mapping, importance sampling, bidirectional path tracing, light transport, density estimation, global illumination",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Suganuma A,Ogata Y,Shimada A,Arita D,Taniguchi RI",Billiard Instruction System for Beginners with a Projector-Camera System,,2008,,,3–8,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 International Conference on Advances in Computer Entertainment Technology,"Yokohama, Japan",2008,9781605583938,,https://doi.org/10.1145/1501750.1501752;http://dx.doi.org/10.1145/1501750.1501752,10.1145/1501750.1501752,"The purpose of our work is to develop an instruction system for billiards for beginners using a projector-camera system. The direction and strength of shot are quite important in order to make the shot successful. The player's shooting stance is also important to shoot the cue-ball exactly. The direction and strength of shot and the proper shooting stance are non-symbolic information which is difficult to send to the beginner. It is generally useful that the beginner easily gets these kinds of information. We use a projector to resolve this problem. In this paper, we describe the method recognizing objects on the table, the method calculating a shooting path and shot difficulty, and the method showing the supporting information. We have confirmed experimental effectiveness of our support information.","projector-camera system, mixed reality, shot support, correcting shooting stance, billiards",ACE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fedorov I,Lawal N,O'Nils M,Alqaysi H",Placement Strategy of Multi-Camera Volumetric Surveillance System for Activities Monitoring,,2017,,,113–118,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Distributed Smart Cameras,"Stanford, CA, USA",2017,9781450354875,,https://doi.org/10.1145/3131885.3131911;http://dx.doi.org/10.1145/3131885.3131911,10.1145/3131885.3131911,"The design of multi-camera surveillance system comes with many advantages, for example it facilitates as understanding how flying objects act in a given volume. One possible application is for the observation interaction of birds and calculate their trajectories around wind turbines to create promising systems for preventing bird collisions with turbine blades. However, there are also challenges, such as finding the optimal node placement and camera calibration. To address these challenges we investigated a trade-off between calibration accuracy and node requirements, including resolution, modulation transfer function, field of view and angle baseline. We developed a strategy for camera placement to achieve improved coverage for golden eagle monitoring and tracking. This strategy based on the modified resolution criterion taking into account the contrast function of the camera and the estimation of the base angle between the cameras.","placement, outdoor monitoring, camera calibration, Multi-camera",ICDSC 2017,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Dean JS,Mitropoulos FJ",An Aspect Pointcut for Parallelizable Loops,,2014,,,1619–1624,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 29th Annual ACM Symposium on Applied Computing,"Gyeongju, Republic of Korea",2014,9781450324694,,https://doi.org/10.1145/2554850.2554917;http://dx.doi.org/10.1145/2554850.2554917,10.1145/2554850.2554917,"In this paper, we describe the design and implementation of a parallelizable loop pointcut for an aspect-oriented compiler. Prior to this study, several prototype solutions existed for loop pointcuts, but the solutions were not very granular. In particular, they were not able to differentiate between loops that are parallelizable and those that are not. Being able to identify parallelizable loops automatically, as part of an aspect-oriented compiler, is particularly important because (1) manually identifying parallelizable loops is known to be a difficult problem and (2) aspectizing parallelized loops can lead to a reduction in code tangling and an increase in separation of concerns.Identifying parallelizable loops is known to be a difficult problem, and as such, this study's parallelizable loop pointcut implements a heuristic solution. Thus, the pointcut identifies many parallelizable loops as being parallelizable, but not all. For two test programs where the pointcut was unable to identify parallelizable loops, the inability to detect parallelizability was, surprisingly, somewhat beneficial. When those programs' loops ran in parallel (as part of a non-aspect-oriented program), their calculated results were slightly different from the known theoretical results, but when run sequentially (with the aspect-oriented compiler), the calculated results matched the known theoretical results.","aspect-oriented programming, loop pointcut, parallelizable loops",SAC '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jianying W,Fei S,Qiang Z",Application of Binocular Vision Algorithm Based on Angle Measuring in Moving Target Tracking System,,2018,,,189–193,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th International Conference on Information Technology: IoT and Smart City,"Hong Kong, Hong Kong",2018,9781450366298,,https://doi.org/10.1145/3301551.3301565;http://dx.doi.org/10.1145/3301551.3301565,10.1145/3301551.3301565,"It is difficult to solve the parallax in detecting the moving target for the traditional binocular vision recognition algorithm. So a moving target recognition and tracking algorithm based on the angle measurement is proposed, which realizes the tracking of the space moving target, the measurement of the three-dimensional position coordinates of the target and the display of the track of the target. In this paper, a dual camera is used to collect video images in real time, and the moving objects are detected by angle measurement method to calculate three-dimensional coordinates and motion trajectories. The experimental results show that the algorithm can quickly and accurately detect the position of the target and draw the target motion trajectory in real time. The target position detection error is 3% 5%.","binocular vision, trajectory, Angle measure, three dimensional coordinates",ICIT 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wu L,Dong S,Cao Y",Research on Subway Collision Animation Based on ANSYS Data,,2020,,,33–36,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 The 2nd World Symposium on Software Engineering,"Chengdu, China",2020,9781450387873,,https://doi.org/10.1145/3425329.3425338;http://dx.doi.org/10.1145/3425329.3425338,10.1145/3425329.3425338,"In this paper, four subway cars are selected as experimental objects, and the finite element analysis software ANSYS is used to simulate collision simulation. On this basis, we provide three sets of data about the displacement of four trains within 0.24s. Through 3d animation of three sets of data, the whole deformation process of train body collision can be obtained intuitively and clearly. Then, from the perspective of displacement, plastic deformation and climbing status of train carriages, the paper makes a detailed analysis, which is obviously different from the motion law used in the traditional 3D animation production. The experimental results of simulation of collision animation show that the use of finite element analysis software ANSYS makes the production of 3D animation to show more details, and more efficient and convenient. 3D animation also makes the data calculated by ANSYS intuitive visualization.","ANSYS, 3D animation, subway collision",WSSE 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Hattenberger TJ,Fairchild MD,Johnson GM,Salvaggio C",A Psychophysical Investigation of Global Illumination Algorithms Used in Augmented Reality,ACM Trans. Appl. Percept.,2009,6,1,,Association for Computing Machinery,"New York, NY, USA",,,,2009-02,,1544-3558,https://doi.org/10.1145/1462055.1462057;http://dx.doi.org/10.1145/1462055.1462057,10.1145/1462055.1462057,"The overarching goal of this research was to compare different rendering solutions in order to understand why some yield better results specifically when applied to rendering synthetic objects into real photographs. A psychophysical experiment was conducted in which the composite images were judged for accuracy against the original photograph. In addition, iCAM, an image color appearance model was also used to calculate image differences for the same set of images. Conclusions obtained included the effect of global illumination on the accuracy of the final composite rendering. Also, it was discovered that the original rendering with all of its artifacts is not necessarily an indicator of the final composite image's judged accuracy. Finally, initial results show promise in using iCAM to predict a relationship similar to the psychophysics, which could eventually be used in-the-rendering-loop to achieve photorealism with minimized computation.","rendering, psychophysics, Image difference, global illumination, perception",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang S,Li J,Yang C,Yang Y,Hu X",Vision-Based UAV Positioning Method Assisted by Relative Attitude Classification,,2020,,,154–160,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2020 5th International Conference on Mathematics and Artificial Intelligence,"Chengdu, China",2020,9781450377072,,https://doi.org/10.1145/3395260.3395263;http://dx.doi.org/10.1145/3395260.3395263,10.1145/3395260.3395263,"When the Unmanned Aerial Vehicle(UAV) is flying in formation, the common communication method is radio frequency(RF) communication. However, in practical applications, the way of RF communication is susceptible to interference from other factors such as electromagnetism. Therefore, in order to improve the anti-interference of the UAV cluster flight, it's necessary to use a positioning method which is based on visual information. Based on the above analysis, this paper proposes a vision-based UAV positioning method assisted by attitude classification. Firstly, the problem of solving the relative attitude of the UAV is transformed into a classification problem by the object recognition method, and a preliminary classification of the relative attitude of the friendly UAV is realized. Based on the principle of camera calibration, the pixel size and coordinates of the target UAV can be transform to the body coordinate system. Since the camera and the carrier UAV are fixedly connected, when the latitude and longitude coordinates of the carrier UAV are known, relative coordinate conversion can be performed to calculate the coordinates of the target UAV in the world coordinate system. Realize the positioning task of the target UAV. Simulation results are performed on the proposed method of the UAV relative attitude recognition accuracy exceeds 90%, and the average error in the distance simulation system of 2.56%. The final coordinate positioning accuracy exceeds 90% without losing the target.","fixed-wing UAV, relative attitude recognition, deep-learning, Computer-visual, UAV formation, target positioning",ICMAI 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Guo T,Wu J,Zhu X,Zhang C",Combining Structured Node Content and Topology Information for Networked Graph Clustering,ACM Trans. Knowl. Discov. Data,2017,11,3,,Association for Computing Machinery,"New York, NY, USA",,,,2017-03,,1556-4681,https://doi.org/10.1145/2996197;http://dx.doi.org/10.1145/2996197,10.1145/2996197,"Graphs are popularly used to represent objects with shared dependency relationships. To date, all existing graph clustering algorithms consider each node as a single attribute or a set of independent attributes, without realizing that content inside each node may also have complex structures. In this article, we formulate a new networked graph clustering task where a network contains a set of inter-connected (or networked) super-nodes, each of which is a single-attribute graph. The new super-node representation is applicable to many real-world applications, such as a citation network where each node denotes a paper whose content can be described as a graph, and citation relationships between papers form a networked graph (i.e., a super-graph). Networked graph clustering aims to find similar node groups, each of which contains nodes with similar content and structure information. The main challenge is to properly calculate the similarity between super-nodes for clustering. To solve the problem, we propose to characterize node similarity by integrating structure and content information of each super-node. To measure node content similarity, we use cosine distance by considering overlapped attributes between two super-nodes. To measure structure similarity, we propose an Attributed Random Walk Kernel (ARWK) to calculate the similarity between super-nodes. Detailed node content analysis is also included to build relationships between super-nodes with shared internal structure information, so the structure similarity can be calculated in a precise way. By integrating the structure similarity and content similarity as one matrix, the spectral clustering is used to achieve networked graph clustering. Our method enjoys sound theoretical properties, including bounded similarities and better structure similarity assessment than traditional graph clustering methods. Experiments on real-world applications demonstrate that our method significantly outperforms baseline approaches.","super-nodes, clustering, Networked graphs, kernel, topology",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mequanint D,Brunie L,Libsie M,Coquil D",A Latency Hiding Framework for Enhanced Ubiquitous Access to Big Data in a Constrained Digital Ecosystem: Application to Digital Medical Archives,,2012,,,80–87,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Management of Emergent Digital EcoSystems,"Addis Ababa, Ethiopia",2012,9781450317559,,https://doi.org/10.1145/2457276.2457292;http://dx.doi.org/10.1145/2457276.2457292,10.1145/2457276.2457292,"This paper presents our latency hiding framework for access to big data in a constrained digital ecosystem with application to digital medical archives. Aiming to enhance ubiquitous access of big data such as patient-oriented access of medical archives, we apply complex/multi-context prefetching to reduce latency thereby improving response time. We propose a formal model for prefetch requests rate and network workload or stress bound that takes into account a diverse set of constraints a digital ecosystem could be in. In addition to that, components of our latency hiding framework such as a generic multi-context functional architecture, use case model, medical database model with emphasis on API (abstracted patient information) and a high-level system architecture have been designed. The development of a complex or multi-context prefetch algorithm that uses a patient's chief complaints, slackness sensitivity, popular content tag, user specified contexts and constraints is underway. A prototype system will also be developed to validate the proposed solutions. Moreover, input and output metrics will be developed to gauge the efficiency and effectiveness of the prefetch algorithm under development.","multi-context prefetching, ubiquitous access to big data, digital medical archives, latency hiding",MEDES '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Sato M,Particle Display System: A Real World Display with Physically Distributable Pixels,,2008,,,3771–3776,Association for Computing Machinery,"New York, NY, USA",,CHI '08 Extended Abstracts on Human Factors in Computing Systems,"Florence, Italy",2008,9781605580128,,https://doi.org/10.1145/1358628.1358928;http://dx.doi.org/10.1145/1358628.1358928,10.1145/1358628.1358928,"In this paper, the author designs and implements a new display system called Particle Display System, which can be installed on the non-planar surface of any objects. It consists of hundreds of full-color and wireless Light Emitting Diode (LED) nodes with a PC and video camera. The wireless capability makes the each node freely movable without distant limitation of the use of wire cables. By processing the images from the camera, the system calculates the positioning information of the each node and performs the timing control of the LED in the each node in real time. Therefore, the author is able to design a uniquely arranged pattern in full-color in the real world, by distributing and controlling the smart nodes. This paper describes the design and implementation of the prototype of Particle Display System.","rfid, intelligent space, tangible display, intuitive interaction, augmented reality, display, pervasive computing",CHI EA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Nelimarkka M,A Review of Research on Participation in Democratic Decision-Making Presented at SIGCHI Conferences. Toward an Improved Trading Zone Between Political Science and HCI,Proc. ACM Hum. -Comput. Interact.,2019,3,CSCW,,Association for Computing Machinery,"New York, NY, USA",,,,2019-11,,,https://doi.org/10.1145/3359241;http://dx.doi.org/10.1145/3359241,10.1145/3359241,"We present a review of 80 papers representing efforts to support participation in democratic decision-making mostly related to local or national governments. The papers were published in leading human--computer interaction (SIGCHI conferences) venues. Most of this literature represents attempts to support assembly-oriented participation, wherein decisions are made through discussion, although referendum-type participation, involving decision-making based on voting, has gained attention too. Primarily, those papers addressing agenda-setting have examined organization-led forms, in which the agenda is controlled by those issuing the call for participation. Accordingly, the authors call for more research into support for representative models and participant-driven agenda-setting. Furthermore, the literature review pinpoints areas wherein further interdisciplinary engagement may be expected to improve research quality: in political science, HCI-informed methods and new ways of using physical input in participation merit more research, while, from the HCI side, cultivating closer relationships with political science concepts such as democratic innovations and calculus of voting could encourage reconsideration of the research foci. These observations speak to the benefits of a new research agenda for human--computer interaction research, involving different forms of participation, most importantly to address lack of engagement under the representative model of participation. Furthermore, in light of these findings, the paper discusses what type of interdisciplinary research is viable in the HCI field today and how political science and HCI scholars could usefully collaborate.","representative democracy, political science, interdisciplinarity, politics, trading zones, citizen participation, assembly democracy, democratic participation, civic engagement",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Su P,Li D,Su K",An Expected Utility-Based Approach for Mining Action Rules,,2012,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ACM SIGKDD Workshop on Intelligence and Security Informatics,"Beijing, China",2012,9781450315500,,https://doi.org/10.1145/2331791.2331800;http://dx.doi.org/10.1145/2331791.2331800,10.1145/2331791.2331800,"One of the central issues in data mining community is to make the mined patterns actionable. Action rules are those actionable patterns, which provide hints to a user what actions (i.e., changes within some values of flexible attributes) should be taken to reclassify some objects from an undesired decision class to a desired one. Both changing the value of a flexible attribute and the corresponding change of the value of a decision attribute may incur cost (negative utility) or bring benefit (positive utility) for the user. Obviously, the user is more interested in the rules which are expected to bring higher utility. In this paper, we formally define the expected utility of an action rule for measuring its interestingness. Our definitions explicitly state the problem of mining action rules as a search problem in a framework of support and expected utility. We also propose an effective algorithm for mining action rules with higher expected utilities. Our experiment shows the usefulness of the proposed approach.","rule induction, expected utility, actionability, action rules",ISI-KDD '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Anagnostopoulos V,Moulos V,Menychtas A,Varvarigou T,Gatzioura A",Intelligent Clouds: A Middleware Architecture Supporting Business Elasticity,,2014,,,1–6,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 18th Panhellenic Conference on Informatics,"Athens, Greece",2014,9781450328975,,https://doi.org/10.1145/2645791.2645844;http://dx.doi.org/10.1145/2645791.2645844,10.1145/2645791.2645844,"Cloud computing aims to realize the vision of computing as a utility provided in an economically viable manner. A necessary condition for its success as a business solution is the existence of proper software tools for the development and provision of applications for this highly dynamic ecosystem. In this paper we focus on the tools providing PaaS (Platform-as-a-Service) functionalities and more specific we propose a new middleware architecture that could allow the creation of elastic applications with the scalability of the application transparently embedded in the middleware. Departing from legacy considerations, we embrace the latest trends in scalable distributed software design as well as concepts from SOAs (Service Oriented Architectures) and agent-based computing with the goal to provide a future-proof platform in technical and business sense. Central to our approach is the tackling of the scalability and pricing problems in order to reliably further the adoption of the pay as you go model. Moreover we put special emphasis on a formal definition of scalability rules and on structuring our middleware along these lines.","resource management, Cloud computing, intelligent cloud, elasticity",PCI '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lampka K,Perathoner S,Thiele L",Analytic Real-Time Analysis and Timed Automata: A Hybrid Method for Analyzing Embedded Real-Time Systems,,2009,,,107–116,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Seventh ACM International Conference on Embedded Software,"Grenoble, France",2009,9781605586274,,https://doi.org/10.1145/1629335.1629351;http://dx.doi.org/10.1145/1629335.1629351,10.1145/1629335.1629351,"This paper advocates a strict compositional and hybrid approach for obtaining key (performance) metrics of embedded systems. At its core the developed methodology abstracts system components by either flow-oriented and purely analytic descriptions or by state-based models in the form of timed automata. The interaction among the heterogeneous components is modeled by streams of discrete activity-triggers. In total this yields a hybrid framework for the compositional analysis of embedded systems. It supplements contemporary techniques for the following reasons: (a) state space explosion as intrinsic to formal verification is limited to the level of isolated components; (b) computed performance metrics such as buffer sizes, delays and utilization rates are not overly pessimistic, because coarse-grained purely analytic models are used for components only which conform to the stateless model of computation. For demonstrating the usefulness of the presented ideas we implemented a corresponding tool-chain and investigated the performance of a two-staged computing system, where one stage exhibits state-dependent behavior only coarsely coverable by a purely analytic and stateless component abstraction.","timed automata, performance analysis, real-time calculus, hard real-time systems",EMSOFT '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Turoff M,Session on Views of the Future: Chairman's Introduction---Opposing Views,,1973,,,717–722,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the June 4-8, 1973, National Computer Conference and Exposition","New York, New York",1973,9781450379168,,https://doi.org/10.1145/1499586.1499755;http://dx.doi.org/10.1145/1499586.1499755,10.1145/1499586.1499755,"This session represents a \first of a kind\"" for a major computer conference. The session is devoted entirely to formal technological forecasting and assessment efforts dealing with the computer industry. Technological forecasting as an autonomous discipline",with its own set of methodologies and techniques,is only about five years old. Of course,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Busjahn T,Bednarik R,Schulte C",What Influences Dwell Time during Source Code Reading? Analysis of Element Type and Frequency as Factors,,2014,,,335–338,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Symposium on Eye Tracking Research and Applications,"Safety Harbor, Florida",2014,9781450327510,,https://doi.org/10.1145/2578153.2578211;http://dx.doi.org/10.1145/2578153.2578211,10.1145/2578153.2578211,"While knowledge about reading behavior in natural-language text is abundant, little is known about the visual attention distribution when reading source code of computer programs. Yet, this knowledge is important for teaching programming skills as well as designing IDEs and programming languages. We conducted a study in which 15 programmers with various expertise read short source codes and recorded their eye movements. In order to study attention distribution on code elements, we introduced the following procedure: First we (pre)-processed the eye movement data using log-transformation. Taking into account the word lengths, we then analyzed the time spent on different lexical elements. It shows that most attention is oriented towards understanding of identifiers, operators, keywords and literals, relatively little reading time is spent on separators. We further inspected the attention on keywords and provide a description of the gaze on these primary building blocks for any formal language. The analysis indicates that approaches from research on natural-language text reading can be applied to source code as well, however not without review.","code reading, program comprehension, eye tracking",ETRA '14,similar efforts have taken place over the years within the long range planning staffs of most technology-oriented companies and organizations. Furthermore,the intuitive judgment of recognized experts is a technological forecasting technique that has always been with us and has been well represented at these meetings by various panel presentations. What appears to be really new is a growing recognition of the need to examine potential futures systematically in order to assess a wide variety of concerns and potential consequences of technological development. The days of looking only for profit related effects seem to be passing into history. Because the scope of concern has significantly widened,with an accompanying increase in the complexity of the required analyses,"new approaches to forecasting have been sought.""",,AFIPS '73,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Grisdale W,Seymour LF",Business Process Management Adoption: A Case Study of a South African Supermarket Retailer,,2011,,,106–115,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the South African Institute of Computer Scientists and Information Technologists Conference on Knowledge, Innovation and Leadership in a Diverse, Multidisciplinary Environment","Cape Town, South Africa",2011,9781450308786,,https://doi.org/10.1145/2072221.2072234;http://dx.doi.org/10.1145/2072221.2072234,10.1145/2072221.2072234,"The management approaches to process change have been dominated by process-oriented theories and \best practices\"" and have been criticized for lacking a theoretical basis. Business Process Management (BPM) the latest approach is no exception. While BPM has had significant press",hype status and high adoption expectations,problems with adoption and justifying benefits to business exist. To increase understanding of these adoption concerns,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Ivanov R,An Approach for Microscopic Path Finding and Obstacle Avoidance for Blind and Visually Impaired People,,2016,,,285–292,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th International Conference on Computer Systems and Technologies 2016,"Palermo, Italy",2016,9781450341820,,https://doi.org/10.1145/2983468.2983482;http://dx.doi.org/10.1145/2983468.2983482,10.1145/2983468.2983482,"One of the main limitations to the successful integration of visually impaired people into social, economic, and cultural life is the inability for them to safely and reliably move in unfamiliar indoor spaces. The majority indoor navigation systems use graph-based models to represent building connectivity. Graph-based (macroscopic) path finding usually uses only centroid of the spaces and connection information between spatial objects when calculating a feasible path. These path-finding strategies cannot be directly used indoors, especially for visually impaired people. They implement door-by-door navigation, but they do not give information about how the user has to go through a room until he or she reaches the next door and they do not support obstacle avoidance. This paper presents an approach for fast microscopic (physical) path finding, which is part of three-level (coarse-to-fine-to-optimal) path planning strategy.","Blind and Visually Impaired, Indoor Navigation, Microscopic Path Planning",CompSysTech '16,this paper explores BPM in a leading Southern African supermarket retailer where various attempts had been made to implement a formal BPM discipline. The research describes the organisation's understanding of BPM and factors influencing its adoption. Qualitative research methods were used to collect rich narrative data from interviews with information systems (IS) and retail professionals. The BPM adoption themes that emerged focused on the understanding and education of BPM,cultural limitations,centralisation as a strategic driver,ERP as an enabler,"structural and people factors. A theoretical model was developed to explain the themes and their inter-relationships. This empirical research provides a conceptual understanding of BPM and its adoption from professionals employed by the retail industry.""","BPM, South Africa, BPR, retail, business process",SAICSIT '11,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Takahashi H,Miyashita H",Expressive Fused Deposition Modeling by Controlling Extruder Height and Extrusion Amount,,2017,,,5065–5074,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems,"Denver, Colorado, USA",2017,9781450346559,,https://doi.org/10.1145/3025453.3025933;http://dx.doi.org/10.1145/3025453.3025933,10.1145/3025453.3025933,"Fused deposition modeling (FDM) 3D printers form objects by stacking layers having a linear structure. To print fine structures, an appropriate choice of parameters is necessary, or printing error occurs. On the other hand, the printing error is exploited as an expression technique. However, the relation between the printed structure and the parameters causing the printing error is unclear. In this paper, we focus on the height position of the extruder and the amount of extruded material, and explore the combination of these parameters to enhance the capability of FDM. By extending an equation that calculates the amount of material from the layer height, we investigate the behavior and structure of material extruded from various height positions. On the basis of experimental results, the printed structure is classified into six categories according to the structural feature. We describe these structural features and demonstrate examples with new inherent expressions for FDM.","expression, printing error, 3D printing, fused deposition modeling, fabrication",CHI '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lu C,Hu X,Park JR,Huang J",Post-Based Collaborative Filtering for Personalized Tag Recommendation,,2011,,,561–568,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 IConference,"Seattle, Washington, USA",2011,9781450301213,,https://doi.org/10.1145/1940761.1940838;http://dx.doi.org/10.1145/1940761.1940838,10.1145/1940761.1940838,"Social tagging provides a collaborative approach for information organization. The tags created by users in social tagging system not only contain rich semantic information about the described web objects, but also provide a window for information providers to learn a user's information interests and preferences. However, the tags created by a user for a document are always limited in terms of quantity and quality. Tag recommendation, especially personalized tag recommendation has been proposed as an approach to address this problem. In this paper, we develop a post-based collaborative filtering framework for personalized tag recommendation based on the tripartite social tagging network. The proposed method is evaluated and compared with a range of methods based on a real world social tagging dataset. The F-score and NDCG calculated to evaluate the recommendation results. The experimental results show that the proposed method can always generate the best results compared to other methods.","social tagging, social annotation, personalized recommendation, tag recommendation",iConference '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hartig O,Hidders J",Defining Schemas for Property Graphs by Using the GraphQL Schema Definition Language,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd Joint International Workshop on Graph Data Management Experiences & Systems (GRADES) and Network Data Analytics (NDA),"Amsterdam, Netherlands",2019,9781450367899,,https://doi.org/10.1145/3327964.3328495;http://dx.doi.org/10.1145/3327964.3328495,10.1145/3327964.3328495,"GraphQL is a highly popular new approach to build Web APIs. An important component of this approach is the GraphQL schema definition language (SDL). The original purpose of this language is to define a so-called GraphQL schema that specifies the types of objects that can be queried when accessing a specific GraphQL Web API. This paper focuses on the question: Can we repurpose this language to define schemas for graph databases that are based on the Property Graph model? This question is relevant because there does not exist a commonly adopted approach to define schemas for Property Graphs, and because the form in which GraphQL APIs represent their underlying data sources is very similar to the Property Graph model. To answer the question we propose an approach to adopt the GraphQL SDL for Property Graph schemas. We define this approach formally and show its fundamental properties.","graph database, schema, constraints",GRADES-NDA'19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Holland S,Marshall P,Bird J,Dalton S,Morris R,Pantidi N,Rogers Y,Clark A",Running up Blueberry Hill: Prototyping Whole Body Interaction in Harmony Space,,2009,,,93–98,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Tangible and Embedded Interaction,"Cambridge, United Kingdom",2009,9781605584935,,https://doi.org/10.1145/1517664.1517690;http://dx.doi.org/10.1145/1517664.1517690,10.1145/1517664.1517690,"Musical harmony is considered to be one of the most abstract and technically difficult parts of music. It is generally taught formally via abstract, domain-specific concepts, principles, rules and heuristics. By contrast, when harmony is represented using an existing interactive desktop tool, Harmony Space, a new, parsimonious, but equivalently expressive, unified level of description emerges. This focuses not on abstract concepts, but on concrete locations, objects, areas and trajectories.This paper presents a design study of a prototype version of Harmony Space driven by whole body navigation, and characterizes the new opportunities presented for the principled manipulation of chord sequences and bass lines. These include: deeper engagement and directness; rich physical cues for memory and reflection, embodied engagement with rhythmic time constraints; hands which are free for other simultaneous activities (such as playing a traditional instrument); and qualitatively new possibilities for collaborative use.","harmony space, embodiment, music, whole body interaction",TEI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Schweickart E,James DL,Marschner S",Animating Elastic Rods with Sound,ACM Trans. Graph.,2017,36,4,,Association for Computing Machinery,"New York, NY, USA",,,,2017-07,,0730-0301,https://doi.org/10.1145/3072959.3073680;http://dx.doi.org/10.1145/3072959.3073680,10.1145/3072959.3073680,"Sound generation methods, such as linear modal synthesis, can sonify a wide range of physics-based animation of solid objects, resolving vibrations and sound radiation from various structures. However, elastic rods are an important computer animation primitive for which prior sound synthesis methods, such as modal synthesis, are ill-suited for several reasons: large displacements, nonlinear vibrations, dispersion effects, and the geometrically singular nature of rods.In this paper, we present physically based methods for simultaneous generation of animation and sound for deformable rods. We draw on Kirchhoff theory to simplify the representation of rod dynamics and introduce a generalized dipole model to calculate the spatially varying acoustic radiation. In doing so, we drastically decrease the amount of precomputation required (in some cases eliminating it completely), while being able to resolve sound radiation for arbitrary body deformations encountered in computer animation. We present several examples, including challenging scenes involving thousands of highly coupled frictional contacts.","physically based animation, sound synthesis",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang H,Liao M,Zhang Q,Yang R,Turk G",Physically Guided Liquid Surface Modeling from Videos,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2009 Papers,"New Orleans, Louisiana",2009,9781605587264,,https://doi.org/10.1145/1576246.1531396;http://dx.doi.org/10.1145/1576246.1531396,10.1145/1576246.1531396,"We present an image-based reconstruction framework to model real water scenes captured by stereoscopic video. In contrast to many image-based modeling techniques that rely on user interaction to obtain high-quality 3D models, we instead apply automatically calculated physically-based constraints to refine the initial model. The combination of image-based reconstruction with physically-based simulation allows us to model complex and dynamic objects such as fluid. Using a depth map sequence as initial conditions, we use a physically based approach that automatically fills in missing regions, removes outliers, and refines the geometric shape so that the final 3D model is consistent to both the input video data and the laws of physics. Physically-guided modeling also makes interpolation or extrapolation in the space-time domain possible, and even allows the fusion of depth maps that were taken at different times or viewpoints. We demonstrated the effectiveness of our framework with a number of real scenes, all captured using only a single pair of cameras.","image-based reconstruction, space-time model completion, physically-based fluid simulation",SIGGRAPH '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Keishi S,Seika A",PaGe: Portable LALR(1) Parser Generator,,2014,,,8,Association for Computing Machinery,"New York, NY, USA",,Proceedings of ILC 2014 on 8th International Lisp Conference,"Montreal, QC, Canada",2014,9781450329316,,https://doi.org/10.1145/2635648.2635650;http://dx.doi.org/10.1145/2635648.2635650,10.1145/2635648.2635650,"PaGe is a portable, compact and reliable LALR(1) parser generator with more general disambiguation method compared to that of traditional parser generator such as Bison.From the past to the present, very many parser generators are implemented in various programming languages. In particular, Bison in C language is a notable one due to its high efficiency and reliability. It is surely the de fact standard parser generator in C.We have recently faced with a requirement of making some parsers for relatively large languages in Common Lisp. We prefer commercial products due to its reliability and user supports. Especially, problems with such complex tool should only be solved by someone who has deep knowledge about the tool. Thus, we chose ACL (Allegro Common Lisp) which is one of the most widely used Lisp programming environment. Unfortunately, ACL does not provide official parser generator. As for free software, as far as we know, there is no such tool comparable to Bison in the above sense.Since Lisp has powerful and universal syntactic expression, namely S-expression, it is sufficient for Lispers to express and handle any syntactic objects. We suspect that that is why parser generators are not so important to Lispers. Nevertheless reliable parser generator in Lisp is needed when we develop tools dealing with anther languages, such as compilers and program analizers.This is the motivation for developing original parser generator in Lisp.One of PaGe's concept is to give a legible implementation of DeRemer's method for Look-Ahead Set. This method makes us enable to generate LALR(1)-parsing-table dircetly from LR(0)-parsing-table by computing Look-Ahead Set based on formal definitions of them. For example, DeRemer's method has used in Bison, but there is few other implementation, particularly on Lisp. Therefore we decided to give a legible implementation for who would like to understand it.Other concept is to simplify PaGe's core program for efficiency and readability as possible. As a result, PaGe is composed of parser generator engine PaGEn and its wrapper. PaGEn is a pared parser-generator engine. PaGEn's input is a grammar whose \symbols\"" are restricted to non-negative integer. By this restriction",we were able to establish both program efficiency and algorithm readablity,for instance we can naturally use array as function.Consequently,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Li M,Research on Extraction of Useful Tourism Online Reviews Based on Multimodal Feature Fusion,ACM Trans. Asian Low-Resour. Lang. Inf. Process.,2021,20,5,,Association for Computing Machinery,"New York, NY, USA",,,,2021-08,,2375-4699,https://doi.org/10.1145/3453694;http://dx.doi.org/10.1145/3453694,10.1145/3453694,"To effectively identify the influencing factors of the perceived usefulness of multimodal data in online reviews of tourism products, this article explores the optimization method of online tourism products based on user-generated content and conducts feature fusion of multimodal data in online reviews of tourism products from the perspective of data fusion analysis. Therefore, based on the word vector model, this article proposes a method to select the seed word set of emotion dictionary. In this method, emotional words are represented in vector form and the distance between word vectors is calculated to form the selection criteria and classification basis of seed word set, and then the sentiment dictionary of online review is formed by category judgment. This article takes the real online review data of tourism products as the research object, carries out descriptive statistical analysis, uses machine learning and deep learning methods, carries out text vector embedding and image content recognition, integrates image and text feature vector, constructs multimodal online review usefulness classification model, and conducts model test. The experimental results show that, compared with the single-mode reviews containing only text or pictures, the multimodal reviews combined with text and pictures can better predict the usefulness of online reviews, improve the quality of online reviews, give full play to the potential value of user-generated content, provide optimization ideas for product providers, and provide decision support for product consumers.","image recognition, feature fusion, deep learning, Multi-modal, tourism online reviews",,the role of wrapper are mainly two of translation and interpreting. A wrapper translates symbolic input such as grammar or sequence of token into numeric input for PaGEn. PaGEn get this as input and return parsing-table or result of parse,for instance. Then the wrapper interprets this result for an user or other system. Now,we have defined only the wrapper for using PaGEn in the same way for traditional parser generator. If you wish to use PaGEn for other purpose,you need only to define the wrapper.Furthermore,PaGEn can deal with ambiguous grammar i.e. it supports disambiguation. PaGEn's disambiguation method is so simple. First we give two priority to each rule for reduce-time and shift-time. If some conflict has occurred,then,we try to solve each conflicts by comparing priorities. For Reduce/Reduce-conflicts,we solve it by Reduce using the rule which has the greatest reduce-time-priority in conflicted rules. For Shift/Reduce-conflicts,2 pattern exists. If the propagation-priority,computed from several shift-time-priorities,is greater than the reduce-time-priority of the rule,we solve by shift. If the reduce-time-priority is greater than the propagation-priority we solve by reduce.This method is more general than the method which specifies the associativity of an operator directly,in translatability sense. And,"dangling-else probrem can be solved uniformly in this method.""","parser generator, disambiguation, modular design",ILC '14,,,,,,,,,,,,,,
1,Conference Paper,"Tilly K,Porkoláb Z",Automatic Classification of Semantic User Interface Services,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Ontology-Driven Software Engineering,"Reno, Nevada",2010,9781450305488,,https://doi.org/10.1145/1937128.1937134;http://dx.doi.org/10.1145/1937128.1937134,10.1145/1937128.1937134,"Current user interfaces are ad hoc, application dependent and constantly change while offering the same functionalities in many different ways. This article investigates methods for creating semantic user interfaces, which are much easier to develop, learn, teach and use. The basic idea of semantic user interfaces is to analyze specific application domains (like word processing, file handling or application deployment), organize domain concepts into ontologies, associate user interface presentation attributes (like icons, menu labels and line mode commands) to ontology nodes, and to use the ontology as a central control entity of application development and execution. The ontology is used inside a service oriented semantic user interface framework, whose elements and potential benefits are also explained.The main contribution of this article is to investigate methods for analyzing and classifying computer system services, as a fundamental step of making the presented semantic user interface architecture operational. The problems and steps of service analysis are described and an automatic classification algorithm is presented based on formal semantic specifications and graph isomorphism. Implementation details and practical experiences are also outlined.","service oriented architecture, formal semantic specification, semantic user interface, classification algorithm",ODiSE'10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Kuttal SK,Sarma A,Rothermel G",On the Benefits of Providing Versioning Support for End Users: An Empirical Study,ACM Trans. Comput. -Hum. Interact.,2014,21,2,,Association for Computing Machinery,"New York, NY, USA",,,,2014-02,,1073-0516,https://doi.org/10.1145/2560016;http://dx.doi.org/10.1145/2560016,10.1145/2560016,"End users with little formal programming background are creating software in many different forms, including spreadsheets, web macros, and web mashups. Web mashups are particularly popular because they are relatively easy to create, and because many programming environments that support their creation are available. These programming environments, however, provide no support for tracking versions or provenance of mashups. We believe that versioning support can help end users create, understand, and debug mashups. To investigate this belief, we have added versioning support to a popular wire-oriented mashup environment, Yahoo! Pipes. Our enhanced environment, which we call “Pipes Plumber,” automatically retains versions of pipes and provides an interface with which pipe programmers can browse histories of pipes and retrieve specific versions. We have conducted two studies of this environment: an exploratory study and a larger controlled experiment. Our results provide evidence that versioning helps pipe programmers create and debug mashups. Subsequent qualitative results provide further insights into the barriers faced by pipe programmers, the support for reuse provided by our approach, and the support for debugging provided.","reuse, programming barriers, Mashups, End-user software engineering, debugging, Yahoo! Pipes, versioning",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zhao P,Technical Efficiency of High-Tech Industries Based on DEA-Malmquist Index,,2021,,,,Association for Computing Machinery,"New York, NY, USA",,The Sixth International Conference on Information Management and Technology,"Jakarta, Indonesia",2021,9781450385015,,https://doi.org/10.1145/3465631.3465817;http://dx.doi.org/10.1145/3465631.3465817,10.1145/3465631.3465817,"The development of high-tech industry reflects a country's economic competitiveness,scientific and technological strength. Facing the increasingly fierce international scientific and technological competition, how to develop China's high-tech industry is an urgent problem to be solved.Therefore, this paper chooses \high-tech industry\"" as the research object. Based on the perspective of technical efficiency",the DEA-Malmquist index method is used to decompose the total factor productivity of high-tech industry,namely,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zubayer MH,Wu J",Modal Analysis of Commercial Aircraft Engine Noise Source and Noise Reduction Technology,,2018,,,164–168,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 7th International Conference on Informatics, Environment, Energy and Applications","Beijing, China",2018,9781450363624,,https://doi.org/10.1145/3208854.3208902;http://dx.doi.org/10.1145/3208854.3208902,10.1145/3208854.3208902,"The reduction of aircraft engine noise has been a priority in the aviation industry for many years. It can cause community annoyance with various health hazard. Minimizing sound emission requires an understanding of engine noise. But it's a quite challenging due to the complex nature of aircraft systems and geometries. Using a model of an aero-engine duct, we provide a more in-depth look at the acoustical field in aircraft engines. Aircraft noise is a noise pollution produced by any aircraft or its components, during various phases of a flight: on the ground while parked such as auxiliary power units, while taxiing, on run-up from propeller and jet exhaust, during take-off, or landing. In this paper, the CFM 56 flow duct and blade is as the research object. And finally this model will show that:[1] Acoustic pressure field and pressure distribution for the cases of hard (top) and lined (bottom) duct wall with mean flow.[2] Compressible Potential Flow (cpf)--for modeling the background mean-flow velocity field as a potential flow.[3] Linearized Potential Flow, Boundary Mode (aebm)--for calculating the boundary eigenmode to be used as the source of the acoustic noise in the background mean-flow.[4] Linearized Potential Flow, Frequency Domain (ae, ae2)--for modeling the time harmonic acoustic field above and below the source plane.","Comsol, Flow duct, CFM56 used blade, Thrust, Aerial Vehicle",IEEA '18,technological progress,pure technical efficiency and scale efficiency.Through this research,we can understand the technological efficiency of China's high-tech industry,reveal the main factors affecting the technological efficiency of high-tech industry,and put forward corresponding policy suggestions according to the research conclusions.This paper first analyzes the factors affecting the technical efficiency of China's high-tech industries,and then uses DEA-Malmquist method to calculate the total factor productivity of China's high-tech industries by sector and by year from 2006 to 2015.The calculation results show that the total factor productivity of China's high-tech industry fluctuates year by year,which is mainly due to the improvement of technical efficiency,while the growth of technological progress is slow.In terms of different industries,except for computer and office equipment manufacturing industry,there is no obvious technological progress,"while other industries show a good trend of improvement in technical efficiency.""",,ICIMTECH 21,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhuo HH,Muñoz-Avila H,Yang Q",Learning Action Models for Multi-Agent Planning,,2011,,,217–224,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,The 10th International Conference on Autonomous Agents and Multiagent Systems - Volume 1,"Taipei, Taiwan",2011,9780982657157,,,,"In multi-agent planning environments, action models for each agent must be given as input. However, creating such action models by hand is difficult and time-consuming, because it requires formally representing the complex relationships among different objects in the environment. The problem is compounded in multi-agent environments where agents can take more types of actions. In this paper, we present an algorithm to learn action models for multi-agent planning systems from a set of input plan traces. Our learning algorithm Lammas automatically generates three kinds of constraints: (1) constraints on the interactions between agents, (2) constraints on the correctness of the action models for each individual agent, and (3) constraints on actions themselves. Lammas attempts to satisfy these constraints simultaneously using a weighted maximum satisfiability model known as MAX-SAT, and converts the solution into action models. We believe this to be one of the first learning algorithms to learn action models in the context of multi-agent planning environments. We empirically demonstrate that Lammas performs effectively and efficiently in several planning domains.","multi-agent learning, single-agent learning, multi-agent planning",AAMAS '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Inoshita C,Hirakawa R,Kawano H,Nakashi K,Nakatoh Y",In Load Collapse Prevention System: Examination of the Relationship between Truck Vibration and Load Inclination,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th ACIS International Conference on Applied Computing and Information Technology,"Honolulu, HI, USA",2019,9781450371735,,https://doi.org/10.1145/3325291.3325393;http://dx.doi.org/10.1145/3325291.3325393,10.1145/3325291.3325393,"In recent years, the demand for the logistics industry has increased enormously due to the spread of Internet mail order. On the other hand, the number of fatal accidents caused by trucks is more than 10,000 a year in Japan. Above all, there is a problem that there is an annual fatal and fatal accident due to truck load collapse. In this study, using the drive recorder, we calculated the inclination of the package photographed during driving by using KCF of object tracking method of image processing. Comparing the change of the Luggage tilt and the amount of change in 3-axis acceleration attached to the vehicle/time of each frame in all the data, frames at each maximum value point almost agreed at the time of \ When riding over convex part of inclined road\"". On the other hand","\""When a sudden steering wheel during driving\""",a point where the absolute value of the change in package inclination during one frame reaches 0.005 ° and the point where the maximum change occurs after that. It almost coincided with the point where the curve was reached in the video. As for the 3-axis acceleration sensor,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhicheng D,Feng L",Evaluation of the Smart Campus Information Portal,,2018,,,73–79,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 2nd International Conference on Education and E-Learning,"Bali, Indonesia",2018,9781450365772,,https://doi.org/10.1145/3291078.3291083;http://dx.doi.org/10.1145/3291078.3291083,10.1145/3291078.3291083,"As the internet wave swept the world, \Internet plus education\"" came into being. Smart campus design and construction has since become a research hotspot. The Campus Information Portal (CIP) plays an increasingly important role in the management of smart campuses. That is why",conducting a comprehensive evaluation study on the construction level of campus information portals is necessary. By combining CIP's own characteristics and incorporating intelligent needs,a comprehensive evaluation index system for CIP was developed. An Analytic Hierarchy Process (AHP) was used to determine index weights,there is no difference in tendency between the curve and the straight running,"and it is considered as the main cause that the influence of the roughness of the road is greatly influenced rather than the influence at the time of the curve.""","Drive recorder, Load collapse prevention, Truck vibration, 3 axis acceleration sensor, Kernelized Correlation Filters",ACIT 2019,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang B,Hu D,Yan H",Compressive Tracking Based on Super-Pixel Structured Information,,2018,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd International Conference on Computer Science and Application Engineering,"Hohhot, China",2018,9781450365123,,https://doi.org/10.1145/3207677.3277927;http://dx.doi.org/10.1145/3207677.3277927,10.1145/3207677.3277927,"Currently1, Compressive Tracking (CT) method has been widely concerned for its high efficiency. However, when it comes to occlusion and scale variation, it may make the objects shifting and lost. In order to handle this problem, we propose an improved compressive tracking method based on super-pixel structured information. Firstly, constructing super-pixel chromaticity confidence maps to estimate the coarse position of the target. Simultaneously, utilizing Euclidean distance between cluster centers of different super-pixel patches to calculate scale ratio to obtain target scale of the current frame. Secondly, a special Measurement Matrix combined super-pixel structured information is constructed to lower the Haar-like feature dimension. After that, the Native Bayes Classifier is performed. The target location is finally estimated accurately. Extensive experiments on some open video sequences on OTB-2013 demonstrate that our approach can not only adapt to scale transform, but also improve the accuracy in the case of real-time tracking.","Compressive tracking, scale estimation, super-pixel, measurement matrix",CSAE '18,while a Fuzzy Comprehensive Evaluation (FCE) was used to calculate the quantitative scores of the evaluation objects. We selected 10 representative Chinese universities for a comprehensive CIP evaluation and experimental analysis. We analyze the final results of the study,"evaluate the validity of our process and methods and finally provide guidance for the construction of a smart campus information portal.""","Comprehensive evaluation, Index system, Smart campus, Campus information portal",ICEEL 2018,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen L,Liu Y,Zheng Z,Yu P",Heterogeneous Neural Attentive Factorization Machine for Rating Prediction,,2018,,,833–842,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th ACM International Conference on Information and Knowledge Management,"Torino, Italy",2018,9781450360142,,https://doi.org/10.1145/3269206.3271759;http://dx.doi.org/10.1145/3269206.3271759,10.1145/3269206.3271759,"Heterogeneous Information Network(HIN) has been employed in recommender system to represent heterogeneous types of data, and meta path has been proposed to capture semantic relationship among objects. When applying HIN to the recommendation, there are two problems: how to extract features from meta paths and how to properly fuse these features to further improve recommendations. Some recent work has employed deep neural network to learn user and item representation, and attention mechanism has been explored to integrate information for recommendation. Inspired by these work, in this paper, we propose Heterogeneous Neural Attentive Factorization Machine(HNAFM) to solve above problems. Specifically, we first calculate the commuting matrices based on meta paths and use multilayer perceptrons to learn user and item features. A hierarchical attention mechanism is employed to find the meta path that best describes user's preference and item's property. Comprehensive experiments based on real-world datasets demonstrate that the proposed HNAFM significantly outperforms state-of-the-art rating prediction methods.","heterogeneous information network, attention mechanism, recommendation, neural network, meta path",CIKM '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ma X,Li R,Lu Z",Role Mining Based on Weights,,2010,,,65–74,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th ACM Symposium on Access Control Models and Technologies,"Pittsburgh, Pennsylvania, USA",2010,9781450300490,,https://doi.org/10.1145/1809842.1809854;http://dx.doi.org/10.1145/1809842.1809854,10.1145/1809842.1809854,"Role mining from the existing permissions has been widely applied to aid the process of migrating to an RBAC system. While all permissions are treated evenly in previous approaches, none of the work has employed the weights of permissions in role mining to our knowledge, thus providing the motivation for this work. In this paper, we generalize this to the case where permissions are given weights to reflect their importance to the system. The weights can correspond to the property of operations, the sensitive degree of objects, and the attribute of users associated with permissions. To calculate the weight of permissions, we introduce the concept of similarity between both users and permissions, and use a similarity matrix to reinforce the similarity between permissions. Then we create a link between the reinforced similarity and the weight of permissions. We further propose a weighted role mining algorithm to generate roles based on weights. Experiments on performance study prove the superiority of the new algorithm.","rbac, weight, role mining, similarity, role engineering",SACMAT '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Burdette PF,Jones WF,Blose BC,Kapfhammer GM",An Empirical Comparison of Java Remote Communication Primitives for Intra-Node Data Transmission,SIGMETRICS Perform. Eval. Rev.,2012,39,4,2–11,Association for Computing Machinery,"New York, NY, USA",,,,2012-04,,0163-5999,https://doi.org/10.1145/2185395.2185397;http://dx.doi.org/10.1145/2185395.2185397,10.1145/2185395.2185397,"This paper presents a benchmarking suite that measures the performance of using sockets and eXtensible Markup Language remote procedure calls (XML-RPC) to exchange intra-node messages between Java virtual machines (JVMs). The paper also reports on an empirical study comparing sockets and XML-RPC with response time measurements from timers that use both operating system tools and Java language instrumentation. By leveraging packet filters inside the GNU/Linux kernel, the benchmark suite also calculates network resource consumption. Moreover, the framework interprets the response time results in light of memory subsystem metrics characterizing the behavior of the JVM. The empirical findings indicate that sockets perform better when transmitting small to very large objects, while XML-RPC exhibits lower response time than sockets with extremely large bulk data transfers. The experiments reveal trade-offs in performance and thus represent the first step towards determining if Java remote communication primitives can support the efficient exchange of intra-node messages.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sengupta D,Bandyopadhyay S,Maulik U",A Novel Measure for Evaluating an Ordered List: Application in MicroRNA Target Prediction,,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Symposium on Biocomputing,"Calicut, Kerala, India",2010,9781605587226,,https://doi.org/10.1145/1722024.1722067;http://dx.doi.org/10.1145/1722024.1722067,10.1145/1722024.1722067,"Sensitivity and specificity are the most widely used statistics for measuring the performance of a binary classification test. They stand vastly meaningful for variety of use cases where the classifying tests are affordable. But unfortunately, there is a legion of problems arriving from different streams of natural sciences where the screening test is too expensive to render for all the predicted objects. Thus, the trend has been for scientists to calculate the sensitivity and the specificity of a binary classification test based on a handful of experimentally proven facts, which is theoretically uncertain. In this article a novel measure is proposed that assigns importance to multiple ordered lists, taking into account the share of majority voted ranked pairs of elements a list contains. A real life bioinformatic application is demonstrated in the domain of microRNA target prediction where a number of algorithms exist. Using the proposed measure, we aim to assign certain weight to each algorithm that conveys its reliability with respect to the rest.","microRNA, sensitivity, ordering",ISB '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lin CX,Ji M,Danilevsky M,Han J",Efficient Mining of Correlated Sequential Patterns Based on Null Hypothesis,,2012,,,17–24,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2012 International Workshop on Web-Scale Knowledge Representation, Retrieval and Reasoning","Maui, Hawaii, USA",2012,9781450317115,,https://doi.org/10.1145/2389656.2389660;http://dx.doi.org/10.1145/2389656.2389660,10.1145/2389656.2389660,"Frequent pattern mining has been a widely studied topic in the research area of data mining for more than a decade. However, pattern mining with real data sets is complicated - a huge number of co-occurrence patterns are usually generated, a majority of which are either redundant or uninformative. The true correlation relationships among data objects are buried deep among a large pile of useless information. To overcome this difficulty, mining correlations has been recognized as an important data mining task for its many advantages over mining frequent patterns.In this paper, we formally propose and define the task of mining frequent correlated sequential patterns from a sequential database. With this aim in mind, we re-examine various interestingness measures to select the appropriate one(s), which can disclose succinct relationships of sequential patterns. We then propose PSBSpan, an efficient mining algorithm based on the framework of the pattern-growth methodology which mines frequent correlated sequential patterns. Our experimental study on real datasets shows that our algorithm has outstanding performance in terms of both efficiency and effectiveness.","correlated pattern mining, frequent pattern mining",Web-KR '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bunt A,Terry M,Lank E",Friend or Foe? Examining CAS Use in Mathematics Research,,2009,,,229–238,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the SIGCHI Conference on Human Factors in Computing Systems,"Boston, MA, USA",2009,9781605582467,,https://doi.org/10.1145/1518701.1518740;http://dx.doi.org/10.1145/1518701.1518740,10.1145/1518701.1518740,"Computer Algebra Systems (CAS) provide sophisticated functionality to assist with mathematical problem solving. Despite their widespread adoption, however, little work in the HCI community has examined the extent to which these computational tools support domain experts. In this paper, we report findings from a qualitative study investigating the work practices and tools of nine mathematicians in a research setting. Counter to our expectations, our data suggests that computational tools play only a minor role in their workflow, with the limited use of CAS owing primarily to four factors: (1) the need for transparency in CAS's reasoning to explain computed results; (2) the problem of rigidity and formality in CAS's input/output style dialogue; (3) the need for 2D input to support a wide range of annotations, diagrams, and in-place manipulation of objects of interest; and (4) the need for collaboration, particularly in early stages of problem solving. While grounded in the study of mathematicians, these findings (particularly the first) have implications for the design of computational systems intended to support complex problem solving.","computer algebra systems, mathematical problem solving",CHI '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Molemaker J,Cohen JM,Patel S,Noh J",Low Viscosity Flow Simulations for Animation,,2008,,,9–18,Eurographics Association,"Goslar, DEU",,Proceedings of the 2008 ACM SIGGRAPH/Eurographics Symposium on Computer Animation,"Dublin, Ireland",2008,9783905674101,,,,"We present a combination of techniques to simulate turbulent fluid flows in 3D. Flow in a complex domain is modeled using a regular rectilinear grid with a finite-difference solution to the incompressible Navier-Stokes equations. We propose the use of the QUICK advection algorithm over a globally high resolution grid. To calculate pressure over the grid, we introduce the Iterated Orthogonal Projection (IOP) framework. In IOP a series of orthogonal projections ensures that multiple conditions such as non-divergence and boundary conditions arising through complex domains shapes or moving objects will be satisfied simultaneously to specified accuracy. This framework allows us to use a simple and highly efficient multigrid method to enforce non-divergence in combination with complex domain boundary conditions. IOP is amenable to GPU implementation, resulting in over an order of magnitude improvement over a CPU-based solver. We analyze the impact of these algorithms on the turbulent energy cascade in simulated fluid flows and the resulting visual quality.",,SCA '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Magro D,Goy A",Towards a First Ontology for Customer Relationship Management,,2008,,,637–643,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Soft Computing as Transdisciplinary Science and Technology,"Cergy-Pontoise, France",2008,9781605580463,,https://doi.org/10.1145/1456223.1456352;http://dx.doi.org/10.1145/1456223.1456352,10.1145/1456223.1456352,"This paper presents some results of an ongoing project aimed at modeling the main concepts related to Customer Relationship Management (CRM). More precisely, the paper presents O-CREAM, a CRM ontology based on DOLCE and on two DOLCE-based modules, DnS (exploited for modeling roles and for handling reification) and OIO (exploited for modeling business knowledge by means of information objects). The project relies on the belief that all the actors involved in CRM could benefit from an ontological investigation of this field, aimed at providing a core set of formally described concepts and relations, useful both for describing CRM processes and for specifying the functionality of CRM applications. In particular, a well-formed CRM ontology would support communication and interoperability both in intra-organization and in inter-organization CRM processes. The paper discusses in details the axiomatization for the sale and customer relationship concepts, as well as for the corresponding business knowledge items (i.e., sale and customer records). It concludes by sketching a possible concrete exploitation of O-CREAM.","customer relationship management, enterprise ontology, CRM ontology",CSTST '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sheffi G,Petrank E",Functional Faults,,2020,,,453–463,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 32nd ACM Symposium on Parallelism in Algorithms and Architectures,"Virtual Event, USA",2020,9781450369350,,https://doi.org/10.1145/3350755.3400261;http://dx.doi.org/10.1145/3350755.3400261,10.1145/3350755.3400261,"Hardware and software faults increasingly surface in today's computing environment and vast theoretical and practical research efforts are devoted to ameliorate the effects of malfunctionality in the computing process. Most research to date, however, has focused on how to discover and handle faulty data. In this paper we formalize and study faulty functionality in a modern multicore shared-memory environment. Functional faults have been previously studied in the architecture community. However, they have never been formally defined and lower/upper bounds were not previously proven. We present a model of functional faults, and study avenues that allow tolerating functional faults while maintaining the correctness of the entire computation. We exemplify this model by constructing a robust consensus protocol from functionally-faulty compare-and-swap objects. We then show a (tight) impossibility result for the same construction, when the number of faults exceeds a certain threshold. Interestingly, for some fault types, more functional faults can be tolerated than the analogue data faults, beating an impossibility result for data faults and demonstrating the difference between the two models.","shared memory, fault-tolerance, software faults, hardware faults, lowerbounds, concurrent algorithms",SPAA '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bickford M,Cohen L,Constable RL,Rahli V",Computability Beyond Church-Turing via Choice Sequences,,2018,,,245–254,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science,"Oxford, United Kingdom",2018,9781450355834,,https://doi.org/10.1145/3209108.3209200;http://dx.doi.org/10.1145/3209108.3209200,10.1145/3209108.3209200,"Church-Turing computability was extended by Brouwer who considered non-lawlike computability in the form of free choice sequences. Those are essentially unbounded sequences whose elements are chosen freely, i.e. not subject to any law. In this work we develop a new type theory BITT, which is an extension of the type theory of the Nuprl proof assistant, that embeds the notion of choice sequences. Supporting the evolving, non-deterministic nature of these objects required major modifications to the underlying type theory. Even though the construction of a choice sequence is non-deterministic, once certain choices were made, they must remain consistent. To ensure this, BITT uses the underlying library as state and store choices as they are created. Another salient feature of BITT is that it uses a Beth-like semantics to account for the dynamic nature of choice sequences. We formally define BITT and use it to interpret and validate essential axioms governing choice sequences. These results provide a foundation for a fully intuitionistic version of Nuprl.",,LICS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wang H,Liao M,Zhang Q,Yang R,Turk G",Physically Guided Liquid Surface Modeling from Videos,ACM Trans. Graph.,2009,28,3,,Association for Computing Machinery,"New York, NY, USA",,,,2009-07,,0730-0301,https://doi.org/10.1145/1531326.1531396;http://dx.doi.org/10.1145/1531326.1531396,10.1145/1531326.1531396,"We present an image-based reconstruction framework to model real water scenes captured by stereoscopic video. In contrast to many image-based modeling techniques that rely on user interaction to obtain high-quality 3D models, we instead apply automatically calculated physically-based constraints to refine the initial model. The combination of image-based reconstruction with physically-based simulation allows us to model complex and dynamic objects such as fluid. Using a depth map sequence as initial conditions, we use a physically based approach that automatically fills in missing regions, removes outliers, and refines the geometric shape so that the final 3D model is consistent to both the input video data and the laws of physics. Physically-guided modeling also makes interpolation or extrapolation in the space-time domain possible, and even allows the fusion of depth maps that were taken at different times or viewpoints. We demonstrated the effectiveness of our framework with a number of real scenes, all captured using only a single pair of cameras.","image-based reconstruction, physically-based fluid simulation, space-time model completion",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hassan R,Bohner S,El-Kassas S",Formal Derivation of Security Design Specifications from Security Requirements,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th Annual Workshop on Cyber Security and Information Intelligence Research: Developing Strategies to Meet the Cyber Security and Information Intelligence Challenges Ahead,"Oak Ridge, Tennessee, USA",2008,9781605580982,,https://doi.org/10.1145/1413140.1413152;http://dx.doi.org/10.1145/1413140.1413152,10.1145/1413140.1413152,"Engineering secure software remains a significant challenge for today's software organizations as they struggle to understand the implications of security o the system and develop systems that guarantee specified software security properties. Despite many software engineering advances, current methods for deriving a design from a set of requirements that guarantee the retention of the intended security properties remains difficult and often unachievable. If security requirements are formalized and transformed into design using formal methods, the result would reduce the potential for security vulnerabilities through better clarity, completeness, and consistency. To this end, we outline a requirements-driven security engineering approach for deriving design specifications from security requirements that guarantee security properties specified in requirements are retained. We build on the goal-oriented KAOS (Knowledge Acquisition in autOmated Specifications) framework to formally construct a complete, consistent, and clear security requirements model. The resulting model is then transformed to the B language to derive security design specifications. Using B enables us to further implement the design while preserving requirements relevant security properties. Using the B refinement mechanism, we generate design specifications and ultimately implementation. The approach treats security-specific elements in a systematic and constructive way while considering security early in the development lifecycle with assurance of completeness, consistency and clarity throughout the development. Moreover, our approach allows for requirement traceability at the various phases of development that helps security evaluators to have more confidence in the target of evaluation.","formal methods, goal-oriented security requirements engineering, design specifications, threat models, attack analysis",CSIIRW '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Hassan H,Awang MI,Makhtar M,Zakaria AH,Ismail R,Ahmad F",Algorithms for Extracting Adjacency Matrix Based on Formal Concept Analysis (FCA),,2017,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the Second International Conference on Internet of Things, Data and Cloud Computing","Cambridge, United Kingdom",2017,9781450347747,,https://doi.org/10.1145/3018896.3018952;http://dx.doi.org/10.1145/3018896.3018952,10.1145/3018896.3018952,"The desire to achieve a holistic representation of Information Retrieval (IR) with the aim for a human-oriented form of representation has spurred the growth of concept-based IR search techniques such as the Semantic Web technology. However, Semantic Web calls for the use of ontologies for many domains. Although meaningful and important, ontology development presents great challenges to the developers especially in terms of conceptual dynamics.. This paper is based on a study that attempts to provide an alternative to ontology lookup for Semantic information retrieval. However, the focus of the paper is on a method proposed to extract adjacency matrix from concepts obtained from the theory of Formal Concept Analysis (FCA) using two consecutive algorithms called the Relatedness Algorithm and Adjacency Matrix Algorithm. Consequently, the adjacency matrices obtained could be used in a similarity measure process based on graph theory. The proposed method offers an alternative to specific domain ontology look-up where results from the measure can further be used in concept-based IR process.","formal concept analysis, graph theory, adjacency matrix, information retrieval",ICC '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhu X,Wu Y,Chen L,Jing N",Research on Gazetteer Information Retrieval Involving Spatial Relationship Semantics,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd International Conference on Computer Science and Application Engineering,"Sanya, China",2019,9781450362948,,https://doi.org/10.1145/3331453.3360970;http://dx.doi.org/10.1145/3331453.3360970,10.1145/3331453.3360970,"As an essential part of geographic information retrieval, gazetteer services are closely related to people's life quality. It is important to construct intelligent gazetteer service and improve its retrieval quality. Considering that the accuracy of document matching in large-scale data scenarios is relatively low and it is difficult to obtain the true intention of user queries, we propose a gazetteer retrieval method which takes into account the spatial relationship semantics. Firstly, the multivariable geo-location retrieval pattern of gazetteer service is defined as the basis for constructing the spatial relationship semantic model. Secondly, a measurement formula is given for calculating attribute similarity and spatial relationship similarity. In particular, we propose a similarity measurement approach that reconstructs geographical name entity so as to adapt the characteristics of non-point objects' spatial relationship. Finally, our proposal is evaluated on real-world datasets against traditional methods. The results reveal that the proposed method can not only enrich user's geo-location retrieval pattern, but also improve the effectiveness and quality of gazetteer services under the background of big data.","Spatial relationship semantic model, Gazetteer services, Geo-location retrieval pattern",CSAE 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Aggarwal N,Prakash N,Sofat S",Web Hypermedia Content Management System Effort Estimation Model,SIGSOFT Softw. Eng. Notes,2009,34,2,1–7,Association for Computing Machinery,"New York, NY, USA",,,,2009-02,,0163-5948,https://doi.org/10.1145/1507195.1507201;http://dx.doi.org/10.1145/1507195.1507201,10.1145/1507195.1507201,"This study aims at creation of a well defined estimation model which can be used to estimate the effort required for designing and developing the web hypermedia content management systems. The data from the different content management system projects are studied and the linear regression approach is used to finalize the model. This model also provides guidelines to calculate phase wise distribution of effort. The model is designed to help project manager to estimate effort at the very early stage of requirement analysis. A set of questionnaire is used to estimate the complexity of the project, which has to be filled after completing the initial requirement analysis. Final effort is estimated using the project size and the different adjustment factors. For better calculation of these adjustments factors, these are categorized into three categories based on their characteristics such as Production and General system characteristics. This model is proposed to be used differently for the different types of projects. These projects are categorized based on their size and total/build effort ratio. The size of the project is estimated by using the modified object point analysis approach. The estimated effort is further phase wise distributed for better scheduling of the project. Another questionnaire is used to refine the model and it has to be filled by the project managers after completing the project. The proposed model is validated by studying twelve completed projects taken from industry and seventy different projects completed by the students. The proposed model shows a great improvement as compared to the earlier models used in effort estimation of CMS projects.","object points analysis, effort estimation, content management system, web project estimation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Withana A,Kondo M,Makino Y,Kakehi G,Sugimoto M,Inami M",ImpAct: Immersive Haptic Stylus to Enable Direct Touch and Manipulation for Surface Computing,Comput. Entertain.,2011,8,2,,Association for Computing Machinery,"New York, NY, USA",,,,2011-12,,,https://doi.org/10.1145/1899687.1899691;http://dx.doi.org/10.1145/1899687.1899691,10.1145/1899687.1899691,"This article explores direct touch and manipulation techniques for surface computing environments using a specialized haptic force feedback stylus, called ImpAct, which can dynamically change its effective length and equipped with sensors to calculate its orientation in world coordinates. When a user pushes it against a touch screen, the physical stylus shrinks and a rendered projection of the stylus is drawn inside the screen, giving the illusion that it is submerged in the display device. Once the users can see the stylus immersed in the digital world below the screen, he or she can manipulate and interact with the virtual objects with active haptic sensations. In this article, ImpAct's functionality, design, and prototype applications are described in detail with relevance to the concept of direct touch, giving special attention to novel interaction scenarios and design challenges. Furthermore, a technical evaluation was done to study ImpAct's accuracy and controlability and the results presented. This article concludes by discussing ImpAct's current limitations and future perspectives as a direct touch and manipulation tool.","Direct Touch, Haptic stylus, touch screen, 3D display",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Guan N,Lv M,Yi W,Yu G",WCET Analysis with MRU Cache: Challenging LRU for Predictability,ACM Trans. Embed. Comput. Syst.,2014,13,4s,,Association for Computing Machinery,"New York, NY, USA",,,,2014-04,,1539-9087,https://doi.org/10.1145/2584655;http://dx.doi.org/10.1145/2584655,10.1145/2584655,"Most previous work on cache analysis for WCET estimation assumes a particular replacement policy called LRU. In contrast, much less work has been done for non-LRU policies, since they are generally considered to be very unpredictable. However, most commercial processors are actually equipped with these non-LRU policies, since they are more efficient in terms of hardware cost, power consumption and thermal output, while still maintaining almost as good average-case performance as LRU.In this work, we study the analysis of MRU, a non-LRU replacement policy employed in mainstream processor architectures like Intel Nehalem. Our work shows that the predictability of MRU has been significantly underestimated before, mainly because the existing cache analysis techniques and metrics do not match MRU well. As our main technical contribution, we propose a new cache hit/miss classification, k-Miss, to better capture the MRU behavior, and develop formal conditions and efficient techniques to decide k-Miss memory accesses. A remarkable feature of our analysis is that the k-Miss classifications under MRU are derived by the analysis result of the same program under LRU. Therefore, our approach inherits the advantages in efficiency and precision of the state-of-the-art LRU analysis techniques based on abstract interpretation. Experiments with instruction caches show that our proposed MRU analysis has both good precision and high efficiency, and the obtained estimated WCET is rather close to (typically 1%∼8% more than) that obtained by the state-of-the-art LRU analysis, which indicates that MRU is also a good candidate for cache replacement policies in real-time systems.","worst-case execution times, cache replacement, MRU, Hard real time",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Izuta R,Murao K,Terada T,Tsukamoto M",Early Gesture Recognition Method with an Accelerometer,,2014,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th Augmented Human International Conference,"Kobe, Japan",2014,9781450327619,,https://doi.org/10.1145/2582051.2582105;http://dx.doi.org/10.1145/2582051.2582105,10.1145/2582051.2582105,"An accelerometer is installed in most current mobile phones, such as the iPhones, Android-powered devices, and video game controllers for Wii or PS3, which enable easy and intuitive operations such as scrolling browsers and drawing 3D objects by detecting the inclination and motion of devices. Therefore, many gesture-based user interfaces with accelerometers are expected to appear in the future. Gesture recognition systems with accelerometers generally have to construct gesture models with user's gesture data before use, and recognize unknown gestures by comparing them with training data. As recognition process generally starts after the gesture has finished, output of the recognition result and feedback, e.g. scrolling, have a delay, which may cause users to retry gestures and degrade interface usability. We propose a method of early gesture recognition that calculates the distance between input data and training data sequentially, and outputs recognition results only when one output candidate has a stronger likelihood than the others. Additionally, we implemented a gesture-based photo viewer as an example of useful applications of our proposed method.","early recognition, gesture recognition, accelerometer",AH '14,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kem O,Balbo F,Zimmermann A",Multi-Goal Pathfinding in Ubiquitous Environments: Modeling and Exploiting Knowledge to Satisfy Goals,,2017,,,1147–1150,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Web Intelligence,"Leipzig, Germany",2017,9781450349512,,https://doi.org/10.1145/3106426.3109054;http://dx.doi.org/10.1145/3106426.3109054,10.1145/3106426.3109054,"Multi-goal pathfinding (MGPF) is a problem of searching for a path between a start and a destination allowing a set of goals to be satisfied. We address MGPF in ubiquitous environments that accommodate cyber, physical and social (CPS) entities from smart objects to sensors and to humans. Given a MGPF problem in a pervasive environment, our approach aims at exploiting data from various resources including CPS entities located in the environment and external resources such as the Web to solve the problem. In this paper, we present a knowledge model for describing a ubiquitous environment integrating its spatial dimension, CPS entities it contains and its relevant resources. A global view of the approach is provided. We address particularly one of the challenges in MGPF, namely goal satisfaction problem, which consists of identifying through which entities a goal can be satisfied. Towards this aim, we design an ontology to formally model CPS entities, goals and their relations. We describe a method to exploit modeled knowledge in order to solve the goal satisfaction problem.","ubiquitous environment, ontology, multi-goal pathfinding",WI '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Jarabo A,Marco J,Muñoz A,Buisan R,Jarosz W,Gutierrez D",A Framework for Transient Rendering,ACM Trans. Graph.,2014,33,6,,Association for Computing Machinery,"New York, NY, USA",,,,2014-11,,0730-0301,https://doi.org/10.1145/2661229.2661251;http://dx.doi.org/10.1145/2661229.2661251,10.1145/2661229.2661251,"Recent advances in ultra-fast imaging have triggered many promising applications in graphics and vision, such as capturing transparent objects, estimating hidden geometry and materials, or visualizing light in motion. There is, however, very little work regarding the effective simulation and analysis of transient light transport, where the speed of light can no longer be considered infinite. We first introduce the transient path integral framework, formally describing light transport in transient state. We then analyze the difficulties arising when considering the light's time-of-flight in the simulation (rendering) of images and videos. We propose a novel density estimation technique that allows reusing sampled paths to reconstruct time-resolved radiance, and devise new sampling strategies that take into account the distribution of radiance along time in participating media. We then efficiently simulate time-resolved phenomena (such as caustic propagation, fluorescence or temporal chromatic dispersion), which can help design future ultra-fast imaging devices using an analysis-by-synthesis approach, as well as to achieve a better understanding of the nature of light transport.","transient rendering, bidirectional path tracing, importance sampling, progressive photon mapping, transient light transport",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Bannon LJ,Re-Framing HCI: From Human-Computer Interaction to Human-Centred Interaction Design,,2011,,,17–18,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM SIGCHI Italian Chapter International Conference on Computer-Human Interaction: Facing Complexity,"Alghero, Italy",2011,9781450308762,,https://doi.org/10.1145/2037296.2037304;http://dx.doi.org/10.1145/2037296.2037304,10.1145/2037296.2037304,"HCI has expanded enormously since the emergence of the field in the early 1980s. Computing has changed significantly; mobile and ubiquitous communication networks span the globe, and technology has been integrated into all aspects of our daily lives. Computing is not simply for calculating, but rather is a medium through which we collaborate and interact with other people. The focus is not so much on human-computer interaction as it is on human activities mediated by computing. Thus much (though by no means all) of the focus of HCI has shifted from the desire to make better \man-machine communication\"" (sic) through for example building more human-like interface agents",to the creation of intuitive,simple,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jacob F,Becker L,Grashöfer J,Hartenstein H",Matrix Decomposition: Analysis of an Access Control Approach on Transaction-Based DAGs without Finality,,2020,,,81–92,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 25th ACM Symposium on Access Control Models and Technologies,"Barcelona, Spain",2020,9781450375689,,https://doi.org/10.1145/3381991.3395399;http://dx.doi.org/10.1145/3381991.3395399,10.1145/3381991.3395399,"The Matrix message-oriented middleware (see https://matrix.org) is gaining momentum as a basis for a decentralized, secure messaging system as shown, for example, by its deployment within the French government and by the Mozilla foundation. Thus, understanding the corresponding access control approach is important. This paper provides an ab- straction and an analysis of the access control approach followed by Matrix. We show that Matrix can be seen as a form of Distributed Ledger Technology (DLT) based on Transaction-based Directed Acyclic Graphs (TDAGs). TDAGs connect individual transactions to form a DAG, instead of collecting transactions in blocks as in blockchains. These TDAGs only provide causal order, eventual consistency, and no finality. However, unlike conventional DLTs, Matrix does not aim for a strict system-wide consensus. Thus, there is also no guarantee for a strict consensus on access rights. By de- composition of the Matrix approach, we show that a sound decen- tralized access control can be implemented for TDAGs in general, and for Matrix in particular, despite those weak guarantees. In ad- dition, we discovered security issues in popular implementations and emphasize the need for a formal verification of the employed conflict resolution mechanism.","transaction-based directed acyclic graphs, access control, policy information, decentralized, publish-subscribe, matrix, distributed ledger technology",SACMAT '20,transparent interaction designs which allow people to easily express themselves through various computationally-enhanced tools and media. While we continue to develop new technological platforms,and investigate the use of gesture,speech and touch as interaction forms,the focus of HCI has been shifting as we realize the disappearance of the computer as the locus of interaction per se. Rather,computation is embodied within existing objects and spaces in the world. The emerging field of interaction design attempts to frame this new discourse around the design of these computationally-enhanced objects and services,and to sensitize us to new ways of thinking about human-computer interaction,"distinct from our earlier engineering focus on the design of efficient tasks and activity sequences. Focus has shifted from measures of efficiency towards an understanding of the ethics and aesthetics of interaction.I believe that we are at a point of inflection for the HCI field. Many of our earlier assumptions about the development of technology and our interaction with computers are being questioned. New disciplines are \""muscling in\"" - anthropology",the design disciplines,art and media theory,to name a few,and questioning the traditional HCI reliance on the psychological and engineering/computing sciences. In this presentation I wish to explore some of the tensions between different frames for approaching HCI -- the human factors engineering tradition,the computing/AI tradition,and the interaction design tradition. Each of these traditions (I hesitate to call them 'paradigms') has developed our understanding of human-computer interaction,so it is not simply a case of one superseding the other. Rather they point to different ways of viewing the field,and lead to different questions and different methods. But this presentation is not designed to be some form of neutral view on these different approaches. Rather,I wish to highlight certain issues that have been of central concern for my own evolving approach to the HCI field. I have recently outlined some of these concerns in a paper in ACM Interactions [1] and will take up some of the themes mentioned there in this presentation.One of these themes relates to the general thrust of computing in human affairs. It seems that despite all we have learned about both human and machine competencies,"there is still a fascination with the elimination of the \""human factor\"" and its substitution by (supposed) machine intelligence. I would argue that even where this goal of substitution is not explicit",it is latent in very many research agendas. As an alternative to this substitution model,I wish to advocate an approach that focuses on human augmentation rather than substitution,where human capabilities are taken as a starting point,with our focus being on how we support,develop and extend people's capabilities through the latest technological developments. This leads to some discussion concerning the relation between the social and the technical,and the more recent approaches in Science and Technology studies to reframe these basic distinctions. Finally,I wish to address briefly the ethical aspects of our approaches,in terms of our value frameworks,an admittedly thorny topic,yet one with which it is necessary to engage,"as we seek for adequate philosophical frameworks for our design research. The emergence of \""human-centred\"" approaches to computing and design in this regard will be discussed.""",,CHItaly
1,Conference Paper,"Basile D,ter Beek MH,Di Giandomenico F,Gnesi S",Orchestration of Dynamic Service Product Lines with Featured Modal Contract Automata,,2017,,,117–122,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st International Systems and Software Product Line Conference - Volume B,"Sevilla, Spain",2017,9781450351195,,https://doi.org/10.1145/3109729.3109741;http://dx.doi.org/10.1145/3109729.3109741,10.1145/3109729.3109741,"In Service-Oriented Computing, contracts provide a way to characterise the behavioural conformance of a composition of services, and to guarantee that the results do not lead to spurious compositions. Adding variability leads to a product line of services capable of adapting to customer requirements and to changes in the context in which they operate. To this aim, we extended a previously introduced formal model of service contracts. In particular, we included: (i) feature-based constraints and (ii) four classes of service requests to characterise different variants of service agreement. We then exploited Supervisory Control Theory to define an algorithm to synthesise an orchestration of services that satisfies: (i) all feature constraints of the service product line, and (ii) the maximal number of service requests for which an agreement can be reached. Moreover, such an orchestration of a service product line, whose number of products is potentially exponential in the number of features, can be synthesised from only a subset of its products. A prototypical tool supports the developed theory. In this short paper, we provide the intuition for our approach and illustrate it by means of a Hotel reservation service product line.","Services, Product lines, Featured Modal Contract Automata",SPLC '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schneider R,Zhang L,Goswami D,Masrur A,Chakraborty S",Compositional Analysis of Switched Ethernet Topologies,,2013,,,1099–1104,EDA Consortium,"San Jose, CA, USA",,"Proceedings of the Conference on Design, Automation and Test in Europe","Grenoble, France",2013,9781450321532,,,,"In this paper we study distributed automotive control applications whose tasks are mapped onto different ECUs communicating via a switched Ethernet network. As traditional automotive communication buses like CAN, FlexRay, LIN and MOST are gradually reaching their performance limits because of the increasing complexity of automotive architectures and applications, Ethernet-based in-vehicle communication systems have attracted a lot of attention in recent times. However, currently there is very little work on systematic timing analysis for Ethernet which is important for its deployment in safety-critical scenarios like in an automotive architecture. In this work, we propose a compositional timing analysis technique that takes various features of switched Ethernet into account like network topology, frame priorities, communication delay, memory requirement on switches, performance, etc. Such an analysis technique is particularly suitable during early design phases of automotive architectures and control software deployment. We demonstrate its use in analyzing mixed-criticality traffic patterns consisting of messages from performance-oriented control loops and timing-sensitive real-time tasks. We further evaluate the tightness of the obtained analytical bounds with an OMNeT++ based network simulation environment, which involves long simulation time and does not provide formal guarantees.",,DATE '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Celorrio-Barragué L,Calvo-Simón S,Gaspar M,Vidal-Cortés M,Martín-Ramos P",3D Printed Models-Based Lab Activities to Enhance Learning-Teaching Processes in Structural Engineering Courses,,2019,,,80–86,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Seventh International Conference on Technological Ecosystems for Enhancing Multiculturality,"León, Spain",2019,9781450371919,,https://doi.org/10.1145/3362789.3362819;http://dx.doi.org/10.1145/3362789.3362819,10.1145/3362789.3362819,"Three-dimensional (3D) printing is a promising tool in Engineering education, as it can facilitate learning, contribute to the development of key skills and competences, increase the engagement and interest of students, and promote their creativity. In this work, a set of laboratory activities aimed at enhancing the learning-teaching experience of sophomore and junior students of engineering degrees related to structures is presented. To improve their understanding and their ability to calculate the stability, strength and rigidity of built structures, the use of 3D printed models is put forward. These printed models can be used as specimens in lab tests and also as visualization objects to improve students' comprehension in lectures. Moreover, they offer interesting advantages in terms of their lower cost, easy manipulation, low weight and short time of production. Five lessons, designed for Strength of Materials and Theory of Structures courses, which cover tensile testing, the analysis of truss and plane frames, bolted and welded joints, and constructive details in reinforced concrete structures are discussed.","Steel structures, Lab activities, Additive manufacturing, 3D printing, Structural Engineering",TEEM'19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yan,Zhao Z,Ng W",Monochromatic and Bichromatic Reverse Nearest Neighbor Queries on Land Surfaces,,2012,,,942–951,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st ACM International Conference on Information and Knowledge Management,"Maui, Hawaii, USA",2012,9781450311564,,https://doi.org/10.1145/2396761.2396880;http://dx.doi.org/10.1145/2396761.2396880,10.1145/2396761.2396880,"Finding reverse nearest neighbors (RNNs) is an important operation in spatial databases. The problem of evaluating RNN queries has already received considerable attention due to its importance in many real-world applications, such as resource allocation and disaster response. While RNN query processing has been extensively studied in Euclidean space, no work ever studies this problem on land surfaces. However, practical applications of RNN queries involve terrain surfaces that constrain object movements, which rendering the existing algorithms inapplicable.In this paper, we investigate the evaluation of two types of RNN queries on land surfaces: monochromatic RNN (MRNN) queries and bichromatic RNN (BRNN) queries. On a land surface, the distance between two points is calculated as the length of the shortest path along the surface. However, the computational cost of the state-of-the-art shortest path algorithm on a land surface is quadratic to the size of the surface model, which is usually quite huge. As a result, surface RNN query processing is a challenging problem.Leveraging some newly-discovered properties of Voronoi cell approximation structures, we make use of standard index structures such as an R-tree to design efficient algorithms that accelerate the evaluation of MRNN and BRNN queries on land surfaces. Our proposed algorithms are able to localize query evaluation by accessing just a small fraction of the surface data near the query point, which helps avoid shortest path evaluation on a large surface. Extensive experiments are conducted on large real-world datasets to demonstrate the efficiency of our algorithms.","land surface, terrain, reverse nearest neighbor",CIKM '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Svenningsson N,Faraon M",Artificial Intelligence in Conversational Agents: A Study of Factors Related to Perceived Humanness in Chatbots,,2019,,,151–161,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 2nd Artificial Intelligence and Cloud Computing Conference,"Kobe, Japan",2019,9781450372633,,https://doi.org/10.1145/3375959.3375973;http://dx.doi.org/10.1145/3375959.3375973,10.1145/3375959.3375973,"Artificial intelligence (AI) is gaining traction in service-oriented businesses in the form of chatbots. A chatbot is a popular type of social AI that uses natural language processing to communicate with users. Past studies have shown discrepancies in terms of whether or not a chatbot should communicate and behave like a human. This article aims to explore these discrepancies in order to provide a theoretical contribution of a list of factors related to perceived humanness in chatbots and how these may consequently lead to a positive user experience. The results suggest that a chatbot should have the following characteristics: avoiding small talk and maintaining a formal tone; identifying itself as a bot and asking how it can help; providing specific information and articulating itself with sophisticated choices of words and well-constructed sentences; asking follow-up questions during decision-making processes and; providing an apology when the context is not comprehensible, followed by a question or a statement to dynamically move a conversation forward. These results may have implications for designers working in the field of AI as well as for the wider debates and the broader discourse around the adoption of AI in society.","user experience, conversation, design guideline, chatbot, artificial intelligence, AI, humanness",AICCC 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yu Y,Kaiya H,Washizaki H,Xiong Y,Hu Z,Yoshioka N",Enforcing a Security Pattern in Stakeholder Goal Models,,2008,,,9–14,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th ACM Workshop on Quality of Protection,"Alexandria, Virginia, USA",2008,9781605583211,,https://doi.org/10.1145/1456362.1456366;http://dx.doi.org/10.1145/1456362.1456366,10.1145/1456362.1456366,"Patterns are useful knowledge about recurring problems and solutions. Detecting a security problem using patterns in requirements models may lead to its early solution. In order to facilitate early detection and resolution of security problems, in this paper, we formally describe a role-based access control (RBAC) as a pattern that may occur in stakeholder requirements models. We also implemented in our goal-oriented modeling tool the formally described pattern using model-driven queries and transformations. Applied to a number of requirements models published in literature, the tool automates the detection and resolution of the security pattern in several goal-oriented stakeholder requirements.","goal models, rbac, model transformations, security patterns",QoP '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Joshaghani R,Black S,Sherman E,Mehrpouyan H",Formal Specification and Verification of User-Centric Privacy Policies for Ubiquitous Systems,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Database Applications & Engineering Symposium,"Athens, Greece",2019,9781450362498,,https://doi.org/10.1145/3331076.3331105;http://dx.doi.org/10.1145/3331076.3331105,10.1145/3331076.3331105,"As our society has become more information oriented, each individual is expressed, defined, and impacted by information and information technology. While valuable, the current state-of-the-art mostly are designed to protect the enterprise/ organizational privacy requirements and leave the main actor, i.e., the user, un-involved or with the limited ability to have control over his/her information sharing practices. In order to overcome these limitations, algorithms and tools that provide a user-centric privacy management system to individuals with different privacy concerns are required to take into the consideration the dynamic nature of privacy policies which are constantly changing based on the information sharing context and environmental variables. This paper extends the concept of contextual integrity to provide mathematical models and algorithms that enables the creations and management of privacy norms for individual users. The extension includes the augmentation of environmental variables, i.e. time, date, etc. as part of the privacy norms, while introducing an abstraction and a partial relation over information attributes. Further, a formal verification technique is proposed to ensure privacy norms are enforced for each information sharing action.","privacy, user-centric policies, formal methods",IDEAS '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tekli G,Chbeir R,Fayolle J",XCDL: An XML-Oriented Visual Composition Definition Language,,2010,,,134–143,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Conference on Information Integration and Web-Based Applications & Services,"Paris, France",2010,9781450304214,,https://doi.org/10.1145/1967486.1967510;http://dx.doi.org/10.1145/1967486.1967510,10.1145/1967486.1967510,"XML data flow has reached beyond the world of computer science and has spread to other areas such as data communication, e-commerce and instant messaging. Therefore, manipulating this data by non expert programmers is becoming imperative. On one hand, Mashups have emerged a few years ago, providing users with visual tools for web data manipulation but not necessarily XML specific. Mashups have been leaning towards functional composition but no formal languages have yet been defined. On the other hand, visual languages for XML have been emerging since the standardization of XML, and mostly relying on querying XML data for extraction or structure transformations. These languages are mainly based on existing textual XML languages, have limited expressiveness and do not provide non expert programmers with means to manipulate XML data. In this paper, we define a generic visual language called XCDL based on Colored Petri Nets allowing non expert programmers to compose manipulation operations. The language is adapted to XML, providing users with means to compose XML oriented operations. The language core syntax is presented here along with an implemented prototype based on it.","XML data manipulation, composition, visual languages, colored Petri nets",iiWAS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sharma M,Hildebrandt D,Newman G,Young JE,Eskicioglu R",Communicating Affect via Flight Path: Exploring Use of the Laban Effort System for Designing Affective Locomotion Paths,,2013,,,293–300,IEEE Press,"Tokyo, Japan",,Proceedings of the 8th ACM/IEEE International Conference on Human-Robot Interaction,,2013,9781467330558,,,,"People and animals use various kinds of motion in a multitude of ways to communicate their ideas and affective state, such as their moods or emotions. Further, people attribute affect and personalities to movements of even non-life like entities based solely on the style of their motions, e.g., the locomotion style of a geometric shape (how it moves about) can be interpreted as being shy, aggressive, etc. We investigate how robots can leverage this locomotion-style communication channel for communication with people. Specifically, our work deals with designing stylistic flying-robot locomotion paths for communicating affective state.To author and unpack the parameters of affect-oriented flying-robot locomotion styles we employ the Laban Effort System, a standard method for interpreting human motion commonly used in the performing arts. This paper describes our adaption of the Laban Effort System to author motions for flying robots, and the results of a formal experiment that investigated how various Laban Effort System parameters influence people's perception of the resulting robotic motions. We summarize with a set of guidelines for aiding designers in using the Laban Effort System to author flying robot motions to elicit desired affective responses.","human-robot interaction, laban effort system, affective computing, motion parameters, social human-robot interaction",HRI '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Whittle J,Wijesekera D,Hartong M",Executable Misuse Cases for Modeling Security Concerns,,2008,,,121–130,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 30th International Conference on Software Engineering,"Leipzig, Germany",2008,9781605580791,,https://doi.org/10.1145/1368088.1368106;http://dx.doi.org/10.1145/1368088.1368106,10.1145/1368088.1368106,"Misuse cases are a way of modeling negative requirements, that is, behaviors that should not occur in a system. In particular, they can be used to model attacks on a system as well as the security mechanisms needed to avoid them. However, like use cases, misuse cases describe requirements in a high-level and informal manner. This means that, whilst they are easy to understand, they do not lend themselves to testing or analysis. In this paper, we present an executable misuse case modeling language which allows modelers to specify misuse case scenarios in a formal yet intuitive way and to execute the misuse case model in tandem with a corresponding use case model. Misuse scenarios are given in executable form and mitigations are captured using aspect-oriented modeling. The technique is useful for brainstorming potential attacks and their mitigations. Furthermore, the use of aspects allows mitigations to be maintained separately from the core system model. The paper, supported by a UML-based modeling tool, describes an application to two case studies, providing evidence that the technique can support red-teaming of security requirements forn realistic systems.","aspect scenarios, misuse cases",ICSE '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wu S,Liu Z,Ren Y,Wu Q",A Novel Stereo Vision Sensor for Fast Moving Objects,,2018,,,41–45,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Machine Vision and Applications,"Singapore, Singapore",2018,9781450363815,,https://doi.org/10.1145/3220511.3220524;http://dx.doi.org/10.1145/3220511.3220524,10.1145/3220511.3220524,"In this paper, we propose a novel stereo vision sensor for the automatic 3-D dynamic surface measurement, which is able to simultaneously acquire the 2-D scan image and the 3-D reconstruction results. The proposed system mainly concludes a line scan camera, a frame camera and two line lasers. Due to the application of line lasers, the proposed system is able to work accurate and stable under complex lighting condition. About our system, the view plane of line scan camera and the light plane of line laser are in coincidence. First, the calibration of intrinsic, extrinsic parameters and the light plane coefficients are obtained. Epipolar line is calculated to extract the accurate position of image point corresponding to each pixel of line scan camera. Finally, the 3-D shape is reconstructed according to binocular stereo vision model. The 2-D image and 3-D façade information can be synchronously acquired by scanning over objects. Physical experiments show that the proposed stereo vision sensor can provide robust and accurate results.","Dynamic measurement, stereo vision sensor, 2-D scan image, 3-D surface reconstruction",ICMVA 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Deb R,Pai MM",Ironing in Dynamic Revenue Management: Posted Prices & Biased Auctions,,2013,,,620–631,Society for Industrial and Applied Mathematics,USA,,Proceedings of the Twenty-Fourth Annual ACM-SIAM Symposium on Discrete Algorithms,"New Orleans, Louisiana",2013,9781611972511,,,,"We consider the design of the revenue maximizing mechanism for a seller with a fixed capacity of C units selling over T periods to buyers who arrive over time. The buyers have single unit demand and multi-dimensional private information-- both their value for the object and the deadline by which they must make a purchase are unknown to the seller. This contrasts with previous work where buyers have single dimensional private information-- deadlines are publicly observed and only values are private. Here, the optimal mechanism can be computed by running a dynamic stochastic knapsack algorithm. However, these mechanisms are only optimal with private deadlines when the calculated allocation rule is monotone-- buyers with higher values and later deadlines should be allocated with higher probability. Such monotonicity only arises in very special cases.By contrast, in the classic static environment of Myerson [7] monotonicity is only violated for 'irregular' value distributions. Myerson characterizes the optimal mechanism by a procedure he calls 'ironing.' We characterize the optimal mechanism in our general dynamic environment by providing the dynamic counterpart of ironing. We show that only a subset of the monotonicity constraints can bind in a solution of the seller's dynamic programming problem. The optimal mechanism can be characterized by 'relaxing' these constraints with their appropriate dual multiplier. Further, the optimal mechanism can be implemented by a series of posted prices followed by a 'biased' auction in the final period where buyers have the auction biased in their favor depending on their arrival time. Our theoretical characterization complements the existing computational approaches for ironing in these settings (e.g. Parkes et al. [10]).",,SODA '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gao Q,Shen X",Height Estimation from Single Aerial Imagery with a Deep Boundary-Guided Network,,2021,,,59–65,Association for Computing Machinery,"New York, NY, USA",,2021 6th International Conference on Mathematics and Artificial Intelligence,"Chengdu, China",2021,9781450389464,,https://doi.org/10.1145/3460569.3460583;http://dx.doi.org/10.1145/3460569.3460583,10.1145/3460569.3460583,"Extracting 3D information from single aerial image plays an important role in computer vision and remote sensing. However, due to the structural complexity of ground objects and noise introduced during the generation stage of ground truth labels, it is challenging to automatically recover the regularized height map from only one orthogonal photography. In this paper, we propose a novel deep network for estimating accurate and regularized height map from a single aerial image. The network mainly contains two sub-networks, namely the height map derivation sub-network and the boundary guidance sub-network. They are sequentially connected together, so that the corresponding boundary map can be directly calculated after the height map is obtained. We also propose a loss function suitable for semantic boundary guidance, which is similar to SSIM loss function at the edges of the ground targets. Apart from pursuing accuracy of height regression, boundary regularity constraints derived from semantic labels are also employed to form a joint metric criterion. We perform a qualitative and quantitative evaluations on ISPRS remote sensing dataset, and the result indicate that our framework improve both accuracy and regularity of estimated depth map.","Neural networks, Aerial image, Boundary guided, Height estimation",ICMAI 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Savage V,Chang C,Hartmann B",Sauron: Embedded Single-Camera Sensing of Printed Physical User Interfaces,,2013,,,447–456,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology,"St. Andrews, Scotland, United Kingdom",2013,9781450322683,,https://doi.org/10.1145/2501988.2501992;http://dx.doi.org/10.1145/2501988.2501992,10.1145/2501988.2501992,"3D printers enable designers and makers to rapidly produce physical models of future products. Today these physical prototypes are mostly passive. Our research goal is to enable users to turn models produced on commodity 3D printers into interactive objects with a minimum of required assembly or instrumentation. We present Sauron, an embedded machine vision-based system for sensing human input on physical controls like buttons, sliders, and joysticks. With Sauron, designers attach a single camera with integrated ring light to a printed prototype. This camera observes the interior portions of input components to determine their state. In many prototypes, input components may be occluded or outside the viewing frustum of a single camera. We introduce algorithms that generate internal geometry and calculate mirror placements to redirect input motion into the visible camera area. To investigate the space of designs that can be built with Sauron along with its limitations, we built prototype devices, evaluated the suitability of existing models for vision sensing, and performed an informal study with three CAD users. While our approach imposes some constraints on device design, results suggest that it is expressive and accessible enough to enable constructing a useful variety of devices.","3d printing, vision-based sensing, prototyping, fabrication",UIST '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang G,Huo J,Zhang Z,He M,Zhang J,Xue M",Novel Pose Measurement with Optimized Principal Component Analysis for Unknown Spacecraft Based on Point Cloud,,2020,,,102–108,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Multimedia and Image Processing,"Nanjing, China",2020,9781450376648,,https://doi.org/10.1145/3381271.3381281;http://dx.doi.org/10.1145/3381271.3381281,10.1145/3381271.3381281,"This paper investigates the issue of vision orientation for unknown spacecraft in orbit-capture, upon which a fast and highly accurate pose measurement method based on improved coordinate system correction by weighted principal component analysis (PCA) is proposed. This algorithm weights point cloud features before dimensionality reduction, and then three principal component vectors in different frames are calculated. Consequently, the effective reduction of the original point cloud and the reduction of information overlap are achieved. The nearest point of the Euclidean distance is employed to corrected the direction of PCA coordinate axis, and thus the initial pose of two sets of point cloud are obtained. Finally, the point cloud in arbitrary pose relationship of unknown space can be aligned accurately by improved iterative closest point (ICP) algorithm with the kd-tree search strategy. The presented method overcomes the disadvantages of high requirement of initial value and avoiding local convergence, which means it achieves a global alignment for unknown target with point cloud of similar shape and integrity. Experiments show that the maximum relative error of attitude is superior to 0.15°, position error is less than ±4mm within the space 2000mmx2000mrnx3000rnm. Results verify that the accuracy and speed performance of the proposed approach can satisfy the requirements of on-orbit spacecraft to capture unknown objects.","pose measurement, unknown spacecraft, optimized PCA algorithm, stereo vision",ICMIP '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Setiyorini A,Purnama IP,Sari JY,Muchtar M,Ngii E",Vehicle Number Plate Identification Using Template Matching Algorithm for Automatic Parking System,,2019,,,196–200,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 5th International Conference on Computing and Artificial Intelligence,"Bali, Indonesia",2019,9781450361064,,https://doi.org/10.1145/3330482.3330483;http://dx.doi.org/10.1145/3330482.3330483,10.1145/3330482.3330483,"Nowadays, some parking system in Indonesia still use manual system that is the parking officer manually records every vehicle number plate that will be parked. This process is less efficient, because it consumes a lot of time and prone to errors. The application of digital image processing methods to automatic parking systems can overcome these problems. This research builds an automatic parking system by applying template matching algorithms. Template matching algorithm is used to help the process of analyzing all forms of character image objects on vehicle number plates, which include mapping the pixel intensity of character images, calculating errors, and searching for minimum error values. The advantage of template matching algorithm is that it processes data in the form of matrices whose computation level is not complex so it does not require a long processing time. Thus, the template matching algorithm is expected to be in accordance with the characteristics of an automatic parking system that will process large amounts of data. System testing has been carried out using 160 datasets of vehicle number plates and obtained good results with the highest accuracy of 91.7% and the average processing time of 13.7 seconds.","vehicle number plate, template matching, Parking system",ICCAI '19,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Song HC,Choi KN",Pedestrian Detection Based on Reduced High-Dimensional Distinctive Feature Using Deep Neural Network,,2018,,,6–10,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 2018 International Conference on Sensors, Signal and Image Processing","Prague, Czech Republic",2018,9781450366205,,https://doi.org/10.1145/3290589.3290601;http://dx.doi.org/10.1145/3290589.3290601,10.1145/3290589.3290601,"Pedestrian detection is an essential and significant research topic due to its diverse applications in the area of safety systems. The distinctiveness is detected by the following three steps. Firstly, images are represented by their respective co-occurrence matrices, which are vectorized by using the bag of visual words (BoVW) framework. Secondly, their weights are calculated from the histograms of visual words of each class. Finally, computed weights are applied to the testing image set as the distinctiveness of visual words. The fully connected Multi-Layer Perceptron (MLP) is used as classification method in our system, which has limited performance. This paper introduces a combination of principle component analysis (PCA), guided filtering, deeplearning architecture into visual data classification. In detail, as a mature dimension reduction architecture, PCA is capable of reducing the redundancy of multi-dimensional information. The proposed method is compared with the MLP using the Caltech 256 datasets, with the following classes: pedestrians, cars, motorbikes and airplanes. The experimental results show that the proposed method outperforms current methods in predicting pedestrians and transportation objects. It yields an average accuracy of 96.50%, which is approximately 8.5% more than the compared state-of-the-art.","Multi-Layer Perceptron, Scale-invariant feature transform, Pedestrian detection, Weighting scheme, Principle Component Analysis, Bag of visual words",SSIP 2018,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Lanman D,Luebke D",Near-Eye Light Field Displays,ACM Trans. Graph.,2013,32,6,,Association for Computing Machinery,"New York, NY, USA",,,,2013-11,,0730-0301,https://doi.org/10.1145/2508363.2508366;http://dx.doi.org/10.1145/2508363.2508366,10.1145/2508363.2508366,"We propose near-eye light field displays that enable thin, lightweight head-mounted displays (HMDs) capable of presenting nearly correct convergence, accommodation, binocular disparity, and retinal defocus depth cues. Sharp images are depicted by out-of-focus elements by synthesizing light fields corresponding to virtual objects within a viewer's natural accommodation range. We formally assess the capabilities of microlens arrays to achieve practical near-eye light field displays. Building on concepts shared with existing integral imaging displays and light field cameras, we optimize performance in the context of near-eye viewing. We establish fundamental trade-offs between the quantitative parameters of resolution, field of view, and depth of field, as well as the ergonomic parameters of form factor and ranges of allowed eye movement. As with light field cameras, our design supports continuous accommodation of the eye throughout a finite depth of field; as a result, binocular configurations provide a means to address the accommodation-convergence conflict occurring with existing stereoscopic displays. We construct a complete prototype display system, comprising: a custom-fabricated HMD using modified off-the-shelf parts and real-time, GPU-accelerated light field renderers (including a general ray tracing method and a \backward compatible\"" rasterization method supporting existing stereoscopic content). Through simulations and experiments",we motivate near-eye light field displays as thin,"lightweight alternatives to conventional near-eye displays.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Lian Z,Rosin PL,Sun X",A Rectilinearity Measurement for 3d Meshes,,2008,,,395–402,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st ACM International Conference on Multimedia Information Retrieval,"Vancouver, British Columbia, Canada",2008,9781605583129,,https://doi.org/10.1145/1460096.1460161;http://dx.doi.org/10.1145/1460096.1460161,10.1145/1460096.1460161,"In this paper, we propose and evaluate a novel shape measurement describing the extent to which a 3D mesh is rectilinear. Since the rectilinearity measure corresponds proportionally to the ratio of the sum of three orthogonal projected areas and the surface area of the mesh, it has the following desirable properties: 1) the estimated rectilinearity is always a number from (0,1]; 2) the estimated rectilinearity is 1 if and only if the measured 3D shape is rectilinear; 3) there are shapes whose estimated rectilinearity is arbitrarily close to 0; 4) the measurement is invariant under scale, rotation, and translation; 5) the 3D objects can be either open or closed meshes, and we can also deal with poor quality meshes; 6) the measurement is insensitive to noise and stable under small topology errors; and 7) a Genetic Algorithm (GA) can be applied to calculate the approximate rectilinearity efficiently. We have also implemented two experiments of its applications. The first experiment shows that, in some cases, the calculation of rectilinearity provides a better tool for registering the pose of 3D meshes compared to PCA. The second experiment demonstrates that the combination of this measurement and other shape descriptors can significantly improve 3D shape retrieval performance.","3d shape retrieval, rectilinearity, 3D shape measurement",MIR '08,"light field displays, virtual reality, head-mounted displays, microlens arrays, accommodation-convergence conflict",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gkaniatsou A,McNeill F,Bundy A,Steel G,Focardi R,Bozzato C",Getting to Know Your Card: Reverse-Engineering the Smart-Card Application Protocol Data Unit,,2015,,,441–450,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 31st Annual Computer Security Applications Conference,"Los Angeles, CA, USA",2015,9781450336826,,https://doi.org/10.1145/2818000.2818020;http://dx.doi.org/10.1145/2818000.2818020,10.1145/2818000.2818020,"Smart-cards are considered to be one of the most secure, tamper-resistant, and trusted devices for implementing confidential operations, such as authentication, key management, encryption and decryption for financial, communication, security and data management purposes. The commonly used RSA PKCS#11 standard defines the Application Programming Interface for cryptographic devices such as smart-cards. Though there has been work on formally verifying the correctness of the implementation of PKCS#11 in the API level, little attention has been paid to the low-level cryptographic protocols that implement it.We present REPROVE, the first automated system that reverse-engineers the low-level communication between a smart-card and a reader, deduces the card's functionality and translates PKCS#11 cryptographic functions into communication steps. REPROVE analyzes both standard-conforming and proprietary implementations, and does not require access to the card. To the best of our knowledge, REPROVE is the first system to address proprietary implementations and the only system that maps cryptographic functions to communication steps and on-card operations. We have evaluated REPROVE on five commercially available smart-cards and we show how essential functions to gain access to the card's private objects and perform cryptographic functions can be compromised through reverse-engineering traces of the low-level communication.","APDU formal modeling, Smart-card reverse-engineering, APDU attacks, PKCS#11 low-level attacks",ACSAC 2015,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Arsyad M,Setiadi",Gate to Gate Life Cycle Assessment Coal Power Plant in Indonesia,,2020,,,333–338,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 3rd Asia Pacific Conference on Research in Industrial and Systems Engineering 2020,"Depok, Indonesia",2020,9781450376006,,https://doi.org/10.1145/3400934.3400995;http://dx.doi.org/10.1145/3400934.3400995,10.1145/3400934.3400995,"Global electricity is mainly supplied by coal as the main fuel, representing about 40%. Even the renewable energy portion is increasing in a developing country. Coal is still the majority as the main fuel of power plant because of abundant availability and low price that makes energy production cost becomes cheap. Besides its advantages, coal also contributes most of the emissions from the power generation sector. The International Energy Agency (IEA) states that in 2019 emissions of electricity sector contribute to 33% of the global sulfur dioxide (SO2), 14% of the nitrogen oxides (NOx), and 5% particulate matter 2.5 (PM2.5). Coal-fired power plants generate 75% of SO2, 70% of NOx, and over 90% of its PM2.5 emissions. The implementation of Life cycle assessment in this research contained in ISO-14040 and ISO-14044. The four LCA steps are goal and scope definition, life cycle inventory (LCI) analysis, life cycle impact assessment (LCIA), and interpretation. One of the typical LCA gate to gate LCA method is used to calculate the global warming potential and acidification potential with the parameter of ton CO2-eq/ GWh and ton-SO2 eq/ GWh. The object of this research is emphasized in the study on one of the biggest coal power plants in Indonesia with unit size 300 MW, which are using medium calory coal for its fuel. The result is the power plant global warming potential is 800-ton CO2 eq/ GWh and Acidification Potential (AP) is 0.6-ton SO2 eq/ GWh. The novelty in this research was to create a database of emissions per electricity produce from a coal power plant in Indonesia. From the database, people can clearly understand the condition of energy production of coal power plant in Indonesia and comparing with another coal power plant in the world.","GHG, Emissions, Coal, Power Plant, LCA",APCORISE 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Held RT,Banks MS",Misperceptions in Stereoscopic Displays: A Vision Science Perspective,,2008,,,23–32,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th Symposium on Applied Perception in Graphics and Visualization,"Los Angeles, California",2008,9781595939814,,https://doi.org/10.1145/1394281.1394285;http://dx.doi.org/10.1145/1394281.1394285,10.1145/1394281.1394285,"3d shape and scene layout are often misperceived when viewing stereoscopic displays. For example, viewing from the wrong distance alters an object's perceived size and shape. It is crucial to understand the causes of such misperceptions so one can determine the best approaches for minimizing them. The standard model of misperception is geometric. The retinal images are calculated by projecting from the stereo images to the viewer's eyes. Rays are back-projected from corresponding retinal-image points into space and the ray intersections are determined. The intersections yield the coordinates of the predicted percept. We develop the mathematics of this model. In many cases its predictions are close to what viewers perceive. There are three important cases, however, in which the model fails: 1) when the viewer's head is rotated about a vertical axis relative to the stereo display (yaw rotation); 2) when the head is rotated about a forward axis (roll rotation); 3) when there is a mismatch between the camera convergence and the way in which the stereo images are displayed. In these cases, most rays from corresponding retinal-image points do not intersect, so the standard model cannot provide an estimate for the 3d percept. Nonetheless, viewers in these situations have coherent 3d percepts, so the visual system must use another method to estimate 3d structure. We show that the non-intersecting rays generate vertical disparities in the retinal images that do not arise otherwise. Findings in vision science show that such disparities are crucial signals in the visual system's interpretation of stereo images. We show that a model that incorporates vertical disparities predicts the percepts associated with improper viewing of stereoscopic displays. Improving the model of misperceptions will aid the design and presentation of 3d displays.","virtual reality, 3D displays, visualization, depth perception",APGV '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Fang XS,Sheng QZ,Wang X,Zhang WE,Ngu AH,Yang J",From Appearance to Essence: Comparing Truth Discovery Methods without Using Ground Truth,ACM Trans. Intell. Syst. Technol.,2020,11,6,,Association for Computing Machinery,"New York, NY, USA",,,,2020-09,,2157-6904,https://doi.org/10.1145/3411749;http://dx.doi.org/10.1145/3411749,10.1145/3411749,"Truth discovery has been widely studied in recent years as a fundamental means for resolving the conflicts in multi-source data. Although many truth discovery methods have been proposed based on different considerations and intuitions, investigations show that no single method consistently outperforms the others. To select the right truth discovery method for a specific application scenario, it becomes essential to evaluate and compare the performance of different methods. A drawback of current research efforts is that they commonly assume the availability of certain ground truth for the evaluation of methods. However, the ground truth may be very limited or even impossible to obtain, rendering the evaluation biased. In this article, we present CompTruthHyp, a generic approach for comparing the performance of truth discovery methods without using ground truth. In particular, our approach calculates the probability of observations in a dataset based on the output of different methods. The probability is then ranked to reflect the performance of these methods. We review and compare 12 representative truth discovery methods and consider both single-valued and multi-valued objects. The empirical studies on both real-world and synthetic datasets demonstrate the effectiveness of our approach for comparing truth discovery methods.","multi-valued objects, Web search, sparse ground truth, single-valued objects, truth discovery methods, performance evaluation",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kumar A,Patel A,Dwivedy SK",Development of a NAO Humanoid Based Medical Assistant,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Advances in Robotics,"New Delhi, India",2017,9781450352949,,https://doi.org/10.1145/3132446.3134899;http://dx.doi.org/10.1145/3132446.3134899,10.1145/3132446.3134899,"In this paper1, socially assistive human-robot interaction has been explored on a NAO Humanoid Robot in order to automate the pharmacy and bio-medical sector, with a broader aim of addressing all similar tasks. The problem has been divided into three sub-segments viz. pick and place operation with smooth gripping mechanism, reading printed and handwritten text from prescriptions, and use of smart detection technology, with a focus on barcode detection to locate target objects (medicine flaps) in real time. Iterative Jacobian Pseudo inverse kinematics algorithm is implemented to calculate the joint angles. To account for the poor performance of Google Tesseract for handwritten text, the image contrast is enhanced for histogram equalization and fed to maximally stable extremal regions (MSER) algorithm in a combination with Stroke Width Transform (SWT) to make text detection more robust even in presence of blur, before feeding it to Tesseract. Lastly, two techniques are developed to incorporate barcode integration with NAO, first using ALBarcodeReader API, the limitations of which are solved using vertical descent sobel scharr operator to attain real time barcode scanning for all types of barcodes.","NAO Humanoid Robot, MSER, text detection, Barcode",AIR '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Huber B,Puffitsch W,Schoeberl M",WCET Driven Design Space Exploration of an Object Cache,,2010,,,26–35,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th International Workshop on Java Technologies for Real-Time and Embedded Systems,"Prague, Czech Republic",2010,9781450301220,,https://doi.org/10.1145/1850771.1850775;http://dx.doi.org/10.1145/1850771.1850775,10.1145/1850771.1850775,"In order to guarantee that real-time systems meet their timing specification, static execution time bounds need to be calculated. Not considering execution time predictability led to architectures which perform well in the average case, but require very pessimistic assumptions when bounding the worst-case execution time (WCET).Computer architecture design is driven by simulations of standard benchmarks estimating the expected average case performance. The design decisions derived from this design methodology do not necessarily result in a WCET analysis-friendly design. Aiming for a time-predictable computer architecture, we propose to employ WCET analysis techniques for the design space exploration of processor architectures. We exemplify this approach by a WCET driven design of a cache for heap allocated objects.Depending on the main memory properties (latency and bandwidth), different cache organizations result in the lowest WCET. The evaluation reveals that for certain cache configurations, the analyzed hit rate is comparable to the average case hit rate obtained by measurements. We believe that an early architecture exploration by means of static timing analysis techniques helps to identify configurations suitable for hard real-time systems.",,JTRES '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cao Z,Wang S,Forestier G,Puissant A,Eick CF",Analyzing the Composition of Cities Using Spatial Clustering,,2013,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd ACM SIGKDD International Workshop on Urban Computing,"Chicago, Illinois",2013,9781450323314,,https://doi.org/10.1145/2505821.2505827;http://dx.doi.org/10.1145/2505821.2505827,10.1145/2505821.2505827,"Cities all around the world are in constant evolution due to numerous factors, such as fast urbanization and new ways of communication and transportation. Since understanding the composition of cities is the key to intelligent urbanization, there is a growing need to develop urban computing and analysis tools to guide the orderly development of cities, as well as to enhance their smooth and beneficiary evolution. This paper presents a spatial clustering approach to discover interesting regions and regions which serve different functions in cities. Spatial clustering groups the objects in a spatial dataset and identifies contiguous regions in the space of the spatial attributes. We formally define the task of finding uniform regions in spatial data as a maximization problem of a plug-in measure of uniformity and introduce a prototype-based clustering algorithm named CLEVER to find such regions. Moreover, polygon models which capture the scope of a spatial cluster and histogram-style distribution signatures are used to annotate the content of a spatial cluster in the proposed methodology; they play a key role in summarizing the composition of a spatial dataset. Furthermore, algorithms for identifying popular distribution signatures and approaches for identifying regions which express a particular distribution signature will be presented. The proposed methodology is demonstrated and evaluated in a challenging real-world case study centering on analyzing the composition of the city of Strasbourg in France.","finding uniform regions in spatial datasets, region discovery, algorithms to discover the spatial structure of a city, spatial data mining, urban computing, spatial clustering",UrbComp '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jia T,Dong W",Research and Exploration on Quantitative Management of University Classes in the Age of Big Data,,2019,,,48–51,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 4th International Conference on Intelligent Information Processing,"China, China",2019,9781450361910,,https://doi.org/10.1145/3378065.3378075;http://dx.doi.org/10.1145/3378065.3378075,10.1145/3378065.3378075,"This paper analyses the problems existing in the class management of colleges and Universities under the current credit system model, and proposes to establish a quantitative management evaluation system suitable for colleges and universities by applying the quantitative management method, so as to help schools to evaluate objectively the quantitative management of students, classes and class teachers. Class quantitative management is to improve and update students and classes' information in real time through information system, and to establish class health index (CHI) and student health index (SHI) based on these data information, and then to calculate class management index (CMI) synthetically through SHI and CHI. Through the data of these three indexes, the evaluation objects are analyzed and evaluated. The purpose of evaluation is not only to evaluate, but also to guide the subject of evaluation to improve and develop in time according to the evaluation results. Therefore, the implementation links of the process management of the quantitative index system include: mobilizing and creating a quantitative management atmosphere, collecting real-time data, timely data analysis, guiding education, quantitative management evaluation and summary. The whole evaluation system pays more attention to the evaluation process than previous studies, and carries out empirical application research with the class as the data source.","Class Management, Quantitative Management, University",ICIIP 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sridhar M,Hamlen KW",Flexible In-Lined Reference Monitor Certification: Challenges and Future Directions,,2011,,,55–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th ACM Workshop on Programming Languages Meets Program Verification,"Austin, Texas, USA",2011,9781450304870,,https://doi.org/10.1145/1929529.1929537;http://dx.doi.org/10.1145/1929529.1929537,10.1145/1929529.1929537,"Over the last few years, in-lined reference monitors (IRM's) have gained much popularity as successful security enforcement mechanisms. Aspect-oriented programming (AOP) provides one elegant paradigm for implementing IRM frameworks. There is a foreseen need to enhance both AOP-style and non-AOP IRM's with static certification due to two main concerns. Firstly, the Trusted Computing Base (TCB) can grow large quickly in an AOP-style IRM framework. Secondly, in many practical settings, such as in the domain of web-security, aspectually encoded policy implementations and the rewriters that apply them to untrusted code are subject to frequent change. Replacing the rewriter with a small, light-weight, yet powerful certifier that is policy-independent and less subject to change addresses both these concerns.The goal of this paper is two-fold. First, interesting issues encountered in the process of building certification systems for IRM frameworks, such as policy specification, certifier soundness, and certifier completeness, are explored in the light of related work. In the second half of the paper, three prominent unsolved problems in the domain of IRM certification are examined: runtime code-generation via eval, IRM certification in the presence of concurrency, and formal verification of transparency. Promising directions suggested by recent work related to these problems are highlighted.","aspect-oriented programming, runtime verification, in-lined reference monitors, static verification",PLPV '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,van Lamsweerde A,Requirements Engineering: From Craft to Discipline,,2008,,,238–249,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th ACM SIGSOFT International Symposium on Foundations of Software Engineering,"Atlanta, Georgia",2008,9781595939951,,https://doi.org/10.1145/1453101.1453133;http://dx.doi.org/10.1145/1453101.1453133,10.1145/1453101.1453133,"Getting the right software requirements under the right environment assumptions is a critical precondition for developing the right software. This task is intrinsically difficult. We need to produce a complete, adequate, consistent, and well-structured set of measurable requirements and assumptions from incomplete, imprecise, and sparse material originating from multiple, often conflicting sources. The system we need to consider comprises software and environment components including people and devices.A rich system model may significantly help us in this task. Such model must integrate the intentional, structural, functional, and behavioral facets of the system being conceived. Rigorous techniques are needed for model construction, analysis, exploitation, and evolution. Such techniques should support early and incremental reasoning about partial models for a variety of purposes including satisfaction arguments, property checks, animations, the evaluation of alternative options, the analysis of risks, threats, and conflicts, and traceability management. The tension between technical precision and practical applicability calls for a suitable mix of heuristic, deductive, and inductive forms of reasoning on a suitable mix of declarative and operational specifications. Formal techniques should be deployed only when and where needed, and kept hidden wherever possible. The paper provides a retrospective account of our research efforts and practical experience along this route. Problem-oriented abstractions, analyzable models, and constructive techniques were permanent concerns.","problem modeling, formal derivation, goal orientation, responsibility assignment, specification construction, lightweight analysis, system design, operationalization, requirements engineering",SIGSOFT '08/FSE-16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Carra E,Santoni C,Pellacini F",GMotion: A Spatio-Temporal Grammar for the Procedural Generation of Motion Graphics,,2018,,,100–107,Canadian Human-Computer Communications Society,"Waterloo, CAN",,Proceedings of the 44th Graphics Interface Conference,"Toronto, Canada",2018,9780994786838,,https://doi.org/10.20380/GI2018.14;http://dx.doi.org/10.20380/GI2018.14,10.20380/GI2018.14,"Creating by hand compelling 2D animations that choreograph several groups of shapes requires a large number of manual edits. We present a method to procedurally generate motion graphics with timeslice grammars. Timeslice grammars are to time what split grammars are to space. We use this grammar to formally model motion graphics, manipulating them in both temporal and spatial components. We are able to combine both these aspects by representing animations as sets of affine transformations sampled uniformly in both space and time. Rules and operators in the grammar manipulate all spatio-temporal matrices as a whole, allowing us to expressively construct animation with few rules. The grammar animates shapes, which are represented as highly tessellated polygons, by applying the affine transforms to each shape vertex given the vertex position and the animation time. We introduce a small set of operators showing how we can produce 2D animations of geometric objects, by combining the expressive power of the grammar model, the composability of the operators with themselves, and the capabilities that derive from using a unified spatio-temporal representation for animation data. Throughout the paper, we show how timeslice grammars can produce a wide variety of animations that would take artists hours of tedious and time-consuming work. In particular, in cases where change of shapes is very common, our grammar can add motion detail to large collections of shapes with greater control over per-shape animations along with a compact rules structure.",,GI '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang Z,Bu J,Ester M,Li Z,Yao C,Yu Z,Wang C",H2MN: Graph Similarity Learning with Hierarchical Hypergraph Matching Networks,,2021,,,2274–2284,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining,"Virtual Event, Singapore",2021,9781450383325,,https://doi.org/10.1145/3447548.3467328;http://dx.doi.org/10.1145/3447548.3467328,10.1145/3447548.3467328,"Graph similarity learning, which measures the similarities between a pair of graph-structured objects, lies at the core of various machine learning tasks such as graph classification, similarity search, etc. In this paper, we devise a novel graph neural network based framework to address this challenging problem, motivated by its great success in graph representation learning. As the vast majority of existing graph neural network models mainly concentrate on learning effective node or graph level representations of a single graph, little effort has been made to jointly reason over a pair of graph-structured inputs for graph similarity learning. To this end, we propose Hierarchical Hypergraph Matching Networks (H2sup>MN) to calculate the similarities between graph pairs with arbitrary structure. Specifically, our proposed H2MN learns graph representation from the perspective of hypergraph, and takes each hyperedge as a subgraph to perform subgraph matching, which could capture the rich substructure similarities across the graph. To enable hierarchical graph representation and fast similarity computation, we further propose a hyperedge pooling operator to transform each graph into a coarse graph of reduced size. Then, a multi-perspective cross-graph matching layer is employed on the coarsened graph pairs to extract the inter-graph similarity. Comprehensive experiments on five public datasets empirically demonstrate that our proposed model can outperform state-of-the-art baselines with different gains for graph-graph classification and regression tasks.","hypergraphs, graph neural networks, graph similarity learning",KDD '21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Sakurai K,Dobashi Y,Iwasaki K,Nishita T",Fabricating Reflectors for Displaying Multiple Images,ACM Trans. Graph.,2018,37,4,,Association for Computing Machinery,"New York, NY, USA",,,,2018-07,,0730-0301,https://doi.org/10.1145/3197517.3201400;http://dx.doi.org/10.1145/3197517.3201400,10.1145/3197517.3201400,"A great deal of attention has been devoted to the fabrication of reflectors that can display different color images when viewed from different directions not only in industry but also for the arts. Although such reflectors have previously been successfully fabricated, the number of images displayed has been limited to two or they suffer from ghosting artifacts where mixed images appear. Furthermore, the previous methods need special hardware and/or materials to fabricate the reflectors. Thus, those techniques are not suitable for printing reflectors on everyday personal objects made of different materials, such as name cards, letter sheets, envelopes, and plastic cases. To overcome these limitations, we propose a method for fabricating reflectors using a standard ultraviolet printer (UV printer). UV printer can render a specified 2D color pattern on an arbitrary material and by overprinting the printed pattern can be raised, that is, the printed pattern becomes a microstructure having color and height. We propose using these micro structures to formulate a method for designing spatially varying reflections that can display different target images when viewed from different directions. The microstructure is calculated by minimizing an objective function that measures the differences between the intensities of the light reflected from the reflector and that of the target image. We show several fabricated reflectors to demonstrate the usefulness of the proposed method.","spatially varying anisotropic BRDF, digital fabrication, ultraviolet printer, reflector",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang Y,Xu J,Xu M,Zheng N,Jiang J,Kong K",A Feature-Based Method for Traffic Anomaly Detection,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2nd ACM SIGSPATIAL Workshop on Smart Cities and Urban Analytics,"Burlingame, California",2016,9781450345835,,https://doi.org/10.1145/3007540.3007545;http://dx.doi.org/10.1145/3007540.3007545,10.1145/3007540.3007545,"The wide spread use of GPS-enabled devices facilitates us to sense the movement of vehicles. Detecting anomalous movement behavior on road segments can benefit both drivers and transportation authorities. An important challenge behind this is how to detect these anomalies effectively and timely under large scale of raw GPS trajectories. In this light, we propose a Feature-Based method for Traffic Anomaly Detection (FBTAD). A key observation is that road segments, where these incidents turns up, tend to have their vehicle flow features changed in a short period of time. For example, a traffic accident may immediately and significantly slow down the travel speed on a road segment. In this paper, we first map-match raw trajectories. Then we calculate the road segments' traffic features in each time slot, e.g., 10 minutes, and introduce an offline spatial-temporal index for speeding up the anomaly detection process. Finally, we retrieve anomaly candidates by checking the road segment's traffic flow acceleration based on the index built above, and examine candidates' density change ratio or moving objects' outflow ratio to further infer traffic anomalies. The effectiveness and efficiency of our approach is validated by extensive experimentation. Our evaluations show that the method proposed in this paper is able to detect traffic anomalies more efficiently as well as earlier than the baseline method.","vehicle flow features, traffic anomaly, city dynamics",UrbanGIS '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Kang K,Image-Time Correlation and Its Applications,,2017,,,98–101,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 6th International Conference on Informatics, Environment, Energy and Applications","Jeju, Republic of Korea",2017,9781450352307,,https://doi.org/10.1145/3070617.3070636;http://dx.doi.org/10.1145/3070617.3070636,10.1145/3070617.3070636,"In this paper, Image-time correlation is a beneficial technique to apply various applications of dynamical events, where temporal changes of positions of particles (or objects) can be quantified, constructed by the collection of time-resolved video data. With the fast development of camera technologies and imaging softwares, the optimization of time-binning and spatial-resolution are much friendly-used for the imaging analysis. Time-dependent different regions of interest (ROIs) can be chosen, such that the time resolution of subsequent images should be at least 10 times faster than the actual dynamical events. Then time-correlation function will be calculated by the 2d intensity-intensity correlation of an each pixel-pixel of individual time frame of image, and the initial slope of correlation function gives a characteristic time scale that measures the average magnitude of particle velocities within the field-of-view. The advantage of image-time correlation is easy to implement as compared to the PIV (particle imaging velocimetry). In this short proceeding, the performance of image-time correlation is highlighted through a number of applications; such as the slowing down behaviors of collective dynamics of orientation textures, dimer-oscillations in rod-networks, and clay (platelet) migrations in an oil-water droplet. In each system, the interpretation of image-time correlation is addressed, based on the experimental observations.","field-induced criticality, dimer-oscillations in rod-networks, decay rates, clay migrations in an oil-water droplet, collective dynamics, Image-time correlation, reconstruction of time-lapsed image",IEEA '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kempke B,Pannuto P,Dutta P","Harmonium: Asymmetric, Bandstitched UWB for Fast, Accurate, and Robust Indoor Localization",,2016,,,,IEEE Press,"Vienna, Austria",,Proceedings of the 15th International Conference on Information Processing in Sensor Networks,,2016,9781509008025,,,,"We introduce Harmonium, a novel ultra-wideband RF localization architecture that achieves decimeter-scale accuracy indoors. Harmonium strikes a balance between tag simplicity and processing complexity to provide fast and accurate indoor location estimates. Harmonium uses only commodity components and consists of a small, inexpensive, lightweight, and FCC-compliant ultra-wideband transmitter or tag, fixed infrastructure anchors with known locations, and centralized processing that calculates the tag's position. Anchors employ a new frequency-stepped narrowband receiver architecture that rejects narrowband interferers and extracts high-resolution timing information without the cost or complexity of traditional ultra-wideband approaches. In a complex indoor environment, 90% of position estimates obtained with Harmonium exhibit less than 31 cm of error with an average 9 cm of inter-sample noise. In non-line-of-sight conditions (i.e. through-wall), 90% of position error is less than 42 cm. The tag draws 75mW when actively transmitting, or 3.9 mJ per location fix at the 19 Hz update rate. Tags weigh 3 g and cost $4.50 USD at modest volumes. Harmonium introduces a new design point for indoor localization and enables localization of small, fast objects such as micro quadrotors, devices previously restricted to expensive optical motion capture systems.",,IPSN '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Truong QC,Truong AT,Dang TK",Privacy Preserving through a Memorizing Algorithm in Location-Based Services,,2009,,,146–153,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Conference on Advances in Mobile Computing and Multimedia,"Kuala Lumpur, Malaysia",2009,9781605586595,,https://doi.org/10.1145/1821748.1821780;http://dx.doi.org/10.1145/1821748.1821780,10.1145/1821748.1821780,"Along with the rapid development of mobile devices having embedded positioning technology, location-based services have become more and more popular. In order to use the services, users often disclose some parts of their private information, especially their location-related information. Thus, it raises a great concern in the users' privacy preserving in location-based services. This paper proposes a solution with a memorizing algorithm working on a trusted middleware. With the proposed solution, the space is organized in a flexible grid and the middleware cloaks the user's location information in an anonymization area before sending it to the service providers. A concerned problem is that overlapped areas among anonymization areas can be used to explore the true position of a user because the overlapped areas have a higher probability of having a user. Our newly introduced memorizing algorithm calculates on the spatial grid to decrease the overlapped areas as much as possible. The solution aims at protecting the user's privacy not only at the time using the service but also against data mining techniques wrt. their history location data. Experimental results with synthesis moving objects over real world maps will establish our theoretical analyses as well as the practical value of the proposed solution.","location privacy, memorizing algorithm, location-based services, legal aspects, privacy preserving, privacy preserving in data mining",MoMM '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Iwasaki Y,Oh J,Handa T,Sereidi AA,Vimolmongkolporn V,Kato F,Iwata H",Experiment Assisting System with Local Augmented Body (EASY-LAB) for Subject Experiments under the COVID-19 Pandemic,,2021,,,,Association for Computing Machinery,"New York, NY, USA",,ACM SIGGRAPH 2021 Emerging Technologies,"Virtual Event, USA",2021,9781450383646,,https://doi.org/10.1145/3450550.3465345;http://dx.doi.org/10.1145/3450550.3465345,10.1145/3450550.3465345,"Since it is challenging to perceive space and objects with a video conferencing system, which communicates using only video and audio, there are difficulties in testing subjects in the COVID-19 pandemic. We propose the EASY-LAB system that allows an experimenter to perform observation and physical interaction with the subject even from a remote location actively. The proposed system displays the camera image on a HMD worn by the experimenter, which camera is mounted on a small 6 DOF robot arm end, allowing observation from an easy-to-see perspective. The experimenter can also instruct the subject using another robot arm with a laser pointer. The robot’s joint angles are calculated by Inverse Kinematics from the experimenter’s head movements, then reflected in the actual robot. Photon Unity Networking component was used for the synchronization process with remote locations. These devices are affordable, effortless to set up, and can be delivered to the subject’s home. Finally, the proposed system was evaluated by four subjects, As a preliminary result, the mean pointing error was 1.1 cm, and the operation time was reduced by 60% compared with the conventional video conferencing system. This result indicated the EASY-LAB’s capability, at least in tasks that require pointing and observation from various angles. The statistical study with more subjects will be conducted in the follow-up study.","Interaction, telepresence, telecommuting work, telexistence, UI/Tools",SIGGRAPH '21,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jin D,Zhang A,Wu J,Wu G,Wang H,Fang L",All-in-Depth via Cross-Baseline Light Field Camera,,2020,,,3559–3567,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 28th ACM International Conference on Multimedia,"Seattle, WA, USA",2020,9781450379885,,https://doi.org/10.1145/3394171.3413974;http://dx.doi.org/10.1145/3394171.3413974,10.1145/3394171.3413974,"Light-field (LF) camera holds great promise for passive/general depth estimation benefited from high angular resolution, yet suffering small baseline for distanced region. While stereo solution with large baseline is superior to handle distant scenarios, the problem of limited angular resolution becomes bothering for near objects. Aiming for all-in-depth solution, we propose a cross-baseline LF camera using a commercial LF camera and a monocular camera, which naturally form a 'stereo camera' enabling compensated baseline for LF camera. The idea is simple yet non-trivial, due to the significant angular resolution gap and baseline gap between LF and stereo cameras.Fusing two depth maps from LF and stereo modules in spatial domain is fluky, which relies on the imprecisely predicted depth to distinguish close or distance range, and determine the weights for fusion. Alternatively, taking the unified representation for both LF and monocular sub-aperture view in epipolar plane image (EPI) domain, we show that for each pixel, the minimum variance along different shearing degrees in EPI domain estimates its depth with the highest fidelity. By minimizing the minimum variance, the depth error is minimized accordingly. The insight is that the calculated minimum variance in EPI domain owns higher fidelity than the predicted depth in spatial domain. Extensive experiments demonstrate the superiority of our cross-baseline LF camera in providing high-quality all-in-depth map from 0.2m to 100m.","EPI domain, light field, cross-baseline, depth map",MM '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Pannuto P,Kempke B,Chuo LX,Blaauw D,Dutta P","Harmonium: Ultra Wideband Pulse Generation with Bandstitched Recovery for Fast, Accurate, and Robust Indoor Localization",ACM Trans. Sen. Netw.,2018,14,2,,Association for Computing Machinery,"New York, NY, USA",,,,2018-06,,1550-4859,https://doi.org/10.1145/3185752;http://dx.doi.org/10.1145/3185752,10.1145/3185752,"We introduce Harmonium, a novel ultra wideband (UWB) RF localization architecture that achieves decimeter-scale accuracy indoors. Harmonium strikes a balance between tag simplicity and processing complexity to provide fast and accurate indoor location estimates. Harmonium uses only commodity components and consists of a small, inexpensive, lightweight, and FCC-compliant UWB transmitter or tag, fixed infrastructure anchors with known locations, and centralized processing that calculates the tag’s position. Anchors employ a new frequency-stepped narrowband receiver architecture that rejects narrowband interferers and extracts high-resolution timing information without the cost or complexity of traditional UWB approaches. In a complex indoor environment, 90% of position estimates obtained with Harmonium exhibit less than 31 cm of error with an average of 9 cm of inter-sample noise. In non-line-of-sight conditions (i.e., through-wall), 90% of position error is less than 42 cm. The tag draws 75 mW when actively transmitting, or 3.9 mJ per location fix at the 19 Hz update rate. Tags weigh 3 g and cost $4.50 USD at modest volumes. Furthermore, VLSI-based design concepts are identified for a simple, low-power realization of the Harmonium tag to offer a roadmap for the realization of Harmonium concepts in future integrated systems. Harmonium introduces a new design point for indoor localization and enables localization of small, fast objects such as micro quadrotors, devices previously restricted to expensive optical motion capture systems.","Ultra wideband, low-power, indoor localization, bandstitching",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Xue T,Luo H,Cheng D,Yuan Z,Yang X",Real-Time Monocular Dense Mapping for Augmented Reality,,2017,,,510–518,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 25th ACM International Conference on Multimedia,"Mountain View, California, USA",2017,9781450349062,,https://doi.org/10.1145/3123266.3123348;http://dx.doi.org/10.1145/3123266.3123348,10.1145/3123266.3123348,"Monocular simultaneous localization and mapping (SLAM) is a key enabling technique for many augmented reality (AR) applications. However, conventional methods for monocular SLAM can obtain only sparse or semi-dense maps in highly-textured image areas. Poorly-textured regions which widely exist in indoor and man-made urban environments can be hardly reconstructed, impeding interactions between virtual objects and real scenes in AR apps. In this paper,we present a novel method for real-time monocular dense mapping based on the piecewise planarity assumption for poorly textured regions. Specifically, a semi-dense map for highly-textured regions is first calculated by pixel matching and triangulation [6, 7]. Large textureless regions extracted by Maximally Stable Color Regions (MSCR) [11], which is a homogeneous-color region detector, are approximated using piecewise planar models which are estimated by the corresponding semi-dense 3D points and the proposed multi-plane segmentation algorithm. Plane models associated with the same 3D area across multiple overlapping views are linked and fused to ensure a consistent and accurate 3D reconstruction. Experimental results on two public datasets [15, 23] demonstrate that our method is 2.3X 2.9X faster than the state-of-the-art method DPPTAM [2], and meanwhile achieves better reconstruction accuracy and completeness. We also apply our method to a real AR application and live experiments with a hand-held camera demonstrate the effectiveness and efficiency of our method in practical scenario.","monocular dense mapping, multiplane segmentation, augmented reality, plane model",MM '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Dutta D,Chowdhury AR,Bhattacharya U,Parui SK",Lightweight User-Adaptive Handwriting Recognizer for Resource Constrained Handheld Devices,,2012,,,114–119,Association for Computing Machinery,"New York, NY, USA",,Proceeding of the Workshop on Document Analysis and Recognition,"Mumbai, India",2012,9781450317979,,https://doi.org/10.1145/2432553.2432574;http://dx.doi.org/10.1145/2432553.2432574,10.1145/2432553.2432574,"Here, we present our recent attempt to develop a lightweight handwriting recognizer suitable for resource constrained handheld devices. Such an application requires real-time recognition of handwritten characters produced on their touchscreens. The proposed approach is well suited for minimal user-lag on devices having only limited computing power in sharp contrast to standard laptops or desktop computers. Moreover, the approach is user-adaptive in the sense that it can adapt through user corrections to wrong predictions. With an increasing number of interactive corrections by the user, the recognition accuracy improves significantly. An input stroke is first re-sampled generating a fixed small number of sample points such that at most two critical points (points corresponding to high curvature) are preserved. We use their x- and y-coordinates as the feature vector and do not compute any other high-level feature vector. The squared Mahalanobis distance is used to identify each stroke of the input sample as one of several stroke categories pre-determined based on a large pool of training samples. The inverted covariance matrix and mean vector for a stroke class that are required for computing the Mahalanobis distance are pre-calculated and stored as Serialized Objects on the SD card of the device. A Look-Up Table (LUT) of stroke combinations as keys and corresponding character class as values is used for the final Unicode character output. In case of an incorrect character output, user corrections are used to automatically update the LUT adapting to the user's particular handwriting style.","handwriting recognition, user adaptation, handheld device",DAR '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Bradford RB,Implementation Techniques for Large-Scale Latent Semantic Indexing Applications,,2011,,,339–344,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 20th ACM International Conference on Information and Knowledge Management,"Glasgow, Scotland, UK",2011,9781450307178,,https://doi.org/10.1145/2063576.2063630;http://dx.doi.org/10.1145/2063576.2063630,10.1145/2063576.2063630,"The technique of latent semantic indexing (LSI) has wide applicability in information retrieval and data mining tasks. To date, however, most applications of LSI have addressed relatively small collections of data. This has been due partly to hardware and software limitations and partly to overly pessimistic estimates of the processing requirements of the singular value decomposition (SVD) process. In recent years, advances in hardware capabilities and software implementations have enabled much larger LSI applications. Moreover, experience with large LSI indexes has shown that the SVD is not the limitation on scalability that it was long thought to be. This paper describes techniques applicable to creating large-scale (multi-million document) LSI indexes. Detailed data regarding the LSI index creation process is presented for collections of up to 100 million documents. Four key factors are shown to contribute to the scalability of LSI. First, in most situations, the time required for calculation of the singular value decomposition (SVD) of the term-document matrix is not the dominant factor determining the overall time required to build an LSI index. Second, the time required to calculate the SVD in LSI is linear in the number of objects indexed. Third, incremental index creation greatly facilitates use of LSI in dynamic environments. Fourth, distributed query processing can be employed to support large numbers of users. It is shown that LSI is well-suited for implementation in modern distributed computing environments. This paper provides the first measurements of the execution time for large-scale LSI build processes in a cloud environment.","SVD, latent semantic indexing, cloud computing, LSI, large-scale applications, scaling",CIKM '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wang SS,Tsai PH,Li WS",Logo Recognition for Image-Based Indoor Positioning Systems on Mobile Devices,,2015,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the ASE BigData & SocialInformatics 2015,"Kaohsiung, Taiwan",2015,9781450337359,,https://doi.org/10.1145/2818869.2818930;http://dx.doi.org/10.1145/2818869.2818930,10.1145/2818869.2818930,"Image recognition techniques have been widely used in positioning systems in recent years. By recognizing the objects targeted by users' camera, one can decide the users' location. In this paper, a mobile indoor positioning system based on the image recognition techniques is implemented for shopping malls. We recognize the stores by their logos, and then use the location of the stores to locate the users. The image recognition method includes extracting local features from the image, calculating the Bag-of-Word structure through a pre-trained hierarchical clustering tree, and using cosine similarity to make the comparison between the training images and the query images. Though SIFT and SURF are the most extensively used local feature detectors and descriptors in the field, the limitations of mobile devices make them infeasible due to their high computational complexity. Moreover, both SIFT and SURF are patent-protected and are not free modules in OpenCV4Android, which will cause additional cost. Therefore, in this paper, we attempt to adopt features that exclude SIFT and SURF. By analyzing the precision and speed of pairwise mashup of feature detectors and descriptors, we target to find the most suitable pair of algorithms to be used on mobile devices. In this paper, the Global Mall at Hsinchu, Taiwan, is used as a scenario for the actual test.","Indoor Positioning, Logo Recognition, Mobile Devices, Feature Extraction",ASE BD&SI '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liu B,Zhang T,Han FX,Niu D,Lai K,Xu Y",Matching Natural Language Sentences with Hierarchical Sentence Factorization,,2018,,,1237–1246,International World Wide Web Conferences Steering Committee,"Republic and Canton of Geneva, CHE",,Proceedings of the 2018 World Wide Web Conference,"Lyon, France",2018,9781450356398,,https://doi.org/10.1145/3178876.3186022;http://dx.doi.org/10.1145/3178876.3186022,10.1145/3178876.3186022,"Semantic matching of natural language sentences or identifying the relationship between two sentences is a core research problem underlying many natural language tasks. Depending on whether training data is available, prior research has proposed both unsupervised distance-based schemes and supervised deep learning schemes for sentence matching. However, previous approaches either omit or fail to fully utilize the ordered, hierarchical, and flexible structures of language objects, as well as the interactions between them. In this paper, we propose Hierarchical Sentence Factorization---a technique to factorize a sentence into a hierarchical representation, with the components at each different scale reordered into a \predicate-argument\"" form. The proposed sentence factorization technique leads to the invention of: 1) a new unsupervised distance metric which calculates the semantic distance between a pair of text snippets by solving a penalized optimal transport problem while preserving the logical relationship of words in the reordered sentences",and 2) new multi-scale deep learning models for supervised semantic training,based on factorized sentence hierarchies. We apply our techniques to text-pair similarity estimation and text-pair relationship classification tasks,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Sutton SM,Concepts in the Definition of an Enterprise Development Process,,2011,,,223–227,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 International Conference on Software and Systems Process,"Waikiki, Honolulu, HI, USA",2011,9781450307307,,https://doi.org/10.1145/1987875.1987914;http://dx.doi.org/10.1145/1987875.1987914,10.1145/1987875.1987914,"Integrated Product Development - IPD - is an enterprise-wide process used by IBM to develop technology products including hardware, software, and services. IPD has been in use at IBM for over a decade and has been very effective at increasing efficiency and reducing costs across the whole product life cycle. Within IBM Software Group, IPD at the top level is defined informally through natural-language documents, ad hoc diagrams, and a database of well-defined deliverables. Some key concepts in the SWG IPD definition include a clear statement of the principles on which the process is based, widespread references to business goals, frequent use of governance-oriented formulations, a clearly defined structure for the high levels of the process, a relative lack of concern about lower levels of the process structure, and an emphasis on the characterization of participant roles. The relative lack of formal and semantic rigor in the SWG IPD definition might seem to open the door to a number of problems in process specification and execution. However, this seems to have allowed the process definers to focus on those aspects of the process that are most important and to present those in a natural way. In the context of an organization that is dedicated to the success of the process, this has been an effective approach.","governance, ipd, process definition, process modeling, integrated product development",ICSSP '11,based on multiple datasets such as STSbenchmark,the Microsoft Research paraphrase identification (MSRP) dataset,the SICK dataset,"etc. Extensive experiments show that the proposed hierarchical sentence factorization can be used to significantly improve the performance of existing unsupervised distance-based metrics as well as multiple supervised deep learning models based on the convolutional neural network (CNN) and long short-term memory (LSTM).""","semantic matching, ordered word mover's distance, hierarchical sentence factorization, abstract meaning representation, sentence reordering",WWW '18,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang Y,Boncz P",XRPC: Interoperable and Efficient Distributed XQuery,,2007,,,99–110,VLDB Endowment,"Vienna, Austria",,Proceedings of the 33rd International Conference on Very Large Data Bases,,2007,9781595936493,,,,"We propose XRPC, a minimal XQuery extension that enables distributed yet efficient querying of heterogeneous XQuery data sources. XRPC enhances the existing concept of XQuery functions with the Remote Procedure Call (RPC) paradigm. By calling out of an XQuery for-loop to multiple destinations, and by calling functions that themselves perform XRPC calls, complex P2P communication patterns can be achieved. The XRPC extension is orthogonal to all XQuery features, including the XQuery Update Facility (XQUF). We provide formal semantics for XRPC that encompasses execution of both read-only and update queries.XRPC is also a network SOAP sub-protocol, that integrates seamlessly with web services and Service Oriented Architectures (SOA), and AJAX-based GUIs. A crucial feature of the protocol is bulk RPC, that allows remote execution of many different calls to the same procedure, using possibly a single network round-trip. The efficiency potential of XRPC is demonstrated via an open-source implementation in MonetDB/XQuery. We show, however, that XRPC is not system-specific: every XQuery data source can service XRPC calls using a wrapper.Since XQuery is a pure functional language, we can leverage techniques developed for functional query decomposition to rewrite data shipping queries into XRPC-based function shipping queries. Powerful distributed database techniques (such as semi-join optimizations) directly map on bulk RPC, opening up interesting future work opportunities.",,VLDB '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Anisetti M,Ardagna CA,Damiani E,Saonara F",A Test-Based Security Certification Scheme for Web Services,ACM Trans. Web,2013,7,2,,Association for Computing Machinery,"New York, NY, USA",,,,2013-05,,1559-1131,https://doi.org/10.1145/2460383.2460384;http://dx.doi.org/10.1145/2460383.2460384,10.1145/2460383.2460384,"The Service-Oriented Architecture (SOA) paradigm is giving rise to a new generation of applications built by dynamically composing loosely coupled autonomous services. Clients (i.e., software agents acting on behalf of human users or service providers) implementing such complex applications typically search and integrate services on the basis of their functional requirements and of their trust in the service suppliers. A major issue in this scenario relates to the definition of an assurance technique allowing clients to select services on the basis of their nonfunctional requirements and increasing their confidence that the selected services will satisfy such requirements. In this article, we first present an assurance solution that focuses on security and supports a test-based security certification scheme for Web services. The certification scheme is driven by the security properties to be certified and relies upon a formal definition of the service model. The evidence supporting a certified property is computed using a model-based testing approach that, starting from the service model, automatically generates the test cases to be used in the service certification. We also define a set of indexes and metrics that evaluate the assurance level and the quality of the certification process. Finally, we present our evaluation toolkit and experimental results obtained applying our certification solution to a financial service implementing the Interactive Financial eXchange (IFX) standard.","service-oriented architecture, web services, Model-based testing, symbolic transition systems, security certification",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kapron BM,Steinberg F",Type-Two Polynomial-Time and Restricted Lookahead,,2018,,,579–588,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 33rd Annual ACM/IEEE Symposium on Logic in Computer Science,"Oxford, United Kingdom",2018,9781450355834,,https://doi.org/10.1145/3209108.3209124;http://dx.doi.org/10.1145/3209108.3209124,10.1145/3209108.3209124,"This paper provides an alternate characterization of second-order polynomial-time computability, with the goal of making second-order complexity theory more approachable. We rely on the usual oracle machines to model programs with subroutine calls. In contrast to previous results, the use of higher-order objects as running times is avoided, either explicitly or implicitly. Instead, regular polynomials are used. This is achieved by refining the notion of oracle-poly-time computability introduced by Cook. We impose a further restriction on oracle interactions to force feasibility. Both the restriction and its purpose are very simple: it is well-known that Cook's model allows polynomial depth iteration of functional inputs with no restrictions on size, and thus does not preserve poly-time computability. To mend this we restrict the number of lookahead revisions, that is the number of times a query whose size exceeds that of any previous query may be asked. We prove that this leads to a class of feasible functionals and that all feasible problems can be solved within this class if one is allowed to separate a task into efficiently solvable subtasks. Formally, the closure of our class under lambda-abstraction and application are the basic feasible functionals. We also revisit the very similar class of strongly poly-time computable operators previously introduced by Kawamura and Steinberg. We prove it to be strictly included in our class and, somewhat surprisingly, to have the same closure property. This is due to the nature of the limited recursion operator: it is not strongly poly-time but decomposes into two such operations and lies in our class.","oracle Turing machines, applied lambda-calculus, feasibility of functionals, higher-order computability",LICS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ramirez AJ,Cheng BH",Design Patterns for Developing Dynamically Adaptive Systems,,2010,,,49–58,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2010 ICSE Workshop on Software Engineering for Adaptive and Self-Managing Systems,"Cape Town, South Africa",2010,9781605589718,,https://doi.org/10.1145/1808984.1808990;http://dx.doi.org/10.1145/1808984.1808990,10.1145/1808984.1808990,"Increasingly, software systems should self-adapt to satisfy new requirements and environmental conditions that may arise after deployment. Due to their high complexity, adaptive programs are difficult to specify, design, verify, and validate. Moreover, the current lack of reusable design expertise that can be leveraged from one adaptive system to another further exacerbates the problem. We studied over thirty adaptation-related research and project implementations available from the literature and open sources to harvest adaptation-oriented design patterns that support the development of adaptive systems. These adaptation-oriented patterns facilitate the separate development of the functional and adaptive logic. In order to support the assurance of adaptive systems, each design pattern includes templates that formally specify invariant properties of adaptive systems. To demonstrate their usefulness, we have applied a subset of our adaptation-oriented patterns to the design and implementation of ZAP.com, an adaptive news web server.","design patterns, adaptive systems, autonomic systems",SEAMS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Elstermann M,Proposal for Using Semantic Technologies as a Means to Store and Exchange Subject-Oriented Process Models,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th Conference on Subject-Oriented Business Process Management,"Darmstadt, Germany",2017,9781450348621,,https://doi.org/10.1145/3040565.3040573;http://dx.doi.org/10.1145/3040565.3040573,10.1145/3040565.3040573,"This article re-investigates the idea of using the semantic-web-technologies for formally describing subject-oriented process models. It proposes improvements to previous knowledge models for subject-oriented process description and discusses why process models should directly be described in the web-ontology language, instead of only using it as secondary meta concept with the overall goal to enable interoperability between various S-BPM tools.","subject-oriented process models, OWL, ontologies, PASS",S-BPM ONE '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Albo Y,Lanir J,Bak P,Rafaeli S",Static vs. Dynamic Time Mapping in Radial Composite Indicator Visualization,,2016,,,264–271,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Working Conference on Advanced Visual Interfaces,"Bari, Italy",2016,9781450341318,,https://doi.org/10.1145/2909132.2909250;http://dx.doi.org/10.1145/2909132.2909250,10.1145/2909132.2909250,"Composite Indicators (CIs), are a common measurement and benchmarking tool that are used to reflect and measure multidimensional concepts such as digital divides, individual's well-being and more. Measurement iterations produce a series of time-oriented data, which stakeholders as well as the general public might be interested to interpret. Visualization of a CI is highly recommended in order to ease interpretation, and many CI websites use radial solutions to visualize CIs. Yet it is unclear how to visualize the temporal dynamics in radial diagrams. Static solutions, mapping time to small multiples might be challenging due to screen space issues. Dynamic solutions are appealing, yet, there is no clear empirical evidence on benefits of dynamic time coding in radial diagrams. In this paper, we compare static vs. dynamic time mapping using two radial CI visualization methods. The popular Radar chart technique is compared to the innovative Flower chart as used in the well-known OECD Better Life index. We compare users' performance and preferences empirically under formal task taxonomy, adjusted to CI tasks. Results indicate that in general, static time encoding was more effective than dynamic encoding. Still, an in depth analysis showed that the dynamic approach is a feasible and sometimes even better solution for important CIs tasks, leveraged by the fact that users seem to like and enjoy it.","small multiples, Animation, evaluation, information visualization, composite indicators",AVI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Belt J,Hatcliff J,Robby,Chalin P,Hardin D,Deng X",Enhancing Spark's Contract Checking Facilities Using Symbolic Execution,,2011,,,47–60,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2011 ACM Annual International Conference on Special Interest Group on the Ada Programming Language,"Denver, Colorado, USA",2011,9781450310284,,https://doi.org/10.1145/2070337.2070357;http://dx.doi.org/10.1145/2070337.2070357,10.1145/2070337.2070357,"Spark, a subset of Ada for engineering safety and security-critical systems, is one of the best commercially available frameworks for formal-methods-supported development of critical software. Spark is designed for verification and includes a software contract language for specifying functional properties of procedures. Even though Spark and its static analysis components are beneficial and easy to use, its contract language is rarely used for stating properties beyond simple constraints on scalar values due to the burdens the associated tool support imposes on developers. Symbolic execution (SymExe) techniques have made significant strides in automating reasoning about deep semantic properties of source code. However, most work on SymExe has focused on bug-finding and test case generation as opposed to tasks that are more verification-oriented such as contract checking. In previous work we have presented: (a) SymExe techniques for checking software contracts in embedded critical systems, and (b) Bakar Kiasan, a tool that implements these techniques in an integrated development environment for Spark. In this paper, we give a detailed walk-through of Bakar Kiasan as it is applied to an industrial code base for an embedded security device. We illustrate how Bakar Kiasan provides significant increases in automation, usability, and functionality over existing Spark contract checking tools, and we present results from performance evaluations of its application to industrial examples.","symbolic execution, program analysis, spark",SIGAda '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Belt J,Hatcliff J,Robby,Chalin P,Hardin D,Deng X",Enhancing Spark's Contract Checking Facilities Using Symbolic Execution,Ada Lett.,2011,31,3,47–60,Association for Computing Machinery,"New York, NY, USA",,,,2011-11,,1094-3641,https://doi.org/10.1145/2070336.2070357;http://dx.doi.org/10.1145/2070336.2070357,10.1145/2070336.2070357,"Spark, a subset of Ada for engineering safety and security-critical systems, is one of the best commercially available frameworks for formal-methods-supported development of critical software. Spark is designed for verification and includes a software contract language for specifying functional properties of procedures. Even though Spark and its static analysis components are beneficial and easy to use, its contract language is rarely used for stating properties beyond simple constraints on scalar values due to the burdens the associated tool support imposes on developers. Symbolic execution (SymExe) techniques have made significant strides in automating reasoning about deep semantic properties of source code. However, most work on SymExe has focused on bug-finding and test case generation as opposed to tasks that are more verification-oriented such as contract checking. In previous work we have presented: (a) SymExe techniques for checking software contracts in embedded critical systems, and (b) Bakar Kiasan, a tool that implements these techniques in an integrated development environment for Spark. In this paper, we give a detailed walk-through of Bakar Kiasan as it is applied to an industrial code base for an embedded security device. We illustrate how Bakar Kiasan provides significant increases in automation, usability, and functionality over existing Spark contract checking tools, and we present results from performance evaluations of its application to industrial examples.","symbolic execution, spark, program analysis",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Cherif A,Belkadi M,Sauveron D",A Lightweight and Secure Data Collection Serverless Protocol Demonstrated in an Active RFIDs Scenario,ACM Trans. Embed. Comput. Syst.,2019,18,3,,Association for Computing Machinery,"New York, NY, USA",,,,2019-04,,1539-9087,https://doi.org/10.1145/3274667;http://dx.doi.org/10.1145/3274667,10.1145/3274667,"In the growing Internet of Things context, thousands of computing devices with various functionalities are producing data (from environmental sensors or other sources). However, they are also collecting, storing, processing and transmitting data to eventually communicate them securely to third parties (e.g., owners of devices or cloud data storage). The deployed devices are often battery-powered mobile or static nodes equipped with sensors and/or actuators, and they communicate using wireless technologies. Examples include unmanned aerial vehicles, wireless sensor nodes, smart beacons, and wearable health objects. Such resource-constrained devices include Active Radio Frequency IDentification (RFID) nodes, and these are used to illustrate our proposal. In most scenarios, these nodes are unattended in an adverse environment, so data confidentiality must be ensured from the sensing phase through to delivery to authorized entities: in other words, data must be securely stored and transmitted to prevent attack by active adversaries even if the nodes are captured. However, due to the scarce resources available to nodes in terms of energy, storage, and/or computation, the proposed security solution has to be lightweight. In this article, we propose a serverless protocol to enable Mobile Data Collectors (MDCs), such as drones, to securely collect data from mobile and static Active RFID nodes and then deliver them later to an authorized third party. The whole solution ensures data confidentiality at each step (from the sensing phase, before data collection by the MDC, once data have been collected by MDC, and during final delivery), while fulfilling the lightweight requirements for the resource-limited entities involved. To assess the suitability of the protocol against the performance requirements, it was implemented on the most resource-constrained devices to get the worst possible results. In addition, to prove the protocol fulfills the security requirements, it was analyzed using security games and also formally verified using the AVISPA and ProVerif tools.","lightweight cryptography, Data collection protocol, serverless protocol, data confidentiality, active RFID nodes",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zhang N,Financial Performance Analysis of Listed Pharmaceutical Companies,,2021,,,364–368,Association for Computing Machinery,"New York, NY, USA",,"2021 12th International Conference on E-Education, E-Business, E-Management, and E-Learning","Tokyo, Japan",2021,9781450388542,,https://doi.org/10.1145/3450148.3450194;http://dx.doi.org/10.1145/3450148.3450194,10.1145/3450148.3450194,"The development of the pharmaceutical industry has always attracted wide attention from all walks of life because it is related to the health needs of the people and is closely related to the problems of our national livelihood. In recent years, China's medical and health system reform has entered the deep-water area, and the pharmaceutical industry is facing more severe tests. In this critical period, the pharmaceutical industry must overcome the immediate difficulties and correctly understand the overall competitiveness of the industry. As a representative of the pharmaceutical industry, the financial indicators of listed pharmaceutical companies play an important role in evaluating the company's operating performance, and at the same time provide a method for the company to formulate correct development strategies and operating policies. This article uses factor analysis to evaluate the financial performance of China's listed pharmaceutical companies in recent years to reflect the current situation of China's pharmaceutical companies. When selecting the sample, we excluded listed companies that could not obtain the required research data and untrue data disclosure and selected 58 listed pharmaceutical companies as research objects according to the sub-categories of the pharmaceutical industry and the market value ranking at the end of 2019. The performance level indicators were screened, and 14 indicators were finally determined. After running the SPSS software, 5 main factors can be extracted to construct a model to measure the financial performance level, calculate each factor score and comprehensive score, and evaluate the financial performance of listed pharmaceutical companies; on the basis, the performance levels of the listed companies in the pharmaceutical industry in the past three years can be compared and their financial performances can be concluded.","pharmaceutical companies, financial performance, factor analysis, Listed companies",IC4E 2021,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Ugawa T,Abe T,Maeda T",Model Checking Copy Phases of Concurrent Copying Garbage Collection with Various Memory Models,Proc. ACM Program. Lang.,2017,1,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2017-10,,,https://doi.org/10.1145/3133877;http://dx.doi.org/10.1145/3133877,10.1145/3133877,"Modern concurrent copying garbage collection (GC), in particular, real-time GC, uses fine-grained synchronizations with a mutator, which is the application program that mutates memory, when it moves objects in its copy phase. It resolves a data race using a concurrent copying protocol, which is implemented as interactions between the collector threads and the read and write barriers that the mutator threads execute. The behavioral effects of the concurrent copying protocol rely on the memory model of the CPUs and the programming languages in which the GC is implemented. It is difficult, however, to formally investigate the behavioral properties of concurrent copying protocols against various memory models. To address this problem, we studied the feasibility of the bounded model checking of concurrent copying protocols with memory models. We investigated a correctness-related behavioral property of copying protocols of various concurrent copying GC algorithms, including real-time GC Stopless, Clover, Chicken, Staccato, and Schism against six memory models, total store ordering (TSO), partial store ordering (PSO), relaxed memory ordering (RMO), and their variants, in addition to sequential consistency (SC) using bounded model checking. For each combination of a protocol and memory model, we conducted model checking with a model of a mutator. In this wide range of case studies, we found faults in two GC algorithms, one of which is relevant to the memory model. We fixed these faults with the great help of counterexamples. We also modified some protocols so that they work under some memory models weaker than those for which the original protocols were designed, and checked them using model checking. We believe that bounded model checking is a feasible approach to investigate behavioral properties of concurrent copying protocols under weak memory models.","memory model, model checking, concurrency, garbage collection",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Westrick S,Yadav R,Fluet M,Acar UA",Disentanglement in Nested-Parallel Programs,Proc. ACM Program. Lang.,2019,4,POPL,,Association for Computing Machinery,"New York, NY, USA",,,,2019-12,,,https://doi.org/10.1145/3371115;http://dx.doi.org/10.1145/3371115,10.1145/3371115,"Nested parallelism has proved to be a popular approach for programming the rapidly expanding range of multicore computers. It allows programmers to express parallelism at a high level and relies on a run-time system and a scheduler to deliver efficiency and scalability. As a result, many programming languages and extensions that support nested parallelism have been developed, including in C/C++, Java, Haskell, and ML. Yet, writing efficient and scalable nested parallel programs remains challenging, primarily due to difficult concurrency bugs arising from destructive updates or effects. For decades, researchers have argued that functional programming can simplify writing parallel programs by allowing more control over effects but functional programs continue to underperform in comparison to parallel programs written in lower-level languages. The fundamental difficulty with functional languages is that they have high demand for memory, and this demand only grows with parallelism. In this paper, we identify a memory property, called disentanglement, of nested-parallel programs, and propose memory management techniques for improved efficiency and scalability. Disentanglement allows for (destructive) effects as long as concurrently executing threads do not gain knowledge of the memory objects allocated by each other. We formally define disentanglement by considering an ML-like higher-order language with mutable references and presenting a dynamic semantics for it that enables reasoning about computation graphs of nested parallel programs. Based on this graph semantics, we formalize a classic correctness property---determinacy race freedom---and prove that it implies disentanglement. This establishes that disentanglement applies to a relatively broad class of parallel programs. We then propose memory management techniques for nested-parallel programs that take advantage of disentanglement for improved efficiency and scalability. We show that these techniques are practical by extending the MLton compiler for Standard ML to support this form of nested parallelism. Our empirical evaluation shows that our techniques are efficient and scale well.","disentanglement, parallel computing, data race, memory management, functional programming",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Jain A,Touch Target Optimization Technique Using Virtual Finger-Tip Library,SIGSOFT Softw. Eng. Notes,2013,38,3,1–9,Association for Computing Machinery,"New York, NY, USA",,,,2013-05,,0163-5948,https://doi.org/10.1145/2464526.2464534;http://dx.doi.org/10.1145/2464526.2464534,10.1145/2464526.2464534,"Touch functionality is the latest mantra for consumers buying new smartphones or mobile devices. With devices screens becoming more compact, providing a user interface with easy navigation and effective usage is becoming increasingly difficult. Typically, the screens are designed using relevant design guidelines and work well for the general majority of people. However, every user is different. The way they handle the touch screen, the size of their finger-tips, everything is different. A single common UI design then fails to satisfy all the different users. Hence, there is a need to bridge the existing gap between the device UI screen design and the variances attached with users' touch inputs.Our latest work1, discussed in this paper, solves this challenge to a significant extent by providing a library of virtual finger-tip entries. Each finger-tip entry in the library is pre-attached with a specific surface area attached to it. These finger-tips, although virtual, are provided with the functionality that they act as wearable objects for a device user. Once worn, the device owner need not worry about their actual finger-tip size (that is, the surface area of user's finger on the device screen). Irrespective of a user's actual finger-tip size, when you place your finger on any icon on the screen, it uses exactly the same surface area that the virtual finger-tip uses. Virtual finger-tip sizes are calculated dynamically based on the relative size interpretations from the actual finger-tip size and the touch inputs to the device. Multiple virtual finger tips options are listed in the library enabling a device user to select the most appropriate one depending on the touch target they plan to work on.","human computer interaction, touch device, user-centric design",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rauf U,Gillani F,Al-Shaer E,Halappanavar M,Chatterjee S,Oehmen C",Formal Approach for Resilient Reachability Based on End-System Route Agility,,2016,,,117–127,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 ACM Workshop on Moving Target Defense,"Vienna, Austria",2016,9781450345705,,https://doi.org/10.1145/2995272.2995275;http://dx.doi.org/10.1145/2995272.2995275,10.1145/2995272.2995275,"The deterministic nature of existing routing protocols has resulted into an ossified Internet with static and predictable network routes. This gives persistent attackers (e.g. eavesdroppers and DDoS attackers) plenty of time to study the network and identify the vulnerable (critical) links to plan devastating and stealthy attacks. Recently, Moving Target Defense (MTD) based approaches have been proposed to to defend against DoS attacks. However, MTD based approaches for route mutation are oriented towards re-configuring the parameters in Local Area Networks (LANs), and do not provide any protection against infrastructure level attacks, which inherently limits their use for mission critical services over the Internet infrastructure. To cope with these issues, we extend the current routing architecture to consider end-hosts as routing elements, and present a formal method based agile defense mechanism to embed resiliency in the existing cyber infrastructure. The major contributions of this paper include: (1) formalization of efficient and resilient End to End (E2E) reachability problem as a constraint satisfaction problem, which identifies the potential end-hosts to reach a destination while satisfying resilience and QoS constraints, (2) design and implementation of a novel decentralized End Point Route Mutation (EPRM) protocol, and (3) design and implementation of planning algorithm to minimize the overlap between multiple flows, for the sake of maximizing the agility in the system. Our PlanetLab based implementation and evaluation validates the correctness, effectiveness and scalability of the proposed approach.","moving target defense, routing agility, route mutation, network resilience",MTD '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Carlson KD,Dutt N,Nageswaran JM,Krichmar JL",Design Space Exploration and Parameter Tuning for Neuromorphic Applications,,2013,,,,IEEE Press,"Montreal, Quebec, Canada",,Proceedings of the Ninth IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis,,2013,9781479914173,,,,"Large-scale spiking neural networks (SNNs) have been used to successfully model complex neural circuits that explore various neural phenomena such as learning and memory, vision systems, auditory systems, neural oscillations, and many other important topics of neural function. Additionally, SNNs are particularly well-adapted to run on neuromorphic hardware as spiking events are often sparse, leading to a potentially large reduction in both bandwidth requirements and power usage. The inclusion of realistic plasticity equations, neural dynamics, and recurrent topologies has increased the descriptive power of SNNs but has also made the task of tuning these biologically realistic SNNs difficult. We present an automated parameter-tuning framework capable of tuning large-scale SNNs quickly and efficiently using evolutionary algorithms (EA) and off-the-shelf graphics processing units (GPUs).To test the feasibility of an automated parameter-tuning framework, our group used EAs to tune open parameters in SNNs running concurrently on a GPU. The SNNs were evolved to produce orientation-dependent stimulus responses similar to those found in simple cells of the primary visual cortex (V1) through the formation of self-organizing receptive fields (SORFs). The general evolutionary approach was as follows: A population of neural networks was created, each with a unique set of neural parameter values that defined overall behavior. Each SNN was then ranked based on a fitness value assigned by an objective function in which higher fitness values were given to SNNs that (a) reproduced responses observed in primate visual cortex, and (b) spanned the stimulus space, and (c) had sparse firing rates. The highest ranked individuals were selected, recombined, and mutated to form the offspring for the next generation. This process continued until a desired fitness was reached or until other termination conditions were met (Figure 1a).The automated parameter-tuning framework consisted of three software packages. The framework included: (a) the CARLsim SNN simulator [1], (2) the Evolving Objects (EO) computational framework [2], and (3) a parameter-tuning interface (PTI), developed by our group, to provide an interface between CARLsim and EO (See Figure 1b). The EO computational framework ran the evolutionary algorithm on the user-designated parameters of SNNs in CARLsim. The PTI allowed the objective function to be calculated independent of the EO computation framework. Parameter values were passed from the EO computation framework through the PTI to the SNN in CARLsim where the objective function is calculated. After the objective function was executed, the results were passed from the SNN in CARLsim through the PTI back to the EO computation framework for processing by the EA. With this approach, the fitness function calculation, which involved running each SNN in the population, could be run in parallel on the GPU while the remainder of EA calculations can be performed using the CPU (Figure 1b).A sample SNN with 4,104 neurons was tuned to respond with V1 simple cell-like tuning curves and produce SORFs. A performance analysis comparing the GPU-accelerated implementation to a single-threaded CPU implementation was carried out and showed that the GPU implementation could achieve a 65 times speedup over the CPU implementation. Additionally, the parameter value solutions found in the tuned SNN were stable and robust.The automated parameter-tuning framework presented here will be of use to both the computational neuroscience and neuromorphic engineering communities, making the process of constructing and tuning large-scale SNNs much quicker and easier.","evolutionary algorithms, neuromorphic engineering, spiking neural networks, GPUs",CODES+ISSS '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Egor P,Digital Transformation of Industrial Companies: What is Management 4.0?,,2020,,,131–138,Association for Computing Machinery,"New York, NY, USA",,"2020 The 11th International Conference on E-Business, Management and Economics","Beijing, China",2020,9781450388016,,https://doi.org/10.1145/3414752.3414779;http://dx.doi.org/10.1145/3414752.3414779,10.1145/3414752.3414779,"The Industry 4.0 or also known as the 4th Industrial Revolution and its integral part in the digitalization of manufacturing companies cause big interest to researchers around the world. But as to date, the bulk of the work is devoted to the technical aspects of digitalization and business development in Industry 4.0, while the managerial aspect of these transformations remains in the background. The main purpose of this article is to analyze the specifics of the industrial companies’ digitalization in the projection on socio-technical transformations which is, to research the experience of digital transformation in terms of its impact on the process management, which supports the company's activities, including the corporate management. There is no doubt that digitalization is the integration of all processes, including production, logistics, personnel and “smart” objects (machines and products), when the physical environment is closely connected with the virtual one by embedding information and communication technologies. The digitalization within Industry 4.0 allows the creation of new cyber-systems and business models that can significantly improve the value chain of the company, and also, increase the well-being of society and the quality of the environment. Business models created within the framework of digitalization that are fully focused on Industry 4.0 technologies are characterized by its undeniable advantages like shorter production cycle, faster delivery, and, faster time to market for new products with improved features. Industry 4.0 and the digital transformation can definitely help companies enter the new growing markets and create their own unique business models. However, as of today, for many industrial companies, digitalization is just a formality and a tribute to fashion. Therefore, this process is still in its early stages. Digital transformation not only requires strong leadership, but it also requires rational decisions, and strong staff competencies, and with that, researching the specifics of digitalization, particularly in the aspect of transforming company management, seems very relevant.","Digital transformation, Digitalization, Industry 4.0, Smart",ICEME 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Zhang S,Li Y,Liu X,Guo S,Wang W,Wang J,Ding B,Wu D",Towards Real-Time Cooperative Deep Inference over the Cloud and Edge End Devices,Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.,2020,4,2,,Association for Computing Machinery,"New York, NY, USA",,,,2020-06,,,https://doi.org/10.1145/3397315;http://dx.doi.org/10.1145/3397315,10.1145/3397315,"Deep neural networks (DNNs) have been widely used in many intelligent applications such as object recognition and automatic driving due to their superior performance in conducting inference tasks. However, DNN models are usually heavyweight in computation, hindering their utilization on the resource-constraint Internet of Things (IoT) end devices. To this end, cooperative deep inference is proposed, in which a DNN model is adaptively partitioned into two parts and different parts are executed on different devices (cloud or edge end devices) to minimize the total inference latency. One important issue is thus to find the optimal partition of the deep model subject to network dynamics in a real-time manner. In this paper, we formulate the optimal DNN partition as a min-cut problem in a directed acyclic graph (DAG) specially derived from the DNN and propose a novel two-stage approach named quick deep model partition (QDMP) to solve it. QDMP exploits the fact that the optimal partition of a DNN model must be between two adjacent cut vertices in the corresponding DAG. It first identifies the two cut vertices and considers only the subgraph in between when calculating the min-cut. QDMP can find the optimal model partition with response time less than 300ms even for large DNN models containing hundreds of layers (up to 66.3x faster than the state-of-the-art solution), and thus enables real-time cooperative deep inference over the cloud and edge end devices. Moreover, we observe one important fact that is ignored in all previous works: As many deep learning frameworks optimize the execution of DNN models, the execution latency of a series of layers in a DNN does not equal to the summation of each layer's independent execution latency. This results in inaccurate inference latency estimation in existing works. We propose a new execution latency measurement method, with which the inference latency can be accurately estimated in practice. We implement QDMP on real hardware and use a real-world self-driving car video dataset to evaluate its performance. Experimental results show that QDMP outperforms the state-of-the-art solution, reducing inference latency by up to 1.69x and increasing throughput by up to 3.81x.","cooperative deep inference, deep model acceleration, deep model partitioning, Edge AI",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Su Y,Awadallah AH,Khabsa M,Pantel P,Gamon M,Encarnacion M",Building Natural Language Interfaces to Web APIs,,2017,,,177–186,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2017 ACM on Conference on Information and Knowledge Management,"Singapore, Singapore",2017,9781450349185,,https://doi.org/10.1145/3132847.3133009;http://dx.doi.org/10.1145/3132847.3133009,10.1145/3132847.3133009,"As the Web evolves towards a service-oriented architecture, application program interfaces (APIs) are becoming an increasingly important way to provide access to data, services, and devices. We study the problem of natural language interface to APIs (NL2APIs), with a focus on web APIs for web services. Such NL2APIs have many potential benefits, for example, facilitating the integration of web services into virtual assistants.We propose the first end-to-end framework to build an NL2API for a given web API. A key challenge is to collect training data, i.e., NL command-API call pairs, from which an NL2API can learn the semantic mapping from ambiguous, informal NL commands to formal API calls. We propose a novel approach to collect training data for NL2API via crowdsourcing, where crowd workers are employed to generate diversified NL commands. We optimize the crowdsourcing process to further reduce the cost. More specifically, we propose a novel hierarchical probabilistic model for the crowdsourcing process, which guides us to allocate budget to those API calls that have a high value for training NL2APIs. We apply our framework to real-world APIs, and show that it can collect high-quality training data at a low cost, and build NL2APIs with good performance from scratch. We also show that our modeling of the crowdsourcing process can improve its effectiveness, such that the training data collected via our approach leads to better performance of NL2APIs than a strong baseline.","crowdsourcing, hierarchical probabilistic model, natural language interface, web api",CIKM '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Pan W,Yang Q,Duan Y,Tan B,Ming Z",Transfer Learning for Behavior Ranking,ACM Trans. Intell. Syst. Technol.,2017,8,5,,Association for Computing Machinery,"New York, NY, USA",,,,2017-06,,2157-6904,https://doi.org/10.1145/3057732;http://dx.doi.org/10.1145/3057732,10.1145/3057732,"Intelligent recommendation has been well recognized as one of the major approaches to address the information overload problem in the big data era. A typical intelligent recommendation engine usually consists of three major components, that is, data as the main input, algorithms for preference learning, and system for user interaction and high-performance computation. We observe that the data (e.g., users’ behavior) are usually in different forms, such as examinations (e.g., browse and collection) and ratings, where the former are often much more abundant than the latter. Although the data are in different representations, they are both related to users’ true preferences and are also deemed complementary to each other for preference learning. However, very few ranking or recommendation algorithms have been developed to exploit such two types of user behavior.In this article, we focus on jointly modeling the examination behavior and rating behavior and develop a novel and efficient ranking-oriented recommendation algorithm accordingly. First, we formally define a new recommendation problem termed behavior ranking, which aims to build a ranking-oriented model by exploiting both the examination behavior and rating behavior. Second, we develop a simple and generic transfer to rank (ToR) algorithm for behavior ranking, which transfers knowledge of candidate items from a global preference learning task to a local preference learning task. Compared with the previous work on integrating heterogeneous user behavior, our ToR algorithm is the first ranking-oriented solution, which can effectively generate recommendations in a more direct manner than those regression-oriented methods. Extensive empirical studies show that our ToR algorithm performs significantly more accurately than the state-of-the-art methods in most cases. Furthermore, our ToR algorithm is very efficient in terms of the time complexity, which is similar to those for homogeneous user behavior alone.","Transfer to rank, preference learning, collaborative recommendation, behavior ranking",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Fomin FV,Gaspers S,Lokshtanov D,Saurabh S",Exact Algorithms via Monotone Local Search,J. ACM,2019,66,2,,Association for Computing Machinery,"New York, NY, USA",,,,2019-03,,0004-5411,https://doi.org/10.1145/3284176;http://dx.doi.org/10.1145/3284176,10.1145/3284176,"We give a new general approach for designing exact exponential-time algorithms for subset problems. In a subset problem the input implicitly describes a family of sets over a universe of size n and the task is to determine whether the family contains at least one set. A typical example of a subset problem is WEIGHTED d-SAT. Here, the input is a CNF-formula with clauses of size at most d, and an integer W. The universe is the set of variables and the variables have integer weights. The family contains all the subsets S of variables such that the total weight of the variables in S does not exceed W and setting the variables in S to 1 and the remaining variables to 0 satisfies the formula. Our approach is based on “monotone local search,” where the goal is to extend a partial solution to a solution by adding as few elements as possible. More formally, in the extension problem, we are also given as input a subset X of the universe and an integer k. The task is to determine whether one can add at most k elements to X to obtain a set in the (implicitly defined) family. Our main result is that a cknO(1) time algorithm for the extension problem immediately yields a randomized algorithm for finding a solution of any size with running time O((2−1/c)n).In many cases, the extension problem can be reduced to simply finding a solution of size at most k. Furthermore, efficient algorithms for finding small solutions have been extensively studied in the field of parameterized algorithms. Directly applying these algorithms, our theorem yields in one stroke significant improvements over the best known exponential-time algorithms for several well-studied problems, including d-HITTING SET, FEEDBACK VERTEX SET, NODE UNIQUE LABEL COVER, and WEIGHTED d-SAT. Our results demonstrate an interesting and very concrete connection between parameterized algorithms and exact exponential-time algorithms.We also show how to derandomize our algorithms at the cost of a subexponential multiplicative factor in the running time. Our derandomization is based on an efficient construction of a new pseudo-random object that might be of independent interest. Finally, we extend our methods to establish new combinatorial upper bounds and develop enumeration algorithms.","Exact exponential algorithm, local search, parameterized algorithm, satisfiability",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Fomin FV,Gaspers S,Lokshtanov D,Saurabh S",Exact Algorithms via Monotone Local Search,,2016,,,764–775,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Forty-Eighth Annual ACM Symposium on Theory of Computing,"Cambridge, MA, USA",2016,9781450341325,,https://doi.org/10.1145/2897518.2897551;http://dx.doi.org/10.1145/2897518.2897551,10.1145/2897518.2897551,"We give a new general approach for designing exact exponential-time algorithms for subset problems. In a subset problem the input implicitly describes a family of sets over a universe of size n and the task is to determine whether the family contains at least one set. A typical example of a subset problem is Weighted d-SAT. Here, the input is a CNF-formula with clauses of size at most d, and an integer W. The universe is the set of variables and the variables have integer weights. The family contains all the subsets S of variables such that the total weight of the variables in S does not exceed W, and setting the variables in S to 1 and the remaining variables to 0 satisfies the formula. Our approach is based on “monotone local search”, where the goal is to extend a partial solution to a solution by adding as few elements as possible. More formally, in the extension problem we are also given as input a subset X of the universe and an integer k. The task is to determine whether one can add at most k elements to X to obtain a set in the (implicitly defined) family. Our main result is that a cknO(1) time algorithm for the extension problem immediately yields a randomized algorithm for finding a solution of any size with running time O((2−1/c)n). In many cases, the extension problem can be reduced to simply finding a solution of size at most k. Furthermore, efficient algorithms for finding small solutions have been extensively studied in the field of parameterized algorithms. Directly applying these algorithms, our theorem yields in one stroke significant improvements over the best known exponential-time algorithms for several well-studied problems, including d-Hitting Set, Feedback Vertex Set, Node Unique Label Cover, and Weighted d-SAT. Our results demonstrate an interesting and very concrete connection between parameterized algorithms and exact exponential-time algorithms. We also show how to derandomize our algorithms at the cost of a subexponential multiplicative factor in the running time. Our derandomization is based on an efficient construction of a new pseudo-random object that might be of independent interest. Finally, we extend our methods to establish new combinatorial upper bounds and develop enumeration algorithms.","exponential time algorithms, randomized algorithms, parameterized algorithms, subset problems, Combinatorial bounds",STOC '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sihag D,Gupta S,Patnaik T",An Efficient Approach to Detection of Type of Text and Removal of Shirorekha in Curved and Straight Text,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Workshop on Multilingual OCR,"Barcelona, Spain",2009,9781605586984,,https://doi.org/10.1145/1577802.1577818;http://dx.doi.org/10.1145/1577802.1577818,10.1145/1577802.1577818,"In Indian language, recognition of curved and multi-oriented text is difficult. In curved text, the shirorekha is curved and character will be at any rotated position. Also in case of multi-oriented text, the text is skewed at some angle. These issues make the recognition of this type of text complex [1][2]. In this paper, we propose envelope point approach for mode detection and direction of shirorekha (headline) of curved and multi-oriented text and removal of shirorekha of curved and straight text without any skew correction. This approach will be able to solve the recognition problem in orientations and multi-skew. Unlike water reservoir principle[1][2], the proposed approach detects direction of shirorekha by calculating the envelope point[2] for left, right, top and bottom side of the text and for removal of shirorekha, the relation is formed by filling the gap within and in between the characters.","Shirorekha, envelope point",MOCR '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zou Y,Hua X,Nigul L,Ng J",Workshop on Automatic Service Composition,,2009,,,343–344,IBM Corp.,USA,,Proceedings of the 2009 Conference of the Center for Advanced Studies on Collaborative Research,"Ontario, Canada",2009,,,https://doi.org/10.1145/1723028.1723097;http://dx.doi.org/10.1145/1723028.1723097,10.1145/1723028.1723097,"In Service-Oriented Architecture (SOA), applications can be assembled by a set of existing distributed services spanning across organizations and platforms. SOA increases reuse and cooperation among services. Therefore, applications can be built in a rapid way with relatively low cost. With the increasing adoption of SOA solutions to application integration, the ability to compose services efficiently and effectively becomes more and more important. A lot of efforts have been devoted to service composition. Service composition integrates existing reusable services together as a process to fulfill business requirements, and exposes the process as a service (i.e., composite service). Specifically, a composition process involves the following five steps:1. Specify business requirements: A requirement (e.g., \purchase a book online\"") for composing services could be a declarative expression using formal or informal languages",an abstract process model (e.g.,a business process model),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sardina S,Padgham L",Goals in the Context of BDI Plan Failure and Planning,,2007,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th International Joint Conference on Autonomous Agents and Multiagent Systems,"Honolulu, Hawaii",2007,9788190426275,,https://doi.org/10.1145/1329125.1329134;http://dx.doi.org/10.1145/1329125.1329134,10.1145/1329125.1329134,"We develop a Belief-Desire-Intention (BDI) style agent-oriented programming language with special emphasis on the semantics of goals in the presence of the typical BDI failure handling present in many BDI systems and a novel account of hierarchical lookahead planning. The work builds incrementally on two existing languages and accommodates three type of goals: classical BDI-style event goals, declarative goals, and planning goals. We mainly focus on the dynamics of these type of goals and, in particular, on a kind of commitment scheme that brings the new language closer to the solid existing work in agent theory. To that end, we develop a semantics that recognises the usual hierarchical structure of active goals as well as their declarative aspects. In contrast with previous languages, the new language prevents an agent from blindly persisting with a (blocked) subsidiary goal when an alternative strategy for achieving a higher-level motivating goal exists. In addition, the new semantics ensures watchfulness by the agent to ensure that goals that succeed or are deemed impossible are immediately dropped, thus conforming to the requirements of basic rational commitment strategy. Finally, a mechanism for the proactive adoption of new goals, other than the mere reaction to events, and a formal account of interaction with the external environment are provided. We believe that the new language is an important step towards turning practical BDI programming languages more compatible with the established results in the area of agent theory.",,AAMAS '07,or design models (e.g.,UML diagrams).2. Provide service description: Service description specifies the capability of services,such as inputs/outputs,exceptions,functional and non-functional description.3. Discover relevant services: Service discovery is the process of locating a service that meets a certain searching criteria. For example,we search for an appropriate service to offer weather forecasting service. The searching criteria for the service discovery could be specified using keywords,"such as \""weather forecast\"".4. Generate composition process model: A composition process model contains a set of selected services",control flows and data flows among those services. Standards,such as BPEL (Business Process Execution Language),"are used to formally specify process models. A business requirement usually cannot be fulfilled by a single service. Various services are integrated using composition process models.5. Evaluate composition results: It is quite common that many returned services have the same or similar functionalities. It leads to more than one composition result to fulfill the business requirements. The different composition results can be evaluated to select the best one that meets the functional and nonfunctional requirements.""",,CASCON '09,,,,,,,,,,,,,,,,,,
1,Conference Paper,Dimitrov S,Distribution of Workforce in a Public Transport Company,,2020,,,186–193,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 21st International Conference on Computer Systems and Technologies '20,"Ruse, Bulgaria",2020,9781450377683,,https://doi.org/10.1145/3407982.3407999;http://dx.doi.org/10.1145/3407982.3407999,10.1145/3407982.3407999,"Increasingly, analytical methods such as mathematical modeling, statistical analysis and mathematical optimization are used in the management of real objects to establish optimal solutions to complex decision-making problems [1]. Among the mathematical modeling approaches, the technique of linear programming boasts with widest application. In it, the criterion for the effectiveness of the model is a linear objective function, which must be maximized or minimized in compliance with certain linear constraints. This technique allows to make a quantitative assessment of decisions on real problems in various areas such as finance, production, sales and distribution, transport, personnel management, marketing and others. Linear programming tasks aim to achieve optimal allocation of limited resources under certain constraints. Resources can be raw materials, labor, machinery, time, money, while constraints can be the company's possible costs or available raw materials. For many organizations, it is crucial to ensure good planning and distribution of the workforce, thus reducing costs and achieving more efficient use of resources, as well as fairer workload. Transport companies make no exception in that respect.Transport service operators need to plan the number of drivers and the number of vehicles correctly in order to comply with their timetables. These two problems are well described in the literature and are known as Crew Scheduling Problem (CSP) and Vehicle Scheduling Problem (VSP), respectively. The aim of resolving them is to minimize the operating costs regarding the use of vehicles and drivers' salaries in case of operational restrictions for vehicles and labor regulations for drivers, and to increase the quality of the offered service [2], [3], [4].Concentrating on these problems allows reaching a relatively easy and effective solution. However, it should be mentioned that the results obtained may not fully satisfy the requirements of transport service operators. Other disadvantages in solving such a class of tasks is that the applied methods are susceptible to interference by dispatchers and they can compromise the resulting solutions. The complexity and size of the tasks are time consuming in reaching an optimal solution and require a large amount of hardware resources.The problem is common and is solved by transport companies operating in different countries. It also concerns Bulgarian public transport operators, according to publications in the media [5], [6]. This reaffirms the need to approach the problem with the help of mathematical tools and offer a management option for this socially significant issue.The paper presents two consecutive tasks for optimal allocation of resources in the transport system. Both tasks are examples of demand modeling. The first task aims to calculate the number of tram drivers in each work shift needed to complete the daily schedule of the tram lines. The second task aims to calculate the number of employees for whom the working week starts from the respective day, so that their total number is minimal. The branch and bound approach is used. It is consisted of a series of subproblems for solving mixed and integer problems. They are solved systematically until the best solution to the main problem is found. Problems are solved with the Matlab program, using the intlinprog function.Then, a modification of the resource allocation tasks is presented. It examines several time ranges for many tram lines (for the first task - different work shifts; for the second task - days of the week).The remainder of the paper is organized as follows. The specific problem is described in Section 1. The mathematical modeling is given in Section 2. In Section 3 an algorithm and a script for optimal distribution of tram drivers are described. The computational results are presented in Section 4 and the paper is finalized with conclusions in Section 5.","Mixed-Integer Problem, Tram-drivers, Distribution of workforce, Transportation System",CompSysTech '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Lock K,Structuring Programs for Multiprogram Time-Sharing on-Line Applications,,1965,,,457–472,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the November 30--December 1, 1965, Fall Joint Computer Conference, Part I","Las Vegas, Nevada",1965,9781450378857,,https://doi.org/10.1145/1463891.1463941;http://dx.doi.org/10.1145/1463891.1463941,10.1145/1463891.1463941,"The modern art of computation has developed from plugboard programming through the stored machine instruction programs controlled by the users on the consoles, then to problem-oriented symbolic programs computed in the batch mode, towards the on-line computing during which the users have a large amount of control over their programs. The lower cost per computation and flexibilities of a large capacity high-speed computer naturally lead us to consider the provision of on-line computing service to several users on a single high-performance machine in a time-sharing mode, rather than several smaller machines, one for each individual. To maximize the efficiency of a man-machine team working in an on-line computing mode, it is desirable to let the man choose the language---say English---for communication and to let the machine do the translation. This idealistic goal is not impossible, but is currently impractical. A good compromise is to select as the user language a formal language such as ALGOL, FORTRAN or LISP which has a set of explicit syntactical rules and a small set of basic vocabulary. The user then may extend the vocabulary by declarative statements and communicate with the machine in the extended vocabulary. Due to frequent message exchanges between the man and the machine during on-line computing, the machine representation of users' programs must be easy to modify at the source language level. The technological trend towards large random access memory suggests the retention of several users' programs in core simultaneously, hence mutual memory protection must be ensured.",,"AFIPS '65 (Fall, part I)",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Güting RH,Valdés F,Damiani ML",Symbolic Trajectories,ACM Trans. Spatial Algorithms Syst.,2015,1,2,,Association for Computing Machinery,"New York, NY, USA",,,,2015-07,,2374-0353,https://doi.org/10.1145/2786756;http://dx.doi.org/10.1145/2786756,10.1145/2786756,"Due to the proliferation of GPS-enabled devices in vehicles or with people, large amounts of position data are recorded every day and the management of such mobility data, also called trajectories, is a very active research field. A lot of effort has gone into discovering “semantics” from the raw geometric trajectories by relating them to the spatial environment or finding patterns, for example, by data mining techniques. A question is how the resulting “meaningful” trajectories can be represented or further queried.In this article, we propose a systematic study of annotated trajectory databases. We define a very simple generic model called symbolic trajectory to capture a wide range of meanings derived from a geometric trajectory. Essentially, a symbolic trajectory is just a time-dependent label; variants have sets of labels, places, or sets of places. They are modeled as abstract data types and integrated into a well-established framework of data types and operations for moving objects. Symbolic trajectories can represent, for example, the names of roads traversed obtained by map matching, transportation modes, speed profile, cells of a cellular network, behaviors of animals, cinemas within 2km distance, and so forth. Symbolic trajectories can be combined with geometric trajectories to obtain annotated trajectories.Besides the model, the main technical contribution of the article is a language for pattern matching and rewriting of symbolic trajectories. A symbolic trajectory can be represented as a sequence of pairs (called units) consisting of a time interval and a label. A pattern consists of unit patterns (specifications for time interval and/or label) and wildcards, matching units and sequences of units, respectively, and regular expressions over such elements. It may further contain variables that can be used in conditions and in rewriting. Conditions and expressions in rewriting may use arbitrary operations available for querying in the host DBMS environment, which makes the language extensible and quite powerful.We formally define the data model and syntax and semantics of the pattern language. Query operations are offered to integrate pattern matching, rewriting, and classification of symbolic trajectories into a DBMS querying environment. Implementation of the model using finite state machines is described in detail. An experimental evaluation demonstrates the efficiency of the implementation. In particular, it shows dramatic improvements in storage space and response time in a comparison of symbolic and geometric trajectories for some simple queries that can be executed on both symbolic and raw trajectories.","moving objects, semantic trajectories, pattern matching, Trajectories, rewriting",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Papakonstantinou Y,"Semistructured Models, Queries and Algebras in the Big Data Era: Tutorial Summary",,2016,,,2229–2233,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 International Conference on Management of Data,"San Francisco, California, USA",2016,9781450335317,,https://doi.org/10.1145/2882903.2912573;http://dx.doi.org/10.1145/2882903.2912573,10.1145/2882903.2912573,"Numerous databases promoted as SQL-on-Hadoop, NewSQL and NoSQL support semi-structured, schemaless and heterogeneous data, typically in the form of enriched JSON. They also provide corresponding query languages. In addition to these genuine JSON databases, relational databases also provide special functions and language features for the support of JSON columns, typically piggybacking on non-1NF (non first normal form) features that SQL acquired over the years. We refer to SQL databases with JSON support as SQL/JSON databases.The evolving query languages present multiple variations: Some are superficial syntactic ones, while other ones are genuine differences in modeling, language capabilities and semantics. Incompatibility with SQL presents a learning challenge for genuine JSON databases, while the table orientation of SQL/JSON databases often leads to cumbersome syntactic/semantic structures that are contrary to the semistructured nature of JSON. Furthermore, the query languages often fall short of full-fledged semistructured query language capabilities, when compared to the yardstick set by XQuery and prior works on semistructured data (even after superficial model differences are abstracted out).We survey features, the designers' options and differences in the approaches taken by actual systems. In particular, we first present a SQL backwards-compatible language, named SQL++, which can access both SQL and JSON data. SQL++ is expected to be supported by Couchbase's CouchDB and UCI's AsterixDB semistructured databases. Then we expand SQL++ into the Configurable SQL++, whereas multiple possible (and different) semantics are formally captured by the multiple options that the language's semantic configuration options can take. We show how appropriate setting of the configuration options morphs the Configurable SQL++ semantics into the semantics of 10 surveyed languages, hence providing a compact and formal tool to understand the essential semantic differences between different systems. We briefly comment on the utility of formally capturing semantic variations in polystore systems.Finally we discuss the comparison with prior nested and semistructured query languages (notably OQL and XQuery) and describe a key aspect of query processor implementation: set-oriented semistructured query algebras. In particular, we transfer into the JSON era lessons from the semistructured query processing research of the 90s and 00s and combine them with insights on current JSON databases. Again, the tutorial presents the algebras' fundamentals while it abstracts away modeling differences that are not applicable.","SQL, semistructured query languages, noSQL, JSON query languages, newSQL, query algebras, polystores",SIGMOD '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Book Chapter,Reilly ED,Expression,,2003,,,689–690,John Wiley and Sons Ltd.,GBR,Encyclopedia of Computer Science,,,2003,9780470864128,,,,"An expression, one of the fundamental constituents of high-level language syntax, is a character sequence that specifies a rule for calculating a value. That value may be either numeric, as in the Pascal expression a+6, or alphanumeric, as in the Basic expression LEFT$ (A$, 5) (whose value is the leftmost 5 characters of string A$). An expression may appear to the right of the replacement symbol (usually = or: = or ←) in statement-oriented languages such as Pascal or Fortran, or may stand alone and be evaluated immediately to yield a particular value in expression- oriented languages such as Lisp or APL.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Desai K,Prabhakaran B,Raghuraman S",Combining Skeletal Poses for 3D Human Model Generation Using Multiple Kinects,,2018,,,40–51,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 9th ACM Multimedia Systems Conference,"Amsterdam, Netherlands",2018,9781450351928,,https://doi.org/10.1145/3204949.3204958;http://dx.doi.org/10.1145/3204949.3204958,10.1145/3204949.3204958,"RGB-D cameras, such as the Microsoft Kinect, provide us with the 3D information, color and depth, associated with the scene. Interactive 3D Tele-Immersion (i3DTI) systems use such RGB-D cameras to capture the person present in the scene in order to collaborate with other remote users and interact with the virtual objects present in the environment. Using a single camera, it becomes difficult to estimate an accurate skeletal pose and complete 3D model of the person, especially when the person is not in the complete view of the camera. With multiple cameras, even with partial views, it is possible to get a more accurate estimate of the skeleton of the person leading to a better and complete 3D model. In this paper, we present a real-time skeletal pose identification approach that leverages on the inaccurate skeletons of the individual Kinects, and provides a combined optimized skeleton. We estimate the Probability of an Accurate Joint (PAJ) for each joint from all of the Kinect skeletons. We determine the correct direction of the person and assign the correct joint sides for each skeleton. We then use a greedy consensus approach to combine the highly probable and accurate joints to estimate the combined skeleton. Using the individual skeletons, we segment the point clouds from all the cameras. We use the already computed PAJ values to obtain the Probability of an Accurate Bone (PAB). The individual point clouds are then combined one segment after another using the calculated PAB values. The generated combined point cloud is a complete and accurate 3D representation of the person present in the scene. We validate our estimated skeleton against two well-known methods by computing the error distance between the best view Kinect skeleton and the estimated skeleton. An exhaustive analysis is performed by using around 500000 skeletal frames in total, captured using 7 users and 7 cameras. Visual analysis is performed by checking whether the estimated skeleton is completely present within the human model. We also develop a 3D Holo-Bubble game to showcase the real-time performance of the combined skeleton and point cloud. Our results show that our method performs better than the state-of-the-art approaches that use multiple Kinects, in terms of objective error, visual quality and real-time user performance.","3D model, point cloud combination, interactive 3D tele-immersion, combined skeleton",MMSys '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chang W,Roy D,Zhao S,Annaswamy A,Chakraborty S",CPS-Oriented Modeling and Control of Traffic Signals Using Adaptive Back Pressure,,2020,,,1686–1691,EDA Consortium,"San Jose, CA, USA",,"Proceedings of the 23rd Conference on Design, Automation and Test in Europe","Grenoble, France",2020,9783981926347,,,,"Modeling and design of automotive systems from a cyber-physical system (CPS) perspective have lately attracted extensive attention. As the trend towards automated driving and connectivity accelerates, strong interactions between vehicles and the infrastructure are expected. This requires modeling and control of the traffic network in a similarly formal manner. Modeling of such networks involves a tradeoff between expressivity of the appropriate features and tractability of the control problem. Back-pressure control of traffic signals is gaining ground due to its decentralized implementation, low computational complexity, and no requirements on prior traffic information. It guarantees maximum stability under idealistic assumptions. However, when deployed in real traffic intersections, the existing back-pressure control algorithms may result in poor junction utilization due to (i) fixed-length control phases; (ii) stability as the only objective; and (iii) obliviousness to finite road capacities and empty roads. In this paper, we propose a CPS-oriented model of traffic intersections and control of traffic signals, aiming to address the utilization issue of the back-pressure algorithms. We consider a more realistic model with transition phases and dedicated turning lanes, the latter influencing computation of the pressure and subsequently the utilization. The main technical contribution is an adaptive controller that enables varying-length control phases and considers both stability and utilization, while taking both cases of full roads and empty roads into account. We implement a mechanism to prevent frequent changes of control phases and thus limit the number of transition phases, which have negative impact on the junction utilization. Microscopic simulation results with SUMO on a 3 × 3 traffic network under various traffic patterns show that the proposed algorithm is at least about 13% better in performance than the existing fixed-length backpressure control algorithms reported in previous works. This is a significant improvement in the context of traffic signal control.",,DATE '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Meyerhoff Nielsen M,Jordanoski Z","Digital Transformation, Governance and Coordination Models: A Comparative Study of Australia, Denmark and the Republic of Korea",,2020,,,285–293,Association for Computing Machinery,"New York, NY, USA",,The 21st Annual International Conference on Digital Government Research,"Seoul, Republic of Korea",2020,9781450387910,,https://doi.org/10.1145/3396956.3396987;http://dx.doi.org/10.1145/3396956.3396987,10.1145/3396956.3396987,"Australia, Denmark and the Republic of Korea are among the most connected countries in the world, with high-speed infrastructure widely available and with high rates of internet use by businesses and individuals alike. The three countries are also among the front-runners when it comes to the utilisation of Information Communication Technology (ICT) in the public sector and have all showed significant achievements related to the digital transformation of public services production and delivery. Although many factors may account for their successes, what is the role played by their strategic approach to governance and inter-governmental cooperation models? How have governance and multi-stakeholder coordination and cooperation approach influences the success of the digital transformation and boost innovations in each of the three cases?The initial findings of this paper support academic that the digital transformation of the public sector largely depends on the focus, governance and intergovernmental coordination and cooperation. Specifically in guiding the use of ICT in building an efficient and user-oriented whole-of-government ecosystem for public service production and delivery. The analysis finds that a strong governance model with clear roles and responsibilities of all institutions complement with formal cross-sectoral bodies for decision-making and ensuring inter-governmental coordination and cooperation are essential for successful digital transformation. High levels of inclusiveness on across all levels of government, society and end-user groups is seen as a positive factor in all three countries. As a result, the success rate of the implementation of their respective ICT/Digital/eGovernment strategies is high, resulting with successful development of the ICT infrastructure, roll-out of key enablers, interoperability systems, technical and legal standards that allowed them as global leaders to move towards real user-centric, integrated service production and delivery. However, to verify the findings, this paper also identifies a set of “leap-frogging” countries for further research.","eServices, Inter-governmental cooperation, eGovernment, Governance",dg.o '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mei Q,Cai D,Zhang D,Zhai C",Topic Modeling with Network Regularization,,2008,,,101–110,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 17th International Conference on World Wide Web,"Beijing, China",2008,9781605580852,,https://doi.org/10.1145/1367497.1367512;http://dx.doi.org/10.1145/1367497.1367512,10.1145/1367497.1367512,"In this paper, we formally define the problem of topic modeling with network structure (TMN). We propose a novel solution to this problem, which regularizes a statistical topic model with a harmonic regularizer based on a graph structure in the data. The proposed method bridges topic modeling and social network analysis, which leverages the power of both statistical topic models and discrete regularization. The output of this model well summarizes topics in text, maps a topic on the network, and discovers topical communities. With concrete selection of a topic model and a graph-based regularizer, our model can be applied to text mining problems such as author-topic analysis, community discovery, and spatial text mining. Empirical experiments on two different genres of data show that our approach is effective, which improves text-oriented methods as well as network-oriented methods. The proposed model is general; it can be applied to any text collections with a mixture of topics and an associated network structure.","social networks, graph-based regularization, statistical topic models",WWW '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shen Y,Miao Z",Oriented Gradients for Human Action Recognition,,2011,,,175–178,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Second International Conference on Internet Multimedia Computing and Service,"Harbin, China",2011,9781450304603,,https://doi.org/10.1145/1937728.1937770;http://dx.doi.org/10.1145/1937728.1937770,10.1145/1937728.1937770,"In this study, we present a simple and effective approach to human action recognition in real time video. We use oriented gradients to represent human contour and recognize human action. First, we detect the human area and obtain human contour information. And then, we use the binary image of contour to extract features and divide the contour area of each frame into several blocks. In each block, we calculate the histogram of oriented gradients and extract the main orientation of gradients as the block feature. In each frame, features of all blocks are concatenated to one feature vector to represent human pose. Then, we concatenate human pose features of sequential frames as an action feature using a sliding window with overlapping ratio. After that, we train a SVM classifier by these action features. In the experiments, our approach has a good recognition performance compared with state-of-the-art methods.","oriented gradients, video analysis, human action recognition",ICIMCS '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Hovy E,Negation and Modality in Distributional Semantics,,2010,,,50,Association for Computational Linguistics,USA,,Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,"Uppsala, Sweden",2010,,,,,"In Natural Language Processing, negation and modality have mostly been handled using the older, pre-statistical methodologies of formal representations subject to rule-based processing. This fits the traditional treatment of negation and modality in logic-based knowledge representation and linguistics. However, in modern-day statistics-based NLP, how exactly negation and modality should be taken into account, and what role these phenomena play overall, is much less clear. The closest statistics-based NLP gets to semantics at this time is lexical-based word distributions (such as used in word sense disambiguation) and topic models (such as produced by Latent Dirichlet Allocation). What exactly in such representations should a negation or a modality actually apply to? What would, or should, the resulting effects be? The traditional approaches are of little or no help.In this talk I argue that neither model is adequate, and that one needs a different model of semantics to be able to accommodate negation and modality. The traditional formalisms are impoverished in their absence of an explicit representation of the denotations of each symbol, and the statistics-based word distributions do not support the compositionality required of semantics since it is unclear how to link together two separate word distributions in a semantically meaningful way. A kind of hybrid, which one could call Distributional Semantics, should be formulated to include the necessary aspects of both: the ability to carry explicit word associations that are still partitioned so as to allow negation and modality to affect the representations in intuitively plausible ways is what is required.I present a specific model of Distributional Semantics that, although still rudimentary, exhibits some of the desired features. I explore the possibilities for accommodating the phenomena of negation and modality. The talk poses many more questions than it answers and is an invitation to consider Distributional Semantics as a model for richer and more semantics-oriented statistics-based NLP.",,NeSp-NLP '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Baguma R,Lubega JT",A Web Design Framework for Improved Accessibility for People with Disabilities (WDFAD),,2008,,,134–140,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 International Cross-Disciplinary Conference on Web Accessibility (W4A),"Beijing, China",2008,9781605581538,,https://doi.org/10.1145/1368044.1368077;http://dx.doi.org/10.1145/1368044.1368077,10.1145/1368044.1368077,"Information and Communication Technology (ICT) such as the World Wide Web (WWW) has increasingly become embedded in everyday life and is progressively becoming indispensable for public, business, personal efficiency or even improvement of livelihoods [1]. Web users including People with Disabilities (PWDs) can conveniently undertake a number of tasks that would otherwise be difficult or impossible. But many Web applications such as e-learning, e-commerce and e-government are not accessible to PWDs including the blind. Through Web accessibility guidelines, Web developers can develop Web applications that are accessible to PWDs. However, majority of the available accessibility guidelines are difficult to integrate into existing developer workflows and rarely offer specific suggestions that are developer oriented. In this paper, we propose a Web Design Framework for Improved Accessibility for People with Disabilities (WDFAD). The WDFAD provides precise guidelines on how to develop Web applications that are accessible to PWDs particularly the blind. These are packaged according to the three components of Web applications namely; content, navigation and user interface. Using constructs of the Non Functional Requirements (NFR) Framework, Web accessibility design objectives are represented as primary goals and sub goals. The primary goals represent the high level accessibility design objectives, while the sub goals represent the requirements that need to be met in the Web development process in order to meet each primary goal. WDFAD also illustrates the overlaps between the process of meeting each primary goal. This unveils the optimal ways of achieving Web accessibility during Web design. The precise nature of WDFAD and its packaging according to the main components of Web applications makes Web accessibility requirements potentially easier to understand and apply by Web developers. Web Developers prefer precise and familiar tools due to their busy work life and daily interface and expression in formal instructions. In addition, the global versus local classification of Web accessibility requirements in WDFAD modularizes the web accessibility guidelines hence making them easier to understand, apply and update.","people with disabilities, web design framework, blind, web accessibility, requirements",W4A '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Bødker S,Design for Reconfiguration,,2008,,,263–264,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th Annual ACM International Conference on Design of Communication,"Lisbon, Portugal",2008,9781605580838,,https://doi.org/10.1145/1456536.1456589;http://dx.doi.org/10.1145/1456536.1456589,10.1145/1456536.1456589,"The desktop computer has been part of our work-life for a while. Even so many work situations do not consist solely of work at the desktop. Many other artefacts are used in changing configurations with and around the computer. Most user interface design has failed to recognize this, and accordingly we are still stuck with the idea that new design should replace existing artefacts, rather than exist together with them.Mobile technology makes it possible to work in many places, and current mobile technologies often seem to assume that as long as the individual user has access to all her personal documents on her laptop, she can work independently of place. This assumes that everybody would always want to carry along every document one has ever produced or received. And on top, many work settings are not about individual documents but presupposes a network-oriented shared use of documents and services across physical place. Furthermore, while moving about, and e.g. working from home, we face a blurring of the boundaries between work and other parts of life, as well as an ongoing reconfiguration of work and non-work technologies. How do we deal with changing configurations of the interfaces in particular such that cross between work and non-work? How do experiences with non-work technology influence work, and how do we deal with those experiences in design of work-place technology?My background for addressing these issues lies in activity theoretical HCI that helped bring focus \from human factors to human actors [1].\"" Focus was moved from individual work to groups working with a collection of applications. Theory focused on work settings and interaction within well-established communities of practice. Rigid guidelines",formal methods,and systematic testing were mostly abandoned for proactive methods such as a variety of participatory design workshops,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rajan A,du Bousquet L,Ledru Y,Vega G,Richier JL",Assertion-Based Test Oracles for Home Automation Systems,,2010,,,45–52,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 7th International Workshop on Model-Based Methodologies for Pervasive and Embedded Software,"Antwerpen, Belgium",2010,9781450301237,,https://doi.org/10.1145/1865875.1865882;http://dx.doi.org/10.1145/1865875.1865882,10.1145/1865875.1865882,"The Home Automation System (HAS) is a service-oriented application that facilitates the automation of a private home to improve the comfort and security of its residents. HAS is implemented using a service-oriented architecture. Many of the services in the HAS dynamically change their configuration during run-time. This occurs due to change in availability and bindings between services. Dynamic reconfigurations of services in the HAS presents several testing challenges, one being the specification of test oracles. In this paper, we give an approach for specifying test oracles for services in the HAS. We formally specify test oracles in the JML specification language. To verify service behavior in the presence of dynamic reconfigurations, we use mechanisms in the service architecture that notify dynamic changes along with run-time evaluation of JML specifications. We illustrate our approach using an example service in the H-Omega HAS developed on the OSGi™ and iPOJO service platform. To evaluate our approach, we developed a testing framework that allows for generation of tests with dynamic service reconfigurations. In addition, we seeded faults into the example service, and evaluated the effectiveness of the test oracles in revealing the faults using the generated tests.",,MOMPES '10,prototyping and contextual inquiries. With the above challenges,we are about to make a next theoretical move,focusing on multiplicity,context,boundaries,"experience and participation in a world of changing configurations of artefacts""","ubiquitous interaction, activity theoretical HCI",SIGDOC '08,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Raja MA,Swamynathan S",Tweet Sentiment Analyzer: Sentiment Score Estimation Method for Assessing the Value of Opinions in Tweets,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Advances in Information Communication Technology & Computing,"Bikaner, India",2016,9781450342131,,https://doi.org/10.1145/2979779.2979862;http://dx.doi.org/10.1145/2979779.2979862,10.1145/2979779.2979862,"Social networking applications are prominent among the internet user communities. Many social media websites are used for sharing the information instantly. Twitter is one of the vibrant social networking websites for sharing small textual information within a short span of time. It is essential to identify the type of information shared on these websites. Sentiment analysis involves the process of analyzing the opinion content present in the text. Millions of tweets are posted in a day about various topics. Twitter sentiment analysis mainly involves the process of identifying the polarity oriented terms mentioned in the tweet. Most of the twitter sentiment analysis works have concentrated on the sentiment polarity identification. Based on the literature, it is observed that, researchers still need to contribute in the area of sentiment score calculation of a tweet. Hence, in this work, sentiment score calculation is carried out with sentiment corpus oriented approach for calculating the score effectively. In addition, the grammatical type of the word used in a tweet, the relationship between the words are properly identified. The tweet tagger, corpus based sentiment score assignment have been distinctively used when compared to other previous works. The experimental results show that the sentimental score based tweet identification resulted in top tweets among the large collection of tweets.","tweet crawler, sentiwordnet, tagger, sentiment score, tweets, sentiment analysis",AICTC '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kwatli MA,Gillot PY","A New Method in Volcano-Morphology to Investigate the Tectonic Constraints on the Volcanism, Case Study of Harrat Al Sham Volcanic Field, Arabia Plate: The Interest of GIS and Relational Database",,2010,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st International Conference and Exhibition on Computing for Geospatial Research & Application,"Washington, D.C., USA",2010,9781450300315,,https://doi.org/10.1145/1823854.1823908;http://dx.doi.org/10.1145/1823854.1823908,10.1145/1823854.1823908,"The volcanic activity of Arabian plate offers an attractive example of intraplate volcanism constrained by a complex tectonic setting. Harrat Ash Shaam volcanic field (HASV) is a basaltic province, extends widely at Arabian plate (over 50 000 km2), covers south of Syria, northeast of Jordan, north of Saudi Arabia, and contains hundreds of well- preserved monogenic volcanic cones.Our method aims to identify those cones volcanic, calculate its morphological parameters (heights, slopes, surfaces, volumes...etc.), and study their correlation. The farther intention of this study is to investigate the consequence of the tectonic events on the volcanic activity by testing the relations between the volcano-morphological parameters and the structure of the lithosphere (basement and moho surfaces).The realization of these objectives is problematic and even impossible by using the traditional exploration methods. Thanks to the computing technology which offers a vast opportunity to develop a new digital method in order to achieve such complex geospatial study.We suggest the integration and the exploitation of following primary data (so called to be distinguished from the extracted data): 1) the remote sensing (RS) technology provides several satellite scenes (landsat7, ETM+), 2) digital elevation models (SRTM data), 3) Digital earth application (by Cornell University), latter source offers internet based open access system of interpretation of geophysical data as estimation of crustal thickness and depth to Moho, 4) several geological maps of the study area, 5) K-Ar ages.The main challenges of this work are: a) building up geospatial database, geo-referencing and managing the primary data of different sources at same platform, b) treating the primary data to extract advanced levels of data, c) sustain the principle of \data independence\"" in order to protect the root of data from confusion after the process of extraction",which is imperative during the results interpretation (e.g. it must be specified if the volume parameter has been mathematically extracted based on the surface or independently).This paper spotlights the role of GIS in our geospatial investigation,and explains techniques employed in our method: 1) processing the satellite images with the purpose of distinguish the cones volcanic at HASV (more than 800 cones have been detected),,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rohloff T,Sauer D,Meinel C",Students' Achievement of Personalized Learning Objectives in MOOCs,,2020,,,147–156,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Seventh ACM Conference on Learning @ Scale,"Virtual Event, USA",2020,9781450379519,,https://doi.org/10.1145/3386527.3405918;http://dx.doi.org/10.1145/3386527.3405918,10.1145/3386527.3405918,"Massive Open Online Courses (MOOCs) provide the opportunity to offer free and open education at scale. Thousands of students with different social and cultural backgrounds from all over the world can enroll for a course. This diverse audience comes with varying motivations and intentions from their personal or professional life. However, course instructors cannot offer individual support and guidance at this scale and therefore usually provide a one-size-fits-all approach. Students have to follow weekly-structured courses and their success is measured with the achievement of a certificate at the end. To better address the varying learning needs, technical support for goal-oriented and self-regulated learning is desired but very limited to date. Both learning strategies are proven to be key factors for students' achievement in large-scale online learning environments. Therefore, this paper presents a continuative study of personalized learning objectives in MOOCs to encourage goal-oriented and self-regulated learning. Based on the previously well-perceived acceptance and usefulness of the concept of personalized learning objectives, this study examines which learners select an objective and how successful they complete objectives. Concerning the learners' socio-demographic and geographical background, we could not identify any practical significant difference between students with selected learning objectives and the total course population. However, we have identified promising objective achievement rates, and we have observed a practical significant improvement of the certification rates comparing the total course population and students who selected an objective that included a graded certificate. This has also demonstrated a method for calculating more reasonable completion rates in MOOCs.","learning objectives, moocs, self-regulated learning",L@S '20,2) using spatial analysis tools in order to obtain automatically the periphery and the virtual bases of each cones volcanic from the digital elevation model,and 3) using GIS platform as tools to manage multi sources- data efficiently.In addition to,we highlight the integration between GIS and Relational Database,that we redesigned the geospatial database and restructured the data tables according to the new defined objects (i.g. the volcanic cones). In addition we have been used SQL widely in order to extract the advanced data levels (e.g. the morphological parameters),and to develop an approach in order to protect data roots.On other hand,the facility of exporting and importing the geospatial data tables between GIS and Microsoft application permitted us to reproduce easily and quickly the results of our research in form of maps (by using mapping tools based on geo-statistical methods of GIS). Consequently we propose an example of data streaming characterized by a geo-database system growing up in two directions (rows and columns). Our suggestion based on an observation; that in this case study,"the geospatial database grows throughout a \""looping process\"" between input and output data (i.g. the output data turn out to be a new batch of input data inserts again to the system). The probability of this looping process seems to be high and relates to the number of the scientific questions under investigation using the geospatial database system.Our prospective of the future challenge is to enhance the update links between the primary and the extracted data levels with the aim of bridging the gap created by high rate data streaming","as well as we proposed to develop the approach of \""data independence\"".This case study shows that the role of GIS and Relational Database in geospatial investigation is not only indispensable as tools to manage and manipulate multi sources data",but is also significant to answer composite scientific questions.That our results demonstrate different spatial density zones contain clusters of hundreds of cones volcanic,in addition to considerable spatial differentiations of the morphological parameters. Consequently,we linked those variations to the lithosphere structures.On other hand our results obtained by applying digital based-method to HASV are in agreement with our dating results (K-Ar ages) of the volcanic activity,and the petrologic evidences at the northern parts of HASV. That enhanced our understanding of the volcano-tectonic evolution of the study area and played key role to suggest a spatial-temporal model characterizes the tectonic alteration between the compression and the extension during the last 26 Ma.We expect the mentioned harmony between results (i.e. direct method and digital based- methods) could reflect an important advantage in comparing the volcanism of HASV and other terrestrial planets.Moreover our results suggest a huge tectonic constrain on the volumes of the volcanic activity; that is fundamental to manage the volcanic risks at active analog zones. Therefore,"we concluded that the digital based- method is helpful for monitoring and predication the natural hazards at regional scales.In the light of the previous facts building up the digital earth and developing its management tools are the future duties.""",,COM.Geo '10,,,,,,,,,,,,,,,
1,Journal Article,"Ávila BT,Lins RD",W-Tree: A Compact External Memory Representation for Webgraphs,ACM Trans. Web,2016,10,1,,Association for Computing Machinery,"New York, NY, USA",,,,2016-02,,1559-1131,https://doi.org/10.1145/2835181;http://dx.doi.org/10.1145/2835181,10.1145/2835181,"World Wide Web applications need to use, constantly update, and maintain large webgraphs for executing several tasks, such as calculating the web impact factor, finding hubs and authorities, performing link analysis by webometrics tools, and ranking webpages by web search engines. Such webgraphs need to use a large amount of main memory, and, frequently, they do not completely fit in, even if compressed. Therefore, applications require the use of external memory. This article presents a new compact representation for webgraphs, called w-tree, which is designed specifically for external memory. It supports the execution of basic queries (e.g., full read, random read, and batch random read), set-oriented queries (e.g., superset, subset, equality, overlap, range, inlink, and co-inlink), and some advanced queries, such as edge reciprocal and hub and authority. Furthermore, a new layout tree designed specifically for webgraphs is also proposed, reducing the overall storage cost and allowing the random read query to be performed with an asymptotically faster runtime in the worst case. To validate the advantages of the w-tree, a series of experiments are performed to assess an implementation of the w-tree comparing it to a compact main memory representation. The results obtained show that w-tree is competitive in compression time and rate and in query time, which may execute several orders of magnitude faster for set-oriented queries than its competitors. The results provide empirical evidence that it is feasible to use a compact external memory representation for webgraphs in real applications, contradicting the previous assumptions made by several researchers.","compression, Webgraph, representation, external memory, data structure",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wan Z,Li Y,Zhang Z",Modeling and Analysis of Integrated Combat Network System Based on VOODAC,,2019,,,81–86,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Industrial Control Network and System Engineering Research,"Shenyang, China",2019,9781450366274,,https://doi.org/10.1145/3333581.3333598;http://dx.doi.org/10.1145/3333581.3333598,10.1145/3333581.3333598,"With the rapid development of network science, Integrated combat network system (ICNS) based on network information have become the mainstream of modern military warfare. The military combat system is formed by different entities connected by information, and the combat network can be abstracted into a heterogeneous network. It is of great military value to study the functionality of heterogeneous networks and the affordability of topologies. This paper applies the OODA (Observe Orient Decider Action) ring to the combat network and proposes the concept of valid OODA chain (VOODAC). The combat network model determines the distributed position of the command and control nodes by using the reverse order heuristic algorithm, and sensor(S) and influence(I) nodes according to a certain ratio. While classifying the nodes and edges, we use the iterative method to calculate the value of VOODAC, Finally, the theoretical and practical consistency is obtained through the simulation, which can prove the correctness of our theory. Through our analysis and simulation, the network topology structure we propose can be used in the combat network appropriately.","Heterogeneous Network, OODA, Robust, Combat Network",ICNSER2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Rovatsos M,Open Student Travel Scholarships Scheme,AI Matters,2019,5,1,4,Association for Computing Machinery,"New York, NY, USA",,,,2019-04,,,https://doi.org/10.1145/3320254.3320256;http://dx.doi.org/10.1145/3320254.3320256,10.1145/3320254.3320256,"As part of its portfolio of student-oriented activities, SIGAI regularly supports its members through the provision of travel scholarships. To date, these have been primarily allocated to key conferences (co-)sponsored by SIGAI, but as the number of events we support formally (whether through financial sponsorship or \in-cooperation\"" status) has increased substantially",we have identified a need to reach out to a broader community of students participating in,and contributing to,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Demiralp Ç,Haas PJ,Parthasarathy S,Pedapati T",Foresight: Recommending Visual Insights,Proc. VLDB Endow.,2017,10,12,1937–1940,VLDB Endowment,,,,,2017-08,,2150-8097,https://doi.org/10.14778/3137765.3137813;http://dx.doi.org/10.14778/3137765.3137813,10.14778/3137765.3137813,"Current tools for exploratory data analysis (EDA) require users to manually select data attributes, statistical computations and visual encodings. This can be daunting for large-scale, complex data. We introduce Foresight, a system that helps the user rapidly discover visual insights from large high-dimensional datasets. Formally, an \insight\"" is a strong manifestation of a statistical property of the data",e.g.,high correlation between two attributes,"a broader range of events.""",,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Prapasuwannakul N,Bussaban K",Mobile Application Development of Food Additive Calculation for Meat Products,,2019,,,18–22,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 4th International Conference on Information and Education Innovations,"Durham, United Kingdom",2019,9781450371698,,https://doi.org/10.1145/3345094.3345114;http://dx.doi.org/10.1145/3345094.3345114,10.1145/3345094.3345114,"Food additives are used in meat products for food safety, shelf life and food technology reasons. The types and levels of food additives used in processed meats must comply with the state regulations in order to process safe foods for human consumption. Food additive calculator which is a web-based version, provided by The Thai Food and Drug Administration to help the producers in calculating maximum use level of food additives for all kinds of foods including meats, is found too complicated for small entrepreneurs with inadequate knowledge. Web-based version is also not responsive design and display to users view and is not mobile user oriented. Therefore, this research was aimed to develop a user friendly and convenient mobile application on Android Mobile Operating System for calculating maximum permitted level of food additives used for meat products. This mobile application is designed for calculating four kinds of food additives widely used in ten different favorite meat products. The application gives a correct results of maximum level of each food additives based on the type and weight of meat products. Therefore, this application may be beneficial to reduce the health risk from food additive abuse in meat products.","Food additives, Preservatives, Meat products, Mobile application, Food additive calculation",ICIEI 2019,high skewness or concentration about the mean of a single attribute,a strong clustering of values,and so on. For each insight type,Foresight initially presents visualizations of the top k instances in the data,"based on an appropriate ranking metric. The user can then look at \""nearby\"" insights by issuing \""insight queries\"" containing constraints on insight strengths and data attributes. Thus the user can directly explore the space of insights","rather than the space of data dimensions and visual encodings as in other visual recommender systems. Foresight also provides \""global\"" views of insight space to help orient the user and ensure a thorough exploration process. Furthermore",Foresight facilitates interactive exploration of large datasets through fast,"approximate sketching.""",,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Liu G,Yan X,Sun Y",Driver Pose Estimation Using a Mixture-Model Method,,2013,,,200–204,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Second International Conference on Innovative Computing and Cloud Computing,"Wuhan, China",2013,9781450321198,,https://doi.org/10.1145/2556871.2556914;http://dx.doi.org/10.1145/2556871.2556914,10.1145/2556871.2556914,"Estimating driver pose from videos is a significant task in driver assistance systems. In this paper, we introduced a mixture model for driver pose estimation. By the mixture model, a driver's upper body is composed of a set of non-oriented parts, and the spatial relationships of parts are modeled by a collection of springs. We described the algorithm of estimation. The steps of the algorithm, such as calculating HOG features, distance transformation, message passing, and back tracking, are discussed in details. The experiment demonstrates that our implementation can achieve good performance.","HOG feature, Non Maximum Suppression, Flexible mixture model, Distance Transformation",ICCC '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,Etzion O,"Event Processing: Past, Present and Future",Proc. VLDB Endow.,2010,3,1–2,1651–1652,VLDB Endowment,,,,,2010-09,,2150-8097,https://doi.org/10.14778/1920841.1921065;http://dx.doi.org/10.14778/1920841.1921065,10.14778/1920841.1921065,"Analysts have marked Event Processing as the most growing segment in enterprise computing during years 2008 and 2009, furthermore, this trend is expected to continue. Many of the large and medium software companies (IBM, Oracle, Microsoft, Sybase, Progress Software, Software AG and TIBCO) are now offering event processing products as well as a collection of smaller companies. Other indications for the emerging nature of this area are: extensive coverage by analysts as a separate area, the establishment of a dedicated research community with an annual conference (DEBS), and the establishment of a consortium that includes vendors and academic people as EPTS (Event Processing Technical Society) http://www.ep-ts.com/.The early event processing commercial products were mostly descendents of research projects rooted in multiple disciplines, some of them are data management disciplines (active databases, data stream management, temporal databases) and some are rooted in other areas (discrete event simulation, distributed computing, formal verification).The tutorial is intended for a technical audience that is interested in deep dive into understanding event processing. The audience will gain insights about event processing: What it really means? Where does it come from? How does it relate to research concepts (e.g. stream computing) as well as enterprise computing terms (e.g. Business Rules Management Systems)? The audience will also gain insights into the current state of the art, the leading architectures, the basic building blocks of event processing, and the various programming styles exemplified by code examples. Last but not least, the audience will gain insights about the current trends, and the research challenges that exist, this part will be based on the discussions in the Event Processing Dagstuhl seminar that was held in May 2010 http://www.dagstuhl.de/de/programm/kalender/semhp/?semnr=10201. The tutorial slides are available for public viewing on slideshare http://www.slideshare.net/search/slideshow?q=opher+etzion+%2B+vldb2010+tutorial The current generation of event processing products [14] has been preceded by several research projects in the 1990-ies: Rapide in Stanford [15], Infospheres in Cal Tech [2], Apama in Cambridge University [6] and Amit in IBM Haifa Research Lab [1]. In later phase there were some research project that have taken the stream oriented approach such as the Stanford Stream project [3] and Aurora [5].A collection of start-up companies, many of them descendents of these projects have emerged, some survived, and some did not. From those who survived some were acquired by bigger companies.Event processing as a research discipline has multiple ancestors. In the database area it is a descendent of work done in active databases [19], temporal databases [12], and data stream management systems [9]. Other ancestors are inference rules, discrete event simulation, and distributed computing (pub/sub).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Sarna K,Vain J",Exploiting Aspects in Model-Based Testing,,2012,,,45–48,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Eleventh Workshop on Foundations of Aspect-Oriented Languages,"Potsdam, Germany",2012,9781450310994,,https://doi.org/10.1145/2162010.2162023;http://dx.doi.org/10.1145/2162010.2162023,10.1145/2162010.2162023,"We introduce an approach to exploiting aspects in model-based testing and describe how an aspect-oriented model for testing purposes can be constructed. At first, we introduce the aspects to be addressed in testing safety and time critical systems and describe how the aspects enhance in defining test cases. We present a way how behavioural aspect models are defined formally as refinements of extended timed automata models, and how the aspect models are used for generating abstract online testers. Applying these techniques aspect-wise allows one to structure the model-based testing process in terms of well-defined model transformation steps. The approach is illustrated with an ATM case study.","aspect oriented modelling, test generation, model refinement, model-based testing",FOAL '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ibrahim S,Harrison C,Larsen M",JIT’s Complicated: A Comprehensive System For Derived Field Generation,,2020,,,27–31,Association for Computing Machinery,"New York, NY, USA",,ISAV'20 In Situ Infrastructures for Enabling Extreme-Scale Analysis and Visualization,"Atlanta, GA, USA",2020,9781450388122,,https://doi.org/10.1145/3426462.3426467;http://dx.doi.org/10.1145/3426462.3426467,10.1145/3426462.3426467,"Derived field calculations are a vital part of the visualization and analysis workflow. These calculations allow simulation users to create important quantities of interest that are not generated by the simulation, and systems that calculate derived quantities must be flexible enough to accommodate a wide variety of user requests. In situ analysis imposes additional constraints on the system, and derived field calculations must be able to leverage the same resources as the simulation to minimize the runtime and memory usage. Just-in-time (JIT) compilation defers code creation until runtime, and a JIT based system is capable of fusing a complex expression into a single kernel invocation (i.e., kernel fusion). Without kernel fusion, the system would be forced to evaluate each piece of the expression (e.g., an operator or function call) as separate kernel invocations, which increases both runtime and memory pressure on the host simulation. In this paper, we present a production-oriented in situ derived field system that leverages JIT compilation to target heterogeneous HPC architectures. Additionally, we explore the runtime costs of using this system to calculate three expressions in three simulation codes.",,ISAV'20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yilmaz E,Shofner G,Winemberg L,Ozev S",Fault Analysis and Simulation of Large Scale Industrial Mixed-Signal Circuits,,2013,,,565–570,EDA Consortium,"San Jose, CA, USA",,"Proceedings of the Conference on Design, Automation and Test in Europe","Grenoble, France",2013,9781450321532,,,,"High test quality can be achieved through defect oriented testing using analog fault modeling approach. However, this approach is computationally demanding and typically hard to apply to large scale circuits. In this work, we use an improved inductive fault analysis approach to locate potential faults at layout level and calculate the relative probability of each fault. Our proposed method yields actionable results such as fault coverage of each test, potential faults, and probability of each fault. We show that the computational requirement can be significantly reduced by incorporating fault probabilities. These results can be used to improve fault coverage or to improve defect resilience of the circuit.",,DATE '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bonato RR,Yang KC",GO System: Design and Implementation of an Output Generator,,1977,,,349–356,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the June 13-16, 1977, National Computer Conference","Dallas, Texas",1977,9781450379144,,https://doi.org/10.1145/1499402.1499466;http://dx.doi.org/10.1145/1499402.1499466,10.1145/1499402.1499466,"This paper concerns a conceptual model for a general purpose output generator and its implementation. The Generated Output (GO) System is based on two major criteria: (1) user oriented and (2) easy maintenance. Its goal is to produce tailored output in an unambiguous, camera-ready form. Basically, the system is comprised of a derived file, a descriptor file and an interface module which integrates the two files according to externally supplied specifications. Derived data are usually numeric results such as percentages, totals, subtotals, etc. Descriptors are defined as alphanumeric labels whose function is to clearly identify derived data. Classification of different types of calculated and label files are discussed with accompanying examples and illustrations.",,AFIPS '77,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li Y,Rubin J,Chechik M",Semantic Slicing of Software Version Histories,,2015,,,686–696,IEEE Press,"Lincoln, Nebraska",,Proceedings of the 30th IEEE/ACM International Conference on Automated Software Engineering,,2015,9781509000241,,https://doi.org/10.1109/ASE.2015.47;http://dx.doi.org/10.1109/ASE.2015.47,10.1109/ASE.2015.47,"Software developers often need to transfer functionality, e.g., a set of commits implementing a new feature or a bug fix, from one branch of a configuration management system to another. That can be a challenging task as the existing configuration management tools lack support for matching high-level semantic functionality with low-level version histories. The developer thus has to either manually identify the exact set of semantically-related commits implementing the functionality of interest or sequentially port a specific subset of the change history, \inheriting\"" additional",unwanted functionality.In this paper,we tackle this problem by providing automated support for identifying the set of semantically-related commits implementing a particular functionality,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yu L,Tan HF,Ma T,Wang CG,Zhou ZG",A Wavy Auxetic Surface and the Prediction Model Inspired by Miura-Ori,,2016,,,152–156,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Mechatronics and Control Engineering,"Venice, Italy",2016,9781450352154,,https://doi.org/10.1145/3036932.3036933;http://dx.doi.org/10.1145/3036932.3036933,10.1145/3036932.3036933,"Negative Poisson's ratio is one of the distinctive property of Miura-ori which is widely used in the deployable structures. A wavy surface was presented by replacing the polylines with trigonometric curves to eliminate the creases in the Miura-ori, and the auxetic response was inherited from the Miura-ori. The negative Poisson's ratios of the wavy surface in two orthogonal directions were obtained by parametric numerical analysis. A model to predict the Poisson's ratio was developed based on the auxetic mechanism of the Miura-ori. Least square method was used to calculate the parameters in the prediction models. The results show that the auxeticity in wavy surface is more evident than the Miura-ori in some cases. The design concept provides a new approach to construct smooth surface by exploring the repositories of the origami and tessellations.","Miura-ori, Auxetic surface, Prediction model",ICMCE '16,which is defined by a set of tests. We refer to our approach,CSLICER,as semantic slicing of version histories. We formally define the semantic slicing problem,provide an algorithm for identifying a set of commits that constitute a slice,"and instantiate it in a specific implementation for Java projects managed in Git. We evaluate the correctness and effectiveness of our approach on a set of open-source software repositories. We show that it allows to identify subsets of change histories that maintain the functionality of interest but are substantially smaller than the original ones.""","software changes, dependency, version history",ASE '15,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Duarte-Sanchez JE,Velasco-Medina J,Moreno PA",Hardware Accelerator for the Multifractal Analysis of DNA Sequences,IEEE/ACM Trans. Comput. Biol. Bioinformatics,2018,15,5,1611–1624,IEEE Computer Society Press,"Washington, DC, USA",,,,2018-09,,1545-5963,https://doi.org/10.1109/TCBB.2017.2731339;http://dx.doi.org/10.1109/TCBB.2017.2731339,10.1109/TCBB.2017.2731339,"The multifractal analysis has allowed to quantify the genetic variability and non-linear stability along the human genome sequence. It has some implications in explaining several genetic diseases given by some chromosome abnormalities, among other genetic particularities. The multifractal analysis of a genome is carried out by dividing the complete DNA sequence in smaller fragments and calculating the generalized dimension spectrum of each fragment using the chaos game representation and the box-counting method. This is a time consuming process because it involves the processing of large data sets using floating-point representation. In order to reduce the computation time, we designed an application-specific processor, here called multifractal processor, which is based on our proposed hardware-oriented algorithm for calculating efficiently the generalized dimension spectrum of DNA sequences. The multifractal processor was implemented on a low-cost SoC-FPGA and was verified by processing a complete human genome. The execution time and numeric results of the Multifractal processor were compared with the results obtained from the software implementation executed in a 20-core workstation, achieving a speed up of 2.6x and an average error of 0.0003 percent.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wu B,Zhang C,Guo Q",A Parallel Network Community Detection Algorithm Based on Distance Dynamics,,2017,,,819–826,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2017 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining 2017,"Sydney, Australia",2017,9781450349932,,https://doi.org/10.1145/3110025.3110135;http://dx.doi.org/10.1145/3110025.3110135,10.1145/3110025.3110135,"In recent years, community detection has drawn more and more researchers' attention. With the development of Internet, the scale of network data is growing fast. It is necessary to find an effective parallel community detection algorithm for large-scale network. In this paper, we propose a novel and parallel community detection algorithm, PCDU algorithm, based on distance dynamics. We send distances information to nodes and update distances of edges constantly, based on previous values and the unified model, which is introduced to quantify different influences from nodes and edges. It ends until the distances are stable. Then we remove some special edges from the original graph and get all subgraphs, which are the community partitions. It still inherits the advantage of uncovering small communities and outliers. Experiments based on synthetic networks and real world networks, show that our algorithm execute more efficient than stand-alone version. Since it is based on the Spark platform and designed in parallelization, the algorithm is very suitable for large datasets. We also provide a novel method taking use of double summation to calculate the NMI value of community partition result and the embedded community structure. Compared with the traditional way, it is not only as accurate as the traditional way and more efficient, but also has less space complexity. Experiments show that it is suitable for evaluating community division results in large-scale network.","community detection, distance dynamics, parallelization, NMI",ASONAM '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Malavolta I,Providing Support for Creating next Generation Software Architecture Languages,,2010,,,517–518,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2,"Cape Town, South Africa",2010,9781605587196,,https://doi.org/10.1145/1810295.1810459;http://dx.doi.org/10.1145/1810295.1810459,10.1145/1810295.1810459,"Many languages for software architectures have been proposed, each dealing with different stakeholder concerns, operating at different levels of abstraction and with different degrees of formality. It is known that a universal architectural language cannot exist since the various concerns, requirements, and domains may change. Moreover, stakeholder concerns and needs are various and ever evolving even while designing a single system. Model-driven techniques may be used to answer the need for supporting the creation of extensible, customizable and stakeholder-oriented architectural languages (i.e., next generation architectural languages). Part of this approach is developed in a framework called byADL.In this paper I present the big picture behind the approach, the research aspects considered in order to get byADL closer to an ideal architectural framework and future research issues.",modeling,ICSE '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"McDonald N,Schoenebeck S,Forte A",Reliability and Inter-Rater Reliability in Qualitative Research: Norms and Guidelines for CSCW and HCI Practice,Proc. ACM Hum. -Comput. Interact.,2019,3,CSCW,,Association for Computing Machinery,"New York, NY, USA",,,,2019-11,,,https://doi.org/10.1145/3359174;http://dx.doi.org/10.1145/3359174,10.1145/3359174,"What does reliability mean for building a grounded theory? What about when writing an auto-ethnography? When is it appropriate to use measures like inter-rater reliability (IRR)? Reliability is a familiar concept in traditional scientific practice, but how, and even whether to establish reliability in qualitative research is an oft-debated question. For researchers in highly interdisciplinary fields like computer-supported cooperative work (CSCW) and human-computer interaction (HCI), the question is particularly complex as collaborators bring diverse epistemologies and training to their research. In this article, we use two approaches to understand reliability in qualitative research. We first investigate and describe local norms in the CSCW and HCI literature, then we combine examples from these findings with guidelines from methods literature to help researchers answer questions like: \should I calculate IRR?\"" Drawing on a meta-analysis of a representative sample of CSCW and HCI papers from 2016-2018",we find that authors use a variety of approaches to communicate reliability; notably,IRR is rare,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Zuidema W,What Are the Productive Units of Natural Language Grammar? A DOP Approach to the Automatic Identification of Constructions,,2006,,,29–36,Association for Computational Linguistics,USA,,Proceedings of the Tenth Conference on Computational Natural Language Learning,"New York City, New York",2006,,,,,"We explore a novel computational approach to identifying \constructions\"" or \""multi-word expressions\"" (MWEs) in an annotated corpus. In this approach",MWEs have no special status,but emerge in a general procedure for finding the best statistical grammar to describe the training corpus. The statistical grammar formalism used is that of stochastic tree substitution grammars (STSGs),"occurring in around 1/9 of qualitative papers. We reflect on current practices and propose guidelines for reporting on reliability in qualitative research using IRR as a central example of a form of agreement. The guidelines are designed to generate discussion and orient new CSCW and HCI scholars and reviewers to reliability in qualitative research.""","IRR, content analysis, inter-rater reliability, interviews, qualitative methods",,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang J,Bai W,Chen K",Enabling ECN for Datacenter Networks with RTT Variations,,2019,,,233–245,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th International Conference on Emerging Networking Experiments And Technologies,"Orlando, Florida",2019,9781450369985,,https://doi.org/10.1145/3359989.3365426;http://dx.doi.org/10.1145/3359989.3365426,10.1145/3359989.3365426,"ECN has been widely employed in production datacenters to deliver high throughput low latency communications. Despite being successful, prior ECN-based transports have an important drawback: they adopt a fixed RTT value in calculating instantaneous ECN marking threshold while overlooking the RTT variations in practice.In this paper, we reveal that the current practice of using a fixed high-percentile RTT for ECN threshold calculation can lead to persistent queue buildups, significantly increasing packet latency. On the other hand, directly adopting lower percentile RTTs results in throughput degradation. To handle the problem, we introduce ECN#, a simple yet effective solution to enable ECN for RTT variations. At its heart, ECN# inherits the current instantaneous ECN marking (based on a high-percentile RTT) to achieve high throughput and burst tolerance, while further marking packets (conservatively) upon detecting long-term queue buildups to eliminate unnecessary queueing delay without degrading throughput. We implement ECN# on a Barefoot Tofino switch and evaluate it through extensive testbed experiments and large-scale simulations. Our evaluation confirms that ECN# can effectively reduce latency without hurting throughput. For example, compared to the current practice, ECN# achieves up to 23.4% (31.2%) lower average (99th percentile) flow completion time (FCT) for short flows while delivering similar FCT for large flows under production workloads.","ECN, AQM, datacenters, RTT variations",CoNEXT '19,such as used in Data-Oriented Parsing. We present an algorithm for calculating the expected frequencies of arbitrary subtrees given the parameters of an STSG,and a method for estimating the parameters of an STSG given observed frequencies in a tree bank. We report quantitative results on the ATIS corpus of phrase-structure annotated sentences,"and give examples of the MWEs extracted from this corpus.""",,CoNLL-X '06,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Alharbi AS,Li Y,Xu Y",Topical Term Weighting Based on Extended Random Sets for Relevance Feature Selection,,2017,,,654–661,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Web Intelligence,"Leipzig, Germany",2017,9781450349512,,https://doi.org/10.1145/3106426.3106440;http://dx.doi.org/10.1145/3106426.3106440,10.1145/3106426.3106440,"It is challenging to discover relevant features from long documents that describe user information needs due to the nature of text where synonymy, polysemy noise, and high dimensionality are inherited problems. Traditional feature selection methods could not effectively deal with these problems, because they assume that documents describe one topic only. Topic-based techniques, such as Latent Dirichlet Allocation (LDA), relax this assumption. They have been developed on the basis that a document can exhibit multiple hidden topics. However, LDA does not show encouraging results in selecting relevant features, because LDA calculates the weight of terms based on their local documents and does not generalise it globally at the collection level. So as to address this problem, we propose an innovative and effective extended random set model to generalise LDA weight for local document terms. The model is used as a weighting scheme for topical terms. It can assign a more discriminately accurate weight to these terms based on their appearance in LDA topics and relevant documents. The experimental results, based on the standard RCV1 dataset, TREC topics, and five standard performance measures, show that the proposed model significantly outperforms eight state-of-the-art baseline models in information filtering.","extended random set, text mining, term weighting, feature selection, latent dirichlet allocation",WI '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Agrawal S,Chaurasiya RK",Ensemble of SVM for Accurate Traffic Sign Detection and Recognition,,2017,,,10–15,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Graphics and Signal Processing,"Singapore, Singapore",2017,9781450352390,,https://doi.org/10.1145/3121360.3121373;http://dx.doi.org/10.1145/3121360.3121373,10.1145/3121360.3121373,"Automatic traffic sign detection and recognition plays a very significant role in advance driver assistance system and intelligent transportation system. In this paper, approach for circular traffic sign detection and recognition is proposed. The entire performance of the proposed system is calculated on German Traffic Sign Detection Benchmark (GTSDB) and German Traffic Sign Recognition Benchmark (GTSRB) datasets. Traffic signs are detected on color images based on RGB color thresholding technique and further detecting circle using circular Hough Transform. In traffic sign recognition, features are extracted using Histogram of Oriented Gradient (HOG) and strong components of the image are selected by Principal Component Analysis (PCA) and classified using Ensemble of SVM as the size of the dataset is increasing day by day. Results obtained undergoes statistical test showing the better performance of the algorithm proposed.","statistical test, PCA, circular hough transform, Ensemble of SVM, HOG, Color thresholding",ICGSP '17,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Li Z,O'Brien L,Zhang H,Keung J",Towards SOA Implementation Complexity Measurement Enlightened by Organization Theory,,2010,,,12–15,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 11th International Conference on Product Focused Software,"Limerick, Ireland",2010,9781450302814,,https://doi.org/10.1145/1961258.1961261;http://dx.doi.org/10.1145/1961258.1961261,10.1145/1961258.1961261,"When implementing information infrastructures to support business, Service-Oriented Architecture (SOA) based systems are inevitably more complex than traditional architecture based systems. Therefore, it is essential to measure the implementation complexity to avoid development that is unworthy of adopting SOA. However, there is little work that covers the SOA implementation complexity measurement with comprehensive analysis. By adopting existing work related to organizational complexity, this paper proposes a framework for comprehending and measuring the organizational complexity of SOA implementation, which comprises four dimensions: Structure, Environment, Business and Resource. Along each dimension, some SOA-compatible metrics have been extracted from the corresponding research on organizational complexity. More importantly, this proposed framework can be used for future work in proposing metrics for integrally and quantitatively calculating the complexity of implementing SOA.","measurement, organization theory, SOA implementation complexity, service-oriented architecture (SOA), organizational complexity",PROFES '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tuan CC,Hung CF,Lin YH",An Information Relevancy-Oriented Cache Replacement Policy in PCS,,2009,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 6th International Conference on Mobile Technology, Application & Systems","Nice, France",2009,9781605585369,,https://doi.org/10.1145/1710035.1710091;http://dx.doi.org/10.1145/1710035.1710091,10.1145/1710035.1710091,"Due to the inherited limitations on the connection qualities and available bandwidth in the mobile networking environment, mobile units (MUs) have been unable to effectively access location based services. This paper proposes a two tier Location Dependent Information Services (LDISs) architecture to calculate pre-fetching information values (PIV) for each location dependent data (LDDs). In this architecture, a proxy server will provide MUs with the LDDs that are attached with the relevancy value to reduce response time and workload for the remote database server.","pre-fetching, proxy server, location dependent information services",Mobility '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"García JM,Piorno JR,Mata-Garcia MG",Automatic Detection of Vehicles in Outdoor Parking Lots from Zenith Perspective Using Neural Networks,,2020,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 2020 Summer Simulation Conference,"Virtual Event, Spain",2020,9781713814290,,,,"Nowadays there are a variety of methods to assist parking users in finding free sites in parking lots. However, there is no automatic system that takes into account the size of the car looking for a space or whether the cars adjacent to the free spaces are correctly parked. This paper presents a new method for detecting and calculating the area of vehicles in images taken from a zenith plane using computer vision and machine learning techniques that will help to create a vehicle-oriented search algorithm dedicated to finding the optimal spaces for vehicles entering an outdoor parking lot based on its characteristics. Results with scaled-down and real vehicles show that this new method can detect the area of the vehicles in an image with an average accuracy of 97.98%.","machine learning, computer vision, neural network, parking lot assistance",SummerSim '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Popović M,Ney H",Syntax-Oriented Evaluation Measures for Machine Translation Output,,2009,,,29–32,Association for Computational Linguistics,USA,,Proceedings of the Fourth Workshop on Statistical Machine Translation,"Athens, Greece",2009,,,,,"We explored novel automatic evaluation measures for machine translation output oriented to the syntactic structure of the sentence: the Bleu score on the detailed Part-of-Speech (pos) tags as well as the precision, recall and F-measure obtained on pos n-grams. We also introduced F-measure based on both word and pos n-grams. Correlations between the new metrics and human judgments were calculated on the data of the first, second and third shared task of the Statistical Machine Translation Workshop. Machine translation outputs in four different European languages were taken into account: English, Spanish, French and German. The results show that the new measures correlate very well with the human judgements and that they are competitive with the widely used BLEU, METEOR and TER metrics.",,StatMT '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cong M,Bao M,E JL,Bhat KS,Fedkiw R",Fully Automatic Generation of Anatomical Face Simulation Models,,2015,,,175–183,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 14th ACM SIGGRAPH / Eurographics Symposium on Computer Animation,"Los Angeles, California",2015,9781450334969,,https://doi.org/10.1145/2786784.2786786;http://dx.doi.org/10.1145/2786784.2786786,10.1145/2786784.2786786,"We present a fast, fully automatic morphing algorithm for creating simulatable flesh and muscle models for human and humanoid faces. Current techniques for creating such models require a significant amount of time and effort, making them infeasible or impractical. In fact, the vast majority of research papers use only a floating mask with no inner lips, teeth, tongue, eyelids, eyes, head, ears, etc.---and even those that build the full visual model would typically still lack the cranium, jaw, muscles, and other internal anatomy. Our method requires only the target surface mesh as input and can create a variety of models in only a few hours with no user interaction. We start with a symmetric, high resolution, anatomically accurate template model that includes auxiliary information such as feature points and curves. Then given a target mesh, we automatically orient it to the template, detect feature points, and use these to bootstrap the detection of corresponding feature curves. These curve correspondences are used to deform the surface mesh of the template model to match the target mesh. Then, the calculated displacements of the template surface mesh are used to drive a three-dimensional morph of the full template model including all interior anatomy. The resulting target model can be simulated to generate a large range of expressions that are consistent across characters using the same muscle activations. Full automation of this entire process makes it readily available to a wide range of users.","muscles, model creation, facial animation",SCA '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Musil J,Schweda A,Winkler D,Biffl S",Synthesized Essence: What Game Jams Teach about Prototyping of New Software Products,,2010,,,183–186,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 32nd ACM/IEEE International Conference on Software Engineering - Volume 2,"Cape Town, South Africa",2010,9781605587196,,https://doi.org/10.1145/1810295.1810325;http://dx.doi.org/10.1145/1810295.1810325,10.1145/1810295.1810325,"The development of video games comprises engineering teams within various disciplines, e.g., software engineering, game production, and creative arts. Game jams are a promising approach for (software+) development projects to foster on new product development. This paper evaluates the concept of game jam, a community design/development activity, and its positive effects on new software product development with tight schedules in time-oriented, competitive environments. Game jams have received more public attention in recent times, but the concept itself has not been formally discussed so far. A game jam is a composition of design and development strategies: new product development, participatory design, lightweight construction, rapid experience prototyping, product-value focusing, aesthetics and technology, concurrent development and multidisciplinarity. Although game jams are normally used for rapid prototyping of small computer games, the constellation of the mentioned elements provides a powerful technique for rapidly prototyping new product ideas and disruptive innovations.","participatory design, agile, new product development, prototyping, innovation, game development",ICSE '10,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yang B,Wang Z,Yu X",Extraction of ORB Features with an Improved Method,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 3rd International Conference on Vision, Image and Signal Processing","Vancouver, BC, Canada",2019,9781450376259,,https://doi.org/10.1145/3387168.3387169;http://dx.doi.org/10.1145/3387168.3387169,10.1145/3387168.3387169,"Improvement of the extraction means of the ORB (Oriented FAST and Rotated BRIEF) feature primarily includes optimization concerning excessive aggregation of ORB features and the improvement of the problem that the correct features could not be extracted when regional image illumination is too bright. First, the local self-adaptive threshold was calculated on the basis of the threshold and FAST features were extracted based on the local threshold as the candidate feature points. Then, image iteration was divided into disparate regions and the optimal feature points of the local region were selected as the extraction result. The experimental data showed that the aggregation level of the improved ORB feature lowered more obviously than that of the ORB feature, which adapted to local illumination and the threshold value with high stability; however, the time still met real-time demands.","FAST, ORB, Feature extraction",ICVISP 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Göttmann H,Luthmann L,Lochau M,Schürr A",Real-Time-Aware Reconfiguration Decisions for Dynamic Software Product Lines,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 24th ACM Conference on Systems and Software Product Line: Volume A - Volume A,"Montreal, Quebec, Canada",2020,9781450375696,,https://doi.org/10.1145/3382025.3414945;http://dx.doi.org/10.1145/3382025.3414945,10.1145/3382025.3414945,"Dynamic Software Product Lines (DSPL) have recently shown promising potentials as integrated engineering methodology for (self-)adaptive software systems. Based on the software-configuration principles of software product lines, DSPL additionally foster reconfiguration capabilities to continuously adapt software products to ever-changing environmental contexts. However, in most recent works concerned with finding near-optimal reconfiguration decisions, real-time aspects of reconfiguration processes are usually out of scope. In this paper, we present a model-based methodology for specifying and automatically analyzing real-time constraints of reconfiguration decisions in a feature-oriented and compositional way. Those real-time aware DSPL specifications are internally translated into timed automata, a well-founded formalism for real-time behaviors. This representation allows for formally reasoning about consistency and worst-case/best-case execution-time behaviors of sequences of reconfiguration decisions. The technique is implemented in a prototype tool and experimentally evaluated with respect to a set of case studies1.","reconfiguration decisions, dynamic software product lines, timed automata",SPLC '20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Schneider V,German R",Integration of Test-Driven Agile Simulation Approach in Service-Oriented Tool Environment,,2013,,,,Society for Computer Simulation International,"San Diego, CA, USA",,Proceedings of the 46th Annual Simulation Symposium,"San Diego, California",2013,9781627480307,,,,"The approach of test-driven agile simulation combines model-based simulation and testing techniques to achieve an improved overall quality during the development process. It intends to provide a cheap and agile technique to validate the models in several iteration steps during early engineering phases. Designated phases of this process can be automated and supported by specialized tools. Originally, the suggested tools have been integrated in one framework, which was only accessible on a single machine. In this paper we show how this approach could be integrated in a distributed, service-oriented tool environment to profit by the advantages of the service-based architecture, such as higher accessibility, interoperability and extensibility. Towards this goal, we specify loosely coupled services for validation, transformation and simulation of models, which may exchange data through formally defined interfaces. Based on common technologies and standards these services are integrated in a heterogeneous development environment to support the whole development lifecycle.","service-oriented computing and simulation, verification and validation, simulation tools and environments, test-driven agile simulation",ANSS 13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang Y,Wang J,Wang Y,Zhou L",Parallel Community Detection on Large Networks with Propinquity Dynamics,,2009,,,997–1006,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 15th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,"Paris, France",2009,9781605584959,,https://doi.org/10.1145/1557019.1557127;http://dx.doi.org/10.1145/1557019.1557127,10.1145/1557019.1557127,"Graphs or networks can be used to model complex systems. Detecting community structures from large network data is a classic and challenging task. In this paper, we propose a novel community detection algorithm, which utilizes a dynamic process by contradicting the network topology and the topology-based propinquity, where the propinquity is a measure of the probability for a pair of nodes involved in a coherent community structure. Through several rounds of mutual reinforcement between topology and propinquity, the community structures are expected to naturally emerge. The overlapping vertices shared between communities can also be easily identified by an additional simple postprocessing. To achieve better efficiency, the propinquity is incrementally calculated. We implement the algorithm on a vertex-oriented bulk synchronous parallel(BSP) model so that the mining load can be distributed on thousands of machines. We obtained interesting experimental results on several real network data.","data mining, parallel algorithm, community detection, graph mining, bulk synchronous parallel",KDD '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Gao X,Liu Y,Qiu Y,Liu H",A Comprehensive Assessment Method of Asset Importance for Key Asset Protection,,2019,,,79–83,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 the 9th International Conference on Communication and Network Security,"Chongqing, China",2019,9781450376624,,https://doi.org/10.1145/3371676.3371679;http://dx.doi.org/10.1145/3371676.3371679,10.1145/3371676.3371679,"In a given system network, an important prerequisite for security risk control is how to accurately calculate the impact of different host assets in the topology on the spread of attack risk. In this regard, we propose a comprehensive asset importance assessment model for critical asset protection. First, the importance of local static assets in the topology was evaluated using three methods: degree centrality, mediation centrality, and closeness centrality. At the same time, PageRank was used to assess the importance of local dynamic assets for asset level changes. By combining the above two methods, and using K-CORE to evaluate the core position of the host in the network topology as the global weight indicator of the importance of assets. The comprehensive evaluation results of the importance of topology-oriented assets was finally obtained, and the validity of the model was verified through the experiment of the simulation ER random network.","Asset importance, K-CORE, PageRank, Centrality, Key asset protection",ICCNS 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Vadapalli R,Suryavanshi K,Vucha R,Sarkar A,Krishna KM",Modular Pipe Climber,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Advances in Robotics 2019,"Chennai, India",2019,9781450366502,,https://doi.org/10.1145/3352593.3352672;http://dx.doi.org/10.1145/3352593.3352672,10.1145/3352593.3352672,"This paper discusses the design and implementation of the Modular Pipe Climber inside ASTM D1785 - 15e1 standard pipes [1]. The robot has three tracks which operate independently and are mounted on three modules which are oriented at 120° to each other. Tracks provide for greater surface traction compared to wheels [2]. The tracks are pushed onto the inner wall of the pipe by passive springs to maintain contact with the pipe during vertical climb and while turning in bends. The modules have the provision to compress asymmetrically, which enables the robot to take turns in bends in all directions. The motor torque required by the robot and the desired spring stiffness are calculated at quasi-static and static equilibriums during vertical climb. The robot is further simulated and analyzed in ADAMS MSC. The prototype built based on the obtained values is experimented on, in complex pipe networks. Differential speed is employed when turning in bends to improve the efficiency and reduce the stresses experienced by the robot.","tracked robot, modular robot, pipe inspection, Pipe climber",AIR 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhu R,Cassel D,Sabry A,Huang Y",NANOPI: Extreme-Scale Actively-Secure Multi-Party Computation,,2018,,,862–879,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security,"Toronto, Canada",2018,9781450356930,,https://doi.org/10.1145/3243734.3243850;http://dx.doi.org/10.1145/3243734.3243850,10.1145/3243734.3243850,"Existing actively-secure MPC protocols require either linear rounds or linear space. Due to this fundamental space-round dilemma, no existing MPC protocols is able to run large-scale computations without significantly sacrificing performance. To mitigate this issue, we developed nanoPI, which is practically efficient in terms of both time and space. Our protocol is based on WRK but introduces interesting and necessary modifications to address several important programmatic and cryptographic challenges. A technique that may be of independent interest (in transforming other computation-oriented cryptographic protocols) is a staged execution model, which we formally define and realize using a combination of lightweight static and dynamic program instrumentation. Our techniques are integrated in nanoPI, an open-source tool for efficiently building and running actively-secure extreme-scale MPC applications. We demonstrate the unprecedented scalability and performance of nanoPI by building and running a suit of bench- mark applications, including an actively-secure four-party logistical regression (involving 4.7 billion ANDs and 8.9 billion XORs) which finished in less than 28 hours on four small-memory machines.","static and dynamic instrumentation for MPC, programming support of MPC, large-scale secure multiparty computation",CCS '18,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Librelotto GR,Ramalho JC,Henriques PR","A Framework to Specify, Extract and Manage Topic Maps Driven by Ontology",,2008,,,155–162,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th Annual ACM International Conference on Design of Communication,"Lisbon, Portugal",2008,9781605580838,,https://doi.org/10.1145/1456536.1456567;http://dx.doi.org/10.1145/1456536.1456567,10.1145/1456536.1456567,"The ability to extract and merge data that from documents (or databases) of different types, in order to acquire knowledge from a vast repository of information, is of unquestionable value. However that desirable integration is not an easy task. Different approaches can be followed to achieve it, ranging from the merge of resources (implying their conversion to a common format) till the fusion of the extracted parts. The idea is to interoperate those resources keeping them independent, without changes or transformations, creating over them an integration layer that gives us a general overview, as the information slices were gathered. This is possible creating a semantic network, or a conceptual map, over the resources, which relates data items among them mapping each one to its different occurrences in the repository; formally speaking, that conceptual map corresponds to the ontology that describes the knowledge we want to acquire. In this paper, we introduce Metamorphosis, a Topic Maps oriented environment to extract data from heterogeneous information repositories and to generate a browser and conceptual navigator for the extracted knowledge.","information systems, semantic web, ontologies, interoperability, topic maps",SIGDOC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"He F,Xu Y,Wang X,Feng A",ALT-Based Route Planning in Dynamic Time-Dependent Road Networks,,2019,,,35–39,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 2nd International Conference on Machine Learning and Machine Intelligence,"Jakarta, Indonesia",2019,9781450372480,,https://doi.org/10.1145/3366750.3366752;http://dx.doi.org/10.1145/3366750.3366752,10.1145/3366750.3366752,"In order to solve the path planning problem of time-dependent road network(TDRN), an dynamic A* landmarks triangle algorithm(ALT) is proposed based on landmark-oriented technique and short-path tree(SPT). There are three main contributions: (1) constructing the shortest path tree in the preprocessing stage and calculating the distance between the landmark and other nodes; (2) using the dynamic shortest path tree to optimize the query in the point-to-point heuristic path planning process; (3) When the edge weight of the network changes, the shortest path tree is dynamically updated, and the structural characteristics of the tree are used to reduce the redundancy calculation. Experimental results indicate that the DALT algorithm not only outperforms the ALT implementation in point-to-point shortest path problem as the average query time is reduced by up to 51.71%, but also computes economically for updating shortest path tree compared with previous dynamic update algorithm as the average update times for increments are reduced by up to 9.90% with less modifications.","time-dependent road networks, dynamic update, Goal directed, landmarks, shortest path tree",MLMI 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Librelotto GR,Ramalho JC,Henriques PR","A Framework to Specify, Extract and Manage Topic Maps Driven by Ontology",,2008,,,155–162,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 26th Annual ACM International Conference on Design of Communication,"Lisbon, Portugal",2008,9781605580838,,https://doi.org/10.1145/1456536.1456567;http://dx.doi.org/10.1145/1456536.1456567,10.1145/1456536.1456567,"The ability to extract and merge data that from documents (or databases) of different types, in order to acquire knowledge from a vast repository of information, is of unquestionable value. However that desirable integration is not an easy task. Different approaches can be followed to achieve it, ranging from the merge of resources (implying their conversion to a common format) till the fusion of the extracted parts. The idea is to interoperate those resources keeping them independent, without changes or transformations, creating over them an integration layer that gives us a general overview, as the information slices were gathered. This is possible creating a semantic network, or a conceptual map, over the resources, which relates data items among them mapping each one to its different occurrences in the repository; formally speaking, that conceptual map corresponds to the ontology that describes the knowledge we want to acquire. In this paper, we introduce Metamorphosis, a Topic Maps oriented environment to extract data from heterogeneous information repositories and to generate a browser and conceptual navigator for the extracted knowledge.","topic maps, information systems, semantic web, ontologies, interoperability",SIGDOC '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Rajbhandari S,Rana OF,Wootten I",A Fuzzy Model for Calculating Workflow Trust Using Provenance Data,,2008,,,,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the 15th ACM Mardi Gras Conference: From Lightweight Mash-Ups to Lambda Grids: Understanding the Spectrum of Distributed Computing Requirements, Applications, Tools, Infrastructures, Interoperability, and the Incremental Adoption of Key Capabilities","Baton Rouge, Louisiana, USA",2008,9781595938350,,https://doi.org/10.1145/1341811.1341823;http://dx.doi.org/10.1145/1341811.1341823,10.1145/1341811.1341823,"Workflow forms a key part of many existing Service Oriented applications, involving the integration of services that may be made available at distributed sites. It is possible to distinguish between an \abstract\"" workflow description - outlining which services must be involved in a workflow execution - and a \""physical\"" workflow description - outlining the particular instance of services that were used in a particular enactment. Provenance information provides a useful way to capture the physical workflow description automatically",especially if this information is captured in a standard format. Subsequent analysis of this provenance information may be used to evaluate whether the abstract workflow description has been adhered to,"and to enable a user executing a workflow-based application to establish \""trust\"" in the outcome; trust",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Chen S,Mei H",Function Design Strategies of University Campuses in Cold Regions of China Based on Analysis of Behavior Patterns,,2020,,,61–65,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 5th International Conference on Information and Education Innovations,"London, United Kingdom",2020,9781450375757,,https://doi.org/10.1145/3411681.3412948;http://dx.doi.org/10.1145/3411681.3412948,10.1145/3411681.3412948,"China has entered the stage of universal higher education in 2019. As an essential space support, the design of new campus and the renewal of existing campus have become important topics. University Campus contains complex and diverse functional space, supporting students, teachers and other different groups of people's life and learning activities, from the perspective of human-oriented, this research set out with the aim to quantitively measure and understand the function design strategies. The research introduced the \social space perspective\"" theory",collected the usage frequency of different campus function spaces from students,teachers and residents around the campus through questionnaires,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Shuoqiu Y,Chaojun X",Research on Constructing Sentiment Dictionary of Online Course Reviews Based on Multi-Source Combination,,2019,,,71–76,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 2nd International Conference on Data Science and Information Technology,"Seoul, Republic of Korea",2019,9781450371414,,https://doi.org/10.1145/3352411.3352452;http://dx.doi.org/10.1145/3352411.3352452,10.1145/3352411.3352452,"The construction of sentiment dictionary is an important task in text sentiment analysis. Using the sentiment words of specific fields to establish a domain-oriented sentiment dictionary can significantly improve the effect on sentiment recognition and classification in the specific field. A method of constructing a sentiment dictionary for online course reviews was proposed, which based on multi-source combination. In the first place, the sentiment words were identified and extracted using TextRank and the word2vec model, which combined with the general sentiment dictionary and the online course reviews corpus. Then, the label propagation algorithm was applied to discriminate the sentiment polarity of sentiment words, thus constructing a sentiment dictionary for online course reviews. Through the accuracy experiment on the determination of the sentiment polarity of words and the experiment on sentiment classification based on different dictionaries, the accuracy rate, the recall rate and the F value are calculated. The experimental results show that the proposed method was an accuracy and effective way to achieve the sentiment classification of online course reviews.","Label propagation, Online course reviews, Sentiment dictionary, TextRank, Word vector",DSIT 2019,in this context,is an abstract mathematical construct that can be computed using provenance information. Performing analysis on such provenance information,"we propose a fuzzy model for calculating trust based on an enacted workflow.""","workflow, SOA, provenance, fuzzy inference, trust",MG '08,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Corral L,Fronza I",Better Code for Better Apps: A Study on Source Code Quality and Market Success of Android Applications,,2015,,,22–32,IEEE Press,"Florence, Italy",,Proceedings of the Second ACM International Conference on Mobile Software Engineering and Systems,,2015,9781479919345,,,,"The quality of a mobile application is a major concern for developers, users and application stores. Even though several mobile-specific techniques have been proposed to evaluate the quality of a mobile software product, there is little evidence about their applicability as an efficient way to forecast a potential success of a mobile software product in a real app store. In this paper, we investigated the contribution of the code quality in the market success of Android apps in the Google Play store. We retrieved the source code of 100 Open Source mobile apps, we calculated a set of product metrics, and we obtained several market indicators from an application store. Utilizing statistical methods we determined whether there is a relationship between product quality and market success. The results obtained shown consistently that the quality of the source code has a marginal impact into the indices that describe the market success, suggesting that the real drivers of customer satisfaction and market penetration in the mobile app business go beyond purely source-oriented quality attributes.","code, app, mobile, store, market, quality",MOBILESoft '15,And the data obtained was input into the Gephi software for social network analysis. The different function spaces of the university campus were taken as nodes to calculate their weighted degree and betweenness centrality. The distribution law of important function nodes was summarized and three design strategies of campus functional space were put forward,including systematic design strategy of the function to meet the different requirements,"intensive design strategy for core function spaces and decentralized design strategy for service function spaces.""","social network analysis, behavior pattern, university campus in cold regions, function design strategy",ICIEI 2020,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Müller S,Plattner H",Aggregation Strategies for Columnar In-Memory Databases in a Mixed Workload,,2011,,,51–58,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 4th Workshop on Workshop for Ph.D. Students in Information & Knowledge Management,"Glasgow, Scotland, UK",2011,9781450309530,,https://doi.org/10.1145/2065003.2065015;http://dx.doi.org/10.1145/2065003.2065015,10.1145/2065003.2065015,"The recent trend towards analytics on operational data has led to an approach of reunifying online transactional processing and online analytical processing in one single database. The advent of columnar in-memory databases makes this viable and feasible as expensive join and aggregation operations can be performed with superior performance compared to traditional row-oriented databases. This has led to the radical proposal of abandoning materialized aggregate tables and calculate all aggregations on the fly.This PhD research project investigates factors that have an influence on the aggregation performance in columnar in-memory databases. Based on the identified factors, we aim to evaluate different cost model approaches, that are subject to validation with real-life data of large industry customers and their mixed workloads. The goal of this project is the design and implementation of an aggregation engine that decides, based on the data and application characteristics, the historic and current workload and other cost-relevant factors, whether it is beneficial with regards to query performance, but also considering aggregation view maintenance costs, to materialize an aggregate or not.","data aggregation, oltp, column store, in-memory database, materialized view, olap, cost model",PIKM '11,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Yang JM,Kang HG",Online Speech Dereverberation Algorithm Based on Adaptive Multichannel Linear Prediction,"IEEE/ACM Trans. Audio, Speech and Lang. Proc.",2014,22,3,608–619,IEEE Press,,,,,2014-03,,2329-9290,https://doi.org/10.1109/TASLP.2013.2294578;http://dx.doi.org/10.1109/TASLP.2013.2294578,10.1109/TASLP.2013.2294578,"This paper proposes a real-time acoustic channel equalization method that uses an adaptive multichannel linear prediction technique. In general, multichannel equalization algorithms can eliminate reverberation if they meet the following specific conditions including: the co-primeness between channels and sufficient filter length. It also requires the characteristic of correct channel information, however, it is difficult to estimate accurate acoustic channels in a practical system. The proposed method utilizes a theoretically perfect channel equalization algorithm and considers problems that may arise in the actual system. Linear-predictive multi-input equalization (LIME) is also an appropriate attempt at blind dereverberation by assuring the theoretical basis. However, a huge computational cost is incurred by calculating the large dimensions of a covariance matrix and its inversion. The proposed equalizer is developed as a multichannel linear prediction (MLP) oriented structure with a new formula that is optimized to time-varying acoustical room environments. Moreover, experimental results show that the proposed method works well even if the channel characteristics of each microphone are similar. The results of experiments using various room impulse response (RIR) models, including both the synthesized and real room environments, show that the proposed method is superior to conventional methods.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Scherrer S,Legner M,Perrig A,Schmid S",Incentivizing Stable Path Selection in Future Internet Architectures,SIGMETRICS Perform. Eval. Rev.,2021,48,3,12–13,Association for Computing Machinery,"New York, NY, USA",,,,2021-03,,0163-5999,https://doi.org/10.1145/3453953.3453956;http://dx.doi.org/10.1145/3453953.3453956,10.1145/3453953.3453956,"By delegating path control to end-hosts, future Internet architectures offer flexibility for path selection. However, a concern arises that the distributed routing decisions by endhosts, in particular load-adaptive routing, can lead to oscillations if path selection is performed without coordination or accurate load information. Prior research has addressed this problem by devising local path-selection policies that lead to global stability. However, little is known about the viability of these policies in the Internet context, where selfish end-hosts can deviate from a prescribed policy if such a deviation is beneficial from their individual perspective. In order to achieve network stability in future Internet architectures, it is essential that end-hosts have an incentive to adopt a stability-oriented path-selection policy.In this work, we perform the first incentive analysis of the stability-inducing path-selection policies proposed in the literature. Building on a game-theoretic model of end-host path selection, we show that these policies are in fact incompatible with the self-interest of end-hosts, as these strategies make it worthwhile to pursue an oscillatory path-selection strategy. Therefore, stability in networks with selfish endhosts must be enforced by incentive-compatible mechanisms. We present two such mechanisms and formally prove their incentive compatibility.","network stability, mechanism design, path-aware internet, path selection, traffic oscillation, game theory",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Djoko SD,Douence R,Fradet P",Aspects Preserving Properties,,2008,,,135–145,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation,"San Francisco, California, USA",2008,9781595939777,,https://doi.org/10.1145/1328408.1328429;http://dx.doi.org/10.1145/1328408.1328429,10.1145/1328408.1328429,"Aspect Oriented Programming can arbitrarily distort the semantics of programs. In particular, weaving can invalidate crucial safety and liveness propertiesof the base program. In this article, we identify categories of aspects that preserve some classes of properties. It is then sufficient to check that an aspect belongs to a specific category to know which properties will remain satisfied by woven programs.Our categories of aspects, inspired by Katz's, comprise observers, aborters and confiners. Observers introduce new instructions and a new local state but they do not modify the base program's state and control-flow. Aborters are observers which may also abort executions. Confiners only ensure that executions remain in the reachable states of the base program.These categories (along with three other) are defined precisely based on a language independent abstract semantics framework. The classes of properties are defined as subsets of LTL for deterministic programs and CTL* for non-deterministic ones. We can formally prove that, for any program, the weaving of any aspect in a category preserves any property in the related class. We give examples to illustrate each category and prove the preservation of one class of properties by one category of aspects in the appendix.","semantics, proof, temporal properties, aspect weaving",PEPM '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Garzón-Rodriguez LP,Diosa HA,Rojas-Galeano S",Deconstructing GAs into Visual Software Components,,2015,,,1125–1132,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Companion Publication of the 2015 Annual Conference on Genetic and Evolutionary Computation,"Madrid, Spain",2015,9781450334884,,https://doi.org/10.1145/2739482.2768466;http://dx.doi.org/10.1145/2739482.2768466,10.1145/2739482.2768466,"We envisage Genetic Algorithms (GA) as search-based optimisation techniques encompassing independent bio-inspired operators and representations that are realizable as self-contained deployable computational units. In other words, we think of GAs as a set of software components conforming to a formally-defined evolution-oriented composition model. Furthermore, we imagine such components being assembled on a visual programming-free board, much like prefabricated electronic chips are wired up to build electronic devices. Here we introduce Goldenberry-GA, a toolbox of visual software components complying with these premises that has been built over the Orange framework for data mining. The paper describes at user-level the suite of new released components (GeneticAlgorithm, InitialPopulation, SolutionRepresentation, Selection, Mutation, Crossover), including working examples that demonstrate some advantages of the reuse and extension principles of its underlying Component-based software architecture. It also explains the composition model specification of the toolbox and the software design patterns that were taken into account during its development. A qualitative comparative study with similar Evolutionary Computation frameworks is reported so as to highlight strengths and weaknesses of the toolbox, as well as to point out directions for future work.Goldenberry-GA is open-source under the New BSD License. Downloading and installation guides are available at: http://goldenberry-labs.org","genetic algorithms, component-based software development, software, evolutionary algorithms, visual programming",GECCO Companion '15,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Tai TC,Lai YT",A Performance-Oriented Algorithm with Consideration on Communication Cost for Dynamically Reconfigurable FPGA Partitioning,ACM Trans. Reconfigurable Technol. Syst.,2011,4,2,,Association for Computing Machinery,"New York, NY, USA",,,,2011-05,,1936-7406,https://doi.org/10.1145/1968502.1968507;http://dx.doi.org/10.1145/1968502.1968507,10.1145/1968502.1968507,"Dynamically reconfigurable FPGAs (DRFPGAs) have high logic utilization because of time-multiplexed interconnects and logic. In this article, we propose a performance-oriented algorithm for the DRFPGA partitioning problem. This algorithm partitions a given circuit system into stages such that the upper bound of the execution times of subcircuits is minimized. The communication cost is taken into consideration in the process of searching for the optimal solution. A graph is first constructed to represent the precedence constraints and calculate the number of buffers needed in a partitioning. This algorithm includes three phases. The first phase reduces the problem size by clustering the gates into subsystems that have only one output. Such a subsystem has a large number of intraconnections because the fan-outs of all vertices except for the one output are fed to the vertices inside the subsystem. This phase significantly reduces the computational complexity of partitioning. The second phase finds a partition with optimal performance. Finally, the third phase minimizes the communication cost by using an iterative improvement approach. Experimental results based on the Xilinx architecture show that our algorithm yields better partitioning solutions than traditional approaches.","Dynamically reconfigurable FPGA, reconfigurable computing, partitioning, performance-oriented",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Paltoglou G,Salampasis M,Satratzemi M",Integral Based Source Selection for Uncooperative Distributed Information Retrieval Environments,,2008,,,67–74,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Workshop on Large-Scale Distributed Systems for Information Retrieval,"Napa Valley, California, USA",2008,9781605582542,,https://doi.org/10.1145/1458469.1458475;http://dx.doi.org/10.1145/1458469.1458475,10.1145/1458469.1458475,"In this paper, a new source selection algorithm for uncooperative distributed information retrieval environments is presented. The algorithm functions by modeling each information source as an integral, using the relevance score and the intra-collection position of its sampled documents in reference to a centralized sample index and selects the collections that cover the largest area in the rank-relevance space. Based on the above novel metric, the algorithm explicitly focuses on addressing the two goals of source selection; high recall which is important for source recommendation applications and high precision aiming to produce a high precision final merged list. For the latter goal in particular, the new approach steps away from the usual practice of DIR systems of explicitly declaring the number of collections that must be queried and instead receives as input only the number of retrieved documents in the final merged list, dynamically calculating the number of collections that are selected and the number of documents requested from each. The algorithm is tested in a wide range of testbeds in both recall and precision oriented settings and its effectiveness is found to be equal or better than other state-of-the-art algorithms.","federated search, distributed information retrieval, source selection",LSDS-IR '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Mera E,Lopez P,Carro M,Hermenegildo M",Towards Execution Time Estimation in Abstract Machine-Based Languages,,2008,,,174–184,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 10th International ACM SIGPLAN Conference on Principles and Practice of Declarative Programming,"Valencia, Spain",2008,9781605581170,,https://doi.org/10.1145/1389449.1389471;http://dx.doi.org/10.1145/1389449.1389471,10.1145/1389449.1389471,"Abstract machines provide a certain separation between platform-dependent and platform-independent concerns in compilation. Many of the differences between architectures are encapsulated in the specific abstract machine implementation and the bytecode is left largely architecture independent. Taking advantage of this fact, we present a framework for estimating upper and lower bounds on the execution times of logic programs running on a bytecode-based abstract machine. Our approach includes a one-time, program-independent profiling stage which calculates constants or functions bounding the execution time of each abstract machine instruction. Then, a compile-time cost estimation phase, using the instruction timing information, infers expressions giving platform-dependent upper and lower bounds on actual execution time as functions of input data sizes for each program. Working at the abstract machine level makes it possible to take into account low-level issues in new architectures and platforms by just reexecuting the calibration stage instead of having to tailor the analysis for each architecture and platform. Applications of such predicted execution times include debugging/verification of time properties, certification of time properties in mobile code, granularity control in parallel/distributed computing, and resource-oriented specialization","cost models, resource awareness, cost analysis, logic programming, execution time estimation, profiling",PPDP '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Wanderley F,da Silveira DS,Araujo J,Lencastre M",Generating Feature Model from Creative Requirements Using Model Driven Design,,2012,,,18–25,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 16th International Software Product Line Conference - Volume 2,"Salvador, Brazil",2012,9781450310956,,https://doi.org/10.1145/2364412.2364416;http://dx.doi.org/10.1145/2364412.2364416,10.1145/2364412.2364416,"Software Product Lines (SPL) have largely been taken on board by industry. Several reports from large companies such as Bosch, Nokia, Philips and Siemens witness gains and benefits achieved with their use, especially with respect to the reduction on time to market. In SPL development, domain analysis plays a central role where the relevant features are identified. Feature-Oriented Domain Analysis is a method which uses a feature model to specify variabilities and commonalities of an SPL. However, activities related to the Domain Analysis process (managing commonalities and variabilities, with users visibility and relevant stakeholders) in most cases, do not seem to be a simple and easy activity, since to represent these analyzes in modelling domain tools with a certain degree of formality, requires a technical knowledge that domain experts do not always have it prior to use. But creative requirements techniques have been suggested to facilitate the elicitation activity by filling the gap the communications problems between domain experts and software engineers, making the domain analysis more agile. Thus, to improve the domain analysis process, this paper seeks to set out the use of a creative and agile technique for modelling requirements by means of mind maps for cognitive and effective support when building feature models.","mind mapping modeling, model-driven engineering, software product line, feature model",SPLC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kaiser P,Langer A,Gaedke M",MPCC: Generic Secure Multi-Party Computation in Centralized Cloud-Based Environments,,2019,,,60–66,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 3rd International Conference on Big Data Research,"Cergy-Pontoise, France",2019,9781450372015,,https://doi.org/10.1145/3372454.3372467;http://dx.doi.org/10.1145/3372454.3372467,10.1145/3372454.3372467,"Comparing business KPIs with other market participants through benchmarking is a means for companies to optimize costs. Those collaborative optimizations require data of all participating actors that might include business secrets and, therefore, must be kept private in many cases. This demonstrates the demand for privacy-preserving Big Data analytics. Over the last decades, a variety of mechanisms and protocols that enable privacy-preserving collaborative computations have been presented such as trusted third party (TTP) approaches or secure multi-party computation (MPC). However, existing solutions for privacy-preserving benchmarking often only compute a fixed set of arithmetic functions and usually follow a decentralized communication scheme among all peers. We will instead investigate a generic secure MPC system that (1) can compute more general functions, (2) discuss benefits of a service-provider oriented centralized setup and (3) determine the class of arithmetic functions that the selected secure computation mechanism can compute feasibly in practice.Our solution proposes an architecture that can calculate functions containing an arbitrary number of additions, subtractions and multiplications, which is capable to operate in scalable cloud environments with also a larger number of peers with the objective to deliver computation results within 24 hours.","Benchmarking, Data Privacy, FHE, MPC, Service Provider",ICBDR 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Horikoshi H,Nakagawa H,Tahara Y,Ohsuga A",Dynamic Reconfiguration in Self-Adaptive Systems Considering Non-Functional Properties,,2012,,,1144–1150,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 27th Annual ACM Symposium on Applied Computing,"Trento, Italy",2012,9781450308571,,https://doi.org/10.1145/2245276.2231956;http://dx.doi.org/10.1145/2245276.2231956,10.1145/2245276.2231956,"Self-adaptive systems have recently been receiving much attention because of their ability to cope with the changes of environment, failures, and unanticipated events. These systems need an adaptation mechanism, which automatically computes the possible configurations, and decides the most appropriate configuration to fit the environment. In particular, the satisfaction of non-functional requirements must be considered when selecting the best reconfiguration. However, there are trade-off problems among non-functional requirements. Moreover, the adaptation mechanisms are typically developed separately from the components to be implemented, and it complicates the construction of such systems. We propose (1) a feature-oriented analysis technique, which can identify adaptation points, and calculate the contribution to non-functional goals of the configuration; (2) a component specification model, which extends an architectural description language for self-adaptation; (3) a reconfiguration framework aimed to reduce the complexity of the reconfiguration and generate the best configuration at run-time. We evaluate the feasibility of our framework by four different scenarios, and show that our framework reduces the complexity of the reconfiguration, and solves the trade-off problem among non-functional requirements.","self-adaptive systems, dynamic reconfiguration, software architecture, feature-oriented analysis, architecture description language",SAC '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Golbandi NG,Katzir LK,Koren YK,Lempel RL",Expediting Search Trend Detection via Prediction of Query Counts,,2013,,,295–304,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Sixth ACM International Conference on Web Search and Data Mining,"Rome, Italy",2013,9781450318693,,https://doi.org/10.1145/2433396.2433435;http://dx.doi.org/10.1145/2433396.2433435,10.1145/2433396.2433435,"The massive volume of queries submitted to major Web search engines reflects human interest at a global scale. While the popularity of many search queries is stable over time or fluctuates with periodic regularity, some queries experience a sudden and ephemeral rise in popularity that is unexplained by their past volumes. Typically the popularity surge is precipitated by some real-life event in the news cycle. Such queries form what are known as search trends. All major search engines, using query log analysis and other signals, invest in detecting such trends. The goal is to surface trends accurately, with low latency relative to the actual event that sparked the trend.This work formally defines precision, recall and latency metrics related to top-k search trend detection. Then, observing that many trend detection algorithms rely on query counts, we develop a linear auto-regression model to predict future query counts. Subsequently, we tap the predicted counts to expedite search trend detection by plugging them into an existing trend detection scheme.Experimenting with query logs from a major Web search engine, we report both the stand-alone accuracy of our query count predictions, as well as the task-oriented effects of the prediction on the emitted trends. We show an average reduction in trend detection latency of roughly twenty minutes, with a negligible impact on the precision and recall metrics.","search trend detection, query count prediction",WSDM '13,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Florez-Larrahondo G,Haddock W",Aspect Oriented Programming with Hidden Markov Models to Verify Design Use Cases,,2009,,,223–228,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 8th ACM International Conference on Aspect-Oriented Software Development,"Charlottesville, Virginia, USA",2009,9781605584423,,https://doi.org/10.1145/1509239.1509269;http://dx.doi.org/10.1145/1509239.1509269,10.1145/1509239.1509269,"The goal of this research is to formulate a framework to determine whether the usage of an application in production environments is consistent with the test cases used to verify it before the application was released. Aspect-Oriented Programming (AOP) techniques are used to apply the instrumentation required for the measuring process so that the program is oblivious to the instrumentation and Hidden Markov Models (HMMs) are used to create signatures of the program. This paper presents the preliminary findings on the use of such mathematical models to measure the completeness of use cases driving the quality assurance testing.To demonstrate the technique, the Web Service API of a commercial product is used. SOAP calls executed through different client applications are used to create test data for the experiments. The HMMs signatures created from collecting method calls can be used to determine whether the application is used according to the uses cases that have been verified. If the likelihood that the stochastic model obtained during testing can generate the sequences of calls collected from the production environment (via AOP techniques) is low, then it suggests that the program is being used in a way that has not been formally tested. These experiments will show that observable differences of the measurements using log likelihood graphs can detect such anomalies.","acm proceedings, runtime verification, aspect-oriented programming, stochastic models",AOSD '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Cieslewicz J,Mee W,Ross KA",Cache-Conscious Buffering for Database Operators with State,,2009,,,43–51,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Fifth International Workshop on Data Management on New Hardware,"Providence, Rhode Island",2009,9781605587011,,https://doi.org/10.1145/1565694.1565704;http://dx.doi.org/10.1145/1565694.1565704,10.1145/1565694.1565704,"Database processes must be cache-efficient to effectively utilize modern hardware. In this paper, we analyze the importance of temporal locality and the resultant cache behavior in scheduling database operators for in-memory, block oriented query processing. We demonstrate how the overall performance of a workload of multiple database operators is strongly dependent on how they are interleaved with each other. Longer time slices combined with temporal locality within an operator amortize the effects of the initial compulsory cache misses needed to load the operator's state, such as a hash table, into the cache. Though running an operator to completion over all of its input results in the greatest amortization of cache misses, this is typically infeasible because of the large intermediate storage requirement to materialize all input tuples to an operator. We show experimentally that good cache performance can be obtained with smaller buffers whose size is determined at runtime. We demonstrate a low-overhead method of runtime cache miss sampling using hardware performance counters. Our evaluation considers two common database operators with state: aggregation and hash join. Sampling reveals operator temporal locality and cache miss behavior, and we use those characteristics to choose an appropriate input buffer/block size. The calculated buffer size balances cache miss amortization with buffer memory requirements.",,DaMoN '09,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Zhang P,Yu J,Ji S",ADF-GA: Data Flow Criterion Based Test Case Generation for Ethereum Smart Contracts,,2020,,,754–761,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops,"Seoul, Republic of Korea",2020,9781450379632,,https://doi.org/10.1145/3387940.3391499;http://dx.doi.org/10.1145/3387940.3391499,10.1145/3387940.3391499,"Testing is an important technique to improve the quality of Ethereum smart contract programs. However, current work on testing smart contract only focus on static problems of smart contract programs. A data flow oriented test case generation approach for dynamic testing of smart contract programs is still missing. To address this problem, this paper proposes a novel test case generation approach, called ADF-GA (All-uses Data Flow criterion based test case generation using Genetic Algorithm), for Solidity based Ethereum smart contract programs. ADF-GA aims to efficiently generate a valid set of test cases via three stages. First, the corresponding program control flow graph is constructed from the source codes. Second, the generated control flow graph is analyzed to obtain the variable information in the Solidity programs, locate the require statements, and also get the definition-use pairs to be tested. Finally, a genetic algorithm is used to generate test cases, in which an improved fitness function is proposed to calculate the definition-use pairs coverage of each test case with program instrumentation. Experimental studies are performed on several representative Solidity programs. The results show that ADF-GA can effectively generate test cases, achieve better coverage, and reduce the number of iterations in genetic algorithm.","blockchain, test case generation, Solidity, smart contract, fitness function, genetic algorithm",ICSEW'20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Jagadeesh J,Pingali P,Varma V",Capturing Sentence Prior for Query-Based Multi-Document Summarization,,2007,,,798–809,LE CENTRE DE HAUTES ETUDES INTERNATIONALES D'INFORMATIQUE DOCUMENTAIRE,"Paris, FRA",,"Large Scale Semantic Access to Content (Text, Image, Video, and Sound)","Pittsburgh, Pennsylvania",2007,,,,,"In this paper, we have considered a real world information synthesis task, generation of a fixed length multi document summary which satisfies a specific information need. This task was mapped to a topic-oriented, informative multi-document summarization. We also tried to estimate, given the human written reference summaries and the document set, the maximum performance (ROUGE scores) that can be achieved by an extraction-based summarization technique. Motivated by the observation that the current approaches are far behind the estimated maximum performance, we have looked at Information Retrieval techniques to improve the relevance scoring of sentences towards information need. Following information theoretic approach we have identified a measure to capture the notion of importance or prior of a sentence. Following a different decomposition of Probability Ranking Principle, the calculated importance/prior is incorporated into the final sentence scoring by weighted linear combination. In order to evaluate the performance, we have explored information sources like WWW and encyclopedia in computing the information measure in a set of different experiments. The t-test analysis of the improvement on DUC 2005 data set is found to be significant (p 0.05). The same system has outperformed rest of the systems at DUC 2006 challenge in terms of ROUGE scores with a significant margin over the next best system.",,RIAO '07,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Gestwicki P,Ahmad K",App Inventor for Android with Studio-Based Learning,J. Comput. Sci. Coll.,2011,27,1,55–63,Consortium for Computing Sciences in Colleges,"Evansville, IN, USA",,,,2011-10,,1937-4771,,,"App Inventor for Android allows people with little or no programming experience to create smart phone applications on the Android platform. This is accomplished by using drag-and-drop UI design and blocks-oriented visual programming. We offered an experimental section during the closed beta testing of App Inventor for Android in which we used Studio-Based Learning to foster positive learning experiences. Studio-Based Learning is a pedagogical approach in which students build their own representations of their knowledge and share these, formally and informally, with both experts and peers. Our students worked in teams on several projects, with the sixteen students creating over thirty Android applications while learning fundamentals of Computer Science.In this paper, we provide the background and inspiration for this work, including a review of literature on Studio-Based Learning and a comparison of App Inventor for Android to other modern visual programming environments. An overview of our semester goals and course design are provided. From our experience and based on the literature, we conclude that App Inventor for Android and Studio-Based Learning make for a powerful combination to introduce non-CS majors to concepts of Computer Science-not just programming, but also ideas that tend not to be covered in conventional CS1 courses such as human-computer interaction, incremental and iterative design processes, collaboration, evaluation, and quality assurance. This paper complements the eponymous Web site at https://sites.google.com/site/appinventorsbl.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Yaacoub A,Assaghir Z,Makki S,Almokdad R",Diagnosing Clinical Manifestation of Apathy Using Machine Learning and Micro-Facial Expressions Detection,,2019,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2019 3rd International Symposium on Computer Science and Intelligent Control,"Amsterdam, Netherlands",2019,9781450376617,,https://doi.org/10.1145/3386164.3386174;http://dx.doi.org/10.1145/3386164.3386174,10.1145/3386164.3386174,"Apathy is a behavioral and personality change and is generally defined as a loss of motivation. In this study, we will explore the detection of apathy in two phases. An apathy detection phase, and relevant features identification phase.In the first one, we apply micro-facial expressions detection systems and counter for the purpose of diagnosing clinical manifestation of apathy from a video for Lebanese citizens. The method works by applying Histogram of Oriented Gradients (HOG) as a feature descriptor on video dataset of spontaneous micro facial movements. Micro-facial expressions appear by video recording participants reacting to emotional stimulating COPE cards. Results are compared to Lille Apathy Rating Scale LARS scores. Kappa agreement was calculated to be 95.96% showing the proposed classification method has a high accuracy of estimation.In a second phase, we aim to identify the demographics and habits that might be affecting the manifestation of apathy using machine leaning algorithms.A statistical model is built based on the results to identify the characteristics that affect the manifestation of apathy by analyzing the data and making a statistical description. Using a sample of 470 participants, we base our results on the decision tree (CART) combined with logistic regression. Finally, we found that insomnia, genetic background and stress are the most important features that influence the manifestation of apathy, with an accuracy of 96.7%.","Logistic Regression, Decision Tree, Facial Feature Detection, Micro Facial Expression, Apathy Diagnosis",ISCSIC 2019,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Tantisuwankul J,Manaskasemsak B,Rungsawang A",Identifying Influencers in Thai Internet Forum Based on Topic-Oriented Gravity Model,,2020,,,271–277,Association for Computing Machinery,"New York, NY, USA",,2020 4th International Conference on Computer Science and Artificial Intelligence,"Zhuhai, China",2020,9781450388436,,https://doi.org/10.1145/3445815.3445859;http://dx.doi.org/10.1145/3445815.3445859,10.1145/3445815.3445859,"The task of identifying influencers provides a lot of benefits for various practical applications such as recommendation systems, viral marketing, and information monitoring. This issue can traditionally be solved via a network structure with several proposed graph algorithms. However, most of them employ a global computation with much time-consuming; some consider only undirected and unweighted networks which may be inconsistent with the nature of data. Inspired by the law of gravity in Physics, we present the Topic-oriented Gravity Model (TopicGM) that investigates a directed and weighted network incorporating users' topical aspects. The key concept is that an individual is first represented as a textual content he created or read. Afterwards, TopicGM simply adopts a topic modeling, i.e., the Hierarchical Dirichlet Process (HDP), to classify topics over those contents. A topical network is then constructed where nodes represent individuals and an edge connects two individuals in the direction from the poster to the reader with a topical confidence weight. Finally, we apply the gravity formula to calculate influence scores and rank individuals. The experimental results, conducted on real-world data gathered from Pantip.com (famous Thai web forum), show that our approach outperforms many state-of-the-art baselines by accurately identifying influencers within the top of rankings.","influencer identification, topic model, social network, viral marketing, gravity model",CSAI 2020,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Ali AM,Eltarhouni WI,Bozed KA",On-Road Vehicle Detection Using Support Vector Machine and Decision Tree Classifications,,2020,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 6th International Conference on Engineering & MIS 2020,"Almaty, Kazakhstan",2020,9781450377362,,https://doi.org/10.1145/3410352.3410803;http://dx.doi.org/10.1145/3410352.3410803,10.1145/3410352.3410803,"On-road vehicle detection is a major part of various applications, such as driver assistance systems and auto-driving, and these systems need to detect vehicles robustly and accurately. This paper proposes a robust vehicle detection system to detect the front vehicles by using a single camera mounted on the car. The proposed system consists of two main steps, which are, hypotheses generation (HG) and hypotheses verification (HV). The first step is to find the candidate regions to the vehicles in the image. The guide to these regions is the shadow underneath the vehicle because it is always darker than the road surface. The system fits the generated regions with the width of the vehicle and reduces the number of hypotheses by calculating the entropy in two different ways. The second step is to verify whether the generated hypotheses contain a vehicle or not, and this done by Histogram of Oriented Gradients (HOG) to extract the features. In designing the proposed system, the Support Vector Machine (SVM) and Decision Tree (DT) classifiers are used for classification. Experiments were conducted using the challenging GTI DATA database to ascertain the usefulness of the approaches. The methodology was evaluated against the state-of the-art and it was found that the proposed approaches produce outstanding results.","hypotheses verification, Decision Tree, hypotheses generation, entropy, Detection, SVM",ICEMIS'20,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Melo M,Smaniotto G,Maich H,Agostini L,Zatt B,Rosa L,Porto M",A Parallel Motion Estimation Solution for Heterogeneous System on Chip,,2017,,,,IEEE Press,"Belo Horizonte, Brazil",,Proceedings of the 29th Symposium on Integrated Circuits and Systems Design: Chip on the Mountains,,2017,9781509027361,,,,"This paper presents a parallel Motion Estimation (ME) solution for video coding on heterogeneous System-On-Chip (SoC), with two Implementation Versions: an OpenCL-based version targeting embedded GPGPUs and a hardware design targeting an embedded FPGA device. The current work considers a heterogeneous SoC composed of a variety distinct processing units such as CPU, DSP, Memory, GPGPU, and FPGA, where the FPGA component has support for dynamic reconfiguration. These two versions implement a parallelism-oriented algorithm and provide two performance/energy operation points allowing flexibility for dynamic power management according to runtime scenarios. The solution presented in this paper uses a scheme to reduce the number of operations required to perform the Sum of Absolute Differences (SAD) for the evaluated candidate blocks. This scheme is based on the accumulation of previously calculated SADs, considering the 8x8 Prediction Unities (PU) as base blocks, to generate the SAD for larger PUs. The proposed solution was evaluated in two platforms, (1) an Odroid XU-3, with a Samsung Exynos 5422 SoC, featuring a 64-core Mali-T628 MP6 GPGPU, and (2) an FPGA device. The performance and energy consumption results shows the FPGA implementation are able to process 49 HD 1080p fps with 1000x increased in energy efficiency when compared to the GPGPU implementation.","FPGA, heterogeneous system, GPGPU, SoC, motion estimation, video coding",SBCCI '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kaushik Y,Bhola A,Jha CK",Proposed SKYMAX Load Balancing Algorithm,,2016,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the International Conference on Advances in Information Communication Technology & Computing,"Bikaner, India",2016,9781450342131,,https://doi.org/10.1145/2979779.2979850;http://dx.doi.org/10.1145/2979779.2979850,10.1145/2979779.2979850,"Cloud computing has fulfill dreams of computing in IT world to provide maximum resource utilizations. It provides flexibility, more capacity, ecosystem and service -oriented ideas. In IT field for small and big enterprise trying to setup public, private and hybrid cloud for storing and transferring their process to the users. We develop an algorithm which solves the problem of resource utilization, performance degradation and availability. We explained about role of virtualization technology in the cloud environment and how its play a very big role in utilization of resources. MERT (minimum expected response time) is calculated and that bases maximum response time is reduced. This system identified how a user request reached to data centers and checks the quality of request on the basis of different parameter that is bandwidth, response time, and throughput. It based on queue for storage of requests followed by sorting concept. We check the availability, size (capacity), MERT and least loaded parameters to check and select VM for request which increases the recourse utilization. When we check the parameters of least loaded we uses the concept of overloading or under loading server with the concept of shifting. After the completion of all request VM's destroy itself and release all the resources.","Eclipse javaIDE(Cloud), MERT, Cloud computing, load balancing, Virtual machine",AICTC '16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Thangarajah J,Sardina S,Padgham L",Measuring Plan Coverage and Overlap for Agent Reasoning,,2012,,,1049–1056,International Foundation for Autonomous Agents and Multiagent Systems,"Richland, SC",,Proceedings of the 11th International Conference on Autonomous Agents and Multiagent Systems - Volume 2,"Valencia, Spain",2012,9780981738123,,,,"In Belief Desire Intention (BDI) agent systems it is usual for goals to have a number of plans that are possible ways of achieving the goal, applicable in different situations, usually captured by a context condition. In Agent Oriented Software Engineering it has been suggested that a designer should be conscious of whether a goal has complete coverage, that is, is there some plan that is applicable for every situation. Similarly a designer should be conscious of overlap, that is, for a given goal, are there situations where more than one plan could be applicable for achieving that goal. In this paper we further develop these notions in two ways, and then describe how they can be used both in agent reasoning and agent system development. Firstly we replace the boolean value for basic coverage and overlap with numerical measures, and explain how these may be calculated. Secondly we describe a measure that combines these basic measures, with the characteristics of the coverage/overlap in the goal-plan tree below a given goal. We then describe how these domain independent measures can be used for both plan selection and intention selection, as well as for guidance in agent system development.","overlap, agent reasoning, intention selection, coverage, plans, goals",AAMAS '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Singer P,"Understanding, Leveraging and Improving Human Navigation on the Web",,2014,,,27–32,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 23rd International Conference on World Wide Web,"Seoul, Korea",2014,9781450327459,,https://doi.org/10.1145/2567948.2567956;http://dx.doi.org/10.1145/2567948.2567956,10.1145/2567948.2567956,"Navigating websites represents a fundamental activity of users on the Web. Modeling this activity, i.e., understanding how predictable human navigation is and whether regularities can be detected has been of interest to researchers for nearly two decades. This is crucial for improving the Web experience of users by e.g., enhancing interfaces or information network structures. This thesis envisions to shedding light on human navigational patterns by trying to understand, leverage and improve human navigation on the Web. One main goal of this thesis is the construction of a versatile framework for modeling human navigational data with the use of Markov chains and for detecting the appropriate Markov chain order by using several advanced inference methods. It allows us to investigate memory and structure in human navigation patterns. Furthermore, we are interested in detecting whether pragmatic human navigational data can be leveraged by e.g., being useful for the task of calculating semantic relatedness between concepts. Finally, we want to find ways of enhancing human navigation models. Concretely, we plan on incorporating prior knowledge about the semantic relatedness between concepts to our Markov chain models as it is known that humans navigate the Web intuitively instead of randomly. Our experiments should be conducted on a variety of distinct navigational data including both goal oriented and free form navigation scenarios. We not only look at navigational paths over websites, but also abstract away to navigational paths over topics in order to get insights into cognitive patterns.","semantics, memory, navigation, semantic relatedness, Markov chain, pragmatics, web",WWW '14 Companion,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Thomas I,Menzel M,Meinel C",Using Quantified Trust Levels to Describe Authentication Requirements in Federated Identity Management,,2008,,,71–80,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2008 ACM Workshop on Secure Web Services,"Alexandria, Virginia, USA",2008,9781605582924,,https://doi.org/10.1145/1456492.1456504;http://dx.doi.org/10.1145/1456492.1456504,10.1145/1456492.1456504,"Service-oriented Architectures (SOA) facilitate the dynamic and seamless integration of services offered by different service providers which in addition can be located in different trust domains. Especially for business integration scenarios, Federated Identity Management emerged as a possibility to propagate identity information as security assertions across company borders in order to secure the interaction between different services. Although this approach guarantees scalability regarding the integration of identity-based services, it exposes a service provider to new security risks. These security risks result from the complex trust relationships within a federation. In a federation the authentication of a user is not necessarily performed within the service provider's domain, but can be performed in the user's local domain. Consequently, the service provider has to rely on authentication results received from a federation partner to enforce access control. This implies that the quality of the authentication process is out of control by the service provider and therefore becomes a factor which needs to be considered in the access control step. In order to guarantee a designated level of security, the quality of the authentication process should be part of the access control decision.To ease this process, we propose in this paper a method to rate authentication information by a level of trust which describes the strength of an authentication method. Additionally, in order to support the concept of a two-factor authentication, we also present a mathematical model to calculate the trust level when combining two authentication methods.","federated identity management, authentication and access control, trust levels, trust management, web service federation",SWS '08,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Soultanopoulos T,Sotiriadis S,Petrakis E,Amza C",Internet of Things Data Management in the Cloud for Bluetooth Low Energy (BLE) Devices,,2016,,,35–39,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the Third International Workshop on Adaptive Resource Management and Scheduling for Cloud Computing,"Chicago, IL, USA",2016,9781450342278,,https://doi.org/10.1145/2962564.2962568;http://dx.doi.org/10.1145/2962564.2962568,10.1145/2962564.2962568,"The use of wearable sensors and their connectivity to Internet offers significant benefits for storing sensing data that could be utilized intelligently for multiple purpose applications such as for monitoring purposes in healthcare domain. This work presents an Internet of Things (IoT) gateway service taking advantage of modern mobile devices and their capabilities to communicate with wearable Bluetooth low energy (BLE) sensors so data could be forwarded to the cloud on the fly and on real time. The service transforms a mobile platform (such as a smartphone) to a gateway allowing continuous and fast communication of data that is forwarded from the device to the cloud on demand or automatically for an automated decision making. Its features include (a) use of an internal processing mechanism for the BLE sensor signals and defines the way in which data is send to the cloud, (b) dynamic service as it has the ability to recognize new BLE sensors properties by easily adapting the data model according to a dynamic schema and (c) universal BLE devices capability that are registered automatically and are monitored on the fly while it keeps historical data that could be integrated into meaningful business intelligence. Building upon principles of service oriented design, the service takes full advantage of cloud services for processing potential big data streams produced by an ever increasing number of users and sensors. The contribution of this work is on the IoT data transmission rate that is averagely calculated to 128 milliseconds and in the experimental section we discuss that this is significantly low for real time data.","Sensor data collection service, REST services, Internet of Things, Cloud Computing, Bluetooth Low Energy (BLE)",ARMS-CC'16,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Su H,Zhu D,Brandt S",An Elastic Mixed-Criticality Task Model and Early-Release EDF Scheduling Algorithms,ACM Trans. Des. Autom. Electron. Syst.,2016,22,2,,Association for Computing Machinery,"New York, NY, USA",,,,2016-12,,1084-4309,https://doi.org/10.1145/2984633;http://dx.doi.org/10.1145/2984633,10.1145/2984633,"Many algorithms have recently been studied for scheduling mixed-criticality (MC) tasks. However, most existing MC scheduling algorithms guarantee the timely executions of high-criticality (HC) tasks at the expense of discarding low-criticality (LC) tasks, which can cause serious service interruption for such tasks. In this work, aiming at providing guaranteed services for LC tasks, we study an elastic mixed-criticality (E-MC) task model for dual-criticality systems. Specifically, the model allows each LC task to specify its maximum period (i.e., minimum service level) and a set of early-release points. We propose an early-release (ER) mechanism that enables LC tasks to be released more frequently and thus improve their service levels at runtime, with both conservative and aggressive approaches to exploiting system slack being considered, which is applied to both earliest deadline first (EDF) and preference-oriented earliest-deadline schedulers. We formally prove the correctness of the proposed early-release--earliest deadline first scheduler on guaranteeing the timeliness of all tasks through judicious management of the early releases of LC tasks. The proposed model and schedulers are evaluated through extensive simulations. The results show that by moderately relaxing the service requirements of LC tasks in MC task sets (i.e., by having LC tasks’ maximum periods in the E-MC model be two to three times their desired MC periods), most transformed E-MC task sets can be successfully scheduled without sacrificing the timeliness of HC tasks. Moreover, with the proposed ER mechanism, the runtime performance of tasks (e.g., execution frequencies of LC tasks, response times, and jitters of HC tasks) can be significantly improved under the ER schedulers when compared to that of the state-of-the-art earliest deadline first—virtual deadline scheduler.","early release, Mixed-criticality systems, earliest deadline first (EDF) scheduling, elastic task models, real-time tasks, scheduling algorithms",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Sotiropoulos T,Chaliasos S,Mitropoulos D,Spinellis D",A Model for Detecting Faults in Build Specifications,Proc. ACM Program. Lang.,2020,4,OOPSLA,,Association for Computing Machinery,"New York, NY, USA",,,,2020-11,,,https://doi.org/10.1145/3428212;http://dx.doi.org/10.1145/3428212,10.1145/3428212,"Incremental and parallel builds are crucial features of modern build systems. Parallelism enables fast builds by running independent tasks simultaneously, while incrementality saves time and computing resources by processing the build operations that were affected by a particular code change. Writing build definitions that lead to error-free incremental and parallel builds is a challenging task. This is mainly because developers are often unable to predict the effects of build operations on the file system and how different build operations interact with each other. Faulty build scripts may seriously degrade the reliability of automated builds, as they cause build failures, and non-deterministic and incorrect outputs. To reason about arbitrary build executions, we present BuildFS, a generally-applicable model that takes into account the specification (as declared in build scripts) and the actual behavior (low-level file system operation) of build operations. We then formally define different types of faults related to incremental and parallel builds in terms of the conditions under which a file system operation violates the specification of a build operation. Our testing approach, which relies on the proposed model, analyzes the execution of single full build, translates it into BuildFS, and uncovers faults by checking for corresponding violations. We evaluate the effectiveness, efficiency, and applicability of our approach by examining 612 Make and Gradle projects. Notably, thanks to our treatment of build executions, our method is the first to handle JVM-oriented build systems. The results indicate that our approach is (1) able to uncover several important issues (247 issues found in 47 open-source projects have been confirmed and fixed by the upstream developers), and (2) much faster than a state-of-the-art tool for Make builds (the median and average speedup is 39X and 74X respectively).","JVM-based builds, Make, incremental builds, parallel builds, Gradle",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Yan B,Zhao Y,Yu X,Li Y,Rahman S,He Y,Xin X,Zhang J",Service Function Path Provisioning With Topology Aggregation in Multi-Domain Optical Networks,IEEE/ACM Trans. Netw.,2020,28,6,2755–2767,IEEE Press,,,,,2020-12,,1063-6692,https://doi.org/10.1109/TNET.2020.3019708;http://dx.doi.org/10.1109/TNET.2020.3019708,10.1109/TNET.2020.3019708,"Traffic flows are often processed by a chain of Service Functions (SFs) (known as Service Function Chaining (SFC)) to satisfy service requirements. The deployed path for a SFC is called Service Function Path (SFP). SFs can be virtualized and migrated to datacenters, thanks to the evolution of Software Defined Network (SDN) and Network Function Virtualization (NFV). In such a scenario, provisioning of paths (i.e., SFPs) between virtualized network functions is an important problem. SFP provisioning becomes more complex in a multi-domain network topology. ‘Topology aggregation’ helps to create a single-domain view of such a network by abstracting multi-domain networks. However, traditional ‘topology aggregation’ methods are unable to abstract SF resources properly, which is required for SFP provisioning. In this paper, we propose an SFC-Oriented Topology Aggregation (SOTA) method to enable abstraction for SFs in multi-domain optical networks. This study explores the node and the link aggregation degree to evaluate information compression during the ‘Topology aggregation’ process. Additionally, we also propose a new data structure named wheel matrix and related operations to store routing information in the aggregated topology. Based on SOTA, we propose two cross-domain SFP provisioning algorithms named Ordered Anchor Selection (OAS) and $k$ -paths OAS (K-OAS), and a benchmark named Global OAS (GOAS). Simulation results show that SOTA could aggregate large-scale multi-domain optical networks into a small network that contains only 6.9% of the nodes and 10.1% of the links. Both OAS and K-OAS can calculate SFPs efficiently and reduce blocking probability up to 52.10% compared to the benchmark.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Kirsch J,Bierbaumer B,Kittel T,Eckert C",Dynamic Loader Oriented Programming on Linux,,2017,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 1st Reversing and Offensive-Oriented Trends Symposium,"Vienna, Austria",2017,9781450353212,,https://doi.org/10.1145/3150376.3150381;http://dx.doi.org/10.1145/3150376.3150381,10.1145/3150376.3150381,"Memory corruptions are still the most prominent venue to attack otherwise secure programs. In order to make exploitation of software bugs more difficult, defenders introduced a vast number of post corruption security mitigations, such as w⊕x memory, Stack Canaries, and Address Space Layout Randomization (ASLR), to only name a few. In the following, we describe the Wiedergänger1-Attack, a new attack vector that reliably allows to escalate unbounded array access vulnerabilities occurring in specifically allocated memory regions to full code execution on programs running on i386/x86_64 Linux.Wiedergänger-attacks abuse determinism in Linux ASLR implementation combined with the fact that (even with protection mechanisms such as relro and glibc's pointer mangling enabled) there exist easy-to-hijack, writable (function) pointers in application memory. To discover such pointers, we use taint analysis and backwards slicing at the binary level and calculate an over-approximation of vulnerable instruction sequences.To show the relevance of Wiedergänger, we exploit one of the discovered instruction sequences to perform an attack on Debian 10 (Buster) by overwriting structures used by the dynamic loader (dl) that are present in any application with glibc and the dynamic loader as dependency. In order to show generality, we solely focus on data structures dispatched at program shutdown, as this is a point that arguably all applications eventually have to reach. This results in a reliable compromise that effectively bypasses all protection mechanisms deployed on x86_64/i386 Linux to date.We believe Wiedergänger to be part of an under-researched type of control flow hijacking attacks targeting internal control structures of the dynamic loader for which we propose to use the terminology Loader Oriented Programming (LOP).","Dynamic Loader, Linux, Software Security, glibc, Address Space Layout Randomization Determinism, Software Exploitation, Loader Oriented Programming, Software Vulnerability",ROOTS,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,Gober PE,The Computer in Manufacturing: Reduction of Scrap by Computer Monitoring,,1977,,,889–894,Association for Computing Machinery,"New York, NY, USA",,"Proceedings of the June 13-16, 1977, National Computer Conference","Dallas, Texas",1977,9781450379144,,https://doi.org/10.1145/1499402.1499563;http://dx.doi.org/10.1145/1499402.1499563,10.1145/1499402.1499563,"A computer furnace monitoring system was implemented as the first stage of a computer process monitoring system designed to provide better control of the process used to manufacture high power semiconductor devices. The purpose of the furnace monitoring system is to reduce scrap resulting from furnace malfunctions that are otherwise not detected in time to salvage the product. The system also improves reproducibility by maintaining a tight control of the elevated furnace temperatures (± 2°C at 1250°C). Additional results of the system are greatly improved operation visibility during the run, increased furnace utilization as a result of computer assisted scheduling, and improved correlation of results among different furnaces.The \w\"" 2500 computer provides the process I/O necessary to monitor furnace temperatures as measured by thermocouples",sound alarms when deviations from the spec occur,store information for later analysis,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Bernard J,Ruppert T,Scherer M,Schreck T,Kohlhammer J",Guided Discovery of Interesting Relationships between Time Series Clusters and Metadata Properties,,2012,,,,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 12th International Conference on Knowledge Management and Knowledge Technologies,"Graz, Austria",2012,9781450312424,,https://doi.org/10.1145/2362456.2362485;http://dx.doi.org/10.1145/2362456.2362485,10.1145/2362456.2362485,"Visual cluster analysis provides valuable tools that help analysts to understand large data sets in terms of representative clusters and relationships thereof. Often, the found clusters are to be understood in context of belonging categorical, numerical or textual metadata which are given for the data elements. While often not part of the clustering process, such metadata play an important role and need to be considered during the interactive cluster exploration process. Traditionally, linked-views allow to relate (or loosely speaking: correlate) clusters with metadata or other properties of the underlying cluster data. Manually inspecting the distribution of metadata for each cluster in a linked-view approach is tedious, especially for large data sets, where a large search problem arises. Fully interactive search for potentially useful or interesting cluster to metadata relationships may constitute a cumbersome and long process.To remedy this problem, we propose a novel approach for guiding users in discovering interesting relationships between clusters and associated metadata. Its goal is to guide the analyst through the potentially huge search space. We focus in our work on metadata of categorical type, which can be summarized for a cluster in form of a histogram. We start from a given visual cluster representation, and compute certain measures of interestingness defined on the distribution of metadata categories for the clusters. These measures are used to automatically score and rank the clusters for potential interestingness regarding the distribution of categorical metadata. Identified interesting relationships are highlighted in the visual cluster representation for easy inspection by the user. We present a system implementing an encompassing, yet extensible, set of interestingness scores for categorical metadata, which can also be extended to numerical metadata. Appropriate visual representations are provided for showing the visual correlations, as well as the calculated ranking scores. Focusing on clusters of time series data, we test our approach on a large real-world data set of time-oriented scientific research data, demonstrating how specific interesting views are automatically identified, supporting the analyst discovering interesting and visually understandable relationships.","information visualization, visual analytics, interestingness measures, guided data exploration, scientific research data, visual cluster analysis",i-KNOW '12,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
1,Journal Article,"Wilczek J,Monna F,Jébrane A,Chazal CL,Navarro N,Couette S,Smith CC",Computer-Assisted Orientation and Drawing of Archaeological Pottery,J. Comput. Cult. Herit.,2018,11,4,,Association for Computing Machinery,"New York, NY, USA",,,,2018-12,,1556-4673,https://doi.org/10.1145/3230672;http://dx.doi.org/10.1145/3230672,10.1145/3230672,"Archaeologists spend considerable time orienting and drawing ceramic fragments by hand for documentation, to infer their manufacture, the nature of the discovery site and its chronology, and to develop hypotheses about commercial and cultural exchanges, social organisation, resource exploitation, and taphonomic processes. This study presents a survey of existing solutions to the time-consuming problem of orienting and drawing pottery fragments. Orientation is based on the 3D geometry of pottery models, which can now be acquired in minutes with low-cost 3D scanners. Several methods are presented: they are based on normal vectors, or circle fittings, or profile fittings. All these methods seek to determine the optimal position of the rotation axis. We also present and discuss new approaches and improvements to existing methods. We have developed a suite of functions for the computer-assisted orientation and drawing of archaeological pottery. The profile and contours of the fragment, as well as any possible decoration, can be depicted in various ways: photorealistic rendering or dotted patterns, calculated by ambient occlusion, combined or not with artificial light. The general workflow, evaluated using both synthetic and real-world fragments, is rapid, accurate, and reproducible. It drastically reduces the amount of routine work required to document ceramic artefacts. The information produced, together with the 3D representation of the fragments, can easily be archived and/or exchanged within the archaeological community for further research. The source code (built in the R environment), together with an installation notice and examples, is freely downloadable.","Archaeology, 3D reconstruction, (semi-)automatic pottery orientation, documentation, pottery illustration",,plot furnace behavior,and assist in scheduling by calculating cycle times. It also provides the furnace operators with the ability to quickly and accurately determine furnace temperature at any time during the cycle. The real time foreground/background operating system of computer,based on a strict priority system,allows data analysis programs to run without disturbing the real time monitoring of physical parameters such as temperature.The furnace operator's interface with the computer,a set of related programs accessed from a teletype by a single command,is also described. The system is user-oriented,"and employs a conversational question and answer format that guides the operator through the various procedures. The system also incorporates error detection and correction methods to prevent mistakes from improperly entered data.The computer is an effective tool for the reduction of cost resulting from scrap. It also provides the basis for an integrated monitoring system encompassing the entire manufacturing process.""",,AFIPS '77,,,,,,,,,,,,,,,,,,,,,
1,Conference Paper,"Khovanskaya V,Bezaitis M,Sengers P",The Case of the Strangerationist: Re-Interpreting Critical Technical Practice,,2016,,,134–145,Association for Computing Machinery,"New York, NY, USA",,Proceedings of the 2016 ACM Conference on Designing Interactive Systems,"Brisbane, QLD, Australia",2016,9781450340311,,https://doi.org/10.1145/2901790.2901860;http://dx.doi.org/10.1145/2901790.2901860,10.1145/2901790.2901860,"We describe a method for critically informed development of new technical systems by combining analysis of historical discourse with critical technical practice. We take the case of social recommender systems, a class of algorithms that calculate which people should be recommended to whom. We demonstrate similarities between limitations of \social network\"" rhetoric in contemporary social matching algorithms and discourse on planning in Artificial Intelligence. We develop an algorithm for social matching that recombines \""lost\"" ideas from the history of AI","orienting around situated behavior and algorithmic transparency. By implementing this approach in a functioning prototype called \""the Strangerationist\""",we examine directly how conceptual commitments inform low-level technical decisions,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,