Item type,Authors,Editors,Title,Journal,Publication year,Volume,Issue,Pages,Edition,Publisher,Address,Book title,Date published,ISBN,ISSN,URLs,DOI,Abstract,Keywords,Notes,Series,,,,,,,,,,,,,,,,,,,
Journal Article,"Cornélio M,Cavalcanti A,Sampaio A",,Refactoring Towards a Layered Architecture,Electronic Notes in Theoretical Computer Science,2005,130,,281-300,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105002264;http://dx.doi.org/10.1016/j.entcs.2005.03.015,10.1016/j.entcs.2005.03.015,"In this paper we present how refactoring of object-oriented programs can be accomplished by using formal refinement. Our approach is based on the use of refactoring rules designed for a sequential object-oriented language of refinement (rool) similar to Java. We define a strategy that aims at structuring programs according to a layered architecture that involves the application of refactoring rules, object-oriented programming laws, and data and algorithm refinement. As the laws are proved in a weakest precondition semantics of rool, correctness of refactoring is ensured by construction.","Refactoring, Formal Refinement, Refinement Calculus",Proceedings of the Brazilian Symposium on Formal Methods (SBMF 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,Medina J,,"Relating attribute reduction in formal, object-oriented and property-oriented concept lattices",Computers & Mathematics with Applications,2012,64,6,1992-2002,,,,,2012,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122112002921;http://dx.doi.org/10.1016/j.camwa.2012.03.087,10.1016/j.camwa.2012.03.087,"Attribute reduction is an important step in reducing computational complexity in order to extract information from relational systems. Three of these systems are the formal, object-oriented and property oriented concept lattices. Attribute reduction in the last two concept lattices has recently been studied. The relation with the first concept lattice is very important since two important, independent tools to extract information from databases–the formal concept analysis and rough set theory–will be related. This paper studies attribute reduction in these three frameworks. The main results are that the classification of each attribute into absolutely necessary, relatively necessary and absolutely unnecessary attributes is independent of the framework considered and that an attribute reduct in one of these relational systems is also an attribute reduct in the others.","Galois connection, Formal concept analysis, Property-oriented and object-oriented concept lattices, Attribute reduction",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dovland J,Johnsen EB,Owe O,Steffen M",,Lazy behavioral subtyping,The Journal of Logic and Algebraic Programming,2010,79,7,578-607,,,,,2010,,1567-8326,https://www.sciencedirect.com/science/article/pii/S156783261000038X;http://dx.doi.org/10.1016/j.jlap.2010.07.008,10.1016/j.jlap.2010.07.008,"Inheritance combined with late binding allows flexible code reuse but complicates formal reasoning significantly, as a method call’s receiver class is not statically known. This is especially true when programs are incrementally developed by extending class hierarchies. This paper develops a novel method to reason about late bound method calls. In contrast to traditional behavioral subtyping, reverification of method specifications is avoided without restricting method overriding to fully behavior-preserving redefinition. The approach ensures that when analyzing the methods of a class, it suffices to consider that class and its superclasses. Thus, the full class hierarchy is not needed, and incremental reasoning is supported. We formalize this approach as a calculus which lazily imposes context-dependent subtyping constraints on method definitions. The calculus ensures that all method specifications required by late bound calls remain satisfied when new classes extend a class hierarchy. The calculus does not depend on a specific program logic, but the examples in the paper use a Hoare style proof system. We show soundness of the analysis method. The paper finally demonstrates how lazy behavioral subtyping can be combined with interface specifications to produce an incremental and modular reasoning system for object-oriented class hierarchies.","Object orientation, Inheritance, Code reuse, Late binding, Proof systems, Method redefinition, Incremental reasoning, Behavioral subtyping",The 20th Nordic Workshop on Programming Theory (NWPT 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,Nordlander J,,Polymorphic subtyping in O'Haskell,Science of Computer Programming,2002,43,2,93-127,,,,,2002,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642302000266;http://dx.doi.org/10.1016/S0167-6423(02)00026-6,10.1016/S0167-6423(02)00026-6,"O'Haskell is a programming language derived from Haskell by the addition of concurrent reactive objects and subtyping. Because Haskell already encompasses an advanced type system with polymorphism and overloading, the type system of O'Haskell is much richer than what is the norm in almost any widespread object-oriented or functional language. Yet, there is strong evidence that O'Haskell is not a complex language to use, and that both Java and Haskell programmers can easily find their way with its polymorphic subtyping system. This paper describes the type system of O'Haskell both formally and from a programmer's point of view; the latter task is accomplished with the aid of an illustrative, real-world programming example: a strongly typed interface to the graphical toolkit Tk.","Type inference, Subtyping, Polymorphism, Haskell, Graphical toolkit",Mathematics of Program Construction (MPC 2000),,,,,,,,,,,,,,,,,,,,
Journal Article,"Andrade L,Sernadas A",,Banking and Management Information System Automation,IFAC Proceedings Volumes,1996,29,1,5518-5523,,,,,1996,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017585602;http://dx.doi.org/10.1016/S1474-6670(17)58560-2,10.1016/S1474-6670(17)58560-2,"An Object Oriented Model for large scale projects is proposed, with a formal framework for inheritance, dynamic classification, object specification decomposition, composition of objects (aggregation) and object single and joint behaviour semantics. The model is based on a full concurrent community of objects. It is advocated that such a model enhances concurrence, improves abstraction, refinement and reusability, explains different forms of inheritance and gives a concise semantic for aggregation and exception handling.","Concurrency, Events, Inheritance, Interaction, Invariants, Object, Synchronisation","13th World Congress of IFAC, 1996, San Francisco USA, 30 June - 5 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Apt KR,de Boer FS,Olderog ER,de Gouw S",,Verification of object-oriented programs: A transformational approach,Journal of Computer and System Sciences,2012,78,3,823-852,,,,,2012,,0022-0000,https://www.sciencedirect.com/science/article/pii/S002200001100081X;http://dx.doi.org/10.1016/j.jcss.2011.08.002,10.1016/j.jcss.2011.08.002,"We show that verification of object-oriented programs by means of the assertional method can be achieved in a simple way by exploiting a syntax-directed transformation from object-oriented programs to recursive programs. This transformation suggests natural proofs rules and its correctness helps us to establish soundness and relative completeness of the proposed proof system. One of the difficulties is how to properly deal in the assertion language with the instance variables and aliasing. The discussed programming language supports arrays, instance variables, failures and recursive methods with parameters. We also explain how the transformational approach can be extended to deal with other features of object-oriented programming, like classes, inheritance, subtyping and dynamic binding.","Object-oriented programs, Null references, Aliasing, Inheritance, Subtyping, Syntax-directed transformation, Recursive programs, Program verification, Strong partial correctness, Relative completeness",In Commemoration of Amir Pnueli,,,,,,,,,,,,,,,,,,,,
Journal Article,AbdelGawad MA,,A Domain-Theoretic Model Of Nominally-Typed Object-Oriented Programming,Electronic Notes in Theoretical Computer Science,2014,301,,3-19,,,,,2014,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066114000036;http://dx.doi.org/10.1016/j.entcs.2014.01.002,10.1016/j.entcs.2014.01.002,"The majority of contemporary mainstream object-oriented (OO) software is written using nominally-typed OO programming languages. Extant domain-theoretic models of OOP developed to analyze OO type systems miss crucial features of these mainstream OO languages, such as nominality. This paper summarizes the construction of NOOP as a domain-theoretic model of OOP that includes nominal information found in nominally-typed mainstream OO software. Inclusion of nominal type information and asserting that type inheritance in statically-typed OO programming languages is an inherently nominal notion allow readily proving that inheritance and subtyping are completely identified in these languages. This conclusion is in full agreement with intuitions of OO developers using these languages, and contrary to the belief that “inheritance is not subtyping”, which came from assuming non-nominal structural models of OO type systems. NOOP, thus, provides a firmer semantic foundation for analyzing and progressing nominally-typed mainstream OO programming languages.","Object-Oriented Programming, Denotational Semantics, Nominative Type Systems, Structural Type Systems, , Type Names, Inheritance, Subtyping, OOP, Java, C#",Proceedings of the 6th International Symposium on Domain Theory and Its Applications (ISDT),,,,,,,,,,,,,,,,,,,,
Journal Article,Puntigam F,,State inference for dynamically changing interfaces,Computer Languages,2001,27,4,163-202,,,,,2001,,0096-0551,https://www.sciencedirect.com/science/article/pii/S0096055101000194;http://dx.doi.org/10.1016/S0096-0551(01)00019-4,10.1016/S0096-0551(01)00019-4,"Types in current programming languages specify constant sets of messages always acceptable throughout the lifetime of the types’ instances. However, especially in concurrent object-oriented systems, the acceptability of messages often changes with the objects’ states. We propose a typed concurrent object calculus where static type checking ensures that users send only acceptable messages although message acceptability may change dynamically. The programmer specifies in types predictable state changes and dependences of message acceptance on states; a compiler infers the needed state information. This state inference has polynomial time complexity and can be used together with subtyping.","Type system, Concurrent object calculus, Behavioral typing",,,,,,,,,,,,,,,,,,,,,
Journal Article,"English M,Cahill T,Buckley J",,Construct specific coupling measurement for C++ software,"Computer Languages, Systems & Structures",2012,38,4,300-319,,,,,2012,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842412000243;http://dx.doi.org/10.1016/j.cl.2012.06.002,10.1016/j.cl.2012.06.002,"Studies which consider the extent to which the encapsulation of a class is weakened by direct access to its hidden members (such as through the use of the friend construct in C++) are scarce, and those that do exist are based on metric suites where the enabling mechanism of the coupling is ignored. This can lead to conclusions of limited construct validity where incorrect causes of coupling are suggested. In this paper a suite of software metrics which measure the amount of coupling enabled by different C++ programming language constructs (such as friendship and inheritance) are proposed. The metrics presented are based on a formal data model which can be easily adapted for other OO languages. This formal approach removes the scope for ambiguity in the metric definitions. These metrics provide a more accurate reflection of the causative agents of coupling in Object Oriented Systems and their utility is illustrated in an empirical study towards the end of the paper.","Coupling, Software metric, C++, Friend, Inheritance, Object-oriented software, Information hiding, Encapsulation, Software measurement",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Giannini P,Servetto M,Zucca E,Cone J",,Flexible recovery of uniqueness and immutability,Theoretical Computer Science,2019,764,,145-172,,,,,2019,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397518305668;http://dx.doi.org/10.1016/j.tcs.2018.09.001,10.1016/j.tcs.2018.09.001,"We present an imperative object calculus where types are annotated with qualifiers for aliasing and mutation control. There are two key novelties with respect to similar proposals. First, the type system is very expressive. Notably, it adopts the recovery approach, that is, using the type context to justify strengthening types, greatly improving its power by permitting to recover uniqueness and immutability properties even in presence of other references. This is achieved by rules which restrict the use of such other references in the portion of code which is recovered. Second, execution is modeled by a non standard operational model, where properties of qualifiers can be directly expressed on source terms, rather than as invariants on an auxiliary structure which mimics physical memory. Formally, this is achieved by the block construct, introducing local variable declarations, which, when evaluated, play the role of store.","Type systems, Imperative calculi, Immutability, Aliasing",Selected papers of ICTCS 2016 (The Italian Conference on Theoretical Computer Science (ICTCS),,,,,,,,,,,,,,,,,,,,
Journal Article,"Luo C,Qin S",,Separation Logic for Multiple Inheritance,Electronic Notes in Theoretical Computer Science,2008,212,,27-40,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108002661;http://dx.doi.org/10.1016/j.entcs.2008.04.051,10.1016/j.entcs.2008.04.051,"As an extension to Floyd-Hoare logic, separation logic has been used to facilitate reasoning about imperative programs manipulating shared mutable data structures. Recently, it has also been extended to support modular reasoning in Java-like object-oriented languages where only single inheritance is allowed. In this paper we propose an extension of separation logic to support also the reasoning for multiple inheritance in C++ -like languages. To cater for multiple inheritance, we modified the standard storage model for separation logic in a way that the correct reference to a field or a method can be easily determined. On top of this storage model, a set of proof rules are proposed. Our verification system also provides basic support for behavioral subtyping.","Multiple Inheritance, Separation Logic, Verification","Proceedings of the First International Conference on Foundations of Informatics, Computing and Software (FICS 2008)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Gil de Lamadrid J,Zimmerman J",,Core FOBS: A hybrid functional and object-oriented language,"Computer Languages, Systems & Structures",2012,38,3,214-241,,,,,2012,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842412000127;http://dx.doi.org/10.1016/j.cl.2012.04.002,10.1016/j.cl.2012.04.002,"We describe a computer language that is a hybrid between functional and object-oriented languages. The language is based on a simple structure called a FOB (functional-object), capable of being used as a function, or accessed as an object. FOBS is a dynamically typed, referentially transparent language, designed for use as a universal scripting language. An extensive library is integral to the language. The library implements the primitive types and provides an interface to the external environment, allowing scripting actions to be carried out. FOBS is structured as an extended language, that is reduced to a core language by macro expansion. Our paper provides an introduction to the core language, a brief discussion of the extended language, and formal specifications of syntax and semantics for the core. The formal semantic description for FOBS is somewhat unusual for a scripting language. However, this description ensures that the FOBS semantics is well-specified, allowing programmers to write well understood programs, increasing program reliability.","Object-oriented, Functional, Hybrid",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Staffetti E,Grau A,Serratosa F,Sanfeliu A",,Object and image indexing based on region connection calculus and oriented matroid theory,Discrete Applied Mathematics,2005,147,2,345-361,,,,,2005,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X04003683;http://dx.doi.org/10.1016/j.dam.2004.09.019,10.1016/j.dam.2004.09.019,"In this paper a novel method for indexing views of 3D objects is presented. The topological properties of the regions of views of an object or of a set of objects are used to define an index based on region connection calculus and oriented matroid theory. Both are formalisms for qualitative spatial representation and reasoning and are complementary in the sense that, whereas region connection calculus characterize connectivity of couples of connected regions of views, oriented matroids encode relative position of disjoint regions of views and give local and global topological information about their spatial distribution. This indexing technique has been applied to hypothesis generation from a single view to reduce the number of candidates in 3D object recognition processes.","Image indexing, Object recognition from a single view, Oriented matroid theory, Region connection calculus",Advances in Discrete Geometry and Topology,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang X,Zhang W",,Relations of attribute reduction between object and property oriented concept lattices,Knowledge-Based Systems,2008,21,5,398-403,,,,,2008,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705108000166;http://dx.doi.org/10.1016/j.knosys.2008.02.005,10.1016/j.knosys.2008.02.005,"As one of the basic problems of knowledge discovery and data analysis, knowledge reduction can make the discovery of implicit knowledge in data easier and the representation simpler. In this paper, relations of attribute reduction between object and property oriented formal concept lattices are discussed. And beautiful results are obtained that attribute reducts and attribute characteristics in the two concept lattices are the same based on new approaches to attribute reduction by means of irreducible elements. It turns out to be meaningful and effective in dealing with knowledge reduction, as attribute reducts and attribute characteristics in the object and property oriented formal concept lattices can be acquainted by only investigating one of the two concept lattices.","Object oriented concept lattice, Property oriented concept lattice, Attribute reduction, Partial relation, Irreducible element",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bono V,Patel A,Shmatikov V,Mitchell J",,A Core Calculus of Classes and Objects,Electronic Notes in Theoretical Computer Science,1999,20,,28-49,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104800653;http://dx.doi.org/10.1016/S1571-0661(04)80065-3,10.1016/S1571-0661(04)80065-3,"We present an imperative calculus for a class-based language. By introducing classes as the basic object-oriented construct in a λ-calculus with records and references, we obtain a system with an intuitive operational semantics. Objects are instantiated from classes and represented by records. The type system for objects uses only functional, record, and reference types, and there is a clean separation between subtyping and inheritance. We demonstrate that the calculus is sound and sufficiently expressive to model advanced language features such as inheritance with method redefinition, multi-level encapsulation, and modular object construction.","object-oriented language, class, calculus, operational semantics, type system.","MFPS XV, Mathematical Foundations of Progamming Semantics, Fifteenth Conference",,,,,,,,,,,,,,,,,,,,
Journal Article,"Maidl AM,Carvilhe C,Musicante MA",,Maude Object-Oriented Action Tool,Electronic Notes in Theoretical Computer Science,2008,205,,105-121,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108001734;http://dx.doi.org/10.1016/j.entcs.2008.03.068,10.1016/j.entcs.2008.03.068,"Object-Oriented Action Semantics (OOAS) incorporates object-oriented concepts to the Action Semantics formalism. Its main goal is to obtain more readable and reusable semantics specifications. Moreover, it supports syntax-independent specifications, due to the way classes are written. Maude Object-Oriented Action Tool (MOOAT) is an executable environment for Object-Oriented Action Semantics implemented as a conservative extension of Full Maude and Maude MSOS Tool (MMT). The Modular SOS of Action Notation has been implemented using MMT transitions and Full Maude has been used to implement the Classes Notation. The syntax created by MOOAT is fairly similar to the original Object-Oriented Action Semantics syntax. In addition to it, the tool combines the modularity aspects observed in the object-oriented approach with the efficient execution and analysis of the Maude system. We use MOOAT to describe syntax-independent specifications of programming languages. In this way, we show how Constructive Object-Oriented Action Semantics (COOAS) may be achieved as a combination between Object-Oriented Action Semantics and Constructive Action Semantics (CAS) using MOOAT, in order to increase the modularity aspects observed in the object-oriented formalism. This paper reports on the development of Maude Object-Oriented Action Tool and its application to the formal specification of programming languages.","Constructive Action Semantics, Formal Semantics, Maude, Modular Structural Operational Semantics, Object-Oriented Action Semantics","Proceedings of the Second Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2007)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Riecke JG,Stone CA",,Privacy via Subsumption,Information and Computation,2002,172,1,2-28,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540100929250;http://dx.doi.org/10.1006/inco.2000.2925,10.1006/inco.2000.2925,"We describe an object calculus allowing object extension and structural subtyping. Each object has a “dictionary” to mediate the connection between names and components. This extra indirection yields the first object calculus combining both object extension and full width subtyping in a type-safe manner. If class inheritance is modeled with object extension, private fields and methods can be achieved directly by scoping restrictions: private fields or methods are those hidden by subsumption. We prove that the type system is sound, discuss a variant allowing covariant self types, and give some examples of the expressiveness of the calculus.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Derrick J,Boiten E,Bowman H,Steen M",,Viewpoints and consistency: translating lotos to Object-z,Computer Standards & Interfaces,1999,21,3,251-272,,,,,1999,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548999000100;http://dx.doi.org/10.1016/S0920-5489(99)00010-0,10.1016/S0920-5489(99)00010-0,"This paper presents a translation between the formal description technique lotos and the object-oriented specification language Object-z. The need for such a translation lies in the use of formal methods in viewpoint specification, and in particular in the Open Distributed Processing standard. The use of viewpoints as a set of partial interlocking specifications brings an obligation to check the consistency of these partial specifications, and to do so we need to relate specifications written in differing languages. The work presented here aims to support the consistency checking of viewpoints written using formal methods by defining a translation from lotos to Object-z. A lotos specification describes both an ADT component and a behavioural model, the former is translated into the z type system, and the behavioural specification is translated into a collection of Object-z classes where we relate lotos actions to operations in the Object-z specification. A case study is presented, illustrating the translation and consistency checking techniques discussed in the paper.","Distributed systems, Open distributed processing, Formal methods (Object-, ), Viewpoints, Consistency, Partial specification",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bettini L,Damiani F,Geilmann K,Schäfer J",,Combining traits with boxes and ownership types in a Java-like setting,Science of Computer Programming,2013,78,2,218-247,,,,,2013,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642311001833;http://dx.doi.org/10.1016/j.scico.2011.10.006,10.1016/j.scico.2011.10.006,"The box model is a lightweight component model for the object-oriented paradigm, which structures the flat object-heap into hierarchical runtime components called boxes. Boxes have clear runtime boundaries that divide the objects of a box into objects that can be used to interact with the box (the boundary objects) and objects that are encapsulated and represent the state of the box (the local objects). The distinction into local and boundary objects is statically achieved by an ownership type system for boxes that uses domain annotations to classify objects into local and boundary objects and that guarantees that local objects can never be directly accessed by the context of a box. A trait is a set of methods divorced from any class hierarchy. Traits are units of fine-grained reuse that can be composed together to form classes or other traits. This paper integrates traits into an ownership type system for boxes. This combination is fruitful in two ways: it can statically guarantee encapsulation of objects and still provide fine-grained reuse among classes that goes beyond the possibilities of standard inheritance. It also solves a specific problem of the box ownership type system: namely that box classes cannot inherit from standard classes (and vice versa), and thus code sharing between these two kinds of classes was not possible in this setting so far. We present an ownership type system and the corresponding soundness proofs that guarantee encapsulation of objects in an object-oriented language with traits.","Boxes, Featherweight Java, Ownership types, Traits",Coordination 2010,,,,,,,,,,,,,,,,,,,,
Journal Article,Beeri C,,A formal approach to object-oriented databases,Data & Knowledge Engineering,1990,5,4,353-382,,,,,1990,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9090020E;http://dx.doi.org/10.1016/0169-023X(90)90020-E,10.1016/0169-023X(90)90020-E,"Object-oriented database systems are the focus of current research and development efforts. Yet, there is no commonly accepted object model, nor is it clear whether such a model can be developed. This paper reports on efforts to develop a formal framework that contains most features found in current object oriented database systems. The framework contains two parts. The first is a structural object model, including concepts such as structured objects, identity, and some form of inheritance. For this model, we explain the distinction between values and (abstract) objects, describe a system as a directed graph, and discuss declarative languages. The second part deals with higher-order concepts, such as classes and functions as data, methods, and inheritance. This part is a sketch, and leaves many issues unresolved. Throughout the paper, the emphasis is on logic-oriented modeling.","Object-oriented database systems, Formal model, Declarative languages, Higher-order logic, Methods",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ghoreshi M,Haghighi H",,An incremental method for extracting tests from object-oriented specification,Information and Software Technology,2016,78,,1-26,,,,,2016,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584916300854;http://dx.doi.org/10.1016/j.infsof.2016.05.005,10.1016/j.infsof.2016.05.005,"Context The nature of the object-oriented development process is iterative and incremental, and through this process, software artifacts are refined and evolved continuously; however, most of proposed methods for deriving test cases from formal, object-oriented specifications have been adapted from previous structural techniques and are not aligned with such an incremental process. These methods are not adaptive with changes in the software specification, and there is no mechanism to evolve test artifacts respectively. Moreover, the existing methods do not cover all different object-oriented testing levels, i.e., intra-method, inter-method, intra-class and inter-class levels. Objective This paper presents an incremental method for extracting tests from formal, object-oriented specifications. Extracted tests are adaptive with changes in the class specification. In addition, the proposed method covers all different object-oriented testing levels. Method We first make a test machine (as a new notion introduced in this paper) for each class operation to cover the intra-method test level. With the combination of these test machines, new test machines covering the inter-method and intra-class test levels can be made. Extracted tests can be easily modified when the class specification is modified, and, in this way, our approach enables iterative and incremental test derivation. With test machines corresponding to a class hierarchy, this approach can also be used for deriving inter-class tests. Results As a case study, we applied our method to the specification of a computer game. Results indicate that test machines can incrementally be extracted through a class hierarchy, and a parent test machine can be used to obtain its corresponding child test machines (by reusing test artifacts). Furthermore, by running extracted test cases on the implemented game, we discovered some real bugs. Conclusion The proposed approach can incrementally extract tests and bring extendibility and reusability as two main advantages of the object- oriented paradigm to the test domain.","Test case generation, Formal specification, Specification-based testing, Object orientation, Object-Z",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dovland J,Broch Johnsen E,Owe O,Steffen M",,Incremental reasoning with lazy behavioral subtyping for multiple inheritance,Science of Computer Programming,2011,76,10,915-941,,,,,2011,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642310001723;http://dx.doi.org/10.1016/j.scico.2010.09.006,10.1016/j.scico.2010.09.006,"Object-orientation supports code reuse and incremental programming. Multiple inheritance increases the possibilities for code reuse, but complicates the binding of method calls and thereby program analysis. Behavioral subtyping allows program analysis under an open world assumption; i.e., under the assumption that class hierarchies are extensible. However, method redefinition is severely restricted by behavioral subtyping, and multiple inheritance may lead to conflicting restrictions from independently designed superclasses. This paper presents a more liberal approach to incremental reasoning for multiple inheritance under an open world assumption. The approach, based on lazy behavioral subtyping, is well-suited for multiple inheritance, as it incrementally imposes context-dependent behavioral constraints on new subclasses. We first present the approach for a simple language and show how incremental reasoning can be combined with flexible code reuse. Then this language is extended with a hierarchy of interface types which is independent of the class hierarchy. In this setting, flexible code reuse can be combined with modular reasoning about external calls in the sense that each class is analyzed only once. We formalize the approach as a calculus and show soundness for both languages.","Lazy behavioral subtyping, Object orientation, Multiple inheritance, Late binding, Proof systems, Code reuse, Method redefinition, Incremental reasoning",Integrated Formal Methods (iFM09),,,,,,,,,,,,,,,,,,,,
Journal Article,Mernik M,,An object-oriented approach to language compositions for software language engineering,Journal of Systems and Software,2013,86,9,2451-2464,,,,,2013,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121213001271;http://dx.doi.org/10.1016/j.jss.2013.04.087,10.1016/j.jss.2013.04.087,"In this paper, it is shown that inheritance, a core concept from object-oriented programming, is a possible solution for realizing composition of computer languages. Language composability is a property of language descriptions, which can be further classified into informal (language syntax and semantics are hard-coded in compiler/interpreter) and formal language descriptions (syntax and semantics are formally specified with one of several formal methods for language definition). However, language composition is much easier to achieve with declarative formal language descriptions into which the notion of inheritance is introduced. Multiple attribute grammar inheritance, as implemented in the language implementation system LISA, can assist in realizing all of the different types of language compositions identified in Erdweg et al. (2012). Different examples are given throughout the paper using an easy to understand domain-specific language that describes simple robot movement.","Software language engineering, Language composition, Domain-specific languages",,,,,,,,,,,,,,,,,,,,,
Journal Article,Ierusalimschy R,,A denotational approach for type-checking in object-oriented programming languages,Computer Languages,1993,19,1,19-40,,,,,1993,,0096-0551,https://www.sciencedirect.com/science/article/pii/0096055193900372;http://dx.doi.org/10.1016/0096-0551(93)90037-2,10.1016/0096-0551(93)90037-2,"Starting with a pragmatical (but formal) definition of type in object-oriented languages, this paper proposes a method to test type safety in this kind of language. We say that a language is (type) safe if it ensures that, during the execution of a correct program, every message sent to an object is matched by an appropriate method. We define a “typical” object oriented programming language, featuring multiple inheritance, recursive types, and separation between specifications and implementations. Then, we give a formal definition for its type system, and a denotational semantics for the execution of the language, based on message passing. Finally, we formally prove that our language is type safe. Along the progress of the work, better understanding is gained about many problems related with type systems in object-oriented languages.","semantics of programming languages, type systems, object oriented programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,Ghelli G,,Termination of SystemF-bounded: A Complete Proof,Information and Computation,1997,139,1,39-56,,,,,1997,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540197926626;http://dx.doi.org/10.1006/inco.1997.2662,10.1006/inco.1997.2662,"SystemF-bounded is a second-order typedλ-calculus with subtyping which has been defined to carry out foundational studies about the type systems of object-oriented languages. The almost recursive nature of the essential feature of this system makes one wonder whether it retains the strong normalization property, with respect to first- and second-orderβϵreduction of systemF⩽. We prove that this is the case. The proof is carried out to the last detail to allow the reader to be convinced of its correctness.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fisher K,Reppy J",,Inheritance-Based Subtyping,Information and Computation,2002,177,1,28-55,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S089054010293169X;http://dx.doi.org/10.1006/inco.2002.3169,10.1006/inco.2002.3169,"Classes play a dual role in mainstream statically typed object-oriented languages, serving as both object generators and object types. In such languages, inheritance implies subtyping. In contrast, the theoretical language community has viewed this linkage as a mistake and has focused on subtyping relationships determined by the structure of object types, without regard to their underlying implementations. In this paper, we explore why inheritance-based subtyping relations are useful, and we describe two different approaches to extending the MOBY programming language with inheritance-based subtyping relations. In addition, we present a typed object calculus that supports both structural and inheritance-based subtyping, and which provides a formal accounting of our extensions to MOBY.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Paulweber P,Simhandl G,Zdun U",,On the Understandability of Language Constructs to Structure the State and Behavior in Abstract State Machine Specifications: A Controlled Experiment,Journal of Systems and Software,2021,178,,110987,,,,,2021,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121221000844;http://dx.doi.org/10.1016/j.jss.2021.110987,10.1016/j.jss.2021.110987,"Abstract State Machine (ASM) theory is a well-known state-based formal method to analyze and specify software and hardware systems. As in other state-based formal methods, the proposed modeling languages for ASMs still lack easy-to-comprehend abstractions to structure state and behavior aspects of specifications. Modern object-oriented languages offer a variety of advanced language constructs, and most of them either offer interfaces, mixins, or traits in addition to classes and inheritance. Our goal is to investigate these language constructs in the context of state-based formal methods using ASMs as a representative of this kind of formal methods. We report on a controlled experiment with 105 participants to study the understandability of the three language constructs in the context of ASMs. Our hypotheses are influenced by the debate of object-oriented communities. We hypothesized that the understandability (measured by correctness and duration variables) shows significantly better understanding for interfaces and traits compared to mixins, as well as at least a similar or better understanding for traits compared to interfaces. The results indicate that understandability of interfaces and traits show a similar good understanding, whereas mixins shows a poorer understanding. We found a significant difference for the correctness of understanding comparing interfaces with mixins.","Abstract State Machines, Empirical software engineering, Understandability, Language constructs, Controlled experiment",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fournet C,Laneve C,Maranget L,Rémy D",,Inheritance in the join calculus,The Journal of Logic and Algebraic Programming,2003,57,1,23-69,,,,,2003,,1567-8326,https://www.sciencedirect.com/science/article/pii/S1567832603000407;http://dx.doi.org/10.1016/S1567-8326(03)00040-7,10.1016/S1567-8326(03)00040-7,"We design an extension of the join calculus with class-based inheritance. Method calls, locks, and states are handled in a uniform manner, using asynchronous messages. Classes are partial message definitions that can be combined and transformed by means of operators for behavioral and synchronization inheritance. We also give a polymorphic type system that statically enforces basic safety properties. Our language and its type system are compatible with the JoCaml implementation of the join calculus.","Concurrent objects, Inheritance, Type systems, Polymorphism, Safety properties",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Arévalo G,Ducasse S,Gordillo S,Nierstrasz O",,Generating a catalog of unanticipated schemas in class hierarchies using Formal Concept Analysis,Information and Software Technology,2010,52,11,1167-1187,,,,,2010,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584910000996;http://dx.doi.org/10.1016/j.infsof.2010.05.010,10.1016/j.infsof.2010.05.010,"Context Inheritance is the cornerstone of object-oriented development, supporting conceptual modeling, subtype polymorphism and software reuse. But inheritance can be used in subtle ways that make complex systems hard to understand and extend, due to the presence of implicit dependencies in the inheritance hierarchy. Objective Although these dependencies often specify well-known schemas (i.e., recurrent design or coding patterns, such as hook and template methods), new unanticipated dependency schemas arise in practice, and can consequently be hard to recognize and detect. Thus, a developer making changes or extensions to an object-oriented system needs to understand these implicit contracts defined by the dependencies between a class and its subclasses, or risk that seemingly innocuous changes break them. Method To tackle this problem, we have developed an approach based on Formal Concept Analysis. Our Formal Concept Analysis based-Reverse Engineering methodology (FoCARE) identifies undocumented hierarchical dependencies in a hierarchy by taking into account the existing structure and behavior of classes and subclasses. Results We validate our approach by applying it to a large and non-trivial case study, yielding a catalog of hierarchy schemas, each one composed of a set of dependencies over methods and attributes in a class hierarchy. We show how the discovered dependency schemas can be used not only to identify good design practices, but also to expose bad smells in design, thereby helping developers in initial reengineering phases to develop a first mental model of a system. Although some of the identified schemas are already documented in existing literature, with our approach based on Formal Concept Analysis (FCA), we are also able to identify previously unidentified schemas. Conclusions FCA is an effective tool because it is an ideal classification mining tool to identify commonalities between software artifacts, and usually these commonalities reveal known and unknown characteristics of the software artifacts. We also show that once a catalog of useful schemas stabilizes after several runs of FoCARE, the added cost of FCA is no longer needed.","Object-oriented development, Class hierarchy schemas, Source code analysis, Formal Concept Analysis",Special Section on Best Papers PROMISE 2009,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yu X,Wang Z,Pu G,Mao D,Liu J",,The Verification of rCOS Using Spin,Electronic Notes in Theoretical Computer Science,2008,207,,49-67,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108001904;http://dx.doi.org/10.1016/j.entcs.2008.03.085,10.1016/j.entcs.2008.03.085,"The rCOS is a relational object-based language with a precise observation-oriented semantics. It can capture key features of object model including subtypes, visibility, inheritance, polymorphism and so on. To analyze the model specified by rCOS, we propose a verification approach to check whether those properties such as the assertion, invariant of class and method contracts hold. The Spin model checker is used in this approach. To enhance the ability of description of concurrency, we extend the original rCOS with parallel structure and synchronization mechanism. The Promela model is constructed from rCOS specification with non-trivial mapping rules. We also present a case study to show how our approach works.","Verification, rCOS, Object Model, Spin",Proceedings of the 1st International Workshop on Harnessing Theories for Tool Support in Software (TTSS 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Wirsing M,Knapp A",,A formal approach to object-oriented software engineering,Theoretical Computer Science,2002,285,2,519-560,,,,,2002,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439750100367X;http://dx.doi.org/10.1016/S0304-3975(01)00367-X,10.1016/S0304-3975(01)00367-X,"We show how formal specifications can be integrated into one of the current pragmatic object-oriented software development methods. Jacobson's “object-oriented software engineering” process is combined with object-oriented algebraic specifications by extending object and interaction diagrams with formal annotations. The specifications are based on Meseguer's rewriting logic and are written in a meta-level extension of the language Maude by process expressions. As a result any such diagram can be associated with a formal specification, proof obligations ensuring invariant properties can be automatically generated, and the refinement relations between documents at different abstraction levels can be formally stated and proved.","Integrated formal software engineering, OOSE, Rewriting logic, Maude, Reflection, Process algebra",Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Giannini P,Richter T,Servetto M,Zucca E",,Tracing sharing in an imperative pure calculus,Science of Computer Programming,2019,172,,180-202,,,,,2019,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642318304337;http://dx.doi.org/10.1016/j.scico.2018.11.007,10.1016/j.scico.2018.11.007,"We introduce a type and effect system, for an imperative object calculus, which infers sharing possibly introduced by the evaluation of an expression, represented as an equivalence relation among its free variables. This direct representation of sharing effects at the syntactic level allows us to express in a natural way, and to generalize, widely-used notions in literature, notably uniqueness and borrowing. Moreover, the calculus is pure in the sense that reduction is defined on language terms only, since they directly encode store. The advantage of this non-standard execution model with respect to a behaviorally equivalent standard model using a global auxiliary structure is that reachability relations among references are partly encoded by scoping.","Imperative calculi, Sharing, Type and effect systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Caromel D,Henrio L,Serpette BP",,Asynchronous sequential processes,Information and Computation,2009,207,4,459-495,,,,,2009,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540108001582;http://dx.doi.org/10.1016/j.ic.2008.12.004,10.1016/j.ic.2008.12.004,"Deterministic behavior for parallel and distributed computation is rather difficult to ensure. To reach that goal, many formal calculi, languages, and techniques with well-defined semantics have been proposed in the past. But none of them focused on an imperative object calculus with asynchronous communications and futures. In this article, an object calculus, Asynchronous Sequential Processes (ASP), is defined, with its semantics. We prove also confluence properties for the ASP calculus. ASPs main characteristics are asynchronous communications with futures, and sequential execution within each process. This paper provides a very general and dynamic property ensuring confluence. Further, more specific and static properties are derived. Additionally, we present a formalization of distributed components based on ASP, and show how such components are used to statically ensure determinacy. This paper can also be seen as a formalization of the concept of futures in a distributed object setting.","Object calculus, Concurrency, Distribution, Parallelism, Object-oriented languages, Components, Determinism, Futures",,,,,,,,,,,,,,,,,,,,,
Journal Article,Logozzo F,,An Approach to Behavioral Subtyping Based on Static Analysis,Electronic Notes in Theoretical Computer Science,2005,116,,157-170,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104052843;http://dx.doi.org/10.1016/j.entcs.2004.02.074,10.1016/j.entcs.2004.02.074,"In mainstream object oriented languages the subclass relation is defined in terms of subtyping, i.e. a class A is a subclass of B if the type of A is a subtype of B. In this paper this notion is extended to consider arbitrary class properties obtained by a modular static analysis of the class. In such a setting, the subclass relation boils down to the order relation on the abstract domain used for the analysis of the classes. Furthermore we show how this approach yields a more semantic characterization of class hierarchies and how it can be used for an effective modular analysis of polymorphic code.","Abstract Interpretation, Inheritance, Object Oriented Languages, Semantics, Specialized Application Languages, Static Analysis",Proceedings of the International Workshop on Test and Analysis of Component Based Systems (TACoS 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Wan Q,Wei L",,Approximate concepts acquisition based on formal contexts,Knowledge-Based Systems,2015,75,,78-86,,,,,2015,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705114004201;http://dx.doi.org/10.1016/j.knosys.2014.11.020,10.1016/j.knosys.2014.11.020,"Formal concepts are abstraction and formalization of the concepts in philosophy. Acquisition of formal concepts is the base of formal concept analysis. Besides the concrete concepts, uncertain but meaningful concepts sometimes are more appropriate for real life. The paper begins with this practical problem and obtains some interesting knowledge based on formal contexts. First, k-grade relation on the object set of a formal context is defined, and the different values of k in different cases are discussed in detail. Then the algorithms to acquire approximate concepts associated with each object are proposed and these approximate concepts are explained. Second, the relationships between approximate concepts associated with objects and concepts of concept lattice (property oriented concept lattice) are studied. Parallel to the above idea, k-grade relation on the attribute set is proposed dually, and approximate concepts associated with each attribute are obtained and interpreted. Meanwhile, the relationships between approximate concepts associated with attributes and concepts of concept lattice (object oriented concept lattice) are also discussed.","Formal concept, Approximate concept, Concept lattice, -Grade relation, Rough set",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Capecchi S,Coppo M,Dezani-Ciancaglini M,Drossopoulou S,Giachino E",,Amalgamating sessions and methods in object-oriented languages with generics,Theoretical Computer Science,2009,410,2,142-167,,,,,2009,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397508006671;http://dx.doi.org/10.1016/j.tcs.2008.09.016,10.1016/j.tcs.2008.09.016,"We suggest an amalgamation of communication-based programming (centered on sessions) and object-oriented programming, whereby sessions between concurrent threads are amalgamated with methods. In our proposal, threads consist of the execution of session bodies on objects and communicate with each other by asynchronously sending/receiving objects on channels. The response to a session request is based on the name of the request and the class of the object receiving the request. The decision of how to continue a session is based on the class of the object sent/received. Sessions can be delegated to other sessions, although sessions themselves are not first class objects. We demonstrate our ideas through a core language with generic types, SAMg, and an example. We then formalize a small calculus, FSAMg, and prove subject reduction and progress. The latter property is notoriously difficult to achieve in concurrent calculi.","Session types, Foundations of object-oriented programming, Subject reduction, Progress",Distributed Computing Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kerbœuf M,Talpin JP",,Encapsulation and behavioral inheritance in a synchronous model of computation for embedded system services adaptation,The Journal of Logic and Algebraic Programming,2005,63,2,241-269,,,,,2005,,1567-8326,https://www.sciencedirect.com/science/article/pii/S1567832604000384;http://dx.doi.org/10.1016/j.jlap.2004.05.005,10.1016/j.jlap.2004.05.005,"Because it encourages the incremental development of software and the reuse of code by abstracting away implementation details, object orientation is an intuitive and sensible way to conceive large software out of existing application components and libraries. In practice, however, object-orientation is most of the time applied and used with sequentiality in mind. This practice may sometimes be conceptually inadequate for, eg., control-dominated reactive system components. We address this issue by proposing a process calculus that melts the paradigm of synchronous programming to key object-oriented features: encapsulation and behavioral inheritance with overriding by means of specific algebraic concurrency combinators. This framework provides support for the reuse of components and, more specifically, for the adaptation of embedded systems with new services. Cast in the context of a strict interpretation of the synchronous hypothesis, the proposed model supports a static interpretation of inheritance: overriding is resolved at compile-time (or link-time) and inheritance combinators are translated into primitive synchronous ones. This compilation technique puts object-orientation to work in a syntax-oriented model of synchronous concurrency that naturally supports the incremental, refinement-based design of concurrent systems starting from encapsulated and reused application components. The benefits of our approach are illustrated by a concrete and practical example: the adaptation of services to a plain old telephone service specification.","Synchronous programming, Process calculi, Encapsulation, Reuse and behavioral inheritance.",Special Issue on Process Algebra and System Architecture,,,,,,,,,,,,,,,,,,,,
Journal Article,"Geetha V,Sreenath N",,Preventing deadlocks and starvation in distributed object oriented systems,Computers & Electrical Engineering,2013,39,2,582-595,,,,,2013,,0045-7906,https://www.sciencedirect.com/science/article/pii/S0045790613000050;http://dx.doi.org/10.1016/j.compeleceng.2012.12.025,10.1016/j.compeleceng.2012.12.025,"This paper proposes a deadlock prevention algorithm for distributed object oriented systems based on the popular resource ordering technique. In distributed object oriented system, objects are the resources requested by the transactions. Though resource-ordering technique is not new, novelty of the proposed deadlock prevention algorithm lies in exploiting the relationships among objects present in the domain to do the resource ordering. Resource ordering rules are formally represented using predicate calculus. This algorithm also addresses the elimination of starvation in wealth and starvation in poverty by proposing a combination of timestamp and expedient access ordering of transactions in accessing the resources.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kogtenkov A,Meyer B,Velder S",,"Alias calculus, change calculus and frame inference",Science of Computer Programming,2015,97,,163-172,,,,,2015,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642313002906;http://dx.doi.org/10.1016/j.scico.2013.11.006,10.1016/j.scico.2013.11.006,"Alias analysis, which determines whether two expressions in a program may reference to the same object, has many potential applications in program construction and verification. We have developed a theory for alias analysis, the “alias calculus”, implemented its application to an object-oriented language, and integrated the result into a modern IDE. The calculus has a higher level of precision than many existing alias analysis techniques. One of the principal applications is to allow automatic change analysis, which leads to inferring “modifies” clauses, providing a significant advance towards addressing the Frame Problem. Experiments were able to infer the “modifies” clauses of an existing formally specified library. Other applications, in particular to concurrent programming, also appear possible. The article presents the calculus, the application to frame inference including experimental results, and other projected applications. The ongoing work includes building more efficient model capturing aliasing properties and soundness proof for its essential elements.","Verification, Alias analysis, Frame inference, Object-oriented, Static analysis",Special Issue on New Ideas and Emerging Results in Understanding Software,,,,,,,,,,,,,,,,,,,,
Journal Article,"Olderog ER,Wehrheim H",,Specification and (property) inheritance in CSP-OZ,Science of Computer Programming,2005,55,1,227-257,,,,,2005,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642304001522;http://dx.doi.org/10.1016/j.scico.2004.05.017,10.1016/j.scico.2004.05.017,"CSP-OZ [C. Fischer, CSP-OZ: A combination of Object-Z and CSP, in: H. Bowman, J. Derrick (Eds.), Formal Methods for Open Object-Based Distributed Systems, FMOODS’97, vol. 2, Chapman & Hall, 1997, pp. 423–438] is a combination of Communicating Sequential Processes (CSP) and Object-Z (OZ). It enables the specification of systems having both a state-based and a behaviour-oriented view using the object-oriented concepts of classes, instantiation and inheritance. CSP-OZ has a process semantics in the failure divergence model of CSP. In this paper we explain CSP-OZ and investigate the notion of inheritance. Furthermore, we study the issue of property inheritance among classes. We prove in a uniform way that behavioural subtyping relations between classes introduced in [H. Wehrheim, Behavioural subtyping in object-oriented specification formalisms, University of Oldenburg, Habilitation Thesis, 2002] guarantee the inheritance of safety and “liveness” properties.","CSP, Object-Z, Failures divergence semantics, Inheritance, Safety and “liveness” properties, Model-checking, FDR",Formal Methods for Components and Objects: Pragmatic aspects and applications,,,,,,,,,,,,,,,,,,,,
Journal Article,Philippi S,,Formally based modeling and inheritance of behaviour in object-oriented systems,Journal of Systems and Software,2004,70,1,129-142,,,,,2004,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121203000116;http://dx.doi.org/10.1016/S0164-1212(03)00011-6,10.1016/S0164-1212(03)00011-6,"Despite the popularity of (graphical) notations for the specification of object behaviour, there is no common understanding of what exactly constitutes the life cycle of an object. Consequently, different frameworks for the object-oriented modeling of systems allow for the specification of different kinds of behaviour. Unfortunately, the semantics of languages used in this area is often not clearly stated. In addition to the problems arising from this lack of formality, inheritance of behaviour is usually not covered by commonly used object-oriented languages. Therefore, flawless systems are difficult to build, because unpleasant surprises most easily occur if an object of a subclass is used in the context of its superclass. In the light of these problems this article states requirements for languages in the area of modeling and inheritance of object behaviour, surveys existing proposals, and introduces a novel approach.","Systems modeling, Object-orientation, Concurrency, Object life cycles, Object behaviour, Dynamic models, Inheritance, Petri-Nets",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cornélio M,Cavalcanti A,Sampaio A",,Sound refactorings,Science of Computer Programming,2010,75,3,106-133,,,,,2010,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642309001300;http://dx.doi.org/10.1016/j.scico.2009.10.001,10.1016/j.scico.2009.10.001,"Refactoring consists in restructuring an object-oriented program without changing its behaviour. In this paper, we present refactorings as transformation rules for programs written in a refinement language inspired on Java that allows reasoning about object-oriented programs and specifications. A set of programming laws is available for the imperative constructs of this language as well as for its object-oriented features; soundness of the laws is proved against a weakest precondition semantics. The proof that the refactoring rules preserve behaviour (semantics) is accomplished by the application of these programming laws and data simulation. As illustration of our approach to refactoring, we use our rules to restructure a program to be in accordance with a design pattern.","Refactoring, Formal methods, Refinement calculus, Object-oriented programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Inoue H,Igarashi A",,"A type system for first-class layers with inheritance, subtyping, and swapping",Science of Computer Programming,2019,179,,54-86,,,,,2019,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642319300619;http://dx.doi.org/10.1016/j.scico.2019.03.008,10.1016/j.scico.2019.03.008,"Context-Oriented Programming (COP) is a programming paradigm to encourage modularization of context-dependent software. Key features of COP are layers—modules to describe context-dependent behavioral variations of a software system—and their dynamic activation, which can modify the behavior of multiple objects that have already been instantiated. Typechecking programs written in a COP language is difficult because the activation of a layer can even change objects' interfaces. Inoue et al. have informally discussed how to make JCop, an extension of Java for COP by Appeltauer et al., type-safe. In this article, we formalize a small COP language called ContextFJ<: with its operational semantics and type system and show its type soundness. The language models main features of the type-safe version of JCop, including dynamically activated first-class layers, inheritance of layer definitions, layer subtyping, and layer swapping.","Context-oriented programming, Dynamic layer composition, First-class layers, Layer inheritance, Type systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shah A,Fotouhi F,Grosky W",,Share-kno: Knowledge Sharing Mechanism of the Temporal Object System,Journal of King Saud University - Computer and Information Sciences,1999,11,,25-43,,,,,1999,,1319-1578,https://www.sciencedirect.com/science/article/pii/S1319157899800020;http://dx.doi.org/10.1016/S1319-1578(99)80002-0,10.1016/S1319-1578(99)80002-0,"Temporal Object System (TOS) handles the structural and stature changes to an object in a uniform and temporal fashion. The TOS takes a hybrid approach of the class-based and prototype-based approaches in modeling the real-word objects and knowledge sharing among the objects. This hybrid approach makes it flexible than the two approaches, i.e., the class-based approach and the prototype-based approach. In this paper, we propose a model of knowledge sharing mechanism, Share-kno (SK) for object hierarchy of the TOS. We also formally prove that the Share-kno (SK) model encapsulates more knowledge than the inheritance hierarchy and delegation hierarchy models proposed by Stein.","Object-oriented Databases, Temporal Database, Temporal Objects, Knowledge Sharing, Mechanism, Inheritance, Delegation, Modeling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aceto L,Hüttel H,Ingólfsdóttir A,Kleist J",,Relating Semantic Models for the Object Calculus: Preliminary Report,Electronic Notes in Theoretical Computer Science,1997,7,,3-18,,,,,1997,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105804621;http://dx.doi.org/10.1016/S1571-0661(05)80462-1,10.1016/S1571-0661(05)80462-1,"Abadi and Cardelli have investigated several versions of the ç-calculus, a calculus for describing central features of object-oriented programs, with particular emphasis on various type systems. In this paper we study the properties of a denotational semantics due to Abadi and Cardelli vis-à-vis the notion of observational congruence for the calculus Ob1<:μ. In particular, we prove that the denotational semantics based on partial equivalence relations is correct with respect to observational congruence. By means of a counter-example, we argue that the denotational model is not fully abstract with respect to observational congruence. In fact, the model is able to distinguish objects that have the same behaviour in every Ob1<:μ-context.",,EXPRESS'97,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hainry E,Péchoux R",,A type-based complexity analysis of Object Oriented programs,Information and Computation,2018,261,,78-115,,,,,2018,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540118300786;http://dx.doi.org/10.1016/j.ic.2018.05.006,10.1016/j.ic.2018.05.006,"A type system is introduced for a generic Object Oriented programming language in order to infer resource upper bounds. A sound and complete characterization of the set of polynomial time computable functions is obtained. As a consequence, the heap-space and the stack-space requirements of typed programs are also bounded polynomially. This type system is inspired by previous works on Implicit Computational Complexity, using tiering and non-interference techniques. The presented methodology has several advantages. First, it provides explicit big O polynomial upper bounds to the programmer, hence its use could allow the programmer to avoid memory errors. Second, type checking is decidable in polynomial time. Last, it has a good expressivity since it analyzes most object oriented features like inheritance, overload, override and recursion. Moreover it can deal with loops guarded by objects and can also be extended to statements that alter the control flow like break or return.","Object Oriented Program, Type system, Complexity, Polynomial time",Developments in Implicit Computational Complexity (DICE) 2014 and 2015,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jifeng H,Li X,Liu Z",,rCOS: A refinement calculus of object systems,Theoretical Computer Science,2006,365,1,109-142,,,,,2006,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439750600483X;http://dx.doi.org/10.1016/j.tcs.2006.07.034,10.1016/j.tcs.2006.07.034,"This article presents a mathematical characterization of object-oriented concepts by defining an observation-oriented semantics for a relational object-based language with a rich variety of features including subtypes, visibility, inheritance, type casting, dynamic binding and polymorphism. The language can be used to specify object-oriented designs as well as programs. We present a calculus that supports both structural and behavioural refinement of object-oriented designs. The design calculus is based on the predicate logic in Hoare and He's Unifying Theories of Programming (UTP).","Object orientation, Refinement, Semantics, UTP",Formal Methods for Components and Objects,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ábrahám E,Grabe I,Grüner A,Steffen M",,Behavioral interface description of an object-oriented language with futures and promises,The Journal of Logic and Algebraic Programming,2009,78,7,491-518,,,,,2009,,1567-8326,https://www.sciencedirect.com/science/article/pii/S1567832609000022;http://dx.doi.org/10.1016/j.jlap.2009.01.001,10.1016/j.jlap.2009.01.001,"This paper formalizes the observable interface behavior of a concurrent, object-oriented language with futures and promises. The calculus captures the core of Creol, a language, featuring in particular asynchronous method calls and, since recently, first-class futures. The focus of the paper are open systems and we formally characterize their behavior in terms of interactions at the interface between the program and its environment. The behavior is given by transitions between typing judgments, where the absent environment is represented abstractly by an assumption context. A particular challenge is the safe treatment of promises: The erroneous situation that a promise is fulfilled twice, i.e., bound to code twice, is prevented by a resource aware type system, enforcing linear use of the write-permission to a promise. We show subject reduction and the soundness of the abstract interface description.","Concurrent object-oriented languages, Creol, Formal semantics, Concurrency, Futures and promises, Open systems, Observable behavior",The 19th Nordic Workshop on Programming Theory (NWPT 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Ensing M,Paton R,Speel PH,Rada R",,An object-oriented approach to knowledge representation in a biomedical domain,Artificial Intelligence in Medicine,1994,6,6,459-482,,,,,1994,,0933-3657,https://www.sciencedirect.com/science/article/pii/0933365794900256;http://dx.doi.org/10.1016/0933-3657(94)90025-6,10.1016/0933-3657(94)90025-6,"An object-oriented approach has been applied to the different stages involved in developing a knowledge base about insulin metabolism. At an early stage the separation of terminological and assertional knowledge was made. The terminological component was developed by medical experts and represented in CORE. An object-oriented knowledge acquisition process was applied to the assertional knowledge. A frame description is proposed which includes features like states and events, inheritance and collaboration. States and events are formalized with qualitative calculus. The terminological knowledge was very useful in the development of the assertional component. It assisteed in understanding the problem domain, and in the implementation stage, it assisted in building good inheritance hierarchies.","Knowledge acquisition, Object-oriented modelling, Medical terminology",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Drossopoulou S,Petrounias A,Buckley A,Eisenbach S",,SCHOOL: a Small Chorded Object-Oriented Language,Electronic Notes in Theoretical Computer Science,2006,135,3,37-47,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106000855;http://dx.doi.org/10.1016/j.entcs.2005.09.019,10.1016/j.entcs.2005.09.019,"Chords are a declarative synchronisation construct based on the Join-calculus, available in the programming language C-omega. To our knowledge, chords have no formal model in an object-oriented setting. In this paper we suggest SCHOOL, a formal model for an imperative, object-oriented language with chords. We give an operational semantics and type system, and can prove soundness of the type system.","chords, join, concurrency, object-oriented, semantics",Proceedings of the First International Workshop on Developments in Computational Models (DCM 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Gordon AD,Hankin PD",,A Concurrent Object Calculus: Reduction and Typing,Electronic Notes in Theoretical Computer Science,1998,16,3,248-264,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104001458;http://dx.doi.org/10.1016/S1571-0661(04)00145-8,10.1016/S1571-0661(04)00145-8,"We obtain a new formalism for concurrent object-oriented languages by extending Abadi and Cardelli's imperative object calculus with operators for concurrency from the π-calculus and with operators for synchronisation based on mutexes. Our syntax of terms is extremely expressive; in a precise sense it unifies notions of expression, process, store, thread, and configuration. We present a chemical-style reduction semantics, and prove it equivalent to a structural operational semantics. We identify a deterministic fragment that is closed under reduction and show that it includes the imperative object calculus. A collection of type systems for object-oriented constructs is at the heart of Abadi and Cardelli's work. We recast one of Abadi and Cardelli's first-order type systems with object types and subtyping in the setting of our calculus and prove subject reduction. Since our syntax of terms includes both stores and running expressions, we avoid the need to separate store typing from typing of expressions. We translate asynchronous communication channels and the choice-free asynchronous π-calculus into our calculus to illustrate its expressiveness; the types of read-only and write-only channels are supertypes of read-write channels.",,"HLCL '98, 3rd International Workshop on High-Level Concurrent Languages (Satellite Workshop of CONCUR '98)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Malti R,Melchior P,Lanusse P,Oustaloup A",,Towards an object oriented CRONE Toolbox for fractional differential systems*,IFAC Proceedings Volumes,2011,44,1,10830-10835,,,,,2011,,1474-6670,https://www.sciencedirect.com/science/article/pii/S147466701645353X;http://dx.doi.org/10.3182/20110828-6-IT-1002.02443,10.3182/20110828-6-IT-1002.02443,"Abstract The CRONE Toolbox, developed since the nineties by the CRONE team, is a Matlab Toolbox dedicated to fractional calculus. It is currently evolving towards an object oriented version, which allows many enhancements. Three main user classes, dedicated to fractional systems representations namely fractional transfer functions (frac_tf), fractional zeros poles and gain (frac_zpk), and fractional state-space (frac_ss), are developed. All three user classes are children of a parent class (frac_lti) which contains some common attributes of fractional systems. Among enhancements of the object programming of the CRONE toolbox, is the overloading of basic operators (+, –, x, /, .x, …) and standard Matlab scripts (lsim, bode, nichols, …) for the new classes. As a consequence, an end user familiar with standard Matlab operators and scripts can use straightforwardly the CRONE toolbox. The main objective of this paper is to present class diagrams and principle features of the object oriented CRONE toolbox, which can be downloaded at http://cronetoolbox.ims-bordeaux.frcronetoolbox.ims-bordeaux.fr.","Fractional calculus, Object oriented programming, Simulation, MIMO system, Matlab toolbox, CRONE toolbox",18th IFAC World Congress,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cirstea H,Kirchner C,Liquori L",,Rewriting Calculus with(out) Types,Electronic Notes in Theoretical Computer Science,2004,71,,3-19,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105825265;http://dx.doi.org/10.1016/S1571-0661(05)82526-5,10.1016/S1571-0661(05)82526-5,"The last few years have seen the development of a new calculus which can be considered as an outcome of the last decade of various researches on (higher order) term rewriting systems, and lambda calculi. In the Rewriting Calculus (or Rho Calculus, ρCal), algebraic rules are considered as sophisticated forms of “lambda terms with patterns”, and rule applications as lambda applications with pattern matching facilities. The calculus can be customized to work modulo sophisticated theories, like commutativity, associativity, associativity-commutativity, etc. This allows us to encode complex structures such as list, sets, and more generally objects. The calculus can either be presented “à la Curry” or “à la Church” without sacrificing readability and without complicating too much the metatheory. Many static type systems can be easily plugged-in on top of the calculus in the spirit of the rich type-oriented literature. The Rewriting Calculus could represent a lingua franca to encode many paradigms of computations together with a formal basis used to build powerful theorem provers based on lambda calculus and efficient rewriting, and a step towards new proof engines based on the Curry-Howard isomorphism.","Lambda calculus, Rho calculus, type systems, pattern matching, theoretical frameworks and foundations, Curry-Howard, logics, pure pattern type systems","WRLA 2002, Rewriting Logic and Its Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"Formica A,Groger HD,Missikoff M",,Object-oriented database schema analysis and inheritance processing: A graph-theoretic approach,Data & Knowledge Engineering,1997,24,2,157-181,,,,,1997,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X97000189;http://dx.doi.org/10.1016/S0169-023X(97)00018-9,10.1016/S0169-023X(97)00018-9,"In this paper we address the inheritance process in the context of strongly typed Object-oriented database (OODB) systems, allowing multiple inheritance and overriding. For such powerful systems, it is important to analyse the inheritance hierarchy to identify a number of significant properties. The first, schema consistency, is connected to the inheritance conflicts. In the presence of an unsolvable inheritance conflict there is a contradiction in the schema. The second property is related to the termination of the inheritance process. We expect that all the subtypes in the schema, if consistent, can be rewritten in expanded form, after inheritance, in a finite time. Schemas that guarantee these two formal properties will be referred to as correct schemas. In the paper a graph-theoretic method is provided, aimed at supporting the designer in checking the correctness and deriving the expanded form of a schema. Furthermore, from the analysis of the complexity of the inheritance process, a third formal property has been defined, concerning the degree of compactness achievable in a schema, by using inheritance hierarchies. In particular, a class of schemas has been defined, referred to as logarithmic schemas, whose expanded forms, after inheritance, become exponential in the size of the original schemas.","Object-oriented databases, Multiple inheritance, Inheritance process, Inheritance conflicts, Recursive schemas, Schema consistency, Subtyping, Substitutivity, Database design",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chen Z,Cau A,Zedan H,Yang H",,Integrating structured OO approaches with formal techniques for the development of real-time systems,Information and Software Technology,1999,41,7,435-450,,,,,1999,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584999000129;http://dx.doi.org/10.1016/S0950-5849(99)00012-9,10.1016/S0950-5849(99)00012-9,"The use of formal methods in the development of time-critical applications is essential if we want to achieve a high level of assurance in them. However, these methods have not yet been widely accepted in industry as compared to the more established structured and informal techniques. A reliable linkage between these two techniques will provide the developer with a powerful tool for developing a provably correct system. In this article, we explore the issue of integrating a real-time formal technique, TAM (Temporal Agent Model), with an industry-strength structured methodology known as HRT-HOOD. TAM is a systematic formal approach for the development of real-time systems based on the refinement calculus. Within TAM, a formal specification can be written (in a logic-based formalism), analysed and then refined to concrete representation through successive applications of sound refinement laws. Both abstract specification and concrete implementation are allowed to freely intermix. HRT-HOOD is an extension to the Hierarchical Object-Oriented Design (HOOD) technique for the development of Hard Real-Time systems. It is a two-phase design technique dealing with the logical and physical architecture designs of the system which can handle both functional and non-functional requirement, respectively. The integrated technique is illustrated on a version of the mine control system.","Object-oriented design, Refinement calculus, Temporal agent model, Semantics, Hard Real-Time Hierarchical Object-Oriented Design (HRT-HOOD)",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bono V,Bugliesi M",,Matching for the lambda calculus of objects,Theoretical Computer Science,1999,212,1,101-140,,,,,1999,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397598001376;http://dx.doi.org/10.1016/S0304-3975(98)00137-6,10.1016/S0304-3975(98)00137-6,"A relation between recursive object types, called matching, has been proposed [8] to provide an adequate typing of inheritance in class-based languages. This paper investigates the role of this relation in the design of a type system for the Lambda Calculus of Objects [15]. A new type system for this calculus is defined that uses implicit matchbounded quantification over type variables instead of implicit quantification over row schemes — as in [15] — to capture MyType polymorphic types for methods. An operational semantics is defined for the untyped calculus and type soundness for the new system is proved as a corollary of a subject reduction property. A formal analysis of the relative expressive power of the two systems is also carried out, that explains how the row schemes of [15] can be understood in terms of matching, and shows that the new system is as powerful as the original one on derivations of typing judgements for closed objects.","Object calculi, Object extension, specialization, Matching",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Castagna G,Ghelli G,Longo G",,A Calculus for Overloaded Functions with Subtyping,Information and Computation,1995,117,1,115-135,,,,,1995,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540185710334;http://dx.doi.org/10.1006/inco.1995.1033,10.1006/inco.1995.1033,"We present a simple extension of typed λ-calculus where functions can be overloaded by putting different \branches of code\"" together. When the function is applied","the branch to execute is chosen according to a particular selection rule which depends on the type of the argument. The crucial feature of the present approach is that the branch selection depends on the \""run-time type\"" of the argument",which may differ from its compile-time type,because of the existence of a subtyping relation among types. Hence overloading cannot be eliminated by a static analysis of code,but it is an essential feature to be dealt with during computation. We obtain in this way a type-dependent calculus,"which differs from the various λ-calculi where types to not play any role during computation. We prove confluence and a generalized subject-reduction theorem for this calculus. We prove strong normalization for a \""stratified\"" subcalculus. The definition of this calculus is guided by the understanding of object-oriented features and the connections between our calculus and object-orientedness are extensive stressed. We show that this calculus provides a foundation for types object-oriented languages which solves some of the problems of the standard record-based approach.""",,,,,,,,,,,,,,,,,
Journal Article,"Hallett JJ,Luchangco V,Ryu S,Steele GL",,Integrating coercion with subtyping and multiple dispatch,Science of Computer Programming,2010,75,9,787-795,,,,,2010,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642309000707;http://dx.doi.org/10.1016/j.scico.2009.04.005,10.1016/j.scico.2009.04.005,"Coercion can greatly improve the readability of programs, especially in arithmetic expressions. However, coercion interacts with other features of programming languages, particularly subtyping and overloaded functions and operators, in ways that can produce surprising behavior. We study examples of such surprising behavior in existing languages. This study informs the design of the coercion mechanism of Fortress, an object-oriented language with multiple dynamic dispatch, multiple inheritance and user-defined coercion. We describe this design and show how its restrictions on overloaded declarations prevent ambiguous calls due to coercion.","Coercion, Subtyping, Overloading, Multiple dispatch","Special Issue on Object-Oriented Programming Languages and Systems (OOPS 2008), A Special Track at the 23rd ACM Symposium on Applied Computing",,,,,,,,,,,,,,,,,,,,
Journal Article,Kulkarni KG,,Object-orientation and the SQL standard,Computer Standards & Interfaces,1993,15,2,287-300,,,,,1993,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899390015J;http://dx.doi.org/10.1016/0920-5489(93)90015-J,10.1016/0920-5489(93)90015-J,"The database language standard, SQL, adopted by both ANSI and ISO, is now well established as a language for developing database applications. The SQL standard has been evolving ever since its first adoption in 1986, with new revisions being announced every three years. The latest revision (SQL-92) has just been announced by both ANSI and ISO. Currently, work is underway on the next revision, SQL3, which is expected in 1995–1996 timeframe. A major focus of SQL3 effort is to incorporate an object-oriented type system while maintaining strict upward compatibility with SQL-92. The type system of SQL3 is based on concepts such as abstract data types, object identity, polymorphism, subtypes-supertypes, parameterized types, dynamic binding, etc. In this paper, we report on the current status of SQL3 type system.","Abstract data types, ANSI, C+ +, COBOL, database languages, dynamic binding, ISO, nested relations, non-first normal form relations, object identity, multiple inheritance, multisets, object-oriented database systems, overloading, parameterized types, polymorphism, query languages, relational database systems, semantic data models, SQL, SQL-86, SQL-89, SQL-92, SQL3, type templates",Object-Oriented Reference Models,,,,,,,,,,,,,,,,,,,,
Journal Article,Wand M,,Type inference for record concatenation and multiple inheritance,Information and Computation,1991,93,1,1-15,,,,,1991,,0890-5401,https://www.sciencedirect.com/science/article/pii/089054019190050C;http://dx.doi.org/10.1016/0890-5401(91)90050-C,10.1016/0890-5401(91)90050-C,"We show that the type inference problem for a lambda calculus with records, including a record concatenation operator, is decidable. We show that this calculus does not have principal types, but does have finite complete sets of types: that is, for any term M in the calculus, there exists an effectively generable finite set of type schemes such that every typing for M is an instance of one of the schemes in the set. We show how a simple model of object-oriented programming, including hidden instance variables and multiple inheritance, may be coded in this calculus. We conclude that type inference is decidable for object-oriented programs, even with multiple inheritance and classes as first-class values.",,Selections from 1989 IEEE Symposium on Logic in Computer Science,,,,,,,,,,,,,,,,,,,,
Journal Article,"O'Donoghue PG,Hull ME",,Using timed CSP during object oriented design of real-time systems,Information and Software Technology,1996,38,2,89-102,,,,,1996,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584995010491;http://dx.doi.org/10.1016/0950-5849(95)01049-1,10.1016/0950-5849(95)01049-1,"Object oriented techniques address analysis, design and implementation, allowing reusable and extensible software to be developed. However, there has been a reluctance to adopt object oriented techniques within the real-time system community due to the effects of polymorphism and dynamic binding on performance. Further objections to object oriented techniques are concerned with the effect of inheritance on coupling. This paper proposes using a dialect of MASCOT to which object oriented concepts have been introduced. Object oriented techniques are used for analysis and design, while real-time languages are used for implementation. The approach, therefore, achieves the advantages of object oriented modelling without the run-time overheads caused by object oriented programming languages. Timed CSP specifications support the less formal techniques used for functional analysis. This is particularly important for understanding semantics when developing safety critical and reactive systems.","Object modelling, MASCOT, Timed CSP, Object-oriented",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bonfè M,Fantuzzi C,Secchi C",,INHERITANCE OF BEHAVIOR IN OBJECT-ORIENTED DESIGNS FOR INDUSTRIAL CONTROL SYSTEMS,IFAC Proceedings Volumes,2005,38,1,49-54,,,,,2005,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016375048;http://dx.doi.org/10.3182/20050703-6-CZ-1902.01492,10.3182/20050703-6-CZ-1902.01492,"The paper presents a feasible approach to introduce object-oriented techniques in the industrial practice of control design. The approach is based on the use of a domain-specific extension of the modeling language UML and on the formalization of design models as transition systems for verification purposes. In particular, the paper shows how to exploit model checking techniques to verify that object classes, designed as subtypes, correctly inherit the behavior of their base classes, according to a notion of substitutability specifically defined for the proposed semantics of object-oriented models.","Manufacturing systems, Logic controllers, Discrete-event systems, Verification",16th IFAC World Congress,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gheyi R,Massoni T,Borba P",,A Static Semantics for Alloy and its Impact in Refactorings,Electronic Notes in Theoretical Computer Science,2007,184,,209-233,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107004434;http://dx.doi.org/10.1016/j.entcs.2007.03.023,10.1016/j.entcs.2007.03.023,"Refactorings are usually proposed in an ad hoc way because it is difficult to prove that they are sound with respect to a formal semantics, not guaranteeing the absence of type errors or semantic changes. Consequently, developers using refactoring tools must rely on compilation and tests to ensure type-correctness and semantics preservation, respectively, which may not be satisfactory to critical software development. In this paper, we formalize a static semantics for Alloy, which is a formal object-oriented modeling language, and encode it in Prototype Verification System (PVS). The static semantics' formalization can be useful for specifying and proving that transformations in general (not only refactorings) do not introduce type errors, for instance, as we show here.","refactoring, type system, theorem proving, object models",Proceedings of the Second Brazilian Symposium on Formal Methods (SBMF 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Halper M,Liu LM,Geller J,Perl Y",,Ownership as a conceptual modeling construct,Data & Knowledge Engineering,2007,62,2,248-273,,,,,2007,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X06001601;http://dx.doi.org/10.1016/j.datak.2006.07.011,10.1016/j.datak.2006.07.011,"Ownership is a relationship that pervades many aspects of our lives, from the personal to the economic, and is particularly important in the realm of the emerging electronic economy. As it is understood on an intuitive level, ownership exhibits a great deal of complexity and carries a rich semantics with respect both to the owner and the possession. A formal model of an ownership relationship that inherently captures varied ownership semantics is presented. This ownership relationship expands the repertoire of available conceptual data modeling primitives. It is built up from a set of characteristic dimensions, namely, exclusiveness, dependency, documentation, transferability, and inheritance, each of which focuses on a specific aspect of ownership semantics. The data modeler has the ability to make a variety of choices along these five dimensions, and thus has access to a wide range of available ownership features in a declarative fashion. These choices ultimately impose various constraints (specified in OCL) on the states of data objects and their respective ownership activities, including transactions such as acquiring and relinquishing ownership. To complement the formal aspects of the ownership model and enhance its usability, we present a graphical ownership notation that augments the Unified Modeling Language (UML) class diagram formalism. An implementation of the ownership relationship in a commercial object-oriented database system is discussed.","Ownership relationship, Semantic relationship, Ownership semantics, Conceptual modeling, Object-oriented modeling, Object-oriented database system, Electronic commerce",,,,,,,,,,,,,,,,,,,,,
Journal Article,Alagić S,,Semantics of Temporal Classes,Information and Computation,2000,163,1,60-102,,,,,2000,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540100928918;http://dx.doi.org/10.1006/inco.2000.2891,10.1006/inco.2000.2891,"A model theory of a typed, declarative, temporal object-oriented language system is presented. The declarative nature of the language makes it very different from the dominating procedural, strongly typed object-oriented programming languages. In this declarative system, methods are specified in a high-level, temporal constraint language. Two fundamental properties of these constraints are that they have an execution model and algebraic semantics. The model theory is based on temporal order-sorted algebras with predicates. A variety of orderings are explored in order to represent various types of inheritance, as well as the subtyping discipline. Temporal classes are viewed as temporal theories and some inheritance relationships as morphisms of temporal theories. A model of a temporal class is a temporal order-sorted structure with predicates which satisfies a set of temporal constraints specified in that class. Morphisms of those models are naturally required to preserve type coercions. A distinguished model of a temporal theory is constructed as a colimit of a suitably defined functor. This colimit construction reflects the temporal nature of the paradigm and generalizes the classical initial algebra semantics. In contradistinction to major difficulties in developing a model theory for full-fledged, typed procedural object-oriented languages, this paper shows that such a task becomes possible for a suitably defined declarative object-oriented language. This, in particular, leads to model-theoretic results on the preservation of the behavioral properties in the inheritance hierarchies.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Buchanan M,Britton C",,Formal specification and object-oriented design,Microprocessing and Microprogramming,1992,34,1,19-22,,,,,1992,,0165-6074,https://www.sciencedirect.com/science/article/pii/016560749290093M;http://dx.doi.org/10.1016/0165-6074(92)90093-M,10.1016/0165-6074(92)90093-M,"In recent years, object-oriented design and formal specification languages have become increasingly important in the development of software systems. In this paper we use the formal specification languages OBJ1 and OBJ3 to investigate the extent to which they support object-oriented design in general and inheritance in particular.","Formal Specification, Inheritance, OBJ",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Din CC,Johnsen EB,Owe O,Yu IC",,A modular reasoning system using uninterpreted predicates for code reuse,Journal of Logical and Algebraic Methods in Programming,2018,95,,82-102,,,,,2018,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220817300597;http://dx.doi.org/10.1016/j.jlamp.2017.11.004,10.1016/j.jlamp.2017.11.004,"This paper proposes a modular proof system based on uninterpreted predicates. The proposed proof system allows modular reasoning about programs with an open-world assumption, which goes beyond behavioral subtyping. The proof system enables modular reasoning about languages with very flexible code reuse mechanisms, such as traits and deltas in the context of object-oriented programming. Whereas related work on incremental proof systems prove soundness in terms of internal consistency, this paper establishes both soundness and relative completeness of the proposed proof system by relating it to a standard proof system for a simple object-oriented language. The applicability of the approach is demonstrated on different code reuse mechanisms: unrestricted class inheritance, delta-oriented programming, and trait-based programming.","Code reuse, Modular reasoning, Early reasoning, Uninterpreted predicates, Soundness, Completeness",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Snoeck M,Dedene G",,Generalization/specialization and role in object oriented conceptual modeling,Data & Knowledge Engineering,1996,19,2,171-195,,,,,1996,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9500044S;http://dx.doi.org/10.1016/0169-023X(95)00044-S,10.1016/0169-023X(95)00044-S,"The “IS A”-relationship and the mechanism of inheritance are powerful concepts that help to reduce complexity of models and redundancy in specifications. However, in the area of conceptual modeling, it seems that current Object Oriented Analysis methods put most emphasis on the structural aspects of the “IS A”-relationship while inheritance and sharing of behaviour are often not or ill-defined. This paper investigates how attribute sharing, behaviour sharing and subset hierarchies can be combined into a sound “IS A”-modelling concept that guarantees universal substitutability. Decision criteria on the use of generalization/specialization are discussed and a formal taxonomy of processes corresponding to the generalization/specialization hierarchy is presented.","Generalization/specialization, Inheritance, Roles, Object oriented modeling methods, Process algebra, Formal specifications",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Glimming J,Ghani N",,Difunctorial Semantics of Object Calculus,Electronic Notes in Theoretical Computer Science,2005,138,2,79-94,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105051364;http://dx.doi.org/10.1016/j.entcs.2005.09.012,10.1016/j.entcs.2005.09.012,"In this paper we give a denotational model for Abadi and Cardelli's first order object calculus FOb1+×μ (without subtyping) in the category pCpo. The key novelty of our model is its extensive use of recursively defined types, supporting self-application, to model objects. At a technical level, this entails using some sophisticated techniques such as Freyd's algebraic compactness to guarantee the existence of the denotations of the object types. The last sections of the paper demonstrates that the canonical recursion operator inherent in our semantics is potentially useful in object-oriented programming. This is witnessed by giving a straightforward translation of algebraic datatypes into so called wrapper classes.","Category theory, object-oriented programming",Proceedings of the Second Workshop on Object Oriented Developments (WOOD 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,de Oliveira Guimarães J,,The Green language type system,"Computer Languages, Systems & Structures",2009,35,4,435-447,,,,,2009,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842408000419;http://dx.doi.org/10.1016/j.cl.2008.09.001,10.1016/j.cl.2008.09.001,"A programming language that considers basic values and classes as objects brings more opportunities of code reuse and it is easier to use than a language that does not support this feature. However, popular statically typed object-oriented languages do not consider classes as first-class objects because this concept is difficult to integrate with static type checking. They also do not consider basic values as objects for sake of efficiency. This article presents the Green language type system which supports classes as classless objects and offers a mechanism to treat basic values as objects. The result is a reasonably simple type system which is statically typed and easy to implement. It simplifies several other language mechanisms and prevents any infinite regression of metaclasses.","Object-oriented languages, Green, Type system, Polymorphism",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhang F,Ma ZM,Li W",,Storing OWL ontologies in object-oriented databases,Knowledge-Based Systems,2015,76,,240-255,,,,,2015,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705114004584;http://dx.doi.org/10.1016/j.knosys.2014.12.020,10.1016/j.knosys.2014.12.020,"The Semantic Web uses ontological descriptions, in particularly Web Ontology Language OWL, as a universal medium to formally describe and exchange knowledge of various domains. Currently, many OWL ontologies for different domains come into being successively. Therefore, how to store OWL ontologies becomes one of ordinary needs of the Semantic Web. Based on the efficient storage mechanism of object-oriented databases, they may be used to store OWL ontologies for realizing the management of large amounts of knowledge in the Semantic Web. To this end, the main objective of this paper is to investigate how to store OWL ontologies in object-oriented databases, and we propose a formal approach and develop a prototype tool for storing OWL ontologies in object-oriented databases. Firstly, after giving a complete formal definition of OWL ontologies, we propose an overall architecture of storing OWL ontologies in object-oriented databases. Based on the architecture, we further give storage rules and explain how to store OWL ontologies in object-oriented databases with a running example in detail. The correctness and quality of the storage approach are proved and analyzed. Finally, we implement a prototype tool which can store OWL ontologies in a widely used open source object database db4o. Also, a query interface is developed in the prototype tool for querying the stored OWL ontologies. The storage and query examples are provided to show that the approach is feasible and the tool is efficient.","OWL, Ontology, Object-oriented database, Storage, Query",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Johnsen EB,Owe O,Clarke D,Bjørk J",,A formal model of service-oriented dynamic object groups,Science of Computer Programming,2016,115-116,,3-22,,,,,2016,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642314005553;http://dx.doi.org/10.1016/j.scico.2014.11.014,10.1016/j.scico.2014.11.014,"Services are autonomous, self-describing, technology-neutral software units that can be published, discovered, queried, and composed into software applications at runtime. Designing and composing software services to form applications or composite services, require abstractions beyond those found in typical object-oriented programming languages. This paper explores service-oriented abstractions such as service adaptation, discovery, and querying in an object-oriented setting. We develop a formal model of dynamic object-oriented groups which offer services to their environment. These groups fit directly into the object-oriented paradigm in the sense that they can be dynamically created, they have an identity, and they can receive method calls. In contrast to objects, groups are not used for structuring code. A group exports its services through interfaces and relies on objects to implement these services. Objects may join or leave different groups. Groups may dynamically export new interfaces, they support service discovery, and they can be queried at runtime for the interfaces they support. We define an operational semantics and a static type system for this model of dynamic object groups, and show that well-typed programs do not cause method-not-understood errors at runtime.","Object orientation, Object groups, Service orientation, Multithreading, Concurrency, Types, Semantics, Type safety",Special Section on Foundations of Coordination Languages and Software (FOCLASA 2012) Special Section on Foundations of Coordination Languages and Software (FOCLASA 2013),,,,,,,,,,,,,,,,,,,,
Journal Article,Konecny J,,Reinventing known results in FCA: Notes on two recently published algorithms for computation of formal concepts,Discrete Applied Mathematics,2020,273,,136-143,,,,,2020,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X19300344;http://dx.doi.org/10.1016/j.dam.2019.01.017,10.1016/j.dam.2019.01.017,"Two recently published algorithms for computation of formal concepts are analyzed. The first algorithm, by Ma et al. (2016), is claimed to provide a new and efficient algorithm for generating all object-oriented concepts. We recall that the generating of all object-oriented concepts and generating of all standard concepts is basically the same problem, since the object-oriented case and the standard case are easily reducible to each other via the set complement. Taking this reducibility into account, Ma et al. merely repeat results by Qian and Wei (2014). The algorithm is not efficient due to its exponential space complexity. Furthermore, we show that the space complexity can be significantly improved by a simple tweak. The algorithm then becomes equivalent to Chein’s algorithm, initially published in 1969. The second analyzed algorithm was published by Singh (2017), who proposes an extension of Formal Concept Analysis which handles vague (fuzzy interval valued) data and provides a method for computation of the associated concept lattice. We show that the same extension has been proposed before by Djouadi and Prade in 2009; that the proposed algorithm is incorrect and that it becomes an already known algorithm when we fix it. Additionally, we fix multiple errors in information about related literature committed by Singh.","Formal concept analysis, Algorithm, Enumeration of concepts, Galois connections",Advances in Formal Concept Analysis: Traces of CLA 2016,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bertino E,Ferrari E,Guerrini G,Merlo I",,T-ODMG: an ODMG compliant temporal object model supporting multiple granularity management,Information Systems,2003,28,8,885-927,,,,,2003,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437902000777;http://dx.doi.org/10.1016/S0306-4379(02)00077-7,10.1016/S0306-4379(02)00077-7,"In this paper we investigate some issues arising from the introduction of multiple temporal granularities in an object-oriented data model. Although issues concerning temporal granularities have been investigated in the context of temporal relational database systems, no comparable amount of work has been done in the context of object-oriented models. Moreover, the main drawback of the existing proposals is the lack of a formal basis—which we believe is essential to manage the inherent complexity of the object-oriented data model. In this paper, we define a comprehensive temporal object-oriented data model supporting multiple temporal granularities. We formally define the main notions of the data model such as types, legal values, classes, and objects. We address issues related to inheritance, type refinement, and substitutability. Finally, we describe the implementation of the presented model on top of an ODMG compliant DBMS.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Johnsen EB,Mai Thuong Tran T,Owe O,Steffen M",,Safe locking for multi-threaded Java with exceptions,The Journal of Logic and Algebraic Programming,2012,81,3,257-283,,,,,2012,,1567-8326,https://www.sciencedirect.com/science/article/pii/S1567832611000968;http://dx.doi.org/10.1016/j.jlap.2011.11.002,10.1016/j.jlap.2011.11.002,"There are many mechanisms for concurrency control in high-level programming languages. In Java, the original mechanism for concurrency control, based on synchronized blocks, is lexically scoped. For more flexible control, Java 5 introduced non-lexical lock primitives on re-entrant locks.These operators may lead to run-time errors and unwanted behavior; e.g., taking a lock without releasing it, which could lead to a deadlock, or trying to release a lock without owning it. This paper develops a static type and effect system to prevent the mentioned lock errors for a formal, object-oriented calculus which supports non-lexical lock handling and exceptions. Based on an operational semantics, we prove soundness of the effect type analysis. Challenges in the design of the effect type system are dynamic creation of threads, objects, and especially of locks, aliasing of lock references, passing of lock references between threads, and reentrant locks as found in Java. Furthermore, the exception handling mechanism complicates the control-flow and thus the analysis.","Java, Multi-threading, Lock-based concurrency, Non-lexical, Re-entrant locks, Exceptions, Static analysis, Type and effect systems",The 22nd Nordic Workshop on Programming Theory (NWPT 2010),,,,,,,,,,,,,,,,,,,,
Journal Article,"Pierik C,de Boer FS",,A proof outline logic for object-oriented programming,Theoretical Computer Science,2005,343,3,413-442,,,,,2005,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397505003671;http://dx.doi.org/10.1016/j.tcs.2005.06.018,10.1016/j.tcs.2005.06.018,This paper describes a proof outline logic that covers most typical object-oriented language constructs in the presence of inheritance and subtyping. The logic is based on a weakest precondition calculus for assignments and object allocation which takes field shadowing into account. Dynamically bound method calls are tackled with a variant of Hoare's rule of adaptation that deals with the dynamic allocation of objects in object-oriented programs. The logic is based on an assertion language that is closely tailored to the abstraction level of the programming language.,"Proof outline logic, Hoare logic, Object-oriented programming, Verification, Rule of adaptation",Formal Methods for Components and Objects,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dezani-Ciancaglini M,Drossopoulou S,Mostrous D,Yoshida N",,Objects and session types,Information and Computation,2009,207,5,595-641,,,,,2009,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540109000261;http://dx.doi.org/10.1016/j.ic.2008.03.028,10.1016/j.ic.2008.03.028,"A session takes place between two parties; after establishing a connection, each party interleaves local computations and communications (sending or receiving) with the other. Session types characterise such sessions in terms of the types of values communicated and the shape of protocols, and have been developed for the π-calculus, CORBA interfaces, and functional languages. We study the incorporation of session types into object-oriented languages through MOOSE, a multi-threaded language with session types, thread spawning, iterative, and higher-order sessions. Our design aims to consistently integrate the object-oriented programming style and sessions, and to be able to treat various case studies from the literature. We describe the design of MOOSE, its syntax, operational semantics, and type system, and develop a type inference system. After proving subject reduction, we establish the progress property: once a communication has been established, well-typed programs will never starve at communication points.",,From Type Theory to Morphological Complexity: Special Issue dedicated to the 60th Birthday Anniversary of Giuseppe Longo,,,,,,,,,,,,,,,,,,,,
Journal Article,Palsberg J,,Efficient Inference of Object Types,Information and Computation,1995,123,2,198-209,,,,,1995,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540185711686;http://dx.doi.org/10.1006/inco.1995.1168,10.1006/inco.1995.1168,"M. Abadi and L. Cardelli have recently investigated a calculus of objects (1994). The calculus supports a key feature of object-oriented languages: an object can be emulated by another object that has more refined methods. Abadi and Cardelli presented four first-order type systems for the calculus. The simplest one is based on finite types and no subtyping, and the most powerful one has both recursive types and subtyping. Open until now is the question of type inference, and in the presence of subtyping \the absence of minimum typings poses practical problems for type inference.\"" In this paper","we give an O(n3) algorithm for each of the four type inference problems and we prove that all the problems are P-complete. We also indicate how to modify the algorithms to handle functions and records.""",,,,,,,,,,,,,,,,,,,,,
Journal Article,Conrad S,,A basic calculus for verifying properties of interacting objects,Data & Knowledge Engineering,1996,18,2,119-145,,,,,1996,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9500039U;http://dx.doi.org/10.1016/0169-023X(95)00039-U,10.1016/0169-023X(95)00039-U,"We introduce a basic calculus for expressing and proving properties of interacting objects. The objects considered have dynamic behaviour and are organized into object communities in a hierarchical way. After a detailed and formal presentation of the calculus, essential properties of the calculus are discussed, especially the question of compositionality. The calculus constitutes a basis for investigating issues of verifying properties of objects and object communities. In consequence, we have focused on a small number of essential concepts. This calculus can be seen as an extensible basis applicable to different object-oriented specification frameworks.","Object specification, Dynamic objects, Verification, Compositional specification, Compositional verification, Basic calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lago JM,Artalejo MR",,A declarative framework for object-oriented programming with genetic inheritance,Theoretical Computer Science,2001,269,1,363-417,,,,,2001,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397501000135;http://dx.doi.org/10.1016/S0304-3975(01)00013-5,10.1016/S0304-3975(01)00013-5,"Seeking the integration of the object-oriented and declarative programming paradigms offers advantages for the software life-cycle activities. Specification is benefited from using declarative expressions as functional descriptions of components, enjoying formal semantic models. But the integration of both paradigms, object-oriented and declarative, following a translation scheme sets an unavoidable representation distance. Classes, inheritance, attributes and methods are codified with abstract elements, thus not being primitive. This work aims to offer a declarative formal model where the main features of object-oriented programming are nuclear, focusing in an algebraic formalization of purely functional objects. Substantially extending (Mateos-Lago and Rodrı́guez-Artalejo, PLILP’96, Lecture Notes in Computer Science, Vol. 1140, Springer, Berlin, 1996, pp. 62–76), we include operations to homogeneously model methods and class-external functions. Multiple inheritance is supported and extended with genetic inheritance and expressions are flexibly typed using genome typing. Following (González-Moreno et al., J. Logic Programming 40(1) (1999) 47), we use a rewriting logic as a technical tool that helps to formalize the semantics based on continuous algebras (Goguen et al., J. ACM 24(1) (1977) 68), and we show initiality with the existence of a distinguished model for program semantics.","Object-oriented declarative programming, Genetic inheritance, Algebraic semantics, Paradigm integration",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Palsberg J,Zhao T",,Type inference for record concatenation and subtyping,Information and Computation,2004,189,1,54-86,,,,,2004,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540103002177;http://dx.doi.org/10.1016/j.ic.2003.10.001,10.1016/j.ic.2003.10.001,"Record concatenation, multiple inheritance, and multiple-object cloning are closely related and part of various language designs. For example, in Cardelli’s untyped Obliq language, a new object can be constructed from several existing objects by cloning followed by concatenation; an error is given in case of field name conflicts. Type systems for record concatenation have been studied by Wand, Harper and Pierce, Remy, and others; and type inference for the combination of record concatenation and subtyping has been studied by Sulzmann and by Pottier. In this paper we present a type inference algorithm for record concatenation, subtyping, and recursive types. Our example language is the Abadi–Cardelli object calculus extended with a concatenation operator. Our algorithm enables type checking of Obliq programs without changing the programs at all. We prove that the type inference problem is NP-complete.","Types, Objects, Complexity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Di Blasio P,Temperini M",,Subtyping Inheritance and Its Application in Languages for Symbolic Computation Systems,Journal of Symbolic Computation,1995,19,1,39-63,,,,,1995,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717185710048;http://dx.doi.org/10.1006/jsco.1995.1004,10.1006/jsco.1995.1004,"Application of object-oriented programming techniques to design and implementation of symbolic computation systems is investigated. We show the significance of certain correctness problems, occurring in programming environments based on specialization inheritance, due to use of method redefinition and polymorphism. We propose a solution to these problems, by defining a mechanism of subtyping inheritance and the prototype of an object-oriented programming language for a symbolic computation system. We devise the subtyping inheritance ESI (Enhanced Strict Inheritance) by lifting to programming language constructs a given model of subtyping, which is established by a monotonic (covariant) subtyping rule. Type safeness of language instructions is proved. The adoption of ESI allows to model method and class specialization in a natural way. The ESI mechanism verifies the type correctness of language statements by means of type checking rules and preserves their correctness at run-time by a suitable method lookup algorithm.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Thüm T,Knüppel A,Krüger S,Bolle S,Schaefer I",,Feature-oriented contract composition,Journal of Systems and Software,2019,152,,83-107,,,,,2019,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121219300044;http://dx.doi.org/10.1016/j.jss.2019.01.044,10.1016/j.jss.2019.01.044,"A software product line comprises a set of products that share a common code base, but vary in specific characteristics called features. Ideally, features of a product line are developed in isolation and composed subsequently. Product lines are increasingly used for safety–critical software, for which quality assurance becomes indispensable. While the verification of product lines gained considerable interest in research over the last decade, the subject of how to specify product lines is only covered rudimentarily. A challenge to overcome is composition; similar to inheritance in object-oriented programming, features of a product line may refine other features along with their specifications. To investigate how refinement and composition of specifications can be established, we derive a notion of feature-oriented contracts comprising preconditions, postconditions, and framing conditions of a method. We discuss six mechanisms to perform contract composition between original and refining contracts. Moreover, we identify and discuss desired properties for contract composition and evaluate which properties are established by which mechanism. Our three main insights are that (a) contract refinement is seldom but crucial, (b) the Liskov principle does not apply to features, and (c) it is sufficient to accommodate techniques from object-orientation in the contract-composition mechanisms for handling frame refinements.","Feature-oriented programming, Software product lines, Design by contract, Deductive verification, Formal methods",,,,,,,,,,,,,,,,,,,,,
Journal Article,Sangiorgi D,,An Interpretation of Typed Objects into Typedπ-Calculus,Information and Computation,1998,143,1,34-73,,,,,1998,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540198927110;http://dx.doi.org/10.1006/inco.1998.2711,10.1006/inco.1998.2711,"An interpretation of Abadi and Cardelli's first-order functionobject calculusinto a typedπ-calculus is presented. The interpretation validates the subtyping relation and the typing judgements of the object calculus and is computationally adequate. This is the first interpretation of a typed object-oriented language into a process calculus. The study intends to offer a contribution to understanding on the one hand, the relationship betweenπ-calculus types and conventional types of programming languages and on the other hand, the usefulness of theπ-calculus as a metalanguage for the semantics of typed object-oriented languages. The type language for theπ-calculus has Pierce and Sangiorgi's I/O annotations, to separate the capabilities of reading and writing on a channel and variant types. Technical contributions of the paper are the presentation ofvariant typesfor theπ-calculus and their typing and subtyping properties, and an analysis of behavioural equivalences in aπ-calculus with variant types.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hakman M,Groth T",,Object-oriented biomedical system modelling — the language,Computer Methods and Programs in Biomedicine,1999,60,3,153-181,,,,,1999,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260799000346;http://dx.doi.org/10.1016/S0169-2607(99)00034-6,10.1016/S0169-2607(99)00034-6,"The paper describes a new object-oriented biomedical continuous system modelling language (OOBSML). It is fully object-oriented and supports model inheritance, encapsulation, and model component instantiation and behaviour polymorphism. Besides the traditional differential and algebraic equation expressions the language includes also formal expressions for documenting models and defining model quantity types and quantity units. It supports explicit definition of model input-, output- and state quantities, model components and component connections. The OOBSML model compiler produces self-contained, independent, executable model components that can be instantiated and used within other OOBSML models and/or stored within model and model component libraries. In this way complex models can be structured as multilevel, multi-component model hierarchies. Technically the model components produced by the OOBSML compiler are executable computer code objects based on distributed object and object request broker technology. This paper includes both the language tutorial and the formal language syntax and semantic description.","OOBSML, Object-oriented modelling language, Biomedical system modelling language, Continuous system modelling language, Distributed model components, Hierarchical models",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Xu H,Yu S",,Type Theory and Language Constructs for Objects with States,Electronic Notes in Theoretical Computer Science,2006,135,3,141-151,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106000946;http://dx.doi.org/10.1016/j.entcs.2005.09.028,10.1016/j.entcs.2005.09.028,"In current class-based Object-Oriented Programming Languages (OOPLs), object types include only static features. How to add object dynamic behaviors modeled by Harel's statecharts into object types is a challenging task. We propose adding states and state transitions, which are largely unstated in object type theory, into object type definitions and typing rules. We argue that dynamic behaviors of objects should be part of object type definitions. We propose our type theory, the τ-calculus, which refines Abadi and Cardelli's ζ-calculus, in modeling objects with their dynamic behaviors. In our proposed type theory, we also explain that a subtyping relation between object types should imply the inclusion of their dynamic behaviors. By adding states and state transitions into object types, we propose modifying programming language constructs for state tracking.","object types, object dynamic behaviors, -calculus, -calculus, programming language constructs, state tracking",Proceedings of the First International Workshop on Developments in Computational Models (DCM 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Baclawski K,Simovici DA",,An algebraic approach to databases with complex objects,Information Systems,1992,17,1,33-47,,,,,1992,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437992900047;http://dx.doi.org/10.1016/0306-4379(92)90004-7,10.1016/0306-4379(92)90004-7,"We propose a formal axiomatic treatment of databases with complex objects. This approach integrates object-oriented features with the binary semantic data model. Our axiomatic approach offers a new prospective on such issues as object identity, structural inheritance and type systems which are of interest to object-oriented database systems.","Object-oriented database, complex objects, restructuring, update, database universe, types, typed database, constituents",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rowe RN,van Bakel SJ",,Semantic Types and Approximation for Featherweight Java,Theoretical Computer Science,2014,517,,34-74,,,,,2014,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397513006415;http://dx.doi.org/10.1016/j.tcs.2013.08.017,10.1016/j.tcs.2013.08.017,"We consider semantics for the class-based object-oriented calculus Featherweight Java (without casts) based upon approximation. We also define an intersection type assignment system for this calculus and show that it satisfies subject reduction and expansion, i.e. types are preserved under reduction and its converse. We establish a link between type assignment and the approximation semantics by showing an approximation result, which leads to a sufficient condition for the characterisation of head-normalisation and termination. We show the expressivity of both our calculus and our type system by defining an encoding of Combinatory Logic into our calculus and showing that this encoding preserves typeability. We also show that our system characterises the normalising and strongly normalising terms for this encoding. We thus demonstrate that the great analytic capabilities of intersection types can be applied to the context of class-based object orientation.","Featherweight Java, Intersection types, Approximation semantics, Derivation reduction, Strong normalisation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Beringer L,Grabowski R,Hofmann M",,Verifying pointer and string analyses with region type systems,"Computer Languages, Systems & Structures",2013,39,2,49-65,,,,,2013,,1477-8424,https://www.sciencedirect.com/science/article/pii/S147784241300002X;http://dx.doi.org/10.1016/j.cl.2013.01.001,10.1016/j.cl.2013.01.001,"Pointer analysis statically approximates the heap pointer structure during a program execution in order to track heap objects or to establish alias relations between references, and usually contributes to other analyses or code optimizations. In recent years, a number of algorithms have been presented that provide an efficient, scalable, and yet precise pointer analysis. However, it is unclear how the results of these algorithms compare to each other semantically. In this paper, we present a general region type system for a Java-like language and give a formal soundness proof. The system is subsequently specialized to obtain a platform for embedding the results of various existing context-sensitive pointer analysis algorithms, thereby equipping the computed relations with a common interpretation and verification. We illustrate our system by outlining an extension to a string value analysis that builds on pointer information.","Pointer alias analysis, Formal verification, Region type system, Object-oriented languages, String analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Borba P,Sampaio A,Cavalcanti A,Cornélio M",,Algebraic reasoning for object-oriented programming,Science of Computer Programming,2004,52,1,53-100,,,,,2004,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642304000474;http://dx.doi.org/10.1016/j.scico.2004.03.003,10.1016/j.scico.2004.03.003,"We present algebraic laws for a language similar to a subset of sequential Java that includes inheritance, recursive classes, dynamic binding, access control, type tests and casts, assignment, but no sharing. These laws are proved sound with respect to a weakest precondition semantics. We also show that they are complete in the sense that they are sufficient to reduce an arbitrary program to a normal form substantially close to an imperative program; the remaining object-oriented constructs could be further eliminated if our language had recursive records. This suggests that our laws are expressive enough to formally derive behaviour preserving program transformations; we illustrate that through the derivation of provably-correct refactorings.",,Special Issue on Program Transformation,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ahrendt W,Dylla M",,A system for compositional verification of asynchronous objects,Science of Computer Programming,2012,77,12,1289-1309,,,,,2012,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642310001553;http://dx.doi.org/10.1016/j.scico.2010.08.003,10.1016/j.scico.2010.08.003,"We present a semantics, calculus, and system for compositional verification of Creol, an object-oriented modelling language for concurrent distributed applications. The system is an instance of KeY, a framework for object-oriented software verification, which has so far been applied foremost to sequential Java. Building on KeY characteristic concepts, like dynamic logic, sequent calculus, symbolic execution via explicit substitutions, and the taclet rule language, the presented system addresses functional correctness of Creol models featuring local cooperative thread parallelism and global communication via asynchronous method calls. The calculus heavily operates on communication histories specified by the interfaces of Creol units. Two example scenarios demonstrate the usage of the system. This article extends the conference paper of Ahrendt and Dylla (2009) [5] with a denotational semantics of Creol and an assumption-commitment style semantics of the logic.","Verification, Concurrency, Semantics, Object-orientation",International Conference on Formal Engineering Methods—ICFEM 2009,,,,,,,,,,,,,,,,,,,,
Journal Article,Castagna G,,A meta-language for typed object-oriented languages,Theoretical Computer Science,1995,151,2,297-352,,,,,1995,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397595000714;http://dx.doi.org/10.1016/0304-3975(95)00071-4,10.1016/0304-3975(95)00071-4,"In [12] we defined the λ&-calculus, a simple extension of the typed λ-calculus to model typed object-oriented languages. This paper is the continuation or, rather, the companion of [12] since it analyzes the practical counterpart of the theoretical issues introduced there. Indeed, to develop a formal study of type systems for object-oriented languages we define a meta-language based on λ& and we show, by a practical example, how it can be used to prove properties of a language. To this purpose, we define a toy object-oriented language and its type-checking algorithm; then we translate this toy language into our meta-language. The translation gives the semantics of the toy language and a theorem on the translation of well-typed programs proves the correctness of the type-checker of the toy language. As an aside we also illustrate the expressivity of the λ&-based model by showing how to translate existing features like multiple inheritance and multiple dispatch, but also by integrating in the toy language new features directly suggested by the model, such as first-class messages, a generalization of the use of super and the use of explicit coercions. An important novelty with respect to previous systems is that we show how to model multiple dispatch also in the presence of a notion of receiver (i.e. of a privileged argument to which the message is passed), a notion that is absent in languages like CLOS.",,13th Conference on Foundations of Software Technology and Theoretical Computer Science,,,,,,,,,,,,,,,,,,,,
Journal Article,"Barbier F,Henderson-Sellers B",,The whole-part relationship in object modelling: a definition in cOlOr,Information and Software Technology,2001,43,1,19-39,,,,,2001,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584900001336;http://dx.doi.org/10.1016/S0950-5849(00)00133-6,10.1016/S0950-5849(00)00133-6,"In object models built according to popular object-oriented formalisms, the commonest relationship types (excluding inheritance) are the structural relationships of association and of whole-part (often called aggregation). This last type is well known to have no accurately prescribed semantics. Here, some of the aggregation semantics frequently presented in the literature and sometimes supported in current object-oriented modelling languages, especially UML, are analysed and criticised. Because of defects, the use of a modelling notation based on these aggregation semantics is dubious and limited. Moreover, many properties are candidates for characterising the whole-part relationship provided that no redundancy and no inconsistency exist between them. A framework known as cOlOr is then offered by means of a metamodel in which the Whole-Part metatype inherits from the Structural-Relationship metatype. Defining a specific aggregation semantics leads then, first, within cOlOr, to the creation of a subtype of the Whole-Part metatype. Next, the behaviour of this last type is extended and/or restricted in using a constraint-based approach. Such a process is developed particularly for considering Composition in UML and Aggregation in OML more formally, as well as for dealing with domain-dependent aggregation semantics. Since a non-negligible feature of cOlOr is the availability of a C++ library that implements the proposed metamodel, some implementation concerns are also briefly discussed.","Object modelling, Structural relationship, Whole-Part relationship, Aggregation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Johnsen EB,Owe O,Yu IC",,Creol: A type-safe object-oriented model for distributed concurrent systems,Theoretical Computer Science,2006,365,1,23-66,,,,,2006,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397506004804;http://dx.doi.org/10.1016/j.tcs.2006.07.031,10.1016/j.tcs.2006.07.031,"Object-oriented distributed computing is becoming increasingly important for critical infrastructure in society. In standard object-oriented models, objects synchronize on method calls. These models may be criticized in the distributed setting for their tight coupling of communication and synchronization; network delays and instabilities may locally result in much waiting and even deadlock. The Creol model targets distributed objects by a looser coupling of method calls and synchronization. Asynchronous method calls and high-level local control structures allow local computation to adapt to network instability. Object variables are typed by interfaces, so communication with remote objects is independent from their implementation. The inheritance and subtyping relations are distinct in Creol. Interfaces form a subtype hierarchy, whereas multiple inheritance is used for code reuse at the class level. This paper presents the Creol syntax, operational semantics, and type system. It is shown that runtime type errors do not occur for well-typed programs.","Distributed object-oriented systems, Type and effect system, Type soundness",Formal Methods for Components and Objects,,,,,,,,,,,,,,,,,,,,
Journal Article,"Castagna G,Chen G",,Dependent Types with Subtyping and Late-Bound Overloading,Information and Computation,2001,168,1,1-67,,,,,2001,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540101931281;http://dx.doi.org/10.1006/inco.2001.3128,10.1006/inco.2001.3128,"We present a calculus with dependent types, subtyping, and late-bound overloading. Besides its theoretical interest this work is motivated by several practical needs that range form the definition of logic encodings to proof specialization and reuse and to object-oriented extension of the SML module system. The theoretical study of this calculus is not straightforward. While confluence is relatively easy to prove, subject reduction is much harder. We were not able to add overloading to any existing system with dependent types and subtyping, and prove subject reduction. This is why we also define here as by-product a new subtyping system for dependent types that improves previous systems and enjoys several properties (notably the transitivity elimination property). The calculus with overloading is then obtained as a conservative extension of this new system. Another difficult point is strong normalization, which is a necessary condition to the decidability of subtyping and typing relations. The calculus with overloading is not strongly normalizing. However, we show that a reasonably useful fragment of the calculus enjoys this property and that its strong normalization implies the decidability of its subtyping and typing relations. The article is divided into two parts: the first three scetions provide a general overview of the systems and its motivations and can be read separately; the remaining sections develop the formal study.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferreira AP,Foss L,Ribeiro L",,Formal Verification of Object-Oriented Graph Grammars Specifications,Electronic Notes in Theoretical Computer Science,2007,175,4,101-114,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107004173;http://dx.doi.org/10.1016/j.entcs.2007.04.020,10.1016/j.entcs.2007.04.020,"Concurrent object-oriented systems are ubiquitous due to the importance of networks and the current demands for modular, reusable, and easy to develop software. However, checking the correctness of such systems is a hard task, mainly due to concurrency and inheritance aspects. In this paper we present an approach to the verification of concurrent object-oriented systems. We use graph grammars equipped with object oriented features (including inheritance and polymorphism) as the specification formalism, and define a translation from such specifications to Promela, the input language of the SPIN model checker.","Graph grammars, object-oriented programming, model checking",Proceedings of the Workshop on Graph Transformation for Concurrency and Verification (GT-VC 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,de Oliveira Guimarães J,,The Green language,"Computer Languages, Systems & Structures",2006,32,4,203-215,,,,,2006,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842405000369;http://dx.doi.org/10.1016/j.cl.2005.07.001,10.1016/j.cl.2005.07.001,"Green is a statically typed object-oriented language which supports parameterized classes, metaobjects, introspective reflection, and classes as first-class objects. Its exception system is completely object-oriented for it encapsulates in classes not only exceptions but also exception handling. The language definition of subtyping is more encompassing than subclassing, thus improving polymorphism. Classes are classless objects which have themselves types. This makes classes first-class objects without the problems associated with languages in which every class is an object of another class, its metaclass. Every basic value such as 7 or ‘A’ is considered as an object whenever necessary which makes programming easy and increases polymorphism.","Object-oriented languages, Type systems, Polymorphism, Exception handling system",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Clifton C,Leavens GT",,MiniMAO1 : An imperative core language for studying aspect-oriented reasoning,Science of Computer Programming,2006,63,3,321-374,,,,,2006,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642306001249;http://dx.doi.org/10.1016/j.scico.2006.02.009,10.1016/j.scico.2006.02.009,"This paper describes MiniMAO1, a core aspect-oriented language. Unlike previous aspect-oriented calculi and core languages, MiniMAO1allows around advice to change the target object of an advised operation before proceeding. MiniMAO1accurately models the ways AspectJ allows changing the target object, e.g., at call join points. Practical uses for changing the target object using advice include proxies and other wrapper objects. MiniMAO1was designed to serve as a core language for studying modular specification and verification in the aspect-oriented paradigm. To this end MiniMAO1•has an imperative, reference-based semantics,•models the control-flow effects of changing target object bindings with advice, and•has a safe static type system. The first two features make MiniMAO1 suitable for the study of aspect-oriented mechanisms, such as those found in AspectJ. These features are important for studying the interaction of aspect-oriented language features with modular specification and verification. A statically type-safe language is also important for such research. AspectJ does not have a safe static type system. To achieve static type safety MiniMAO1uses a slightly different form of proceed and advice binding than in AspectJ. These changes are sufficient for static type safety, but we do not claim that they are necessary; a less restrictive type system might suffice. This paper gives an operational semantics, type system, and proof of soundness for MiniMAO1.","Aspect-oriented programming, MiniMAO calculus, Formal semantics",Special issue on foundations of aspect-oriented programming,,,,,,,,,,,,,,,,,,,,
Journal Article,Clark RG,,Type safety and behavioural inheritance,Information and Software Technology,1995,37,10,539-545,,,,,1995,,0950-5849,https://www.sciencedirect.com/science/article/pii/095058499590929O;http://dx.doi.org/10.1016/0950-5849(95)90929-O,10.1016/0950-5849(95)90929-O,"In object-oriented systems, inheritance is used for two separate purposes: for the inheritance of behaviour and for the inheritance of implementation. Combining inclusion polymorphism with inheritance can cause problems. We describe the restrictions on inheritance that have been proposed so that this combination does not introduce the possibility of type errors at run time. These restrictions do not, however, provide behavioural inheritance. During object-oriented software development, we want to be able to reason about the behaviour of a subclass in terms of the behaviour of its superclasses. We examine the various proposals that have been made for further restricting inheritance so that this is possible and discuss how such a discplined approach can be achieved in Eiffel and C++.","behavioural and incremental inheritance, object-oriented development, subtyping",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ruhroth T,Wehrheim H",,Static Class Elements for Object-Z,Electronic Notes in Theoretical Computer Science,2009,259,,193-205,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109005076;http://dx.doi.org/10.1016/j.entcs.2009.12.025,10.1016/j.entcs.2009.12.025,"Static variables and methods are part of almost every modern object-oriented programming language. Static elements are for instance indispensable for certain kinds of design patterns applied during programming. Object-oriented specification formalisms on the other hand lack such concepts. This can prevent writing formal specifications close to the actual implementation, and can thus hamper a refinement-based stepwise development. In this paper, we extend the state-based object-oriented specification language Object-Z with a concept for static class elements. We furthermore show how refinement can introduce static elements into a specification.","Object-Z, Class, Static Variables",Proceedings of the 14th BCS-FACS Refinement Workshop (REFINE 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Combi C,Chittaro L",,Abstraction on clinical data sequences: an object-oriented data model and a query language based on the event calculus,Artificial Intelligence in Medicine,1999,17,3,271-301,,,,,1999,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365799000226;http://dx.doi.org/10.1016/S0933-3657(99)00022-6,10.1016/S0933-3657(99)00022-6,"In this work, we deal with temporal abstraction of clinical data. Abstractions are, for example, blood pressure state (e.g. normal, high, low) and trend (e.g. increasing, decreasing and stationary) over time intervals. The goal of our work is to provide clinicians with automatic tools to extract high-level, concise, important features of available collections of time-stamped clinical data. This capability is especially important when the available collections constantly increase in size, as in long-term clinical follow-up, leading to information overload. The approach we propose exploits the integration of the deductive and object-oriented approaches in clinical databases. The main result of this work is an object-oriented data model based on the event calculus to support temporal abstraction. The proposed approach has been validated building the CARDIOTABS system for the abstraction of clinical data collected during echocardiographic tests.","Temporal reasoning, Temporal abstraction, Object-oriented databases, Deductive databases, Time sequences",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bossi A,Bugliesi M,Gabbrielli M,Levi G,Meo MC",,Differential logic programs: Programming methodologies and semantics,Science of Computer Programming,1996,27,3,217-262,,,,,1996,,0167-6423,https://www.sciencedirect.com/science/article/pii/0167642396000135;http://dx.doi.org/10.1016/0167-6423(96)00013-5,10.1016/0167-6423(96)00013-5,"We introduce the notion of differential logic programs and we define an operator for composing them in a hierarchical fashion. The semantics of this composition operator is reminiscent of the semantics of inheritance in the object oriented paradigm. Similar to classes in that paradigm, differential programs can be organized in isa schemas where each component inherits or redefines, modifying them, the predicates defined in the components that are placed higher up in the schema. We demonstrate the use of this form of composition as a programming methodology that enhances reusability, code sharing and information hiding. We define a proof theory and a model theory for the composition of differential programs and we prove that the two theories coincide. We also define a compositional and fully abstract semantics for differential programs and we address the importance of this semantics as a formal tool for reasoning on the computational properties of differential programs and their composition. A preliminary version of this paper appeared in Bossi et al. (1993)","Logic programming, Object-oriented, Inheritance, Compositional semantics, Full abstraction",,,,,,,,,,,,,,,,,,,,,
Journal Article,Olivé A,,A method for the definition of integrity constraints in object-oriented conceptual modeling languages,Data & Knowledge Engineering,2006,59,3,559-575,,,,,2006,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X05001606;http://dx.doi.org/10.1016/j.datak.2005.10.006,10.1016/j.datak.2005.10.006,"We propose a new method that eases the definition of integrity constraints in object-oriented conceptual modeling languages. The essence of the method is to represent constraints by special operations that we call constraint operations. The formal specification of these operations is the definition of the corresponding constraints. The method allows the specialization of constraints and the definition of exceptions. The main application of the method is for static constraints. However, a variant of it can also be applied for creation-time and deletion-time constraints, two particular classes of temporal constraints. The method can be adapted to any object-oriented language, and we show its adaptation to the UML. We also show that our method has several advantages over existing methods.","Integrity constraints, Conceptual modeling, Exceptions",Including: ER 2003,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fan W,Kuper GM,Siméon J",,A unified constraint model for XML,Computer Networks,2002,39,5,489-505,,,,,2002,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128602002190;http://dx.doi.org/10.1016/S1389-1286(02)00219-0,10.1016/S1389-1286(02)00219-0,"Integrity constraints are an essential part of modern schema definition languages. They are useful for semantic specification, update consistency control, query optimization, etc. In this paper, we propose UCM, a model of integrity constraints for XML that is both simple and expressive. Because it relies on a single notion of keys and foreign keys, the UCM model is easy to use and makes formal reasoning possible. Because it relies on a powerful type system, the UCM model is expressive, capturing in a single framework the constraints found in relational databases, object-oriented schemas and XML document type definitions. We study the problem of consistency of UCM constraints, the interaction between constraints and subtyping, and algorithms for implementing these constraints.","XML, XML schema, Integrity constraints, Keys, Reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cirstea H,Houtmann C,Wack B",,Distributive ρ-calculus,Electronic Notes in Theoretical Computer Science,2007,176,4,95-111,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107005154;http://dx.doi.org/10.1016/j.entcs.2007.06.010,10.1016/j.entcs.2007.06.010,"The rewriting calculus has been introduced as a general formalism that uniformly integrates rewriting and λ-calculus. In this calculus all the basic ingredients of rewriting such as rewrite rules, rule applications and results are first-class objects. The rewriting calculus has been originally designed and used for expressing the semantics of rule based as well as object oriented paradigms. We have previously shown that convergent term rewriting systems and classic strategies can be encoded naturally in the calculus. In this paper, we go a step further and we propose an extended version of the calculus that allows one to encode unrestricted term rewriting systems. This version of the calculus features a new evaluation rule describing the behavior of the result structures and a call-by-value evaluation strategy. We prove the confluence of the obtained calculus and the correctness and completeness of the proposed encoding.","rewriting calculus, lambda calculus, term rewriting systems, fixpoints",Proceedings of the 6th International Workshop on Rewriting Logic and its Applications (WRLA 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"di Sciascio C,Zanni-Merk C,Wemmert C,Marc-Zwecker S,de Beuvron FB",,Towards a Semi-automatic Semantic Approach for Satellite Image Analysis,Procedia Computer Science,2013,22,,1388-1397,,,,,2013,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050913012702;http://dx.doi.org/10.1016/j.procs.2013.11.057,10.1016/j.procs.2013.11.057,"The extended use of high and very high spatial resolution imagery inherently demands the adoption of classification methods capable of capturing the underlying semantic. Object-oriented classification methods are currently considered the most appropriate alternative, due to the incorporation of contextual information and domain knowledge into the analysis. Integrating knowledge initially requires a detailed process of acquisition and later the achievement of a formal representation. Ontologies constitute a very suitable approach to address both knowledge formalization and exploitation. A novel semi-automatic semantic approach focused on the extraction and classification of urban objects is hereby introduced. The use of a three-layered architecture allows the separation of concerns among knowledge, rules and experience. Knowledge represents the fundamental layer with which the other layers interact. Rules are meant to derive conclusions and make assertions based on knowledge. Finally, the experience layer supports the classification process in case of failure when attempting to identify an object, by applying specific expert rules to infer unusual membership.","object-oriented image analysis, ontology, ontology reasoning, expert knowledge",17th International Conference in Knowledge Based and Intelligent Information and Engineering Systems - KES2013,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bouabana-Tebibel T,Belmesk M",,An object-oriented approach to formally analyze the UML 2.0 activity partitions,Information and Software Technology,2007,49,9,999-1016,,,,,2007,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584906001777;http://dx.doi.org/10.1016/j.infsof.2006.10.007,10.1016/j.infsof.2006.10.007,"Nowadays, UML is the de-facto standard for object-oriented analysis and design. Unfortunately, the deficiency of its dynamic semantics limits the possibility of early specification analysis. UML 2.0 comes to precise and complete this semantics but it remains informal and still lacks tools for automatic validation. The main purpose of this study is to automate the formal validation, according a value-oriented approach, of the behavior of systems expressed in UML. The marriage of Petri nets with temporal logics seems a suitable formalism for translating and then validating UML state-based models. The contributions of the paper are threefold. We first, consider how UML 2.0 activity partitions can be transformed into Object Petri Nets to formalize the object dynamics, in an object-oriented context. Second, we develop an approach based on the object and sequence diagram information to initialize the derived Petri nets in terms of objects and events. Finally, to thoroughly verify if the UML model meets the system required properties, we suggest to use the OCL invariants exploiting their association end constructs. The verification is performed on a predicate/transition net explored by model checking. A case study is given to illustrate this methodology throughout the paper.","UML 2.0, Object Petri Nets, Activity partitions, Sequence diagram, Object diagram",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yalcin A,Namballa RK",,An object-oriented simulation framework for real-time control of automated flexible manufacturing systems,Computers & Industrial Engineering,2005,48,1,111-127,,,,,2005,,0360-8352,https://www.sciencedirect.com/science/article/pii/S0360835204001408;http://dx.doi.org/10.1016/j.cie.2004.07.010,10.1016/j.cie.2004.07.010,"This paper describes an object-oriented simulation approach for the design of a flexible manufacturing system that allows the implementation of control logic during the system design phase. The object-oriented design approach is built around the formal theory of supervisory control based on Finite Automata. The formalism is used to capture inter-object relationships that are difficult to identify in the object-oriented design approach. The system resources are modeled as object classes based on the events that have to be monitored for real-time control. Real-time control issues including deadlock resolution, resource failures in various modes of operation and recovery from failures while sustaining desirable logical system properties are integrated into the logical design for simulating the supervisory controller.","Object-oriented simulation, Flexible manufacturing systems, Real-time control",Selected Papers from the 31st. International Conference on Computers and Industrial Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Carvalho SE,Fiadeiro JL,Haeusler EH",,A Formal Approach to Real-Time Object Oriented Software,IFAC Proceedings Volumes,1997,30,23,71-76,,,,,1997,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017413942;http://dx.doi.org/10.1016/S1474-6670(17)41394-2,10.1016/S1474-6670(17)41394-2,"The ARTS paradigm involves a friendly user plane, where object oriented designs take place, and a corresponding formal plane where user decisions are verified, and which allows for early prototyping. The approach adopted for modelling real-time aspects (timed transition systems for the object’s life-cycle specification) relies on an extension of Henzinger’s Timed Transition Systems and Chang’s Metric Temporal Logic with δ-operators in the style of Segerberg, and actions modelling methods and message passing.","concurrency, object-oriented systems, real-time systems, specification, temporal logic","IFAC/IFIP Workshop on Real Time Programming 1997, Lyon, France, 15-17 September",,,,,,,,,,,,,,,,,,,,
Journal Article,"Iglewski M,Müldner T",,Comparison of formal specification methods and object-oriented paradigms,Journal of Network and Computer Applications,1997,20,4,355-377,,,,,1997,,1084-8045,https://www.sciencedirect.com/science/article/pii/S1084804597900503;http://dx.doi.org/10.1006/jnca.1997.0050,10.1006/jnca.1997.0050,"Object orientation and formal methods are widely regarded as two fields with significant potential for new software engineering techniques. This paper discusses the relations between these two approaches. We present various specification techniques which incorporate object-oriented paradigms, discuss their place in software development process, and analyse possible benefits from their applications.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Xu D,,Towards an object-oriented logic framework for knowledge based systems,Knowledge-Based Systems,1998,10,6,351-357,,,,,1998,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705197000464;http://dx.doi.org/10.1016/S0950-7051(97)00046-4,10.1016/S0950-7051(97)00046-4,"This article presents an object-oriented logic framework, LKO, for the dependable development of knowledge based systems. Based on logical objects which are viewed as abstractions with states, constraints, behaviors and nonmonotonic inheritance, a hybrid knowledge representation amalgamating rule, frame, semantics network and blackboard is available for both most structured and flat knowledge and requirements of knowledge based systems. After the iterations of specification modification and verification in terms of knowledge acquisition activities, prototypes are correctly formed. The LKO methodology, applying the concepts of rapid prototyping, top-down design and object-orientation, is designed to deal with changing and incomplete requirements and to provide multiple abstract models of the domain, where formal methods might be used at each abstract level.","Knowledge-based systems, Logic programming, Object-oriented programming, Specification, Verification",,,,,,,,,,,,,,,,,,,,,
Journal Article,de Boer FS,,A shared-variable concurrency analysis of multi-threaded object-oriented programs,Theoretical Computer Science,2009,410,2,128-141,,,,,2009,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397508006737;http://dx.doi.org/10.1016/j.tcs.2008.09.024,10.1016/j.tcs.2008.09.024,In this paper a proof outline logic is introduced for the partial correctness of multi-threaded object-oriented programs like in Java. The main contribution is a generalization of the Owicki& Gries proof method for shared-variable concurrency to dynamic thread creation. This paper also provides a formal justification of this generalization in terms of soundness and completeness proofs.,"Verification, Partial correctness, Multi-threaded object-oriented programs interference, Soundness, Completeness",Distributed Computing Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,"Edmunds A,Butler M",,Linking Event-B and Concurrent Object-Oriented Programs,Electronic Notes in Theoretical Computer Science,2008,214,,159-182,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108003514;http://dx.doi.org/10.1016/j.entcs.2008.06.008,10.1016/j.entcs.2008.06.008,"The Event-B method is a formal approach to modelling systems, using refinement. Initial specification is done at a high level of abstraction; detail is added in refinement steps as the development proceeds toward implementation. In software systems that use concurrent processing it is necessary to provide details of concurrent features before implementation. Our contribution is to show how Event-B models can be linked to concurrent, object-oriented implementations using an intermediate, object-oriented style specification notation. To validate our approach and gain further insight we automated the translation process with an Eclipse plug-in which produces an Event-B model and Java code. We call the new notation Object-oriented Concurrent-B (OC-B). The notation facilitates specification of the concurrent aspects of a development, and facilitates reasoning about concurrency issues in an abstract manner. We abstract away implementation details, such as locking, and provide the developer with a clear view of atomicity using labelled atomic clauses. We build on techniques introduced in UML-B to model object-oriented developments, introducing non-atomic operations and features for specifying implementation level details.","Event-B, Object-oriented, Concurrency, Refinement",Proceedings of the 13th BAC-FACS Refinement Workshop (REFINE 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,Philippi S,,Visual Programming of Concurrent Object-Oriented Systems,Journal of Visual Languages & Computing,2001,12,2,127-143,,,,,2001,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X00901927;http://dx.doi.org/10.1006/jvlc.2000.0192,10.1006/jvlc.2000.0192,"In order to be able to understand the functionality of even small concurrent systems, visual and formally-based notations for their description are needed. The handling of complex systems additionally demands for notations offering adequate structuring capabilities. From a theoretical point of view the combination of Petri-Nets and object-oriented concepts is a promising approach in this area. Despite their potential, only few of the existing object-oriented Petri-Net proposals support the seamless development of systems ranging from high-level analysis to visual programming. This article introduces a set of essential properties for approaches in the area of object-oriented Petri-Nets and briefly surveys the common problems of existing work. Afterwards OOPr/T-Models, a novel approach intended to overcome the limitations of existing ones, are introduced. Their practical use as visual programming language for the description of (concurrent) object-oriented systems is shown with an example for the rendering of fractal images.","Concurrency, object-orientation, integrated systems modeling, formally-based, Petri-Nets",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Welsch Y,Poetzsch-Heffter A",,A fully abstract trace-based semantics for reasoning about backward compatibility of class libraries,Science of Computer Programming,2014,92,,129-161,,,,,2014,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642313002529;http://dx.doi.org/10.1016/j.scico.2013.10.002,10.1016/j.scico.2013.10.002,"Backward compatibility is the property that an old version of a library can safely be replaced by a new version without breaking existing clients. Formal reasoning about backward compatibility requires an adequate semantic model to compare the behavior of two library implementations. In the object-oriented setting with inheritance and callbacks, such a model must account for the complex interface between library implementations and clients. In this paper, we develop a fully abstract trace-based semantics for class libraries in object-oriented languages, in particular for Java-like sealed packages. Our approach enhances a standard operational semantics such that the change of control between the library and the client context is made explicit in terms of interaction labels. By using traces over these labels, we abstract from the data representation in the heap, support class hiding, and provide fully abstract package denotations. Soundness and completeness of the trace semantics is proven using specialized simulation relations on the enhanced operational semantics. The simulation relations also provide a proof method for reasoning about backward compatibility.","Full abstraction, Class libraries, Trace semantics, Contextual preorder, Backward compatibility",Selected papers from the Brazilian Symposium on Formal Methods (SBMF 2011),,,,,,,,,,,,,,,,,,,,
Journal Article,Ferrando A,,"The early bird catches the worm: First verify, then monitor!",Science of Computer Programming,2019,172,,160-179,,,,,2019,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642318304349;http://dx.doi.org/10.1016/j.scico.2018.11.008,10.1016/j.scico.2018.11.008,"Trace expressions are a compact and expressive formalism, initially devised for runtime verification of agent interactions in multiagent systems, which has been successfully employed to model real-world protocols, and to generate monitors for mainstream multiagent system platforms, and generalized to support runtime verification of different kinds of properties and systems. In this paper, we propose an algorithm to check Linear Temporal Logic (LTL) properties satisfiability on trace expressions. To do this, we show how to translate a trace expression into a Büchi Automaton in order to realize an Automata-Based Model Checking. We show that this translation generates an over-approximation of our trace expression leading us to obtain a sound procedure to verify LTL properties. Once we have statically checked a set of LTL properties, we can conclude that: (1) our trace expression is formally correct (2) since we use this trace expression to generate monitors checking the runtime behavior of the system, the LTL properties verified by this trace expression are also verified by the monitored system.","Runtime verification of object-oriented programming, Trace expressions, Automata-based model checking, Runtime monitoring, Combining static and runtime verification",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Beeri C,"Kim W,Nicolas JM,Nishio S",Formal Models for Object Oriented Databases**This research is partially supported by grant 2633 from the Israeli Ministry of Science,,1990,,,405-430,,North-Holland,Amsterdam,Deductive and Object-Oriented Databases,1990,9780444884336,,https://www.sciencedirect.com/science/article/pii/B9780444884336500307;http://dx.doi.org/10.1016/B978-0-444-88433-6.50030-7,10.1016/B978-0-444-88433-6.50030-7,"Object oriented database systems are the focus of current research and development efforts. Yet, there is no commonly accepted object model, nor is it clear whether such a model can be developed. This paper informally reports on efforts to develop a formal framework that contains most features found in current object oriented database systems. The framework contain two parts. The first is a structural object model, including concepts such as structured objects, identity, and some form of inheritance. For this model, we explain the distinction between values and (abstract) objects, describe a system as a directed graph, and discuss declarative languages. The second part deals with high order concepts, such as classes and functions as data, methods, inheritance and encapsulation. This part is a sketch, and leaves many issues unresolved.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Seiffert D,Hummel O",,Adapting collections and arrays: Another step towards the automated adaptation of object ensembles,Journal of Systems and Software,2017,123,,79-91,,,,,2017,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412121630200X;http://dx.doi.org/10.1016/j.jss.2016.10.002,10.1016/j.jss.2016.10.002,"An important obstacle to reuse in object-oriented development is that objects or more generally components often cannot be plugged together directly due to interface mismatches. Consequently, automating the adaptation of software building blocks has been on the research agenda for quite a while. However, apart from various approaches based on (semi-)formal specifications, adaptation approaches based on test cases have only recently demonstrated that practically useable implementations of this idea are feasible. This article addresses the automated adaptation of arrays and collections in order to increase the applicability of existing test-based adaptation approaches.","Object adaptation, Signature mismatches, Test-driven adaptation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dedene G,Snoeck M",,Formal deadlock elimination in an object oriented conceptual schema,Data & Knowledge Engineering,1995,15,1,1-30,,,,,1995,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X94000319;http://dx.doi.org/10.1016/0169-023X(94)00031-9,10.1016/0169-023X(94)00031-9,"Object oriented models model structural and behavioural aspects of objects in the Universe of Discourse. As the dynamic aspects of objects include parallelism and synchronisation of object life cycles, conceptual schemes must be verified for problematic behaviour like deadlock. In this paper we will present fragments of a method for object oriented analysis and the process algebra that allows to formally verify a conceptual schema build according to this method for deadlock behaviour.","Object oriented modeling methods, Process algebra, Deadlock elimination, Formal specifications",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Leino KR,Stata R",,Virginity: A contribution to the specification of object-oriented software,Information Processing Letters,1999,70,2,99-105,,,,,1999,,0020-0190,https://www.sciencedirect.com/science/article/pii/S0020019099000435;http://dx.doi.org/10.1016/S0020-0190(99)00043-5,10.1016/S0020-0190(99)00043-5,"In object-oriented programs built in layers, an object at a higher level of abstraction is implemented by objects at lower levels of abstraction. It is usually crucial to correctness that a lower-level object not be shared among several higher-level objects. This paper unveils some difficulties in writing procedure specifications strong enough to guarantee that a lower-level object can be used in the implementation of another object at a higher level of abstraction. To overcome these difficulties, the paper presents virginity, a convenient way of specifying that an object is not globally reachable and thus can safely be used in the implementation of a higher-level abstraction.","Program specification, Object-oriented programming, Program verification, Specification languages, Formal semantics, Static program checking",,,,,,,,,,,,,,,,,,,,,
Journal Article,Liu L,,A recursive object algebra based on aggregation abstraction for manipulating complex objects,Data & Knowledge Engineering,1993,11,1,21-60,,,,,1993,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9390044P;http://dx.doi.org/10.1016/0169-023X(93)90044-P,10.1016/0169-023X(93)90044-P,"We present an object algebra for manipulating complex objects in object-oriented database systems. All operators are recursively defined. Unlike most of the existing query languages, the design of this object algebra is based on aggregation abstraction. It allows to take complex objects collectively as a unit of high level queries and enables complex objects to be accessed at all levels of aggregation hierarchies without resorting to any kind of path expressions. Features of aggregation abstraction, such as acyclicity of aggregation hierarchies and aggregation inheritance, have played important roles in such a development. We also formally described the output type of each operator in order to support dynamic classification of query results in the IsA type/class semi-lattice. The algebraic-equivalence rewriting rules for query optimization of this algebra are developed, too.","Object-oriented databases, object algebra, object-creating operators, object preserving operators, query optimization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Vogel-Heuser B,Braun S,Kormann B,Friedrich D",,Implementation and evaluation of UML as modeling notation in object oriented software engineering for machine and plant automation,IFAC Proceedings Volumes,2011,44,1,9151-9157,,,,,2011,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016450810;http://dx.doi.org/10.3182/20110828-6-IT-1002.01343,10.3182/20110828-6-IT-1002.01343,Abstract Our goal is to increase efficiency and quality in automation engineering in machine and plant manufacturing industry by supporting modularity and reuse. This article proofs that object-oriented model-based design can beneficially be applied in industry and that the code automatically derived from the UML model can be implemented on industrial PLCs without additional effort. We had to solve the formal mapping from UML models to IEC 61131-3 program code in order to use an object-oriented approach with Unified Modeling Language (UML) as modeling notation integrated into a classical Programmable Logic Controller (PLC) programming environment (IEC 61131-3).,,18th IFAC World Congress,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gkolfi A,Din CC,Johnsen EB,Kristensen LM,Steffen M,Yu IC",,Translating active objects into colored Petri nets for communication analysis,Science of Computer Programming,2019,181,,1-26,,,,,2019,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642318300418;http://dx.doi.org/10.1016/j.scico.2019.04.002,10.1016/j.scico.2019.04.002,"Actor-based languages attract attention for their ability to scale to highly parallel architectures. Active objects combine the asynchronous communication of actors with object-oriented programming by means of asynchronous method calls and synchronization on futures. However, the combination of asynchronous calls and synchronization may introduce communication cycles which lead to a form of communication deadlock and livelock. This paper addresses such communication deadlocks and livelocks for ABS, a formally defined active object language which additionally supports cooperative scheduling to express complex distributed control flow, using first-class futures and explicit process release points. Our approach is based on a translation of the semantics of ABS into colored Petri nets, such that a program and its state correspond to a marking of this net. We prove the soundness of this translation and demonstrate by example how the implementation of this net can be used to analyze ABS programs with respect to communication deadlocks and livelocks.","Colored Petri nets, Model checking, Semantics, Static analysis, Concurrency",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ling TW,Teo PK",,Toward resolving inadequacies in object-oriented data models,Information and Software Technology,1993,35,5,267-276,,,,,1993,,0950-5849,https://www.sciencedirect.com/science/article/pii/095058499390060G;http://dx.doi.org/10.1016/0950-5849(93)90060-G,10.1016/0950-5849(93)90060-G,"The object oriented (OO) paradigm suffers from several inadequacies which are widely recognized, e.g. lack of a formal foundation, general disagreement in interpreting OO concepts, lack of a declarative query language, use of a navigational interface, inheritance conflicts in class hierarchies, etc. In the paper, a representative list of these inadequacies is presented. Some proposals that have been made to resolve some of these inadequacies are reviewed. Then the authors outline and justify an entity relationship based three level schema architecture which addresses several OO data modelling inadequacies, viz. the lack of support for the notion of relationship in the OO approach, the lack of support for external schemas, the inability to judge the quality of an OO schema and the lack of a reasonable approach to resolve inheritance conflicts in class hierarchies.","object-oriented data model, three-level schema architecture, normal form",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rafe V,Golparian M,Rasoolzadeh S",,Using graph transformation systems to formalize Tropos diagrams,Journal of Visual Languages & Computing,2015,30,,1-16,,,,,2015,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X15000452;http://dx.doi.org/10.1016/j.jvlc.2015.08.001,10.1016/j.jvlc.2015.08.001,"Today, the agent-oriented methodologies become increasingly attractive to the software system development industry. These methodologies mostly use object-oriented paradigms by concepts like autonomy, pro activity, reactivity, cooperation and alike. There are different agent-oriented methodologies each with different phases and diagrams. However, most of them are using informal graphical diagrams. Hence, automatic analysis of these diagrams may be a challenge. Automated analysis capabilities are necessary to develop high quality software systems. To alleviate this problem, using a formal method to describe the underlying semantics seems necessary. Since graph transformation systems (GTS) are widely used for defining the syntax and semantics of different diagrams and notations formally, in this paper, we are using GTS to formalize agent-oriented methodologies. Among different agent-oriented methodologies, we consider Tropos, because it is basically agent-based, in contrast to the other methodologies which are extensions of the existing object-oriented methodologies. To do so, our proposal consists of four steps: first, we define a meta-model for the abstract syntax of the existing diagrams which are used by the methodology (as a type graph); second, the structural diagrams are defined using host graphs consistent with the designed meta-model and behavioral ones using graph rules. Third, we refine the diagrams automatically to generate some detailed diagrams along with the JACK skeleton codes, and four, we finally verify and validate all the steps through checking consistency, compatibility, correctness and so on.","Formal modeling, Graph transformation systems, Agent-oriented software engineering, Tropos",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Kuno Y,,Misty: An Object-Oriented Programming Language with Multiple Inheritance and Strict Type-Checking,,1992,3,,109-125,,Elsevier,,Japan Society for Software Science and Technology,1992,,1044-7997,https://www.sciencedirect.com/science/article/pii/B9780120371037500139;http://dx.doi.org/10.1016/B978-0-12-037103-7.50013-9,10.1016/B978-0-12-037103-7.50013-9,"Summary A strong type-checking facility is indispensable for an object-oriented programming language to be usable in large-scale software development. Misty is an object-oriented programming language with both multiple inheritance and strict type-checking facilities. Type-checking is applied not according to subtype relations between types, but according to strict equality between types. This principle differs markedly from that of other object-oriented programming languages with “strong” type-checking facilities, which incorporate subtype relations, and Misty's type-checking facility therefore termed a “strict” one. In spite of this strictness, Misty retains most of the flexibility seen in object-oriented programming languages without compile-time type checking. Moreover, experience of programming in Misty has revealed that program design and development using a class specification hierarchy along with a compiler to check its consistency will be a valuable and powerful tool for programming-in-the-large.",,,Advances in Software Science and Technology,,,,,,,,,,,,,,,,,,,
Journal Article,"Formica A,Frank H",,Consistency of the static and dynamic components of object-oriented specifications,Data & Knowledge Engineering,2002,40,2,195-215,,,,,2002,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X01000520;http://dx.doi.org/10.1016/S0169-023X(01)00052-0,10.1016/S0169-023X(01)00052-0,"Object-oriented (OO) modeling and design methodologies have been receiving a significant attention since they allow a quick and easy-to-gasp overview about a complex model. However, in the literature there are no formal frameworks that allow designers to verify the consistency (absence of contradictions) of both the static and dynamic components of the specified models, that are often assumed to be consistent. In this paper, a unifying formal framework is proposed that allows the consistency checking of both the static and dynamic components of a simplified OO model.","Object-oriented specifications, Consistency, Integrity constraints, Static model, Dynamic model",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Baresi L,Pezzè M",,Improving UML with Petri nets1 1This work has been partially supported by Ministero della Ricerca Scientifica e Technologica under the SALADIM Project and by Polipecnico di Milano under the TATOOS Project,Electronic Notes in Theoretical Computer Science,2001,44,4,107-119,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104809472;http://dx.doi.org/10.1016/S1571-0661(04)80947-2,10.1016/S1571-0661(04)80947-2,"UML is the OMG standard notation for object-oriented modeling. It is easy, graphical and appealing, but in several cases still too imprecise. UML is strong as modeling means, supplies several different diagrammatic notations for representing the different aspects of a system under development, but lacks simulation and verifiability capabilities. This drawback comes from its semi-formal nature: UML is extremely precise and wide if we consider syntactical aspects, but its semantics is as precise as those of informal notations. Scientists and users, together with standardization efforts (UML 2.0), are trying to overcome this problem, but as side effect, they are also limiting the intrinsic flexibility of UML. Moreover, several formalization efforts concentrated on its static elements (for example, inheritance), leaving dynamic semantics almost untouched. In this paper we propose the paring of UML dynamic models with high-level timed Petri nets (HLTPN) to obtain a flexible and customizable means to reason on the dynamic aspects of object-oriented models, to simulate particular parts of these models, and if necessary analyze them. The proposal exploits rules to ascribe main UML elements with formal semantics in terms of functionally equivalent HLTPNs and to show results (from execution and analysis) as decorations to UML symbols. Besides sketching the approach, the paper presents also some experiences we have gained so far with it and a research agenda to identify other possible uses of the dual definition of the notation.","UML, Petri Nets, Formal Specifications, Simulation, Analysis","UNIGRA 2001, Uniform Approaches to Graphical Process Specification Techniques (a Satellite Event of ETAPS 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Johnsen EB,Blanchette JC,Kyas M,Owe O",,Intra-Object versus Inter-Object: Concurrency and Reasoning in Creol,Electronic Notes in Theoretical Computer Science,2009,243,,89-103,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109002291;http://dx.doi.org/10.1016/j.entcs.2009.07.007,10.1016/j.entcs.2009.07.007,"In thread-based object-oriented languages, synchronous method calls usually provide the mechanism to transfer control from caller to callee, blocking the caller until the call is completed. This model of control flow is well-suited for sequential and tightly coupled systems but may be criticized in the concurrent and distributed setting, not only for unnecessary delays but also for the reasoning complexity of multithreaded programs. Concurrent objects propose an alternative to multithread concurrency for object-oriented languages, in which each object encapsulates a thread of control and communication between objects is asynchronous. Creol is a formally defined modeling language for concurrent objects which clearly separates intra-object scheduling from inter-object communication by means of interface encapsulation, asynchronous method calls, and internal processor release points. This separation of concerns provides a very clean model of concurrency which significantly simplifies reasoning for highly parallel and distributed object-oriented systems. This paper gives an example-driven introduction to these basic features of Creol and discusses how this separation of concerns influences analysis of Creol models.","Creol, Abstract behavioral modeling, Asynchronous method call, Concurrent objects, Distributed systems",Proceedings of the 2nd International Workshop on Harnessing Theories for Tool Support in Software (TTSS 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Din CC,Owe O",,A sound and complete reasoning system for asynchronous communication with shared futures,Journal of Logical and Algebraic Methods in Programming,2014,83,5,360-383,,,,,2014,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220814000376;http://dx.doi.org/10.1016/j.jlamp.2014.03.003,10.1016/j.jlamp.2014.03.003,"Distributed and concurrent object-oriented systems are difficult to analyze due to the complexity of their concurrency, communication, and synchronization mechanisms. We consider the setting of concurrent objects communicating by asynchronous method calls. The future mechanism extends the traditional method call communication model by facilitating sharing of references to futures. By assigning method call result values to futures, third party objects may pick up these values. This may reduce the time spent waiting for replies in a distributed environment. However, futures add a level of complexity to program analysis, as the program semantics becomes more involved. This paper presents a Hoare style reasoning system for distributed objects based on a general concurrency and communication model focusing on asynchronous method calls and futures. The model facilitates invariant specifications over the locally visible communication history of each object. Compositional reasoning is supported, and each object may be specified and verified independently of its environment. The presented reasoning system is proven sound and (relatively) complete with respect to the given operational semantics.","Distributed systems, Compositional reasoning, Hoare Logic, Concurrent objects, Operational semantics, Communication history",The 24th Nordic Workshop on Programming Theory (NWPT 2012),,,,,,,,,,,,,,,,,,,,
Journal Article,Tzouvaras A,,Objects and their lambda calculus,Theoretical Computer Science,2001,258,1,209-232,,,,,2001,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397500000098;http://dx.doi.org/10.1016/S0304-3975(00)00009-8,10.1016/S0304-3975(00)00009-8,"A kind of parallel typed lambda calculus is presented based on the language and structure of objects. The term “object” is used here in a sense different from that related to the expression “object-oriented language (programming)”. By “objects” here we mean any class of entities which (a) are resource dependent and (b) combine to each other (via some fitness relation) to form more complex ones. Two operators, λ and its dual λ̄, are used, and two operations, a binary one, ⊙, for juxtaposition, and an n-ary one, |, for every n, for branching. The construct λv.x represents, roughly, a receiving scheme producing copies of x when fed with proper objects y to fill the empty place v of x, while the dual construct λ̄y.z represents a sending scheme that throws y out z in proper surroundings. The interaction of these two constructs takes place when they are matched together by ⊙ and yields an exchange of resources in a way that preserves the total amount of them. The calculus captures such notions as concurrency, interaction and branching in a way analogous to that of (Berrey and Boudol, Theoret. Comput. Sci. 96 (1992) 217–248; Boudol, Lecture Notes in Computer Science, Vol. 351, Springer, Berlin, pp. 149–161) [3,4], but with a quite different meaning of the operations. What is described here is “situations” of coexisting entities rather than computations, and resource-preserving transformations between them. The terms are shown to have unique normal forms. Object structures that model the simple theory of objects are extended here in suitable graph structures that provide sound and complete semantics of the calculus.","Structure of objects, -calculus, Concurrency, Branching",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Borges RM,Mota AC",,Integrating UML and Formal Methods,Electronic Notes in Theoretical Computer Science,2007,184,,97-112,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107004379;http://dx.doi.org/10.1016/j.entcs.2007.03.017,10.1016/j.entcs.2007.03.017,"UML is a widespread language used in both industry and academia, despite the fact that its semantics is still informal and allows ambiguities. On the other hand, OhCircus is a formal specification language which unifies Z, CSP, the refinement calculus of Morgan and object-oriented theories. In this work we integrate UML class diagrams and OhCircus by written UML elements in terms of OhCircus constructs. However, instead of a simply syntactical mapping, we also propose the concept of a class model to capture associations and global constraints. Finally, we use this integration to prove the refinement of associations as attributes, a result that relates analysis to design to implementation and which is very common in industry.","UML, , formal methods, translation, refinement",Proceedings of the Second Brazilian Symposium on Formal Methods (SBMF 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"da S. Ribeiro A,Lima EJ,Lepikson H",,Implementation of a SCADA System for Flexible Manufacturing Systems using object-oriented Petri nets model,IFAC Proceedings Volumes,2009,42,4,1673-1678,,,,,2009,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016340381;http://dx.doi.org/10.3182/20090603-3-RU-2001.0300,10.3182/20090603-3-RU-2001.0300,"This work proposes the implementation of a Supervisory, Control and Data Acquisition (SCADA) System for a Flexible Manufacturing System (FMS) based on an object-oriented Petri Net model of the plant. Considering the complexity of a FMS (different types of parts and raw materials, different schedules, processes and programs to deal with, ways of handling parts, etc.), the implementation of a SCADA System to manage and control the plant is complex and susceptible to errors, even deadlocks. The creation of a program based on a formal model capable of dealing with such complexity and problems minimizes mistakes and allows such a model to be simulated, anticipating error situations and its possible solutions. The editing and debugging processes are also facilitated, as well as the inclusion of new types of parts or processes that can be easily performed by the definition of new attributes and methods according to the model. The analysis of the program performance is carried out using a formal methodology based on the model. A case-study implementation is shown for demonstration and validation purposes.","Object-oriented Petri Nets, Flexible Manufacturing System (FMS), Process Control, Object Oriented Programming",13th IFAC Symposium on Information Control Problems in Manufacturing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yang L,Stolz V",,Integrating Refinement into Software Development Tools,Electronic Notes in Theoretical Computer Science,2008,207,,69-88,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108001916;http://dx.doi.org/10.1016/j.entcs.2008.03.086,10.1016/j.entcs.2008.03.086,"It is a challenge for automatic tool support to formal design by refinement transformations. In this paper, we bring this matter to the attention of the research community and discuss a component-based model transformational approach for integrating refinement into software development tools. Models, their consistency and correctness, in an object-oriented and component-based development process are defined in rCOS, that is a refinement calculus recently developed at UNU-IIST. Correctness preserving transformations between models are formalized and proved as refinement rules in rCOS. In this paper, we will discuss on how these transformations can be implemented in the relations language of Query/View/Transformation (QVT) standardized by OMG.","Model transformations, MDA, QVT, rCOS",Proceedings of the 1st International Workshop on Harnessing Theories for Tool Support in Software (TTSS 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,Reddy US,,Objects and Classes in Algol-Like Languages,Information and Computation,2002,172,1,63-97,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S089054010192927X;http://dx.doi.org/10.1006/inco.2001.2927,10.1006/inco.2001.2927,"Many object-oriented languages used in practice descend from Algol. With this motivation, we study the theoretical issues underlying such languages via the theory of Algol-like languages. It is shown that the basic framework of this theory extends cleanly and elegantly to the concepts of objects and classes. Moreover, a clear correspondence emerges between classes and abstract data types, whose theory corresponds to that of existential types. Equational and Hoare-like reasoning methods and relational parametricity provide powerful formal tools for reasoning about Algol-like object-oriented programs.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Johnsen EB,Schlatte R,Tapia Tarifa SL",,Integrating deployment architectures and resource consumption in timed object-oriented models,Journal of Logical and Algebraic Methods in Programming,2015,84,1,67-91,,,,,2015,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220814000479;http://dx.doi.org/10.1016/j.jlamp.2014.07.001,10.1016/j.jlamp.2014.07.001,"Software today is often developed for many deployment scenarios; the software may be adapted to sequential, concurrent, distributed, and even virtualized architectures. Since software performance can vary significantly depending on the target architecture, design decisions need to address which features to include and what performance to expect for different architectures. To make use of formal methods for these design decisions, system models need to range over deployment scenarios. For this purpose, it is desirable to lift aspects of low-level deployment to the abstraction level of the modeling language. This paper proposes an integration of deployment architectures in the Real-Time ABS language, with restrictions on processing resources. Real-Time ABS is a timed, abstract and behavioral specification language with a formal semantics and a Java-like syntax, that targets concurrent, distributed and object-oriented systems. A separation of concerns between execution cost at the object level and execution capacity at the deployment level makes it easy to compare the timing and performance of different deployment scenarios already during modeling. The language and associated simulation tool is demonstrated on examples and its semantics is formalized.","Deployment architecture, Resource management, Object orientation, Formal methods, Performance, Real-Time ABS","Special Issue: The 23rd Nordic Workshop on Programming Theory (NWPT 2011) Special Issue: Domains X, International workshop on Domain Theory and applications, Swansea, 5-7 September, 2011",,,,,,,,,,,,,,,,,,,,
Journal Article,"Danvy O,Johannsen J",,Inter-deriving semantic artifacts for object-oriented programming,Journal of Computer and System Sciences,2010,76,5,302-323,,,,,2010,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000009000932;http://dx.doi.org/10.1016/j.jcss.2009.10.004,10.1016/j.jcss.2009.10.004,"We present a new abstract machine for Abadi and Cardelli's untyped non-imperative calculus of objects. This abstract machine mechanically corresponds to both the reduction semantics (i.e., small-step operational semantics) and the natural semantics (i.e., big-step operational semantics) specified in Abadi and Cardelli's monograph. To move closer to actual implementations, which use environments rather than actual substitutions, we then represent methods as closures and we present three new semantic artifacts for a version of Abadi and Cardelli's calculus with explicit substitutions: a reduction semantics, an environment-based abstract machine, and a natural semantics (i.e., an interpreter) with environments. These three new semantic artifacts mechanically correspond to each other, and the two abstract machines are bisimilar. Their significance lies in the fact that they have not been designed from scratch and then proved correct; instead, they have been inter-derived. To illustrate the inter-derivation and to make this article stand-alone, we also comprehensively treat the example of negational normalization over Boolean formulas, in appendix.","Functional calculus of objects, Reduction semantics, Abstract machine, Natural semantics, Syntactic correspondence, Functional correspondence","Workshop on Logic, Language, Information and Computation",,,,,,,,,,,,,,,,,,,,
Journal Article,"Estler HC,Ruhroth T,Wehrheim H",,Modelchecking Correctness of Refactorings - Some Experiments,Electronic Notes in Theoretical Computer Science,2007,187,,3-17,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107004653;http://dx.doi.org/10.1016/j.entcs.2006.08.041,10.1016/j.entcs.2006.08.041,"Refactorings are changes made to programs, models or specifications with the intention of improving their structure and thus making them clearer, more readable and re-usable. Refactorings are required to be behaviour-preserving in that the external behaviour of the program/model/specification remains unchanged. In this paper we show how a simple type of refactorings on object-oriented specifications (written in Object-Z) can be formally shown to be behaviour-preserving using a modelchecker (SAL). The class of refactorings treated covers those operating on a single method only.","Refactoring, Object Z, Model Checking, SAL",Proceedings of the 11th Refinement Workshop (REFINE 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Compagnoni A,Goguen H",,Typed operational semantics for higher-order subtyping,Information and Computation,2003,184,2,242-297,,,,,2003,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540103000622;http://dx.doi.org/10.1016/S0890-5401(03)00062-2,10.1016/S0890-5401(03)00062-2,"Bounded operator abstraction is a language construct relevant to object oriented programming languages and to ML2000, the successor to Standard ML. In this paper, we introduce Fω⩽, a variant of F<:ω with this feature and with Cardelli and Wegner’s kernel Fun rule for quantifiers. We define a typed-operational semantics with subtyping and prove that it is equivalent with Fω⩽, using logical relations to prove soundness. The typed-operational semantics provides a powerful and uniform technique to study metatheoretic properties of Fω⩽, such as Church–Rosser, subject reduction, the admissibility of structural rules, and the equivalence with the algorithmic presentation of the system that performs weak-head reductions. Furthermore, we can show decidability of subtyping using the typed-operational semantics and its equivalence with the usual presentation. Hence, this paper demonstrates for the first time that logical relations can be used to show decidability of subtyping.","Subtyping, Type theory, Typed-operational semantics, Lambda calculus, Dependent kinds",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Davis KC,Delcambre LM",,Foundations for object-oriented query processing,Computer Standards & Interfaces,1991,13,1,207-212,,,,,1991,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899190028X;http://dx.doi.org/10.1016/0920-5489(91)90028-X,10.1016/0920-5489(91)90028-X,"A minimal framework for an object-oriented query language standard should (1) include a formal definition of a high-level data model and the syntax and semantics of associated query languages, (2) provide the functionality of relational query languages, and (3) support proofs of correctness of transformations for logical query optimization. In this paper, a high-level conceptual model for object-oriented query processing is discussed; the model includes widely-used structural abstractions such as the isa relationship, associations (properties) between complex objects and complex objects/values, and inheritance of properties. A formal, algebraic query language for the model, inspired by relational algebra, is presented. Operators of the algebra allow queries based on values, queries that manipulate entire objects, and queries that construct new objects from existing objects/values. All queries retain connections to existing database objects, providing logical access paths to data. Each query result is a class, so the algebra has the closure property. The intensional and extensional results of query operators are summarized. Two forms of logical query optimization supported by the query algebra are outlined: algebraic transformations and classifier-based optimizations (optimizations which employ inclusion and exclusion dependencies between classes).","Object-oriented query processing, logical query optimization, conceptual model, classifier, algebraic query language",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Houston IS,Josephs MB",,A formal description of the OMG's Core Object Model and the meaning of compatible extension,Computer Standards & Interfaces,1995,17,5,553-558,,,,,1995,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899500019Q;http://dx.doi.org/10.1016/0920-5489(95)00019-Q,10.1016/0920-5489(95)00019-Q,"The Object Management Group's Core Object Model provides a standard type structure that must be supported by compliant object-oriented systems (such as IBM's SOM Object Request Broker) and languages (such as C++). The standard is expressed in prose and punctuated by several small examples. The standard also attempts to convey the idea of compatible extensions to the model. The objective of the work reported here was to understand and to communicate the essence of the above standard by use of a formal description technique, the Z notation. In so doing, the meaning of compatibility was clarified. These efforts have been well-received by authors of the original standard.","Object-oriented technology, Portability, Interoperability, Object model, Compatible extension, Formal description, Z notation",Formal Description Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ramezanifarkhani T,Owe O,Tokas S",,A secrecy-preserving language for distributed and object-oriented systems,Journal of Logical and Algebraic Methods in Programming,2018,99,,1-25,,,,,2018,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220817300603;http://dx.doi.org/10.1016/j.jlamp.2018.04.001,10.1016/j.jlamp.2018.04.001,"In modern systems it is often necessary to distinguish between confidential (low-level) and non-confidential (high-level) information. Confidential information should be protected and not communicated or shared with low-level users. The non-interference policy is an information flow policy stipulating that low-level viewers should not be able to observe a difference between any two executions with the same low-level inputs. Only high-level viewers may observe confidential output. This is a non-trivial challenge when considering modern distributed systems involving concurrency and communication. The present paper addresses this challenge, by choosing language mechanisms that are both useful for programming of distributed systems and allow modular system analysis. We consider a general concurrency model for distributed systems, based on concurrent objects communicating by asynchronous methods. This model is suitable for modeling of modern service-oriented systems, and gives rise to efficient interaction avoiding active waiting and low-level synchronization primitives such as explicit signaling and lock operations. This concurrency model has a simple semantics and allows us to focus on information flow at a high level of abstraction, and allows realistic analysis by avoiding unnecessary restrictions on information flow between confidential and non-confidential data. Due to the non-deterministic nature of concurrent and distributed systems, we define a notion of interaction non-interference policy tailored to this setting. We provide two kinds of static analysis: a secrecy-type system and a trace analysis system, to capture inter-object and network level communication, respectively. We prove that interaction non-interference is satisfied by the combination of these analysis techniques. Thus any deviation from the policy caused by implicit information leakage visible through observation of network communication patterns, can be detected. The contribution of the paper lies in the definition of the notion of interaction non-interference, and in the formalization of a secrecy type system and a static trace analysis that together ensure interaction non-interference. We also provide several versions of a main example (a news subscription service) to demonstrate network leakage.","Concurrent objects, Asynchronous methods, Non-interference, Interaction non-interference, Information flow, Secrecy",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bravetti M,Giachino E,Lienhardt M,Wong PY",,Dynamic Rebinding for Concurrent Object Groups: Theory and practice,Journal of Logical and Algebraic Methods in Programming,2017,86,1,349-390,,,,,2017,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220816300189;http://dx.doi.org/10.1016/j.jlamp.2016.03.002,10.1016/j.jlamp.2016.03.002,"In this paper we propose a new mechanism for Dynamic Rebinding, a particular kind of Dynamic Software Updating that focuses on modifying the workflow of a program. This mechanism is built upon the concurrency model of Concurrent Object Groups that is adopted in programming languages like Coboxes, Creol or ABS. Using this model, which extends and solves some of the limitations of Active Objects, it becomes possible for an update to wait for the program to reach a local quiescent state and then perform the update without creating any inconsistency in the program's state. We validate our mechanism by formally proving that i) no updates are performed when the program has not reached a local quiescent state, ii) an update is guaranteed to be applied if we first wait for the program to reach a local quiescent state, and iii) it is possible to perform different updates atomically. We also provide a type system that checks the good usage of the rebinding operator. We implemented a prototype supporting our mechanism in the toolchain of the ABS language, and we tested the implementation by supporting dynamic changes in the server policy of an industrial case study from the eCommerce Fredhopper platform, offered by SDL. Without our rebinding mechanism, supporting such dynamic changes in a provably correct manner would not have been so simple. Finally, we developed an implementation of type checking for the ABS language extended with our rebinding primitives, and successfully tested it for the case study discussed in the paper.","Object-oriented programming, Dynamic Software Updating, Consistency, Concurrency",,,,,,,,,,,,,,,,,,,,,
Journal Article,Lechner U,,Object-Oriented Specifications of Distributed Systems in the μ-Calculus and Maude,Electronic Notes in Theoretical Computer Science,1996,4,,385-404,,,,,1996,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104000489;http://dx.doi.org/10.1016/S1571-0661(04)00048-9,10.1016/S1571-0661(04)00048-9,"We refine an abstract property-oriented specification in the μ-calculus to a specification in Maude. As an intermediate step, we use a structured specification in the μ-calculus blended with propositions on states appropriate for object-oriented specification. We use the loose approach in refinement and refine data types as well as behavior. Throughout, our example is the bounded buffer.",,"RWLW96, First International Workshop on Rewriting Logic and its Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,Xu D,,A logic based language for networked agents,Information and Software Technology,1998,40,8,435-442,,,,,1998,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584998000615;http://dx.doi.org/10.1016/S0950-5849(98)00061-5,10.1016/S0950-5849(98)00061-5,"This paper presents a logic based language, SAFIN, for developing networked software agents. It integrates agent-oriented programming, KQML and basic mobile techniques to support intelligent behaviors, software interoperatablity and code transportability. As prototype based logic objects, agents are composed of network connections, knowledge bases (facts and beliefs), databases, behaviors, constraints, services, goals and KQML performatives. An approach to non-monotonic inheritance with both predicate level and clause level knowledge reuse is proposed and formally defined. Multi-level components and the interfaces to FTP services and relational database systems are also provided for developing specific distributed agents.","Software agents, KQML, Logic programming, Inheritance, Object-oriented programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,Durnota B,,Defining relationships in ecology using object-oriented formal specifications,Mathematical and Computer Modelling,1994,20,8,83-96,,,,,1994,,0895-7177,https://www.sciencedirect.com/science/article/pii/089571779490233X;http://dx.doi.org/10.1016/0895-7177(94)90233-X,10.1016/0895-7177(94)90233-X,"A formal object-oriented specification using Object-Z is given of an animal's environment which builds on previous work using formal descriptions in this area. The object framework provides a closer match between natural categories and specified classes, and the formal specification acts as a tool to explicitly state all assumptions, consequences and behaviors involved for a set of objects at hand. The object-oriented specification can then be used as a basis for building a corresponding software system using an object-oriented language.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bettini L,Capecchi S,Damiani F",,On flexible dynamic trait replacement for Java-like languages,Science of Computer Programming,2013,78,7,907-932,,,,,2013,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642312002092;http://dx.doi.org/10.1016/j.scico.2012.11.003,10.1016/j.scico.2012.11.003,"Dynamic trait replacement is a programming language feature for changing the objects’ behavior at runtime by replacing some of the objects’ methods. In previous work on dynamic trait replacement for Java-like languages, the objects’ methods that may be replaced must correspond exactly to a named trait used in the object’s class definition. In this paper we propose the notion of replaceable: a programming language feature that decouples the trait replacement operation code and the class declaration code, thus making it possible to refactor classes and to perform unanticipated trait replacement operations without invalidating existing code. We give a formal account of our proposal through a core calculus, FDTJ (Featherweight Dynamic Trait Java), equipped with a static type system guaranteeing that in a well-typed program no runtime type error will take place.","Featherweight Java, Trait, Type system","Special section on Formal Methods for Industrial Critical Systems (FMICS 2009 + FMICS 2010) & Special section on Object-Oriented Programming and Systems (OOPS 2009), a special track at the 24th ACM Symposium on Applied Computing",,,,,,,,,,,,,,,,,,,,
Journal Article,"Lu J,White DW,Chen WF,Dunsmore HE",,A matrix class library in C++ for structural engineering computing,Computers & Structures,1995,55,1,95-111,,,,,1995,,0045-7949,https://www.sciencedirect.com/science/article/pii/004579499400421X;http://dx.doi.org/10.1016/0045-7949(94)00421-X,10.1016/0045-7949(94)00421-X,"Matrix computations are traditionally performed using procedural languages such as FORTRAN. This paper describes the object-oriented design and implementation of a matrix class library in C++. A wide range of abstractions and algorithms such as symmetric matrices, profile matrices, banded matrices, column vectors, and LU decompositions are presented which address a variety of time/ space demands in structural engineering computing. The object-oriented design presented here applies encapsulation, inheritance, composition, and type parameterization. Consistent semantics and uniform syntax of the interface is a major focus of the design for the matrix class library. Careful design to take advantage of the type system of C++, a strongly typed object-oriented programming language, allows potential misuses of abstractions to be detected at compile time. The proposed object-oriented matrix library not only improves the clarity and expressiveness of the client code, but also enhances its reliability.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kanso B,Taha S",,Specification of temporal properties with OCL,Science of Computer Programming,2014,96,,527-551,,,,,2014,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642314000963;http://dx.doi.org/10.1016/j.scico.2014.02.029,10.1016/j.scico.2014.02.029,"The Object Constraint Language (OCL) is widely used to express static constraints on models and object-oriented systems. However, the notion of dynamic constraints, controlling the system behavior over time, has not been natively supported. Such dynamic constraints are necessary to handle temporal and real-time properties of systems. In this paper, we first add a temporal layer to the OCL language, based syntactically on Dwyer et al.'s specification patterns. We enrich it with formal scenario-based semantics and integrate it into the current Eclipse OCL plug-in. Second, we translate, with a compositional approach, OCL temporal properties into finite-state automata and we connect our framework to automatic test generators. This way, we create a bridge linking model driven engineering and usual formal methods.","OCL, Temporal patterns, Eclipse/MDT, Model-driven engineering, Formal methods",Selected Papers from the Fifth International Conference on Software Language Engineering (SLE 2012),,,,,,,,,,,,,,,,,,,,
Journal Article,"Iosif R,Sisto R",,Temporal logic properties of Java objects,Journal of Systems and Software,2003,68,3,243-251,,,,,2003,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121203000621;http://dx.doi.org/10.1016/S0164-1212(03)00062-1,10.1016/S0164-1212(03)00062-1,"Applying finite-state verification techniques to software systems looks attractive because they are capable of detecting very subtle defects in the logic design of these systems. Nevertheless, the integration of existing formal verification tools within programming environments is not yet easy, mainly because of the semantic gap between widely used programming languages and the languages used to describe system requirements. In this paper, we propose a formal requirement specification notation based on linear temporal logic, with regard to object oriented program elements, such as classes and interfaces. The specification is inherently object oriented and is meant for the verification of concurrent and distributed software systems.","Source code verification, Linear temporal logic, Object orientation, Java",Best papers on Software Engineering from the SEKE'01 Conference,,,,,,,,,,,,,,,,,,,,
Journal Article,Charatan Q,,MOOV++: modular object-oriented VDM,Information and Software Technology,2000,42,4,275-280,,,,,2000,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584999000646;http://dx.doi.org/10.1016/S0950-5849(99)00064-6,10.1016/S0950-5849(99)00064-6,"This paper describes MOOV++, a methodology for formal object-oriented development. MOOV++ takes as its starting point an object-oriented specification, which is subsequently developed by means of an existing and well-established formal method, the Vienna Development Method (VDM). MOOV++ utilises the VDM module notation to represent a class; the paper demonstrates how all the important concepts, which together define Object-Orientation can be captured formally in VDM. It also provides a proof obligation by which the behaviour of an inherited class can be proved to be consistent with its base class.","Object-oriented development, Formal methods, Vienna development method",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Grinchenkov DV,Mokhov VA,Spiridonova IA",,Object-oriented Approach to Design of the Complex Mechanical System Dynamics Mathematical Models,Procedia Engineering,2015,129,,356-361,,,,,2015,,1877-7058,https://www.sciencedirect.com/science/article/pii/S1877705815039624;http://dx.doi.org/10.1016/j.proeng.2015.12.078,10.1016/j.proeng.2015.12.078,"The article presents the results of an object-oriented approach applied to modeling the dynamics of complex mechanical systems when it is used in the educational process. The results of formalization the mathematical model design in the form of the second kind (conventional) Lagrange equations and the resulting Cauchy problem are considered. The article contains the authors’ presentation of the corresponding information flows diagram. The ways to use of object-oriented approach discussed in this article are proposed to be used in the educational process to establish interdisciplinary connections, as well as to create e-learning resources for students of applied mathematics, information technology and engineering profiles. The examples of the display forms for designed software used in the simulation of a transport vehicle mechanical system are presented.","Modeling, computer simulation, object-oriented approach, complex mechanical system, formal method, e-leaning",International Conference on Industrial Engineering (ICIE-2015),,,,,,,,,,,,,,,,,,,,
Journal Article,"Bonfè M,Fantuzzi C",,On the suitability of object-oriented models for industrial logic controllers,IFAC Proceedings Volumes,2004,37,18,291-296,,,,,2004,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017307619;http://dx.doi.org/10.1016/S1474-6670(17)30761-9,10.1016/S1474-6670(17)30761-9,"The paper presents a discussion on the practical issues of applying object-oriented modeling and formal verification techniques to the design of Manufacturing Systems logic controllers. In particular, the semantical aspects of specification languages like UML and Statecharts, which are widely used in many areas of Software Engineering, are analysed in terms of their adequacy for the industrial domain. Then, the paper presents the results of an application of these modeling languages to a practical case, showing that model checking techniques can also be adopted, given an adequate and domain-specific semantics of the object-oriented design model.","Manufacturing systems, Logic controllers, Discrete-event systems, Verification","7th International Workshop on Discrete Event Systems (WODES'04), Reims, France, September 22-24, 2004",,,,,,,,,,,,,,,,,,,,
Journal Article,"Heričko M,Rozman I,Živkovič A",,A formal representation of functional size measurement methods,Journal of Systems and Software,2006,79,9,1341-1358,,,,,2006,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121205001640;http://dx.doi.org/10.1016/j.jss.2005.11.568,10.1016/j.jss.2005.11.568,"Estimating software size is a difficult task that requires a methodological approach. Many different methods that exist today use distinct abstractions to depict a software system. The gap between abstractions becomes even greater with object-oriented artifacts developed in unified modeling language (UML). In this paper, a formal foundation for the representation of functional size measurement (FSM) methods is presented. The generalized abstraction of the software system (GASS) is then used to formalize different functional measurement methods, namely the FPA, MK II FPA and COSMIC-FFP. The same model is also used for object-oriented projects where UML artifacts are mapped into the GASS form. The algorithms in symbolic code for those UML diagrams that are crucial for size estimation are also given. The mappings defined in this paper enable diverse FSM methods to be supported in estimation tools, the automation of counting steps and a higher-level of independence from the FSM method, since the software abstraction is written in a generalized form. Both improvements are crucial for the practical use of FSM methods.","Function points, Software size, Formal model, Object-oriented projects",Selected papers from the fourth Source Code Analysis and Manipulation (SCAM 2004) Workshop,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jackson RB,Embley DW,Woodfield SN",,"Developing formal object-oriented requirements specifications: A model, tool and technique",Information Systems,1995,20,4,273-289,,,,,1995,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799500014U;http://dx.doi.org/10.1016/0306-4379(95)00014-U,10.1016/0306-4379(95)00014-U,"The creation of a requirements specification for systems development has always been a difficult problem and continues to be a problem in the object-oriented software development paradigm. The problem persists because there is a paucity of formal, object-oriented specification models that are seamlessly integrated into the development cycle and that are supported by automated tools. Here, we present a formal object-oriented specification model (OSS), which is an extension of an object-oriented analysis model (OSA), and which is supported by a tool (IPOST) that automatically generates a prototype from an OSA model instance, lets the user execute the prototype, and permits the user to refine the OSA model instance to generate a requirements specification. This technique leverages the benefits of a formal model, an object-oriented model, a seamless model, a graphical diagrammatic model, incremental development, and CASE tool support to facilitate the development of requirements specifications.","Requirements specification, rapid prototyping, specification model, model refinement",Sixth International Conference on Advanced Information Systems Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,Poll E,,A Coalgebraic Semantics of Subtyping,Electronic Notes in Theoretical Computer Science,2000,33,,276-293,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105803524;http://dx.doi.org/10.1016/S1571-0661(05)80352-4,10.1016/S1571-0661(05)80352-4,"Subtyping is a central notion in object-oriented programming. In this paper we investigate how the coalgebraic semantics of objects accounts for subtyping. We show that different characterisations of so-called behavioural subtyping found in the literature can conveniently be expressed in coalgebraic terms. We define subtyping between coalgebras and subtyping between coalgebraic specifications, and show that the latter is sound and complete w.r.t. the former. We also illustrate the subtle difference between the notions of subtyping and refinement.",,"CMCS'2000, Coalgebraic Methods in Computer Science",,,,,,,,,,,,,,,,,,,,
Journal Article,"De Nicola R,Latella D,Loreti M,Massink M",,MarCaSPiS: a Markovian Extension of a Calculus for Services,Electronic Notes in Theoretical Computer Science,2009,229,4,11-26,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610900293X;http://dx.doi.org/10.1016/j.entcs.2009.07.071,10.1016/j.entcs.2009.07.071,"Service Oriented Computing (SOC) is a design paradigm that has evolved from earlier paradigms including object-orientation and component-based software engineering. Important features of services are compositionality, context-independence, encapsulation and re-usability. To support the formal design and analysis of SOC applications recently a number of Service Oriented Calculi have been proposed. Most of them are based on process algebras enriched with primitives specific of service orientation such as operators for manipulating semi-structured data, mechanisms for describing safe client-service interactions, constructors for composing possibly unreliable services and techniques for services query and discovery. In this paper we show a versatile technique for the definition of Structural Operational Semantics of MarCaSPiS, a Markovian extension of one of such calculi, namely the Calculus of Sessions and Pipelines, CaSPiS. The semantics deals in an elegant way with a stochastic version of two-party synchronisation, typical of a service-oriented approach, and with the problem of transition multiplicity while preserving highly desirable mathematical properties such as associativity and commutativity of parallel composition. We also show how the proposed semantics can be naturally used for defining a bisimulation-based behavioural equivalence for MarCaSPiS terms that induces the same equalities as those obtained via Strong Markovian Equivalence.","Calculi for Service Oriented Computing, Quantitative Analysis of Systems, Stochastic Process Algebras",Proceedings of the Fifth Workshop on Structural Operational Semantics (SOS 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Bono V,Salvo I",,A CuCh Interpretation of an Object-Oriented Language1 1Partially supported by MURST Cofin '99 TOSCA,Electronic Notes in Theoretical Computer Science,2001,50,2,159-177,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104001719;http://dx.doi.org/10.1016/S1571-0661(04)00171-9,10.1016/S1571-0661(04)00171-9,"Böhm's CuCh machine extends the pure lambda-calculus with algebraic data types and provides the possibility of defining functions over disjoint sums of algebras. We exploit such natural form of overloading to define a functional interpretation of a simple, but significant fragment of a typical objectoriented classbased language.",,"BOTH 2001, Bohm's theorem: applications to Computer Science Theory (Satellite Workshop of ICALP 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,Ghelli G,,Foundations for Extensible Objects with Roles,Information and Computation,2002,175,1,50-75,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540101929438;http://dx.doi.org/10.1006/inco.2001.2943,10.1006/inco.2001.2943,"Object-oriented database systems are an emerging, promising technology, underpinned by the integration of ideas from object-oriented languages along with the specific needs of database applications. The fundamental reason for using such systems is that any real-world entity can be modeled by one object which matches its structure and behavior. To this end, the standard notion of object must be augmented so that it can model the fact that an entity may acquire new pieces of structure and behavior during its existence without changing its identity. To allow this extensibility in a statically typed system, a notion of context-dependent behavior (role playing) must be added to the basic features of object-oriented languages. This feature is also a useful modeling device. Languages with role mechanisms have already been proposed. However, their design is full of choices which cannot be easily justified. A strong foundation for the object-with-roles notion would be extremely helpful to justify these choices and to understand, and prove, the properties of such a mechanism. In this paper we describe such a foundation, building on the object model proposed by Abadi and Cardelli.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bruce KB,,Some Challenging Typing Issues in Object-Oriented Languages: Extended Abstract,Electronic Notes in Theoretical Computer Science,2003,82,8,1-29,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104807990;http://dx.doi.org/10.1016/S1571-0661(04)80799-0,10.1016/S1571-0661(04)80799-0,In this paper we discuss some of the remaining problems in the design of static type systems for object-oriented programming languages. We look at typing problems involved in writing a simple interpreter as a good example of a simple problem leading to difficult typing issues. The difficulties encountered seem to arise in situations where a programmer desires to simultaneously refine mutually interdependent classes and object types.,,"WOOD2003, Workshop on Object Oriented Developments (Satellite Event of ETAPS 2003)",,,,,,,,,,,,,,,,,,,,
Journal Article,Reza JR,,Java supervenience,"Computer Languages, Systems & Structures",2012,38,1,73-97,,,,,2012,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842411000182;http://dx.doi.org/10.1016/j.cl.2011.08.002,10.1016/j.cl.2011.08.002,"This paper reports on the development of a language construct designed to solve certain problems in composability at the level of object-oriented programming languages. Features were chosen to investigate how much compositional functionality could be added to core Java with as small a change as possible and in an additive manner. A fairly elegant and effective syntax on core Java resulted in reducing the clutter of the \mechanics\"" of composition. This construct features eliminating runtime cast and null exceptions within the construct",and the option of parametric covariant override. It does so while avoiding undesirable restrictions or new frameworks. Recently,new techniques intended to improve the composability of software components in the Java ecosystem have been vigorously pursued. Proposals take on the objectives of composition in largescale systems and enterprise applications but often implement on conventional object-oriented languages which face the same kinds of problems from the ground up. Benefitting from those experiences,the present work seeks to provide core Java-level solutions to problems that are analogous to those at the higher-levels. The supervenience construct described in this paper is based on a well-established formulation for composing a relationship over classes with some common behavioral elements,their behavioral intersection. The narrow concern of this construct is the sound composition of components across class families while eliminating certain barriers to runtime type-safety in core Java. The supervenience construct has been applied to certain classic problems and key case studies in composability and extensibility which represent fundamental issues that emerge at every level. The implementation requires no installed runtime frameworks and no changes to the JVM or type system of core Java. It is designed to deploy stand-alone or later integrate with the standard Java compiler and IDEs. The continuing research is now focusing on a more formal proof of its type-safety,"applying the reference implementation to mid-scale and distributed applications.""","Java, Supervenience, Covariant override, Accord relationship, Behavioral intersection, Polymorphic method, Subaltern, Synthetic variable, Type safety, Type system, Soundness barrier, Object-oriented",SMALLTALKS 2010,,,,,,,,,,,,,,,
Journal Article,"Bertino E,Catania B,Wong L",,Finitely representable nested relations,Information Processing Letters,1999,70,4,165-173,,,,,1999,,0020-0190,https://www.sciencedirect.com/science/article/pii/S0020019099000629;http://dx.doi.org/10.1016/S0020-0190(99)00062-9,10.1016/S0020-0190(99)00062-9,"Advanced temporal and spatial applications require both the representation of complex objects and the ability to finitely represent infinite relations. Representing such data requires combining the constraint relational model (allowing finite representation of infinite information) and either the nested relational or the object-oriented model (allowing representation of complex objects). In this paper, we extend the nested relational calculus to deal with finitely representable relations. The aim of the language we propose, called frNRC, is to provide the right formal foundations to analyze nested constraint query languages, overcoming some limitations of already existing languages. As an example of the theoretical foundations of frNRC, we show that it is effectively computable and has low data complexity. Moreover, frNRC queries are independent of the depth of set nesting in data generated by intermediate computations.","Databases, Nested relational calculus, Constraints",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dovland J,Johnsen EB,Owe O,Yu IC",,A proof system for adaptable class hierarchies,Journal of Logical and Algebraic Methods in Programming,2015,84,1,37-53,,,,,2015,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220814000595;http://dx.doi.org/10.1016/j.jlamp.2014.09.001,10.1016/j.jlamp.2014.09.001,"The code base of a software system undergoes changes during its life time. For object-oriented languages, classes are adapted, e.g., to meet new requirements, customize the software to specific user functionalities, or refactor the code to reduce its complexity. However, the adaptation of class hierarchies makes reasoning about program behavior challenging; even classes in the middle of a class hierarchy can be modified. This paper develops a proof system for analyzing the effect of operations to adapt classes, in the context of method overriding and late bound method calls. The proof system is incremental in the sense that reverification is avoided for methods that are not explicitly changed by adaptations. Furthermore, the possible adaptations are not unduly restricted; i.e., flexibility is retained without compromising on reasoning control. To achieve this balance, we extend the mechanism of lazy behavioral subtyping, originally proposed for reasoning about inheritance when subclasses are added to a class hierarchy, to deal with the more general situation of adaptable class hierarchies and changing specifications. The reasoning system distinguishes guaranteed method behavior from requirements toward methods, and achieves incremental reasoning by tracking guarantees and requirements in adaptable class hierarchies. We show soundness of the proposed proof system.","Software evolution, Object orientation, Verification, Proof systems, Class updates, Dynamic code modification","Special Issue: The 23rd Nordic Workshop on Programming Theory (NWPT 2011) Special Issue: Domains X, International workshop on Domain Theory and applications, Swansea, 5-7 September, 2011",,,,,,,,,,,,,,,,,,,,
Journal Article,"Schlatte R,Johnsen EB,Kazemeyni F,Tarifa SL",,Models of Rate Restricted Communication for Concurrent Objects,Electronic Notes in Theoretical Computer Science,2011,274,,67-81,,,,,2011,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066111000909;http://dx.doi.org/10.1016/j.entcs.2011.07.007,10.1016/j.entcs.2011.07.007,"Many software systems today are designed for deployment on a range of architectures. However, in formal models it is typically assumed that the architecture is known and fixed; for example, that the software is sequential or concurrent, that the communication environment is synchronous or asynchronous but ordered, etc. In order to specify and analyze models which range over different deployment scenarios, it is interesting to lift aspects of low-level deployment variability to the abstraction level of the modeling language. In this paper, we propose a technique for introducing explicit resource constraints on concurrent objects in a timed extension of Creol, a formally defined high-level object-oriented modeling language. The technique is demonstrated by examples concerning rate restrictions on communication between objects. These restrictions are compositional and non-invasive: no change to the functional parts of the model is required, and restrictions can be selectively applied to parts of the model. In fact, the rate restrictions are captured by parameters in the model, which allows timed simulations to be performed with varying rate restrictions. We demonstrate the usefulness of explicit rate restrictions on communication in the model by a case study of wireless sensor networks. In this domain, rate restrictions may be understood as an abstraction over the collision patterns of broadcast data packets. Simulation results with different rate restrictions show how the timed throughput of data to the sink node in the network varies depending on the available rates.","bandwidth modeling, simulation, object-oriented models, deployment scenarios",4th International Workshop on Harnessing Theories for Tool Support in Software (TTSS),,,,,,,,,,,,,,,,,,,,
Journal Article,"Middelkoop R,Huizing C,Kuiper R,Luit EJ",,Invariants for Non-Hierarchical Object Structures,Electronic Notes in Theoretical Computer Science,2008,195,,211-229,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108000200;http://dx.doi.org/10.1016/j.entcs.2007.08.034,10.1016/j.entcs.2007.08.034,"We present a Hoare-style specification and verification approach for invariants in sequential OO programs. It allows invariants over non-hierarchical object structures, in which update patterns that span several objects and methods occur frequently. This gives rise to invalidating and subsequent re-establishing of invariants in a way that compromises standard data induction, which assumes invariants hold when a method is called. We provide specification constructs (inc and coop) that identify objects and methods involved in such patterns, allowing a refined form of data induction. The approach now handles practical designs, as illustrated by a specification of the Observer Pattern.","Invariants, Formal specification, Program verification, Object-oriented programs",Proceedings of the Brazilian Symposium on Formal Methods (SBMF 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Opdahl AL,Henderson-Sellers B,Barbier F",,Ontological analysis of whole–part relationships in OO-models,Information and Software Technology,2001,43,6,387-399,,,,,2001,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584900001750;http://dx.doi.org/10.1016/S0950-5849(00)00175-0,10.1016/S0950-5849(00)00175-0,"Earlier semantic and formal analyses of whole–part (WP) relationships in object-oriented models have led to a framework, which distinguishes between primary, consequential, secondary and dependent characteristics of WP relationships. This paper interprets, validates and elaborates on that framework using an existing ontological theory and an associated formal model of objects. The revised framework confirms most of the original characteristics and suggests a number of additions and modifications. The analysis also grounds the characteristics in the framework and thereby suggests more precise definitions for some of them.","Object-oriented modelling, Whole–part, Part–whole, Aggregation, Ontological analysis and evaluation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Grandi F,Mandreoli F",,A formal model for temporal schema versioning in object-oriented databases,Data & Knowledge Engineering,2003,46,2,123-167,,,,,2003,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X02002070;http://dx.doi.org/10.1016/S0169-023X(02)00207-0,10.1016/S0169-023X(02)00207-0,"In this paper we present a formal model for the support of temporal schema versions in object-oriented databases. Its definition is partially based on a generic (ODMG compatible) object model and partially introduces new concepts. The proposed model supports all the schema changes which are usually considered in the OODB literature, for which an operational semantics and a formal analysis of their correct behaviour is provided. Semantic issues arising from the introduction of temporal schema versioning in a conventional or temporal database (concerning the interaction between the intensional and extensional levels of versioning and the management of data in the presence of multiple schema versions) are also considered.","Schema versioning, Schema evolution, Temporal versioning, Temporal database",,,,,,,,,,,,,,,,,,,,,
Journal Article,Walker D,,Objects in the π-Calculus,Information and Computation,1995,116,2,253-271,,,,,1995,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540185710188;http://dx.doi.org/10.1006/inco.1995.1018,10.1006/inco.1995.1018,Two semantics for a parallel object-oriented programming language are presented. One is a two-level transitional semantics in which the global behaviour of a system is derived directly from the possible actions of its constituent objects. The other is by translation into the π-calculus. A close correspondence between the semantics is established.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Owe O,Steffen M,Torjusen AB",,Model Testing Asynchronously Communicating Objects using Modulo AC Rewriting,Electronic Notes in Theoretical Computer Science,2010,264,3,69-84,,,,,2010,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066110001623;http://dx.doi.org/10.1016/j.entcs.2010.12.015,10.1016/j.entcs.2010.12.015,"Testing and verification of asynchronously communicating objects in open environments are challenging due to non-determinism. We explore a formal approach for black-box testing by proposing an interface specification language that gives an assumption-commitment style description of an object's behavior. The approach is applied to Creol objects. Creol is a high-level, object-oriented modelling language, hence we do model-based testing of behavioral models. The testing is done by synchronising execution of a specification and the component under test. Due to the asynchronous nature of communication, testing should be done up-to observational equivalence. This leads to a large increase in the reachable state space for the test cases. We reduce the state space by using facilities for rewriting modulo AC (associativity and commutativity) built into the rewriting logic system Maude, and explore the state space by breadth first search. We present experimental results that show the usefulness of this approach.","Testing and verification, asynchronous method calls, active objects, rewriting logic, formal semantics",Proceedings of the Sixth Workshop on Model-Based Testing (MBT 2010),,,,,,,,,,,,,,,,,,,,
Book Chapter,"Gonnet S,Leone H,Henning G","Barbosa-Póvoa A,Matos H",An integrated model for capturing the process design process,,2004,18,,415-420,,Elsevier,,European Symposium on Computer-Aided Process Engineering-14,2004,,1570-7946,https://www.sciencedirect.com/science/article/pii/S1570794604801354;http://dx.doi.org/10.1016/S1570-7946(04)80135-4,10.1016/S1570-7946(04)80135-4,"This paper presents an integrated deductive object-oriented model that, in relation to a design process, is able to capture (i) the activities, operations and actors that have generated each design product, (ii) the imposed requirements as well as (iii) the rationale behind each adopted decision. Furthermore, it also offers an explicit mechanism to manage the different model versions that have participated during the design process. Thus, the proposed model allows the tracing of such design process and its resulting products.","Design Process Support, Version Management, Situational Calculus, Object-Oriented Technology, Deductive Object Base",,Computer Aided Chemical Engineering,,,,,,,,,,,,,,,,,,,
Journal Article,Hagiya M,,Meta-circular interpreter for a strongly typed language,Journal of Symbolic Computation,1989,8,6,651-680,,,,,1989,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717189800665;http://dx.doi.org/10.1016/S0747-7171(89)80066-5,10.1016/S0747-7171(89)80066-5,"A functional language is introduced, whose type system is defined by its meta-circular interpreter. The functional language is an extension of λ-calculus augmented with the rule for conditional terms that allows the condition of a conditional term to be used for reducing its branches. This makes it possible to deduce the well-typing of terms with dependent types including the meta-circular interpreter. In the type system built by the interpreter, types are represented by ordinary terms, which reflects the recent object-oriented programming languages, in which classes are manipulated as ordinary objects. The paper first discusses the untyped system of the functional language and its consistency, then develops the representation of types and the representation of terms, and define a meta-circular interpreter, by which the well-typing of the language is defined and also discusses the extensibility of the interpreter and the type system.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ramalho F,Robin J,Schiel U",,Concurrent Transaction Frame Logic Formal Semantics for UML Activity and Class Diagrams,Electronic Notes in Theoretical Computer Science,2004,95,,83-109,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104050169;http://dx.doi.org/10.1016/j.entcs.2004.04.007,10.1016/j.entcs.2004.04.007,"We propose Concurrent Transaction Frame Logic (CTFL) as a language to provide formal semantics to UML activity and class diagrams. CTFL extends first-order Horn logic with object-oriented class hierarchy and object definition terms, and with five new logical connectives that declaratively capture temporal and concurrency constraints on updates and transactions. CTFL has coinciding, sound and refutation complete proof and model theories. CTFL allows using a single language to (1) formally describe the semantics of both activity and class diagrams, (2) verify UML models based on these two diagrams using theorem proving and (3) implement the model as an executable, object-oriented logic program.","UML Semantics, Object-Oriented Logic Programming, Concurrent Transaction Logic, Frame Logic",Proceedings of the Brazilian Workshop on Formal Methods,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wirsing M,Knapp A",,A Formal Approach to Object-Oriented Software Engineering,Electronic Notes in Theoretical Computer Science,1996,4,,322-360,,,,,1996,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104000465;http://dx.doi.org/10.1016/S1571-0661(04)00046-5,10.1016/S1571-0661(04)00046-5,"The goal of this paper is to show how formal specifications can be integrated into one of the current pragmatic object-oriented software development methods. Jacobson's method OOSE (“Object-Oriented Software-Engineering”) is combined with object-oriented algebraic specifications by extending object and interaction diagrams with formal annotations. The specifications are based on Meseguer's Rewriting Logic and are written in an extension of the language Maude by process expressions. As a result any such diagram can be associated with a formal specification, proof obligations ensuring invariant properties can be automatically generated, and the refinement relations between documents on different abstraction levels can be formally stated and proved. Finally, we provide a schematic translation of the specification to Java and thus an automatic generation of an object-oriented implementation.",,"RWLW96, First International Workshop on Rewriting Logic and its Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"H. Chang K,Liao SS,Seidman SB,Chapman R",,Testing object-oriented programs: from formal specification to test scenario generation,Journal of Systems and Software,1998,42,2,141-151,,,,,1998,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121298100055;http://dx.doi.org/10.1016/S0164-1212(98)10005-5,10.1016/S0164-1212(98)10005-5,"New problems associated with the testing and maintenance of object-oriented programs (OOPs) have been introduced with the dramatically increasing use of OOPs over the past decade. Testing OOPs beyond the class level has been rarely discussed. This paper presents an approach performing high level testing for OOPs based on formal specifications and usage profiles. The behavior of a software system is specified in an object-oriented formal specification. A state model provides a complementary representation of the dynamic behavior. In the model, a state represents the cumulative results of the system behavior. Probability distributions are used to derive the anticipated operation sequences of a program from the state model. An enhanced state transition diagram (ESTD) is used to describe the state model, which incorporates hierarchy, usage and parameter information. This paper describes the construction of state transition diagrams (STDs) based on the formal specification, and the derivation of test scenarios from the ESTD.","Formal methods, Software testing, Object-oriented programs, Software process models, Software validation and verification",,,,,,,,,,,,,,,,,,,,,
Journal Article,"da Silva Feitosa S,Ribeiro RG,Rauber Du Bois A",,Generating Random Well-Typed Featherweight Java Programs Using QuickCheck,Electronic Notes in Theoretical Computer Science,2019,342,,3-20,,,,,2019,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066119300027;http://dx.doi.org/10.1016/j.entcs.2019.04.002,10.1016/j.entcs.2019.04.002,"Currently, Java is one of the most used programming language, being adopted in many large projects, where applications reach a level of complexity for which manual testing and human inspection are not enough to guarantee quality in software development. Even when using automated unit tests, such tests rarely cover all interesting cases of code, which means that a bug could never be discovered, once the code is tested against the same set of rules over and over again. This paper addresses the problem of generating random well-typed programs in the context of Featherweight Java, a well-known object-oriented calculus, using QuickCheck, a Haskell library for property-based testing.","Random Program Generation, Property-Based Testing, Featherweight Java","The proceedings of CLEI 2018, the XLIV Latin American Computing Conference",,,,,,,,,,,,,,,,,,,,
Journal Article,"Davies J,Faitelson D,Welch J",,Domain-specific Semantics and Data Refinement of Object Models,Electronic Notes in Theoretical Computer Science,2008,195,,151-170,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108000170;http://dx.doi.org/10.1016/j.entcs.2007.08.031,10.1016/j.entcs.2007.08.031,"This paper shows how a domain-specific semantics for object models can be used to support the development of transformations that reflect a particular implementation strategy. The semantics captures model constraints and domain assumptions in terms of abstract data types, and a transformation is correct if and only if it corresponds to a data refinement. The transformations represent development steps, involving the completion of method descriptions, and validity checks, addressing issues of definedness and consistency. The paper shows how compositions of transformations may be used for the automatic generation of working systems from formal, object-oriented designs.","formal methods, object modelling, data refinement, automatic programming, model-driven development, Z notation",Proceedings of the Brazilian Symposium on Formal Methods (SBMF 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Diskin Z,Kadish B",,Variable set semantics for keyed generalized sketches: formal semantics for object identity and abstract syntax for conceptual modeling,Data & Knowledge Engineering,2003,47,1,1-59,,,,,2003,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X03000478;http://dx.doi.org/10.1016/S0169-023X(03)00047-8,10.1016/S0169-023X(03)00047-8,"We introduce a mathematical framework where a formal semantics for object identity can be built irrespectively to computer related things like object identifiers, memory allocations etc. Then, on this base, we build formal semantics for a few major constructs of conceptual modeling (CM) such as association, aggregation, generalization, isA- and isPartOf-relationships. We also give a formal meaning to the two fundamental dichotomies of CM: objects vs. values and entities vs. relationships. On the syntactical side, the language we use for specifying our formal semantic constructs is graph-based and brief: specifications are directed graphs consisting only of three kinds of items––nodes, arrows and marked diagrams. The latter are configurations of nodes and arrows closed in some technical sense and marked with predicate labels taken from a predefined signature. We show that this format does provide a universal abstract syntax for the entire CM-field. Then any particular CM-notation appears as a particular visualization superstructure (concrete syntax) over the same basic specification format as above.","Conceptual modeling, Object-oriented visual modeling, ER, UML, Object identity, Entity, Relationship, Association, Aggregation, Composition, Generalization, Formal semantics, Category theory, Variable set, Keyed sketch",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lagorio G,Servetto M,Zucca E",,Featherweight Jigsaw — Replacing inheritance by composition in Java-like languages,Information and Computation,2012,214,,86-111,,,,,2012,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540112000399;http://dx.doi.org/10.1016/j.ic.2012.02.004,10.1016/j.ic.2012.02.004,"We present FJig, a simple calculus where basic building blocks are classes in the style of Featherweight Java, declaring fields, methods and one constructor. However, inheritance has been generalized to the much more flexible notion originally proposed in Brachaʼs Jigsaw framework. That is, classes play also the role of modules, that can be composed by a rich set of operators, all of which can be expressed by a minimal core. Fields and methods can be declared of four different kinds (abstract, virtual, frozen, local) determining how they are affected by the operators. We keep the nominal approach of Java-like languages, that is, types are class names. However, a class is not necessarily a structural subtype of any class used in its defining expression. While this allows a more flexible reuse, it may prevent the (generalized) inheritance relation from being a subtyping relation. So, the required subtyping relations among classes are declared by the programmer and checked by the type system. The calculus allows the encoding of a large variety of different mechanisms for software composition in class-based languages, including standard inheritance, mixin classes, traits and hiding. Hence, FJig can be used as a unifying framework for analyzing existing mechanisms and proposing new extensions. We provide two different semantics of an FJig program: flattening and direct semantics. The difference is analogous to that between two intuitive models to understand inheritance: the former where inherited methods are copied into heir classes, and the latter where member lookup is performed by ascending the inheritance chain. Here we address equivalence of these two views for a more sophisticated composition mechanism.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Greiner S,Brest J,Žumer V",,Zero—a blend of static typing and dynamic metaprogramming,"Computer Languages, Systems & Structures",2009,35,3,241-251,,,,,2009,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842408000146;http://dx.doi.org/10.1016/j.cl.2008.04.001,10.1016/j.cl.2008.04.001,"Zero is an experimental statically typed, fully object-oriented reflective programming language. Reflective features cover introspection as well as structural and behavioural reflection. The reflective facilities include safe method and class replacements and detailed modification of methods. These enable Zero programs to quickly accommodate to run-time requirements. Behavioural reflection is realised using handlers (hooks), which may be attached to all language constructs based on closures. Zero provides an efficient static typing system with run-time extensions. Methods are first class values and are represented as objects when such representation is required. By using such representation, Zero provides elegant use of statically typed higher-order methods.","Language design, Object-oriented programming, Structural reflection, Behavioural reflection, Static typing, Run-time modification",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Briand LC,Labiche Y,He S",,Automating regression test selection based on UML designs,Information and Software Technology,2009,51,1,16-30,,,,,2009,,0950-5849,https://www.sciencedirect.com/science/article/pii/S095058490800133X;http://dx.doi.org/10.1016/j.infsof.2008.09.010,10.1016/j.infsof.2008.09.010,"This paper presents a methodology and tool to support test selection from regression test suites based on change analysis in object-oriented designs. We assume that designs are represented using the Unified Modeling Language (UML) 2.0 and we propose a formal mapping between design changes and a classification of regression test cases into three categories: Reusable, Retestable, and Obsolete. We provide evidence of the feasibility of the methodology and its usefulness by using our prototype tool on an industrial case study and two student projects.","Regression testing, Test selection, Object-oriented software engineering, UML",Special Section - Most Cited Articles in 2002 and Regular Research Papers,,,,,,,,,,,,,,,,,,,,
Journal Article,"Le DM,Dang DH,Nguyen VH",,Generative software module development for domain-driven design with annotation-based domain specific language,Information and Software Technology,2020,120,,106239,,,,,2020,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584919302563;http://dx.doi.org/10.1016/j.infsof.2019.106239,10.1016/j.infsof.2019.106239,"Context Object-oriented domain-driven design (DDD) aims to iteratively develop software around a realistic model of the application domain, which both thoroughly captures the domain requirements and is technically feasible for implementation. The main focus of recent work in DDD has been on using a form of annotation-based domain specific language (aDSL), internal to an object-oriented programming language, to build the domain model. However, these work do not consider software modules as first-class objects and thus lack a method for their development. Objective In this paper, we tackle software module development with the DDD method by adopting a generative approach that uses aDSL. To achieve this, we first extend a previous work on module-based software architecture with three enhancements that make it amenable to generative development. We then treat module configurations as first-class objects and define an aDSL, named MCCL, to express module configuration classes. To improve productivity, we define function MCCGen to automatically generate each configuration class from the module’s domain class. Method We define our method as a refinement of an aDSL-based software development method from a previous work. We apply meta-modelling with UML/OCL to define MCCL and implement MCCL in a Java software framework. We evaluate the applicability of our method using a case study and formally define an evaluation framework for module generativity. We also analyse the correctness and performance of function MCCGen. Results MCCL is an aDSL for module configurations. Our evaluation shows MCCL is applicable to complex problem domains. Further, the MCCs and software modules can be generated with a high and quantifiable degree of automation. Conclusion Our method bridges an important gap in DDD with a software module development method that uses a novel aDSL with a module-based software architecture and a generative technique for module configuration.","Domain-driven design (DDD), Module-based architecture, UML-based domain modelling, Domain-specific language (DSL), Object-oriented programming language (OOPL), Attribute-oriented programming (AtOP)",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Henrio L,Kammüller F,Lutz B",,ASPfun : A typed functional active object calculus,Science of Computer Programming,2012,77,7,823-847,,,,,2012,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642311000037;http://dx.doi.org/10.1016/j.scico.2010.12.008,10.1016/j.scico.2010.12.008,"This paper provides a sound foundation for autonomous objects communicating by remote method invocations and futures. As a distributed extension of ς-calculus we define ASPfun, a calculus of functional objects, behaving autonomously and communicating by a request-reply mechanism: requests are method calls handled asynchronously and futures represent awaited results for requests. This results in an object language enabling a concise representation of a set of active objects interacting by asynchronous method invocations. This paper first presents the ASPfun calculus and its semantics. Then, we provide a type system for ASPfun which guarantees the “progress” property. Most importantly, ASPfun has been formalised; its properties have been formalised and proved using the Isabelle theorem prover and we consider this as an important step in the formalization of distributed languages. This work was also an opportunity to study different binder representations and experiment with two of them in the Isabelle/HOL theorem prover.","Theorem proving, Object calculus, Futures, Distribution, Typing, Binders",(1) FOCLASA’09 (2) FSEN’09,,,,,,,,,,,,,,,,,,,,
Journal Article,"Altaf A,Abbas H,Iqbal F,Khan FA,Rubab S,Derhab A",,Context-oriented trust computation model for industrial Internet of Things,Computers & Electrical Engineering,2021,92,,107123,,,,,2021,,0045-7906,https://www.sciencedirect.com/science/article/pii/S0045790621001270;http://dx.doi.org/10.1016/j.compeleceng.2021.107123,10.1016/j.compeleceng.2021.107123,"The Industrial Internet of Things (IIoT) has revolutionized the industrial sector by providing advanced and intelligent applications. The objects and nodes communicate with one another to collect, exchange, and analyze a large amount of sensing data using techno-social systems, thereby challenging the security and trustworthiness of the data. To achieve effective communication in IIoT, trustworthy relationships must be established among these objects. This makes trust an important security parameter in an IoT-based environment to achieve secure and reliable service communication at the edge nodes. In this paper, we propose an adaptive Context-Based Trust Evaluation System (CTES), which calculates distributed trust at the node level to achieve edge intelligence. Each edge node takes recommendations from its context-similar nodes to calculate the trust of serving nodes. This collaborative trust calculation mechanism helps in filtering out malicious nodes in the network. The weighing factor “μ” is dynamically assigned based on the previously calculated trust score experienced by the edge node. This research also focuses on formal verification of the proposed CTES model. We analyze the efficiency of CTES in terms of accuracy, dynamic assignment of μ, and resiliency against Ballot Stuffing and Bad Mouthing attacks to avoid malicious nodes. The results ensure the significance of the proposed CTES model for dynamic assignment of μ and provide satisfactory results against EigenTrust, ServiceTrust, and ServiceTrust++ in terms of detecting malicious nodes and isolating them from providing recommendations.","IoT, Trust, Direct observation, Recommendation, Malicious, Ballot Stuffing, Bad Mouthing, Edge intelligence",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lievens D,Harrison W",,Abstraction over implementation structure with symmetrically encapsulated multimethods,Science of Computer Programming,2013,78,7,953-968,,,,,2013,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642312002225;http://dx.doi.org/10.1016/j.scico.2012.12.007,10.1016/j.scico.2012.12.007,"In object-oriented languages, methods are encapsulated, hence module interfaces are made up of sets of methods partitioned along the objects or classes that make up the module. This prevents abstraction over the implementation structure of applications. Any change in method placement may cause a global effect that ripples through all clients depending on that method. Sometimes this unduly restricts the scope of software evolution, particularly for methods with multiple parameters where there is no clear owner. We investigate a simple scheme where methods may be defined in the classes of any of their parameters. This allows client code to be oblivious to choice of method placement, and therefore immune against it changing. When combined with multiple dispatch, this scheme allows for modular extensibility, where methods defined in one class may be overloaded by methods defined in classes that are not its subclasses. We detail our proposal by extending a core calculus of class-based object-oriented languages with these symmetrically encapsulated multimethods, and prove the result sound. It is well-known that multiple dispatch is at odds with modular type-checking. We also discuss different strategies that can be followed to mitigate the type-checking problem and propose variants of the original calculus that are amenable to modular checking.","Object-orientation, Encapsulated multimethods, Modular type-checking","Special section on Formal Methods for Industrial Critical Systems (FMICS 2009 + FMICS 2010) & Special section on Object-Oriented Programming and Systems (OOPS 2009), a special track at the 24th ACM Symposium on Applied Computing",,,,,,,,,,,,,,,,,,,,
Journal Article,"Depke R,Heckel R,Küster JM",,Formal agent-oriented modeling with UML and graph transformation,Science of Computer Programming,2002,44,2,229-252,,,,,2002,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642302000400;http://dx.doi.org/10.1016/S0167-6423(02)00040-0,10.1016/S0167-6423(02)00040-0,"The agent paradigm can be seen as an extension of the notion of (active) objects by concepts like autonomy and cooperation. Mainstream object-oriented modeling techniques do not account for these agent-specific aspects. Therefore, dedicated techniques for agent-oriented modeling are required which are based on the concepts and notations of object-oriented modeling and extend these in order to support agent-specific concepts. In this paper, an agent-oriented modeling technique is introduced which is based on UML notation. Graph transformation is used both on the level of modeling in order to capture agent-specific aspects and as the underlying formal semantics of the approach. Concepts of the concurrency theory of graph transformation systems following the double-pushout approach are exploited in order to formalize the relation between global requirements specification by means of sequence diagrams, and implementation-oriented design models where graph transformation rules specify the agents’ local operations.","Agent-oriented modeling, UML, Formal semantics",Special Issue on Applications of Graph Transformations (GRATRA 2000),,,,,,,,,,,,,,,,,,,,
Journal Article,"Bubel R,Hähnle R",,Integration of Informal and Formal Development of Object-Oriented Safety-Critical Software: A Case Study with the KeY System,Electronic Notes in Theoretical Computer Science,2003,80,,1-23,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104808065;http://dx.doi.org/10.1016/S1571-0661(04)80806-5,10.1016/S1571-0661(04)80806-5,The KeY system allows integrated informal and formal development of object oriented Java software. In this paper we report on a major industrial case study involving safety-critical software for computation of a particular kind of railway time table used by train drivers. Our case study includes formal specification of requirements on the analysis and the implementation level. Particular emphasis in our research is put on the challenge of how authoring and maintenance of formal specifications can be made easier. We demonstrate that the technique of specification patterns implemented in KeY for the language OCL yields significant improvements.,,Eighth International Workshop on Formal Methods for Industrial Critical Systems (FMICS'03),,,,,,,,,,,,,,,,,,,,
Journal Article,"Najafi M,Haghighi H",,An approach to animate Object-Z specifications using C++,Scientia Iranica,2012,19,6,1699-1721,,,,,2012,,1026-3098,https://www.sciencedirect.com/science/article/pii/S1026309812001423;http://dx.doi.org/10.1016/j.scient.2012.06.021,10.1016/j.scient.2012.06.021,"Object-Z is an extension of the Z notation which facilitates specification of large, complex software by defining a system as a collection of independent classes. A number of contributions have been made so far to map Object-Z to various object-oriented languages. However, the given mapping approaches do not cover several Object-Z specification constructs, such as class union, object aggregation, object containment and some of the operation operators. Also, in much of the existing work, mapping rules are given in a very abstract form. In other words, they do not consider all cases in a detailed way needed to automate the mapping procedure. In our previous work, we partially tackled these issues; however, in this paper, we present a much more comprehensive way to animate Object-Z specifications using C++. The given method covers some constructs that have not been addressed in our previous work. Also, mapping rules are described with enough details facilitating automation. Finally, we consider some level of user interaction in our new method which increases the flexibility and efficiency of final codes from the user point of view.","Formal program development, Object-oriented programming, Animation, Object-Z, C++",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Atkinson M,DeWitt D,Maier D,Bancilhon F,Dittrich K,Zdonik S","Kim W,Nicolas JM,Nishio S",The Object-Oriented Database System Manifesto,,1990,,,223-240,,North-Holland,Amsterdam,Deductive and Object-Oriented Databases,1990,9780444884336,,https://www.sciencedirect.com/science/article/pii/B9780444884336500204;http://dx.doi.org/10.1016/B978-0-444-88433-6.50020-4,10.1016/B978-0-444-88433-6.50020-4,"This paper attempts to define an object-oriented database system. It describes the main features and characteristics that a system must have to qualify as an object-oriented database system. We have separated these characteristics into three groups: •Mandatory, the ones the system must satisfy in order to be termed an object-oriented database system. These are complex objects, object identity, encapsulation, types or classes, inheritance, overriding combined with late binding, extensibility, computational completeness, persistence, secondary storage management, concurrency, recovery and an ad hoc query facility.•Optional, the ones that can be added to make the system better, but which are not mandatory. These are multiple inheritance, type checking and inferencing, distribution, design transactions and versions.•Open, the points where the designer can make a number of choices. These are the programming paradigm, the representation system, the type system, and uniformity. We have taken a position, not so much expecting it to be the final word as to erect a provisional landmark to orient further debate.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bruce KB,Cardelli L,Pierce BC",,Comparing Object Encodings,Information and Computation,1999,155,1,108-133,,,,,1999,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540199928298;http://dx.doi.org/10.1006/inco.1999.2829,10.1006/inco.1999.2829,"Recent years have seen the development of several foundational models for statically typed object-oriented programming. But despite their intuitive similarity, differences in the technical machinery used to formulate the various proposals have made them difficult to compare. Using the typed lambda-calculus Fω<: as a common basis, we now offer a detailed comparison of four models: (1) a recursive-record encoding similar to the ones used by Cardelli, Reddy, Cook, and others; (2) Hofmann, Pierce, and Turner's existential encoding; (3) Bruce's model based on existential and recursive types; and (4) Abadi, Cardelli, and Viswanathan's type-theoretic encoding of a calculus of primitive objects.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bonniot D,,Using kinds to type partially-polymorphic methods,Electronic Notes in Theoretical Computer Science,2003,75,,21-40,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104807771;http://dx.doi.org/10.1016/S1571-0661(04)80777-1,10.1016/S1571-0661(04)80777-1,"We extend type constraints with kind constraints to increase the expressiveness of constraint-based nominal type systems. In the context of object-oriented programming languages, they offer an alternative to the use of F-bounded polymorphism to type homogeneous binary methods. We also introduce the notion of partially polymorphic methods to describe a common situation in object-oriented hierarchies, and show how these can be typed in a modular fashion with kind constraints.",,"TIP'02, International Workshop in Types in Programming",,,,,,,,,,,,,,,,,,,,
Journal Article,"Ridgway J,Wileden JC",,Reasoning About Multi-Lingual Exception Handling Using RIPLS,Electronic Notes in Theoretical Computer Science,2008,212,,177-189,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108002764;http://dx.doi.org/10.1016/j.entcs.2008.04.061,10.1016/j.entcs.2008.04.061,"Building multi-lingual software is a practical necessity. At present, with object-oriented programming the dominant paradigm, it is common to assemble software systems comprising components written in at least two different object-oriented languages. Modern object-oriented languages provide exception handling mechanisms as a means of enriching the signatures of methods with a specification of what to do if the method “fails”, i.e., cannot carry out its intended (normal) function for some reason. Indeed, Java and C++ (and many other object-oriented languages, including C#) have remarkably similar exception handling mechanisms. As we demonstrate, however, those exception handling mechanisms do not necessarily interoperate smoothly when used in multi-lingual software systems. We believe that our long-term goal of maximally effortless and error-free multi-lingual programming requires automated tools that are based on solid formal foundations. Toward that end, we have developed a formal language, which we call RIPLS, that can be used to rigorously study properties of multi-lingual software. In this paper, we demonstrate RIPLS and our approach by using it to study exception handling in multilingual object-oriented systems, and show how use of our methods can identify problems that standard techniques cannot. We then exhibit a correctly-working version of multi-lingual exception-handling and use our methods to confirm its correctness. Finally we discuss how experience with these RIPLS-based methods has informed our designs for automated tools that will implement correctly-working multi-lingual exception handling. This work makes a significant contribution by demonstrating that formal, theoretical foundations can be used to solve practical problems in multi-lingual software development.","Exception Handling, Formal Methods and Software, Multi-lingual Programming","Proceedings of the First International Conference on Foundations of Informatics, Computing and Software (FICS 2008)",,,,,,,,,,,,,,,,,,,,
Journal Article,Kung DC,,An executable visual formalism for object-oriented conceptual modeling,Journal of Systems and Software,1995,31,1,33-43,,,,,1995,,0164-1212,https://www.sciencedirect.com/science/article/pii/0164121294000852;http://dx.doi.org/10.1016/0164-1212(94)00085-2,10.1016/0164-1212(94)00085-2,"Conceptual modeling aims at establishing the conceptual knowledge necessary for proper communication between a development team and users. This article presents an executable visual formalism for object-oriented modeling of information systems. This formalism is an integration of the entity-relationship approach, Petri nets, relational calculus, and time temporal logic. It supports integrated and encapsulated modeling of the structural and behavioral aspects of objects, and object evolution. The formalism has textual and graphical representations, allows formal analysis of model properties, and supports rapid prototyping. An environment and a methodology for conceptual modeling also are described.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Idani A,Ledru Y",,Object Oriented Concepts Identification from Formal B Specifications,Electronic Notes in Theoretical Computer Science,2005,133,,159-174,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105050292;http://dx.doi.org/10.1016/j.entcs.2004.08.063,10.1016/j.entcs.2004.08.063,"This paper addresses the graphical representation of static aspects of B specifications, using UML class diagrams. These diagrams can help understand the specification for stakeholders who are not familiar with the B method, such as customers or certification authorities. The paper first discusses some rules for a preliminary derivation of a class diagram. It then studies the consistency of the concepts preliminarily identified from an object oriented point of view. A formal concept analysis technique is used to distinguish between consistent classes, attributes, associations and operations. The proposed technique is to incrementally add operations to the formal specification which automatically result in evolution of the class diagram.","B, UML, integrated methods",Proceedings of the Ninth International Workshop on Formal Methods for Industrial Critical Systems (FMICS 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Analyti A,Constantopoulos P,Spyratos N",,Specialization by restriction and schema derivations,Information Systems,1998,23,1,1-38,,,,,1998,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437998000015;http://dx.doi.org/10.1016/S0306-4379(98)00001-5,10.1016/S0306-4379(98)00001-5,"Specialization and inheritance are well-known concepts in the area of object-oriented modelling and knowledge representation. However, certain aspects of these concepts lack formal foundations. In particular, when properties of different classes are semantically related, several different semantics are possible for the inherited properties, and a choice is necessary. Conventional systems impose an a priori solution that supports only one of the possible semantics of inheritance. In this paper, we present constructs that allow to differentiate between the possible semantics of inheritance, in a formal and sound way. Our approach is based on a structured view of the real world and a model for its representation. By necessity, the model only partly represents the real world. Thus, reasoning in the model is done with reference to the real world. We introduce restriction isa, a form of specialization that represents property restriction, and demonstrate that it can be a useful conceptual modelling mechanism. We employ restriction isa to formally define property inheritance. Reasoning in our model is done through a number of inference rules that reflect real world constraints. These rules allow for sound derivations both at the instance and schema levels. At the schema level, in particular, these rules allow us to relate inherited properties to other properties through restriction-isa and isa relations. Such relations not only give useful information about the inherited properties but also refine the values of these properties.","Property Inheritance, Semantics, Inference Rules, Schema Derivations, Conceptual Modelling, Object-Oriented Modelling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Carreira PJ,Costa ME",,Automatically verifying an object-oriented specification of the Steam-Boiler system,Science of Computer Programming,2003,46,3,197-217,,,,,2003,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642302000928;http://dx.doi.org/10.1016/S0167-6423(02)00092-8,10.1016/S0167-6423(02)00092-8,"Correctness is a desired property of industrial software systems. Although the employment of formal methods and their verification techniques in embedded real-time systems has started to be a common practice, the same cannot be said about object-oriented software. This paper presents an experiment of a technique for the automated verification of a subset of the object-oriented language OBject LOGic (OBLOG). In our setting, object-oriented models are automatically translated to LOTOS specifications using a programmable rule-based engine included in the Development Environment of the OBLOG language. The resulting specifications are then verified by model-checking using the CADP tool-box. To illustrate the concept we develop and verify an object-oriented specification of a well-known case study—the Steam-Boiler Control System.","Automatic verification, Code generation, LOTOS, Model-checking, Object-oriented systems, Steam-boiler",Special issue on Formal Methods for Industrial Critical Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Golas U,Lambers L,Ehrig H,Orejas F",,Attributed graph transformation with inheritance: Efficient conflict detection and local confluence analysis using abstract critical pairs,Theoretical Computer Science,2012,424,,46-68,,,,,2012,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397512000680;http://dx.doi.org/10.1016/j.tcs.2012.01.032,10.1016/j.tcs.2012.01.032,"Inheritance is an important and widely spread concept enabling the elegant expression of hierarchy in object-oriented software programs or models. It has been defined for graphs and graph transformations enhancing the applicability of this formal technique. Up to now, for the analysis of transformations with inheritance a flattening construction has been used, which yields all the well-known results for graph transformation but results in a large number of graphs and rules that have to be analyzed. In this paper, we introduce a new category of typed attributed graphs with inheritance. For the detection of conflicts between graph transformations on these graphs, the notion of abstract critical pairs is defined. This allows us to perform the analysis on polymorphic rules and transformations without the need for flattening, which significantly increases the efficiency of the analysis and eases the interpretation of the analysis results. The new main result is the Local Confluence Theorem for typed attributed graph transformation with inheritance using abstract critical pairs. All constructions and results are demonstrated on an example for the analysis of refactorings.","Typed attributed graph transformation, Critical pair analysis, Inheritance, -adhesive category with NACs",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Massoni T,Gheyi R,Borba P",,A Framework for Establishing Formal Conformance between Object Models and Object-Oriented Programs,Electronic Notes in Theoretical Computer Science,2008,195,,189-209,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108000194;http://dx.doi.org/10.1016/j.entcs.2007.08.033,10.1016/j.entcs.2007.08.033,"Conformance between structural models and their implementations are usually simplified in practice, restraining reasoning to simple mappings between modeling and implementation constructs. This is not appropriate to accommodate the usual freedom of implementation for abstract concepts. A more flexible conformance notion must be addressed by conformance checking tools and model-driven development. In this paper, we propose a formal framework for defining conformance relationships between structural object models and object-oriented programs. In our framework, a syntactic mapping between model and program elements must be provided, yielding a coupling relation, used in framework instantiations for specific conformance relationships. Additionally, as in practice some intermediate program states are not relevant to conformance, we include the notion of heaps of interest, encompassing the filtered stable states for a less strict conformance checking. The framework is applied for establishing a conformance relationship in a technique of model-driven refactoring of programs.","Object Model, Semantics, Conformance",Proceedings of the Brazilian Symposium on Formal Methods (SBMF 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Cavarra A,Crichton C,Davies J",,A method for the automatic generation of test suites from object models,Information and Software Technology,2004,46,5,309-314,,,,,2004,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584903001940;http://dx.doi.org/10.1016/j.infsof.2003.09.004,10.1016/j.infsof.2003.09.004,"This paper shows how object-oriented specifications, written in the Unified Modeling Language (UML) can be translated into formal, behavioural descriptions and used as a basis for automatic test generation. The behavioural descriptions are written in a language of communicating state machines: the Intermediate Format (IF). The translation from UML to IF is based upon an earlier formal semantics, written in the Abstract State Machine (ASM) notation. Descriptions written in IF can be automatically explored; the results of these explorations are test trees, ready for input to a variety of testing packages.","Unified modeling language (UML), Formal semantics, Testing, Object modelling","Special Issue on Software Engineering, Applications, Practices and Tools from the ACM Symposium on Applied Computing 2003",,,,,,,,,,,,,,,,,,,,
Journal Article,"Buchlovsky P,Thielecke H",,A Type-theoretic Reconstruction of the Visitor Pattern,Electronic Notes in Theoretical Computer Science,2006,155,,309-329,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106001988;http://dx.doi.org/10.1016/j.entcs.2005.11.061,10.1016/j.entcs.2005.11.061,"In object-oriented languages, the Visitor pattern can be used to traverse tree-like data structures: a visitor object contains some operations, and the data structure objects allow themselves to be traversed by accepting visitors. In the polymorphic lambda calculus (System F), tree-like data structures can be encoded as polymorphic higher-order functions. In this paper, we reconstruct the Visitor pattern from the polymorphic encoding by way of generics in Java. We sketch how the quantified types in the polymorphic encoding can guide reasoning about visitors in general.","Visitor pattern, polymorphic types, object-oriented programming, Generic Java",Proceedings of the 21st Annual Conference on Mathematical Foundations of Programming Semantics (MFPS XXI),,,,,,,,,,,,,,,,,,,,
Journal Article,Mili H,,On behavioral descriptions in object-oriented modeling,Journal of Systems and Software,1996,34,2,105-121,,,,,1996,,0164-1212,https://www.sciencedirect.com/science/article/pii/0164121295000690;http://dx.doi.org/10.1016/0164-1212(95)00069-0,10.1016/0164-1212(95)00069-0,"In the past decade, object-oriented programming has come to be considered a panacea for all computing headaches. We view object orientation as a modeling paradigm, first and foremost. We attempt to provide a formal characterization of objects' behaviors as a step toward the formal analysis and validation of object-oriented systems. In particular, we address the following questions: (1) what should be the scope of objects' behavior? (2) what are the desirable functional properties of behaviors? and (3) what implicit and explicit behavioral composition paradigms need to be supported by an object-oriented model? Unfortunately, but expectedly, the answers to these questions rely on some formal proofs, but also on common sense and general software engineering principles. In particular, we argue that all that an object-oriented model needs to support for behavioral specifications are (1) purely functional behaviors, with no side-effects on the objects implementing them; (2) purely side-effectal behaviors, whose effects are restricted to the implementer and its components; and (3) constraints (between objects). An object-oriented model based on these principles has proven valuable for predicting the behavioral properties of object-oriented systems. The model is briefly discussed.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kifer M,Wu J",,A logic for programming with complex objects,Journal of Computer and System Sciences,1993,47,1,77-120,,,,,1993,,0022-0000,https://www.sciencedirect.com/science/article/pii/002200009390021N;http://dx.doi.org/10.1016/0022-0000(93)90021-N,10.1016/0022-0000(93)90021-N,"We present a logic for reasoning with complex objects, which is a repaired and significantly extended version of Maier's O-logic [43]. The logic naturally supports complex objects, object identity, and deduction, and has several other interesting features. It elegantly combines object-oriented and value-oriented paradigms and, in particular, contains all of predicate calculus as a special case. The revised O-logic has a sound and complete resolution-based proof procedure.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Foster S,Baxter J,Cavalcanti A,Woodcock J,Zeyda F",,Unifying semantic foundations for automated verification tools in Isabelle/UTP,Science of Computer Programming,2020,197,,102510,,,,,2020,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642320301192;http://dx.doi.org/10.1016/j.scico.2020.102510,10.1016/j.scico.2020.102510,"The growing complexity and diversity of models used for engineering dependable systems implies that a variety of formal methods, across differing abstractions, paradigms, and presentations, must be integrated. Such an integration requires unified semantic foundations for the various notations, and co-ordination of a variety of automated verification tools. The contribution of this paper is Isabelle/UTP, an implementation of Hoare and He's Unifying Theories of Programming, a framework for unification of formal semantics. Isabelle/UTP permits the mechanisation of computational theories for diverse paradigms, and their use in constructing formalised semantics. These can be further applied in the development of verification tools, harnessing Isabelle's proof automation facilities. Several layers of mathematical foundations are developed, including lenses to model variables and state spaces as algebraic objects, alphabetised predicates and relations to model programs, algebraic and axiomatic semantics, proof tools for Hoare logic and refinement calculus, and UTP theories to encode computational paradigms.","Theorem proving, Lenses, Unifying theories of programming, Hoare logic, Isabelle/HOL",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Lano K,Goldsack S","Zedan H,Cau A",2 - Design Patterns and their Role in Formal Object-oriented Development,,1999,,,17-34,,Woodhead Publishing,,Object-Oriented Technology and Computing Systems Re-engineering,1999,9781898563563,,https://www.sciencedirect.com/science/article/pii/B9781898563563500067;http://dx.doi.org/10.1533/9781782420613.17,10.1533/9781782420613.17,"This paper describes how object-oriented design patterns can be used within a formal development process, and how the structure of formal requirements specifications, as expressed in their invariant properties, may serve to suggest suitable patterns to be used in their design and implementation. An example of a simple real-time system is used to illustrate the approach.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hofmann M,Pierce BC",,Positive Subtyping,Information and Computation,1996,126,1,11-33,,,,,1996,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540196900310;http://dx.doi.org/10.1006/inco.1996.0031,10.1006/inco.1996.0031,"The statementS⩽Tin aλ-calculus with subtyping is traditionally interpreted by a semantic coercion function of type [[S]]→[lsqb;T]] that extracts the “Tpart” of an element ofS. If the subtyping relation is restricted to covariant positions, this interpretation may be enriched to include both the implicit coercion and an overwriting functionput[S, T]∈[[S]]→[[T]]→[[S]] that updates theTpart of an element ofS. We give a realizability model and a sound equational theory for a second-order calculus of positive subtyping. Though weaker than familiar calculi of bounded quantification, positive subtyping retains 1?sufficient power to model objects, encapsulation, and message passing, and inheritance. The equational laws relating the behavior of coercions andputfunctions can be used to prove simple properties of the resulting ?classes in such a way that proofs for superclasses are “inherited” by subclasses.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Murphy J,Grimson J",,Formal specification of a persistent object management system,Information and Software Technology,1993,35,5,277-286,,,,,1993,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584993900617;http://dx.doi.org/10.1016/0950-5849(93)90061-7,10.1016/0950-5849(93)90061-7,The goal of the research on which the paper is based was to specify formally a persistent object management system and to implement a part of the specification in the form of a prototype. The prototype is called the persistent object storage manager (POSM). The prototype was implemented in C++ using the IBM OS/2 operating system. POSM is formally specified in the paper. The data model used in POSM is rigorously defined using the Z notation. The operations of POSM and its state space are also specified in Z notation. Example schemas for the operations of the node management component of the prototype are presented. Z notation is justified in the paper and the benefits of using Z in the research are discussed.,"object management, object-oriented database systems, formal techniques, Z notation, mathematics in software design",,,,,,,,,,,,,,,,,,,,,
Journal Article,Shao Z,,Invited Talk: Towards a Principled Multi-Language Infrastructure,Electronic Notes in Theoretical Computer Science,2001,59,1,2,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105804499;http://dx.doi.org/10.1016/S1571-0661(05)80449-9,10.1016/S1571-0661(05)80449-9,"Sun's Java architecture introduced a safe virtual machine (VM) in which an ensemble of software components developed independently could smoothly interoperate. The goal of Microsoft's Common Language Runtime (CLR) is to generalize this approach and allow components in many source languages to interoperate safely. CLR supports flexible interoperation by compiling various source languages into a common intermediate language and by using a unified type system. However, the type system in CLR (and Java VM) enforces only conventional type safety in an object-oriented system. Therefore, higher-level specifications (e.g., resource bounds, generalized access control, formal software protocols) cannot be enforced. Because conventional type systems are too inflexible for real applications, developers often bypass the type system, producing code that steps outside the managed part of the VM; such components cannot be verified. At Yale we have been developing typed common intermediate languages (named FLINT) that can support safely not only the standard object-oriented model, but also higher-order generic (polymorphic) programming and Java-style reflection (introspection). Unlike CLR, our type system is independent of any particular programming model, yet it is capable of expressing all valid propositions and proofs in higher-order predicate logic (so it can be used to capture and verify advanced program properties). The rich type system of FLINT makes it possible to typecheck both compiler intermediate code and low level machine code; this allows typechecking to take place at any phase of compilation, even after optimizations and register allocation. It also leads to a smaller and more extensible VM because low-level native routines that would otherwise be in VM can now be verified and moved into a certified library. This talk describes our vision of the FLINT system, outline our approach to its design, and survey the technologies that can be brought to support its implementation.",,"BABEL'01, First International Workshop on Multi-Language Infrastructure and Interoperability (Satellite Event of PLI 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,Robert G,,Aspects of Decision Making,IFAC Proceedings Volumes,2001,34,21,105-108,,,,,2001,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017330288;http://dx.doi.org/10.1016/S1474-6670(17)33028-8,10.1016/S1474-6670(17)33028-8,Attributes of efficient decision-making processes for complex systems considering human beings are outlined. The decision-making process is taken in account as a prerequisite that suitable measures are started for the solution of problems. The impact of new technology for knowledge management and learning is stressed. Object oriented modelling and visual presentations are pointed out.,"Decision making, committee, complex systems, knowledge representation, learning, object-oriented, formal methods, visual","8th IFAC Conference on Social Stability: The Challenge of Technology Development (SWIIS '01), Vienna, Austria, 27-29 September 2001",,,,,,,,,,,,,,,,,,,,
Journal Article,"Kovács G,van Bommel P",,Conceptual modelling-based design of object-oriented databases,Information and Software Technology,1998,40,1,1-14,,,,,1998,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584998000226;http://dx.doi.org/10.1016/S0950-5849(98)00022-6,10.1016/S0950-5849(98)00022-6,"The focus of this article is the transformation of conceptual data models (such as ER, NIAM and PSM) to object-oriented databases. This transformation is captured within the framework of a two-level architecture. Conceptual models are first mapped to abstract intermediate specifications, which are then transformed to database schemas in a given object-oriented database environment. This enables us to treat different target systems in a uniform way. As final implementation environments, we consider object-oriented as well as object-relational DBMSs, including the SQL3 and ODMG-93 standards. We do not reveal the specific details of these standards. Rather, we use intermediate representations expressed in F-logic, a logic-based abstract specification language for object-oriented systems. Several transformation alternatives are discussed in a formal context, resulting in a collection of design options.","Database design, Conceptual data models, Object-oriented databases",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhao X,Liu C,Lin T",,Incorporating business logics into RFID-enabled applications,Information Processing & Management,2012,48,1,47-62,,,,,2012,,0306-4573,https://www.sciencedirect.com/science/article/pii/S0306457311000227;http://dx.doi.org/10.1016/j.ipm.2011.02.004,10.1016/j.ipm.2011.02.004,"Radio Frequency Identification (RFID) technology promises many benefits to business process automation with real-time context awareness and item level accuracy. Through readers to RFID middleware systems, the information and the movements of tagged objects can be used to trigger business transactions. With the aim to seamlessly incorporate RFID technology into business process automation, this paper investigates the deployment of business logics to RFID edge systems. A comprehensive framework is proposed to model business rules in an event-driven perspective on the basis of event calculus. This framework first elicits the business meaningful events from the large volume of raw RFID reads, and guides the behaviours and interactions of involved objects in response to the elicited events and the pre-defined business rules. The execution and functional invocations are enforced with RFID queries, where a two-block buffering mechanism is proposed to handle the identified delayed effects and thereby improve the RFID query efficiency. Experiments and analysis are conducted to discuss the query efficiency improvements and the scalability to more complex applications.","RFID event handling, Business process modelling and business transaction automation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shah A,Mathkour H",,Transforming an Imperative Design into an Object-Oriented Design,Journal of King Saud University - Computer and Information Sciences,2000,12,,1-44,,,,,2000,,1319-1578,https://www.sciencedirect.com/science/article/pii/S1319157800800014;http://dx.doi.org/10.1016/S1319-1578(00)80001-4,10.1016/S1319-1578(00)80001-4,"Most of the traditional and legacy systems were designed using traditional methodologies such as Structured Analysis/Structured Design (SA/SD) methodology. Design of such a system is called an imperative design. After the introduction of the object-oriented technology, there are compelling reasons to redevelop those systems using this new technology to benefit from its merits. To redevelop them, there are two possible choices: either develop them from scratch using some object-oriented methodology, or use the available design documents (i.e., imperative design) of those systems and transform their designs into object-oriented designs. The second choice clearly results in saving both the development cost and time. This paper reports on an effort to build support for the second choice mentioned above. We started our effort in 1992 and proposed a framework of a redesign methodology. Our proposed redesign methodology, i.e., imperative design to object-oriented design (ID-OOD), transforms a given imperative design of an already implemented system into an object-oriented design using the design documents of the system. The methodology works in four phases and they are presented formally. We also illustrate the methodology with a case study.","Object-oriented design, Imperative design, ID-OOD methodology, Entity relationship, Data flow diagram, Redesign methodology",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Glykas M,Valiris G",,Formal methods in object oriented business modelling,Journal of Systems and Software,1999,48,1,27-41,,,,,1999,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121299000436;http://dx.doi.org/10.1016/S0164-1212(99)00043-6,10.1016/S0164-1212(99)00043-6,"Most of BPR methodologies lack the formal underpining to ensure the logical consistency of their business models. Agent Relationship Morphism Analysis (ARMA) is a BPR methodology in which modelling of the business environment is achieved with the use of three perspectives: the structural, behavioural and process. A technique called Agent Relationship Modeling (ARM) has been developed for modelling the structural perspective. The more dynamic organizational concepts are described in the behavioural and process perspectives. These perspectives are modeled in a technique called Agent/Object Lifecycles (ALCs/OLCs). In this paper we present the application of ARMA in a petrochemical industry. The conceptual part of ARMA allowed us to articulate our ideas by creating an informal model of the situation. Then a formal model was developed that enforced rigour to the modelling exercise introducing the concept of business rules in agent and object classes. Finally, we present the verification of the ARM and ALC/OLC models in order to secure that the resulting formal models are logically consistent.","Formal methods, Business modelling, Verification, Implementation, Process redesign",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Płodzień J,Kraken A",,Object query optimization through detecting independent subqueries,Information Systems,2000,25,8,467-490,,,,,2000,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437900000314;http://dx.doi.org/10.1016/S0306-4379(00)00031-4,10.1016/S0306-4379(00)00031-4,"The problem of query optimization in object-oriented databases is addressed. We follow the Stack-Based Approach to query languages, which employs the naming-scoping-binding paradigm of programming languages rather than traditional database concepts such as relational/object algebras or calculi. The classical environment stack is a semantic basis for definitions of object query operators, such as selection, projection/navigation, dependent join, and quantifiers. We describe a general object data model and define a formalized OQL-like query language SBQL. Optimization by rewriting concerns queries containing so-called independent subqueries. It consists in detecting them and then factoring outside loops implied by query operators. The idea is based on the formal static analysis of scoping rules and binding names occurring in a query. It is more general than the classical pushing selections/projections before joins.","Object-Oriented Databases, Query Languages, Stack-Based Approach, Query Optimization, Rewriting Rules, Independent Subqueries",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gheyi R,Borba P",,Refactoring Alloy Specifications,Electronic Notes in Theoretical Computer Science,2004,95,,227-243,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104050236;http://dx.doi.org/10.1016/j.entcs.2004.04.014,10.1016/j.entcs.2004.04.014,"This paper proposes modeling laws for Alloy, a formal object-oriented modeling language. These laws are important not only to define the axiomatic semantics of Alloy but also to guide and formalize popular software development practices. In particular, these laws can be used to formaly refactor specifications. As an example, we formally refactor a specification for Java types.","Formal Methods, Model Transformations, Refactoring, Model Checking",Proceedings of the Brazilian Workshop on Formal Methods,,,,,,,,,,,,,,,,,,,,
Book Chapter,Rudkin S,"Parker KR,Rose GA",Inheritance in LOTOS,,1992,,,409-424,,Elsevier,Amsterdam,"Formal Description Techniques, IV",1992,9780444894021,,https://www.sciencedirect.com/science/article/pii/B9780444894021500370;http://dx.doi.org/10.1016/B978-0-444-89402-1.50037-0,10.1016/B978-0-444-89402-1.50037-0,"Inheritance is a powerful technique, supporting reusability of specifications and/or implementations. However the formal description technique LOTOS was designed before object oriented techniques became widely accepted, and so does not provide explicit support for the concept. This paper examines the extent to which the existing facilities of LOTOS can be used to achieve the desired effect.",,,IFIP Transactions C: Communication Systems,,,,,,,,,,,,,,,,,,,
Journal Article,"Rodríguez L,Ogata H,Yano Y",,A temporal versioned object-oriented data schema model,Computers & Mathematics with Applications,2001,41,1,177-192,,,,,2001,,0898-1221,https://www.sciencedirect.com/science/article/pii/S089812210185015X;http://dx.doi.org/10.1016/S0898-1221(01)85015-X,10.1016/S0898-1221(01)85015-X,"This paper describes in a formal way a data schema model which introduces temporal and versioning schema features in an object-oriented environment. In our model, the schema is time dependent and the history of the changes which occur on its elements are kept into version hierarchies. A fundamental assumption behind our approach is that a new schema specification should not define a new database, so that previous schema definitions are considered as alternative design specifications, and consequently, existing data can be accessed in a consistent way using any of the defined schemas.","Object-oriented databases, Temporal databases, Schema versioning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Xu WL,Kuhnert L,Foster K,Bronlund J,Potgieter J,Diegel O",,Object-oriented knowledge representation and discovery of human chewing behaviours,Engineering Applications of Artificial Intelligence,2007,20,7,1000-1012,,,,,2007,,0952-1976,https://www.sciencedirect.com/science/article/pii/S0952197606002272;http://dx.doi.org/10.1016/j.engappai.2006.12.006,10.1016/j.engappai.2006.12.006,"Mastication is a complex process influenced by numerous factors including those associated with an individual and the ingested food. Human chewing behaviour can be characterised by measuring mandibular movements and muscular activities during a masticatory sequence or by measuring the particle size distribution and rheological characteristics of the swallowed food mass. To constructively understand the mastication process and assess the mastication performance, a formal description of the chewing behaviour is proposed in this paper. An object-oriented model is developed and described in Unified Modelling Language (UML). The chewing behaviour model is composed of three objects, one for the jaw's physiological apparatus, one for the properties defining the mastication process and foods being chewed, and a further one for the association of the properties. A complete representation of the chewing behaviour is achieved by linking three object models via an additional class for chewing data that is collected experimentally. With the object model, the chewing behaviour is further instantiated by discovering knowledge hidden in the chewing database by data mining. A case study is presented to show the procedure of how the hidden knowledge is discovered and the data mining results are interpreted in the context of food science.","Chewing behaviour, Food properties, Mastication, Object-oriented model, Knowledge-based system, Data mining, Knowledge discovery",,,,,,,,,,,,,,,,,,,,,
Journal Article,Wieringa R,,Steps towards a method for the formal modeling of dynamic objects,Data & Knowledge Engineering,1991,6,6,509-540,,,,,1991,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9190026T;http://dx.doi.org/10.1016/0169-023X(91)90026-T,10.1016/0169-023X(91)90026-T,"Fragments of a method to formally specify object-oriented models of a universe of discourse are presented. The task of finding such models is divided into three subtasks, object classification, event specification, and the specification of the life cycle of an object. Each of these subtasks is further subdivided, and for each of the subtasks heuristics are given that can aid the analyst in deciding how to represent a particular aspect of the real world. The main sources of inspiration are Jackson System Development, algebraic specification of data- and object types, and algebraic specification of processes.","Formal specification, object-oriented modeling methods",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Walraet B,Walraet B,CHAPTER 11 - Object-oriented Programming,,1991,,,471-484,,North-Holland,Amsterdam,A Discipline of Software Engineering,1991,9780444891310,,https://www.sciencedirect.com/science/article/pii/B9780444891310500231;http://dx.doi.org/10.1016/B978-0-444-89131-0.50023-1,10.1016/B978-0-444-89131-0.50023-1,"Publisher Summary This chapter presents the formal ideas behind object-oriented programming. Properties that are received from the class and can be valued by the particular object are instance variables. This receiving of slots to be valued is called “inheritance of variables.― Slots that are already valued in the class are also inherited by the object instance, but cannot be changed. Such slots are instance constants. Circles have a perimeter and a surface that need to be computed. The computation template is attached for perimeter and surface to the circle class. The terminology is that the class comprises methods and like properties, the methods are inherited by all instances of the class. The way to execute a method is by sending a message to the object concerned, informing it that it has to apply a method to itself. An important aspect in object-oriented programming is that the data structure of an object is not visible outside the object. Therefore, no external actor can access any of an object's properties. If modification of a slot is needed, this can be achieved by a method provided by the object itself.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chemaa S,Bachtarzi F,Chaoui A",,A High-level Petri Net Based Approach for Modeling and Composition of Web Services,Procedia Computer Science,2012,9,,469-478,,,,,2012,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050912001718;http://dx.doi.org/10.1016/j.procs.2012.04.050,10.1016/j.procs.2012.04.050,"Web services are modular, self-describing, self-contained and loosely coupled applications, which intercommuni-cate via messages exchanging. The evolution of the internet and the emergence of new technologies like e-business have influenced the use of these last ones, which have become popular. The composition of web services is a topic that attracts the interest of researchers. It offers complex problems process ability even with simple existing web services while cooperating with each other. However, modeling tools and formal techniques for the completion of this task are required.In this paper, we show how simple existing web services can be composed, in order to create a composite service, which offers new features. In this context, we propose an expressive object-oriented Petri net based algebra that succeeds in the complex composition of Web services.","web services, web services composition, algebra, e-business, object-oriented Petri net","Proceedings of the International Conference on Computational Science, ICCS 2012",,,,,,,,,,,,,,,,,,,,
Journal Article,"Gheyi R,Massoni T,Borba P",,An Abstract Equivalence Notion for Object Models,Electronic Notes in Theoretical Computer Science,2005,130,,3-21,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105002124;http://dx.doi.org/10.1016/j.entcs.2005.03.002,10.1016/j.entcs.2005.03.002,"Equivalence notions for object models are usually too concrete in the sense that they assume that the compared models are formed by elements with the same names. This is not adequate in several situations: during model refactoring, when using auxiliary model elements, or when the compared models comprise distinct but corresponding elements. So, in this paper, we propose a more abstract and language-independent equivalence notion for object models. It supports, as desired, abstraction from names and elements when comparing models. We use the PVS system to specify and prove properties of our notion. It is illustrated here by comparing simple models in Alloy, a formal object-oriented modeling language, but has also been applied for deriving a comprehensive set of algebraic laws for Alloy.","equivalence notion, theorem proving, object models",Proceedings of the Brazilian Symposium on Formal Methods (SBMF 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Capuchino AM,Juristo N,Van de Riet RP",,Formal justification in object-oriented modelling: A linguistic approach,Data & Knowledge Engineering,2000,33,1,25-47,,,,,2000,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X99000464;http://dx.doi.org/10.1016/S0169-023X(99)00046-4,10.1016/S0169-023X(99)00046-4,"When software engineers set out to build a system, they usually have the informal idea that there is a relation between the linguistic world and the conceptual world. In this paper, we present a formalisation of this empirical relation, defining an intermediate mapping of the components of the linguistic and conceptual worlds to their mathematical representations. This process outputs a justified correspondence between natural language, used as a means of communication between users and software engineers, and conceptual models, employed by software engineers as a first step towards building a system. In other words, our aim is to show how the equivalence of the linguistic and conceptual representations of a requirement can be established in a formal and justified manner.","Object-oriented conceptual models, Natural language analysis, Object-oriented analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chan JT,Yang W",,An attribute-grammar framework for specifying the accessibility in Java programs,"Computer Languages, Systems & Structures",2002,28,2,203-235,,,,,2002,,1477-8424,https://www.sciencedirect.com/science/article/pii/S0096055101000212;http://dx.doi.org/10.1016/S0096-0551(01)00021-2,10.1016/S0096-0551(01)00021-2,"The three access modifiers—public, protected, and private—control the accessibility of the members of a type in the Java programming language. Furthermore, the accessibility may be transmitted along the two structures—package structure and inheritance structure. It is difficult to identify the weaknesses of the access modifiers from the informal semantics stated in the language manual. We develop a formal framework for specifying the accessibility in Java programs based on attribute grammars. With the help of this framework, we found several situations in the language specification that are irregular or counter-intuitive or ambiguous. These situations may confuse the programmers and hence may create weaknesses in Java programs.","Access modifiers, Attribute grammars, Java, Object-oriented programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fernandes AA,Barja ML,Paton NW,Williams MH",,The formalisation of ROCK & ROLL: A deductive object-oriented database system,Information and Software Technology,1997,39,6,379-389,,,,,1997,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584996000079;http://dx.doi.org/10.1016/S0950-5849(96)00007-9,10.1016/S0950-5849(96)00007-9,"This paper describes the formalisation of the deductive object-oriented database system ROCK & ROLL. This is a system which integrates the deductive and object-oriented paradigms in a way that is both clean and consistent, and that has a sound theoretical foundation. The system uses a formally defined object-oriented data model as a foundation for both a logic query language and an imperative data manipulation language in such a way that impedance mismatches are minimised. This paper introduces the facilities offered by ROCK & ROLL, and indicates how their formalisation has been achieved.","Deductive databases, Logic programming, Object-oriented databases, Programming language semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wleringa R,Dubois E",,Integrating semi-formal and formal software specification techniques,Information Systems,1998,23,3,159-178,,,,,1998,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437998000076;http://dx.doi.org/10.1016/S0306-4379(98)00007-6,10.1016/S0306-4379(98)00007-6,"In this paper, we report on the integration of informal, semiformal and formal system specification techniques. We present a framework for system specification called TRADE, within which several well-known semiformal specification techniques are placed. TRADE is based on an analysis of structured and object-oriented requirements specification methods. In this paper, we combine TRADE with the logic-based specification language Albert II and show that this leads to a coherent formal and semiformal requirements specification. We illustrate our approach with examples taken from a large distributed telecommunication application case study, performed in the context of the Esprit project 2RARE.","Object-Oriented Specification, Formal Specification, Method Integration",Advance information systems engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hartel P,Denker G,Kowsari M,Krone M,Ehrich HD",,Information systems modelling with troll formal methods at work,Information Systems,1997,22,2,79-99,,,,,1997,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437997000069;http://dx.doi.org/10.1016/S0306-4379(97)00006-9,10.1016/S0306-4379(97)00006-9,In this paper we present a national project located in the area of computer aided testing and certifying (CATC) of physical devices. The objective of this project is to develop an information system that supports the various activities of different user groups in a German federal institute of weights and measures. We decided to use formal methods right from the beginning of the project. Our approach is based on the formal object oriented specification language troll. Starting point of the development is an abstract model of the organization which will serve later on as a formal basis for implementation. We present parts of this specification and its relations with the underlying formal semantics. The experiences we made so far are rather positive and we expect further positive effects in the future.,"Object Oriented Specification, Case Study, Information System, Information Modelling, Requirements Engineering, Formal Method",Eighth international conference on advanced information systems engineering (CAiSE '96),,,,,,,,,,,,,,,,,,,,
Journal Article,"Gilmore S,Shkaravska O",,Estimating the Cost of Native Method Calls for Resource-bounded Functional Programming Languages,Electronic Notes in Theoretical Computer Science,2006,151,3,27-45,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106003574;http://dx.doi.org/10.1016/j.entcs.2006.03.010,10.1016/j.entcs.2006.03.010,We address the problem of applying resource-bounded functional programming languages in practice on object-oriented virtual machines which include calls to native methods coded in low-level languages without garbage collection support. We consider the application of a functional language with a high-level type system which incorporates measures of heap space consumption in types on such an execution platform. We supplement the syntactic type inference procedure of the functional language with a separate analysis which estimates the costs of memory leaks incurred by calls to garbage collection-ignorant functions.,"Resource-bounded functional programming languages, native method calls, object-oriented virtual machine",Proceedings of the Second International Workshop on the Practical Application of Stochastic Modeling (PASM 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"de Carvalho SE,de O. Cruz S,de Oliveirae TC",,Second Generation Object-Oriented Development,Electronic Notes in Theoretical Computer Science,1998,14,,94-106,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105802324;http://dx.doi.org/10.1016/S1571-0661(05)80232-4,10.1016/S1571-0661(05)80232-4,"Well-integrated development tools, allowing automatic code generation from visual representations of analysis and design decisions, are important assets in handling the complexities of todays software. This paper describes a few features of a method independent, object-oriented development tool, essentially consisting of a users plane, where visual system construction takes place, a formal plane, where user actions are verified, and underlying platforms, providing user-formal mappings. The paper concentrates on the users plane, addressing aspects of static and dynamic system views.",,US-Brazil Joint Workshops on the Formal Foundations of Software Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sveda M,Vrba R",,AN APPROACH TO THE DESIGN OF NETWORKED EMBEDDED SYSTEMS,IFAC Proceedings Volumes,2005,38,1,20-25,,,,,2005,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016371944;http://dx.doi.org/10.3182/20050703-6-CZ-1902.01182,10.3182/20050703-6-CZ-1902.01182,"The paper presents an approach to formal specification, verification and prototyping of network applications ranging from large information systems down to small components embedded e.g. in mobile devices. Main attention focuses both on architectural and behavioral specifications of either reactive or real-time activities utilizing either structured or object-oriented approach depending on application requirements. This contribution discusses in more detail executable specifications and rapid prototyping for structured design and structural specifications and verifications for object-oriented design. The paper presents two original tools developed for that purpose: (i) Asynchronous Specification Language and (ii) Class Specification Language.","embedded systems, design systems, formal specification, computer communication networks, sensor systems",16th IFAC World Congress,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Simon L,Marshall LS","Parker KR,Rose GA",Using VDM to Specify OSI Managed Objects,,1992,,,17-31,,Elsevier,Amsterdam,"Formal Description Techniques, IV",1992,9780444894021,,https://www.sciencedirect.com/science/article/pii/B9780444894021500114;http://dx.doi.org/10.1016/B978-0-444-89402-1.50011-4,10.1016/B978-0-444-89402-1.50011-4,"Protocol standards must be defined in a precise, unambiguous and concise manner as they serve as the basis for implementation and testing of compatible systems. It is this need which has resulted in the development within the International Organization for Standardization (ISO) of two formal description techniques (FDTs), viz. LOTOS and Estelle. These FDTs have been applied to the formal specification of a number of Open Systems Interconnection (OSI) communication protocol standards. The formal specification of OSI network management protocols presents a number of interesting challenges as the structure and semantics of the information to be communicated across an interoperable interface is modelled as managed objects. The challenge arises in integrating existing formal techniques into the specific object-oriented framework developed by the ISO management standards. The ISO management standards currently provide notational tools for describing the syntactical aspects of OSI managed objects. The choice of a particular specification language(s) for defining the behaviour of managed objects has been left open, although in practice only English has so far been used. This paper examines the suitability of VDM as a candidate specification technique for use in formally specifying the behaviour of OSI managed objects. It builds on some earlier work reported elsewhere proposing a semi-formal technique for describing the behaviour of managed objects based on pre-conditions and post-conditions written in English. To investigate the suitability of VDM to incorporate object-oriented concepts such as inheritance, we take as a case study a simplified Discriminator managed object class, described in English within the ISO management standards.",,,IFIP Transactions C: Communication Systems,,,,,,,,,,,,,,,,,,,
Journal Article,"Cadavid JJ,Combemale B,Baudry B",,An analysis of metamodeling practices for MOF and OCL,"Computer Languages, Systems & Structures",2015,41,,42-65,,,,,2015,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842415000068;http://dx.doi.org/10.1016/j.cl.2015.02.002,10.1016/j.cl.2015.02.002,"The definition of a metamodel that precisely captures domain knowledge for effective know-how capitalization is a challenging task. A major obstacle for domain experts who want to build a metamodel is that they must master two radically different languages: an object-oriented, MOF-compliant, modeling language to capture the domain structure and first order logic (the Object Constraint Language) for the definition of well-formedness rules. However, there are no guidelines to assist the conjunct usage of both paradigms, and few tools support it. Consequently, we observe that most metamodels have only an object-oriented domain structure, leading to inaccurate metamodels. In this paper, we perform the first empirical study, which analyzes the current state of practice in metamodels that actually use logical expressions to constrain the structure. We analyze 33 metamodels including 995 rules coming from industry, academia and the Object Management Group, to understand how metamodelers articulate both languages. We implement a set of metrics in the OCLMetrics tool to evaluate the complexity of both parts, as well as the coupling between both. We observe that all metamodels tend to have a small, core subset of concepts, which are constrained by most of the rules, in general the rules are loosely coupled to the structure and we identify the set of OCL constructs actually used in rules.","Metamodeling, MOF, OCL",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liu X,Walker D",,Partial confluence of processes and systems of objects,Theoretical Computer Science,1998,206,1,127-162,,,,,1998,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397597001114;http://dx.doi.org/10.1016/S0304-3975(97)00111-4,10.1016/S0304-3975(97)00111-4,"A process calculus extending the π-calculus with higher-order agent abstractions as in the Higher-Order π-calculus and first-order data other than names but with only first-order interaction is used to give a natural and direct semantic definition for a concurrent object-oriented programming language. A notion of partial confluence of agents is introduced and its theory developed, first in the setting of CCS and then in the mobile-process calculus. It is shown how the semantic definition can be used as a basis for reasoning about systems prescribed by programs of the language: the theory of partial confluence is used to prove the indistinguishability in an arbitrary program context of two classes whose instances combine to form data structures only one of which supports concurrent operations.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Duchier D,Kuttler C",,Biomolecular Agents as Multi-behavioural Concurrent Objects,Electronic Notes in Theoretical Computer Science,2006,150,1,31-49,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106000983;http://dx.doi.org/10.1016/j.entcs.2005.12.022,10.1016/j.entcs.2005.12.022,"In recent years, there has been increasing interest in computational models of biological systems based on various calculi of communicating processes, such as the stochastic pi-calculus. These models make it possible to simulate and eventually visualize the dynamic evolution of complex biosystems in time and under varying environmental conditions. While the elegance of the pi-calculus lies in its minimality, this is also a drawback when it comes to modeling because much effort must be devoted to encoding high-level ideas into the low-level means that the language affords us. In this paper, we describe an on-going effort to design a new higher-level programming language that provides direct ontological support for the concepts which are used to formulate, organize and structure models of biomolecular systems. Our language has an object-oriented flavour where we view molecular components as agents with finite sets of behaviours (states). Reactions are modeled as exchanges over connected ports that may cause agents to switch states.","biological systems, stochastic pi-calculus, communicating agents, systems biology, simulation, programming","Proceedings of the First International Workshop on Methods and Tools for Coordinating Concurrent, Distributed and Mobile Systems (MTCoord 2005)",,,,,,,,,,,,,,,,,,,,
Book Chapter,Lipovski GJ,Lipovski GJ,Chapter 8 - Programming in C and C++,,2004,,,239-273,Second Edition,Academic Press,Burlington,Introduction to Microcontrollers (Second Edition),2004,9780124518384,,https://www.sciencedirect.com/science/article/pii/B9780124518384500121;http://dx.doi.org/10.1016/B978-012451838-4/50012-1,10.1016/B978-012451838-4/50012-1,"Publisher Summary A C program has one or more procedures of which the first to be executed is called main, and the others are “subroutines” or “functions” if they return a value. An important feature of C is its ability to describe variables and the addresses of variables. If “a” is a variable, then “&a” is the address of “a.” The chapter also discusses object-oriented programming in C++. This concept was developed to program symbolic processes, database storage and retrieval systems, and user-friendly graphic interfaces. Programmers using C wanted to use object-oriented techniques. Standard C cannot be used, but a derivative of C, called C++, has been developed to utilize objects with a syntax similar to that of C. C++ has a few differences from C. C++ permits declarations inside expressions. Parameters can be passed by name using a PASCAL like convention; “&” in front of a formal parameter is like VAR. An object's data are data members, and its procedures are function members; data and function members are encapsulated together in an object. Object-oriented programming has very useful features for designing the state of the art microcomputer's I/O device software.",,,Academic Press Series in Engineering,,,,,,,,,,,,,,,,,,,
Journal Article,"Dar S,Gehani NH,Jagadish HV,Srinivasan J",,Queries in an Object-Oriented Graphical Interface,Journal of Visual Languages & Computing,1995,6,1,27-52,,,,,1995,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X85710038;http://dx.doi.org/10.1006/jvlc.1995.1003,10.1006/jvlc.1995.1003,"The graphical user interface OdeView for the Ode object-oriented database system allows users to perform complex operations against sets of objects. These include selection, projection, display, creation, deletion and update of objects, and the invocation of member functions (methods). OdeView utilizes type information for displaying objects and the relationships between objects, and for guiding the user in constructing syntactically correct query predicates. We present a formal model that underlies the OdeView display and query interface, illustrate the graphical query facilities through examples, and discuss our design decisions. We also describe our implementation, focusing on the usage of the Ode type catalog and the dynamic translation and execution of queries. As object database systems are becoming increasingly popular, we hope that the design and implementation details provided in this paper will benefit those interested in building graphical interfaces to database systems, particularly object-oriented database systems.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Dami L,,A lambda-calculus for dynamic binding,Theoretical Computer Science,1998,192,2,201-231,,,,,1998,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397597001503;http://dx.doi.org/10.1016/S0304-3975(97)00150-3,10.1016/S0304-3975(97)00150-3,"Dynamic binding is a runtime lookup operation which extracts values corresponding to some “names” from some “environments” (finite, unordered associations of names and values). Many situations related with flexible software assembly involve dynamic binding: first-class modules, mobile code, object-oriented message passing. This paper proposes λN, a compact extension of the λ-calculus to model dynamic binding, where variables are labelled by names, and where arguments are passed to functions along named channels. The resulting formalism preserves familiar properties of the λ-calculus, has a Curry-style-type inference system, and has a formal notion of compatibility for reasoning about extensible environments. It can encode records and record extensions, as well as first-class contexts with context-filling operations, and therefore provides a basic framework for expressing a wide range of name-based coordination mechanisms. An experimental functional language based on λN illustrates the exploitation of dynamic binding in programming language design.","Lambda-calculus, Records, Contexts, Dynamic binding",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Henrio L,Kammüller F",,Functional Active Objects: Typing and Formalisation,Electronic Notes in Theoretical Computer Science,2009,255,,83-101,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109004460;http://dx.doi.org/10.1016/j.entcs.2009.10.026,10.1016/j.entcs.2009.10.026,"This paper provides a sound foundation for autonomous objects communicating by remote method invo- cations and futures. As a distributed extension of ζ-calculus, we define ASPfun, a calculus of functional objects, behaving autonomously and communicating by a request-reply mechanism: requests are method calls handled asynchronously and futures represent awaited results for requests. This results in a well structured distributed object language enabling a concise representation of asynchronous method invoca- tions. This paper first presents the ASPfun calculus and its semantics. Secondly we provide a type system for ASPfun, which guarantees the “progress” property. Most importantly, ASPfun and its properties have been formalised and proved using the Isabelle theorem prover, and we consider it as a good step toward formalisation of distributed languages.","Theorem proving, object calculus, futures, distribution, typing",Proceedings of the 8th International Workshop on the Foundations of Coordination Languages and Software Architectures (FOCLASA 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Chamaillard Y,Gissinger GL",,"Formal and Architectural Aspects of Modelling, the Case of a Semi-Trailer",IFAC Proceedings Volumes,1996,29,1,7714-7719,,,,,1996,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017589326;http://dx.doi.org/10.1016/S1474-6670(17)58932-6,10.1016/S1474-6670(17)58932-6,This paper presents a new modelling architecture and a formal modelling approach based on concepts derived from object-oriented programming. It also presents the conclusions of a comparative study of the methods used for numerical and formal solution. The architecture and approach that are described here have been applied to a complex real system : modelling the road behaviour of an articulated vehicle - a tractor and semi-trailer.,"Modelling, Simulation, Software-architecture, Object-oriented programming, Transportation","13th World Congress of IFAC, 1996, San Francisco USA, 30 June - 5 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Hausmann C,Wiechert W,Ebert J",,Object Oriented Design of an On Line Data Manager for Hybrid Bioprocess Control,IFAC Proceedings Volumes,1995,28,3,360-363,,,,,1995,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017456631;http://dx.doi.org/10.1016/S1474-6670(17)45663-1,10.1016/S1474-6670(17)45663-1,"Various highly sophisticated methods from different scientific disciplines have been applied to bioprocess control and supervision. However it became dear that for an adequate system representation a hybrid coupling of such modules is desirable. For this purpose an advanced communication architecture is required. Software engineering methods can help to identify common structures and operations required for hybrid systems. This paper presents an advanced channel concept for module coupling, that is based on matrix valued time series. It makes extensive use of object oriented technology.","Software engineering, Object modelling technique, Formal specification, Object oriented programming, Hybrid bioprocess control, Data management, Time series","6th International Conference on Computer Applications in Biotechnology (CAB 6), Garmisch-Partenkirchen, Germany, 14-17 May, 1995",,,,,,,,,,,,,,,,,,,,
Journal Article,Kyas M,,Tool Support for Holistic Modelling of Distributed Embedded Systems in Creol,Electronic Notes in Theoretical Computer Science,2009,243,,105-120,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109002308;http://dx.doi.org/10.1016/j.entcs.2009.07.008,10.1016/j.entcs.2009.07.008,"A holistic approach to modelling embedded systems is advocated: Many aspects of a system should be analysed in isolation to keep the task manageable, but they often influence each other during integration in a way that the desired system becomes unrealisable. A tool-supported approach that aims at integrated models of different concerns based on formal methods is suggested to solve this problem. This approach uses Creol, which is a language designed for object-oriented modelling of distributed systems. We report on ongoing work on the design and the implementation of tools that support modelling, validation, and verification. We focus on sensor networks, which are distributed system that consists of many embedded devices with tight constraints on computational power, energy availability, and timeliness. The described tools are a compiler that performs static checks and optimisations, an interpreter that defines a formal semantics, and a prototypical LTL model checker. This supports seamless development with formal methods.","Distributed systems, object-oriented systems, modelling, sensor networks",Proceedings of the 2nd International Workshop on Harnessing Theories for Tool Support in Software (TTSS 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Masri A,Bourdeaud'huy T,Toguyeni A",,Performance Analysis of IEEE 802.11b Wireless Networks with Object Oriented Petri Nets,Electronic Notes in Theoretical Computer Science,2009,242,2,73-85,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109002035;http://dx.doi.org/10.1016/j.entcs.2009.06.024,10.1016/j.entcs.2009.06.024,"Communication protocols are often investigated using simulation. This paper presents a performance study of the distributed coordination function of 802.11 networks. Firstly, our study illustrates the different classes of Petri Nets used for modeling network protocols and their robustness in modeling based on formal methods. Next we propose a detailed 802.11b model based on Object-oriented Petri Nets that precises backoff procedure and time synchronization. Then, performance analyses are evaluated by simulation for a dense wireless network and compared with other measurements approaches. Our main goal is to propose a modular model that will enable to evaluate the impact of network performances on the performances of distributed discrete event systems.","LAN protocols modeling, Petri Nets, Performance Analysis, 802.11b Standard, Simulation",Proceedings of the First Workshop on Formal Methods for Wireless Systems (FMWS 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Bastide R,Palanque P",,A Visual and Formal Glue between Application and Interaction,Journal of Visual Languages & Computing,1999,10,5,481-507,,,,,1999,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X99901271;http://dx.doi.org/10.1006/jvlc.1999.0127,10.1006/jvlc.1999.0127,"The construction of interactive software is known to be a difficult task. As far as the non-interactive part of the application is concerned, designers can find support in the field of software engineering, using object-oriented design methods for example. With regard to the user interface per se, a number of interactive tools (interface builders) are available, that allows creating interactively the look and feel of the interface. However, relating an object-oriented design with a proper user-interface design is still a matter of craft and experience, and few techniques permit the seamless integration of the two. The work presented here aims at bridging this gap. The paper proposes a visual language, based on Petri nets, for the design of the dialogue of interactive systems. This language allows specifying both activation and rendering on the one hand, and provides a seamless integration with an object-oriented design on the other.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chamaillard Y,Gissinger GL",,Formal and architectural aspects of modelling; Implications in the case of vehicles,Control Engineering Practice,1997,5,8,1161-1168,,,,,1997,,0967-0661,https://www.sciencedirect.com/science/article/pii/S096706619700110X;http://dx.doi.org/10.1016/S0967-0661(97)00110-X,10.1016/S0967-0661(97)00110-X,This paper presents a new modelling architecture and a formal modelling approach based on concepts derived from object-oriented programming. It also presents the conclusions of a comparative study of the methods used for numerical and formal solutions. The architecture and the approach that are described here have been applied to a complex real system: modelling the road behaviour of vehicles - articulated or not.,"Modelling, simulation, software architectures, object-oriented programming, transportation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Golubski W,Lippe WM",,A complete semantics for SMALLTALK-80,Computer Languages,1995,21,2,67-79,,,,,1995,,0096-0551,https://www.sciencedirect.com/science/article/pii/009605519500002L;http://dx.doi.org/10.1016/0096-0551(95)00002-L,10.1016/0096-0551(95)00002-L,"In this paper we introduce a formal model of the object-oriented programming language SMALLTALK-80. The model can be useful for different applications in the framework of language design and implementation like compiter or interpreter generation, correctness proofs of the implementations, and standardization of the language.","object-oriented programming languages, SMALLTALK-80, formal model, operational semantics, denotational semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,Sanderson DO,,Requirements for a new object-oriented methodology,Computer Standards & Interfaces,1991,13,1,311-313,,,,,1991,,0920-5489,https://www.sciencedirect.com/science/article/pii/0920548991900393;http://dx.doi.org/10.1016/0920-5489(91)90039-3,10.1016/0920-5489(91)90039-3,"Object-oriented components, such as languages, engines, persistent storages, and development environments, are not sufficient for developing high quality object-oriented applications. New formal methodologies, based on object-oriented concepts, also need to be developed that address all life cycle phases. A preliminary list of requirements for such an object-oriented methodology is proposed. From this new methodology, practical techniques and tools can be developed that increase productivity using the new object-oriented technologies.","Methodology, object-oriented applications, object-oriented modeling, life cycle support, software design tools",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Barja ML,Fernandes AA,Paton NW,Williams MH,Dinn A,Abdelmoty AI",,Design and implementation of ROCK & ROLL: A deductive object-oriented database system,Information Systems,1995,20,3,185-211,,,,,1995,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799500009S;http://dx.doi.org/10.1016/0306-4379(95)00009-S,10.1016/0306-4379(95)00009-S,"This paper presents an approach to the development of a deductive object-oriented database system, describing the key design decisions and their consequences for implementation. The approach is novel, in that it integrates an object-oriented database system manipulated using an imperative programming language (ROCK) with a logic language for expressing queries and methods (ROLL). The integration is made seamless by deriving both the imperative and logic languages from a single formally defined data model, thereby avoiding impedance mismatches when they are integrated.","Deductive Object-Oriented Databases, Deductive Databases, Object-Oriented Databases, Database Programming, Logic Programming",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Gibson P,Méry D","Zedan H,Cau A",9 - Fair Objects,,1999,,,122-140,,Woodhead Publishing,,Object-Oriented Technology and Computing Systems Re-engineering,1999,9781898563563,,https://www.sciencedirect.com/science/article/pii/B9781898563563500134;http://dx.doi.org/10.1533/9781782420613.122,10.1533/9781782420613.122,"The temporal logic of actions (TLA) provides operators to express liveness requirements in an abstract specification model. TLA does not, however, provide high level composition mechanisms which are essential for synthesising and analysing complex behaviour. Contrastingly, the object oriented paradigm has proven itself in the development of structured specifications. However, most, if not all, of the object oriented formalisms are based on the specification of safety properties and, as such, they do not provide an adequate means of expressing liveness conditions. This paper examines how we combine temporal semantics and object oriented concepts in a complementary fashion. High level re-usable concepts are formalised as different kinds of fair objects. The object oriented semantics aid validation and customer communication, whilst the TLA semantics provide a means of formally verifying liveness requirements. The fairness concepts are founded on the notion of objects as servers which may have multiple (concurrent) clients. Some simple telephone feature specifications illustrate the practical application of our fair object semantics.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee JH,Pun PK",,Object logic integration: A multiparadigm design methodology and a programming language,Computer Languages,1997,23,1,25-42,,,,,1997,,0096-0551,https://www.sciencedirect.com/science/article/pii/S0096055197000040;http://dx.doi.org/10.1016/S0096-0551(97)00004-0,10.1016/S0096-0551(97)00004-0,"In the past decade, there has been much research effort dedicated to combine the object-oriented programming paradigm and the logic programming paradigm. Most of this effort sheds light upon the philosophy of multiparadigm programming as a near ideal mental model for a wide class of problem domains. In this paper we propose a scheme for object and logic integration—the OLI scheme. This scheme contributes to the multiparadigm programming philosophy by putting forward a multiparadigm design methodology and describing a multiparadigm programming language. Above all, the OLI scheme integrates the object-oriented and the logic programming paradigms at the design and language levels with a precise and well-balanced interface so that each paradigm shares an equal and cooperating partnership in problem analysis and problem solving. An important property of the OLI language is that programmers can program either in one of the paradigms alone or in a mixed paradigm without sacrificing expressiveness and efficiency. We give a formal definition of the OLI language and study its semantics both from the logical perspective and the object-oriented perspective. By viewing objects as an enrichment of the Herbrand universe, we define the declarative and operational semantics of OLI. We show that OLI's operational semantics, a generalized form of SLD-resolution, is sound and complete. From the object-oriented point of view, the logic part of OLI is simply an object with logic programs as states and methods for performing logical deduction.","multiparadigm programming languages, logic programming, object-oriented programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Grinchenkov DV,Mokhov VA,Spiridonova IA",,Formal Method to Design a Macro-model of a Transport Vehicle Mechanical System Translational Motion,Procedia Engineering,2015,129,,362-368,,,,,2015,,1877-7058,https://www.sciencedirect.com/science/article/pii/S1877705815039636;http://dx.doi.org/10.1016/j.proeng.2015.12.079,10.1016/j.proeng.2015.12.079,"The article is devoted to the formalization [1] of the design of mathematical model for the computer simulation of complex mechanical systems. The simulation object is the mechanical system of the transport vehicle (railway or automotive). The complete system is split into subsystems (macro-elements), each of macro-element has one degree of freedom. The whole system of macro-elements can be considered as a translational moving system. A two-stage algorithm to construct a mathematical macro-model of the transport vehicle mechanical system - is presented. The results of the computer simulation are presented. This modeling method is beneficial to be used in the educational process to establish interdisciplinary connections, as well as to create e-learning resources for students of applied mathematics, information technology and engineering profiles.","Computer simulation, complex mechanical system, vehicle, formal method, object-oriented approach, e-leaning.",International Conference on Industrial Engineering (ICIE-2015),,,,,,,,,,,,,,,,,,,,
Journal Article,"Ölveczky PC,Meseguer J",,Specification of real-time and hybrid systems in rewriting logic,Theoretical Computer Science,2002,285,2,359-405,,,,,2002,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397501003632;http://dx.doi.org/10.1016/S0304-3975(01)00363-2,10.1016/S0304-3975(01)00363-2,"This paper explores the application of rewriting logic to the executable formal modeling of real-time and hybrid systems. We give general techniques by which such systems can be specified as ordinary rewrite theories, and show that a wide range of real-time and hybrid system models, including object-oriented systems, timed automata, hybrid automata, timed and phase transition systems, and timed extensions of Petri nets, can indeed be expressed in rewriting logic quite naturally and directly. Since rewriting logic is executable and is supported by several language implementations, our approach complements property-oriented methods and tools less well suited for execution purposes, and can be used as the basis for symbolic simulation and formal analysis of real-time and hybrid systems. The relationships with the timed rewriting logic approach of Kosiuczenko and Wirsing are also studied.","Rewriting logic, Maude, Real-time systems, Hybrid systems, Timed Petri nets, Real-time object-oriented systems",Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Igarashi A,Pierce BC",,Foundations for Virtual Types,Information and Computation,2002,175,1,34-49,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540101929426;http://dx.doi.org/10.1006/inco.2001.2942,10.1006/inco.2001.2942,"Virtual types have been proposed as a notation for generic programming in object-oriented languages—an alternative to the more familiar mechanism of parametric classes. The trade-offs between the two mechanisms are a matter of current debate: for many examples, both appear to offer convenient (indeed almost interchangeable) solutions; in other situations, one or the other seems to be more satisfactory. However, it has proved difficult to draw rigorous comparisons between the two approaches, partly because current proposals for virtual types vary considerably in their details, and partly because the proposals themselves are described rather informally, usually in the complicating context of full-scale language designs. Work on the foundations of object-oriented languages has already established a clear connection between parametric classes and the polymorphic functions found in familiar typed lambda-calculi. Our aim here is to explore a similar connection between virtual types and dependent records. We present, by means of examples, a straightforward model of objects with embedded type fields in a typed lambda-calculus with subtyping, type operators, fixed points, dependent functions, and dependent records with both bounded and manifest type fields (this combination of features can be viewed as a measure of the inherent complexity of virtual types). Using this model, we then discuss some of the major differences between previous proposals and show why some can be checked statically while others require run-time checks. We also investigate how the partial “duality” of virtual types and parametric classes can be understood in terms of translations between universal and (dependent) existential types.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Blakeley J,Thompson CW,Alashqur AM",,Strawman reference model for object query languages,Computer Standards & Interfaces,1991,13,1,185-199,,,,,1991,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899190026V;http://dx.doi.org/10.1016/0920-5489(91)90026-V,10.1016/0920-5489(91)90026-V,"We begin by presenting a descriptive reference model that identifies the important features that need to exist in object query languages. This reference model can be used as a basis for comparing these languages and helps provide a foundation for future standardization efforts in this area. We then describe the main features of an object query language that is based on the type system of C ++, which we refer to as OQL[C ++]. A query module based on OQL[C ++] is being developed as part of the Zeitgeist OODB project at Texas Instruments. OQL[C ++] extends the C ++ programming language by providing support for managing and associatively querying sets of objects in a C ++ program. OQL[C ++] queries are orthogonal to persistence in the sense that they can be issued against persistent as well as transient sets of objects. The proposed OQL[C ++], provides an evolutionary path from the industry's standard query language SQL to an object query language. Using ideas similar to those presented in this paper, one can propose OQL[X] where X is either an object data model, or the type system of an object-oriented programming language such as CLOS or Object Pascal.","Query languages, query processing, query and programming language integration, object-oriented database system",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Geilen MC,Voeten JP,van der Putten PH,van Bokhoven LJ,Stevens MP",,Object-oriented modelling and specification using SHE,Computer Languages,2001,27,1,19-38,,,,,2001,,0096-0551,https://www.sciencedirect.com/science/article/pii/S0096055101000145;http://dx.doi.org/10.1016/S0096-0551(01)00014-5,10.1016/S0096-0551(01)00014-5,"Industry is facing a crisis in the design of complex hardware/software systems. Due to the increasing complexity, the gap between the generation of a product idea and the realisation of a working system is expanding rapidly. To manage complexity and to shorten design cycles, industry is forced to look at system-level languages towards specification and design. The (formal) system-level modelling language called POOSL is very expressive and is able to model dynamic hard real-time behaviour and to (visually) capture static (architecture and topology) structure in an object-oriented fashion. The language integrates a process part, based on the process algebra CCS, with a data part, based on the concepts of traditional object-oriented programming languages and it is equipped with a formal semantics. Currently, a number of automated software tools (model editing, simulator and compiler tools) are available in an environment called SHESim. These tools allow visual entry of structure and topology of the system, whereas dynamic behaviour of individual processes is expressed in an expressive imperative language. The formal semantics of POOSL provides a solid basis for the application of verification and performance analysis techniques and establishing a rigorous connection to existing analysis tools.","Object-orientation, Hardware/software systems, System-level languages, Modelling and specification",Visual Formal Methods-VFM'99 Symposium,,,,,,,,,,,,,,,,,,,,
Journal Article,"Duke R,Rose G,Smith G",,Object-Z: A specification language advocated for the description of standards,Computer Standards & Interfaces,1995,17,5,511-533,,,,,1995,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899500024O;http://dx.doi.org/10.1016/0920-5489(95)00024-O,10.1016/0920-5489(95)00024-O,"The importance of formalising the specification of standards has been recognised for a number of years. This paper advocates the use of the formal specification language Object-Z in the definition of standards. Object-Z is an extension to the Z language specifically to facilitate specification in an object-oriented style. First, the syntax and semantics of Object-Z are described informally. Then the use of Object-Z in formalising standards is demonstrated by presenting a case study based on the ODP Trader. Finally, a formal semantics is introduced that suggests an approach to the standardisation of Object-Z itself. Because standards are typically large complex systems, the extra structuring afforded by the Object-Z class construct and operation expressions enables the various hierarchical relationships and the communication between objects in a system to be succinctly specified.","Object-orientation, Formal specification, Formal semantics, Standards",Formal Description Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,"Altisen K,Maraninchi F,Stauch D",,"Aspect-oriented programming for reactive systems: Larissa, a proposal in the synchronous framework",Science of Computer Programming,2006,63,3,297-320,,,,,2006,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642306001237;http://dx.doi.org/10.1016/j.scico.2005.12.001,10.1016/j.scico.2005.12.001,"Aspect-oriented programming (AOP) has emerged recently as a language concept for expressing cross-cutting concerns, mainly in object-oriented software. Since then, the concept has been applied to a wide variety of other contexts. In this paper, we explore some cross-cutting concerns for parallel programs of reactive systems: we propose an aspect language, Larissa, and a weaving mechanism, in a core language based on parallel communicating Mealy machines.","Reactive systems, Aspect-oriented programming, Synchronous languages, Formal semantics",Special issue on foundations of aspect-oriented programming,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dragoni N,Gaspari M",,An object based algebra for specifying a fault tolerant software architecture,The Journal of Logic and Algebraic Programming,2005,63,2,271-297,,,,,2005,,1567-8326,https://www.sciencedirect.com/science/article/pii/S1567832604000396;http://dx.doi.org/10.1016/j.jlap.2004.05.006,10.1016/j.jlap.2004.05.006,In this paper we present an algebra of actors extended with mechanisms to model crash failures and their detection. We show how this extended algebra of actors can be successfully used to specify distributed software architectures. The main components of a software architecture can be specified following an object-oriented style and then they can be composed using asynchronous message passing or more complex interaction patterns. This formal specification can be used to show that several requirements of a software system are satisfied at the architectural level despite failures. We illustrate this process by means of a case study: the specification of a software architecture for intelligent agents which supports a fault tolerant anonymous interaction protocol.,"Process algebra, Software architectures, Actors, Fault tolerance, Object-oriented design",Special Issue on Process Algebra and System Architecture,,,,,,,,,,,,,,,,,,,,
Journal Article,Taivalsaari A,,On the notion of object,Journal of Systems and Software,1993,21,1,3-16,,,,,1993,,0164-1212,https://www.sciencedirect.com/science/article/pii/016412129390013N;http://dx.doi.org/10.1016/0164-1212(93)90013-N,10.1016/0164-1212(93)90013-N,"As in science in general, in computer science there is a desire to unify general concepts. The notion of object has recently emerged as a promising answer to such desires. This article examines the seemingly simple notion of object from conceptual, philosophical, data abstraction, implementation, and formal viewpoints. We hope to provide new insights into what objects in object-oriented programming are, and an extensive literature analysis on the subject.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Arbab F,,Abstract Behavior Types: a foundation model for components and their composition,Science of Computer Programming,2005,55,1,3-52,,,,,2005,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642304001455;http://dx.doi.org/10.1016/j.scico.2004.05.010,10.1016/j.scico.2004.05.010,"The notion of Abstract Data Type (ADT) has served as a foundation model for structured and object oriented programming for some thirty years. The current trend in software engineering toward component based systems requires a foundation model as well. The most basic inherent property of an ADT, i.e., that it provides a set of operations, subverts some highly desirable properties in emerging formal models for components that are based on the object oriented paradigm. We introduce the notion of Abstract Behavior Type (ABT) as a higher-level alternative to ADT and propose it as a proper foundation model for both components and their composition. An ABT defines an abstract behavior as a relation among a set of timed-data-streams, without specifying any detail about the operations that may be used to implement such behavior or the data types it may manipulate for its realization. The ABT model supports a much looser coupling than is possible with the ADT’s operational interface, and is inherently amenable to exogenous coordination. We propose that both of these are highly desirable, if not essential, properties for models of components and their composition. To demonstrate the utility of the ABT model, we describe Reo: an exogenous coordination language for compositional construction of component connectors based on a calculus of channels. We show the expressive power of Reo, and the applicability of ABT, through a number of examples.","Coordination, Components, Composition, Abstract Behavior Types, Reo, Coalgebraic semantics, Streams",Formal Methods for Components and Objects: Pragmatic aspects and applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Leavens GT,Pigozzi D",,Class-Based and Algebraic Models of Objects,Electronic Notes in Theoretical Computer Science,1998,14,,214-244,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105802385;http://dx.doi.org/10.1016/S1571-0661(05)80238-5,10.1016/S1571-0661(05)80238-5,"We compare different kinds of first-order models of objects and message passing, as found in object-oriented programming languages. We show that generic function models can easily simulate record models for static, class-based languages. We explore type systems for such languages, and show that our simulation preserves typing. Algebraic models emerge as abstractions of the generic function model that suppress details that are irrelevant for client code. Thanks to Todd Millstein for comments on an earlier draft, and for suggesting that we make our comparisons between the record and generic function models constructive, which greatly improved the paper. Thanks to Todd and Craig Chambers for many discussions about multimethod languages and their type systems.",,US-Brazil Joint Workshops on the Formal Foundations of Software Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,Attoui A,,An environment based on rewriting logic for parallel systems formal specification and prototyping,Journal of Systems Architecture,1997,44,2,79-105,,,,,1997,,1383-7621,https://www.sciencedirect.com/science/article/pii/S1383762197000039;http://dx.doi.org/10.1016/S1383-7621(97)00003-9,10.1016/S1383-7621(97)00003-9,"Design of real time/parallel systems requires formal approaches in order to facilitate verification and validation at each step. Methods based on formal logic have been previously suggested but they often work only in a specific domain and are generally only possible with specialized users. In an attempt to overcome these two restrictions, this paper proposes a method based on rewriting logic. This method integrates the main principles of an object-oriented approach (distributed configurations are made up of concurrent objects and messages). Different tools are proposed to support this approach: a graphical editor for the specification of the structure and the behavior of objects, a prototype generator and an inference engine for rule validation based on rewriting logic decidability. Thanks to these tools a grounding in theory is not a prerequisite for end-users. The method and tools are presented on a distributed banking system example which is followed throughout the paper.","Specification, Validation, Rewriting logic, Object-oriented approach, Concurrent and parallel systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Venugopal M,Eastman CM,Sacks R,Teizer J",,Semantics of model views for information exchanges using the industry foundation class schema,Advanced Engineering Informatics,2012,26,2,411-428,,,,,2012,,1474-0346,https://www.sciencedirect.com/science/article/pii/S1474034612000067;http://dx.doi.org/10.1016/j.aei.2012.01.005,10.1016/j.aei.2012.01.005,"The industry foundation classes (IFC) data schema is generic, designed to support the full range of model exchanges needed in the construction industry. For any particular working exchange for some sub-domain of building construction, a set of model view definitions (MVD) is required to specify exactly what information should be exchanged, and in what form and structure the IFC entities are to be used. Defining model view definitions requires principle decisions and workarounds because the IFC itself does not address a number of semantic issues comprehensively. Some of the issues identified and discussed include the typing of objects, instances, geometry, relationships, and rules, which are supported in the IFC schema, and the complexities of exchanging such information accurately between applications. This paper advances the idea of MVD Concepts as an object-oriented and modular mechanism for embedding semantic meaning in model views. We conclude that although the IFC product model schema is richly expressive, it lacks formal definition of its entities, attributes, and relationships. To achieve standardized and re-usable model views, further research towards a modular and logical framework based on formal specification of IFC concepts is recommended. This research is expected to impact the overall interoperability of applications in the building information modeling realm.","Industry foundation classes (IFC), Model view definitions (MVD), National BIM Standard (NBIMS), Product modeling, Process modeling, Interoperability",Knowledge based engineering to support complex product design,,,,,,,,,,,,,,,,,,,,
Book Chapter,Hevner AR,Yovits MC,Object-Oriented System Development Methods,,1992,35,,135-198,,Elsevier,,,1992,,0065-2458,https://www.sciencedirect.com/science/article/pii/S0065245808605951;http://dx.doi.org/10.1016/S0065-2458(08)60595-1,10.1016/S0065-2458(08)60595-1,"Publisher Summary This chapter explains what is meant by object-orientation, surveys current methods of object-oriented system development, and presents an integrated methodology for performing object-oriented system development. The chapter defines objects and explains object-oriented concepts as a basis for understanding the object-oriented system development methods. Armed with a basic understanding of object-oriented concepts, principles, and terminology, the chapter surveys the background of research and practice in the object-oriented field. The chapter surveys representations of the object-oriented system life cycle and discusses existing methods, techniques, and tools that support the development phases of object-oriented analysis, object-oriented design, and object-oriented implementation and testing. Brief surveys of research and development projects on object-oriented system development methods and tools are presented. A critique of the current state of object-oriented system development (OOSD) concludes the survey. The chapter elaborates OOSD with box structures. As an example of an integrated system development methodology that supports both object-oriented and formal concepts, the cleanroom system development process (CSPD) is presented. The central box structure concepts are shown to support object orientation in system development. Within CSDP, methods of object-oriented analysis (OOA) and object-oriented design (OOD) using box structures are employed. The appendix to the chapter summarizes a case study that demonstrates the use of box structures in a realistic system development. A critique of CSDP discusses the need for more experience with the practical application of cleanroom concepts in real development projects. The chapter presents conclusions and future research directions.",,,Advances in Computers,,,,,,,,,,,,,,,,,,,
Journal Article,"Hartmann A,Amme W,von Ronne J,Franz M",,Code Annotation for Safe and Efficient Dynamic Object Resolution,Electronic Notes in Theoretical Computer Science,2004,82,2,362-376,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105825976;http://dx.doi.org/10.1016/S1571-0661(05)82597-6,10.1016/S1571-0661(05)82597-6,"The execution time of object oriented programs can be drastically reduced by transforming “non escaping” objects into a collection of its component scalar data fields. But for languages that support dynamic linking, this kind of optimization (which we call “object resolution”) can usually only be performed at runtime, when the entire program is available for analysis. In such cases, the resulting performance increases will be offset by the additional costs that arise during the analysis and restructuring phases. In this paper, we describe work in progress, which provides an annotation technique that reduces the runtime overhead required for performing object resolutions. Our method performs a partial static escape analysis of each class at compile-time and then annotates the intermediate representation of that class with information which the just-in-time (JIT) compiler can use for object resolution. We apply this technique to the safe TSA intermediate representation, producing a simple extension to safe TSA's type system that guarantees a safe and verifiable transmission of the annotated program.",,"COCV'03, Compiler Optimization Meets Compiler Verification",,,,,,,,,,,,,,,,,,,,
Journal Article,Küster JM,,Towards Inconsistency Handling of Object-Oriented Behavioral Models,Electronic Notes in Theoretical Computer Science,2004,109,,57-69,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104052090;http://dx.doi.org/10.1016/j.entcs.2004.02.056,10.1016/j.entcs.2004.02.056,"With the Unified Modeling Language being used in diverse contexts, the ability of defining and checking customized consistency conditions is of increasing importance. Often, consistency checks rely on existing formal analysis tools such as model checkers and require the translation of models into input languages of these tools. The technique of inconsistency handling aims at systematically dealing with inconsistencies de- tected by such consistency checks. Resolution of inconsistencies typically involves changing the model, with guidance of the software engineer or completely automated in the ideal case. As a consequence, in cases where formal analysis tools are used for consistency checks, the output of these tools must be presented in a form understandable for the software engineer. In this paper, we develop a concept for inconsistency handling of object-oriented behavioral models and discuss how graph transformation can be used for reconstructing UML models from outputs generated by analysis tools.","consistency management, UML, model transformation, model analysis",Proceedings of the Workshop on Graph Transformation and Visual Modelling Techniques (GT-VMT 2004),,,,,,,,,,,,,,,,,,,,
Book Chapter,"Munoz E,Capon-Garcia E,Lainez-Aguirre JM","Espuña A,Graells M,Puigjaner L",Towards Advanced Enterprise Wide Optimization Based On Explicit Concept-Object Oriented Mathematical Modeling,,2017,40,,2347-2352,,Elsevier,,27th European Symposium on Computer Aided Process Engineering,2017,,1570-7946,https://www.sciencedirect.com/science/article/pii/B9780444639653503937;http://dx.doi.org/10.1016/B978-0-444-63965-3.50393-7,10.1016/B978-0-444-63965-3.50393-7,"The basis of decision-making in the enterprise consists of formally representing the system and its subsystems in a model, which adequately captures those features that are necessary to reach consistent decisions. This work proposes an explicit concept-object oriented mathematical modeling approach for formalizing the domain knowledge represented by mathematical models. A systematic framework is developed in order to manage and exploit mathematical models used in the process systems domain. The ultimate goal of this work is the development of intelligent agents for supporting enterprise wide optimization at scheduling level.","Mathematical modeling, Semantic model, Enterprise wide optimization",,Computer Aided Chemical Engineering,,,,,,,,,,,,,,,,,,,
Journal Article,"Agrawal R,DeMichiel LG",,Type derivation using the projection operation,Information Systems,1994,19,1,55-68,,,,,1994,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437994900264;http://dx.doi.org/10.1016/0306-4379(94)90026-4,10.1016/0306-4379(94)90026-4,"We present techniques for deriving types from existing object-oriented types using the relational algebraic projection operation and for inferring the methods that are applicable to these types. Such type derivation occurs, for example, as a result of defining algebraic views over object types. We refactor the type hierarchy and place the derived types in the type hierarchy in such a way that the state and behavior of existing types remain exactly as before. Our results have applicability to relational databases extended with object-oriented type systems and to object-oriented systems that support algebraic operations.",,Extending Database Technology,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bottoni P,Fish A,Heußner A,Presicce FP",,Resource-aware policies,Journal of Visual Languages & Computing,2017,38,,84-96,,,,,2017,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X15300513;http://dx.doi.org/10.1016/j.jvlc.2016.10.004,10.1016/j.jvlc.2016.10.004,"In previous papers, we proposed an extension of Spider Diagrams to object-oriented modelling, called Modelling Spider Diagrams (MSDs), as a visual notation for specifying admissible states of instances of types, and for verifying the conformance of configurations of instances with such specifications. Based on this formalisation, we developed a notion of transformation of MSDs, modelling admissible evolutions of configurations. In the original version of MSD, individual instances evolve independently, but in reality evolutions often occur in the context of available resources, so transformations must be extended to take this into account. In this paper we provide an abstract syntax for MSDs, in terms of typed attributed graphs, and a semantics for the specification of policies based on notions from the theory of graph transformations, and we associate with them a notion of resources. We also introduce a synchronisation mechanism, based on annotation of instances with resources, so that the transformations required by a policy occur with respect to available resources. In particular, resources can be atomically produced or consumed or can change their state consistently with the evolution of the spiders subject to the policy.","Annotations, Resources, Modelling spider diagrams, Synchronisation, Conformance, Policies",SI:In honor of Prof SK Chang,,,,,,,,,,,,,,,,,,,,
Journal Article,Kurz A,,Specifying coalgebras with modal logic,Theoretical Computer Science,2001,260,1,119-138,,,,,2001,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397500001250;http://dx.doi.org/10.1016/S0304-3975(00)00125-0,10.1016/S0304-3975(00)00125-0,"We propose to use modal logic as a logic for coalgebras and discuss it in view of the work done on coalgebras as a semantics of object-oriented programming. Two approaches are taken: First, standard concepts of modal logic are applied to coalgebras. For a certain kind of functor it is shown that the logic exactly captures the notion of bisimulation and a complete calculus is given. Examples of verifications of object properties are given. Second, we discuss the relationship of this approach with the coalgebraic logic of Moss (Coalgebraic logic, Ann Pure Appl. Logic 96 (1999) 277–317.).","Coalgebras, Modal logic, Object-oriented programming, Verification, Specification",Coalgebraic Methods in Computer Science 1998,,,,,,,,,,,,,,,,,,,,
Journal Article,Ferrara P,,A generic framework for heap and value analyses of object-oriented programming languages,Theoretical Computer Science,2016,631,,43-72,,,,,2016,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397516300299;http://dx.doi.org/10.1016/j.tcs.2016.04.001,10.1016/j.tcs.2016.04.001,"Abstract interpretation has been widely applied to approximate data structures and (usually numerical) value information, but their combination is needed to effectively apply static analysis to real software. In this context, we introduce a generic framework that, given a heap and a value analysis, combines them, proving formally its soundness. We plug inside this framework a standard allocation site-based pointer analysis, a TVLA-based shape analysis, and standard existing numerical domains. As far as we know, this is the first sound generic automatic framework for statically typed object-oriented programming languages combining heap and value analyses that allows to summarize and materialize heap identifiers.","Static analysis, Abstract interpretation, Generic analyzers",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ludäscher B,Himmeröder R,Lausen G,May W,Schlepphorst C",,Managing semistructured data with FLORID: A deductive object-oriented perspective,Information Systems,1998,23,8,589-613,,,,,1998,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437998000301;http://dx.doi.org/10.1016/S0306-4379(98)00030-1,10.1016/S0306-4379(98)00030-1,"The closely related research areas management of semistructured data and languages for querying the Web have recently attracted a lot of interest. We argue that languages supporting deduction and object-orientation (dood languages) are particularly suited in this context: Object-orientation provides a flexible common data model for combining information from heterogeneous sources and for handling partial information. Techniques for navigating in object-oriented databases can be applied to semistructured databases as well, since the latter may be viewed as (very simple) instances of the former. Deductive rules provide a powerful framework for expressing complex queries in a high-level, declarative programming style. We elaborate on the management of semistructured data and show how reachability queries involving general path expressions and the extraction of data paths in the presence of cyclic data can be handled. We then propose a formal model for querying structure and contents of Web data and present its declarative semantics. A main advantage of our approach is that it brings together the above-mentioned issues in a unified, formal framework and—using the Florid system—supports rapid prototyping and experimenting with all these features. Concrete examples illustrate the concise and elegant programming style supported by Florid and substantiate the above-mentioned claims.","Semistructured Data, Querying the Web, Information Integration, Deductive Object-Oriented Databases",Semistructured Data,,,,,,,,,,,,,,,,,,,,
Journal Article,"Carbone M,Honda K,Yoshida N",,A Calculus of Global Interaction based on Session Types,Electronic Notes in Theoretical Computer Science,2007,171,3,127-151,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107003350;http://dx.doi.org/10.1016/j.entcs.2006.12.041,10.1016/j.entcs.2006.12.041,"This paper proposes a calculus for describing communication-centred programs and discusses its use through a formal description of several use cases from real business protocols. The formalism, called global calculus, aims at representing global message flows as structured communications. The global calculus originates from the Choreography Description Language (CDL), a web service description language developed by W3C's WS-CDL Working Group. Its type discipline is based on session types which have been studied over long years in the context of the π-calculus [Honda, K., V. Vasconcelos and M. Kubo, Language primitives and type disciplines for structured communication-based programming, in: ESOP'98, LNCS 1381, 1998, pp. 22–138; Dezani-Ciancaglini, M., D. Mostrous, N. Yoshida and S. Drossopoulou, Session Types for Object-Oriented Languages, in: Proceedings of ECOOP'06, LNCS, 2006; Vasconcelos, V., A. Ravara and S.J. Gay, Session types for functional multithreading., in: CONCUR'04, LNCS 3170, 2004, pp. 497–511; Bonelli, E., A.B. Compagnoni and E.L. Gunter, Correspondence assertions for process synchronization in concurrent communications., JFP 15 (2005), pp. 219–247]. Session types offer a high-level abstraction and articulation for complex communication behaviours, and play a fundamental role to guide the programmer towards a clear, well-structured description of business protocols.","Web Services, Communication-Centred Programming, -Calculus, Session Types",Proceedings of the Second International Workshop on Developments in Computational Models (DCM 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Schweimeier R,Jeffrey A",,A Categorical and Graphical Treatment of Closure Conversion,Electronic Notes in Theoretical Computer Science,1999,20,,481-511,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104800902;http://dx.doi.org/10.1016/S1571-0661(04)80090-2,10.1016/S1571-0661(04)80090-2,"This paper gives a formal basis for the closure conversion phase of functional programming languages with imperative features, using a graphical semantics for the language. We present normal forms of graphs, one corresponding to procedural languages, and one corresponding to object-oriented languages. Using closure conversion, we can prove normalization results for both normal forms. Thus, we obtain sound algorithms for compiling the language into either procedural or object-oriented code. We discuss efficiency issues of the translation and suggest some improvements on the algorithm.",,"MFPS XV, Mathematical Foundations of Progamming Semantics, Fifteenth Conference",,,,,,,,,,,,,,,,,,,,
Journal Article,"Hitchcock P,Wang B",,Formal approach to hypertext system based on object-oriented database system,Information and Software Technology,1992,34,9,573-592,,,,,1992,,0950-5849,https://www.sciencedirect.com/science/article/pii/095058499290135C;http://dx.doi.org/10.1016/0950-5849(92)90135-C,10.1016/0950-5849(92)90135-C,"InterSect is a prototype hypertext system designed to meet the requirements of complex documentation environments. It differs from conventional hypertext systems in that its nodes can behave like records in a database, as well as participating in normal hypertext links. This helps to overcome some of the problems, such as getting lost in hyperspace, exhibited by first-generation hypertext systems. The object-oriented database DAMOKLES is used in the prototype. The paper describes the use of the formal language Z to specify the InterSect system.","formal method, hypertext, object-oriented database",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bogusch R,Marquardt W",,A formal representation of process model equations,Computers & Chemical Engineering,1997,21,10,1105-1115,,,,,1997,,0098-1354,https://www.sciencedirect.com/science/article/pii/S0098135496003213;http://dx.doi.org/10.1016/S0098-1354(96)00321-3,10.1016/S0098-1354(96)00321-3,"The lack of adequate support for the development of mathematical process models confines the application of model-based techniques in the design and operation of complex chemical processes. To overcome this problem considerable effort has to be put into the development of knowledge-based software tools. The development of such tools requires a proper structuring of process models followed by a formalization of their representation. In this contribution, elementary modeling objects for the representation of the behavioral aspects of chemical processes are defined. The introduced methodology is based on ontological principles and general systems theory. Its formalization in terms of the object-oriented data model VeDa allows the formal representation of the mixed types of equations and formalisms arising in mathematical process models. It provides generality and extensibility since new types of equations or formalisms can be incorporated easily.","mathematical process models, computer-aided modeling, explicit conceptualization, formal ontology, object-oriented representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Koch C,Firmenich B",,An approach to distributed building modeling on the basis of versions and changes,Advanced Engineering Informatics,2011,25,2,297-310,,,,,2011,,1474-0346,https://www.sciencedirect.com/science/article/pii/S1474034610001059;http://dx.doi.org/10.1016/j.aei.2010.12.001,10.1016/j.aei.2010.12.001,"Actors involved in the computer-supported design process work together towards a common goal – the design of a building. Current collaboration approaches often focus on versioned and distributed building models, which describe virtual building states on the basis of the object-oriented method. State changes (for example moving a wall or modifying its material) remain unconsidered and lead to inconsistency problems when exchanging, comparing and merging versioned building models. This paper presents a new modeling approach that combines existing state-oriented descriptions of a virtual building with additional change-oriented information by means of design steps denoted as modeling operations. A new language is defined for the formal description of modeling operations. These operations establish a standardized processing interface for existing building models, can represent design intents, enhance current models with change semantics and add to the consistency of these models. Moreover, this paper presents new concepts for intra-domain collaboration and model management that overcome current limitations when exchanging, comparing and merging versioned building models. The pilot implementation and some project scenarios in industry verify that current design processes can benefit in principle from combined state-oriented and change-oriented building information.","Collaboration, Versioning, Change management, Object-oriented modeling, Building information modeling, Diff and merge",Information mining and retrieval in design,,,,,,,,,,,,,,,,,,,,
Journal Article,"Blanchette JC,Owe O",,An Open System Operational Semantics for an Object-Oriented and Component-Based Language,Electronic Notes in Theoretical Computer Science,2008,215,,151-169,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108003691;http://dx.doi.org/10.1016/j.entcs.2008.06.026,10.1016/j.entcs.2008.06.026,"Object orientation and component-based development have both proven useful for the elaboration of open distributed systems. These paradigms are offered by the Creol language. Creol objects are concurrent, each with its own virtual processor and internal process control, and communicate using asynchronous (non-blocking) method calls. This provides the efficiency of message passing systems, while keeping the structuring benefits of methods and object-oriented programming. Conditional processor release points provide a high-level synchronization mechanism based on passive waiting that allows us to combine active and reactive behavior. A Creol component can be a single (concurrent) object or a collection of objects, together with a number of interfaces, and cointerfaces, defining the provided and required interaction and semantic behavior. Creol's semantics is defined formally using operational semantics and Hoare logic. An operational semantics lets us simulate an entire system, where all components are known in advance; in contrast, Hoare logic, together with class invariants and communication histories, lets us reason locally about a method body, without needing access to the implementations of the other classes. To bridge the gap between these two semantics, we introduce a history-based operational semantics for open systems. This new semantics can be used as an intermediate step for proving that Creol's Hoare logic is sound and complete with respect to the language's operational semantics. The approach can easily be adapted to other component-based languages where communication is done by message passing or by method interaction.","Operational semantics, open distributed systems, communication histories, object orientation",Proceedings of the 4th International Workshop on Formal Aspects of Component Software (FACS 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Motus L,Naks T",,A Method and a Tool for Formal Timing Analysis of OMT Designs,IFAC Proceedings Volumes,1996,29,5,7-12,,,,,1996,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017463476;http://dx.doi.org/10.1016/S1474-6670(17)46347-6,10.1016/S1474-6670(17)46347-6,"A variay of tools, based on object-orimted design methodology is already available commercially. Many new tools are being developed. Many applications built by using these tools are inherently time-critical. However, it is widely known that object-orimted methodologies, in spite of all their virtues, are pretty awkward in verifying quantitative time correctness of the specification, design and implementation of the developed product. This paper discusses same reasons of why object-oriented methods cannot be quite aware of timing problems and how the situation could be improved. The discussion is illustrated with examples from HRT-HOOD and OMT. The technical contents of the paper is based on a new generation software tool LIMITS, which is designed and built as a coprocessor to an OMI tool (EU grant COP-94-1577). Key theoraical and methodological issues of LIMITS insist on introductioo of non-functional requirements (timing, safety, reliability, ac.) early in the requirements specification stage, selection of time model with appropriate complexity to support formal verification of all the timing properties, support to all life-cycle stages and combining formal verification with informal (simulation) study.","Object-oriented design, time-critical systems, time correctness, formal verification, software engineering environments","IFAC Workshop on real Time Programming WRTP 96, Gramado, Brazil, 4-6 November",,,,,,,,,,,,,,,,,,,,
Journal Article,Jones CB,,Fixing the Semantics of Some Concurrent Object-Oriented Concepts: Extended Abstract,Electronic Notes in Theoretical Computer Science,1995,1,,307-312,,,,,1995,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104800185;http://dx.doi.org/10.1016/S1571-0661(04)80018-5,10.1016/S1571-0661(04)80018-5,"Concurrent object-oriented languages provide a suitable target for a compositional design process that copes with the interference inherent with concurrency. Fixing the semantics of an object-based design language has been undertaken using structured operational semantics and by a mapping to the pi-calculus. These two approaches are outlined and contrasted. In particular, the difficulties in the two approaches of justifying the proof rules of the proposed design method are explained.",,"MFPS XI, Mathematical Foundations of Programming Semantics, Eleventh Annual Conference",,,,,,,,,,,,,,,,,,,,
Journal Article,Shen VR,,A PN-based approach to the high-level synthesis of digital systems,Integration,2006,39,3,182-204,,,,,2006,,0167-9260,https://www.sciencedirect.com/science/article/pii/S0167926005000246;http://dx.doi.org/10.1016/j.vlsi.2005.05.002,10.1016/j.vlsi.2005.05.002,"A Petri net (PN)-based approach associated with object-oriented technique is proposed to support the specification, analysis, and design of digital systems. Starting from system level to register-transfer level (RTL), the marked Petri net (MPN) with colored tokens is well applied to capture the designer's ideas and to present the system's behavior graphically. Through the net model, reachability analysis technique is employed to formally verify the digital system designed. Hence, using the behavioral properties—liveness (i.e. absence of deadlock) and safety (i.e. absence of overflow) of the net model can avoid the hardware system from deadlocks and hazards, respectively. From the live and safe MPN model we can obtain the desired hardware prototype at RTL by using the system optimization rules and object-oriented model checking. Furthermore, a time Petri net (TPN) model can be used to check the time consistency among events. This PN-based modeling approach is superior to the current techniques for requirements analysis. Finally, main results are presented in the form of four properties and supported by some experiments.","High-level synthesis, Object-oriented model, Petri nets, Requirements analysis, Rapid protyping",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bowen JP,Breuer PT,Lano KC",,Formal specifications in software maintenance: from code to Z++ and back again,Information and Software Technology,1993,35,11,679-690,,,,,1993,,0950-5849,https://www.sciencedirect.com/science/article/pii/095058499390083F;http://dx.doi.org/10.1016/0950-5849(93)90083-F,10.1016/0950-5849(93)90083-F,"The paper presents a number of techniques that have been developed as components of the software maintenance process as part of the ESPRIT REDO project. These techniques are all based on formal methods, and the work described has provided the mathematical underpinning to a large collaborative project that has been investigating various aspects of software maintenance. The focus of the project has been on reverse engineering, and methods for this part of the maintenance process are reported on here, along with techniques for subsequent re-engineering. A proposal for specification-oriented software maintenance is presented, in which specifications in an object-oriented extension of the formal notation Z are maintained in step with the corresponding programs.","formal methods, formal specification, object-oriented techniques, re-engineering, reverse engineering, software maintenance, Z notation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Van den Bussche J,Heuer A",,Using SQL with object-oriented databases,Information Systems,1993,18,7,461-487,,,,,1993,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799390003J;http://dx.doi.org/10.1016/0306-4379(93)90003-J,10.1016/0306-4379(93)90003-J,"We investigate how the standard database query language SQL can be extended to deal with the newly emerging trends of complex objects and object orientation. Our main concern is to extend SQL as naturally as possible, rather than to redesign SQL into “yet another” object-oriented query language. We achieve this goal through a faithful mapping from a complete object-oriented database model, compatible with recent proposals in the field, to the nested relational database model, which is widely accepted as a natural extension of the relational database model on which standard SQL is based. We provide formal definitions of syntax and semantics. We also review related research and situate our work into it.","Object-oriented database models, query languages, SQL",,,,,,,,,,,,,,,,,,,,,
Journal Article,Tseytin GS,,A formalization of reasoning not derived from standard predicate logic,Theoretical Computer Science,1999,224,1,291-317,,,,,1999,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397598003168;http://dx.doi.org/10.1016/S0304-3975(98)00316-8,10.1016/S0304-3975(98)00316-8,"A system of formal reasoning, termed object-oriented logic (OOL), is presented which is based on the logical concepts present in modern Computer programming and not related directly to predicate logic. It is expected to be efficient in deriving simple conclusions when information is centered around objects and in combining independently designed subsystems. Some examples are discussed, as well as relation to other systems for logic and/or programming.","Non-predicate logic, Logic programming, Object-oriented programming, Open data model",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mahfoudhi A,Abed M,Angué JC",,TOOD: Task Object Oriented Description for Ergonomic Interfaces Specification,IFAC Proceedings Volumes,1995,28,15,641-646,,,,,1995,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017453055;http://dx.doi.org/10.1016/S1474-6670(17)45305-5,10.1016/S1474-6670(17)45305-5,"Despite the recent progress in the domain of Man-Machine Interface engineering, several problems concerning the incompatibily between the information presentation to the user and his cognitive representation are still present. This paper presents a new Task Object Description methodology (TOOD). It tries to relate the characteristics of the user’s task with those of the interface. The introduction of ergonomic concepts allows to take the human factors into account. And the joint use of the object oriented techniques and the High Level Petri Nets supplies complete, coherent and re-usable entities allowing to give a formal description of the interactive systems’ characteristics and an appropriate specification of the user interface. An example, extracted from the air traffic control, is presented to illustrate this new methodology.","Task Analysis, Man-Machine Interface, Specification, Co-operation, Object Oriented Techniques, Object Petri Nets, Human Factors","6th IFAC/IFIP/IFORS/IEA Symposium on Analysis, Design and Evaluation of Man-Machine Systems 1995, Cambridge, MA, USA, 27-29 June 1995",,,,,,,,,,,,,,,,,,,,
Journal Article,Newman RM,,The ClassiC programming language and design of synchronous concurrent object oriented languages,Journal of Systems Architecture,1998,45,5,387-407,,,,,1998,,1383-7621,https://www.sciencedirect.com/science/article/pii/S1383762197000891;http://dx.doi.org/10.1016/S1383-7621(97)00089-1,10.1016/S1383-7621(97)00089-1,"Many real-time systems make use of concurrent programming systems and are often designed using object oriented design methods. Concurrent Object Oriented Languages (COOLS) are a class of programming language that integrates the facilities of concurrent and object oriented programming in an integrated rather than orthogonal manner. With the increasing interest in the use of object oriented languages such as C++ for the programming of embedded and real-time systems COOLs seem to be a natural candidate for such tasks. Several COOLs have been described in the literature which address the requirements of concurrent programming, inter-process communication (IPC) and synchronisation in various different ways. This paper discusses one such language, ClassiC, and examines the approach to this problem taken in its design. In particular, it is shown that the features of ClassiC allow derivation of active classes from other active classes. It is shown how this property can be used to overcome some of the problems associated with synchronous IPC schemes while maintaining the advantages of them and how the use of the asynchronous IPC model allows verification of synchronisation and deadlock properties based on the use of CSP methods.","Concurrency, Object-orientation, Formal methods, Programming, Real-time systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kolberg M,Sinnott RO,Magill EH",,Experiences modelling and using formal object-oriented telecommunication service frameworks,Computer Networks,1999,31,23,2577-2592,,,,,1999,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128699001218;http://dx.doi.org/10.1016/S1389-1286(99)00121-8,10.1016/S1389-1286(99)00121-8,"This paper describes experiences in using SDL and its associated tools to create telecommunication services by producing and specialising object-oriented frameworks. The chosen approach recognises the need for the rapid creation of validated telecommunication services. It introduces two stages to service creation. Firstly a software expert produces a service framework, and secondly a telecommunications `business consultant' specialises the framework by means of graphical tools to rapidly produce services. Here the focus is given to the underlying technology required. In particular, the advantages and disadvantages of SDL and tools for this purpose are highlighted.","Object-oriented Frameworks, Service creation, SDL, TINA, TTCN",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Damaševičius R,Štuikys V",,Application of the object-oriented principles for hardware and embedded system design,Integration,2004,38,2,309-339,,,,,2004,,0167-9260,https://www.sciencedirect.com/science/article/pii/S0167926004000641;http://dx.doi.org/10.1016/j.vlsi.2004.08.005,10.1016/j.vlsi.2004.08.005,"As the complexity of hardware (HW) and embedded system design is constantly increasing, the researchers are seeking to develop new more abstract and productive design methods or adapt the existing ones from other domains such as software design. This paper addresses the problem of using the object-oriented (OO) design techniques in HW domain. The main OO design techniques are as follows: abstraction, separation of concerns, composition and generalization. The application of the OO design paradigm has many aspects: high-level specification of HW models using OO formal notations such as Petri Nets and UML diagrams, HW description using OO HW description languages such as VHDL extensions and SystemC, HW design using OO HW architectures, platforms and design patterns. In this paper, we present a comprehensive overview of the application of the OO design paradigm in HW and embedded system design domains and formulate its main principles, discuss the current achievements in the area, and outline the future trends.","Object-oriented hardware design, Embedded system design, Modeling, UML, Class diagram.",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Iranmanesh Z,Fallah MS",,Specification and static enforcement of scheduler-independent noninterference in a middleweight Java,"Computer Languages, Systems & Structures",2016,46,,20-43,,,,,2016,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842415300300;http://dx.doi.org/10.1016/j.cl.2016.05.003,10.1016/j.cl.2016.05.003,"We introduce a new timing covert channel that arises from the interplay between multithreading and object orientation. This example motivates us to explore the root of the problem and to devise a mechanism for preventing such errors. In doing so, we first add multithreading constructs to Middleweight Java, a subset of the Java programming language with a fairly rich set of features. A noninterference property is then presented which basically demands program executions be equivalent in the view of whom observing final public values in environments using the so-called high-independent schedulers. It is scheduler-independent in the sense that no matter which scheduler is employed, the executions of the program satisfying the property do not lead to illegal information flows in the form of explicit, implicit, or timing channels. We also give a provably sound type-based static mechanism to enforce the proposed property.","Covert channels, Multithreaded object-oriented programming, Scheduler-independent noninterference, Security type systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ölveczky PC,Meseguer J",,Real-Time Maude 2.1,Electronic Notes in Theoretical Computer Science,2005,117,,285-314,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104053058;http://dx.doi.org/10.1016/j.entcs.2004.06.015,10.1016/j.entcs.2004.06.015,"Real-Time Maude 2.1 is an extension of Full Maude 2.1 supporting the formal specification and analysis of real-time and hybrid systems. Symbolic simulation, search and model checking analysis are supported for a wide range of systems. This paper gives an overview of the tool and documents its semantic foundations.","Rewriting logic, real-time systems, object-oriented specification, formal analysis, simulation, model checking",Proceedings of the Fifth International Workshop on Rewriting Logic and Its Applications (WRLA 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Özsu MT,Straube DD",,Issues in query model design in object-oriented database systems,Computer Standards & Interfaces,1991,13,1,157-167,,,,,1991,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899190024T;http://dx.doi.org/10.1016/0920-5489(91)90024-T,10.1016/0920-5489(91)90024-T,"The provision of a powerful query system, including a declarative query language and the systems support for efficiently processing queries is essential for the success of object-oriented database technology. Designing a query system involves making a large number of decisions, further complicated by the lack of a universally accepted object-oriented object data model. In this paper, object data model and query model design decisions are enumerated, alternatives are identified, and the tradeoffs are specified.","Object-oriented database systems, query languages, object calculus, object algebra",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cardelli L,Martini S,Mitchell JC,Scedrov A",,An Extension of System F with Subtyping,Information and Computation,1994,109,1,4-56,,,,,1994,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540184710133;http://dx.doi.org/10.1006/inco.1994.1013,10.1006/inco.1994.1013,"System F is a well-known typed λ-calculus with polymorphic types, which provides a basis for polymorphic programming languages. We study an extension of F, called F<: (pronounced ef-sub), that combines parametric polymorphism with subtyping. The main focus of the paper is the equational theory of F<:, which is related to PER models and the notion of parametricity. We study some categorical properties of the theory when restricted to closed terms, including interesting categorical isomorphisms. We also investigate proof-theoretical properties, such as the conservativity of typing judgments with respect to F. We demonstrate by a set of examples how a range of constructs may be encoded in F<:. These include record operations and subtyping hierarchies that are related to features of object-oriented languages.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tabary D,Abed M",,A software environment task object-oriented design (ETOOD),Journal of Systems and Software,2002,60,2,129-140,,,,,2002,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121201000851;http://dx.doi.org/10.1016/S0164-1212(01)00085-1,10.1016/S0164-1212(01)00085-1,"This paper is intended to present an approach to the construction of a task model of method, named task object-oriented design (TOOD), used for the development of an interactive system. This approach is based on a formal notation, giving quantitative results which may be checked by designers and which provide the possibility of performing mathematical verifications on the models. The modeling formalism is based on the joint use of the object approach and of high-level Petri nets. The concepts borrowed from the object approach make it possible to describe the static aspect of tasks and the Petri nets enable the description of dynamics and behavior. We also describe a software aid tool for the manipulation of these models, which allow the editing of a task model. In order to facilitate comprehension of the method, a simple example of procedure used in missile firing management will be given.","Tasks, Human-centered design, Petri nets, Object modeling techniques, Human-machine interface, Methodology","Artificial and Computational Intelligence for Decisions, Control, and Automation in Engineering and Industrial Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,Alagić S,,"Institutions: integrating objects, XML and databases",Information and Software Technology,2002,44,4,207-216,,,,,2002,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584902000101;http://dx.doi.org/10.1016/S0950-5849(02)00010-1,10.1016/S0950-5849(02)00010-1,"A general model theory based on institutions is proposed as a formal framework for investigating typed object-oriented, XML and other data models equipped with integrity constraints. A major challenge in developing such a unified model theory is in the requirement that it must be able to handle major structural differences between the targeted models as well as the significant differences in the logic bases of their associated constraint languages. A distinctive feature of this model theory is that it is transformation-oriented. It is based on structural transformations within a particular category of models or across different categories with a fundamental requirement that the associated constraints are managed in such a way that the database integrity is preserved.","Object-oriented, XML, Data models, Institutions, Transformations, Integrity constraints",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferri F,Massari F,Rafanelli M",,A Pictorial Query Language for Geographic Features in an Object-Oriented Environment,Journal of Visual Languages & Computing,1999,10,6,641-671,,,,,1999,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X99901362;http://dx.doi.org/10.1006/jvlc.1999.0136,10.1006/jvlc.1999.0136,"In this paper, a visual algebra and the relative pictorial query language (PQL) for geographic information systems (GIS) are proposed and discussed. The base data structure of the object oriented model for geographical data is defined and the symbolic features used in the PQL are described. The algebra operators are formally defined, besides their properties and applicability. The use of the symbolic features to express the queries is illustrated, as well as the possible pictorial operations are considered. The used interface is part of the Scenario GIS, developed using an object-oriented environment. This PQL makes easier the formulation of a complex query and simplifies user approach to the system, maintaining a strong expressive power. Finally, an example of query and its pictorial composition on the screen is shown.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Pooley R,Wilcox P","Pooley R,Wilcox P",Chapter 3 - Where's the UML going?,,2004,,,39-48,,Butterworth-Heinemann,Oxford,Applying UML,2004,9780750656832,,https://www.sciencedirect.com/science/article/pii/B9780750656832500036;http://dx.doi.org/10.1016/B978-075065683-2/50003-6,10.1016/B978-075065683-2/50003-6,"Publisher Summary This chapter reviews the development of the unified modeling language (UML) notation. The chapter considers the “advanced features” of the UML, for example, “profiles” and “extensions.” It provides a brief history of the evolution of the UML and describes how it is changing and what can be expected in the future. Object orientation began as a feature within programming languages, notably SIMULA 67, which introduced the idea of classes and instances as a way of encapsulating data structures, along with inheritance as a mechanism for generalization. This was formally referred to as “data abstraction.” The appearance and popularity of programming languages, such as Smalltalk and C++, created a need for appropriate design languages within the developing community of OO programmers. By the mid-1990s, new versions began to appear—namely, Booch's methodology, object modeling technique (OMT) and object-oriented software engineering (OOSE). Two major contributions to the UML in the form of incorporation of pre-existing modeling views include “sequence diagrams” and “statecharts.” The efforts of Booch, Rumbaugh, and Jacobson resulted in the release of the UML 0.9 and 0.91 documents in June and October of 1996. The development of further versions of the UML standard is a result of the combined efforts of an Object Management Group (OMG) committee, which includes representatives of various companies including Rational (now owned by IBM), who maintain a keen interest in developments. The key features such as object constraint language (OCL), action semantics, and profile, aim to add to the expressiveness of UML. In mid-2001 OMG members started work on a major upgrade that was intended to lead to UML 2.0..",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li Q,Smith G",,Formal development of multi-agent systems using MAZE,Science of Computer Programming,2016,131,,126-150,,,,,2016,,0167-6423,https://www.sciencedirect.com/science/article/pii/S016764231630017X;http://dx.doi.org/10.1016/j.scico.2016.04.008,10.1016/j.scico.2016.04.008,"MAZE is an extension of the Object-Z specification language supporting the specification and development of multi-agent systems (MAS). Following recommendations from the agent-oriented software engineering community, it supports three distinct levels of abstraction: (i) the macro level which focusses on the system's overall, global behaviour, independently of how the agents of the system operate and interact, (ii) the meso level which focusses on agent interactions, and (iii) the micro level which focusses on the operation of individual agents. Object-Z's high-level support for component-based specification, which is well suited to modelling MAS, is complemented in MAZE with support for action refinement to facilitate the top-down development process from the macro to micro level, and with a number of syntactic conventions aimed at abstractly specifying the low-level mechanisms required for dealing with asynchronous communication and timing constraints at the micro level. The latter are shorthands for existing Object-Z notation and so require no redefinition of Object-Z's semantics. In this paper, we provide an overview of MAZE and illustrate its use on a non-trivial case study: a swarm robotic algorithm for self-assembly.","Formal modelling, Object-Z, Refinement, Multi-agent systems","Abstract State Machines, Alloy, B, TLA, VDM and Z (ABZ 2014)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Basile F,Chiacchio P,Del Grosso D",,A two-stage modelling architecture for distributed control of real-time industrial systems: Application of UML and Petri Net,Computer Standards & Interfaces,2009,31,3,528-538,,,,,2009,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548908000391;http://dx.doi.org/10.1016/j.csi.2008.03.021,10.1016/j.csi.2008.03.021,"The use of UML in the design process of distributed automation systems is here proposed. UML is used to formally express system's requirements, model the uncontrolled system and design the controlled one. It is here proposed a domain transformation: to go from the informal description to UML and from UML to PN models. In this way the capability to describe the system behavior is fully exploited, while the system analysis can be more properly performed in PN domain. Furthermore, it is to show the possibility of conferring intelligence to real objects, even to immaterial objects, so that they can cooperate to fulfil the desired tasks in a distributed plant. To illustrate the methodology a real case study is used.","UML, Petri Net, Object-Oriented paradigm, Industrial automation",Industrial Networking Standards for Real-time Automation and Control,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kamandi A,Abdollahi Azgomi M,Movaghar A",,Transformation of UML Models into Analyzable OSAN Models,Electronic Notes in Theoretical Computer Science,2006,159,,3-22,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106002714;http://dx.doi.org/10.1016/j.entcs.2005.12.059,10.1016/j.entcs.2005.12.059,"The unified modelling language (UML) is a de facto standard for object-oriented modelling. However, the formal semantics for the notations included in UML are not provided, which are a key requirement for the verification and evaluation purposes. To solve this problem, Petri net formalism has been used as a complement to UML in several research projects. However, there is not a complete transformation technique for all concepts and diagrams of UML to an extension of Petri nets. We have recently introduced object stochastic activity networks (OSANs). OSANs are a high-level modelling formalism that integrates object-orientation into stochastic activity networks (SANs). In this paper, we present some transformation techniques for the most important concepts and diagrams of UML into OSANs. The resulting OSAN models can be used for both evaluation and verification purposes.","Unified Modeing Language (UML), Object Stochastic Activity Networks (OSANs), Evaluation, Verification",Proceedings of the First IPM International Workshop on Foundations of Software Engineering (FSEN 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Aït-Kaci H,Podelski A",,Towards a meaning of life,The Journal of Logic Programming,1993,16,3,195-234,,,,,1993,,0743-1066,https://www.sciencedirect.com/science/article/pii/074310669390043G;http://dx.doi.org/10.1016/0743-1066(93)90043-G,10.1016/0743-1066(93)90043-G,"LIFE is an experimental programming language proposing to integrate three orthogonal programming paradigms proven useful for symbolic computation. From the programmer's standpoint, it may be perceived as a language taking after logic programming, functional programming, and object-oriented programming. From a formal perspective, it may be seen as an instance (or rather, a composition of three instances) of a Constraint Logic Programming scheme due to Höhfeld and Smolka refining that of Jaffar and Lassez. We start with an informal overview demonstrating LIFE as a programming language, illustrating how its primitives offer rather unusual, and perhaps (pleasantly) startling, conveniences. The second part is a formal account of LIFE's object unification seen as constraint-solving over specific domains. We build on work by Smolka and Rounds to develop type-theoretic, logical, and algebraic renditions of a calculus or order-sorted feature approximations.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Ihme T,"Zedan H,Cau A",6 - Object-Oriented Development Of X-Ray Spectrometer Software,,1999,,,77-90,,Woodhead Publishing,,Object-Oriented Technology and Computing Systems Re-engineering,1999,9781898563563,,https://www.sciencedirect.com/science/article/pii/B9781898563563500109;http://dx.doi.org/10.1533/9781782420613.77,10.1533/9781782420613.77,"Embedded computer systems, incorporated in various types of products and systems, are common in a wide range of everyday commodities as well as industrial and scientific equipment. In connection with the increasing use of object-oriented methodologies in the development of real-time computer systems, better means are provided for reusable embedded software architectures and components, as well. Yet, there is still no large-scale application and routine utilisation of commercial object-oriented technology in the development of hard real-time embedded software. Commercial object-oriented technology usually has to be tailored to the specific characteristics and needs of individual embedded computer system domains. This paper is concerned with the object-oriented development process of scientific on-board X-ray spectrometer control software. It discusses the experiences gained through the utilisation of object-oriented real-time methods and tools based on OMT (Object Modelling Technique), MSC (Message Sequence Charts) and formal SDL (Specification and Description Language) notations.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Quer C,Olivé A",,Determining object interaction in object-oriented deductive conceptual models,Information Systems,1994,19,3,211-227,,,,,1994,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437994900426;http://dx.doi.org/10.1016/0306-4379(94)90042-6,10.1016/0306-4379(94)90042-6,"We present the main components of an object-oriented deductive approach to conceptual modelling of information systems. This approach does not model object interaction explicitly. However, interaction among objects can be derived by means of a formal procedure that we outline. Based on our results, we discuss whether explicit object interaction is a desirable feature of conceptual models.","Conceptual modelling, deductive conceptual models, object-orientation",Fifth International Conference on Advanced Information Systems Engineering (CAISE '93),,,,,,,,,,,,,,,,,,,,
Journal Article,"Nestmann U,Hüttel H,Kleist J,Merro M",,Aliasing Models for Mobile Objects,Information and Computation,2002,175,1,3-33,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540101931049;http://dx.doi.org/10.1006/inco.2001.3104,10.1006/inco.2001.3104,"In Obliq, a lexically scoped, distributed, object-oriented programming language, object migration was suggested as the creation of a copy of the state of an object at the target site, followed by turning the object itself into an alias, also called surrogate, for the remote copy. We consider the creation of object surrogates as an abstraction of the above-mentioned style of migration. We introduce Øjeblik, a typed distribution-free subset of Obliq, and provide four different configuration-style semantics, which only differ in the respective aliasing model. We show that two of the semantics, one of which matches Obliq's implementation, render migration unsafe, while our new proposal allows for safe migration at least for a large class of program contexts. In addition, we propose a type system that allows a programmer to statically guarantee that programs belong to that class. Our work suggests a straightforward repair of Obliq's aliasing model.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chen Z,Liu Z,Ravn AP,Stolz V,Zhan N",,Refinement and verification in component-based model-driven design,Science of Computer Programming,2009,74,4,168-196,,,,,2009,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642308000890;http://dx.doi.org/10.1016/j.scico.2008.08.003,10.1016/j.scico.2008.08.003,"Modern software development is complex as it has to deal with many different and yet related aspects of applications. In practical software engineering this is now handled by a UML-like modelling approach in which different aspects are modelled by different notations. Component-based and object-oriented design techniques are found effective in the support of separation of correctness concerns of different aspects. These techniques are practised in a model-driven development process in which models are constructed in each phase of the development. To ensure the correctness of the software system developed, all models constructed in each phase are verifiable. This requires that the modelling notations are formally defined and related in order to have tool support developed for the integration of sophisticated checkers, generators and transformations. This paper summarises our research on the method of Refinement of Component and Object Systems (rCOS) and illustrates it with experiences from the work on the Common Component Modelling Example (CoCoME). This gives evidence that the formal techniques developed in rCOS can be integrated into a model-driven development process and shows where it may be integrated in computer-aided software engineering (CASE) tools for adding formally supported checking, transformation and generation facilities.","Formal methods, Multi-view modelling, rCOS, Software design process, Tool design, UML",Special Issue on the Grand Challenge,,,,,,,,,,,,,,,,,,,,
Journal Article,"Allende E,Callaú O,Fabry J,Tanter É,Denker M",,Gradual typing for Smalltalk,Science of Computer Programming,2014,96,,52-69,,,,,2014,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642313001445;http://dx.doi.org/10.1016/j.scico.2013.06.006,10.1016/j.scico.2013.06.006,"Being able to combine static and dynamic typing within the same language has clear benefits in order to support the evolution of prototypes or scripts into mature robust programs. While being an emblematic dynamic object-oriented language, Smalltalk is lagging behind in this regard. We report on the design, implementation and application of Gradualtalk, a gradually-typed Smalltalk meant to enable incremental typing of existing programs. The main design goal of the type system is to support the features of the Smalltalk language, like metaclasses and blocks, live programming, and to accommodate the programming idioms used in practice. We studied a number of existing projects in order to determine the features to include in the type system. As a result, Gradualtalk is a practical approach to gradual types in Smalltalk, with a novel blend of type system features that accommodate most programming idioms.","Type systems, Gradual typing, Smalltalk",Special issue on Advances in Smalltalk based Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,Wolf G,,Schedule management: An object oriented approach,Decision Support Systems,1994,11,4,373-388,,,,,1994,,0167-9236,https://www.sciencedirect.com/science/article/pii/0167923694900825;http://dx.doi.org/10.1016/0167-9236(94)90082-5,10.1016/0167-9236(94)90082-5,"In this paper we discuss the design of decision support systems, usable in several planning situations. We consider resource-constrained time-dependent scheduling problems with time as the important planning component. Instead of dealing with optimization aspects of the planning problem, we concentrate on schedule management, i.e. stepwise planning with respect to primitive functions, like handling single decisions or constraints. The design of these systems is based on a mathematical model, giving a formal characterization of a class of scheduling problems and allowing generic descriptions of scheduling objects like processors, operations, decisions and constraints. The model is applied to various scheduling problems, like resource constrained project scheduling, car routing, the construction of time tables both for schools and for nursery in hospitals. An object oriented implementation of the model, based on the natural hierarchy of scheduling problems, turns out to lead to a clear separation between the generic and the domain specific components of the schedule manager, minimizing redundant code and resulting in software with a high degree of maintainability.","Decision support system, Scheduling, Object oriented design",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lau HY,Mak KL",,A development framework for supervisory control software of automated manufacturing systems,IFAC Proceedings Volumes,1999,32,2,385-390,,,,,1999,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017560668;http://dx.doi.org/10.1016/S1474-6670(17)56066-8,10.1016/S1474-6670(17)56066-8,"The performance of automated manufacturing system (AMS) relies heavily on the quality of their supervisory control software. This paper presents a methodology that provides an object-oriented framework for the development and verification of supervisory control software for automated manufacturing systems. Such a framework consists of five well-defined milestones to quantify software production, refinement procedures to guide the overall software development process, and software models and procedures for software verification. The objective is to ensure efficient production of high quality supervisory control software for AMSs. The effectiveness of the framework is illustrated by using a case example concerning the development of supervisory control software for a flexible manufacturing system.","Manufacturing systems, system methodology, object-oriented programming, software specification, verification, system design, formal methods","14th IFAC World Congress 1999, Beijing, Chia, 5-9 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Houari T,Jean-Claude C",,An Object Language with States: SOL,IFAC Proceedings Volumes,1998,31,4,47-52,,,,,1998,,1474-6670,https://www.sciencedirect.com/science/article/pii/S147466701742132X;http://dx.doi.org/10.1016/S1474-6670(17)42132-X,10.1016/S1474-6670(17)42132-X,"Synchronous reactive systems continually react with their environment. Based on formal hypothesis and complete semantics, this approach brings rigor and flexibility. The aim of some research is to specify a common code which can be used as an intermediate code or gateway for the present synchronous languages, this paper is consistent with this spirit. SOL (State Object Language) is proposed and its concepts are presented. From an object code of synchronous language, the equivalent SOL program is generated. The result is a clean program with a high abstraction level, this allows the application evolution and maintenance in an incremental way.","object-oriented programming, synchronous theory, finite automata, states, statecharts","5th IFAC Workshop on Algorithms & Architecture for Real Time Control (AARTC'98), Cancun, Mexico, 15-17 April 1998",,,,,,,,,,,,,,,,,,,,
Journal Article,Saake G,,Descriptive specification of database object behaviour,Data & Knowledge Engineering,1991,6,1,47-73,,,,,1991,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9190015P;http://dx.doi.org/10.1016/0169-023X(91)90015-P,10.1016/0169-023X(91)90015-P,"Traditional database design methodologies are not appropriate for the specific requirements of object-oriented database systems and new database application areas. Apart from semantic complications arising from object-oriented database structures with complex objects, arbitrary data types as attribute domains, or generalization hierarchies, specification and semantics of dynamic database behaviour has to be of main interest for typical object-oriented applications, too. We propose the use of a temporal logic as a specification language for dynamic object behaviour and point out the formal semantics of such database dynamics specifications. A layered conceptual database design methodology is presented together with a discussion on design support techniques for behaviour specifications. Finally, implementation aspects are treated.","Database specification, Object-oriented databases, Conceptual schema, Database integrity, Temporal constraints, Object behaviour, Temporal logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bogusch R,Marquardt W",,A formal representation of process model equations,Computers & Chemical Engineering,1995,19,,211-216,,,,,1995,,0098-1354,https://www.sciencedirect.com/science/article/pii/0098135495870385;http://dx.doi.org/10.1016/0098-1354(95)87038-5,10.1016/0098-1354(95)87038-5,"The lack of adequate support for the development of mathematical process models confines the application of model—based techniques in the design and operation of complex chemical processes. To overcome this problem considerable effort has to be put in the development of knowledge—based software tools. The development of such tools requires a proper structuring of process models followed by a formalization of their representation. In this contribution, elementary modeling objects for the representation of the behavioral aspects of chemical processes are defined. The introduced methodology and its formalization in terms of the object—oriented data model VeDa allows the representation of the mixed types of equations and formalisms arising in mathematical process models. It provides generality and extensibility since new types of equations or formalisms can be incorporated easily.","Process models, computer—aided modeling object—oriented representation.",European Symposium on Computer Aided Process Engineering\3-5,,,,,,,,,,,,,,,,,,,,
Journal Article,Garcia HE,,A hierarchical platform for implementing hybrid systems in process control,Control Engineering Practice,1997,5,6,779-789,,,,,1997,,0967-0661,https://www.sciencedirect.com/science/article/pii/S0967066197000622;http://dx.doi.org/10.1016/S0967-0661(97)00062-2,10.1016/S0967-0661(97)00062-2,"This paper describes a development platform for the description, analysis and implementation of real-time control systems, consisting of a mixture of continuous and discrete components. Hybrid and discrete-event system techniques are used for formally defining the control and supervisory system requirements. These requirements result from functional characteristics specified for the process to be controlled. Based on the specifications, a series of control components belonging to a finite set of object classes is defined and arranged in a hierarchical architecture. The hierarchical topology is a simple tree, where any component has a single parent. Object-oriented technologies are used to implement the notion of component classes. With this formal description of process functionality, a computer software generator interprets the control specifications and produces executable control software. This software reacts to environmental responses by executing the supervisory and control actions required to achieve the desired process behavior. The paper only describes the conceptual idea of the proposed control development platform in a general manner. As an example, an application of this platform is presented for developing the control software for a production process that converts metallic sodium from nuclear reactors to sodium carbonate for safe waste disposal.","Hybrid systems, discrete-event, hierarchical systems, object-oriented application",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Igarashi A,Kobayashi N",,Type Reconstruction for Linear π-Calculus with I/O Subtyping,Information and Computation,2000,161,1,1-44,,,,,2000,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540100928724;http://dx.doi.org/10.1006/inco.2000.2872,10.1006/inco.2000.2872,"Powerful concurrency primitives in recent concurrent languages and thread libraries provide great flexibility about implementation of high-level features like concurrent objects. However, they are so low-level that they often make it difficult to check global correctness of programs or to perform nontrivial code optimization, such as elimination of redundant communication. In order to overcome those problems, advanced type systems for input-only/output-only channels and linear (use-once) channels have been recently studied, but the type reconstruction problem for those type systems remained open, and therefore, their applications to concurrent programming languages have been limited. In this paper, we develop type reconstruction algorithms for variants of Kobayashi, Pierce, and Turner's linear channel type system with Pierce and Sangiorgi's subtyping based on input-only/output-only channel types and prove correctness of the algorithms. To our knowledge, no complete type reconstruction algorithm has been previously known for those type systems. We have implemented one of the algorithms and incorporated it into the compiler of the concurrent language HACL. This paper also shows some experimental results on the algorithm and its application to compile-time optimizations.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Beeri C,Nasr R,Tsur S","Beeri C,Schmidt JW,Dayal U",Embedding ψ-terms in a Horn-clause Logic Language,,1988,,,347-359,,Morgan Kaufmann,,Proceedings of the Third International Conference on Data and Knowledge Bases,1988,9781483213132,,https://www.sciencedirect.com/science/article/pii/B9781483213132500330;http://dx.doi.org/10.1016/B978-1-4832-1313-2.50033-0,10.1016/B978-1-4832-1313-2.50033-0,"This paper proposes the reconciliation of a number of notions, typically associated with object-oriented languages, with a Horn-clause logic language. In particular, typing, support of inheritance and type-subtype relationships can be introduced using ψ-terms. The paper includes a brief description of LDL - an extended Horn-clause logic language for knowledge intensive applications, a description of ψ-terms and a demonstration that these notions can be combined within the model-based semantics of LDL. The paper further proposes a way by which methods may be introduced using ψ-terms and it concludes by a discussion of update issues in this combined logic/object-oriented environment.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Ferrarini L,,Reference Models to Design Automation System for Manufacturing Lines,IFAC Proceedings Volumes,2001,34,17,93-98,,,,,2001,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017332627;http://dx.doi.org/10.1016/S1474-6670(17)33262-7,10.1016/S1474-6670(17)33262-7,"The problem of the design of the control system functions for automated manufacturing lines is addressed. In particular, a modeling framework is proposed which is based on proper hierarchical composition, formal representations, and compliance with international control standards for logic control. The object-oriented modeling technique has been exploited for the definition of two basic reference models, one for the plant to be controlled and one for the control functions. The results here proposed are particularly useful in the perspective of the design process. The paper shows the application of such concepts to an industrial serigraph line for glasses.","Manufacturing systems, sequential control, object modeling techniques, control system design, simulation","10th IFAC Symposium on Information Control Problems in Manufacturing (INCOM 2001), Vienna, Austria, 20-22 September 2001",,,,,,,,,,,,,,,,,,,,
Journal Article,"Jorng-Tzong H,Baw-Jhiune L",,Some aspects of operations in an object-oriented data base based on graphs,Journal of Systems and Software,1994,24,2,155-179,,,,,1994,,0164-1212,https://www.sciencedirect.com/science/article/pii/0164121294900779;http://dx.doi.org/10.1016/0164-1212(94)90077-9,10.1016/0164-1212(94)90077-9,"Object-oriented data base operators have been extensively studied in recent years. In this article we attempt to enhance the set of operators and define them in a more formal way based on graphs. We adopt directed acyclic graphs to model object-oriented data bases. The operators are defined by graph transformations. Based on this graph-theoretic approach, a family of operators on graphs are defined as the basic operators for object-oriented data bases. Moreover, many applications of graphs, such as matching problems, are used to enhance the set of operators on object-oriented data bases. We can use this kind of operator to implement certain queries that are adequate for new application domains such as decision support systems. We also develop a set of schema-restructuring operators which can be used to integrate individual schemas. The integration presents users with a logically integrated global view of the data stored in the individual schemas without requiring that the schemas be physically integrated. We use a query language based on SMALLTALK-like messages. Queries will be implemented by translating the queries into our defined operators, which are then interpreted.",,Object-orientation in Info. Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Her JS,Yuan H,Kim SD",,Traceability-centric model-driven object-oriented engineering,Information and Software Technology,2010,52,8,845-870,,,,,2010,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584910000601;http://dx.doi.org/10.1016/j.infsof.2010.03.012,10.1016/j.infsof.2010.03.012,"Context Object-oriented (OO) development method is a popular paradigm in developing target systems. However, the current practices of OO analysis and design (OOAD) and implementation largely rely on human developers’ experience and expertise, making it possible less efficient and more error-prone. Hence, there is room for improving the development efficiency while preserving high quality of programs. Objective Model-driven development (MDD) is a promising approach to developing programs by machine-assisted model transformation, saving human efforts and reducing the possibility of introducing program faults. Hence, it is appealing to apply key disciplines of MDD in developing OO programs. Method In this paper, we propose a comprehensive framework for applying MDD on OO program engineering in a rigorous and formal fashion. The framework consists of: (1) a hybrid engineering model of human and machine, (2) meta-models of OOAD artifacts, (3) traceability map with trace links, and (4) transformation rules. Results We identified five platform independent models and two platform specific models, and defined formal representations for them. We identified 16 traceability links and accordingly 16 transformation rules among the eight artifacts. Through the case study, we showed that our work is feasible and applicable. We assessed our work and concluded that our work is sound, complete, and extendable. Our work established the foundation toward automatic generation of OO programs based on the traceability framework. Conclusion It is concluded that it is essential to identify the OOAD artifacts, traceability links, and transformation rules for automatic generation of OO programs. It is also important to understand the human involvement nature in MDD and to explicitly treat them in the model transformation.","Traceability, Object-orientation, Model-driven, Transformation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Tsuiki H,,A domain-theoretic semantics of lax generic functions,Theoretical Computer Science,2003,294,1,307-331,,,,,2003,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397501002468;http://dx.doi.org/10.1016/S0304-3975(01)00246-8,10.1016/S0304-3975(01)00246-8,"The semantic structure of a polymorphic calculus λm is studied. λm is defined over a hierarchical type structure, and a function in this calculus, called a generic function, can be composed from more than one lambda expression and the ways it behaves on each type are weakly related in that it lax commutes with the coercion functions defined from the subtypes to the supertypes. Since laxness is intermediate between ad hocness (behaviors on each type are not related) and coherency (commuting with the coercion functions), λm has syntactic properties lying between those of calculi with ad hoc generic functions and coherent generic functions studied in Tsuiki (Math. Struct. Comput. Sci. 8 (1998) 321). That is, although λm allows self application and thus is not normalizing, it does not have any unsolvable terms. For this reason, all the semantic domains are connected by mutually recursive equations and, at the same time, they do not have the least elements.We solve them by considering fibrations and expressing the equations as a recursive equation about fibrations. We also show the adequacy theorem for λm following the construction of Pitts and use it to derive some syntactic properties.","Overriding, Lax transformation, Fibration, Domain theory, Object oriented",Category Theory and Computer Science,,,,,,,,,,,,,,,,,,,,
Journal Article,"Žumer V,Korbar N,Mernik M",,Automatic implementation of programming languages using object oriented approach,Journal of Systems Architecture,1997,43,1,203-210,,,,,1997,,1383-7621,https://www.sciencedirect.com/science/article/pii/S1383762196001014;http://dx.doi.org/10.1016/S1383-7621(96)00101-4,10.1016/S1383-7621(96)00101-4,"We present our implementation of a tool for automatic language implementation. From formal language definition, Language Implementation System based on Attribute Grammars (LISA) produces an interpreter or a compiler for the defined language. We describe the development of the tool. It is one of the first such tools developed using the object oriented technology and is coded in the C+ + programming language.","Programming languages, Automatic compiler generation, Syntax, Semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Koo SR,Son HS,Seong PH",,A method of formal requirement analysis for NPP I&C systems based on UML modeling with software cost reduction,Journal of Systems and Software,2003,67,3,213-224,,,,,2003,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121202001310;http://dx.doi.org/10.1016/S0164-1212(02)00131-0,10.1016/S0164-1212(02)00131-0,"In this work, a formal requirement analysis method for Nuclear Power Plant (NPP) instrumentation and control (I&C) systems is suggested. This method uses unified modeling language (UML) for modeling a system visually and software cost reduction (SCR) for formally verifying the system. Since object-oriented methods enable us to analyze problems in terms of the objects in a real system, UML models are useful for understanding the problems and communicating with people involved in a project. In order to analyze problems more formally, SCR is used and the UML models are converted into SCR tabular notations. This work tries to acquire the flow-through from UML models to SCR specifications by suggesting additional syntactic extensions for UML notation and a converting procedure. The proposed method has been applied to a dynamic safety system (DSS) and inadequate core cooling monitoring system (ICCMS), which are parts of a NPP I&C system. Through these applications, some errors have been detected in the existing system requirements. Furthermore, in this work, through the comparison of our proposed method with the conventional inspection, we conclude that our method can complement the limitations of the inspection, which suffers from lack of detectability.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"De Giacomo G,Felli P,Logan B,Patrizi F,Sardiña S",,Situation Calculus for Controller Synthesis in Manufacturing Systems with First-Order State Representation,Artificial Intelligence,2021,,,103598,,,,,2021,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370221001491;http://dx.doi.org/10.1016/j.artint.2021.103598,10.1016/j.artint.2021.103598,"Manufacturing is transitioning from a mass production model to a service model in which facilities ‘bid’ to produce products. To decide whether to bid for a complex, previously unseen product, a facility must be able to synthesize, on the fly, a process plan controller that delegates abstract manufacturing tasks in a supplied process recipe to the available manufacturing resources. Often manufacturing processes depend on the data and objects (parts) they produce and consume. To formalise this aspect we need to adopt a first-order representation of the state of the processes. First-order representations of the state are commonly considered in reasoning about action in AI, and here we show that we can leverage the wide literature on the Situation Calculus and ConGolog programs to formalise this kind of manufacturing. With such a formalization available, we investigate how to synthesize process plan controllers in this first-order state setting. We also identify two important decidable cases—finite domains and bounded action theories—for which we provide techniques to actually synthesize the controller.","reasoning about actions, situation calculus, automated synthesis, smart manufacturing",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shatnawi A,Seriai AD,Sahraoui H",,Recovering software product line architecture of a family of object-oriented product variants,Journal of Systems and Software,2017,131,,325-346,,,,,2017,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121216301327;http://dx.doi.org/10.1016/j.jss.2016.07.039,10.1016/j.jss.2016.07.039,"Software Product Line Engineering (SPLE) aims at applying a pre-planned systematic reuse of large-grained software artifacts to increase the software productivity and reduce the development cost. The idea of SPLE is to analyze the business domain of a family of products to identify the common and the variable parts between the products. However, it is common for companies to develop, in an ad-hoc manner (e.g. clone and own), a set of products that share common services and differ in terms of others. Thus, many recent research contributions are proposed to re-engineer existing product variants to a software product line. These contributions are mostly focused on managing the variability at the requirement level. Very few contributions address the variability at the architectural level despite its major importance. Starting from this observation, we propose an approach to reverse engineer the architecture of a set of product variants. Our goal is to identify the variability and dependencies among architectural-element variants. Our work relies on formal concept analysis to analyze the variability. To validate the proposed approach, we evaluated on two families of open-source product variants; Mobile Media and Health Watcher. The results of precision and recall metrics of the recovered architectural variability and dependencies are 81%, 91%, 67% and 100%, respectively.","Software reuse, Software architecture recovery, Software product line, Object-oriented product variants, Software component, Formal concept analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,Wezeman CD,,Using Z for network modelling: An industrial experience report,Computer Standards & Interfaces,1995,17,5,631-638,,,,,1995,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899500017O;http://dx.doi.org/10.1016/0920-5489(95)00017-O,10.1016/0920-5489(95)00017-O,"As telecommunication and computing networks have grown in size and complexity, so has the scale of the problems encountered when modelling them. This paper demonstrates a new method for modelling network components from a network management viewpoint. The method, which was developed by BT, uses an object oriented variant of the formal description technique Z. As a result of its development and successful application, the international standardization organization ITU has now adopted Z for specification of network components.","Formal methods, Formal specification, Network management, Object orientation, Standards, Z",Formal Description Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,"Allen SF,Bickford M,Constable RL,Eaton R,Kreitz C,Lorigo L,Moran E",,Innovations in computational type theory using Nuprl,Journal of Applied Logic,2006,4,4,428-469,,,,,2006,,1570-8683,https://www.sciencedirect.com/science/article/pii/S1570868305000704;http://dx.doi.org/10.1016/j.jal.2005.10.005,10.1016/j.jal.2005.10.005,"For twenty years the Nuprl (“new pearl”) system has been used to develop software systems and formal theories of computational mathematics. It has also been used to explore and implement computational type theory (CTT)—a formal theory of computation closely related to Martin-Löf's intuitionistic type theory (ITT) and to the calculus of inductive constructions (CIC) implemented in the Coq prover. This article focuses on the theory and practice underpinning our use of Nuprl for much of the last decade. We discuss innovative elements of type theory, including new type constructors such as unions and dependent intersections, our theory of classes, and our theory of event structures. We also discuss the innovative architecture of Nuprl as a distributed system and as a transactional database of formal mathematics using the notion of abstract object identifiers. The database has led to an independent project called the Formal Digital Library, FDL, now used as a repository for Nuprl results as well as selected results from HOL, MetaPRL, and PVS. We discuss Howe's set theoretic semantics that is used to relate such disparate theories and systems as those represented by these provers.","Martin-Löf type theory, Dependent intersection types, Union types, Polymorphic subtyping, Logic of events, Formal digital libraries, Computational type theory, Proofs as programs, Program extraction, Tactics",Towards Computer Aided Mathematics,,,,,,,,,,,,,,,,,,,,
Journal Article,Patel-Schneider PF,,"Practical, object-based knowledge representation for knowledge-based systems",Information Systems,1990,15,1,9-19,,,,,1990,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799090013F;http://dx.doi.org/10.1016/0306-4379(90)90013-F,10.1016/0306-4379(90)90013-F,"Object-based knowledge representation systems are systems expressly designed for representing knowledge in the form of objects and classes. These systems derive their behavior from a formal specification of the meaning of objects and classes and, because of this firm representational foundation and their increased expressive power, are better suited for providing representation services for knowledge-based systems than are object-oriented programming systems. However, object-based knowledge representation systems are hard to implement correctly, and also suffer from tractability problems. These problems can be circumvented by using a weaker semantics, resulting in practical object-based knowledge representation systems for use in knowledge-based systems.",,Knowledge Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,Missikoff M,,An Object-oriented Approach to an Information and Decision Support System for Railway Traffic Control,Engineering Applications of Artificial Intelligence,1998,11,1,25-40,,,,,1998,,0952-1976,https://www.sciencedirect.com/science/article/pii/S0952197697000584;http://dx.doi.org/10.1016/S0952-1976(97)00058-4,10.1016/S0952-1976(97)00058-4,"The paper describes the analysis, design, and fast prototyping of MINT (Manager of Integrated Networks of Train traffic), an information and decision support system for railways traffic control. MINT is a complex system that tightly integrates information management and problem-solving functionalities, by means of an object-oriented approach. The work is characterized by several issues: (i) object-oriented analysis and design; (ii) knowledge-based application modeling, by means of a powerful conceptual language (TQL++); (iii) advanced search techniques in the problem-solving component; (iv) fast prototyping by the automatic generation of executable code; (v) use of an advanced knowledge-based modeling and prototyping environment (Mosaico). The paper starts with a description of the railway traffic control problem; then it focuses on the architecture of MINT, paying particular attention to the database component and its train conflict-solving capabilities. Finally, a few experimental results are reported.","Object-oriented information systems, decision support system, railway traffic control, formal specification, rapid prototyping",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Caltais G,Meyer B",,On the verification of SCOOP programs,Science of Computer Programming,2017,133,,194-215,,,,,2017,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642316301058;http://dx.doi.org/10.1016/j.scico.2016.08.005,10.1016/j.scico.2016.08.005,"In this paper we focus on the development of a unifying framework for the formal modeling of an object oriented-programming language, its underlying concurrency model and their associated analysis tools. More precisely, we target SCOOP – an elegant concurrency model, recently formalized based on Rewriting Logic (RL) and Maude. SCOOP is implemented in Eiffel and its applicability is demonstrated also from a practical perspective, in the area of robotics programming. Our contribution consists of devising and integrating an alias analyzer and a Coffman deadlock detector under the roof of the same RL-based semantic framework of SCOOP. This enables using the Maude rewriting engine and its LTL model-checker “for free,” in order to perform the analyses of interest. We discuss the limitations of our approach for model-checking deadlocks and provide possible workarounds for the state space explosion problem. On the aliasing side, we propose an extension of a previously introduced alias calculus based on program expressions, to the setting of unbounded program executions. Moreover, we devise a corresponding executable specification easily implementable on top of the SCOOP formalization. An important property of our extension is that, in non-concurrent settings, the corresponding alias expressions can be over-approximated in terms of a notion of regular expressions. This further enables us to derive an algorithm for computing a sound over-approximation of the “may aliasing” information, where soundness stands for the lack of false negatives.","SCOOP, Operational semantics, Alias analysis, Deadlock detection, Rewriting logic",Formal Techniques for Safety-Critical Systems (FTSCS 2014),,,,,,,,,,,,,,,,,,,,
Journal Article,"v. Bochmann G,Poirier S,Mondain-Monval P",,Object-oriented design for distributed systems: The OSI directory example,Computer Networks and ISDN Systems,1995,27,4,571-590,,,,,1995,,0169-7552,https://www.sciencedirect.com/science/article/pii/0169755293E0114T;http://dx.doi.org/10.1016/0169-7552(93)E0114-T,10.1016/0169-7552(93)E0114-T,"For an object-oriented design methodology to be effective, it is important to provide methods and tools for validating the design specification before going into the implementation phase. The paper proposes a design methodology and a related object-oriented specification language which allows the validation of specifications through simulated execution, or through automatic exhaustive simulation for a certain subset of the language. The paper also discusses the relation of this design methodology and language to other design methodologies which are in wide use, such as the entity-relationship model for databases, the ASN.1 notation used for Open Systems Interconnection (OSI) communication protocols, as well as methodologies used in the standardization committees for the elaboration and description of various kinds of distributed systems standards. It is shown how these different approaches can be integrated into a single methodology and language, using the OSI Directory System as an example, which is explained in certain detail.","Object-oriented analysis, Design methodologies, Entity-relationship modelling, Object behavior, Formal specifications, Abstract Syntax Notation 1 (ASN.1), Remote Operations (ROSE), Directory systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,Oliver Stehr M,,CINNI - A Generic Calculus of Explicit Substitutions and its Application to λ- ς- and π-Calculi,Electronic Notes in Theoretical Computer Science,2000,36,,70-92,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105801252;http://dx.doi.org/10.1016/S1571-0661(05)80125-2,10.1016/S1571-0661(05)80125-2,"We approach the general problem of representing higher-order languages, that are usually equipped with special variable binding constructs, in a less specialized first-order framework such as membership equational logic and the corresponding version of rewriting logic. The solution we propose is based on CINNI, a new calculus of explicit substitutions that makes use of a term representation that contains both the standard named notation and de Bruijn's indexed notation as special subcases. The calculus is parametric in the syntax of the object language, which allows us to apply it to different object languages such as λ-calculus, Abadi and Cardelli's object calculus (ς-calculus) and Milner's calculus of communicating mobile processes (π-calculus). As a practical result we obtain executable formal representations of these object languages in Maude with a representational distance close to zero.","Higher-Order Languages, Explicit Substitutions, Logical Frameworks, Rewriting Logic, Maude, Lambda-Calculus, Sigma-Calculus, Pi-Calculus",The 3rd International Workshop on Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hidders J,Kwasnikowska N,Sroka J,Tyszkiewicz J,Van den Bussche J",,DFL: A dataflow language based on Petri nets and nested relational calculus,Information Systems,2008,33,3,261-284,,,,,2008,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437907000634;http://dx.doi.org/10.1016/j.is.2007.09.002,10.1016/j.is.2007.09.002,"In this paper we propose DFL—a formal, graphical workflow language for dataflows, i.e., workflows where large amounts of complex data are manipulated, and the structure of the manipulated data is reflected in the structure of the workflow. It is a common extension of (1) Petri nets, which are responsible for the organization of the processing tasks, and (2) nested relational calculus, which is a database query language over complex objects, and is responsible for handling collections of data items (in particular, for iteration) and for the typing system. We demonstrate that dataflows constructed in a hierarchical manner, according to a set of refinement rules we propose, are semi-sound, i.e., initiated with a single token (which may represent a complex scientific data collection) in the input node, terminate with a single token in the output node (which represents the output data collection). In particular they never leave any “debris data” behind and an output is always eventually computed regardless of how the computation proceeds.","DFL, Petri net, Workflow system, Dataflow, Scientific workflow, Nested relational calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sheu PC,Sull W",,Knowledge management in deductive object bases,Data & Knowledge Engineering,1990,5,1,39-58,,,,,1990,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X90900329;http://dx.doi.org/10.1016/0169-023X(90)90032-9,10.1016/0169-023X(90)90032-9,"A deductive object base is a deductive database that is constructed based of an object data model. Using mathematical logic as formal representation, it can be constructed to support classification, aggregation, generalization, and association. It further extends existing databases with procedural semantics. In this paper we extended the framework of deductive object base with the constructs for meta-knowledge. To enhance the quality of knowledge, we also present a knowledge assimilation scheme based on the resolutional scheme.","Deductive database, Object-oriented database, Meta-knowledge, Query optimization, Concurrency control, Knowledge assimilation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aspinall D,Beringer L,Hofmann M,Loidl HW,Momigliano A",,A program logic for resources,Theoretical Computer Science,2007,389,3,411-445,,,,,2007,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397507006627;http://dx.doi.org/10.1016/j.tcs.2007.09.003,10.1016/j.tcs.2007.09.003,"We introduce a reasoning infrastructure for proving statements about resource consumption in a fragment of the Java Virtual Machine Language (JVML). The infrastructure is based on a small hierarchy of program logics, with increasing levels of abstraction: at the top there is a type system for a high-level language that encodes resource consumption. The infrastructure is designed to be used in a proof-carrying code (PCC) scenario, where mobile programs can be equipped with formal evidence that they have predictable resource behaviour. This article focuses on the core logic in our infrastructure, a VDM-style program logic for partial correctness, which can make statements about resource consumption alongside functional behaviour. We establish some important results for this logic, including soundness and completeness with respect to a resource-aware operational semantics for the JVML. We also present a second logic built on top of the core logic, which is used to express termination; it too is shown to be sound and complete. We then outline how high-level language type systems may be connected to these logics. The entire infrastructure has been formalized in Isabelle/HOL, both to enhance the confidence in our meta-theoretical results, and to provide a prototype implementation for PCC. We give examples to show the usefulness of this approach, including proofs of resource bounds on code resulting from compiling high-level functional programs.","Program logic, Proof-carrying-code, Object-oriented languages, Java virtual machine language, Cost modelling, Quantitative type-systems, Lightweight verification",Semantic and Logical Foundations of Global Computing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jagadeesan R,Jeffrey A,Riely J",,Typed parametric polymorphism for aspects,Science of Computer Programming,2006,63,3,267-296,,,,,2006,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642306001225;http://dx.doi.org/10.1016/j.scico.2006.02.008,10.1016/j.scico.2006.02.008,"We study the incorporation of generic types in aspect languages. Since advice acts like method update, such a study has to accommodate the subtleties of the interaction of classes, polymorphism and aspects. Indeed, simple examples demonstrate that current aspect compiling techniques do not avoid runtime type errors. We explore type systems with polymorphism for two models of parametric polymorphism: the type erasure semantics of Generic Java, and the type carrying semantics of designs such as generic C#. Our main contribution is the design and exploration of a source-level type system for a parametric OO language with aspects. We prove progress and preservation properties. We believe our work is the first source-level typing scheme for an aspect-based extension of a parametric object-oriented language.","Aspect-oriented programming, Typing, Generic types",Special issue on foundations of aspect-oriented programming,,,,,,,,,,,,,,,,,,,,
Journal Article,"Andrei O,Kirchner H",,A Port Graph Calculus for Autonomic Computing and Invariant Verification,Electronic Notes in Theoretical Computer Science,2009,253,4,17-38,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109004356;http://dx.doi.org/10.1016/j.entcs.2009.10.015,10.1016/j.entcs.2009.10.015,"From our previous work on biochemical applications, the structure of port graph (or multigraph with ports) and a rewriting calculus have proved to be well-suited formalisms for modeling interactions between proteins. Then port graphs have been proposed as a formal model for distributed resources and grid infrastructures, where each resource is modeled by a node with ports. The lack of global information and the autonomous and distributed behavior of components are modeled by a multiset of port graphs and rewrite rules which are applied locally, concurrently, and non-deterministically. Some computations take place wherever it is possible and in parallel, while others may be controlled by strategies. In this paper, we first introduce port graphs as graphs with multiple edges and loops, with nodes having explicit connection points, called ports, and edges attaching to ports of nodes. We then define an abstract biochemical calculus that instantiates to a rewrite calculus on these graphs. Rules and strategies are themselves port graphs, i.e. first-class objects of the calculus. As a consequence, they can be rewritten as well, and rules can create new rules, providing a way of modeling adaptive systems. This approach also provides a formal framework to reason about computations and to verify useful properties. We show how structural properties of a modeled system can be expressed as strategies and checked for satisfiability at each step of the computation. This provides a way to ensure invariant properties of a system. This work is a contribution to the formal specification and verification of adaptive systems and to theoretical foundations of autonomic computing.","Port graph, port graph rewriting, rewriting calculus, biochemical calculus, rewriting strategies, adaptive systems, autonomic computing, invariant verification",Proceedings of the Fifth International Workshop on Computing with Terms and Graphs (TERMGRAPH 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,Kurz A,,Specifying Coalgebras with Modal Logic,Electronic Notes in Theoretical Computer Science,1998,11,,56-70,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104000532;http://dx.doi.org/10.1016/S1571-0661(04)00053-2,10.1016/S1571-0661(04)00053-2,"We propose to use modal logic as a logic for coalgebras and discuss it in view of the work done on coalgebras as a semantics of object-oriented programming. Two approaches are taken: First, standard concepts of modal logic are applied to coalgebras. For a certain kind of functor it is shown that the logic exactly captures the notion of bisimulation and a complete calculus is given. Second, we discuss the relationship of this approach with the coalgebraic logic of Moss [6].",,"CMCS '98, First Workshop on Coalgebraic Methods in Computer Science",,,,,,,,,,,,,,,,,,,,
Journal Article,"Mok WY,Embley DW",,Using NNF to transform conceptual data models to object-oriented database designs,Data & Knowledge Engineering,1998,24,3,313-336,,,,,1998,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X97821088;http://dx.doi.org/10.1016/S0169-023X(97)82108-8,10.1016/S0169-023X(97)82108-8,"More work is needed on devising practical, but theoretically well-founded procedures for doing object-oriented database (OODB) design [17]. Design procedures should also be flexible enough to take into account various application characteristics (such as whether objects are very large or are read-only). In this paper, we present and discuss an OODB design procedure that addresses these problems. The procedure is practical in the sense that it is based on a common family of conceptual models and in the sense that it does not expect users to supply esoteric, difficult-to-discover, and hard-to-understand constraints (such as multivalued dependencies), nor does it make hard-to-check and easy-to-overlook assumptions (such as the universal relation scheme assumption). At the same time, the procedure is well-founded and formal, being based on NNF (Nested Normal Form [21]), a new theoretical result that characterizes properties of interest in designing complex objects. It is also adaptable to various applications characteristics.","Object-oriented database design, Conceptual modeling, Constraint extraction from conceptual models, Conceptual-model transformations, Scheme and method-signature generation, Design properties, Design adjustments",ER '96,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ghilezan S,Jakšić S,Pantović J,Scalas A,Yoshida N",,Precise subtyping for synchronous multiparty sessions,Journal of Logical and Algebraic Methods in Programming,2019,104,,127-173,,,,,2019,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220817302237;http://dx.doi.org/10.1016/j.jlamp.2018.12.002,10.1016/j.jlamp.2018.12.002,"This paper proves the soundness and completeness, together referred to as preciseness, of the subtyping relation for a synchronous multiparty session calculus. We address preciseness from operational and denotational viewpoints. The operational preciseness has been recently developed with respect to type safety, i.e., the safe replacement of a process of a smaller type in a context where a process of a bigger type is expected. The denotational preciseness is based on the denotation of a type: a mathematical object describing the meaning of the type, in accordance with the denotations of other expressions from the language. The main technical contribution of this paper is a novel proof strategy for the operational completeness of subtyping. We develop the notion of characteristic global type of a session type T, which describes a deadlock-free circular communication protocol involving all participants appearing in T. We prove operational completeness by showing that, if we place a process not conforming to a subtype of T in a context that matches the characteristic global type of T, then we obtain a deadlock. The denotational preciseness is proved as a corollary of the operational preciseness.","Concurrency, Process calculi, Multiparty session types, Subtyping",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Ishikawa Y,Tomura S,Futatsugi K",,The Semantics of an Object-Oriented Concurrent Programming Language: Process Algebraic Approach,,1992,3,,127-150,,Elsevier,,Japan Society for Software Science and Technology,1992,,1044-7997,https://www.sciencedirect.com/science/article/pii/B9780120371037500140;http://dx.doi.org/10.1016/B978-0-12-037103-7.50014-0,10.1016/B978-0-12-037103-7.50014-0,"Summary In this paper, the formal semantics of an object-oriented concurrent programming language called Mono is given. Mono is a model language that includes key features of object-oriented concurrent languages, e.g., synchronous and asynchronous message passing, delegation mechanism, and so on. A process algebra called ECCS, which is an extension of CCS, is introduced. The semantics of ECCS is defined by inference rules. The transformation function that transforms Mono into ECCS gives the formal semantics of Mono.",,,Advances in Software Science and Technology,,,,,,,,,,,,,,,,,,,
Journal Article,"Soloviev S,Luo Z",,Coercion completion and conservativity in coercive subtyping,Annals of Pure and Applied Logic,2001,113,1,297-322,,,,,2001,,0168-0072,https://www.sciencedirect.com/science/article/pii/S016800720100063X;http://dx.doi.org/10.1016/S0168-0072(01)00063-X,10.1016/S0168-0072(01)00063-X,"Coercive subtyping offers a general approach to subtyping and inheritance by introducing a simple abbreviational mechanism to constructive type theories. In this paper, we study coercion completion in coercive subtyping and prove that the formal extension with coercive subtyping of a type theory such as Martin–Löf's type theory and UTT is a conservative extension. The importance of coherence conditions for the conservativity result is also discussed.","Dependent types, Subtyping",First St. Petersburg Conference on Days of Logic and Computability,,,,,,,,,,,,,,,,,,,,
Journal Article,"Schewe KD,Turull-Torres JM",,Computable Queries for Object Oriented Databases,Electronic Notes in Theoretical Computer Science,2002,67,,296-312,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104805553;http://dx.doi.org/10.1016/S1571-0661(04)80555-3,10.1016/S1571-0661(04)80555-3,"A relational database can be considered as a finite structure for a finite relational signature in first-order logic, i.e., there are no function symbols. Interpreting the logic over this signature in such structures allows the expressiveness and complexity of queries to be studied in detail. This is the starting point for finite model theory which has proven to be a viable tool to study relational database theory. In particular, it is known that computable queries expressed as isomorphism-preserving partial recursive functions can be formalized by Reflective Relational Machines. These are extended Turing Machines with an additional relational store, a query tape and the facility to evaluate the query on the tape against the database in the store in a single step. In this paper we start to generalize the theory to post-relational databases. We first consider the case of having set-based complex values and references such that the semantics can still be expressed in finite sets. Following the approach that object oriented databases in general including those, where the underlying type systems does no longer allow the semantics defined by sets, can be expressed as theories in higher-order intuitionistic logic, we use such a logic instead of first-order logic. However, as we are not yet exploiting the full power of such logics, we can interpret the logic in the category FINSET of finite sets, i.e., again in a structure defined by a database. Having done this the definition of computable queries and the model of Reflective Relational Machines carry over easily. We can show that the new model of Reflective Object Machines guarantees completeness, i.e., all computable queries can be expressed by the model.","computable query, object oriented database, reflective machine, finite model theory","WoLLIC'2002, 9th Workhop on Logic, Language, Information and Computation",,,,,,,,,,,,,,,,,,,,
Journal Article,"Ölveczky PC,Meseguer J",,Recent Advances in Real-Time Maude,Electronic Notes in Theoretical Computer Science,2007,174,1,65-81,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107001545;http://dx.doi.org/10.1016/j.entcs.2006.10.020,10.1016/j.entcs.2006.10.020,"This paper gives an overview of recent advances in Real-Time Maude. Real-Time Maude extends the Maude rewriting logic tool to support formal specification and analysis of object-based real-time systems. It emphasizes ease and generality of specification and supports a spectrum of analysis methods, including symbolic simulation, unbounded and time-bounded reachability analysis, and LTL model checking. Real-Time Maude can be used to specify and analyze many systems that, due to their unbounded features, such as unbounded data structures or dynamic object and message creation, cannot be modeled by current timed/hybrid automaton-based tools. We illustrate this expressiveness and generality by summarizing two case studies: (i) an advanced scheduling algorithm with unbounded queues; and (ii) a state-of-the-art wireless sensor network algorithm. Finally, we give some (often easily checkable) conditions that ensure that Real-Time Maude's analysis methods are complete, also for dense time, for object-based real-time systems. In practice, our result implies that Real-Time Maude's time-bounded search and model checking of LTL time-bounded formulas are complete decision procedures for a large and useful class of non-Zeno real-time systems that fall outside the scope of systems that can be modeled in decidable fragments of hybrid automata, including the sensor network case study discussed in this paper.","formal analysis, real-time systems, rewriting logic, Maude, object-oriented specification, wireless sensor networks, completeness",Proceedings of the 7th International Workshop on Rule Based Programming (RULE 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Rees DL,Stephenson K,Tucker JV",,The algebraic structure of interfaces,Science of Computer Programming,2003,49,1,47-88,,,,,2003,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642303000327;http://dx.doi.org/10.1016/j.scico.2003.04.001,10.1016/j.scico.2003.04.001,"In this paper we examine formally the idea that the architecture of a system can be modelled by the structure of its interface expressed in terms of the interfaces for its components. Thus,SystemInterfaceArchitecture=StructuredsetofSub-systemInterfaces.We specify an abstract model for interface definition languages (IDLs) based on this idea and the idea that anInterface=Name+Imports+Body.A set of interfaces is a repository. An interface architecture is a repository with some primary interfaces identified; the import dependencies between the interfaces of a repository are used to determine its structure. The abstract model uses algebraic specifications to define the abstract syntax of a general IDL, and interface transformations using structural induction. We examine a flattening process which assembles a system interface from its components. We use the general model to derive a simple IDL suitable for the design phase of object-oriented software development. This requires us to specify a form of Body that treats both data types and state, and in Body we explicitly distinguish between methods with and without side-effects, by commands and queries, respectively. We also consider alternative proposals for Body that yield new IDLs, including other object-oriented design languages and data type specification languages.","Interface, Interface definition language, Imports, Flattening, Software architecture, Algebraic specification, Abstract syntax, Object-oriented architecture",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ölveczky PC,Meseguer J",,Abstraction and Completeness for Real-Time Maude,Electronic Notes in Theoretical Computer Science,2007,176,4,5-27,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107005105;http://dx.doi.org/10.1016/j.entcs.2007.06.005,10.1016/j.entcs.2007.06.005,"This paper presents criteria that guarantee completeness of Real-Time Maude search and temporal logic model checking analyses, under the maximal time sampling strategy, for a large class of real-time systems. As a special case, we characterize simple conditions for such completeness for object-oriented real-time systems, and show that these conditions can often be easily proved even for large and complex systems, such as advanced wireless sensor network algorithms and active network multicast protocols. Our results provide completeness and decidability of time-bounded search and model checking for a large and useful class of dense-time non-Zeno real-time systems far beyond the class of automaton-based real-time systems for which well known decision procedures exist. For discrete time, our results justify abstractions that can drastically reduce the state space to make search and model checking analyses feasible.","Rewriting logic, real-time systems, object-oriented specification, formal analysis, abstraction, completeness",Proceedings of the 6th International Workshop on Rewriting Logic and its Applications (WRLA 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Chudoba R,Butenweg C,Peiffer F",,Technical information system for collaborative material research,Advances in Engineering Software,2004,35,10,747-756,,,,,2004,,0965-9978,https://www.sciencedirect.com/science/article/pii/S096599780400095X;http://dx.doi.org/10.1016/j.advengsoft.2004.03.021,10.1016/j.advengsoft.2004.03.021,"This paper describes concepts used in the development of a technical information system for supporting collaborative material research of textile-reinforced concrete (TRC). The system has been set up by applying the modern theoretical concepts of software and database engineering to integrate the available open source tools in an effective way. The design is focused on the support of the activities such as experiment planning and analysis, calibration of material models and their subsequent validation. The technical information system works as a database-powered Internet server with a transparent definition of the product and process model. These models have been formally specified by using the Unified Modeling Language [UML distilled. A brief guide to the standard object modeling language (2003)] and implemented by defining class hierarchies and methods in an object-oriented database system employing the technique of object-relational mapping.","Product modeling, Software engineering, Database engineering, Material modeling, zModel calibration",Engineering Computational Technology,,,,,,,,,,,,,,,,,,,,
Journal Article,"Palanque P,Bastide R",,"Synergistic modelling of tasks, users and systems using formal specification techniques",Interacting with Computers,1997,9,2,129-153,,,,,1997,,0953-5438,https://www.sciencedirect.com/science/article/pii/S0953543897000131;http://dx.doi.org/10.1016/S0953-5438(97)00013-1,10.1016/S0953-5438(97)00013-1,"This paper aims at clarifying the articulation between the task models and system models encountered in CHI design practices. We demonstrate how the use of a formal task model may enhance the design of interactive systems, by providing quantitative results on which designers may base their decisions. We also demonstrate that it is possible to describe both task and system models within the same formal framework. This enables us firstly to formally prove that task and system models comply with each other, and secondly to perform quantitative analysis on the combination of task and system models. The approach is illustrated by a toy example which, despite its small size, allows us to develop both task and device models, and to perform several iterations of the design process. The device and tasks are modelled using the Interactive Cooperative Objects (ICO) formalism, which is based on Petri nets and on the object-oriented approach. The formality of Petri nets allows for axiomatic validation of isolated and interacting subsystems.","Interactive systems design, Task modelling, Performance evaluation, Formal specification, Petri nets",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Beeri C,Milo T",,Subtyping in OODBs,Journal of Computer and System Sciences,1995,51,2,223-243,,,,,1995,,0022-0000,https://www.sciencedirect.com/science/article/pii/S002200008571063X;http://dx.doi.org/10.1006/jcss.1995.1063,10.1006/jcss.1995.1063,"One of the central concepts supported by object-oriented databases is isa relationship. Its intuitive simplicity is deceptive. In reality, this term denotes several concepts, such as subtyping, subset relationships, and inheritance of structure and/or behavior. Each of these is non-trivial, and their interaction may be quite subtle. This paper deals with subtyping and its properties, in the context of a model that allows arbitrary data types and type constructors (but no function constructor). For simplicity a model based on the algebraic specification approach is used, which partially explains the inability to deal with the function constructor. Two intuitive ideas about subtyping are generalized and investigated: first, that the set of elements associated with a subtype is a subset of the set associated with supertype, and second, that each element of the subtype may be used in any place where an element of the supertype is expected. A generalized subtyping relation among abstract data types is defined, and its properties are investigated. In particular, it is shown that often there exist many possible subtyping relations among two types and that testing for some desirable properties, such as correctness, is in general undecidable. The notion of natural subtyping relation (that is related to parametric abstract data types) is introduced and shown to have a simple correctness proof. The paper concludes with a generalized type checking algorithm.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bergel A,Ducasse S,Nierstrasz O,Wuyts R",,Stateful traits and their formalization,"Computer Languages, Systems & Structures",2008,34,2,83-108,,,,,2008,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842407000140;http://dx.doi.org/10.1016/j.cl.2007.05.003,10.1016/j.cl.2007.05.003,"Traits offer a fine-grained mechanism to compose classes from reusable components while avoiding problems of fragility brought by multiple inheritance and mixins. Traits as originally proposed are stateless, that is, they contain only methods, but no instance variables. State can only be accessed within stateless traits by accessors, which become required methods of the trait. Although this approach works reasonably well in practice, it means that many traits, viewed as software components, are artificially incomplete, and classes that use such traits may contain significant amounts of boilerplate glue code. We present an approach to stateful traits that is faithful to the guiding principle of stateless traits: the client retains control of the composition. Stateful traits consist of a minimal extension to stateless traits in which instance variables are purely local to the scope of a trait, unless they are explicitly made accessible by the composing client of a trait. We demonstrate by means of a formal object calculus that adding state to traits preserves the flattening property: traits contained in a program can be compiled away. We discuss and compare two implementation strategies, and briefly present a case study in which stateful traits have been used to refactor the trait-based version of the Smalltalk collection hierarchy.","Traits, Mixin, Multiple-inheritance, Eiffel, Jigsaw, Flattening",Best Papers 2006 International Smalltalk Conference,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bonfè M,Fantuzzi C,Secchi C",,Verification of Fault Tolerance of Discrete-Event Object-Oriented Models using Model Checking,IFAC Proceedings Volumes,2008,41,2,5095-5100,,,,,2008,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016397518;http://dx.doi.org/10.3182/20080706-5-KR-1001.00856,10.3182/20080706-5-KR-1001.00856,"The Object-Oriented (O-O) approach has been recently used in the industrial automation to design logic control systems, thanks to the features of specification languages (e.g. UML) that can help to describe event-based behavioral requirements. In this paper, we aim to formalise an O-O framework for the design of modular logic controllers, in which faults occurring in the plant can alter the behavior of closed-loop system. Given the formal model of the system in terms of Kripke structures, it is possible to verify with model checking that even in case of faults the system do not violate given safety and liveness properties. Moreover, we will consider the case in which an O-O logic controller is refined applying the so-called “design-by-extension” mechanism, in which case it is important to verify that the fault tolerance property is inherited by the refined system.",,17th IFAC World Congress,,,,,,,,,,,,,,,,,,,,
Journal Article,Glew N,,Object Closure Conversion,Electronic Notes in Theoretical Computer Science,1999,26,,52-68,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580283X;http://dx.doi.org/10.1016/S1571-0661(05)80283-X,10.1016/S1571-0661(05)80283-X,"An integral part of implementing functional languages is closure conversion—the process of converting code with free variables into closed code and auxiliary data structures. Closure conversion has been extensively studied in this context, but also arises in languages with first-class objects. In fact, one variant of Java's inner classes are an example of objects that need to be closure converted, and the transformation for converting these inner classes into Java Virtual Machine classes is an example of closure conversion. This paper argues that a direct formulation of object closure conversion is interesting and gives further insight into general closure conversion. It presents a formal closure-conversion translation for a second-order object language and proves it correct. The translation and proof generalise to other object-oriented languages, and the paper gives some examples to support this statement. Finally, the paper discusses the well known connection between function closures and single-method objects. This connection is formalised by showing that an encoding of functions into objects, object closure conversion, and various object encodings compose to give various closure-conversion translations for functions.",,"HOOTS '99, Higher Order Operational Techniques in Semantics",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Kappel G,Schrefl M","Sol HG,Van Hee KM",USING AN OBJECT-ORIENTED DIAGRAM TECHNIQUE FOR THE DESIGN OF INFORMATION SYSTEMS,,1991,,,121-164,,North-Holland,Amsterdam,Dynamic Modelling of Information Systems,1991,9780444889232,,https://www.sciencedirect.com/science/article/pii/B9780444889232500082;http://dx.doi.org/10.1016/B978-0-444-88923-2.50008-2,10.1016/B978-0-444-88923-2.50008-2,Abstract An object-oriented diagram technique is introduced for the design of information systems. Structural properties of objects are depicted in object diagrams. Dynamic properties are shown in behaviour diagrams. Object diagrams are based on semantic data model concepts. Behaviour diagrams are based on Petri nets and model the life cycles of objects through a set of states (places) and activities (transitions). The relationship between Object/Behaviour diagrams and Predicate/Transition nets is shown. The semantics of Object/Behaviour diagrams is formally defined through a mapping into Predicate/Transition nets.,"Object/behaviour modeling, object/behaviour diagrams, predicate/transition nets",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Abadi M,Cardelli L",,A theory of primitive objects: Second-order systems,Science of Computer Programming,1995,25,2,81-116,,,,,1995,,0167-6423,https://www.sciencedirect.com/science/article/pii/0167642395000100;http://dx.doi.org/10.1016/0167-6423(95)00010-0,10.1016/0167-6423(95)00010-0,"We describe a second-order calculus of objects. The calculus supports object subsumption, method override, and the type Self. It is constructed as an extension of System F with subtyping, recursion, and first-order object types.",,"Selected Papers of ESOP'94, the 5th European Symposium on Programming",,,,,,,,,,,,,,,,,,,,
Journal Article,"Lano K,Bicarregui J,Kan P",,Experiences of Using Formal Methods for Chemical Process Control Specification,IFAC Proceedings Volumes,1998,31,15,147-151,,,,,1998,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017405441;http://dx.doi.org/10.1016/S1474-6670(17)40544-1,10.1016/S1474-6670(17)40544-1,"This paper discusses the benefits of adding fonnal specification in B to existing controller synthesis techniques, and some of the limitations of B for this area of application. Examples from case studies carried out in the “Object-oriented specification of Real-time and Reactive Systems” (ROOS) project are given","Control engineering, Control system design, Formal specification, Formal verification, Realtime","9th IFAC Symposium on Information Control in Manufacturing 1998 (INCOM '98), Nancy, France, 24-26 June",,,,,,,,,,,,,,,,,,,,
Journal Article,Elyasaf A,,Context-Oriented Behavioral Programming,Information and Software Technology,2021,133,,106504,,,,,2021,,0950-5849,https://www.sciencedirect.com/science/article/pii/S095058492030094X;http://dx.doi.org/10.1016/j.infsof.2020.106504,10.1016/j.infsof.2020.106504,"Context: Modern systems require programmers to develop code that dynamically adapts to different contexts, leading to the evolution of new context-oriented programming languages. These languages introduce new software-engineering challenges, such as: how to maintain the separation of concerns of the codebase? how to model the changing behaviors? how to verify the system behavior? and more. Objective: This paper introduces Context-Oriented Behavioral Programming (COBP) — a novel paradigm for developing context-aware systems, centered on natural and incremental specification of context-dependent behaviors. As the name suggests, we combine behavioral-programming (BP) — a scenario-based modeling paradigm — with context idioms that explicitly specify when scenarios are relevant and what information they need. The core idea is to connect the behavioral model with a data model that represents the context, allowing an intuitive connection between the models via update and select queries. Combining behavioral-programming with context-oriented programming brings the best of the two worlds, solving issues that arise when using each of the approaches in separation. Methods: We begin with providing abstract semantics for COBP and two implementations for the semantics, laying the foundations for applying reasoning algorithms to context-aware behavioral programs. Next, we exemplify the semantics with formal specifications of systems, including a variant of Conway’s Game of Life. Then, we provide two case studies of real-life context-aware systems (one in robotics and another in IoT) that were developed using this tool. Throughout the examples and case studies, we provide design patterns and a methodology for coping with the above challenges. Results: The case studies show that the proposed approach is applicable for developing real-life systems, and presents measurable advantages over the alternatives — behavioral programming alone and context-oriented programming alone. Conclusion: We present a paradigm allowing programmers and system engineers to capture complex context-dependent requirements and align their code with such requirements.","Behavioral programming, Scenario-based programming, Programming paradigm, Context awareness, Context-oriented programming, Context-Oriented Behavioral Programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,Pinto A,,Variability in the formal and informal content instructors convey in lectures,The Journal of Mathematical Behavior,2019,54,,100680,,,,,2019,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312317301827;http://dx.doi.org/10.1016/j.jmathb.2018.11.001,10.1016/j.jmathb.2018.11.001,"This paper investigates the variability in the content of lectures by different university mathematics instructors teaching concurrently in the same course. The instructors enacted a shared lesson-plan and coordinated their teaching to ensure students in different sections of the course will receive equivalent academic preparation. However, classroom observations and interviews with the instructors indicate that while explicitly discussing the same definitions and theorems and working out similar examples, the instructors were implicitly trying to convey different informal content. An analysis of the instructors’ mathematical discourse during the lectures and the interviews reveals that the instructors coordinated with each other content corresponding with object-level learning, while implicitly orienting their lectures towards fostering meta-level learning. This found gap highlights miscommunication between the instructors and points to the need of a shared and explicit discourse on meta-level learning at the collegiate level.","University mathematics lectures, Informal content, Implicit curriculum, Mathematical discourse, The derivative",,,,,,,,,,,,,,,,,,,,,
Journal Article,Della Penna G,,A type system for static and dynamic checking of C++ pointers,"Computer Languages, Systems & Structures",2005,31,2,71-101,,,,,2005,,1477-8424,https://www.sciencedirect.com/science/article/pii/S147784240400020X;http://dx.doi.org/10.1016/j.cl.2004.05.002,10.1016/j.cl.2004.05.002,"Object-oriented programming is the most used programming paradigm when dealing with large-scale, modular software. In this field, the two leading languages are Java and C++. The former has superior qualities in terms of safety and ease of programming, whereas the latter is often considered an “old” language, too complex and potentially unsafe. In this paper, we describe a new type system designed to analyze the security problems derived from pointer manipulation in C++. This type system tries to trap the most common errors through static analysis, i.e., at compile-time, and only when static analysis fails it generates and embeds code fragments that apply runtime checks on specific instructions. The aim of this new type system is to give C++ the same safety of Java in the most important memory-related operations, without adding much runtime overhead. An experimental implementation of the type system is also presented, embedded in a C++ analysis tool called GPCC.","C++, Legacy code, Pointer analysis, Code safety, Type systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tseng FS,Chen CL",,Extending the UML concepts to transform natural language queries with fuzzy semantics into SQL,Information and Software Technology,2006,48,9,901-914,,,,,2006,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584905001886;http://dx.doi.org/10.1016/j.infsof.2005.12.002,10.1016/j.infsof.2005.12.002,"Database applications tend toward getting more versatile and broader to comply with the expansion of various organizations. However, naïve users usually suffer from accessing data arbitrarily by using formal query languages. Therefore, we believe that accessing databases using natural language constructs will become a popular interface in the future. The concept of object-oriented modeling makes the real world to be well represented or expressed in some kinds of logical form. Since the class diagram in UML is used to model the static relationships of databases, in this paper, we intend to study how to extend the UML class diagram representations to capture natural language queries with fuzzy semantics. By referring to the conceptual schema throughout the class diagram representation, we propose a methodology to map natural language constructs into the corresponding class diagram and employ Structured Object Model (SOM) methodology to transform the natural language queries into SQL statements for query executions. Moreover, our approach can handle queries containing vague terms specified in fuzzy modifiers, like ‘good’ or ‘bad’. By our approach, users obtain not only the query answers but also the corresponding degree of vagueness, which can be regarded as the same way we are thinking.","Natural Language Query, UML, Class Diagram, Object-Oriented Modeling, Fuzzy Set Theory",Special Issue Section: Distributed Software Development,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bugliesi M,Pericás-Geertsen SM",,Type Inference for Variant Object Types,Information and Computation,2002,177,1,2-27,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540102930919;http://dx.doi.org/10.1006/inco.2002.3091,10.1006/inco.2002.3091,"Existing type systems for object calculi are based on invariant subtyping. Subtyping invariance is required for soundness of static typing in the presence of method overrides, but it is often in the way of the expressive power of the type system. Flexibility of static typing can be recovered in different ways: in first-order systems by the adoption of object types with variance annotations, in second-order systems by resorting to Self types. Type inference is known to be P-complete for first-order systems of finite and recursive object types, and NP-complete for a restricted version of Self types. The complexity of type inference for systems with variance annotations is yet unknown. This paper presents a new object type system based on the notion of Split types, a form of object types where every method is assigned two types, namely, an update type and a select type. The subtyping relation that arises for Split types is variant and, as a result, subtyping can be performed both in width and in depth. The new type system generalizes all the existing first-order type systems for objects, including systems based on variance annotations. Interestingly, the additional expressive power does not affect the complexity of the type inference problem, as we show by presenting an O(n3) inference algorithm.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Varsamidis T,Hope S,Jobling CP",,An object-oriented information model for computer-aided control engineering,Control Engineering Practice,1996,4,7,929-937,,,,,1996,,0967-0661,https://www.sciencedirect.com/science/article/pii/0967066196000913;http://dx.doi.org/10.1016/0967-0661(96)00091-3,10.1016/0967-0661(96)00091-3,"The aim of modern computer-aided engineering research is to create integrated sets of tools that support all stages of the control-systems design life-cycle. The most efficient way to achieve the exchange of data between the tools of the integrated environment is to define an information model that is shared by all tools and maintained by a common software environment. An object-oriented information model for life-cycle support of computer-aided control engineering is presented in this paper, and a possible architecture for its implementation is suggested. The model has been formally specified in the information modelling language EXPRESS. Object-oriented methods are also to be used for database support and inter-tool communications. The design is evaluated against previously published information models for computer-aided control engineering.","Computer-aided control systems design, computer-aided control engineering, information modelling, data exchange, standards, object modelling techniques, STEP/EXPRESS",,,,,,,,,,,,,,,,,,,,,
Journal Article,Janssens D,,Process Languages for ESM Systems,Electronic Notes in Theoretical Computer Science,1995,2,,137-138,,,,,1995,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105801902;http://dx.doi.org/10.1016/S1571-0661(05)80190-2,10.1016/S1571-0661(05)80190-2,"In most approaches to graph grammars the formal description of their behaviour is based on a derivation relation between graphs. Graph grammar processes may then be constructed from derivation sequences. However one may also follow an alternative approach, considering a graph grammar directly as the generator of a language of process objects, as was done in earlier work about ESM graph rewriting. In this paper the relation between the two approaches is clarified, using results about the composition and decomposition of ESM processes. It is shown that processes in the usual sense correspond to a special case of general ESM process objects. The use of these general process objects is illustrated by an application of ESM graph rewriting to the modeling of parallel object-oriented systems.",,"SEGRAGRA 1995, Joint COMPUGRAPH/SEMAGRAPH Workshop on Graph Rewriting and Computation",,,,,,,,,,,,,,,,,,,,
Journal Article,Rodríguez DE,,Combining Techniques to Reduce State Space and Prove Strong Properties,Electronic Notes in Theoretical Computer Science,2009,238,3,267-280,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109001467;http://dx.doi.org/10.1016/j.entcs.2009.05.024,10.1016/j.entcs.2009.05.024,"An on-the-fly symmetry reduction technique that exploits the lexicographic order on metarepresentations of Maude terms, and a technique that uses auxiliary data to verify strong properties that are not directly expressible in propositional temporal logic are presented. Both are implemented by simple transformations of rewrite theories. They are applied in the verification of a strong-consistency property of a client-server protocol, a simplification of the Chain-Replication protocol.","Verification, symmetry reduction, lexicographic order, formal object-oriented specifications",Proceedings of the Seventh International Workshop on Rewriting Logic and its Applications (WRLA 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Anderson C,Barbanera F,Dezani-Ciancaglini M,Drossopoulou S",,Can Addresses be Types?: A case study: objects with delegation,Electronic Notes in Theoretical Computer Science,2003,82,8,108-129,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104808041;http://dx.doi.org/10.1016/S1571-0661(04)80804-1,10.1016/S1571-0661(04)80804-1,"We adapt the aliasing constraints approach for designing a flexible typing of evolving objects. Types are singleton types (addresses of objects, as a matter of fact) whose relevance is mainly due to the sort of safety property they guarantee. In particular we provide a type system for an imperative object based calculus with delegation and which supports method and delegate overriding, addition, and removal.","object based calculi, delegation, alias types, effects","WOOD2003, Workshop on Object Oriented Developments (Satellite Event of ETAPS 2003)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Åkesson J,Ekman T,Hedin G",,Implementation of a Modelica compiler using JastAdd attribute grammars,Science of Computer Programming,2010,75,1,21-38,,,,,2010,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642309001087;http://dx.doi.org/10.1016/j.scico.2009.07.003,10.1016/j.scico.2009.07.003,"We have implemented a compiler for key parts of Modelica, an object-oriented language supporting equation-based modeling and simulation of complex physical systems. The compiler is extensible, to support experiments with emerging tools for physical models. To achieve extensibility, the implementation is done declaratively in JastAdd, a metacompilation system supporting modern attribute grammar mechanisms such as reference attributes and nonterminal attributes. This paper reports on experiences from this implementation. For name and type analyses, we illustrate how declarative design strategies, originally developed for a Java compiler, could be reused to support Modelica’s advanced features of multiple inheritance and structural subtyping. Furthermore, we present new general design strategies for declarative generation of target ASTs from source ASTs. We illustrate how these strategies are used to resolve a generics-like feature of Modelica called modifications, and to support flattening, a fundamental part of Modelica compilation. To validate that the approach is practical, we have compared the execution speed of our compiler to two existing Modelica compilers.","Compiler construction, JastAdd, Modelica, Reference attributed grammars","Special Issue on ETAPS 2006 and 2007 Workshops on Language Descriptions, Tools, and Applications (LDTA ’06 and ’07)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Vyatkin V,Hanisch HM,Bouzon G",,Open Object-Oriented Modelling and Validation Framework for Modular Industrial Automation Systems,IFAC Proceedings Volumes,2004,37,4,171-176,,,,,2004,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017361141;http://dx.doi.org/10.1016/S1474-6670(17)36114-1,10.1016/S1474-6670(17)36114-1,"This paper introduces a framework for formal modelling and validation of automation systems intended to be used by control engineers. The framework is based on a graphical, modular, and typed formalism of Net Condition/Event Systems. This allows for modelling of realistic hierarchically organized industrial automation systems in a closed loop. The framework consists of methodologies and tools which enable formal analysis of automation systems. The framework will be used to improve safety, reliability and robustness of automation systems predicting potential faults and deadlocks.","Verification, PLC modelling, manufacturing systems, discrete event systems","11th IFAC Symposium on Information Control Problems in Manufacturing (INCOM 2004), Salvador, Brazil, 5-7 April 2004",,,,,,,,,,,,,,,,,,,,
Journal Article,"Bettini L,Capecchi S,Venneri B",,Featherweight Java with dynamic and static overloading,Science of Computer Programming,2009,74,5,261-278,,,,,2009,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642309000136;http://dx.doi.org/10.1016/j.scico.2009.01.007,10.1016/j.scico.2009.01.007,"We propose FMJ (Featherweight Multi Java), an extension of Featherweight Java with encapsulated multi-methods thus providing dynamic overloading. Multi-methods (collections of overloaded methods associated to the same message, whose selection takes place dynamically instead of statically as in standard overloading) are a useful and flexible mechanism which enhances re-usability and separation of responsibilities. However, many mainstream languages, such as, e.g., Java, do not provide it, resorting to only static overloading. The proposed extension is conservative and type safe: both “message-not-understood” and “message-ambiguous” are statically ruled out. Possible ambiguities are checked during type checking only on method invocation expressions, without requiring to inspect all the classes of a program. A static annotation with type information guarantees that in a well-typed program no ambiguity can arise at run-time. This annotation mechanism also permits modeling static overloading in a smooth way. Our core language can be used as the formal basis for an actual implementation of dynamic (and static) overloading in Java-like languages.","Object-oriented languages, Featherweight Java, Multi-methods, Static overloading, Dynamic overloading, Type system",Special Issue on Principles and Practices of Programming in Java (PPPJ 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Stocks P,Raymond K,Carrington D,Lister A",,Modelling open distributed systems in Z,Computer Communications,1992,15,2,103-113,,,,,1992,,0140-3664,https://www.sciencedirect.com/science/article/pii/0140366492901307;http://dx.doi.org/10.1016/0140-3664(92)90130-7,10.1016/0140-3664(92)90130-7,"Formal modelling can greatly assist the design and development of distributed systems. To be effective, such modelling needs formal description techniques capable of representing concepts particular to distributed systems (as well as more general concepts applicable to all systems). The Open Distributed Processing (ODP) standardization effort describes a set of concepts considered relevant to the description of open distributed systems, and also specifies requirements for formal description techniques used in modelling these systems. In this paper we show how the Z specification language (and its object-oriented extension, Object-Z) satisfies ODP requirements and can express ODP concepts. We conclude that Z and Object-Z are well-suited to modelling ODP systems in particular, and distributed systems in general.","open distributed systems, Z, formal description techniques, modelling",,,,,,,,,,,,,,,,,,,,,
Journal Article,Barros O,,Object-oriented case-supported development of information systems,Journal of Systems and Software,1994,24,2,95-113,,,,,1994,,0164-1212,https://www.sciencedirect.com/science/article/pii/0164121294900736;http://dx.doi.org/10.1016/0164-1212(94)90073-6,10.1016/0164-1212(94)90073-6,"We present an object-oriented approach to development based on a high-level problem-oriented external-view model of an information system. It covers the integrated specification and design of the structural (data) and behavioral (processing) components of an information system. We thus avoid current consistency problems associated with separate models for structure, such as entity relationship, and for processing, such as structured analysis. We also propose a formal specification language that, with CASE support, allows for specification execution and simulation before actual code generation is performed for system implementation. Thus, a true prototyping capability is provided for complex application iteration. Santiago, Chile",,Object-orientation in Info. Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jacobs B,Smans J,Piessens F,Schulte W",,A Simple Sequential Reasoning Approach for Sound Modular Verification of Mainstream Multithreaded Programs,Electronic Notes in Theoretical Computer Science,2007,174,9,23-47,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610700357X;http://dx.doi.org/10.1016/j.entcs.2007.04.005,10.1016/j.entcs.2007.04.005,"Reasoning about multithreaded object-oriented programs is difficult, due to the non-local nature of object aliasing, data races, and deadlocks. We propose a programming model that prevents data races and deadlocks, and supports local reasoning in the presence of object aliasing and concurrency. Our programming model builds on the multi-threading and synchronization primitives as they are present in current mainstream languages. Java or C# programs developed according to our model can be annotated by means of stylized comments to make the use of the model explicit. We show that such annotated programs can be formally verified to comply with the programming model. In other words, if the annotated program verifies, the underlying Java or C# program is guaranteed to be free from data races and deadlocks, and it is sound to reason locally about program behavior. Our approach supports immutable objects as well as static fields and static initializers. We have implemented a verifier for programs developed according to our model in a custom build of the Spec# programming system, and have validated our approach on a case study.","Aliasing, class initialization, concurrency, data races, deadlocks, immutable objects, local reasoning, modular reasoning, ownership, verification condition generation",Proceedings of the Thread Verification Workshop (TV 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Sernadas A,Sernadas C,Ramos J",,A temporal logic approach to object certification,Data & Knowledge Engineering,1996,19,3,267-294,,,,,1996,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X96000043;http://dx.doi.org/10.1016/0169-023X(96)00004-3,10.1016/0169-023X(96)00004-3,"A brief overview is made of the use of temporal logic formalisms for specifying and verifying concurrent systems in general and information systems in particular. The requirements imposed by object-orientation on such formalisms are examined. A logic is proposed fulfilling those requirements (except concerning non-monotonic features), allowing the uniform treatment of both local and global properties of systems with concurrent, interacting components organized in classes, and supporting specialization. A semantics and a calculus (following an axiomatic, Hilbert style) are presented in detail. The calculus includes rules for the sound inheritance and reflection of theorems between classes. Practical aspects of the usage of such a logic for both specification and verification are considered. To this end a set of metatheorems is provided for expediting the proof of invariants. Finally, the need and availability of automatic theorem proving for systems querying is briefly discussed.","Object-orientation, Interaction, Formal specification, Temporal logic, Certification, Correctness verification, Information system",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Steen MW,Derrick J",,ODP enterprise viewpoint specification,Computer Standards & Interfaces,2000,22,3,165-189,,,,,2000,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548900000313;http://dx.doi.org/10.1016/S0920-5489(00)00031-3,10.1016/S0920-5489(00)00031-3,"The Open Distributed Processing (ODP) standardisation initiative has led to a framework by which distributed systems can be modelled using a number of viewpoints. These include an enterprise viewpoint, which focuses on the objectives and policies of the enterprise that the system is meant to support. Although the ODP reference model provides abstract languages of relevant concepts, it does not prescribe particular techniques that are to be used in the individual viewpoints. In particular, there is a need to develop appropriate notations for ODP enterprise specification, in order to increase the applicability of the ODP framework. In this paper, we tackle this concern and develop a specification language to support the current draft of the enterprise viewpoint. In doing so, we analyse the current definition of the ODP enterprise viewpoint language. Using the Unified Modelling Language (uml), a meta-model of the core concepts and their relationships is constructed, and we also investigate to what extent the uml can be used for enterprise viewpoint specification. We, then, focus on the expression of enterprise policies that govern the behaviour of enterprise objects. We develop a policy language, which is a combination of structured English and simple predicate logic and is built on top of the formal object-oriented specification language Object-Z, into which the complete language is translated. We illustrate the ideas in the paper with a case study that presents an enterprise specification of a library support system.","Open distributed processing (ODP), ODP enterprise viewpoint, , Object-Z, Formal methods, Enterprise policies, Policy specification",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Lewis BJ,Onder EN,Prudil AA","Lewis BJ,Onder EN,Prudil AA",Chapter 14 - Calculus of variations,,2022,,,373-387,,Butterworth-Heinemann,,Advanced Mathematics for Engineering Students,2022,9780128236819,,https://www.sciencedirect.com/science/article/pii/B9780128236819000228;http://dx.doi.org/10.1016/B978-0-12-823681-9.00022-8,10.1016/B978-0-12-823681-9.00022-8,"Chapter 14 describes the calculus of variations that complements ordinary differential calculus. It provides a powerful technique to find an optimum quantity to be minimized (or maximized). It leads to the development of the Euler–Lagrange equations, with application to find the motion or optimal shape of an object, or determine the shortest path on a surface (geodesic).","Lagrange–Euler equation, geodesic, Christoffel symbol, field equations of general relativity, Lagrange multipliers, brachistochrone problem, optimal path, contravariant and covariant tensors, Hamilton's principle, Lagrangian",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Åkesson J,Ekman T,Hedin G",,Development of a Modelica Compiler Using JastAdd,Electronic Notes in Theoretical Computer Science,2008,203,2,117-131,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108001539;http://dx.doi.org/10.1016/j.entcs.2008.03.048,10.1016/j.entcs.2008.03.048,"This paper describes experiences from implementing key parts of a compiler for Modelica, an object-oriented language supporting declarative modeling and simulation of complex physical systems. Our implementation uses the attribute-grammar based tool JastAdd. In particular, we discuss the implementation of Modelica name analysis which is highly context-dependent, type analysis which is based on structural subtyping, and flattening which is a fundamental part of the Modelica compilation process.of so called modifications, Modelica.","Modelica, JastAdd, compiler construction, reference attributed grammars","Proceedings of the Seventh Workshop on Language Descriptions, Tools, and Applications (LDTA 2007)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Szafnicki K,Gentil S",,An Object Oriented Knowledge-Based System for Process Identification,IFAC Proceedings Volumes,1991,24,4,159-164,,,,,1991,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017542640;http://dx.doi.org/10.1016/S1474-6670(17)54264-0,10.1016/S1474-6670(17)54264-0,"An object oriented knowledge-based system (KBS) for identification of industrial processes is presented. The algorithmic part of the software is discussed first. The implemented parameter estimation methods and the post-optimization computations are briefly reviewed. The knowledge necessary to determine an adequate structure of the model of an unknown process is analysed next. This knowledge has been implemented within an Object-Oriented tool, which readily allows an easy updating and/or extension of the theoretical knowledge about identification. The heuristic part of the knowledge is included in a set of several small production-rule bases, on which an inference engine is run, when necessary, to compute values of object attributes. The numerical-symbolic interface includes fuzzy logic calculus. A dedicated graphic interface enables the displaying of the main features of the reasoning as well as a global monitoring of the run of the KBS. An industrial case study is discussed at the end.","Artificial intelligence, expert systems, identification, object-oriented representation, fuzzy sets theory","IFAC Symposium on Computer Aided Design in Control Systems, Swansea, UK, 15-17 July 1991",,,,,,,,,,,,,,,,,,,,
Journal Article,"Pelechano V,Pastor O,Insfrán E",,Automated code generation of dynamic specializations: an approach based on design patterns and formal techniques,Data & Knowledge Engineering,2002,40,3,315-353,,,,,2002,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X02000204;http://dx.doi.org/10.1016/S0169-023X(02)00020-4,10.1016/S0169-023X(02)00020-4,"In this work, we present an automatic code generation process from conceptual models. This process incorporates the use of design patterns in OO-Method, an automated software production method, which is built on a formal object-oriented model called OASIS. Our approach defines a precise mapping between conceptual patterns, design patterns and their implementation. Design patterns make the code generation process easy because they provide methodological guidance to go from the problem space to the solution space. In order to understand these ideas, we introduce a complete code generation process for conceptual models that have dynamic specialization relationships. This proposal can be incorporated into CASE tools, making the automation of the software production process feasible.","Conceptual modeling, Object orientation, Formal languages, Design patterns, Code generation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Howse J,Schuman S,Stapleton G,Oliver I",,Diagrammatic Formal Specification of a Configuration Control Platform,Electronic Notes in Theoretical Computer Science,2009,259,,87-104,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109005015;http://dx.doi.org/10.1016/j.entcs.2009.12.019,10.1016/j.entcs.2009.12.019,"This paper presents a diagrammatic logic framework that is suitable for use in formal specification and for reasoning about and refining formal software models. We take a case study style approach to presenting the framework by developing, in some detail, an abstract model for a transparent configuration control platform. The model is built up by stages, corresponding to separate concerns of configuration control. Each successive level is a refinement of the previous level. We discuss the possibilities for developing tools to support the use of the diagrammatic logic, including automated diagram drawing and reasoning procedures. Our wider goal is to make a formal specification easier for its clients to understand.","configuration control case-study, constraint diagrams, object-oriented formal specification, visual modeling, visual refinement",Proceedings of the 14th BCS-FACS Refinement Workshop (REFINE 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Sosa-Reyna CM,Tello-Leal E,Lara-Alabazares D",,Methodology for the model-driven development of service oriented IoT applications,Journal of Systems Architecture,2018,90,,15-22,,,,,2018,,1383-7621,https://www.sciencedirect.com/science/article/pii/S1383762118301875;http://dx.doi.org/10.1016/j.sysarc.2018.08.008,10.1016/j.sysarc.2018.08.008,"The main problem with the current technology solutions for Internet of Things (IoT) is located at the application level, in which there is still a lack of software components, frameworks, and tools which can help end-users to easily develop IoT applications and to manage the things or objects. These requirements lead to the use of the principles of Model-Driven Development (MDD) and Service-Oriented Architecture (SOA) for the construction of software applications, allowing the generation of models at different levels of abstraction, with the possibility of generating software implementation artifacts (code) on different platforms, as well as allow the decomposition of complex and monolithic systems into loosely coupled components. In this paper, we propose a methodology based on the MDD for solving the challenges in the IoT system developments. The methodology is composed of four phases with different levels of abstraction, viewpoint, granularity, and service-oriented. Furthermore, a set of MDD methods for the transformation of models using formal rules are proposed. We present a smart vehicle scenario in which the methodology and methods are implemented, allowing the generation of executable code as a component of a real-time system. In addition, an architecture for IoT systems composed of four layers is presented, which is based on the SOA approach. In this way, the methodology and the architecture allow the interoperability (from the perspective of models and software components) between heterogeneous devices to be guaranteed in multiple ways, establishing a bridge between the digital and physical world of the IoT domain .","Thing, IoT, MDD, SOA, Transformation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kim K,Kwon K,Moon S",,Development of object-oriented database management system: OOIM,Microprocessing and Microprogramming,1994,40,10,729-732,,,,,1994,,0165-6074,https://www.sciencedirect.com/science/article/pii/0165607494900280;http://dx.doi.org/10.1016/0165-6074(94)90028-0,10.1016/0165-6074(94)90028-0,"This paper describes two focal issues: visual query optimization and concurrency control in designing OOIM, which is an object-oriented database management system being developed at KAIST. The basic principles for optimization are to build a framework on a formal algebraic basis and to operate directly with graph-based query specifications. The philosophy behind these principles is to utilize existing relational technology in supporting a graph-based object-oriented query language. For concurrency control, the principles of modeling method hierarchy as a nested transaction, exploiting semantics of methods, and dynamic determination of conflicts resulting from referential sharing are used. The basic idea is to enhance the degree of concurrency without allowing a non-serializable schedule.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tabary D,Abed M",,"Modelling of Tasks, Users, and Systems Using Formal Specification Techniques",IFAC Proceedings Volumes,2001,34,16,187-192,,,,,2001,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017415230;http://dx.doi.org/10.1016/S1474-6670(17)41523-0,10.1016/S1474-6670(17)41523-0,"Human-task modelling constitutes a field of research in its own right. This one also proves particularly significant since it is integrated, in the stages upstream of the development process of a mono or multi-user interactive system, as well as in the stages downstream aiming to evaluate and validate a human-machine system. A large number of methods exist in the literature on this subject. This article deals with the operational model of The TOOD (Task Object Oriented Design).","tasks, human-centered design, petri nets, object modelling techniques, human-machine interface, methodology","8th IFAC Symposium on Analysis, Design and Evaluation of Human-Machine Systems (HMS 2001), Kassel, Germany, 18-20 September, 12001",,,,,,,,,,,,,,,,,,,,
Journal Article,"Saini A,Thiry L",,Functional Programming for Business Process Modeling,IFAC-PapersOnLine,2017,50,1,10526-10531,,,,,2017,,2405-8963,https://www.sciencedirect.com/science/article/pii/S2405896317318207;http://dx.doi.org/10.1016/j.ifacol.2017.08.1299,10.1016/j.ifacol.2017.08.1299,"This paper presents how Functional Programming (FP) helps to provide an other formal semantics (relation between the syntax and the model of computation) for Business Process Modeling (BPM); a semantics relatively different from Object Oriented semantics. More precisely, it proposes a general methodology to model business processes using mathematical functions and higher-order functions. We describe the basic part of Business Process Modeling, behavioral semantics via Petri Nets (PN) and Functional implementation of the models. Also, we will see how the business process model is translated into its equivalent form in Petri Nets and how these can be described through Functional Programming.","Functional Programming, Semantics, Business Process Modeling, Petri Nets",20th IFAC World Congress,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lano K,Bicarregui J,Kan P",,Experiences of using formal methods for chemical process control specification,Control Engineering Practice,2000,8,1,71-79,,,,,2000,,0967-0661,https://www.sciencedirect.com/science/article/pii/S0967066199001380;http://dx.doi.org/10.1016/S0967-0661(99)00138-0,10.1016/S0967-0661(99)00138-0,"This paper discusses the benefits of adding formal specification in B to existing controller synthesis techniques, and some of the limitations of B for this area of application. Examples from case studies carried out in the “Object-oriented specification of real-time and reactive systems” (ROOS) project are given.","Control engineering, Control system design, Formal specification, Formal verification, Realtime",,,,,,,,,,,,,,,,,,,,,
Journal Article,Sheu PC,,Object-oriented graphics knowledge bases,Computers & Graphics,1988,12,1,115-123,,,,,1988,,0097-8493,https://www.sciencedirect.com/science/article/pii/0097849388900167;http://dx.doi.org/10.1016/0097-8493(88)90016-7,10.1016/0097-8493(88)90016-7,"An object-oriented knowledge base is a database that is constructed on object data model. Using mathematical logic as formal representation, an object-oriented knowledge base can be constructed to support classification, aggregation, generalization, and association. It further extends the existing databases with procedural semantics. In this paper we describe the application of object-oriented knowledge bases as the basis for computer graphics systems. In particular, we discuss how solid objects, graphical features, and geometric constraints can be represented in logic. Furthermore, we describe the approaches to process declarative transactions, side effects, windows, and incremental interpretation taking advantages of knowledge.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Yilmaz B,,A new type electromagnetic curves in optical fiber and rotation of the polarization plane using fractional calculus,Optik,2021,247,,168026,,,,,2021,,0030-4026,https://www.sciencedirect.com/science/article/pii/S0030402621015862;http://dx.doi.org/10.1016/j.ijleo.2021.168026,10.1016/j.ijleo.2021.168026,"In the present paper, the geometric properties of the linearly polarized light wave are researched along an optical fiber using the conformable fractional derivative and integral in 3D Riemannian manifold. Since the optical fiber is supposed to be a one-dimensional object imbedded in a 3D Riemannian manifold, the evolution of a linearly polarized light wave is associated with geometric phase. So, we generate a new type of geometric phase model with fractional derivative. Also, we introduce a magnetic curves which are generated by the electric field E. Finally, examples consistent with the theory are examined and visualized for different values of the conformable fractional derivative. The difference of this study from others is the use of conformal fractional derivatives and integrals in calculations. Fractional calculus has applications in many fields such as physics, engineering, mathematical biology, fluid mechanics, signal processing, etc. Fractional derivatives and integrals have become an extremely important and new mathematical method in solving various problems in many sciences.","Applications to physics, Optical fiber, Polarized light wave, Electromagnetic curves, Fractional calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bettini L,Damiani F,Schaefer I",,Implementing type-safe software product lines using parametric traits,Science of Computer Programming,2015,97,,282-308,,,,,2015,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642313001901;http://dx.doi.org/10.1016/j.scico.2013.07.016,10.1016/j.scico.2013.07.016,"A software product line (SPL) is a set of related software systems with well-defined commonality and variability that are developed by reusing common artifacts. In this paper, we present a novel technique for implementing SPLs by exploiting mechanisms for fine-grained reuse which are orthogonal to class-based inheritance. In our approach the concepts of type, behavior, and state are separated into different and orthogonal linguistic concepts: interfaces, traits and classes, respectively. We formalize our proposal by means of Featherweight Parametric Trait Java (FPTJ), a minimal core calculus where units of product functionality are modeled by parametric traits. Traits are a well-known construct for fine-grained reuse of behavior. Parametric traits are traits parameterized by interface names and class names. Parametric traits are applied to interface names and class names to generate traits that can be assembled in other (possibly parametric) traits or in classes that are used to build products. The composition of product functionality is realized by explicit operators of the calculus, allowing code manipulations for modeling product variability. The FPTJ type system ensures that the products in the SPL are type-safe by inspecting the parametric traits and classes shared by different products only once. Therefore, type-safety of an extension of a (type-safe) FPTJ SPL can be guaranteed by inspecting only the newly added parts.","Featherweight Java, Feature model, Software product line, Trait, Type system",Object-Oriented Programming and Systems (OOPS 2010) Modeling and Analysis of Compositional Software (papers from EUROMICRO SEAA’12),,,,,,,,,,,,,,,,,,,,
Journal Article,"Clarke DT,Crum GP",,Dialogue specification and control: a review of models and techniques,Information and Software Technology,1994,36,9,539-547,,,,,1994,,0950-5849,https://www.sciencedirect.com/science/article/pii/095058499490099X;http://dx.doi.org/10.1016/0950-5849(94)90099-X,10.1016/0950-5849(94)90099-X,"This paper examines the variety of techniques and notations that have been proposed for dialogue specification and control in interactive systems. Notations covered include state transition diagrams, grammars, event-based approaches, formal notations and object-oriented techniques. The various advantages and disadvantages of each are indicated, and related user interface software tools are referenced where appropriate. Dialogue specification in the context of traditional system design is also discussed.","dialogue specification, state transition diagrams (STD), grammars, events, formal notation, user interface, UIMS, systems design, object-oriented",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Theelen BD,Voeten JP,Kramer RD",,Performance modelling of a network processor using POOSL,Computer Networks,2003,41,5,667-684,,,,,2003,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128602004553;http://dx.doi.org/10.1016/S1389-1286(02)00455-3,10.1016/S1389-1286(02)00455-3,"The increasing complexity of innovative real-time hardware/software systems forced industry to consider system-level design methods. Before actually implementing a system with hardware and software components, system-level design methods enable analysing the performance of different design alternatives that realise the required functionality. In order to develop performance models early in the design process, the parallel object-oriented specification language (POOSL) can be used. POOSL is an expressive modelling language for analysing complex real-time distributed hardware/software systems. Being equipped with a formal semantics, POOSL ensures unambiguous execution of models and proper application of performance analysis techniques. This paper discusses the use of POOSL for analysing the performance of a network processor. A network processor consists of components that perform their behaviour in a synchronously concurrent way, whereas POOSL is based on an asynchronous modelling paradigm. In this paper, we illustrate that constructing abstract models of synchronous systems for the purpose of performance analysis may benefit from an asynchronous modelling approach.","Performance modelling, Network processor, Parallel object-oriented specification language, System-level design, Concurrency, Formal description techniques",Network Processors,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang HK,Wu JL",,Object model for hypermedia applications,Computer Communications,1995,18,7,475-485,,,,,1995,,0140-3664,https://www.sciencedirect.com/science/article/pii/014036649594374K;http://dx.doi.org/10.1016/0140-3664(95)94374-K,10.1016/0140-3664(95)94374-K,"To illustrate how hypermedia applications are developed, details of a multimedia document architecture are first introduced, including the physical and logical structures of hypermedia, and its temporal requirements. The MH object classes of the Multimedia and Hypermedia information coding Expert Group (MHEG), an ISO standard, are then introduced in view of the heterogeneity of applications and platforms available. With reference to the latter, and an augmented Petri net model, we present a formal definition of the Multimedia Hypermedia Petri-Net model (MHPN). Through this proposed model, issues of authoring, rendering and the interaction of multimedia information (i.e. spatial-temporal relationships, stoppage, reverse display of a dynamic representation, and others, such as coauthoring and networking) can all be implemented. Moreover, based on the MHPN model, we describe an experimental object-oriented multimedia information system, called the Petri net Object Information System (POIS). We believe this offers considerable potential for the development of distributed hypermedia applications.","hypermedia, object-oriented, Petri net, synchronization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Azadbakht K,de Boer FS,Bezirgiannis N,de Vink E",,A formal actor-based model for streaming the future,Science of Computer Programming,2020,186,,102341,,,,,2020,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642319301364;http://dx.doi.org/10.1016/j.scico.2019.102341,10.1016/j.scico.2019.102341,"Asynchronous Actor-based programming has gained increasing attention as a model of concurrency and distribution. The Abstract Behavioral Specification (ABS) language is an actor-based programming language that has been developed for both the modeling and formal analysis of distributed systems. In ABS, actors are modeled as concurrent objects that communicate by asynchronous method calls. Return values are also communicated asynchronously via return statements and so-called futures. Many modern distributed software applications require a form of continuous interaction between their components which consists of streaming data from a server to its clients. In this paper, we extend the ABS language in order to support the streaming of data. We introduce the notion of “future-based data streams” by augmenting the syntax, type system, and operational semantics of ABS. As a proof of concept, we further discuss a prototype implementation for supporting future-based data streams on top of ABS, and discuss the impact of the use of these data streams in ABS on the performance in the implementation of a distributed application for the generation of social networks.","Future, Streaming, Cooperative scheduling, Active objects, Social networks",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fernandes AA,Dinn A,Paton NW,Williams MH,Liew O",,Extending a deductive object-oriented database system with spatial data handling facilities,Information and Software Technology,1999,41,8,483-497,,,,,1999,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584998001219;http://dx.doi.org/10.1016/S0950-5849(98)00121-9,10.1016/S0950-5849(98)00121-9,"This paper describes the integration of a spatial data-handling component with the ROCK & ROLL deductive object-oriented database system. The extended ROCK & ROLL system provides much more comprehensive and better integrated database programming facilities than other candidate platforms for spatial information systems. The extended system serves developers with an intuitive, expressive, formally defined collection of spatial data types as primitive types whose operations have state-of-the-art computational complexity. The integration of these types with the object-oriented modelling, imperative programming and deductive querying facilities of ROCK & ROLL makes available a comprehensive and integrated suite of complementary mechanisms for the development of spatial information systems. The paper also provides preliminary benchmark results which indicate that kernel-support for spatial data handling does yield performance gains and that the extended ROCK & ROLL system compares well with a specialist geographic information system and two widely known extensible database systems when the latter are extended with spatial data handling facilities.","Spatial data management, Realms, Spatial data types, ROSE algebras, Deductive object-oriented databases, Database programming languages, ROCK & ROLL",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Van Eetvelde N,Janssens D",,A Hierarchical Program Representation for Refactoring,Electronic Notes in Theoretical Computer Science,2003,82,7,91-104,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104807497;http://dx.doi.org/10.1016/S1571-0661(04)80749-7,10.1016/S1571-0661(04)80749-7,"Currently there is a lot of interest in graph representations of software systems, as they provide a natural and flexible means to describe complex structures. The various visual sublanguages of the UML are perhaps the most obvious example of this. In [11] a graph representation of object-oriented programs was presented that enables one to describe refactoring operations (behaviour-preserving changes in the structure of a program) in a formal, concise way by graph rewriting productions. In general, however, a refactoring makes changes to a small part of a program, so the graph representation should only contain the information needed to carry out that refactoring. All other details are redundant and make the graph unnecessarily large for good visualization. A possible solution consists in using a hierarchical representation. Such a representation of object-oriented programs is presented in this paper. It is based on node-rewriting graph productions: each refinement step corresponds to a production. The construction is illustrated by applying it to a small Java simulation of a Local Area Network.",,"UNIGRA'03, Uniform Approaches to Graphical Process Specification Techniques (Satellite Event for ETAPS 2003)",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Manca D,Buzzi-Ferraris G","Pleşu V,Agachi PŞ",The solution of DAE systems by a numerically robust and efficient solver,,2007,24,,93-98,,Elsevier,,17th European Symposium on Computer Aided Process Engineering,2007,,1570-7946,https://www.sciencedirect.com/science/article/pii/S1570794607800393;http://dx.doi.org/10.1016/S1570-7946(07)80039-3,10.1016/S1570-7946(07)80039-3,The paper describes a modern approach to the solution of Differential and Algebraic Equation (DAE) Systems through a C++ routine: BzzDae belonging to the BzzMath freeware numerical library. After an introduction to BzzMath and the object oriented approach to numerical problems the manuscript focuses the attention on the robustness and efficiency features that characterize BzzDae with respect to the Fortran counterparts. A number of clarifications are given to describe the capabilities of BzzDae over the other solvers.,"Numerical calculus, DAE solver, robustness, efficiency, algorithm, routine",,Computer Aided Chemical Engineering,,,,,,,,,,,,,,,,,,,
Journal Article,"Lin L,Wakabayashi M,Adiga S",,Object-oriented modeling and implementation of control software for a robotic flexible manufacturing cell,Robotics and Computer-Integrated Manufacturing,1994,11,1,1-12,,,,,1994,,0736-5845,https://www.sciencedirect.com/science/article/pii/0736584594900027;http://dx.doi.org/10.1016/0736-5845(94)90002-7,10.1016/0736-5845(94)90002-7,"This paper discusses the development of an object-oriented software for the control of a robotic flexible manufacturing cell (FMC). The control software is based on a formal modeling of the entities involved in a cell and their interactions. An entity-relationship model, message flow diagrams, and state transition models are used to specify the software objects needed to model the operation of an FMC. In an object-oriented approach, the cell controller takes care of coordination and synchronization issues while the individual objects are responsible for their own activities. This approach has numerous advantages over the conventional state transition method where the number of state grows exponentially with the increase in cell components and complexity of control tasks. Implemented in Turbo C++ on an IBM PS/2 computer, the software can accommodate cell configuration changes, such as the number of machines, without reprogramming. Robot dispatching rules that are independent of the cell configuration were developed for handling the simultaneous setups, prevention of order sequence interference and batch break-up situations that are often encountered in FMC control.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aaltonen T,Helin J,Katara M,Kellomäki P,Mikkonen T",,Coordinating Aspects and Objects,Electronic Notes in Theoretical Computer Science,2003,68,3,248-267,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580372X;http://dx.doi.org/10.1016/S1571-0661(05)80372-X,10.1016/S1571-0661(05)80372-X,"Conventional software architectures emphasize individual software components and their interconnections. While offering many advantages this results in problems with concerns that cut across the component structure. The code addressing such concerns is scattered around the components and tangled with some other code inside the components. Approaches addressing such issues are emerging with new paradigms like aspect-oriented programming. However, aspects addressing cross-cutting concerns need to be incorporated in an object-oriented design without support from a higher-level design. We propose an approach where aspects and objects rely on coordination provided by a common high level specification. The common specification links the parts of specification that are refined independently and implemented using different techniques. We use the formal specification method DisCo, and demonstrate the approach by providing a specification of a simplified telecommunications system. In addition, we also sketch an Aspect J implementation built in the architectural style encouraged by the method. Funding from Tampere Graduate School in Information Science and Engineering (TISE) and the Academy of Finland (project 100005) is gratefully acknowledged.",,"Foclasa 2002, Foundations of Coordination Languages and Software Architectures (Satellite Workshop of CONCUR 2002)",,,,,,,,,,,,,,,,,,,,
Journal Article,Wu Z,,Designing the Information Framework of OOP Models Approach of High Level Petri Nets,IFAC Proceedings Volumes,1996,29,1,607-612,,,,,1996,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017577290;http://dx.doi.org/10.1016/S1474-6670(17)57729-0,10.1016/S1474-6670(17)57729-0,"The paper introduces how an object-oriented programming (OOP) model can be transformed to a kind of high level Petri net----CEM/T net, which can make use of database, rulebase and expert system to help the net's expression ability. The aim of this paper is to obtain a formal description and achieve a reliable and satisfactory design for the OOP application model. A typical discrete event system, job-shop production line, is considered as an example to be transfonned from its object structure to an CEM/T net.","Object-oriented programming, High level Petri net, CEM/T net, Job shop production line","13th World Congress of IFAC, 1996, San Francisco USA, 30 June - 5 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Campin J,Paton NW,Williams MH",,A structured specification of an active database system,Information and Software Technology,1995,37,1,47-61,,,,,1995,,0950-5849,https://www.sciencedirect.com/science/article/pii/095058499400013I;http://dx.doi.org/10.1016/0950-5849(94)00013-I,10.1016/0950-5849(94)00013-I,"Active database systems are a current focus of considerable research interest, as a means of supporting a range of tasks including constraint enforcement, real-time applications and derived data management. However, although many different proposals have been made for active rule systems, such proposals are normally described in an informal manner, which makes it difficult to understand how different proposals differ or how a set of rules will behave. This paper compares a range of formal specification methods, considering how suitable they are for describing active database functionality, and then shows how the model-based notation Object-Z, an object-oriented extension of Z, can be used to specify the semantics of a representative active database system, namely Starburst.","formal specification, active rules, active database, Starburst, Z, Object-Z",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fitzgerald K,Browne LM,Butler RF",,Using the Agile software development lifecycle to develop a standalone application for generating colour magnitude diagrams,Astronomy and Computing,2019,28,,100283,,,,,2019,,2213-1337,https://www.sciencedirect.com/science/article/pii/S2213133718300556;http://dx.doi.org/10.1016/j.ascom.2019.05.001,10.1016/j.ascom.2019.05.001,"Virtual observatories allow the means by which an astronomer is able to discover, access, and process data seamlessly, regardless of its physical location. However, steep learning curves are often required to become proficient in the software employed to access, analyse and visualise this trove of data. It would be desirable, for both research and educational purposes, to have applications which allow users to visualise data at the click of a button. Therefore, we have developed a standalone application (written in Python) for plotting photometric Colour Magnitude Diagrams (CMDs) — one of the most widely used tools for studying and teaching about astronomical populations. The CMD Plot Tool application functions “out of the box” without the need for the user to install code interpreters, additional libraries and modules, or to modify system paths; and it is available on multiple platforms. Interacting via a graphical user interface (GUI), users can quickly and easily generate high quality plots, annotated and labelled as desired, from various data sources. This paper describes how CMD Plot Tool was developed using Object Orientated Programming and a formal software design lifecycle (SDLC). We highlight the need for the astronomical software development culture to identify appropriate programming paradigms and SDLCs. We outline the functionality and uses of CMD Plot Tool, with examples of star cluster photometry. All results plots were created using CMD Plot Tool on data readily available from various online virtual observatories, or acquired from observations and reduced with IRAF/PyRAF.","Agile software development, Object oriented development, Scientific visualisation, Hertzsprung–Russell diagram, Globular clusters: General",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Davies J,Milward D,Wang CW,Welch J",,Formal model-driven engineering of critical information systems,Science of Computer Programming,2015,103,,88-113,,,,,2015,,0167-6423,https://www.sciencedirect.com/science/article/pii/S016764231400536X;http://dx.doi.org/10.1016/j.scico.2014.11.004,10.1016/j.scico.2014.11.004,"Model-driven engineering is the generation of software artefacts from abstract models. This is achieved through transformations that encode domain knowledge and implementation strategies. The same transformations can be used to produce quite different systems, or to produce successive versions of the same system. A model-driven approach can thus reduce the cost of development. It can also reduce the cost of verification: if the transformations are shown or assumed to be correct, each new system or version can be verified in terms of its model, rather than its implementation. This paper introduces an approach to model-driven engineering that is particularly suited to the development of critical information systems. The language of the models, and the language of the transformations, are amenable to formal analysis. The transformation strategy, and the associated development methodology, are designed to preserve systems integrity and availability.","Model-driven engineering, Formal methods, Critical systems, Information systems, Data migration",Selected papers from the First International Workshop on Formal Techniques for Safety-Critical Systems (FTSCS 2012),,,,,,,,,,,,,,,,,,,,
Book Chapter,"Steppler M,Lott M","Cavalli A,Sarma A",- SPEET —SDL Performance Evaluation Tool,,1997,,,53-67,,Elsevier Science B.V.,Amsterdam,SDL '97: Time for Testing,1997,9780444828163,,https://www.sciencedirect.com/science/article/pii/B9780444828163500058;http://dx.doi.org/10.1016/B978-044482816-3/50005-8,10.1016/B978-044482816-3/50005-8,"Publisher Summary This chapter presents the tool Specification Description Language (SDL) Performance Evaluation Tool (SPEET) for the performance analysis of formally specified systems under real-time conditions. SPEET facilitates the simulation and emulation of several formal specifications at the same time. The systems to be simulated can be triggered by traffic load generators and can be interconnected with transmission links that correspond to physical channels. The user can easily define probes within the formal specifications. The data of these probes generated during simulation runs can be statistically evaluated. SPEET provides a new computer aided software engineering (CASE) oriented solution for product development using formal methods. The CASE cycle of development include object-oriented analysis using the object modeling technique (OMT), formal specification of this analysis' result in SDL, and the evaluation and verification of the implementation of formal specifications under real-time conditions on target hardware processor systems.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Canal C,Pimentel E,Troya JM",,Compatibility and inheritance in software architectures,Science of Computer Programming,2001,41,2,105-138,,,,,2001,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642301000028;http://dx.doi.org/10.1016/S0167-6423(01)00002-8,10.1016/S0167-6423(01)00002-8,"The application of formal methods to the development of software depends on the availability of adequate models and formalisms for each of the stages of the development process. In this work, we focus on the level of design called Software Architecture. At this level, the system is described as a collection of interrelated components, and it is here where the properties derived from the system's structure can be naturally analyzed. Our approach uses process algebras as a formal basis for the description and analysis of software architectures. Process algebras are widely accepted for the specification of software systems. In particular, π-calculus addresses the description of systems with a dynamic or evolving topology, and permits their analysis for bisimilarity and other interesting properties. Though bisimilarity determines the equivalence of behavior, more flexible relations are needed in the context of Software Engineering, in order to support formally the notions of conformance and refinement of behavior. In this paper we present a relation of compatibility in the context of π-calculus which formalizes the notion of conformance of behavior between software components. Our approach is enhanced with the definition of a relation of inheritance among processes. This relation preserves compatibility and indicates whether a process can be considered as a specialization or extension of another one. The suitability of our approach is shown by its application to the field of Software Architecture.","Theory of concurrency, Process calculi, -calculus, Software architecture, Compatibility and inheritance of behavior",,,,,,,,,,,,,,,,,,,,,
Journal Article,"France R,Evans A,Lano K,Rumpe B",,The UML as a formal modeling notation,Computer Standards & Interfaces,1998,19,7,325-334,,,,,1998,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548998000208;http://dx.doi.org/10.1016/S0920-5489(98)00020-8,10.1016/S0920-5489(98)00020-8,"The Unified Modeling Language (UML) is an Object Management Group (OMG) object-oriented (OO) modeling notation standard. It consists of a set of notations for modeling systems from a variety of views and at varying levels of abstraction. While the UML reflects some of the best OO modeling experiences available, it suffers from a lack of precise semantics that is necessary if one is to use the notations to precisely model systems and to rigorously reason about the models. In this paper we discuss some of the problems with the current UML semantic document and present the approach that the precise UML group (pUML) group is using to develop a precise semantics for the UML. The approach utilizes mathematical techniques to explore and gain insights into appropriate semantics for UML modeling concepts. The insights and formal expressions will then be used to develop a UML semantics document written in natural language that defines the semantics in a precise, consistent, and understandable manner.","UML, Formal methods, Graphical notations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cirstea H,Kirchner C",,The simply typed rewriting calculus,Electronic Notes in Theoretical Computer Science,2000,36,,24-42,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105801276;http://dx.doi.org/10.1016/S1571-0661(05)80127-6,10.1016/S1571-0661(05)80127-6,"The rewriting calculus is a rule construction and application framework. As such it embeds in a uniform way term rewriting and lambda-calculus. Since rule application is an explicit object of the calculus, it allows us also to handle the set of results explicitly. We present a simply typed version of the rewriting calculus. With a good choice of the type system, we show that the calculus is type preserving and terminating, i.e. verifies the subject reduction and strong normalization properties.",,The 3rd International Workshop on Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bono V,Bugliesi M",,"Preface: Volume 82, Issue 8",Electronic Notes in Theoretical Computer Science,2003,82,8,151-152,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105808060;http://dx.doi.org/10.1016/S1571-0661(05)80806-0,10.1016/S1571-0661(05)80806-0,"First Workshop on Object Oriented Developments This volume contains the Proceedings of the First Workshop on Object Oriented Developments (WOOD'2003). The Workshop was held in Warsaw, Poland on April 13, 2003, as a satellite event to ETAPS'2003. Object-oriented programming languages have long been the subject of extensive foundational and applied research in a wide range of fields, including semantics, type theory, program verification and program development. More recently, object-oriented programming has emerged as an effective paradigm for structuring, composing and coordinating concurrent, distributed, and mobile code. The workshop provided a forum for discussion about theoretical work on object-oriented models and type systems, as well as presentation of experience reports on, and novel techniques for, program analysis and verification. The volume includes two invited presentations, and five papers selected for publication by the following Program Committee Members: •Viviana Bono (University of Torino, Italy)•Michele Bugliesi (University of Venezia, Italy)•Giuseppe Castagna(Ecole Normale Superieure, Paris, France)•Adriana Compagnoni(Stevens Institute of Technology, USA)•Kathleen Fisher(AT&T Labs, USA)•Matthew Flatt(University of Utah, USA)•Julian Rathke(University of Sussex, UK)•Christopher Stone(Harvey Mudd College, USA)) This volume will be published as Volume 82 in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs We would like to thank all who contributed to the success of WOOD2003:the participants, the invited speakers Kim B. Bruce and Vladimiro Sassone, the authors, the PC members, the ETAPS organisers and the ENTCS editors. Special thanks to Damian Niwinski for his help with the organization of the Workshop, to Michael Mislove and Elsevier Publishers for making it possible to include our proceedings in Electronic Notes in Theoretical Computer Science and to Warsaw University for printing the hard copy of our proceedings. June 15, 2003Viviana Bono and Michele Bugliesi",,"WOOD2003, Workshop on Object Oriented Developments (Satellite Event of ETAPS 2003)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Abbas M,Rioboo R,Ben-Yelles CB,Snook CF",,Formal modeling and verification of UML Activity Diagrams (UAD) with FoCaLiZe,Journal of Systems Architecture,2021,114,,101911,,,,,2021,,1383-7621,https://www.sciencedirect.com/science/article/pii/S1383762120301776;http://dx.doi.org/10.1016/j.sysarc.2020.101911,10.1016/j.sysarc.2020.101911,"The UML Activity Diagram (UAD) is mostly used for modeling behavioral aspects of objects and systems. OCL (Object Constraint Language) is used together with UAD to specify guard conditions and action constraints. Due to the ambiguous semantics of UAD, it is relevant to formalize such diagrams using formal semantics and formal methods. In this paper, we opt for a formal transformation of UML activity diagrams denoted by functional semantics into FoCaLiZe, a proof based formal language. The ultimate goal is to detect eventual inconsistencies of UML activity diagrams and to prove their properties using Zenon, the automatic theorem prover of FoCaLiZe. In addition to the proposed formal basis for UAD. The presented approach directly supports action constraints, activity partitions and the communication between structural and dynamic aspects of UML models.","UML Activity Diagram, UML semantics, Software engineering, Model properties, Model verification, Formal methods",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wallis S,Edmonds B,Moss S,Gaylard H",,A Strictly Declarative Language for Multi-Agent Modelling,IFAC Proceedings Volumes,1998,31,16,165-170,,,,,1998,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017404769;http://dx.doi.org/10.1016/S1474-6670(17)40476-9,10.1016/S1474-6670(17)40476-9,"A programming language which is optimised for modelling multi-agent interaction within articulated social structures such as organizations is described with several examples of its functionality. The language is SDML, a strictly declarative modelling language which has object-oriented features and corresponds to a known formal logic. The virtues of SDML include the ease of building complex models and the facility for representing agents flexibly as models of cognition as well as modularity and code reusability. Features of SDML are illustrated by a model of an economic system with cognitive agents and explicit representation of transactions as a process of negotiation and agreement leading to exchange","Modelling, Agents, Communication, Rule-based systems, Databases, Object-oriented programming, Simulation languages, Logic, Economic systems","IFAC Symposium on Computation in Economics, Finance and Engineering: Economic Systems, Cambridge, UK, 29 June - 1 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Millstein T,Chambers C",,Modular Statically Typed Multimethods,Information and Computation,2002,175,1,76-118,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540102931032;http://dx.doi.org/10.1006/inco.2002.3103,10.1006/inco.2002.3103,"Multimethods offer several well-known advantages over the single dispatching of conventional object-oriented languages, including a simple solution to the binary method problem, a natural implementation of the strategy design pattern, and a form of open objects that enables easy addition of new operations to existing classes. However, previous work on statically typed multimethods whose arguments are treated symmetrically has required the whole program to be available in order to perform typechecking. We describe Dubious, a simple core language including first-class generic functions with symmetric multimethods, a classless object model, and modules that can be separately typechecked. We identify two sets of restrictions that ensure modular type safety for Dubious as well as an interesting intermediate point between these two. We have proved each of these modular type systems sound.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhang W,Oliveira BC",,Castor: Programming with extensible generative visitors,Science of Computer Programming,2020,193,,102449,,,,,2020,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642320300599;http://dx.doi.org/10.1016/j.scico.2020.102449,10.1016/j.scico.2020.102449,"Much recent work on type-safe extensibility for Object-Oriented languages has focused on design patterns that require modest type system features. Examples of such design patterns include Object Algebras, Extensible Visitors, Finally Tagless interpreters, or Polymorphic Embeddings. Those techniques, which often use a functional style, can solve basic forms of the Expression Problem. However, they have important limitations. This paper presents Castor: a Scala framework for programming with extensible, generative visitors. Castor has several advantages over previous approaches. Firstly, Castor comes with support for (type-safe) pattern matching to complement its visitors with a concise notation to express operations. Secondly, Castor supports type-safe interpreters (à la Finally Tagless), but with additional support for pattern matching and a generally recursive style. Thirdly, Castor enables many operations to be defined using an imperative style, which is significantly more performant than a functional style (especially in the JVM platform). Finally, functional techniques usually only support tree structures well, but graph structures are poorly supported. Castor supports type-safe extensible programming on graph structures. The key to Castor's usability is the use of annotations to automatically generate large amounts of boilerplate code to simplify programming with extensible visitors. To illustrate the applicability of Castor we present several applications and two case studies. The first case study compares the ability of Castor for modularizing the interpreters from the “Types and Programming Languages” book with previous modularization work. The second case study on UML activity diagrams illustrates the imperative aspects of Castor, as well as its support for hierarchical datatypes and graphs.","Modularity, Visitor pattern, Pattern matching, Metaprogramming, OOP",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jackson RB,Embley DW",,Using joint application design to develop readable formal specifications,Information and Software Technology,1996,38,10,615-631,,,,,1996,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584995010580;http://dx.doi.org/10.1016/0950-5849(95)01058-0,10.1016/0950-5849(95)01058-0,"A requirements specification is a ‘contract’ between a client and a systems developer. This document is frequently written in some type of ‘computerese’ or formal specification that is unintelligible to most clients. Why can't we have a precise, formal specification that is understandable? In fact, why can't we let the client take charge of developing a formal specification? In this paper, we present OSS (Object-oriented Systems Specification), a graphical model with an embedded textual language that has a formal foundation, is suitable for requirements specification, and is understandable to at least technically oriented clients. We also introduce IPOST, a prototyping/specification tool to assist the client. We describe a Joint Application Development (JAD) scenario utilizing OSS and IPOST that involves heavy client participation in the development of formal requirements specifications.","Requirements specifications, Joint application design, Rapid prototyping",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aguiar MW,Murgatroyd IS,Edwards JM",,Object-oriented resource models: their role in specifying components of integrated manufacturing systems,Computer Integrated Manufacturing Systems,1996,9,1,33-48,,,,,1996,,0951-5240,https://www.sciencedirect.com/science/article/pii/0951524095000364;http://dx.doi.org/10.1016/0951-5240(95)00036-4,10.1016/0951-5240(95)00036-4,"In response to the need to identify improved operating strategies within manufacturing enterprises, a number of formal methods for enterprise engineering have been defined. Predominantly, these methodologies take a ‘top down’ approach based on an analysis of business requirements. Top down design must be tempered by an understanding that manufacturing processes are implemented using what are often inflexible hardware and software resources. This paper describes a CASE environment which provides structured support for resource modelling based on object orientation, and demonstrates the necessary integration with a top down enterprise engineering workbench based on the CIM-OSA reference architecture. The paper concludes by identifying requirements for future resource reference models that will be required to support enterprise engineering and that should be supplied by resource vendors.","manufacturing, object-orientation, CASE, resource, CIM-OSA",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Heiner M,Ventre G,Wikarski D",,A Petri net based methodology to integrate qualitative and quantitative analysis,Information and Software Technology,1994,36,7,435-441,,,,,1994,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584994900663;http://dx.doi.org/10.1016/0950-5849(94)90066-3,10.1016/0950-5849(94)90066-3,"An innovative net-based methodology to integrate qualitative and quantitative analysis of distributed software systems is outlined, and an on-going prototype implementation of a related graphic-oriented tool kit is sketched. The proposed method combines qualitative analysis, monitoring and testing as well as quantitative analysis on the basis of a net-based intermediate representation of the distributed software system under consideration. All transformations (from the distributed software system into a first Petri net model, and between the different kinds of net models) can be made formally, and therefore automated to a high degree. The evaluation of quantitative properties is based on so-called object nets which are obtained by a property-preserving structural compression and quantitative expansion of the qualitative model. In this way, the frequency and delay attributes necessary to generate quantitative models are provided by the monitoring and testing component.","parallel software engineering, process-oriented imperative languages, software validation, static analysis, monitoring, testing, performance evaluation, dependability, formal methods, Petri nets, object nets",Software Engineering for Parallel Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,Xuqin W,,Application of network protocol improvement and image content search in mathematical calculus 3D modeling video analysis,Alexandria Engineering Journal,2021,60,5,4473-4482,,,,,2021,,1110-0168,https://www.sciencedirect.com/science/article/pii/S1110016821001022;http://dx.doi.org/10.1016/j.aej.2021.02.030,10.1016/j.aej.2021.02.030,"This article connects mobile terminals through improved network protocols, and connects monitoring devices through improved network protocols in the local area network. At the same time, it can convert mobile terminal requests into requests that comply with improved network protocols and forward them to monitoring devices. Method of three-dimensional feature extraction based on dynamic data. First, normalize the coordinates and scales of the three-dimensional calculus model, and use two kinds of data (voxel representation and pixel representation) to deal with video object recognition. Then construct a convolutional neural network as an input to the network, extract visual information and geometric information, and use deep learning to improve the recognition ability of single-modal features. Based on the convolutional neural network, the geometric descriptor and the view descriptor of the three-dimensional calculus model are extracted separately, and the two feature descriptors are fused in a network to find the association between the patterns. After forming the fused feature descriptor, it is applied to micro Classification and retrieval of integral 3D features. The multi-feature fusion layer can not only learn more distinguishing features of the two descriptors, but also supplement relevant information between the two descriptors. Compared with using these two representations alone, this method produces a much better classifier and improves retrieval efficiency.","Network protocol, Image content search, Calculus 3D modeling, Video analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Boffa S,Murinová P,Novák V",,A proposal to extend Relational Concept Analysis with fuzzy scaling quantifiers,Knowledge-Based Systems,2021,231,,107452,,,,,2021,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705121007140;http://dx.doi.org/10.1016/j.knosys.2021.107452,10.1016/j.knosys.2021.107452,"In this article, we integrate Relational Concept Analysis with fuzzy logic to explore multi-relational datasets including also vague information. Mainly, we aim to extract a family of fuzzy concept lattices from data organized as a collection of fuzzy formal contexts and fuzzy relations between objects of different types. To achieve this goal, we use existing fuzzy FCA techniques and fuzzy scaling quantifiers. Our principal contribution here consists of introducing and studying fuzzy scaling quantifiers, which are fuzzy quantifiers based on the concept of evaluative linguistic expression.","Relational concept analysis, Scaling quantifiers, Fuzzy quantifiers, Fuzzy formal concept analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,Watt DA,,The Design of Monty: a Programming/Scripting Language,Electronic Notes in Theoretical Computer Science,2005,141,4,5-28,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105051820;http://dx.doi.org/10.1016/j.entcs.2005.05.011,10.1016/j.entcs.2005.05.011,"This paper describes the design of Monty, a language intended to be equally suitable for both scripting and conventional programming. Monty features an unusually flexible type system in which all values are viewed as objects in a single-inheritance class hierarchy, static and dynamic typing are smoothly integrated, and both nonvariant and covariant generic classes are supported. An interesting byproduct of the design of Monty has been the light it has shed on the power of mutability as a linguistic concept. Among other things, it turns out that the type-soundness of a covariant generic class is closely related to the class's mutability.","Programming language, scripting language, static typing, dynamic typing, single inheritance, mutability, inclusion polymorphism, parametric polymorphism, generic class, covariant type parameterization","Proceedings of the Fifth Workshop on Language Descriptions, Tools, and Applications (LDTA 2005)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Beeri Y,Spiegler I",,Synergetic expert systems,Decision Support Systems,1996,17,2,73-82,,,,,1996,,0167-9236,https://www.sciencedirect.com/science/article/pii/0167923695000143;http://dx.doi.org/10.1016/0167-9236(95)00014-3,10.1016/0167-9236(95)00014-3,"A model for integrating Expert Systems is presented. The model — Synergetic Expert System (SES) — contains several expert systems which can be arranged synergetically to suit the particular needs of a problem. An object-oriented approach is used to design the model and handle its various components. The building blocks of the model, arranged in series or parallel, are defined together with a formal delineation of efficient and economic expert systems. These lead to a definition of marginal cost and value of an expert to a system. The model may be applied when different experts or expert systems are needed to tackle a complex problem. Treating experts or expert systems in parallel may also be viewed as a form of Group Decision Support System (GDSS).","Expert system, Decision support system (DSS), Artificial intelligence, Decision making, Object-oriented design, Group decision support system (GDSS), Value of information",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aubry F,Chameroy V,Di Paola R",,A medical image object-oriented database with image processing and automatic reorganization capabilities,Computerized Medical Imaging and Graphics,1996,20,4,315-331,,,,,1996,,0895-6111,https://www.sciencedirect.com/science/article/pii/S0895611196000225;http://dx.doi.org/10.1016/S0895-6111(96)00022-5,10.1016/S0895-6111(96)00022-5,"The paper presents the medical image database developed for use in the methodological research environment and in the laboratory clinical environment, designed to be capable of being interfaced to an image processing system. This database is intended to solve the numerous problems due to the complexity—multidimensionality and multimodality—of medical images. These problems are posed in terms of management, archiving, structuring and accessing of this archive, and specification of the interfaces with users and with image processing systems. Solving these problems involves making a formal description of the image and the data associated with the image, while taking into account the specifics of medical imaging. The kernel which contains this description allows the physical architecture of the management and archiving system to be decoupled from its logical architecture. This decoupling is essential in order to automate the recording of new data, the automatic reorganization of the system schema in the event of change in the system environment, and to help in consulting the database.","Directory services, Image processing, Medical Image Database, Referential dependency graph, Meta-schema (of a database), Object oriented DBMS, Relational DBMS, Semantic model",Medical Image Databases,,,,,,,,,,,,,,,,,,,,
Journal Article,Singh PK,,m-polar fuzzy graph representation of concept lattice,Engineering Applications of Artificial Intelligence,2018,67,,52-62,,,,,2018,,0952-1976,https://www.sciencedirect.com/science/article/pii/S0952197617302257;http://dx.doi.org/10.1016/j.engappai.2017.09.011,10.1016/j.engappai.2017.09.011,"Recently, the calculus of fuzzy concept lattice is studied beyond the three-way fuzzy space ([0,1]3) for precise representation of uncertainty and vagueness in the attributes. However, to dovetail the uncertainty in case of voxel, multi-index or multi-polar information the properties of lattice theory need to be explored in component wise m-polar fuzzy space ([0,1]m). In this case, another problem arises while finding some of the hidden or interested pattern from the given m-polar fuzzy context for the knowledge processing tasks. To conquer this problem, current paper generalizes the mathematical background of concept lattice with m-polar fuzzy sets and its graphical properties. To elicit this objective, two methods are introduced for providing a unified framework based on discovered m-polar formal fuzzy concepts and their projection.","Formal concept analysis, Fuzzy concept lattice, -polar fuzzy set, -polar fuzzy graph, -polar formal fuzzy concept",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Pérez J,Ramos I,Anaya V,Cubel JM,Domínguez F,Boronat A,Carsí JA",,Data Reverse Engineering of Legacy Databases to Object Oriented Conceptual Schemas,Electronic Notes in Theoretical Computer Science,2003,72,4,7-19,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104806224;http://dx.doi.org/10.1016/S1571-0661(04)80622-4,10.1016/S1571-0661(04)80622-4,This paper presents a solution and a methodology to recover legacy databases of most DBMS using formal-method based techniques. These formal methods (terms rewriting systems) are applied during the data reverse engineering process and allow for an automatic approach. This automatic approach reduces the time invested and the number of people involved in the data reverse engineering and data migration processes. This solution is being implemented in the RELS (Re-Engineering of Legacy Systems) tool. The RELS tool is under development in the Department of Information Systems and Computation of the Valencia University of Technology in collaboration with the industrial partner CARE-Technologies. RELS is used together with the model compiler Sosy Technology® of CARE-Technologies and provides a complete solution to the re-engineering proccess.,"Re-engineering, Reverse engineering, Terms rewriting system (TRS), Data reverse engineering, Rewriting rules, Algebraic expressions, ADT (Abstract Data Type)",Workshop on Software Evolution Through Transformations - Toward Uniform Support Throughout the Software Life-Cycle (First International Conference on Graph Transformation),,,,,,,,,,,,,,,,,,,,
Journal Article,"Coulibaly A,Mutel B,Ait-Kadi D",,Product modeling framework for behavioral performance evaluation at design stage,Computers in Industry,2007,58,6,567-577,,,,,2007,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361507000024;http://dx.doi.org/10.1016/j.compind.2006.12.005,10.1016/j.compind.2006.12.005,In this paper we present a framework for product behavioral performances evaluation during design process. It is based on the product behavioral modeling approach and uses an evaluation method that determines performance indicators for different domains of the product lifecycle. We are mainly focused on semantic and fuzzy domains that are complex to formalize. We show how the product design solutions represented in a CAD system can be analyzed to evaluate the product performances at some specific domains. After a short state of art on product modeling methods we define a FBS product behavioral modeling approach based on the object-oriented modeling formalism. Here the product is described as a conceptual object with properties and formal criteria evaluation methods for different domains. Then a behavioral performance evaluation procedure is detailed and we outline software architecture for implementation in a CAD system. An application for product maintainability assessment of an industrial trailer illustrates the approach.,"Product modeling, Behavioral Performance Assessment, Maintainability, CAD systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ahn GJ,Hong SP,Shin ME",,Reconstructing a formal security model,Information and Software Technology,2002,44,11,649-657,,,,,2002,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584902000927;http://dx.doi.org/10.1016/S0950-5849(02)00092-7,10.1016/S0950-5849(02)00092-7,"Role-based access control (RBAC) is a flexible approach to access control, which has generated great interest in the security community. The principal motivation behind RBAC is to simplify the complexity of administrative tasks. Several formal models of RBAC have been introduced. However, there are a few works specifying RBAC in a way which system developers or software engineers can easily understand and adopt to develop role-based systems. And there still exists a demand to have a practical representation of well-known access control models for system developers who work on secure system development. In this paper we represent a well-known RBAC model with software engineering tools such as Unified Modeling Language (UML) and Object Constraints Language (OCL) to reduce a gap between security models and system developments. The UML is a general-purpose visual modeling language in which we can specify, visualize, and document the components of a software system. And OCL is part of the UML and has been used for object-oriented analysis and design as a de facto constraints specification language in software engineering arena. Our representation is based on a standard model for RBAC proposed by the National Institute of Standards and Technology. We specify this RBAC model with UML including three views: static view, functional view, and dynamic view. We also describe how OCL can specify RBAC constraints that is one of important aspects to constrain what components in RBAC are allowed to do. In addition, we briefly discuss future directions of this work.","Access control, Role-based, Formal model, UML",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Štuikys V,Burbaitė R,Bespalova K,Ziberkas G",,Model-driven processes and tools to design robot-based generative learning objects for computer science education,Science of Computer Programming,2016,129,,48-71,,,,,2016,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642316300247;http://dx.doi.org/10.1016/j.scico.2016.03.009,10.1016/j.scico.2016.03.009,"In this paper, we introduce a methodology to design robot-oriented generative learning objects (GLOs) that are, in fact, heterogeneous meta-programs to teach computer science (CS) topics such as programming. The methodology includes CS learning variability modelling using the feature-based approaches borrowed from the SW engineering domain. Firstly, we define the CS learning domain using the known educational framework TPACK (Technology, Pedagogy And Content Knowledge). By learning variability we mean the attributes of the framework extracted and represented as feature models with multiple values. Therefore, the CS learning variability represents the problem domain. Meta-programming is considered as a solution domain. Both are represented by feature models. The GLO design task is formulated as mapping the problem domain model on the solution domain model. Next, we present the design framework to design GLOs manually or semi-automatically. The multi-level separation of concepts, model representation and transformation forms the conceptual background. Its theoretical background includes: (a) a formal definition of feature-based models; (b) a graph-based and set-based definition of meta-programming concepts; (c) transformation rules to support the model mapping; (d) a computational Abstract State Machine model to define the processes and design tool for developing GLOs. We present the architecture and some characteristics of the tool. The tool enables to improve the GLO design process significantly (in terms of time and quality) and to achieve a higher quality and functionality of GLOs themselves (in terms of the parameter space enlargement for reuse and adaptation). We demonstrate the appropriateness of the methodology in the real teaching setting. In this paper, we present the case study that analyses three robot-oriented GLOs as the higher-level specifications. Then, using the meta-language processor, we are able to produce, from the specifications, the concrete robot control programs on demand automatically and to demonstrate teaching algorithms visually by robot's actions. We evaluate the approach from technological and pedagogical perspectives using the known structural metrics. Also, we indicate the merits and demerits of the approach. The main contribution and originality of the paper is the seamless integration of two known technologies (feature modelling and meta-programming) in designing robot-oriented GLOs and their supporting tools.","Feature models, Model transformation, Generative learning objects (GLOs), GLO design tool, Educational robots",Special issue on eLearning Software Architectures,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yang L,Xu L",,On Rough Concept Lattices,Electronic Notes in Theoretical Computer Science,2009,257,,117-133,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109004800;http://dx.doi.org/10.1016/j.entcs.2009.11.030,10.1016/j.entcs.2009.11.030,"Formal concept analysis and rough set theory provide two different methods for data analysis and knowledge processing. Given a context K, one can get the concept lattice L(K) in Wille's sense and the object-oriented rough concept lattice RO-L(K) (resp., attribute-oriented RA-L(K)). We study relations of the three kinds of lattices and their properties from the domain theory point of view. The concept of definable sets is introduced. It is proved that the family Def (K) of the definable sets in set-inclusion order is a complete sublattice of RO-L(K) and is a complete field of sets under some reasonable conditions. A necessary and sufficient condition for Def (K) to be equal to RO-L(K) is given. A necessary and sufficient condition is also given for the complete distributivity of RO-L(K). We also study algebraicity of RO-L(K) and several sufficient conditions are given for RO-L(K) to be algebraic.","Rough, Concept, Galois connection, Algebraic lattice, Definable set",Proceedings of the Fifth International Symposium on Domain Theory (ISDT 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Chen B,Sun M,Zhou M",,Granular Rough Theory: A representation semantics oriented theory of roughness,Applied Soft Computing,2009,9,2,786-805,,,,,2009,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494608001592;http://dx.doi.org/10.1016/j.asoc.2008.07.008,10.1016/j.asoc.2008.07.008,"The present work is an archival paper for a series of contributions proposed in last few years on building a theory of roughness over pure mereological relations among information granules. There are five major efforts taken in the present paper: (1) emphasizing on the representational semantics of theory of roughness: to approximately represent a class of entities characterized by some aspects in terms of entity collections described at other aspects; (2) defining a representation model Granular Representation Calculus (GrRC) to synthesize complex information systems from information granules; (3) establishing notion of Granular Rough Theory (GrRT) over information granules operated in terms of GrRC; (4) extending GrRC/GrRT to various computational environments such as multi-agent systems and ontological computing environments; (5) exploring pragmatic aspects of GrRC/GrRT in implementing prototypes with data model and object programming orientations, and proposing an Ontology-Driven Web Information System as a granular-rough computational Web intelligence framework over GrRC/GrRT.","Granular Representation Calculus, Granular Rough Theory, Granular-Rough Computational Web Intelligence",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Færgemand O,Olsen A",,Introduction to SDL-92,Computer Networks and ISDN Systems,1994,26,9,1143-1167,,,,,1994,,0169-7552,https://www.sciencedirect.com/science/article/pii/0169755294900167;http://dx.doi.org/10.1016/0169-7552(94)90016-7,10.1016/0169-7552(94)90016-7,"This paper contains an introduction to SDL — Specification and Description Language — as it appears in the revised CCITT (At the plenary assembly March 1993, CCITT was renamed to WTSC (World Telecommunication Standardization Conference); however, this paper uses the more familiar term CCITT) recommendation. The paper covers main aspects of the new version of SDL in three main areas: structure, behaviour and data. The paper covers in particular the new features for object-oriented structuring in the language. The paper concludes with an overview of current activities in standards, research and industry.","Formal description technique, Computer-aided software engineering, Graphical representation, Object-orientation, Type, Instance, Specialization, Generic types, State machines",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Durán F,Roldán M,Vallecillo A",,Using Maude to write and execute ODP information viewpoint specifications,Computer Standards & Interfaces,2005,27,6,597-620,,,,,2005,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548904001308;http://dx.doi.org/10.1016/j.csi.2004.10.008,10.1016/j.csi.2004.10.008,"The aim of the open distributed processing (ODP) information viewpoint is to describe the semantics of the information and of the information processing in a system, from a global point of view, without having to worry about other considerations, such as how the information will be finally distributed or implemented or the technology used to achieve such implementation. Although several notations have been proposed to model this ODP viewpoint, they are not expressive enough to faithfully represent all the information concepts, or they tend to suffer from a lack of (formal) support, or both. In this paper, we explore the use of Maude as a formal notation for writing ODP information specifications. Maude is an executable rewriting logic language especially well suited for the specification of object-oriented open and distributed systems. We show how Maude offers a simple, natural, and accurate way of modeling the ODP information viewpoint concepts, allows the execution of the specifications produced, and offers good tool support for reasoning about them.","Rewriting logic, Maude, RM-ODP, ODP information viewpoint, Collective behavior, Invariants",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yan E,Yu C,Lu L,Hong W,Tang C",,Incremental concept cognitive learning based on three-way partial order structure,Knowledge-Based Systems,2021,220,,106898,,,,,2021,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705121001611;http://dx.doi.org/10.1016/j.knosys.2021.106898,10.1016/j.knosys.2021.106898,"With the vigorous development of the information technology industry, the information data available to mankind has shown an explosive growth trend. Dynamic concept learning is an approach that can effectively process the acquired massive data and extract valuable information from them. Concept cognitive learning (CCL) is a very active research direction in the field of dynamic concept learning, while partial order formal structure analysis (POFSA) is a concrete and practical model of CCL. However, the existing CCL algorithms in POFSA face some challenges when processing constantly changing data. Therefore, this paper is devoted to explore an incremental CCL algorithm based on three-way object partial order structure diagram (OPOSD) in POFSA with the incorporation of the thoughts of incremental learning. The features of five object categories are considered, and their incremental influences on three-way OPOSD are analyzed and their incremental CCL algorithms in three-way OPOSD are established. Based on some real famous formal contexts, this paper conducts numerical experiments, and the results show that the incremental CCL algorithm based on three-way OPOSD is consistent with human cognitive principles, and can improve the CCL performance of POFSA as well.","Partial order formal structure analysis, Object partial order structure, Concept cognitive learning, Incremental learning, Dynamic concept learning, Three-way decision",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Qutaishat MA,Fiddian NJ,Gray WA",,Extending OMT to support bottom-up design modelling in a heterogeneous distributed database environment,Data & Knowledge Engineering,1997,22,2,191-205,,,,,1997,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X97814103;http://dx.doi.org/10.1016/S0169-023X(97)81410-3,10.1016/S0169-023X(97)81410-3,"We present an extension to the object model of OMT to cope with bottom-up database design. By investigation, it was discovered that OMT as it stands is inadequate to capture some real world semantic and structural information needed to perform schema integration for pre-existing databases in a heterogeneous distributed database environment. Therefore the proposed extension, called Integrated OMT (IOMT), was formally defined and an appropriate extended graphical notation was produced as a part of our work. This extended form was implemented and applied effectively using a tool which we call the schema meta-integration/visualisation system (SMIS/SMVS).","Heterogeneous distributed databases, Bottom-up design, Object-oriented data modelling, Schema integration, Schema visualisation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Edward Nawarecki EC,Cetnarowicz K",,Agent Oriented Technology of Decentralized Systems Based on the M-Agent Architecture,IFAC Proceedings Volumes,1997,30,19,381-386,,,,,1997,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017423299;http://dx.doi.org/10.1016/S1474-6670(17)42329-9,10.1016/S1474-6670(17)42329-9,"An idea of autonomous agents that arises as an extension of the object and process concepts may be applied to distributed and decentralized systems development. In the paper the authors have undertaken an attempt to describe formally the architecture of multi-agent systems (called M-agent architecture) that may be considered as a starting point to develop a decentralized multiagent, system technology such as Agent Oriented Analysis, Design and Programming.","decentralized systems, agents, distributed artificial intelligence, systems design","IFAC/IFIP Conference on Management and Control of Production and Logistics (MCPL'97), Campinas, SP, Brazil, 31 August-3 September 1997",,,,,,,,,,,,,,,,,,,,
Journal Article,"Krbek M,Musilova J",,Representation of the variational sequence by differential forms,Reports on Mathematical Physics,2003,51,2,251-258,,,,,2003,,0034-4877,https://www.sciencedirect.com/science/article/pii/S0034487703800186;http://dx.doi.org/10.1016/S0034-4877(03)80018-6,10.1016/S0034-4877(03)80018-6,"The complete solution of the problem of representation of the finite-order variational sequence in field theory by differential forms is presented by means of formal differential operators. A close relationship between this representation and familiar objects of the calculus of variations, such as Lagrangians, dynamical forms, Euler-Lagrange and Helmholtz-Sonin mappings is described and illustrated by examples.","Contact form, de Rhann sequence, variational sequence, Euler-Lagrange mapping, Helmholtz-Sonin mapping, formal differential operator",Proceedings of the XXXIV Symposium on Mathematical Physics,,,,,,,,,,,,,,,,,,,,
Journal Article,Åhlander K,,Einstein summation for multidimensional arrays,Computers & Mathematics with Applications,2002,44,8,1007-1017,,,,,2002,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122102002109;http://dx.doi.org/10.1016/S0898-1221(02)00210-9,10.1016/S0898-1221(02)00210-9,"One of the most common data structures, at least in scientific computing, is the multidimensional array. Some numerical algorithms may conveniently be expressed as a generalized matrix multiplication, which computes a multidimensional array from two other multidimensional arrays. By adopting index notation with the Einstein summation convention, an elegant tool for expressing generalized matrix multiplications is obtained. Index notation is the succinct and compact notation primarily used in tensor calculus. In this paper, we develop computer support for index notation as a domain specific language. Grammar and semantics are proposed, yielding an unambiguous interpretation algorithm. An object-oriented implementation of a C++ library that supports index notation is described. A key advantage with computer support of index notation is that the notational gap between a mathematical index notation algorithm and its implementation in a computer language is avoided. This facilitates program construction as well as program understanding. Program examples that demonstrate the close resemblance between code and the original mathematical formulation are presented.","Index notation, Mathematical software, Domain specific language, Tensor calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rocco CM,Hernandez-Perdomo E,Mun J",,Introduction to formal concept analysis and its applications in reliability engineering,Reliability Engineering & System Safety,2020,202,,107002,,,,,2020,,0951-8320,https://www.sciencedirect.com/science/article/pii/S0951832020305032;http://dx.doi.org/10.1016/j.ress.2020.107002,10.1016/j.ress.2020.107002,"Formal Analysis of Concepts (FCA) is a method of data analysis that helps to study the relationship between a set of objects and a set of attributes (the formal context). FCA not only allows detecting data groups (concepts) and their graphical visualization, but also extracting rules that could reveal the underlying structure of the analyzed context. The main idea of this paper is to present the fundamentals of FCA and how it can be used in reliability engineering problems. To this aim, examples in reliability engineering, from both the literature and authors’ experience, have been selected for analysis. Comments on the new insights provided by FCA are also highlighted. Finally, the results from the examples selected show that other reliability areas could benefit from using an FCA-based approach.","Defense strategies, Failure analysis, Formal concept analysis, Knowledge space theory, Partial order, Reliability engineering",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Luo Z,Soloviev S,Xue T",,Coercive subtyping: Theory and implementation,Information and Computation,2013,223,,18-42,,,,,2013,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540112001757;http://dx.doi.org/10.1016/j.ic.2012.10.020,10.1016/j.ic.2012.10.020,"Coercive subtyping is a useful and powerful framework of subtyping for type theories. The key idea of coercive subtyping is subtyping as abbreviation. In this paper, we give a new and adequate formulation of T[C], the system that extends a type theory T with coercive subtyping based on a set C of basic subtyping judgements, and show that coercive subtyping is a conservative extension and, in a more general sense, a definitional extension. We introduce an intermediate system, the star-calculus T[C]⁎, in which the positions that require coercion insertions are marked, and show that T[C]⁎ is a conservative extension of T and that T[C]⁎ is equivalent to T[C]. This makes clear what we mean by coercive subtyping being a conservative extension, on the one hand, and amends a technical problem that has led to a gap in the earlier conservativity proof, on the other. We also compare coercive subtyping with the ‘ordinary’ notion of subtyping – subsumptive subtyping, and show that the former is adequate for type theories with canonical objects while the latter is not. An improved implementation of coercive subtyping is done in the proof assistant Plastic.","Coercive subtyping, Conservativity, Definitional extension, Subsumptive subtyping, Type theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sunyé G,Le Guennec A,Jézéquel JM",,Using UML Action Semantics for model execution and transformation,Information Systems,2002,27,6,445-457,,,,,2002,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437902000145;http://dx.doi.org/10.1016/S0306-4379(02)00014-5,10.1016/S0306-4379(02)00014-5,"The Unified Modelling Language (UML) lacks precise and formal foundations and semantics for several modeling constructs, such as transition guards or method bodies. These semantic discrepancies and loopholes prevent executability, making early testing and validation out of reach of UML tools. Furthermore, the semantic gap from high-level UML concepts to low-level programming constructs found in traditional object-oriented language prevents the development of efficient code generators. The recent Action Semantics (AS) proposal tackles these problems by extending the UML with yet another formalism for describing behavior, but with a strong emphasis on dynamic semantics. This formalism provides both, a metamodel integrated into the UML metamodel, and a model of execution for these statements. As a future OMG standard, the AS eases the move to tool interoperability, and allows for executable modeling and simulation. We explore in this paper a specificity of the AS: its applicability to the UML metamodel, itself a UML model. We show how this approach paves the way for powerful metaprogramming for model transformation. Furthermore, the overhead for designers is minimal, as mappings from usual object-oriented languages to the AS will be standardized.","UML, Action Semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Abdalazeim A,Meziane F",,A review of the generation of requirements specification in natural language using objects UML models and domain ontology,Procedia Computer Science,2021,189,,328-334,,,,,2021,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050921012266;http://dx.doi.org/10.1016/j.procs.2021.05.102,10.1016/j.procs.2021.05.102,"In the software development life cycle, requirements engineering is the main process that is derived from users by informal interviews written in natural language by requirements engineers (analysts). The requirements may suffer from incompleteness and ambiguity when transformed into formal or semi-formal models that are not well understood by stakeholders. Hence, the stakeholder cannot verify if the formal or semi-formal models satisfy their needs and requirements. Another problem faced by requirements is that when code and/or designs are updated, it is often the case that requirements and specifically the requirements document are not updated. Hence ending with a requirements document not reflecting the implemented software. Generating requirements from the design and/or implementation document is seen by many researchers as a way to address the latter issue. This paper presents a survey of some works undertaken in the field of generation natural language specifications from object UML model using the support of an ontology. and analyzing the robustness and limitations of these existing approaches. This includes studying the generation of natural language from a formal model, review the generation of natural language from ontologies, and finally reviews studies about check to generate natural language from OntoUML.","Requirements Specification, Natural Language Generation, Object UML Model, Ontology",AI in Computational Linguistics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Xiong X,Liu J,Ding Z",,Design and Verification of a Trustable Medical System,Electronic Notes in Theoretical Computer Science,2010,266,,77-92,,,,,2010,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066110001295;http://dx.doi.org/10.1016/j.entcs.2010.08.050,10.1016/j.entcs.2010.08.050,"Developing an advanced medical informatics system is a grand challenge in the 21st century. In this paper, we construct and analyze a trustable medical system by Refinement Calculus of Object Systems (rCOS) in a model-driven development process. Our method greatly improves the dependability and efficiency of the complicate system. This implies that the formal techniques developed in rCOS can be integrated into a model-driven development process. For the verification, a tool, called UPPAAL, is used to ensure the safety and correctness of the medical system. Our result suggests a way to corporate design and verification in system development process.","formal method, rCOS, UPPAAL, telemedicine",Proceedings of the 3rd International Workshop on Harnessing Theories for Tool Support in Software (TTSS),,,,,,,,,,,,,,,,,,,,
Journal Article,"Fowler S,Karinthi R",,Remote access to CAD databases using an information sharing system,Computers in Industry,1996,29,1,117-122,,,,,1996,,0166-3615,https://www.sciencedirect.com/science/article/pii/0166361595000836;http://dx.doi.org/10.1016/0166-3615(95)00083-6,10.1016/0166-3615(95)00083-6,"This paper describes the access to a database of prosthetic parts using an information sharing system (ISS). The prosthetic parts modeled are made of ceramic materials. The prosthetic parts modeled are a formal head, a cup, and a cup and head device. The information about the prosthetic parts is based on a feature based model and is stored in a relational database which is a part of a CAD system. The model for the information sharing system is object-oriented. The relational database is accessed remotely from the object-oriented model of the ISS using a gateway to the CAD system. This implementation illustrates two key concepts: the ISS approach to distributed, heterogeneous database integration and the ISS methodology for building gateways. It also shows some of the problems and solutions in databases that do not support sql type queries.","Distributed, Heterogeneous, Database, CAD, Features",WET ICE '95,,,,,,,,,,,,,,,,,,,,
Journal Article,Muñoz C,,Proof-term synthesis on dependent-type systems via explicit substitutions,Theoretical Computer Science,2001,266,1,407-440,,,,,2001,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397500001961;http://dx.doi.org/10.1016/S0304-3975(00)00196-1,10.1016/S0304-3975(00)00196-1,"Typed λ-terms are used as a compact and linear representation of proofs in intuitionistic logic. This is possible since the Curry–Howard isomorphism relates proof-trees with typed λ-terms. The proofs-as-terms principle can be used to verify the validity of a proof by type checking the λ-term extracted from the complete proof-tree. In this paper we present a proof synthesis method for dependent-type systems where typed open terms are built incrementally at the same time as proofs are done. This way, every construction step, not just the last one, may be type checked. The method is based on a suitable calculus where substitutions as well as meta-variables are first-class objects.","Proof synthesis, Higher-order unification, Explicit substitutions, Lambda calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Malti R,Victor S",,CRONE Toolbox for system identification using fractional differentiation models,IFAC-PapersOnLine,2015,48,28,769-774,,,,,2015,,2405-8963,https://www.sciencedirect.com/science/article/pii/S2405896315028475;http://dx.doi.org/10.1016/j.ifacol.2015.12.223,10.1016/j.ifacol.2015.12.223,"This paper presents the latest developments for the continuous-time system identification toolbox with fractional models (or fractional order systems): the CRONE toolbox. This toolbox is to be run with Matlab which includes time-domain identification algorithms for estimating continuous-time models directly from sampled data. The originality of the implemented algorithms is that they allow either fixing fractional differentiation orders or estimating them along with transfer function coefficients. One of the main issues when dealing with fractional models is their time-domain simulation. Three different time-domain simulation methods can be used independently from system identification methods. Output Error (OE), state variable filters (SVF) and (optimal) instrumental variables (IV) methods for ARX and OE models are provided to the end-user. The object oriented programming of the toolbox allows overloading standard script names. As a consequence, an end-user familiar with standardMatlab operators and scripts can use straightforwardly the CRONE toolbox.","Similarity transformation, Fractional calculus, Subspace method, pseudo-state-space representation, system identification",17th IFAC Symposium on System Identification SYSID 2015,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bettini L,Damiani F,Schaefer I,Strocco F",,TraitRecordJ: A programming language with traits and records,Science of Computer Programming,2013,78,5,521-541,,,,,2013,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642311001572;http://dx.doi.org/10.1016/j.scico.2011.06.007,10.1016/j.scico.2011.06.007,"Traits have been designed as units for fine-grained reuse of behavior in the object-oriented paradigm. Records have been devised to complement traits for fine-grained reuse of state. In this paper, we present the language TraitRecordJ, a Java dialect with records and traits. Records and traits can be composed by explicit linguistic operations, allowing code manipulations to achieve fine-grained code reuse. Classes are assembled from (composite) records and traits and instantiated to generate objects. We introduce the language through examples and illustrate the prototypical implementation of TraitRecordJ using Xtext, an Eclipse framework for the development of programming languages as well as other domain-specific languages. Our implementation comprises an Eclipse-based editor for TraitRecordJ with typical IDE functionalities, and a stand-alone compiler, which translates TraitRecordJ programs into standard Java programs. As a case study, we present the TraitRecordJ implementation of a part of the software used in a web-based information system previously implemented in Java.","Java, Trait, Type system, Implementation, Eclipse",Special section: Principles and Practice of Programming in Java 2009/2010 & Special section: Self-Organizing Coordination,,,,,,,,,,,,,,,,,,,,
Journal Article,"Durán F,Eker S,Escobar S,Martí-Oliet N,Meseguer J,Rubio R,Talcott C",,Programming and symbolic computation in Maude,Journal of Logical and Algebraic Methods in Programming,2020,110,,100497,,,,,2020,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220818301135;http://dx.doi.org/10.1016/j.jlamp.2019.100497,10.1016/j.jlamp.2019.100497,"Rewriting logic is both a flexible semantic framework within which widely different concurrent systems can be naturally specified and a logical framework in which widely different logics can be specified. Maude programs are exactly rewrite theories. Maude has also a formal environment of verification tools. Symbolic computation is a powerful technique for reasoning about the correctness of concurrent systems and for increasing the power of formal tools. We present several new symbolic features of Maude that enhance formal reasoning about Maude programs and the effectiveness of formal tools. They include: (i) very general unification modulo user-definable equational theories, and (ii) symbolic reachability analysis of concurrent systems using narrowing. The paper does not focus just on symbolic features: it also describes several other new Maude features, including: (iii) Maude's strategy language for controlling rewriting, and (iv) external objects that allow flexible interaction of Maude object-based concurrent systems with the external world. In particular, meta-interpreters are external objects encapsulating Maude interpreters that can interact with many other objects. To make the paper self-contained and give a reasonably complete language overview, we also review the basic Maude features for equational rewriting and rewriting with rules, Maude programming of concurrent object systems, and reflection. Furthermore, we include many examples illustrating all the Maude notions and features described in the paper.","Maude and rewriting logic, Strategies, External objects, Unification and narrowing, Symbolic model checking, Meta-interpreters",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Mahfoudhi A,Abed M,Angué JC",Sheridan TB,TOOD : TASK OBJECT ORIENTED DESCRIPTION FOR ERGONOMIC INTERFACES SPECIFICATION,,1995,,,641-646,,Pergamon,Oxford,"Analysis, Design and Evaluation of Man–Machine Systems 1995",1995,9780080423708,,https://www.sciencedirect.com/science/article/pii/B9780080423708500495;http://dx.doi.org/10.1016/B978-0-08-042370-8.50049-5,10.1016/B978-0-08-042370-8.50049-5,"Despite the recent progress in the domain of Man-Machine Interface engineering, several problems concerning the incompatibily between the information presentation to the user and his cognitive representation are still present. This paper presents a new Task Object Description methodology (TOOD). It tries to relate the characteristics of the user's task with those of the interface. The introduction of ergonomic concepts allows to take the human factors into account. And the joint use of the object oriented techniques and the High Level Petri Nets supplies complete, coherent and re-usable entities allowing to give a formal description of the interactive systems' characteristics and an appropriate specification of the user interface. An example, extracted from the air traffic control, is presented to illustrate this new methodology.",,,IFAC Postprint Volume,,,,,,,,,,,,,,,,,,,
Journal Article,"Meyer B,Westerman GD,Gogolla M",,Drafting ER and OO schemas in prototype environments,Data & Knowledge Engineering,1996,19,3,201-240,,,,,1996,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9500046U;http://dx.doi.org/10.1016/0169-023X(95)00046-U,10.1016/0169-023X(95)00046-U,"The system Queer is a prototype of an information system design tool which directly supports an extended Entity-Relationship model on its front-end and uses a semantically well-founded query and manipulation language based on an Entity-Relationship calculus. The system basically consists of a set of compilers written in Prolog which translate data specifications, schema definitions, queries, integrity constraints and data-manipulation statements into Prolog programs. All features mentioned are implemented in form and extent as described here.","Conceptual modelling, Entity Relationship model, Object-oriented modelling, Logic programming, Prototyping",,,,,,,,,,,,,,,,,,,,,
Journal Article,Abel A,,A Third-Order Representation of the λμ-Calculus,Electronic Notes in Theoretical Computer Science,2001,58,1,97-114,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104002816;http://dx.doi.org/10.1016/S1571-0661(04)00281-6,10.1016/S1571-0661(04)00281-6,"Higher-order logical frameworks provide a powerful technology to reason about object languages with binders. This will be demonstrated for the case of the λμ-calculus with two different binders which can most elegantly be represented using a third-order constant. Since cases of third- and higher-order encodings are very rare in comparison with those of second order, a second-order representation is given as well and equivalence to the third-order representation is proven formally.",,MERLIN 2001: Mechanized Reasoning about Languages with Variable Binding (in connection with IJCAR 2001),,,,,,,,,,,,,,,,,,,,
Journal Article,"Diskin Z,Wolter U",,A Diagrammatic Logic for Object-Oriented Visual Modeling,Electronic Notes in Theoretical Computer Science,2008,203,6,19-41,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108004350;http://dx.doi.org/10.1016/j.entcs.2008.10.041,10.1016/j.entcs.2008.10.041,"Formal generalized sketches is a graph-based specification format that borrows its main ideas from categorical and ordinary first-order logic, and adapts them to software engineering needs. In the engineering jargon, it is a modeling language design pattern that combines mathematical rigor and appealing graphical appearance. The paper presents a careful motivation and justification of the applicability of generalized sketches for formalizing practical modeling notations. We extend the sketch formalism by dependencies between predicate symbols and develop new semantic notions based on the Instances-as-typed-structures idea. We show that this new framework fits in the general patterns of the institution theory and is well amenable to algebraic manipulations.","Diagrammatic modeling, model management, generic logic, categorical logic, diagram predicate, categorical sketch",Proceedings of the Second Workshop on Applied and Computational Category Theory (ACCAT 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Vityaev E,Pak B",,Prototypes of the “natural” concepts discovery,Cognitive Systems Research,2021,67,,1-8,,,,,2021,,1389-0417,https://www.sciencedirect.com/science/article/pii/S138904172030111X;http://dx.doi.org/10.1016/j.cogsys.2020.12.005,10.1016/j.cogsys.2020.12.005,"In works of Eleanor Rosch “natural” concepts was introduced that reflect a high correlated structure of features of objects of the external world. Prototypes of the “natural” concepts are clearest cases of objects that reflect this highly correlated structure. The same high correlated structure manifested in the “natural” phenotypical classification. To formalize this highly correlated structure, we define a special type of probabilistic causal relations and then probabilistic formal concepts as a cyclically connected probabilistic causal relations. Based on these definitions, we developed a method of prototypes discovery and illustrate it on the example of digits’ prototypes discovery.","Clustering, Concepts, Concepts discovery, Formal concepts analysis, Data mining",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ligatti J,Walker D,Zdancewic S",,A type-theoretic interpretation of pointcuts and advice,Science of Computer Programming,2006,63,3,240-266,,,,,2006,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642306001213;http://dx.doi.org/10.1016/j.scico.2006.01.004,10.1016/j.scico.2006.01.004,"This article defines the semantics of MinAML, an idealized aspect-oriented programming language, by giving a type-directed translation from a user-friendly external language to a compact, well-defined core language. We argue that our framework is an effective way to give semantics to aspect-oriented programming languages in general because the translation eliminates shallow syntactic differences between related constructs and permits definition of an elegant and extensible core language. The core language extends the simply-typed lambda calculus with two central new abstractions: explicitly labeled program points and first-class advice. The labels serve both to trigger advice and to mark continuations that the advice may return to. These constructs are defined orthogonally to the other features of the language and we show that our abstractions can be used in both functional and object-oriented contexts. We prove Preservation and Progress lemmas for our core language and show that the translation from MinAML source into core is type-preserving. Together these two results imply that the source language is type safe. We also consider several extensions to our basic framework including a general mechanism for analyzing the current call stack.","Aspects, Aspect-oriented programming languages, Operational semantics, Type theory",Special issue on foundations of aspect-oriented programming,,,,,,,,,,,,,,,,,,,,
Journal Article,"Erwig M,Schneider M",,A visual language for the evolution of spatial relationships and its translation into a spatio-temporal calculus,Journal of Visual Languages & Computing,2003,14,2,181-211,,,,,2003,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X02000575;http://dx.doi.org/10.1016/S1045-926X(02)00057-5,10.1016/S1045-926X(02)00057-5,"Queries about objects that change their spatial attributes over time become particularly interesting when they ask for changes in the spatial relationships between different objects. We propose a visual notation that is able to describe scenarios of changing object relationships. The visual language is based on the idea to analyze two-dimensional traces of moving objects to infer a temporal development of their mutual spatial relationships. We motivate the language design by successively simplifying object traces to their intrinsic properties. The notation can be effectively translated into a calculus of spatio-temporal predicates that formally characterizes the evolution of spatial relationships. We also outline a user interface that supports specifications by menus and a drawing editor. The visual notation can be used directly as a visual query interface to spatio-temporal databases, or it can provide predicate specifications that can be integrated into textual query languages leading to heterogeneous languages.","Visual predicate specification, Visual database interface, Spatio-temporal queries, Object traces, Translation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mo JP,Tang BC",,Petri net modelling and design of task oriented messaging system for robot control,Computers & Industrial Engineering,1998,34,4,729-742,,,,,1998,,0360-8352,https://www.sciencedirect.com/science/article/pii/S0360835298001004;http://dx.doi.org/10.1016/S0360-8352(98)00100-4,10.1016/S0360-8352(98)00100-4,Manufacturing Message Specification (MMS) is an international standard for shop floor machine control. It defines a set of conceptual schema and an interactive software object known as Virtual Manufacturing Device (VMD). Many systems have been established using this protocol but very few formal methods have been used to build such systems. This paper addresses the problems of the design and analysis of a network-based task oriented messaging system for flexible robot task control using a Petri net. The information and message transfer processes of the MMS systems were analysed. The modelling methodology allows a top down approach by which the net model is decomposed into fine details with clear identification of components which can be realised directly from the model. This approach is illustrated in this paper by a Windows-based robot control prototype system implemented from the Petri net model. The prototype was built using Object Windows Library and the NetBIOS session layer protocol on a PC network.,"Flexible robot control, Messaging system, Manufacturing Message Specification (MMS), Petri net modelling, Virtual manufacturing device, Object windows",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Calvanese D,De Giacomo G,Montali M,Patrizi F",,First-order μ-calculus over generic transition systems and applications to the situation calculus,Information and Computation,2018,259,,328-347,,,,,2018,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540117301487;http://dx.doi.org/10.1016/j.ic.2017.08.007,10.1016/j.ic.2017.08.007,"We consider μL, μLa, and μLp, three variants of the first-order μ-calculus studied in verification of data-aware processes, that differ in the form of quantification on objects across states. Each of these three logics has a distinct notion of bisimulation. We show that the three notions collapse for generic dynamic systems, which include all state-based systems specified using a logical formalism, e.g., the situation calculus. Hence, for such systems, μL, μLa, and μLp have the same expressive power. We also show that, when the dynamic system stores only a bounded number of objects in each state (e.g., for bounded situation calculus action theories), a finite abstraction can be constructed that is faithful for μL (the most general variant), yielding decidability of verification. This contrasts with the undecidability for first-order ltl, and notably implies that first-order ltl cannot be captured by μL.","Reasoning about actions, Verification, Situation calculus, First-order -calculus, Infinite transition systems, State-bounded transition systems",22nd International Symposium on Temporal Representation and Reasoning,,,,,,,,,,,,,,,,,,,,
Journal Article,"Coen-Porisini A,Gatti D,Mariani D",,High Level Design of Supervision and Control Systems Using Corba: an Example,IFAC Proceedings Volumes,1998,31,32,137-142,,,,,1998,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017363474;http://dx.doi.org/10.1016/S1474-6670(17)36347-4,10.1016/S1474-6670(17)36347-4,"This paper discusses how a TRIO specification can be used to derive the CORBA-oriented high level design of a Supervision and Control System. The paper identifies a sequence of steps which allow the designers to define the application objects and their IDL interfaces, starting from a formal specification. In the paper such steps are presented by means of a case study, namely an airport ground traffic controller.","Formal Specification, Design, CORBA, TRIO","15th IFAC Workshop on Distributed Computer Control Systems (DCCS'98), Como, Italy, 9-11 September 1998",,,,,,,,,,,,,,,,,,,,
Journal Article,"Reus B,Streicher T",,Semantics and logic of object calculi,Theoretical Computer Science,2004,316,1,191-213,,,,,2004,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397504000830;http://dx.doi.org/10.1016/j.tcs.2004.01.030,10.1016/j.tcs.2004.01.030,"The main contribution of this paper is a formal characterization of recursive object specifications and their existence based on a denotational untyped semantics of the object calculus. Existence is not guaranteed but can be shown employing Pitts’ results on relational properties of domains. The semantics can be used to analyse and verify Abadi and Leino's object logic but it also suggests extensions. For example, specifications of methods may not only refer to fields but also to methods of objects in the store. This can be achieved without compromising the existence theorem. An informal logic of predomains is in use intentionally in order to avoid any commitment to a particular syntax of specification logic.","Object logic, Programming logic, Program verification, Denotational semantics, Domain theory",Recent Developments in Domain Theory: A collection of papers in honour of Dana S. Scott,,,,,,,,,,,,,,,,,,,,
Journal Article,De Troyer O,,A formalization of the Binary Object-Role Model based on logic,Data & Knowledge Engineering,1996,19,1,1-37,,,,,1996,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9500045T;http://dx.doi.org/10.1016/0169-023X(95)00045-T,10.1016/0169-023X(95)00045-T,"This paper proposes a formalization of the Binary Object-Role Model (B-ORM) based on a general logical formalism for data models, called DM-Logic. This formalism can also be used to formally describe, e.g. ER-models, the Relational Model and Object-Oriented Models. As such, this formalization not only describes in a comprehensive manner the many complex aspects of B-ORM, it also provide a formal basis for interoperability. We define the concepts of schema, population or state, and integrity constraint. A schema is defined as a first-order logical theory, the states are the models of the theory and the integrity constraints are closed well formed formulas. Queries can be considered as open well formed formulas. The formalism is then used to define the different types of constraints and lexical referenceability, a key concept for transforming B-ORM schemas into Relational one's.","Binary-relationship model, Conceptual models, Data schema, Integrity constraints, Lexical reference-ability, First-order logic, Many sorted logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Boronat A,Carsí JÁ,Ramos I,Letelier P",,Formal Model Merging Applied to Class Diagram Integration,Electronic Notes in Theoretical Computer Science,2007,166,,5-26,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106005263;http://dx.doi.org/10.1016/j.entcs.2006.06.013,10.1016/j.entcs.2006.06.013,"The integration of software artifacts is present in many scenarios of the Software Engineering field: object-oriented modeling, relational databases, XML schemas, ontologies, aspect-oriented programming, etc. In Model Management, software artifacts are viewed as models that can be manipulated by means of generic operators, which are specified independently of the context in which they are used. One of these operators is Merge, which enables the automated integration of models. Solutions for merging models that are achieved by applying this operator are more abstract and reusable than the ad-hoc solutions that are pervasive in many contexts of the Software Engineering field. In this paper, we present our automated approach for generic model merging from a practical standpoint, providing support for conflict resolution and traceability between software artifacts by using the QVT Relations language. We focus on the definition of our operator Merge, applying it to Class Diagrams integration.","Model-Driven Engineering, Model Management, model merging, conflict resolution, QVT Relations",Proceedings of the ERCIM Working Group on Software Evolution (2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Moser S,Henderson-Sellers B,Mišić VB",,Cost estimation based on business models,Journal of Systems and Software,1999,49,1,33-42,,,,,1999,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121299000643;http://dx.doi.org/10.1016/S0164-1212(99)00064-3,10.1016/S0164-1212(99)00064-3,"Software development requires early and accurate cost estimation in order to enhance likely success. System complexity needs to be measured and then correlated with development effort. One of the best known approaches to such measurement-based estimation in the area of Information Systems is Function Point Analysis (FPA). Although it is reasonably well used in practice, FPA has been shown to be formally ambiguous and to have some serious practical deficiencies as well, mainly in the context of newly emerged object-oriented modeling approaches. This paper reports results from an empirical study undertaken in Swiss industry covering 36 projects. We observed that a new formally sound approach, the System Meter (SM) method, which explicitly takes reuse into account, predicts effort substantially better than FPA.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Daugherty GW,,"Unification of the models for types, classes and state machines",Computer Standards & Interfaces,1998,19,7,347-359,,,,,1998,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548998000221;http://dx.doi.org/10.1016/S0920-5489(98)00022-1,10.1016/S0920-5489(98)00022-1,"The static model, specified formally, and the dynamic model, represented by hierarchical state machines, are intimately related. By defining a mapping between the two, we are able to provide a definition of inheritance, multiple inheritance and behavioral subtyping for state machines based on that for formally specified types and classes, and provide a graphical representation for formal specifications in terms of state machines. The state machine notation is based on statecharts. It, however, supports both a declarative style, appropriate for types, and an imperative style, appropriate for classes. State machines may be parameterized and may be viewed from different perspectives, based on an arbitrary choice of state predicates. And states are interpreted not as an expression of concurrency, but result from a choice of independent state predicates.","Models, State machines, Multiple inheritance",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Nielson F,Hansen RR,Nielson HR",,Abstract interpretation of mobile ambients,Science of Computer Programming,2003,47,2,145-175,,,,,2003,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642302001314;http://dx.doi.org/10.1016/S0167-6423(02)00131-4,10.1016/S0167-6423(02)00131-4,We show how abstract interpretation can be expressed in a constraint-based formalism that is becoming increasingly popular for the analysis of functional and object-oriented languages. This is illustrated by developing analyses for the ambient calculus. The first step of the development constructs an analysis for counting occurrences of processes inside other processes; we show that the analysis is semantically correct and that the set of acceptable solutions constitutes a Moore family. The second step considers a previously developed control flow analysis and shows how to induce it from the counting analysis; we show that its properties can be derived from those of the counting analysis using general results about abstract interpretation for constraint-based analyses.,,Special Issue on Static Analysis (SAS'99),,,,,,,,,,,,,,,,,,,,
Journal Article,Beringer L,,Relational bytecode correlations,The Journal of Logic and Algebraic Programming,2010,79,7,483-514,,,,,2010,,1567-8326,https://www.sciencedirect.com/science/article/pii/S1567832610000354;http://dx.doi.org/10.1016/j.jlap.2010.07.005,10.1016/j.jlap.2010.07.005,"We present a calculus for tracking equality relationships between values through pairs of bytecode programs. The calculus may serve as a certification mechanism for non-interference, a well-known program property in the field of language-based security, and code transformations. Contrary to previous type systems for non-interference, no restrictions are imposed on the control flow structure of programs. Objects, static and virtual methods are included, and heap-local reasoning is supported by frame rules. In combination with polyvariance, the latter enable the modular verification of programs over heap-allocated data structures, which we illustrate by verifying and comparing different implementations of list copying. The material is based on a complete formalisation in Isabelle/HOL.","Non-interference, Relational proof systems, Program transformations, Proof-carrying code, Formalised program analyses",The 20th Nordic Workshop on Programming Theory (NWPT 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Kleist J,Sangiorgi D",,Imperative objects as mobile processes,Science of Computer Programming,2002,44,3,293-342,,,,,2002,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642302000345;http://dx.doi.org/10.1016/S0167-6423(02)00034-5,10.1016/S0167-6423(02)00034-5,"An interpretation of Abadi and Cardelli's first-order Imperative ς-calculus into a typed π-calculus is presented. The interpretation validates the subtyping relation and the typing judgments of the ς-calculus, and is computationally adequate. The proof of computational adequacy makes use of (a π-calculus version) of ready simulation, and of a factorization of the interpretation into a functional part and a very simple imperative part. The interpretation can be extended to accommodate various type features. The interpretation can be used to compare and contrast the Imperative and the Functional ς-calculus, and to prove properties about them, within a unified framework.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Webster CJ,Omare CN",,Structured methods for GIS design part 2: An object-oriented system for physical plan monitoring,"Computers, Environment and Urban Systems",1994,18,1,19-41,,,,,1994,,0198-9715,https://www.sciencedirect.com/science/article/pii/0198971594900337;http://dx.doi.org/10.1016/0198-9715(94)90033-7,10.1016/0198-9715(94)90033-7,"Part 1 of this two-paper series presented a case study illustrating how structured data analysis methods may be employed to order the data requirements of a spatial planning domain for efficient GIS design. This paper uses a second case study to extend the discussion in three ways. First, it demonstrates the application of a different set of data analysis tools to a similar system design problem. Second, it gives a more detailed treatment of the task of defining elementary information system functions. Third, the tools used are compatible with the design of a more sophisticated postrelational database system and the two case studies therefore illustrate a technical advancement in the application of structured methods for GIS design. The methodology presented reduces an entity-attribute model of the plan monitoring domain to a digraph via subtype matrix analysis. By labelling the arcs of the graph, a semantic network formalism is created which is capable of direct implementation as an object-oriented database. Detailed object descriptions (database schemata) are constructed and discussed in order to emphasise the important relationship between structured methods of data analysis and system functionality.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Holocher M,Michalski R,Solte D,Vicuña F",,MIDA: An open systems architecture for model-oriented integration of data and algorithms,Decision Support Systems,1997,20,2,135-147,,,,,1997,,0167-9236,https://www.sciencedirect.com/science/article/pii/S0167923696000644;http://dx.doi.org/10.1016/S0167-9236(96)00064-4,10.1016/S0167-9236(96)00064-4,"MIDA defines an architecture for building distributed Decision Support Systems by integrating high-level modeling approaches and implementation techniques for platform independent distributed client/server applications. One of the chief design goals is hiding of all infrastructural and system specific implementation details to users. MIDA covers solutions for model-oriented representation, administration, and (remote) access to both data and methods in distributed heterogeneous computer and networking environments. AMBAS-SOOM is an implemented variant of the MIDA architecture which has been developed at FAW. AMBAS-SOOM has two main components: the distributed operating platform AMBAS and the modeling environment SOOM, which implements concepts of Structured Modeling (SM) and Object Orientation. Models are developed using the graphical expert interface of SOOM and include formal descriptions of data types, of methods (functions, solvers) and relationships between data and methods. These models are translated automatically into executables for AMBAS. AMBAS contains an Object Request Broker mechanism to assign requests for data or methods from applications to services available within the network and, therefore, enables reuse of distributed data and methods to build up new models.","Adaptive method base shell, Client server computing, Distributed platform, Model-oriented integration, Modeling environment, Open system, Operational programming, Structured modeling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Parrish AS,Borie RB,Cordes DW",,Automated flow graph-based testing of object-oriented software modules,Journal of Systems and Software,1993,23,2,95-109,,,,,1993,,0164-1212,https://www.sciencedirect.com/science/article/pii/016412129390076A;http://dx.doi.org/10.1016/0164-1212(93)90076-A,10.1016/0164-1212(93)90076-A,"Classes represent the fundamental building blocks in object-oriented software development. Several techniques have been proposed for testing classes. However, most of these techniques are heavily specification based, in the sense that they demand the existence of formal specifications for the module. In addition, most existing techniques generate test cases at random rather than systematically. We present some test case generation techniques that are based entirely on class implementation, involve systematic generation of test cases, and are fully automated. Our techniques are based on an adaptation of existing white-box, flow graph-based techniques for unit testing conventional procedures and functions. We also provide a general conceptual framework to support the modeling of classes using flow graphs. Our framework clarifies the fundamental definitions and concepts associated with this method for modeling classes.",,Object-Oriented Software,,,,,,,,,,,,,,,,,,,,
Journal Article,"Živkovič A,Rozman I,Heričko M",,Automated software size estimation based on function points using UML models,Information and Software Technology,2005,47,13,881-890,,,,,2005,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584905000303;http://dx.doi.org/10.1016/j.infsof.2005.02.008,10.1016/j.infsof.2005.02.008,"A systematic approach to software size estimation is important for accurate project planning. In this paper, we will propose the unified mapping of UML models into function points. The mapping is formally described to enable the automation of the counting procedure. Three estimation levels are defined that correspond to the different abstraction levels of the software system. The level of abstraction influences an estimate's accuracy. Our research, based on a small data set, proved that accuracy increases with each subsequent abstraction level. Changes to the FPA complexity tables for transactional functions will also be proposed in order to better quantify the characteristics of object-oriented software.","Function points, Software size measure, Project planning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gupta S,Chatterjee B",,Compiler with Auto-Debugger: an Intelligent Computing Approach Towards Self-Improvised Correction of Errors,Procedia Technology,2012,4,,286-296,,,,,2012,,2212-0173,https://www.sciencedirect.com/science/article/pii/S2212017312003234;http://dx.doi.org/10.1016/j.protcy.2012.05.044,10.1016/j.protcy.2012.05.044,"Many languages viz. COBOL, C, C++, Java, Python etc have emerged and evolved in the arena of formal systems over the past few decades,. Programming language processors are designed to convert a high level language written source code to equivalent object code viz. interpreter, compiler etc. There exist variations in programming paradigm, like procedure-oriented, object–based, object oriented, low-level and logic/invariant. But irrespective of the programming methodology, trivial issues related with errors or bugs are often faced. Bug is always undesired to occur. So, need for a debugger embedded to compiler exists. Almost every language has a debugger module mostly dependent on involvement of developers. But again programmer needs to eliminate errors from the source code manually by dint of debugger module. The presented approach, a framework is proposed in which the elimination of the errors from the program source code is developer independent. The function of this module is to remove of the error one by one and to generate a debugged i.e. error-free form of the whole program. Then we will execute than debugged form of the source code to obtain our intended result. The framework is well-documented in the works of Gupta et al. [1], [2]. However, the issue ‘if the debugged form of the source code is non-unique i.e. more than one debugged form is found’ is not widely circulated in the literature. Effort has been made to get rid of the problems. The work presents an auto-debugger module in the interdisciplinary area of compiler design and machine intelligence that can take care of non-unique errors. The concept is accompanied by a developed compiler named SHARP. SHARP facilitates use of variable length of data type and further a framework of floating-point arithmetic different from the standard practice of mantissa-exponent scheme. It is expected that this will navigate the study of automated language processor to a new horizon.","Auto-debugger, Floating-point arithmetic, Language-processor, Programming paradigm, Sharp","2nd International Conference on Computer, Communication, Control and Information Technology( C3IT-2012) on February 25 - 26, 2012",,,,,,,,,,,,,,,,,,,,
Journal Article,Denker G,,From Rewrite Theories to Temporal Logic Theories,Electronic Notes in Theoretical Computer Science,1998,15,,105-126,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105825551;http://dx.doi.org/10.1016/S1571-0661(05)82555-1,10.1016/S1571-0661(05)82555-1,"The work presented here aims at bridging the gap between executable specifications and formal verification. In this paper we combine two levels of description without changing the framework. The operational level of Maude/rewriting logic and the property-oriented level of temporal logics are combined. The combination is done by an embedding. We propose a distributed temporal logic as an extension of rewriting logic. Rewriting logic is primarily a logic of change in which the deduction directly corresponds to the computation. In contrast to that, temporal logic is a logic to talk about change in a global way. Especially, more complex system properties such as safety and liveness can be regarded in a temporal logic setting. In our approach we maintain the possibility of executing Maude specifications on the rewrite machine for validation purposes, and add the possibility of formally reasoning about Maude specifications in a temporal logic setting. The work presented focuses on object-oriented Maude specifications.",,International Workshop on Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Opdahl AL,Sindre G",,A taxonomy for real-world modelling concepts,Information Systems,1994,19,3,229-241,,,,,1994,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437994900434;http://dx.doi.org/10.1016/0306-4379(94)90043-4,10.1016/0306-4379(94)90043-4,"A major component in problem analysis is to model the real world itself. However, the modelling languages suggested so far, suffer from several weaknesses, especially with respect to dynamics. First, dynamic modelling languages originally aimed at describing data—rather than real-world—processes. Moreover, they are either weak in expression, so that models become too vague to be meaningful, or they are cluttered with rigorous detail, which makes modelling unnecessarily complicated and inhibits the communication with end users. This paper establishes a simple and intuitive conceptual basis for the modelling of the real world, with an emphasis on dynamics. Object-orientation is not considered appropriate for this purpose, due to its focus on static object structure. Dataflow diagrams, on the other hand, emphasize dynamics, but unfortunately, some major conceptual deficiencies make DFDs, as well as their various formal extensions, unsuited for real-world modelling. This paper presents a taxonomy of concepts for real-world modelling which rely on some seemingly small, but essential modifications of the DFD language, Hence the well-known, communication-oriented diagrammatic representations of DFDs can be retained. It is indicated how the approach can support a smooth transition into later stages of object-oriented design and implementation.","Dataflow diagrams, real-world modelling, conceptual modelling, object-orientation, problem analysis",Fifth International Conference on Advanced Information Systems Engineering (CAISE '93),,,,,,,,,,,,,,,,,,,,
Journal Article,"Puitg F,Dufourd JF",,Formalizing mathematics in higher-order logic: A case study in geometric modelling,Theoretical Computer Science,2000,234,1,1-57,,,,,2000,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439759800228X;http://dx.doi.org/10.1016/S0304-3975(98)00228-X,10.1016/S0304-3975(98)00228-X,"An innovative attempt to develop formal techniques of specification, proof, and program extraction in geometric modelling is reported through the axiomatization of the mathematical model of the combinatorial maps in the calculus of inductive constructions (CIC), a variety of type theory well suited for mechanizing mathematics in higher-order logic. A hierarchical specification of ordered sorts is presented and validated by inductive proofs of consistency and completeness in the Coq system, a prover built on CIC. Automatic extraction of functional algorithms from constructive proofs is investigated through the development of a prototype. Classical difficulties in formal specification and theorem proving – like cohabitation of objects with their generalization in the same hierarchy, smooth handling of subtyping, completion of partial relations or objects, observationality vs. constructivism, and symmetry of relations – are addressed, not only at the formal specification and theorem proving level but also from the prototyping viewpoint. Geometrical modelling issues are thus solved in a new and unquestionable fashion, giving a great insight on the domain and a deep understanding of the model. A methodology of formal program development that could apply to other areas of computer science is then proposed.","Formal specifications, Theorem proving, Inductive proofs, Program extraction, Geometric modelling, Coq",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Van Cutsem T,Miller MS",,Robust trait composition for Javascript,Science of Computer Programming,2015,98,,422-438,,,,,2015,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642312002079;http://dx.doi.org/10.1016/j.scico.2012.11.001,10.1016/j.scico.2012.11.001,"We introduce traits.js, a small, portable trait composition library for Javascript. Traits are a more robust alternative to multiple inheritance and enable object composition and reuse. traits.js is motivated by two goals: first, it is an experiment in using and extending Javascript’s recently added meta-level object description format. By reusing this standard description format, traits.js can be made more interoperable with similar libraries, and even with built-in primitives. Second, traits.js makes it convenient to create “high-integrity” objects whose integrity cannot be violated by clients, an important property when web content is composed from mutually suspicious scripts. We describe the design of traits.js and provide an operational semantics for traits-js, a minimal calculus that models the core functionality of the library.","Traits, Mixins, Javascript, ECMAScript 5",Special Issue on Advances in Dynamic Languages,,,,,,,,,,,,,,,,,,,,
Journal Article,Azzouz TA,,Spectrum of a linear differential equation over a field of formal power series,Journal of Number Theory,2021,,,,,,,,2021,,0022-314X,https://www.sciencedirect.com/science/article/pii/S0022314X20303607;http://dx.doi.org/10.1016/j.jnt.2020.11.021,10.1016/j.jnt.2020.11.021,"In this paper we associate to a linear differential equation with coefficients in the field of Laurent formal power series a new geometric object, a spectrum in the sense of Berkovich. We compute this spectrum and show that it contains interesting information about the equation.","Berkovich spaces, Spectral theory, Ultrametric differential equations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Merro M,Kleist J,Nestmann U",,Mobile Objects as Mobile Processes,Information and Computation,2002,177,2,195-241,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S089054010293172X;http://dx.doi.org/10.1006/inco.2002.3172,10.1006/inco.2002.3172,"Obliq is a lexically scoped, distributed, object-based programming language. In Obliq, the migration of an object is proposed as creating a clone of the object at the target site, whereafter the original object is turned into an alias for the clone. Obliq has only an informal semantics, so there is no proof that this style of migration is safe, i.e., transparent to object clients. In previous work, we introduced Ø, an abstraction of Obliq, where, by lexical scoping, sites have been abstracted away. We used Ø in order to exhibit how the semantics behind Obliq's implementation renders migration unsafe. We also suggested a modified semantics that we conjectured instead to be safe. In this paper, we rewrite our modified semantics of Ø in terms of the π-calculus, and we use it to formally prove the correctness of object surrogation, the abstraction of object migration in Ø.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Machado JT,Lopes AM",,Multidimensional scaling and visualization of patterns in prime numbers,Communications in Nonlinear Science and Numerical Simulation,2020,83,,105128,,,,,2020,,1007-5704,https://www.sciencedirect.com/science/article/pii/S1007570419304472;http://dx.doi.org/10.1016/j.cnsns.2019.105128,10.1016/j.cnsns.2019.105128,"This paper explores the prime numbers (PN) in the perspective of complex systems (CS) using computational and information visualization resources. The PN are interpreted as features that characterize the outputs of a CS. Four distinct metrics are adopted to assess the differences between such objects, namely the Canberra, Euclidean, Jaccard and Lorentzian distances, and the information is treated with a multidimensional scaling (MDS) algorithm. The MDS produces loci, organized according with the objects’ features, that are analyzed under the light of the emerging patterns. Additionally, these patterns are explored in the Fourier domain under the point of view of fractional calculus. The representations constitute a new philosophy for tackling the challenging topic of PN using advanced scientific visualization.","Complex systems, Prime numbers, Information visualization, Distance metrics, Multidimensional scaling",,,,,,,,,,,,,,,,,,,,,
Journal Article,Fleutot F,,Encoding an Object Calculus into Interaction Nets,Electronic Notes in Theoretical Computer Science,2005,127,5,83-111,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105050152;http://dx.doi.org/10.1016/j.entcs.2005.03.024,10.1016/j.entcs.2005.03.024,"We propose an encoding of an object calculus into interaction nets in two stages. First, we make the calculus fully explicit, i.e. with explicit substitutions, duplications and erasures. Then, we use this explicit calculus to produce an interaction net encoding of objects.","Object calculus, Interaction nets, Linearisation, Explicit substitution",Proceedings of the 2nd International Workshop on Term Graph Rewriting (TERMGRAPH 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,Selic B,,Real-Time Object-Oriented Modeling,IFAC Proceedings Volumes,1996,29,5,1-6,,,,,1996,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017463464;http://dx.doi.org/10.1016/S1474-6670(17)46346-4,10.1016/S1474-6670(17)46346-4,"The \architecture\"" of a software system refers to its highest-level modular decomposition and the interrelationship patterns between its modules. An architecture serves as a blueprint for implementation and also as the chief determinant of a system's ability evolve. Consequently","there is an increased interest in methods for specifying and validating software architectures. One such method is based on the ROOM mode ling language which combines the object paradigm with mode ling abstractions devised specifically for distributed real-time software. To overcome the treacherous \""architectural decay\"" phenomenon",whereby,over time,software diverges increasingly from its specification,ROOM formally constrains the implementation to its architectural specification. This is achieved primarily through full automated code generation,"a technique that is panicularly challenging in real-time applications where stringent performance and memory requirements are the norm.""",,"IFAC Workshop on real Time Programming WRTP 96, Gramado, Brazil, 4-6 November",,,,,,,,,,,,,,
Journal Article,"Cuppens F,Gabillon A",,Cover story management,Data & Knowledge Engineering,2001,37,2,177-201,,,,,2001,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X01000064;http://dx.doi.org/10.1016/S0169-023X(01)00006-4,10.1016/S0169-023X(01)00006-4,"In a multilevel database, cover stories are usually managed using the ambiguous technique of polyinstantiation. In this paper, we define a new technique to manage cover stories and propose a formal representation of a multilevel database containing cover stories. Our model aims to be a generic model, that is, it can be interpreted for any kind of database (e.g., relational, object-oriented, etc.). We then consider the problem of updating a multilevel database containing cover stories managed with our technique.","Database security, Security model, Multilevel security policy, Cover story, Management, Mathematical logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Frank AU,Egenhofer MJ",,Computer cartography for GIS: An object-oriented view on the display transformation,Computers & Geosciences,1992,18,8,975-987,,,,,1992,,0098-3004,https://www.sciencedirect.com/science/article/pii/009830049290015J;http://dx.doi.org/10.1016/0098-3004(92)90015-J,10.1016/0098-3004(92)90015-J,"Geographic Information Systems (GISs) are widely used tools for the collection, management, and display—or visualization—of many types of data that describe space. Visualization of spatial data has been the domain of expertise of cartographers and elaborate recommendations for best rendering of spatial data exist. Unfortunately, this body of knowledge is not cast yet into a formalization and thus is not accessible immediately for programming GIS software. A particular problem is the description of the rendering parameters for complex spatial objects. This paper presents a method for describing the set of individual geometric objects parts to which different rendering parameters can be assigned. The geometric data model uses the concepts of boundary and interior, and their specializations returning objects of particular dimensions. It is applicable equally to both raster and vector data, and, therefore, a contribution to the integration of vector and taster GIS. The rendering parameters are based upon Bertin's “visual variables.” Abbreviated class definitions in C++ are included as a method to describe formally the concepts treated.","Object-oriented programming, C++, Computer cartography, Visual variables, Topology, Boundary, Interior",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mavrovouniotis ML,Prickett S,Constantinou L",,Object-oriented estimation of properties from molecular structure,Computers & Chemical Engineering,1992,16,,S353-S360,,,,,1992,,0098-1354,https://www.sciencedirect.com/science/article/pii/S0098135409800422;http://dx.doi.org/10.1016/S0098-1354(09)80042-2,10.1016/S0098-1354(09)80042-2,"We are developing a computer-based method for the estimation of thermodynamic, physical, and chemical properties of organic compounds from their molecular structure. The method retains some of the simplicity and additive character that have made group-contribution methods so useful, while using more chemical concepts to achieve wider applicability and better accuracy. The approach is based on the contributions of Atoms and Bonds in the properties of Conjugate forms (ABC) of a molecular structure. Conjugate forms are alternative formal arrangements of valence electrons in a molecule; a real chemical compound can be considered the hybrid of all its conjugates. In ABC, we start by generating all conjugate forms of the molecule whose properties we wish to estimate. Properties are assigned to each conjugate, simply by summing contributions from atoms and bonds in the particular electronic arrangement of the conjugate. Then, these properties of the conjugates are combined to derive the properties of the compound. A central computational issue in the method is the generation of the necessary large set of conjugates. The development and implementation of suitable algorithms for this task is facilitated by symbolic computing environments and Object-Oriented Programming, which allow the flexible representation and manipulation of molecular structures; atoms, bonds, molecules, electron pairs, and other entities can be represented as interconnected objects. The generation, comparison, and analysis of conjugates can be carried out through computer-based manipulation of the objects and their interconnections. OOP will play an important role in the systematic application of the technique in the analysis and design of complex systems. Based on the ABC approach, a method for the estimation of the enthalpies of formation of acyclic hydrocarbons (saturated and unsaturated) is presented.","Object-Oriented Programming, Property Estimation, Group Contributions, Conjugation, Hybridization, Molecular Structure, Conjugate Form",European Symposium on Computer Aided Process Engineering—1,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hildebrandt TT,Johansen C,Normann H",,A stable non-interleaving early operational semantics for the pi-calculus,Journal of Logical and Algebraic Methods in Programming,2019,104,,227-253,,,,,2019,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220817302249;http://dx.doi.org/10.1016/j.jlamp.2019.02.006,10.1016/j.jlamp.2019.02.006,"We give the first non-interleaving early operational semantics for the pi-calculus which generalises the standard interleaving semantics and unfolds to the stable model of prime event structures. Our starting point is the non-interleaving semantics given for CCS by Mukund and Nielsen, where the so-called structural (prefixing or subject) causality and events are defined from a notion of locations derived from the syntactic structure of the process terms. We conservatively extend this semantics with a notion of extruder histories, from which we infer the so-called link (name or object) causality and events introduced by the dynamic communication topology of the pi-calculus. We prove that the semantics generalises both the standard interleaving early semantics for the pi-calculus and the non-interleaving semantics for CCS. In particular, it gives rise to a labelled asynchronous transition system unfolding to prime event structures.","Pi-calculus, Non-interleaving, Early semantics, Asynchronous transition systems, Stability, Causality",,,,,,,,,,,,,,,,,,,,,
Journal Article,Dami L,,"Operational Subsumption, an Ideal Model of Subtyping",Electronic Notes in Theoretical Computer Science,1998,10,,28-49,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105806863;http://dx.doi.org/10.1016/S1571-0661(05)80686-3,10.1016/S1571-0661(05)80686-3,"In a previous paper we have defined a semantic preorder called operational subsumption, which compares terms according to their error generation behaviour. Here we apply this abstract framework to a concrete language, namely the Abadi-Cardelli object calculus. Unlike most semantic studies of objects, which deal with typed equalities and therefore require explicitly typed languages, we start here from a untyped world. Type inference is introduced in a second step, together with an ideal model of types and subtyping. We show how this approach flexibly accommodates for several variants, and finally propose a novel semantic interpretation of structural subtyping as embedding-projection pairs.",,"HOOTS II, Second Workshop on Higher-Order Operational Techniques in Semantics",,,,,,,,,,,,,,,,,,,,
Journal Article,"Kong J,Zhang K,Dong J,Xu D",,Specifying behavioral semantics of UML diagrams through graph transformations,Journal of Systems and Software,2009,82,2,292-306,,,,,2009,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121208001593;http://dx.doi.org/10.1016/j.jss.2008.06.030,10.1016/j.jss.2008.06.030,"The Unified Modeling Language (UML) has been widely accepted as a standard for modeling software systems from various perspectives. The intuitive notations of UML diagrams greatly improve the communication among developers. However, the lack of a formal semantics makes it difficult to automate analysis and verification. This paper offers a graphical yet formal approach to specifying the behavioral semantics of statechart diagrams using graph transformation techniques. It supports many advanced features of statecharts, such as composite states, firing priority, history, junction, and choice. In our approach, a graph grammar is derived automatically from a state machine to summarize the hierarchy of states. Based on the graph grammar, the execution of a set of non-conflict state transitions is interpreted by a sequence of graph transformations. This facilitates verifying a design model against system requirements. To demonstrate our approach, we present a case study on a toll-gate system.","Graph transformation, Graph grammars, Visual programming, Visual languages, UML, Behavioral semantics, Object-oriented systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Andries M,Engels G",,A Hybrid Query Language for an Extended Entity-Relationship Model,Journal of Visual Languages & Computing,1996,7,3,321-352,,,,,1996,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X96900178;http://dx.doi.org/10.1006/jvlc.1996.0017,10.1006/jvlc.1996.0017,"We present the hybrid query language HQL/EER for an Extended Entity-Relationship model. As its main characteristic, this language allows a user to usebothgraphical and textual elements in the formulation of one and the same query. We demonstrate the look-and-feel of this query language by means of examples, and show how syntax and semantics of this language are formally defined using programmed graph rewriting systems. Although we present the language in the context of the EER model, the concept of hybrid languages is applicable in the context of other database models as well. We illustrate this claim by discussing a prototype implementation of a Hybrid Query Tool based on an object-oriented approach, namely the Object Modeling Technique (OMT).",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Caseau Y,"Kim W,Nicolas JM,Nishio S",A FORMAL SYSTEM FOR PRODUCING DEMONS FROM RULES IN AN OBJECT-ORIENTED DATABASE,,1990,,,203-219,,North-Holland,Amsterdam,Deductive and Object-Oriented Databases,1990,9780444884336,,https://www.sciencedirect.com/science/article/pii/B9780444884336500198;http://dx.doi.org/10.1016/B978-0-444-88433-6.50019-8,10.1016/B978-0-444-88433-6.50019-8,"Abstract This paper presents how to combine the advantages of both procedural attachment and logic programming in a deductive object-oriented database. The solution we propose is to generate demons from logical rules that define the operations to be performed. Three steps are introduced to achieve this goal: each logic rule is first represented by a term of a relational algebra. A formal transformation produces computational terms from these algebraic terms. These terms are, in turn, compiled into low-level procedures that may be used as demons in order to perform logic resolution.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liang WY,O'Grady P",,An internet-based application for electronics assemblies components selection,Computers & Industrial Engineering,1999,37,1,85-88,,,,,1999,,0360-8352,https://www.sciencedirect.com/science/article/pii/S0360835299000285;http://dx.doi.org/10.1016/S0360-8352(99)00028-5,10.1016/S0360-8352(99)00028-5,"The use of such EACS promises substantial benefits but its successful implementation is hampered by the lack of a suitable formalism, particularly where, as is often the case, participants are geographically separated. The work presented in this paper is focused on how to implement EACS, where the participants may be remote, in a formal and systematic way. An Internet network based application is described that uses the Internet to support EACS, and an example is used to illustrate the implementation.","Electronic Assemblies Component Selection, Concurrent Engineering, Internet, Object-Oriented",Proceedings of the 24th international conference on computers and industrial engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Durán F,Vallecillo A",,Formalizing ODP enterprise specifications in Maude,Computer Standards & Interfaces,2003,25,2,83-102,,,,,2003,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548902001216;http://dx.doi.org/10.1016/S0920-5489(02)00121-6,10.1016/S0920-5489(02)00121-6,"Maude is an executable rewriting logic language specially well suited for the specification of object-oriented open and distributed systems. In this paper, we explore the possibility of using Maude as a formal notation for writing and reasoning about RM-ODP enterprise specifications. Maude offers a simple, natural and accurate way of modeling the enterprise viewpoint concepts, which provides interesting benefits over previous modeling approaches, allows overcoming some of their limitations, and offers good tool support.","Rewriting logic, Maude, RM-ODP, Enterprise viewpoint",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sicilia MÁ,Lytras MD,Sánchez-Alonso S,García-Barriocanal E,Zapata-Ros M",,"Modeling instructional-design theories with ontologies: Using methods to check, generate and search learning designs",Computers in Human Behavior,2011,27,4,1389-1398,,,,,2011,,0747-5632,https://www.sciencedirect.com/science/article/pii/S0747563210002360;http://dx.doi.org/10.1016/j.chb.2010.07.040,10.1016/j.chb.2010.07.040,"Instructional theories have been defined as practice-oriented theories offering explicit guidance on how to help people learn that offer situation-specific methods. The descriptions of many instructional theories include recommendations or rules that can be subject to modeling in formal knowledge representation languages. Further, recent work in the application of ontologies to learning technology has made openly available formal representation schemas for activity sequences and learning resource descriptions, based on evolving standards. Combining these with the representation of instructional-design theories provides a framework for developing rule-based, instructional theory-aware support tools for different practical purposes. These purposes include (partially) checking the compatibility of learning designs with instructional theories in authoring tools, using methods as query criteria in learning resource repositories, and the generation of tentative learning activities for some given instructional design methods. This paper addresses the main epistemological issues and the representation of the main elements of instructional models using the formal ontology language OWL, which can be used in conjunction with the SWRL rule language for the purposes described. Following existing conceptualizations, methods and conditions are modeled in a generic way able of capturing a plurality of views.","Instructional design, Ontologies, Learning objects, IMS LD, OWL, SWRL",Social and Humanistic Computing for the Knowledge Society,,,,,,,,,,,,,,,,,,,,
Journal Article,"Habibi A,Tahar S",,On the Transformation of SystemC to AsmL Using Abstract Interpretation,Electronic Notes in Theoretical Computer Science,2005,131,,39-49,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105002562;http://dx.doi.org/10.1016/j.entcs.2005.01.021,10.1016/j.entcs.2005.01.021,"SystemC is among a group of system level design languages proposed to raise the abstraction level for embedded system design and verification. A straight and sound verification by model checking or theorem proving of SystemC designs is, however, infeasible given the object-oriented nature of this library and the complexity of its simulation environment. We illustrated, in a previous work, the feasibility and success of performing model checking and assertions monitors generation of SystemC using a variant of Abstract State Machines (ASM) languages (AsmL). In this paper, we establish the soundness of our approach by proving the correctness of the transformation from SystemC to AsmL.","SystemC, Formal Verification, Abstract Interpretation",Proceedings of the First International Workshop on Abstract Interpretation of Object-oriented Languages (AIOOL 2005),,,,,,,,,,,,,,,,,,,,
Book Chapter,,Maddux RD,Chapter 1 Calculus of relations,,2006,150,,1-33,,Elsevier,,Relation Algebras,2006,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X06800236;http://dx.doi.org/10.1016/S0049-237X(06)80023-6,10.1016/S0049-237X(06)80023-6,"Publisher Summary The calculus of binary relations was founded in the latter half of the nineteenth century and reached a peak in its development. With the introduction of the concept of relation into logic, its importance, and the properties of relations and operations on relations were studied. Boole's logical algebra has such singular beauty, so far as it goes, that it is interesting to inquire whether it cannot be extended over the whole realm of formal logic, instead of being restricted to that simplest and least useful part of the subject, the logic of absolute terms, which, when he wrote, was the only formal logic known. The object of this chapter is to show that an affirmative answer can be given to this question. This chapter also presents the binary relations, complement and converse, union and intersection, relative multiplication and addition; three binary operations on relations, one of them called as composition that coincides with relative multiplication, but neither of the other two is relative addition; the four distinguished relations, axiomatization of the calculus of relations, definitions of relation algebras, undecidability and inexpressibility, incompleteness, representability, and the weakened associativity. Most of the basic algebraic theory of relation algebras carries over to the class of nonassociative relation algebras. The development of the theory of relation algebras in this chapter is, therefore, generalized wherever possible to semiassociative, weakly associative, and nonassociative relation algebras.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Scagnetto I,Miculan M",,Ambient Calculus and its Logic in the Calculus of Inductive Constructions,Electronic Notes in Theoretical Computer Science,2002,70,2,76-95,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104805073;http://dx.doi.org/10.1016/S1571-0661(04)80507-3,10.1016/S1571-0661(04)80507-3,"The Ambient Calculus has been recently proposed as a model of mobility of agents in a dynamically changing hierarchy of domains. In this paper, we describe the implementation of the theory and metatheory of Ambient Calculus and its modal logic in the Calculus of Inductive Constructions. We take full advantage of Higher-Order Abstract Syntax, using the Theory of Contexts a fundamental tool for developing formally the metatheory of the object system. Among others, we have successfully proved a set of fresh renamings properties, and formalized the connection between the Theory of Contexts and Gabbay-Pitts' “new” quantifier. As a feedback, we introduce a new definition of satisfaction for the Ambients logic and derive some of the properties originally assumed as axioms in the Theory of Contexts.",,LFM 2002 International Workshop on Logical Frameworks and Meta-Languages (FLoC Satellite Event),,,,,,,,,,,,,,,,,,,,
Journal Article,"Prat N,Akoka J,Comyn-Wattiau I",,A UML-based data warehouse design method,Decision Support Systems,2006,42,3,1449-1473,,,,,2006,,0167-9236,https://www.sciencedirect.com/science/article/pii/S0167923605001788;http://dx.doi.org/10.1016/j.dss.2005.12.001,10.1016/j.dss.2005.12.001,"Data warehouses are a major component of data-driven decision support systems (DSS). They rely on multidimensional models. The latter provide decision makers with a business-oriented view to data, thereby easing data navigation and analysis via On-Line Analytical Processing (OLAP) tools. They also determine how the data are stored in the data warehouse for subsequent use, not only by OLAP tools, but also by other decision support tools. Data warehouse design is a complex task, which requires a systematic method. Few such methods have been proposed to date. This paper presents a UML-based data warehouse design method that spans the three design phases (conceptual, logical and physical). Our method comprises a set of metamodels used at each phase, as well as a set of transformations that can be semi-automated. Following our object orientation, we represent all the metamodels using UML, and illustrate the formal specification of the transformations based on OMG's Object Constraint Language (OCL). Throughout the paper, we illustrate the application of our method to a case study.","Data warehouse, On-Line Analytical Processing (OLAP), Decision support, Conceptual design, Logical design, Physical design",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Djang RW,Burnett MM,Chen RD",,Static Type Inference for a First-Order Declarative Visual Programming Language with Inheritance,Journal of Visual Languages & Computing,2000,11,2,191-235,,,,,2000,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X99901532;http://dx.doi.org/10.1006/jvlc.1999.0153,10.1006/jvlc.1999.0153,"The early detection of type errors is a well-known benefit of static typing, but until recent years, this benefit usually has come at the cost of requiring the programmer to explicitly declare the type of every object in a program. Since many visual programming languages (VPLs), especially those VPLs intended for end users, are designed to eliminate such programming mechanisms, most VPLs have been implemented with dynamic typing, thereby sacrificing early type error feedback and other benefits of static typing. One potential solution for this dilemma is static type inference, but unfortunately, the types inferred under previous approaches have been notoriously difficult to understand, even for professional programmers. Compounding this problem is the fact that when support for inheritance is added to such type inference systems, explicit type declarations have re-emerged. In this paper, we present a model of types that supports static type inference for a declarative VPL that includes inheritance. Our model addresses the problems presented in the previous paragraph. We present the formal model of our type system, and show that the model is not only sound with respect to type safety, but that it also has sufficient power to support traditional and non-traditional forms of inheritance, and further that it requires the user to understand only a small vocabulary of types, a feature important in addressing the understandability problem in end-user VPLs.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Alvarez JM,Díaz M,Llopis LM,Pimentel E,Troya JM","Dssouli R,v. Bochmann G,Lahav Y",Integrating Schedulability Analysis and SDL in an Object-Oriented Methodology for Embedded Real-time Systems,,1999,,,241-256,,Elsevier Science B.V.,Amsterdam,SDL '99,1999,9780444502285,,https://www.sciencedirect.com/science/article/pii/B9780444502285500175;http://dx.doi.org/10.1016/B978-044450228-5/50017-5,10.1016/B978-044450228-5/50017-5,"The usage of object oriented methodologies in conjunction with formal description techniques has arisen as a promising way of dealing with the increasing complexity of embedded real-time systems. These methodologies are currently well supported by a set of tools that allow the specification, simulation and validation of the functional aspects of these systems. However most of these methodologies do not take into account non-functional aspects as hardware interaction and real-time constraints, which are especially important in the context of this kind of systems. In this paper, we present a new methodology for the design of embedded real-time systems. This methodology is based on a combination of ideas from different existing methodologies (UML, OCTOPUS,…) together with the integration of rate-monotonic analysis in the context of the SDL Formal Description Technique development cycle. The methodology pays special attention to the transition from the object model to the task model, taking into account real-time and hardware integration issues. In addition to the presentation of the methodology, we also describe its application to a real-life example as the development of a multi-handset cordless telephone.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fadlisyah M,Ölveczky PC,Ábrahám E",,Formal modeling and analysis of interacting hybrid systems in HI-Maude: What happened at the 2010 Sauna World Championships?,Science of Computer Programming,2015,99,,95-127,,,,,2015,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642314002895;http://dx.doi.org/10.1016/j.scico.2014.06.010,10.1016/j.scico.2014.06.010,"In this paper we use HI-Maude to model and analyze the human thermoregulatory system and the effect of extreme heat exposure to the human body. The case study is motivated by the 2010 Sauna World Championships, which ended in a tragedy when the last two finalists were severely burnt in surprisingly short time (one of them died the next day). HI-Maude is a rewriting-logic-based formal modeling language and analysis tool for complex hybrid systems whose components influence each others' continuous dynamics. One distinguishing feature of HI-Maude is that the user only needs to describe the continuous dynamics of single components and interactions, instead of having to explicitly define the continuous dynamics of the entire system. HI-Maude analyses are based on numerical approximations of the system's continuous behaviors. We use HI-Maude to analyze how long the human body can survive when experiencing extreme conditions such as those encountered in the Sauna World Championships.","Simulation, Rewriting logic, Hybrid systems, Object-oriented specification, Human thermoregulatory system",Selected Papers from the Ninth International Workshop on Rewriting Logic and its Applications (WRLA 2012),,,,,,,,,,,,,,,,,,,,
Journal Article,"Ziou D,Rodriguez DR,Nacereddine N,Tabbone S",,A novel correlation filter based on variational calculus,Signal Processing: Image Communication,2019,78,,77-85,,,,,2019,,0923-5965,https://www.sciencedirect.com/science/article/pii/S0923596518311810;http://dx.doi.org/10.1016/j.image.2019.06.003,10.1016/j.image.2019.06.003,"Correlation filters have been a popular technique for tackling image classification problems. The traditional criteria used to design correlation filters overlook some properties that can improve their discriminative power. Therefore, new criteria are proposed to design a novel correlation filter. Such criteria take advantage of negative samples, spatial information and the smoothness of the correlation output space. A closed form is derived from the criteria proposed using variational calculus. Moreover, it is shown that the resulting correlation filter is a bandpass filter. Experiments are conducted for face identification under illumination variation for a single training image per subject and head pose classification. The correlation filter proposed delivers favorable scores when compared to other correlation filters and state-of-the-art approaches.","Correlation filter, Variational calculus, Face identification, Illumination variation, Single training image, Pose classification",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Gurugé A,Gurugé A,5 - Soap,,2004,,,189-226,,Digital Press,Burlington,Web Services,2004,9781555582821,,https://www.sciencedirect.com/science/article/pii/B9781555582821500075;http://dx.doi.org/10.1016/B978-155558282-1/50007-5,10.1016/B978-155558282-1/50007-5,"Publisher Summary Simple Object Access Protocol (SOAP) is a totally Extensible Markup Language (XML)-centric messaging scheme that can be formally characterized as a lightweight communications protocol for exchanging XML-based information among applications in a decentralized, distributed environment. SOAP is used to send input to and receive output from Web services—given that XML Web services operate via exchanging XML documents. Because a Web service requires input parameters to be activated, SOAP is also considered to be what invokes a Web service—given that it is what delivers the input parameters. While it is theoretically possible to have Web services that do not use SOAP, today's conventional wisdom is that SOAP is a mandatory prerequisite for XML Web services at least for the next 4 to 5 years. The role and scope of SOAP, however, are not limited to Web services. SOAP is the latest in a long line of distributed computing initiatives, which in this context includes CORBA and Microsoft's component object models/distributed component object models (COM/DCOM), though it is not meant to totally displace either of these powerful and object-oriented methodologies.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cuppens F,Gabillon A",,Logical foundations of multilevel databases,Data & Knowledge Engineering,1999,29,3,259-291,,,,,1999,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X98000445;http://dx.doi.org/10.1016/S0169-023X(98)00044-5,10.1016/S0169-023X(98)00044-5,"In this paper, we propose a formal model for multilevel databases. This model aims at being a generic model, that is it can be interpreted for any kind of database (relational, object-oriented …). Our model has three layers. The first layer corresponds to a model for a non-protected database. The second layer corresponds to a model for a multilevel database. In this second layer, we propose a list of theorems that must be respected in order to build a secure multilevel database. We also propose a new solution to manage cover stories without using the ambiguous technique of polyinstantiation. The third layer corresponds to a model for a MultiView database, that is, a database that provides at each security level a consistent view of the multilevel database. Finally, as an illustration, we interpret our 3-layer model in the case of an object-oriented database.","Database security, Security model, Multilevel security policy, Cover story management, Mathematical logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sousa JP,Garlan D",,Formal modeling of the Enterprise JavaBeans™ component integration framework,Information and Software Technology,2001,43,3,171-188,,,,,2001,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584900001579;http://dx.doi.org/10.1016/S0950-5849(00)00157-9,10.1016/S0950-5849(00)00157-9,"An emerging trend in the engineering of complex systems is the use of component integration frameworks. Such a framework prescribes an architectural design that permits flexible composition of third-party components into applications. A good example is Sun Microsystems' Enterprise JavaBeans™ (EJB) framework, which supports object-oriented, distributed, enterprise-level applications, such as account management systems. One problem with frameworks like EJB is that they are documented informally, making it difficult to understand precisely what is provided by the framework, and what is required to use it. We believe formal specification can help, and in this paper show how a formal architectural description language can be used to describe and provide insight into such frameworks.","Software architecture, Software frameworks, Component integration standards, Component-based software, Enterprise JavaBeans, Formal specification",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Krause PJ,Byers PJ,Hajnal S",,Formal specification and decision support,Decision Support Systems,1994,12,3,189-197,,,,,1994,,0167-9236,https://www.sciencedirect.com/science/article/pii/0167923694900035;http://dx.doi.org/10.1016/0167-9236(94)90003-5,10.1016/0167-9236(94)90003-5,"To gain widespread acceptance, decision support systems must be built to the highest possible standards. We believe techniques of formal specification and refinement have a valuable role to play in the development of certain components of decision support systems. We present a tutorial study of the use of formal specification focused on a system for maintaining deductive extensions of a knowledge base. The system is specified using an object-oriented variant of the specification language Z. The relationship of the formal specification with existing theoretical work in AI is discussed together with its refinement into a demonstrably correct implementation.","DSS development, Formal specification, Software engineering, KBS validation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Castro J,Kolp M,Mylopoulos J",,Towards requirements-driven information systems engineering: the Tropos project,Information Systems,2002,27,6,365-389,,,,,2002,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437902000121;http://dx.doi.org/10.1016/S0306-4379(02)00012-1,10.1016/S0306-4379(02)00012-1,"Information systems of the future will have to perform well within ever-changing organizational environments. Unfortunately, existing software development methodologies (object-oriented, structured or otherwise) have traditionally been inspired by programming concepts, not organizational ones, leading to a semantic gap between the software system and its operational environment. To reduce this gap, we propose a software development methodology named Tropos which is founded on concepts used to model early requirements. Our proposal adopts the i∗ organizational modeling framework, which offers the notions of actor, goal and (actor) dependency, and uses these as a foundation to model early and late requirements, architectural and detailed design. The paper outlines Tropos phases through an e-business example, and sketches a formal language which underlies the methodology and is intended to support formal analysis. The methodology seems to complement well proposals for agent-oriented programming platforms.","Software development methodology, Requirements engineering, Information systems analysis and design, Agent-oriented systems, Software architectures",,,,,,,,,,,,,,,,,,,,,
Journal Article,Padovani L,,A type checking algorithm for concurrent object protocols,Journal of Logical and Algebraic Methods in Programming,2018,100,,16-35,,,,,2018,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220817301463;http://dx.doi.org/10.1016/j.jlamp.2018.06.001,10.1016/j.jlamp.2018.06.001,Concurrent objects can be accessed and possibly modified concurrently by several running processes. It is notoriously difficult to make sure that such objects are consistent with – and are used according to – their intended protocol. In this paper we detail a type checking algorithm for concurrent objects protocols that provides automated support for this verification task. We model concurrent objects in the Objective Join Calculus and specify protocols using terms of a Commutative Kleene Algebra. The presented results are an essential first step towards the application of this static analysis technique to real-world programs.,"Objective Join Calculus, Concurrent objects, Object protocols, Behavioral type checking, Type inference, Commutative Kleene Algebra",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Golshani F,Dimitrova N",,Retrieval and delivery of information in multimedia database systems,Information and Software Technology,1994,36,4,235-242,,,,,1994,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584994900779;http://dx.doi.org/10.1016/0950-5849(94)90077-9,10.1016/0950-5849(94)90077-9,"EVA is a multimedia database system capable of storage, retrieval, management, analysis and delivery of objects of various media types, including text, audio, images and moving pictures. The interface language deals with the temporal and spatial aspects of multimedia information retrieval and delivery, in addition to the usual capabilities provided by the ordinary database languages. EVA has five classes of operations, namely: operations for querying and updating (i.e. editing) the multimedia information, operations for screen management, temporal operators, operators for specifying rules and constraints, and aggregation (computational) operators. EVA, an extension of the query language Varqa, is a functional language whose notation is based on that of conventional set theory. It is formally defined in an algebraic framework. EVA is object oriented and supports objects, object classes, attributes and methods of objects, and relationships between objects. The current implementation of EVA runs on several different platforms.","multimedia systems, query languages, information delivery",Multimedia Information Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cerbah F,Euzenat J",,Traceability between models and texts through terminology,Data & Knowledge Engineering,2001,38,1,31-43,,,,,2001,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X01000155;http://dx.doi.org/10.1016/S0169-023X(01)00015-5,10.1016/S0169-023X(01)00015-5,"Modeling often concerns the translation of informal texts into formal representations. This translation process requires support for itself and for its traceability. We pretend that inserting a terminology between informal textual documents and their formalization can help to serve both of these goals. Modern terminology extraction tools support the formalization process by using terms as a first sketch of formalized concepts. Moreover, the terms can be employed for linking the concepts and the textual sources. They act as a powerful navigation structure. This is exemplified through the presentation of a fully implemented system.","Terminology extraction, Traceability, Model generation, Hypertext, Object-oriented modeling, Natural language",Natural Language for Data Bases (NLDB'00),,,,,,,,,,,,,,,,,,,,
Journal Article,"Fougères AJ,Ostrosi E",,Intelligent agents for feature modelling in computer aided design,Journal of Computational Design and Engineering,2018,5,1,19-40,,,,,2018,,2288-4300,https://www.sciencedirect.com/science/article/pii/S2288430017300520;http://dx.doi.org/10.1016/j.jcde.2017.11.001,10.1016/j.jcde.2017.11.001,"CAD modelling can be referred to as the process of generating an integrated multiple view model as a representation of multiple views of engineering design. In many situations, a change in the model of one view may conflict with the models of other views. In such situations, the model of some views needs to be adapted in order to make all models consistent. Thus, CAD models should be capable of adapting themselves to new situations. Recently, agent based technologies have been considered in order to increase both knowledge level and intelligence of real and virtual objects. The contribution of this paper consists in introducing the intelligent agents in intelligent CAD modelling. The proposed agents are elementary geometrical and topological objects. They incorporate the functions of observation, decision and action, and possess their own knowledge. Agents have the capacity of communication and inference based on the feature grammars. They are modelled as bio-dynamic objects that enjoy the properties of fusion, division and multiplication. Being aware of the context, the proposed agents interact to form potential regional transitory communities, called regions. Being aware of their belonging in a region, agents interact by generating virtual links (virtual extensions). These virtual links produce: (a) fusion of agents, (b) division of agents and c) multiplication of agents. The emerged agents interact with the other agents in a region to recognize each other and to form specific sub-communities, called intelligent features. From a CAD software development point of view, this paper advocates the idea of a new phase of CAD system development based on the agent-oriented programming (AOP) paradigm.","CAD modelling, Intelligent features, Feature recognition, Geometric knowledge, Intelligent agents, Emerged agent",,,,,,,,,,,,,,,,,,,,,
Journal Article,"V.j. P,J.l. A,U. P",,Object-oriented integration of macroscopic and microscopic characterization of matter,Computers & Chemical Engineering,1999,23,,S731-S734,,,,,1999,,0098-1354,https://www.sciencedirect.com/science/article/pii/S0098135499801793;http://dx.doi.org/10.1016/S0098-1354(99)80179-3,10.1016/S0098-1354(99)80179-3,"Molecular simulation is of growing importance in chemical engineering. The gap usually present in knowledge representations between disciplines is, however, a serious obstacle for efficient utilization of knowledge. The way of bridging the gap between macroscopic and microscopic characterization of matter presented in this paper is based on the view that the solution for integrating knowledge and for enhancing communication, in general, is possible by developing and adopting a unified concept system (PSSP language). The advantage of this system is that the same concepts can be used both in macroscopic and microscopic worlds, whereby the presentational gap is eliminated. Knowledge integration by the formal approach is illustrated by an example starting from an informal description of the example process which is represented as an object with its purpose and some features of its structure and state as specified. The structure of the process is then detailed hierarchically down to the molecular level. It is emphasized that structural detailing should be done in a manner which supports the subsequent state aggregation. The PSSP language can not eliminate discontinuities, which are in knowledge itself but precise location of the knowledge gap and its nature become more detectable by this kind of formal presentation","knowledge integration, process design, molecular modeling",European Symposium on Computer Aided Process Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,Pasquali F,,A characterization of those categories whose internal logic is Hilbert's ε-calculus,Annals of Pure and Applied Logic,2019,170,4,446-464,,,,,2019,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007218301301;http://dx.doi.org/10.1016/j.apal.2018.11.003,10.1016/j.apal.2018.11.003,We characterize categories whose internal logic is Hilbert's ε-calculus as those categories which have a proper factorization system satisfying the axiom of choice and in which every non-initial object is injective. We provide an example of such a category where the law of excluded middle is not valid.,"Hilbert's epsilon calculus, Categorical logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tasos A,Franco J,Drossopoulou S,Wrigstad T,Eisenbach S",,"Reshape your layouts, not your programs: A safe language extension for better cache locality",Science of Computer Programming,2020,197,,102481,,,,,2020,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642320300915;http://dx.doi.org/10.1016/j.scico.2020.102481,10.1016/j.scico.2020.102481,"The vast divide between the speed of CPU and RAM means that effective use of CPU caches is often a prerequisite for high performance on modern architectures. Hence, developers need to consider how to place data in memory so as to exploit spatial locality and achieve high memory bandwidth. Such manual memory optimisations are common in unmanaged languages (e.g. C, C++), but they sacrifice readability, maintainability, memory safety, and object abstraction. In managed languages, such as Java and C#, where the runtime abstracts away the memory from the developer, such optimisations are almost impossible. We present a language extension called SHAPES, which aims to offer developers more fine-grained control over the placement of data, without sacrificing memory safety or object abstraction. In SHAPES, programmers group related objects into pools, and specify how objects are laid out in these pools. Classes and types are annotated by pool parameters, which allow placement aspects to be changed orthogonally to the code that operates on the objects in the pool. These design decisions disentangle business logic and memory concerns. We give a formal model of SHAPES, present its type and memory safety model, and present its translation to a low-level language. We argue why we expect this translation to be efficient in terms of runtime representation of objects and access to their fields. We argue that SHAPES can be incorporated into existing managed and unmanaged language runtimes and fit well with garbage collection.","Type systems, Cache utilisation, Data representation, Memory safety",,,,,,,,,,,,,,,,,,,,,
Journal Article,Caires L,,Spatial-behavioral types for concurrency and resource control in distributed systems,Theoretical Computer Science,2008,402,2,120-141,,,,,2008,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397508003496;http://dx.doi.org/10.1016/j.tcs.2008.04.030,10.1016/j.tcs.2008.04.030,"We develop a notion of spatial-behavioral typing suitable to discipline concurrent interactions and resource usage in distributed object systems. Our type structure reflects a resource sensitive model, where a parallel composition type operator expresses resource independence, a sequential composition type operator expresses resource synchronization, and a type modality expresses resource ownership. We model the intended computational systems using a concurrent object calculus. Soundness of our type system is established using a logical relations technique, building on a interpretation of types as properties expressible in a spatial logic.","Behavioral types, Spatial logics, Concurrency control, Distributed systems, Service-based systems",Trustworthy Global Computing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hussain T,Eschbach R",,Statistical Testing of IEC 61499 Compliant Software Components,IFAC Proceedings Volumes,2009,42,4,662-667,,,,,2009,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016338708;http://dx.doi.org/10.3182/20090603-3-RU-2001.0311,10.3182/20090603-3-RU-2001.0311,"The standard IEC 61499 ushered in the use of Object-Oriented (OO) paradigm and Model Driven Development (MDD) in the realm of industrial automation. Consequently, it paved the way for easier integration of off-the-shelf and vendor specific or legacy software components in the applications. The standard provides a means for specifying implementation or hardware independent software modules which quite obviously would undergo innumerable reuses. Therefore, it is quite important to ensure that these modules as well as its implementations fulfill the requirements, especially the safety-critical ones. This necessitates that on one hand, the requirements are specified formally and on the other hand an exhaustive verification is performed. Often exhaustive verification of the requirements appears to be costly and a hasty and random choice of properties leaves out the critical an essential ones. To combat these challenges, this article presents a means for specifying functional requirements formally and a technique to produce black-box test-cases on the basis of these specifications. The specification can also be used to prudently and effectively choose test-cases when exhaustive testing appears to be improbable.","Discrete Event Controller, Formalisms and Modeling Techniques, Design of Safe Controllers",13th IFAC Symposium on Information Control Problems in Manufacturing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liang SJ,Cheng J,Zhang JW",,Research on data load balancing technology of massive storage system for wearable devices,Digital Communications and Networks,2020,,,,,,,,2020,,2352-8648,https://www.sciencedirect.com/science/article/pii/S235286482030287X;http://dx.doi.org/10.1016/j.dcan.2020.11.002,10.1016/j.dcan.2020.11.002,"Because of the limited memory of the increasing amount of information in current wearable devices, the processing capacity of the servers in the storage system can not keep up with the speed of information growth, resulting in low load balancing, long load balancing time and data processing delay. Therefore, a data load balancing technology is applied to the massive storage systems of wearable devices in this paper. We first analyze the object-oriented load balancing method, and formally describe the dynamic load balancing issues, taking the load balancing as a mapping problem. Then, the task of assigning each data node and the request of the corresponding data node’s actual processing capacity are completed. Different data is allocated to the corresponding data storage node to complete the calculation of the comprehensive weight of the data storage node. According to the load information of each data storage node collected by the scheduler in the storage system, the load weight of the current data storage node is calculated and distributed. The data load balancing of the massive storage system for wearable devices is realized. The experimental results show that the average time of load balancing using this method is 1.75 ​h, which is much lower than the traditional methods. The results show the data load balancing technology of the massive storage system of wearable devices has the advantages of short data load balancing time, high load balancing, strong data processing capability, short processing time and obvious application.","Wearable device, Massive data, Data storage system, Load balancing, Weight",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cabalar P,Santos PE",,Formalising the Fisherman's Folly puzzle,Artificial Intelligence,2011,175,1,346-377,,,,,2011,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370210000408;http://dx.doi.org/10.1016/j.artint.2010.04.004,10.1016/j.artint.2010.04.004,"This paper investigates the challenging problem of encoding the common sense knowledge involved in the manipulation of spatial objects from a reasoning about actions and change perspective. In particular, we propose a formal solution to a puzzle composed of non-trivial objects (such as holes and strings) assuming a version of the Situation Calculus written over first-order Equilibrium Logic, whose models generalise the stable model semantics.","Common sense reasoning, Qualitative spatial reasoning, Reasoning about actions and change",John McCarthy's Legacy,,,,,,,,,,,,,,,,,,,,
Journal Article,"Herranz A,Moreno JJ,Maya N",,Declarative Reflection and its Application as a Pattern Language,Electronic Notes in Theoretical Computer Science,2002,76,,197-215,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104807941;http://dx.doi.org/10.1016/S1571-0661(04)80794-1,10.1016/S1571-0661(04)80794-1,"The paper presents the reflection facilities of the specification language Slam-sl. Slam-sl is an object oriented specification language where class methods are specified by pre and postconditions. The reflection capabilities allow managing these pre and postconditions in specifications what means that semantic reflection is possible. The range of interesting applications is very wide: formal specification of interfaces and abstract classes, specification of component based software, formalization of design pattern, using Slam-sl as a pattern language, etc. The paper discusses the last two advantages in some detail.",,"WFLP 2002, 11th International Workshop on Functional and (Constraint) Logic Programming, Selected Papers",,,,,,,,,,,,,,,,,,,,
Journal Article,Sheu PC,,Describing semantic data bases with logic,Journal of Systems and Software,1989,9,1,19-27,,,,,1989,,0164-1212,https://www.sciencedirect.com/science/article/pii/0164121289900046;http://dx.doi.org/10.1016/0164-1212(89)90004-6,10.1016/0164-1212(89)90004-6,"This paper describes the representation and structural formalism used in LOOD (logic-oriented object data base), a semantic data base that enhances the existing semantic data bases with formal representation and more procedural semantics. It provides a formal means to assert knowledge into a knowledge base, and therefore provides a solid basis on which automatic reasoning and verification are possible. A LOOD specification describes a data base in terms of entities, classes, relations, procedures, properties, transactions, integrity rules, and deductive laws. LOOD can be considered an extension of deductive data bases, since it allows more semantics be described for real-world objects; it can also be considered an extension of contemporary semantic data bases, since it couples logical representation, procedural semantics, and a powerful query language into the semantic framework.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Silva SF,Catarci T,Schiel U",,Formalizing visual interaction with historical databases,Information Systems,2002,27,7,487-521,,,,,2002,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437902000170;http://dx.doi.org/10.1016/S0306-4379(02)00017-0,10.1016/S0306-4379(02)00017-0,"Recent database applications are typically oriented towards a large set of non-expert users, and therefore, they need to be equipped with suitable interfaces facilitating the interaction with the system. Moreover, the incorporation of the time dimension in database systems is a desirable feature. Indeed, several temporal data models and the corresponding textual query languages have been proposed. However, there is a limited amount of research concerning the investigation of user-oriented languages for querying temporal databases. Our proposal addresses such a need. In particular, we propose a visual query environment, namely Temporal Visual Query Environment (TVQE) which provides an easier interaction of the user with temporal databases. The system adopts a diagrammatic representation of the database schema (including temporal classes and relationships) and a “graphical notebook” as interaction metaphor. In our approach, non-database experts are released from syntactical difficulties which are typical of textual languages, and they can easily express temporal queries by means of elementary graphical operations (e.g. click on a node label). Differently from many proposals in the field of visual query languages, the language underlying TVQE is provided with formal syntax and semantics. It is based on a minimal set of temporal graphical primitives (TGPs), which are defined on a Temporal Graph Model (TGM), with visual syntax and object-based semantics. In this paper we mainly concentrate on the formal aspects of TVQE, and provide some hints on the visual interaction mechanisms and implementation issues.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Enqvist S,Seifan F,Venema Y",,Completeness for μ-calculi: A coalgebraic approach,Annals of Pure and Applied Logic,2019,170,5,578-641,,,,,2019,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007218301490;http://dx.doi.org/10.1016/j.apal.2018.12.004,10.1016/j.apal.2018.12.004,"We set up a generic framework for proving completeness results for variants of the modal mu-calculus, using tools from coalgebraic modal logic. We illustrate the method by proving two new completeness results: for the graded mu-calculus (which is equivalent to monadic second-order logic on the class of unranked tree models), and for the monotone modal mu-calculus. Besides these main applications, our result covers the Kozen–Walukiewicz completeness theorem for the standard modal mu-calculus, as well as the linear-time mu-calculus and modal fixpoint logics on ranked trees. Completeness of the linear-time mu-calculus is known, but the proof we obtain here is different and places the result under a common roof with Walukiewicz' result. Our approach combines insights from the theory of automata operating on potentially infinite objects, with methods from the categorical framework of coalgebra as a general theory of state-based evolving systems. At the interface of these theories lies the notion of a coalgebraic modal one-step language. One of our main contributions here is the introduction of the novel concept of a disjunctive basis for a modal one-step language. Generalizing earlier work, our main general result states that in case a coalgebraic modal logic admits such a disjunctive basis, then soundness and completeness at the one-step level transfer to the level of the full coalgebraic modal mu-calculus.","Modal fixpoint logic, Completeness, Coalgebra, Automata, Graded modal mu-calculus, Monotone modal mu-calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liaw TM,Lin SC",,A general theory of concept lattice with tractable implication exploration,Theoretical Computer Science,2020,837,,84-114,,,,,2020,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397520302826;http://dx.doi.org/10.1016/j.tcs.2020.05.014,10.1016/j.tcs.2020.05.014,"This work develops the general concept lattice for the problem concerning categorisation of objects according to their properties. Unlike the conventional approaches, such as the formal concept lattice and the rough set lattice, the general concept lattice is designed to adhere to the general principle that the information content should be invariant regardless how the variables/parameters are presented. Here, one will explicitly demonstrate the existence of such a construction by a sequence of fulfilments compatible with the conventional lattice structure. The general concept lattice promises to be a comprehensive categorisation for all the distinctive object classes according to whatever properties they are equipped with. It will be shown that one can always regain the formal concept lattice and rough set lattice from the general concept lattice. One also speaks of the tractability of the general concept lattice for both its lattice structure and logical content. The general concept lattice permits a feasible construction that can be completed in a single scan of the formal context, though the conventional formal-concept lattice and rough-set lattice can be regained from the general concept lattice. The logic implication deducible from the general concept lattice takes the form of μ1→μ2 where μ1,μ2∈M⁎ are composite attributes out of the concerned formal attributes M. Remarkable is that with a single formula based on the contextual truth 1η one can deduce all the implication relations extractable from the formal context. For concreteness, it can be shown that any implication A→B (A,B being subsets of the formal attributes M) discussed in the formal-concept lattice corresponds to a special case of μ1→μ2 by means of μ1=∏A and μ2=∏B. Thus, one may elude the intractability due to searching for the Guigues-Duquenne basis appropriate for the implication relations deducible from the formal-concept lattice. Likewise, one may identify those μ1→μ2 where μ1=∑A and μ2=∑B with the implications that can be acquired from the rough-set lattice. (Here, the product ∏ stands for the conjunction and the summation ∑ the disjunction.)","General concept lattice, Formal concept lattice, Rough set lattice, Contextual truth, Pseudo intent, Guigues-Duquenne basis",,,,,,,,,,,,,,,,,,,,,
Journal Article,Santas PS,,A Type System for Computer Algebra,Journal of Symbolic Computation,1995,19,1,79-109,,,,,1995,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717185710061;http://dx.doi.org/10.1006/jsco.1995.1006,10.1006/jsco.1995.1006,"This paper presents a type system for support of subtypes, parameterized types with sharing and categories in a computer algebra environment. By modeling representation of instances in terms of existential types, we obtain a simplified model, and build a basis for defining subtyping among algebraic domains. The inheritance at category level has been formalized; this allows the automatic inference of type classes. By means of type classes and existential types we construct subtype relations without involving coercions. A type sharing mechanism works in parallel and allows the consistent extension and combination of domains. The expressiveness of the system is further increased by viewing domain types as special case of package types, forming weak and strong sums respectively. The introduced system, although awkward at first sight, is simpler than other proposed systems for computer algebra without including some of their problems. The system can be further extended in order to support more constructs and increase its flexibility.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Simeoni F,Manghi P,Lievens D,Connor RC,Neely S",,An approach to high-level language bindings to XML,Information and Software Technology,2002,44,4,217-228,,,,,2002,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584902000113;http://dx.doi.org/10.1016/S0950-5849(02)00011-3,10.1016/S0950-5849(02)00011-3,"Values of existing typed programming languages are increasingly generated and manipulated outside the language jurisdiction. Instead, they often occur as fragments of XML documents, where they are uniformly interpreted as labelled trees in spite of their domain-specific semantics. In particular, the values are divorced from the high-level type with which they are conveniently, safely, and efficiently manipulated within the language. We propose language-specific mechanisms which extract language values from arbitrary XML documents and inject them in the language. In particular, we provide a general framework for the formal interpretation of extraction mechanisms and then instantiate it to the definition of a mechanism for a sample language core L. We prove that such mechanism can be built by giving a sound and complete algorithm that implements it. The values, types, and type semantics of L are sufficiently general to show that extraction mechanisms can be defined for many existing typed languages, including object-oriented languages. In fact, extraction mechanisms for a large class of existing languages can be directly derived from L's. As a proof of this, we introduce the SNAQue prototype system, which transforms XML fragments into CORBA objects and exposes them across the ORB framework to any CORBA-compliant language.","prototype, XML fragments, ORB framework",,,,,,,,,,,,,,,,,,,,,
Journal Article,Stehr MO,,Compositionality for Tightly Coupled Systems: A New Application of the Propositions-as-Types Interpretation,Electronic Notes in Theoretical Computer Science,2006,159,,299-323,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106002878;http://dx.doi.org/10.1016/j.entcs.2005.12.073,10.1016/j.entcs.2005.12.073,"The design of complex software systems fundamentally relies on the understanding of abstract components and their interactions. Although compositional techniques are being successfully employed in practice, the use of such techniques is often rather informal and intuitive, and typically a justification for correct behaviour of the composed system exists but is not expressed explicitly. In this paper, we show what can be gained from treating such justifications as first-class citizens. The fairly general setting for this paper is a formal development of a UNITY-style temporal logic for labeled transition systems in the calculus of inductive constructions which has been conducted using the Coq proof assistant in a formally rigorous way. Our development not only subsumes the original UNITY approach to program verification and the more recent approach of New UNITY, but goes beyond it in several essential aspects, such as the generality of the program/system model, the notion of fairness, and the issue of compositionality. The last aspect, which we feel is crucial in the foundations for software engineering, is subject of this paper. We present a general proof rule for compositional verification of liveness assertions in tightly coupled systems. It relies on a notion of compositional proofs, which in turn is closely related to classical work on interference-free proofs for parallel programs. The formulation of this new proof rule and the verification of its soundness does not only exploit the strong inductive reasoning capabilities of the calculus of inductive constructions, but it also uses the propositions-as-types interpretation and the associated proofs-as-objects interpretation in an essential way.","UNITY, program verification, compositionality, software engineering",Proceedings of the First IPM International Workshop on Foundations of Software Engineering (FSEN 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,Hyland M,,Towards a Notion of Lambda Monoid,Electronic Notes in Theoretical Computer Science,2014,303,,59-77,,,,,2014,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066114000309;http://dx.doi.org/10.1016/j.entcs.2014.02.004,10.1016/j.entcs.2014.02.004,Any interpretation of the lambda calculus determines a composition monoid and this monoid can be equipped with structure from which the interpretation can be recovered. That is the essence of Dana Scott's account of the lambda calculus in terms of its category of retracts. This paper presents a new approach to the needed structure on the monoid deriving from a recent analysis of the lambda calculus in terms of algebraic theory.,"Algebraic theories, Abstract clones, -calculus, Reflexive objects, Λ-monoids","Proceedings of the Workshop on Algebra, Coalgebra and Topology (WACT 2013)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Lipton J,O'Donnell MJ",,Some intuitions behind realizability semantics for constructive logic: Tableaux and Läuchli countermodels,Annals of Pure and Applied Logic,1996,81,1,187-239,,,,,1996,,0168-0072,https://www.sciencedirect.com/science/article/pii/0168007296000024;http://dx.doi.org/10.1016/0168-0072(96)00002-4,10.1016/0168-0072(96)00002-4,"We use formal semantic analysis based on new constructions to study abstract realizability, introduced by Läuchli in 1970, and expose its algebraic content. We claim realizability so conceived generates semantics-based intuitive confidence that the Heyting Calculus is an appropriate system of deduction for constructive reasoning. Well-known semantic formalisms have been defined by Kripke and Beth, but these have no formal concepts corresponding to constructions, and shed little intuitive light on the meanings of formulae. In particular, the completeness proofs for these semantics do not generate confidence in the sufficiency of the Heyting Calculus, since we have no reason to believe that every intuitively constructive truth is valid in the formal semantics. Läuchli has proved completeness for a realizability semantics with formal concepts analogous to constructions. We argue in some detail that, in spite of a certain inherent inexactness of the analogy, every intuitively constructive truth is valid in Läuchli semantics, and therefore the Heyting Calculus is powerful enough to prove all constructive truths. Our argument is based on the postulate that a uniformly constructible object must be communicable in spite of imprecision in our language, and that the permutations in Läuchli's semantics represent conceivable imprecision in a language, while allowing a certain amount of freedom in choosing the particular structure of the language. We give a detailed generalization of Läuchli's proof of completeness for the propositional part of the Heyting Calculus, in order to make explicit constructive and algebraic content. In our treatment, we establish several new results about Läuchli models. We show how to extend the sconing and gluing constructions familiar from Kripke and Frame semantics and Topos theory, to Läuchli models, and use them to give an algebraic approach to countermodel construction. In particular, the Läuchli arguments are given without the restriction to the integers, Z, as a group of permutations, which makes much of the coding scheme used in Läuchli's original paper transparent. We also make use of a new propositions-as-types syntax for the Heyting calculus, with limited nondeterminism, in which validity of formulae can be decided without loop-detection.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Morakis E,Vidalis S,Blyth A",,Measuring vulnerabilities and their exploitation cycle,Information Security Technical Report,2003,8,4,45-55,,,,,2003,,1363-4127,https://www.sciencedirect.com/science/article/pii/S1363412703000062;http://dx.doi.org/10.1016/S1363-4127(03)00006-2,10.1016/S1363-4127(03)00006-2,"In a world ruled by chaotic causality, Heisenberg's uncertainty principle is only a natural limitation. Analysts only have their personal logic, experience and intuition to depend on in order to make judgments regarding the safety of a system. However, today's analysts are getting bombarded with large amounts of data coming from all kinds of security-related products, such as vulnerability scanners, anti-viruses, firewalls etc, causing information overload and data congestion. Thus, the question remains: How can analysts make a correct judgment regarding the vulnerabilities from which a system is suffering, especially when all the ammunition he/she possesses can not deal with such a complex, ever-changing environment? To this end, we believe that structuring knowledge/information regarding a specific domain in an object-oriented hierarchy tree, and providing a formal model to reason and construct possible scenarios of attacks, will provide an analyst with the necessary ammunition.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Breazu-Tannen V,Coquand T,Gunter CA,Scedrov A",,Inheritance as implicit coercion,Information and Computation,1991,93,1,172-221,,,,,1991,,0890-5401,https://www.sciencedirect.com/science/article/pii/0890540191900557;http://dx.doi.org/10.1016/0890-5401(91)90055-7,10.1016/0890-5401(91)90055-7,"We present a method for providing semantic interpretations for languages with a type system featuring inheritance polymorphism. Our approach is illustrated on an extension of the language Fun of Cardelli and Wegner, which we interpret via a translation into an extended polymorphic lambda calculus. Our goal is to interpret inheritances in Fun via coercion functions which are definable in the target of the translation. Existing techniques in the theory of semantic domains can be then used to interpret the extended polymorphic lambda calculus, thus providing many models for the original language. This technique makes it possible to model a rich type discipline which includes parametric polymorphism and recursive types as well as inheritance. A central difficulty in providing interpretations for explicit type disciplines featuring inheritance in the sense discussed in this paper arises from the fact that programs can type-check in more than one way. Since interpretations follow the type-checking derivations, coherence theorems are required: that is, one must prove that the meaning of a program does not depend on the way it was type-checked. Proofs of such theorems for our proposed interpretation are the basic technical results of this paper. Interestingly, proving coherence in the presence of recursive types, variants, and abstract types forced us to reexamine fundamental equational properties that arise in proof theory (in the form of commutative reductions) and domain theory (in the form of strict vs. non-strict functions).",,Selections from 1989 IEEE Symposium on Logic in Computer Science,,,,,,,,,,,,,,,,,,,,
Journal Article,"Scollo G,Zecchini S",,Architectural Unit Testing,Electronic Notes in Theoretical Computer Science,2005,111,,27-52,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104052314;http://dx.doi.org/10.1016/j.entcs.2004.12.006,10.1016/j.entcs.2004.12.006,"A formal testing methodology is outlined in this paper, that proves applicable to validation of architectural units in object-oriented models, and its use is illustrated in the context of the design of a robot teleoperation architecture. Automated generation of test cases to validate the functionality of the robot trajectory generation unit showcases the key features of this methodology. A disciplined use of UML state diagrams, to model the unit's dynamics consistently with its static properties as modeled by class diagrams, enables one to provide such models with Input/Output Labelled Transition Systems (IOLTS) semantics, whence a rich machinery of testing theories and tools based on those theories become readily available. Our case study tells that, besides black-box testing of nal implementation units, white-box analysis of architectural units may greatly benefit from the exibility of parameterized I/O-conformance relations. Test purposes turn out to be a useful methodological link between functional requirements, which they are drawn from, and conformance relations, which they help one to instantiate, thereby delimiting test selection to purposeful tests. Contingent aspects of our methodology include: a mechanical translation of state diagrams in Basic LOTOS, a non-mechanical, use-case driven synthesis of test purposes, expressed in the same language, and the use of the TGV tool for automated test case generation. Other choices in these respects are well possible, without a ecting the characteristic traits of the proposed methodology, that are rather to be found in: 1) the combination of object-oriented architectural modeling with IOLTS semantics; 2) the aim at maximizing the potential for test generation from UML models, in a broad view of testing which applies throughout the development process; 3) the speci c proposal to consider internal actions as testable actions, in view of a better coordination between testing (discovery of faults) and debugging (discovery of internal sources of faults).","formal testing methods, white-box testing, test purpose, test selection, automated test case generation",Proceedings of the Workshop on Model Based Testing (MBT 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Pastor O,Gómez J,Insfrán E,Pelechano V",,The OO-method approach for information systems modeling: from object-oriented conceptual modeling to automated programming,Information Systems,2001,26,7,507-534,,,,,2001,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437901000357;http://dx.doi.org/10.1016/S0306-4379(01)00035-7,10.1016/S0306-4379(01)00035-7,"Current and future (conventional) notations used in Conceptual Modeling Techniques should have a precise (formal) semantics to provide a well-defined software development process, in order to go from specification to implementation in an automated way. To achieve this objective, the OO-method approach to Information Systems Modeling presented in this paper attempts to overcome the conventional (informal)/formal dichotomy by selecting the best ideas from both approaches. The OO-method makes a clear distinction between the problem space (centered on what the system is) and the solution space (centered on how it is implemented as a software product). It provides a precise, conventional graphical notation to obtain a system description at the problem space level, however this notation is strictly based on a formal OO specification language that determines the conceptual modeling constructs needed to obtain the system specification. An abstract execution model determines how to obtain the software representations corresponding to these conceptual modeling constructs. In this way, the final software product can be obtained in an automated way.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Foss L,Ribeiro L",,A Translation from Object-Based Hypergraph Grammars into π-Calculus,Electronic Notes in Theoretical Computer Science,2004,95,,245-267,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104050248;http://dx.doi.org/10.1016/j.entcs.2004.04.015,10.1016/j.entcs.2004.04.015,"Object-based models offer abstract constructions to describe complex systems. The Object-Based Graph Grammar (OBGG) is a formalism that may be used to describe this kind of system. This formalism is very intuitive, however, up to now, there are no automatic tools for verification of OBGGs. In this work we propose a translation from Object-Based Hypergraph Grammars into π-Calculus. So, we may be able to prove properties of the systems modeled in this kind of graph grammars through this translation and automatic checkers for π-calculus.","Graph Grammar, π-Calculus, Object-Based Systems",Proceedings of the Brazilian Workshop on Formal Methods,,,,,,,,,,,,,,,,,,,,
Journal Article,"Valova I,Zhechev B",,Mathematical Modeling of Object-Oriented Multidimensional Model of Data for Analytical Data Processing,IFAC Proceedings Volumes,2004,37,19,113-117,,,,,2004,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017306687;http://dx.doi.org/10.1016/S1474-6670(17)30668-7,10.1016/S1474-6670(17)30668-7,"In this paper is proposed a conceptual model of data, which should formalize the theory of the multidimensional models for On-Line Analytical Processing. The developed mathematical model facilitates the precise and strict conceptualization for On- Line Analytical Processing and may serve as a basis for the purposes of the standardization and future research work. In order to make the explanation full and understandable, the model and its constructive elements are represented at three levels – low, middle and upper. The main component of the models for On-Line Analytical Processing is the notion for multidimensional infocube. Two operators have been formally represented, which are base components in the multidimensional model analysis","mathematical models, operators, directed graphs, D-structures, facts, on-line analytical data processing, measures, infocube","4th IFAC Workshop DECOM-TT 2004: Automatic Systems for Building the Infrastructure in Developing Countries, Bansko, Bulgaria, October 3-5, 2004",,,,,,,,,,,,,,,,,,,,
Journal Article,"Baldan P,Ghelli G,Raffaetà A",,Basic Theory of F-Bounded Quantification,Information and Computation,1999,153,2,173-237,,,,,1999,,0890-5401,https://www.sciencedirect.com/science/article/pii/S089054019992802X;http://dx.doi.org/10.1006/inco.1999.2802,10.1006/inco.1999.2802,"System F-bounded is a second-order typed lambda calculus, where the basic features of object-oriented languages can be naturally modelled. F-bounded extends the better known system F⩽, in a way that provides an immediate solution for the treatment of the so-called “binary methods.” Although more powerful than F⩽ and also quite natural, system F-bounded has only been superficially studied from a foundational perspective and many of its essential properties have been conjectured but never proved in the literature. The aim of this paper is to give a solid foundation to F-bounded, by addressing and proving the key properties of the system. In particular, transitivity elimination, completeness of the type checking semi-algorithm, the subject reduction property for βη reduction, conservativity with respect to system F⩽, and antisymmetry of a “full” subsystem are considered, and various possible formulations for system F-bounded are compared. Finally, a semantic interpretation of system F-bounded is presented, based on partial equivalence relations.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Boscá D,Maldonado JA,Moner D,Robles M",,Automatic generation of computable implementation guides from clinical information models,Journal of Biomedical Informatics,2015,55,,143-152,,,,,2015,,1532-0464,https://www.sciencedirect.com/science/article/pii/S1532046415000696;http://dx.doi.org/10.1016/j.jbi.2015.04.002,10.1016/j.jbi.2015.04.002,"Clinical information models are increasingly used to describe the contents of Electronic Health Records. Implementation guides are a common specification mechanism used to define such models. They contain, among other reference materials, all the constraints and rules that clinical information must obey. However, these implementation guides typically are oriented to human-readability, and thus cannot be processed by computers. As a consequence, they must be reinterpreted and transformed manually into an executable language such as Schematron or Object Constraint Language (OCL). This task can be difficult and error prone due to the big gap between both representations. The challenge is to develop a methodology for the specification of implementation guides in such a way that humans can read and understand easily and at the same time can be processed by computers. In this paper, we propose and describe a novel methodology that uses archetypes as basis for generation of implementation guides. We use archetypes to generate formal rules expressed in Natural Rule Language (NRL) and other reference materials usually included in implementation guides such as sample XML instances. We also generate Schematron rules from NRL rules to be used for the validation of data instances. We have implemented these methods in LinkEHR, an archetype editing platform, and exemplify our approach by generating NRL rules and implementation guides from EN ISO 13606, openEHR, and HL7 CDA archetypes.","Archetype, Natural Rule Language, Implementation guide, Data validation, Clinical information model",,,,,,,,,,,,,,,,,,,,,
Journal Article,Laneve C,,A lightweight deadlock analysis for programs with threads and reentrant locks,Science of Computer Programming,2019,181,,64-81,,,,,2019,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642318303812;http://dx.doi.org/10.1016/j.scico.2019.06.002,10.1016/j.scico.2019.06.002,"Deadlock analysis of multi-threaded programs with reentrant locks is complex because these programs may have infinitely many states. We define a simple calculus featuring recursion, threads and synchronizations that guarantee exclusive access to objects. We detect deadlocks by associating an abstract model to programs – the extended lam model – and we define an algorithm for verifying that a problematic object dependency (e.g. a circularity) between threads will not be manifested. The analysis is lightweight because the deadlock detection problem is fully reduced to the corresponding one in lams (without using other models). In fact, the technique is intended to be an effective tool for the deadlock analysis of programming languages by defining ad-hoc extraction processes. We demonstrate this effectivity by applying our analysis to a core calculus featuring shared objects, threads and Java-like synchronization primitives. We also discuss a prototype verifier, called JaDA, that covers several features of Java and deliver initial assessments of the tool.","Deadlock analysis, Threads and reentrant locks, Lams, Circularities, Static semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang L,Li Q",,A logic for Lawson compact algebraic L-domains,Theoretical Computer Science,2020,813,,410-427,,,,,2020,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397520300591;http://dx.doi.org/10.1016/j.tcs.2020.01.025,10.1016/j.tcs.2020.01.025,"In this paper, we build a logic which is named N-sequent calculus. Based on this logic, we provide two kinds of logical representations of Lawson compact algebraic L-domains: one in terms of logical algebras and the other in terms of logical syntax. The first representation takes the corresponding logical algebras as research objects. The use of prime filters achieves the connection between our logic and Lawson compact algebraic L-domains. This approach is inspired by Abramsky's SFP domain logic and the disjunctive propositional logic on algebraic L-domains introduced by Yixiang Chen and Achim Jung. However, there are essential differences between them at the morphisms part. For the second representation, we directly adopt N-sequent calculi themselves as objects instead of the logical algebras. Then we establish the category of N-sequent calculi with consequence relations equivalent to that of Lawson compact algebraic L-domains with Scott continuous maps. This demonstrates the capability of the syntax of the logic in representing domains.","Domain theory, Lawson compact algebraic L-domains, Domain logic, N-sequent calculus, FD-lattice",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Buro S,Crole R,Mastroeni I",,Equational Logic and Categorical Semantics for Multi-Languages,Electronic Notes in Theoretical Computer Science,2020,352,,79-103,,,,,2020,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066120300517;http://dx.doi.org/10.1016/j.entcs.2020.09.005,10.1016/j.entcs.2020.09.005,"Programming language interoperability is the capability of two programming languages to interact as parts of a single system. Each language may be optimized for specific tasks, and a programmer can take advantage of this. HTML, CSS, and JavaScript yield a form of interoperability, working in conjunction to render webpages. Some object oriented languages have interoperability via a virtual machine host (.NET CLI compliant languages in the Common Language Runtime, and JVM compliant languages in the Java Virtual Machine). A high-level language can interact with a lower level one (Apple's Swift and Objective-C). While there has been some research exploring the interoperability mechanisms (Section 1) there is little development of theoretical foundations. This paper presents an approach to interoperability based around theories of equational logic, and categorical semantics. We give ways in which two languages can be blended, and interoperability reasoned about using equations over the blended language. Formally, multi-language equational logic is defined within which one may deduce valid equations starting from a collection of axioms that postulate properties of the combined language. Thus we have the notion of a multi-language theory and much of the paper is devoted to exploring the properties of these theories. This is accomplished by way of category theory, giving us a very general and flexible semantics, and hence a nice collection of models. Classifying categories are constructed, and hence equational theories furnish each categorical model with an internal language; from this we can also establish soundness and completeness. A set-theoretic semantics follows as an instance, itself sound and complete. The categorical semantics is based on some pre-existing research, but we give a presentation that we feel is easier and simpler to work with, improves and mildly extends current research, and in particular is well suited to computer scientists. Throughout the paper we prove some interesting properties of the new semantic machinery. We provide a small running example throughout the paper to illustrate our ideas, and a more complex example in conclusion.","categorical logic, equational logic, interoperability, multi-languages, order-sorted signatures and theories, programming languages, subsort polymorphism","The 36th Mathematical Foundations of Programming Semantics Conference, 2020",,,,,,,,,,,,,,,,,,,,
Journal Article,"Montesi F,Guidi C,Lucchi R,Zavattaro G",,JOLIE: a Java Orchestration Language Interpreter Engine,Electronic Notes in Theoretical Computer Science,2007,181,,19-33,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107003660;http://dx.doi.org/10.1016/j.entcs.2007.01.051,10.1016/j.entcs.2007.01.051,"Service oriented computing is an emerging paradigm for programming distributed applications based on services. Services are simple software elements that supply their functionalities by exhibiting their interfaces and that can be invoked by exploiting simple communication primitives. The emerging mechanism exploited in service oriented computing for composing services –in order to provide more complex functionalities– is by means of orchestrators. An orchestrator is able to invoke and coordinate other services by exploiting typical workflow patterns such as parallel composition, sequencing and choices. Examples of orchestration languages are XLANG [IBM, “XLANG: Web Services for Business Process Design,” http://www.gotdotnet.com/team/xml_wsspecs/xlang-c/default.htm] and WS-BPEL [OASIS, “Web Services Business Process Execution Language Version 2.0, Working Draft,” http://www.oasis-open.org/committees/download.php/10347/wsbpel-specification-draft-120204.htm]. In this paper we present JOLIE, an interpreter and engine for orchestration programs. The main novelties of JOLIE are that it provides an easy to use development environment (because it supports a more programmer friendly C/Java-like syntax instead of an XML-based syntax) and it is based on a solid mathematical underlying model (developed in previous works of the authors [N. Busi, R. Gorrieri, C. Guidi, R. Lucchi and G. Zavattaro, Towards a formal framework for Choreography, in: Proc. of 3rd International Workshop on Distributed and Mobile Collaboration (DMC 2005) (2005), N. Busi, R. Gorrieri, C. Guidi, R. Lucchi and G. Zavattaro, Choreography and orchestration conformance for system design, in: Proc. of 8th International Conference on Coordination Models and Languages (COORDINATION'06), LNCS to appear, 2006, C. Guidi and R. Lucchi, Mobility mechanisms in service oriented computing, in: Proc. of 8th International Conference on on Formal Methods for Open Object-Based Distributed Systems (FMOODS'06), LNCS to appear, 2006]).","SOA, coordination, orchestration, Java, service, engine","Combined Proceedings of the Second International Workshop on Coordination and Organization (CoOrg 2006) and the Second International Workshop on Methods and Tools for Coordinating Concurrent, Distributed and Mobile Systems (MTCoord 2006)",,,,,,,,,,,,,,,,,,,,
Journal Article,Selic B,,Extending the Unified Modeling Language for Large-Scale Highly-Dependable Distributed Systems,IFAC Proceedings Volumes,1998,31,20,1135-1139,,,,,1998,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017419513;http://dx.doi.org/10.1016/S1474-6670(17)41951-3,10.1016/S1474-6670(17)41951-3,"The Unified Modeling Language (UML) has been proposed as an extensible general-purpose standard for modeling of object-oriented applications. In this paper, we describe a specialization of UML for the domain of highly-dependable distributed realtime systems. This specialization, which is defined using the built-in extensibility mechanisms of UML, is based on a combination of the ISO/ITU Reference Model for Open Distributed Processing and the architectural modeling capabilities of the ROOM language. A notable feature of this extension is that it has formal semantics allowing the construction of executable models as well as complete code generation from the models.","large-scale systems, distributed models, real-time, availability, reliability, code converters","8th IFAC/IFORS/IMACS/IFIP Symposium on Large Scale Systems: Theory and Applications 1998 (LSS'98), Rio Patras, Greece, 15-17 July 1998",,,,,,,,,,,,,,,,,,,,
Journal Article,Shoham Y,,Agent-oriented programming,Artificial Intelligence,1993,60,1,51-92,,,,,1993,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370293900349;http://dx.doi.org/10.1016/0004-3702(93)90034-9,10.1016/0004-3702(93)90034-9,"A new computational framework is presented, called agent-oriented programming (AOP), which can be viewed as a specialization of object-oriented programming. The state of an agent consists of components such as beliefs, decisions, capabilities, and obligations; for this reason the state of an agent is called its mental state. The mental state of agents is described formally in an extension of standard epistemic logics: beside temporalizing the knowledge and belief operators, AOP introduces operators for obligation, decision, and capability. Agents are controlled by agent programs, which include primitives for communicating with other agents. In the spirit of speech act theory, each communication primitive is of a certain type: informing, requesting, offering, and so on. This article presents the concept of AOP, discusses the concept of mental state and its formal underpinning, defines a class of agent interpreters, and then describes in detail a specific interpreter that has been implemented.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mohammed O,Rachida AA,Abdelaziz M",,Logical Computer Vision on IOT,Procedia Computer Science,2021,191,,505-510,,,,,2021,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050921014654;http://dx.doi.org/10.1016/j.procs.2021.07.065,10.1016/j.procs.2021.07.065,"With the Internet of Things, an infinite number of devices must generate and share information flows that describe real life. this is why the IoT software platform is very complicated and composed of several entities that depend heavily on each other to connect the tangible world of objects to the virtual world and embeds an intelligence that offers multiple possibilities, stores and analyzes the measurement taken by a sensor, in order to monitor and control connected objects or to create a history allowing prediction and these strong dependencies which complicate the development and maintenance circuit and the evolution of this software, Not all projects adopt a formally identical architecture, however it is possible to schematize an optimal architecture with weak dependencies.","Internet of Things, Smart City, microservices architectures, IoT, IoT platform","The 18th International Conference on Mobile Systems and Pervasive Computing (MobiSPC), The 16th International Conference on Future Networks and Communications (FNC), The 11th International Conference on Sustainable Energy Information Technology",,,,,,,,,,,,,,,,,,,,
Journal Article,Laird J,,"From Global to Local State, Coalgebraically and Compositionally",Electronic Notes in Theoretical Computer Science,2019,347,,203-222,,,,,2019,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066119301276;http://dx.doi.org/10.1016/j.entcs.2019.09.011,10.1016/j.entcs.2019.09.011,"We describe a type theory or metalanguage for constructing and reasoning about higher-order programs with global and local state, and its categorical model. This provides an encapsulation primitive for abstracting global state and making it local to an object, so that it is passed only between its invocations. Our calculus and its semantics extend the interpretation of lambda-terms in a Cartesian closed category with a monoidal action on a category of evaluation contexts — the sequoid — which is dual to the action of the function type. This gives an interpretation of a new type constructor which allows the representation of both global state — via “state-passing-style” interpretation which uses it to represent output states — and local state, via encapsulation, which corresponds to the unique map into a final coalgebra for the sequoid. This provides the equational theory of our calculus with a coinduction rule for proving equivalence between objects with local state. We show that this theory is sound and complete with respect to the categorical semantics by constructing a term model and we show that it is consistent by giving a concrete example based on a category of games and strategies previously used to interpret general references.",,Proceedings of the Thirty-Fifth Conference on the Mathematical Foundations of Programming Semantics,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Glässer U,Gotzhein R,Prinz A","Dssouli R,v. Bochmann G,Lahav Y",Towards a New Formal SDL Semantics based on Abstract State Machines,,1999,,,171-190,,Elsevier Science B.V.,Amsterdam,SDL '99,1999,9780444502285,,https://www.sciencedirect.com/science/article/pii/B9780444502285500138;http://dx.doi.org/10.1016/B978-044450228-5/50013-8,10.1016/B978-044450228-5/50013-8,"With the year 2000 approaching, a new version of SDL called SDL-2000 is currently reaching maturity, and is expected to pass the standardization bodies shortly. Apart from the usual language maintenance, SDL-2000 will offer new features for exception handling and object-oriented data types. To capture these features formally, a new formal SDL semantics is being devised. In several meetings of ITU-T SG10/Q6, the essential design objectives have been clarified, and an outline of the behaviour model for SDL has been presented and discussed. A major concern in this discussion has been the demand for an executable model, which calls for an operational formalism with readily available tool support. Subsequent investigations have shown that Abstract State Machines (ASMs) meet this and all other design objectives, and therefore have been chosen as the underlying formalism. In this paper, ASMs are applied to define the behaviour model of a sample SDL specification formally, thereby illustrating the approach in general.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fichera L,Messina F,Pappalardo G,Santoro C",,A Python framework for programming autonomous robots using a declarative approach,Science of Computer Programming,2017,139,,36-55,,,,,2017,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642317300242;http://dx.doi.org/10.1016/j.scico.2017.01.003,10.1016/j.scico.2017.01.003,"This paper describes PROFETA (standing for Python RObotic Framework for dEsigning sTrAtegies), a framework for the programming of autonomous robots based on the Belief-Desire-Intention (BDI) software model. PROFETA is inspired by AgentSpeak(L), a formal language for the creation of BDI software agents. The framework is implemented in Python, and utilizes the metaprogramming capabilities offered by this language to implement the operational semantics of AgentSpeak(L). PROFETA provides a flexible environment offering both traditional object-oriented imperative constructs and declarative constructs, enabling the definition of a robot's high-level behavior in a simple, natural way. The contributions of this paper, in the area of software design and development, are: (i) a methodology, equipped with suitable technical solutions, to extend the Python programming language with AgentSpeak(L) declarative constructs; and (ii) a unified environment enabling software components for robots to be developed using a single language (Python) within a single runtime environment (the Python virtual machine). A comparison between PROFETA and other similar frameworks is provided, illustrating common aspects and key differences.","Robot programming, BDI model, AgentSpeak(L), Python, Operator overloading",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Daum B,Merten U","Daum B,Merten U",4 - Meaning,,2003,,,169-192,,Morgan Kaufmann,San Francisco,System Architecture with XML,2003,9781558607453,,https://www.sciencedirect.com/science/article/pii/B9781558607453500052;http://dx.doi.org/10.1016/B978-155860745-3/50005-2,10.1016/B978-155860745-3/50005-2,"Publisher Summary This chapter elaborates formal semantics, context, and ontologies. If planned to implement collaborative applications, this is required reading. The Internet is about sharing information. This involves publishing the information, navigating to the relevant information and interpreting that information. Some have called the markup of XML a “semantic markup.” The XML specification does not define semantics for tags. Tags in XML are user-defined, so it is the responsibility of the user to associate a meaning with each tag. Most XML-based languages do so, but they do it in a rather informal way. Unfortunately, there is no standard way to formally define semantics for an XML-based language. In a generic language such as XML, it is possible to standardize semantics only in the most fundamental way. The datatypes in XML Schema allow users to specify a given document element as string, date, and numeric. Semantic modeling has a tradition in knowledge engineering and in agent technology, but is also applied to many other fields in information technology, such as database design, object-oriented analysis, and information retrieval.",,,The Morgan Kaufmann Series in Software Engineering and Programming,,,,,,,,,,,,,,,,,,,
Journal Article,"Veloso PA,Veloso SR,Benevides MR",,On a graph calculus for modalities,Theoretical Computer Science,2017,685,,83-103,,,,,2017,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397517301238;http://dx.doi.org/10.1016/j.tcs.2016.11.037,10.1016/j.tcs.2016.11.037,"We present a sound and complete graph calculus for modalities. This calculus is a general framework for expressing modal formulas and frame properties, with a rich repertoire of relations, and reasoning about them in a uniform manner. The calculus employs graphical interpretations of logical operators and builds graphical objects that represent conditions on Kripke structures.","Modal logics, Graph calculus, Kripke semantics, Special modalities, Frames",Logical and Semantic Frameworks with Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cockett JR,Gallagher JD",,Categorical Models of the Differential λ-Calculus Revisited,Electronic Notes in Theoretical Computer Science,2016,325,,63-83,,,,,2016,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066116300810;http://dx.doi.org/10.1016/j.entcs.2016.09.032,10.1016/j.entcs.2016.09.032,"The paper shows that the Scott-Koymans theorem for the untyped λ-calculus extends to the differential λ-calculus. The main result is that every model of the untyped differential λ-calculus may be viewed as a differential reflexive object in a Cartesian closed differential category. This extension of the Scott-Koymans theorem depends critically on unravelling the somewhat subtle issue of which idempotents can be split so that differential structure lifts to the idempotent splitting. The paper uses (total) Turing categories with “canonical codes” as the basic categorical semantics for the λ-calculus. It shows how the main result may be developed in a modular fashion by first adding left-additive structure to a Turing category, and then – on top of that – differential structure. For both levels of structure it is necessary to identify how “canonical codes” behave with respect to the added structure and, furthermore, how “universal objects” behave. The latter is closely tied to the question – which is the crux of the paper – of which idempotents can be split in these more structured settings.","Scott-Koymans, Differential Lambda Calculus, Categorical Models",The Thirty-second Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXII),,,,,,,,,,,,,,,,,,,,
Journal Article,"Songhafouo Tsopméné PA,Stanley D",,Polynomial functors in manifold calculus,Topology and its Applications,2018,248,,75-116,,,,,2018,,0166-8641,https://www.sciencedirect.com/science/article/pii/S0166864117306764;http://dx.doi.org/10.1016/j.topol.2018.08.012,10.1016/j.topol.2018.08.012,"Let M be a smooth manifold, and let O(M) be the poset of open subsets of M. Manifold calculus, due to Goodwillie and Weiss, is a calculus of functors suitable for studying contravariant functors (cofunctors) F:O(M)⟶Spaces from O(M) to the category of spaces. Weiss showed that polynomial cofunctors of degree ≤k are determined by their values on Ok(M), where Ok(M) is the full subposet of O(M) whose objects are open subsets diffeomorphic to the disjoint union of at most k balls. Afterwards Pryor showed that one can replace Ok(M) by more general subposets and still recover the same notion of polynomial cofunctor. In this paper, we generalize these results to cofunctors from O(M) to any simplicial model category M. If Fk(M) stands for the unordered configuration space of k points in M, we also show that the category of homogeneous cofunctors O(M)⟶M of degree k is weakly equivalent to the category of linear cofunctors O(Fk(M))⟶M provided that M has a zero object. Using a new approach, we also show that if M is a general model category and F:Ok(M)⟶M is an isotopy cofunctor, then the homotopy right Kan extension of F along the inclusion Ok(M)↪O(M) is also an isotopy cofunctor.","Manifold calculus, Polynomial functor, Model category",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tay FE,Gu J",,Product modeling for conceptual design support,Computers in Industry,2002,48,2,143-155,,,,,2002,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361502000143;http://dx.doi.org/10.1016/S0166-3615(02)00014-3,10.1016/S0166-3615(02)00014-3,"Traditional product modeling techniques and computer-aided design (CAD) systems are mainly focused on physical product modeling and geometric representation, which makes them insufficient to help in the conceptual design process. This paper describes a function-based product model for conceptual design support. It formally represents and organizes product information in both functional and physical domain in a multilevel and object-oriented manner. In each domain, the information is organized according to the product decomposition structure. Function–form relations are used to map the two domains. This makes it possible to retain design intentions, and allows designers from different backgrounds with various interests to access the design information and to communicate with one another easily. Multilevel product class structures are constructed to model products at different levels of abstraction, which facilitates design decision-making through the whole conceptual design process. A prototype system has also been developed to implement and demonstrate the proposed product model.","Modeling, Conceptual design, Prototype system",,,,,,,,,,,,,,,,,,,,,
Journal Article,Butler G,,Easy verification of behavioural subtyping in common cases,Information Processing Letters,1995,55,1,57-58,,,,,1995,,0020-0190,https://www.sciencedirect.com/science/article/pii/002001909500064J;http://dx.doi.org/10.1016/0020-0190(95)00064-J,10.1016/0020-0190(95)00064-J,"In many common cases, the checklist for verification of behavioral subtyping presented by Liskov and Wing can be simplified by removing one of the three checks. The common case, called state biconnectivity, occurs where it is possible to undo the effect of each method which changes the state of an object of the supertype.","Program correctness, Formal semantics, Software engineering",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Nishiwaki Y,Kakutani Y,Murase Y",,Modality via Iterated Enrichment,Electronic Notes in Theoretical Computer Science,2018,341,,297-320,,,,,2018,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066118300963;http://dx.doi.org/10.1016/j.entcs.2018.11.015,10.1016/j.entcs.2018.11.015,"This paper investigates modal type theories by using a new categorical semantics called change-of-base semantics. Change-of-base semantics is novel in that it is based on (possibly infinitely) iterated enrichment and interpretation of modality as hom objects. In our semantics, the relationship between meta and object levels in multi-staged computation exactly corresponds to the relationship between enriching and enriched categories. As a result, we obtain a categorical explanation of situations where meta and object logics may be completely different. Our categorical models include conventional models of modal type theory (e.g., cartesian closed categories with a monoidal endofunctor) as special cases and hence can be seen as a natural refinement of former results. On the type theoretical side, it is shown that Fitch-style modal type theory can be directly interpreted in iterated enrichment of categories. Interestingly, this interpretation suggests the fact that Fitch-style modal type theory is the right adjoint of dual-context calculus. In addition, we present how linear temporal, S4, and linear exponential modalities are described in terms of change-of-base semantics. Finally, we show that the change-of-base semantics can be naturally extended to multi-staged effectful computation and generalized contextual modality a la Nanevski et al. We emphasize that this paper answers the question raised in the survey paper by de Paiva and Ritter in 2011, what a categorical model for Fitch-style type theory is like.","Lambda Calculus, Curry-Howard Isomorphism, Modal Logic, Enriched Category Theory",Proceedings of the Thirty-Fourth Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXIV),,,,,,,,,,,,,,,,,,,,
Book Chapter,"Macário CG,Pedroso M,Borelli WC","Cavalli A,Sarma A",- Designing a Multi-user Software Environment for Development and Analysis using a combination of OMT and SDL92,,1997,,,3-17,,Elsevier Science B.V.,Amsterdam,SDL '97: Time for Testing,1997,9780444828163,,https://www.sciencedirect.com/science/article/pii/B9780444828163500022;http://dx.doi.org/10.1016/B978-044482816-3/50002-2,10.1016/B978-044482816-3/50002-2,"Publisher Summary This chapter presents a novel approach to the development of Ambiente Integrado para Desenvolvimento e Análise or Integrated Environment for Development and Analysis (AIDA), a software environment for the management and statistical analysis of experimental data, being developed by the Empresa Brasileira de Pesquisa Agropecuária (EMBRAPA), Brazil. This approach combines the use of an object-oriented methodology with a Specification Description Language (SDL) formal description, greatly enhancing the software development process. The proposed object model and its SDL92 specification, as well as a simulation example are provided for a multiuser AIDA network configuration. The use of object modeling technique (OMT) is shown as an excellent option in the software development process. Besides other features, it allows software reuse, offers some abstraction details, and provides modularity, making the evolution and maintenance activities much easier. There are two main classes in AIDA: the analysis environment and the programming language environment. The chapter focuses on the analysis environment because this part of the system mainly represents the AIDA functionalities.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Crole RL,Furniss A",,Canonical HybridLF: Extending Hybrid with Dependent Types,Electronic Notes in Theoretical Computer Science,2016,323,,125-142,,,,,2016,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066116300366;http://dx.doi.org/10.1016/j.entcs.2016.06.009,10.1016/j.entcs.2016.06.009,"We introduce Canonical HybridLF (CHLF), a metalogic for proving properties of deductive systems, implemented in Isabelle HOL. CHLF is closely related to two other metalogics. The first is the Edinburgh Logical Framework (LF) by Harper, Honsell and Plotkin. The second is the Hybrid system developed by Ambler, Crole and Momigliano which provides a Higher-Order Abstract Syntax (HOAS) based on un-typed lambda calculus. Historically there are two problems with HOAS: its incompatibility with inductive types and the presence of exotic terms. Hybrid provides a partial solution to these problems whereby HOAS functions that include bound variables in the metalogic are automatically converted to a machine-friendly de Bruijn representation hidden from the user. The key innovation of CHLF is the replacement of the un-typed lambda calculus with a dependently-typed lambda calculus in the style of LF. CHLF allows signatures containing constants representing the judgements and syntax of an object logic, together with proofs of metatheorems about its judgements, to be entered using a HOAS interface. Proofs that metatheorems defined in the signature are valid are created using the M2 metalogic of Schurmann and Pfenning. We make a number of advances over existing versions of Hybrid: we now have the utility of dependent types; the unitary bound variable capability of Hybrid is now potentially finitary; a type system performs the role of Hybrid well-formedness predicates; and the old method of indicating errors using special elements of core datatypes is replaced with a more streamlined one that uses the Isabelle option type.","dependent types, HOAS, logical frameworks, metalogical reasoning, variable binding","Proceedings of the Tenth Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2015)",,,,,,,,,,,,,,,,,,,,
Journal Article,Papadopoulos GA,,Experience using an intermediate compiler target language for parallel machines,Microprocessors and Microsystems,1997,20,9,511-520,,,,,1997,,0141-9331,https://www.sciencedirect.com/science/article/pii/S0141933196011234;http://dx.doi.org/10.1016/S0141-9331(96)01123-4,10.1016/S0141-9331(96)01123-4,"The generalised computational model of term graph rewriting systems (TGRSs) has been used extensively as an implementation vehicle for a number of, often divergent, programming paradigms ranging from the traditional functional programming ones to the (concurrent) logic programming ones and various amalgamations of them, to (concurrent) object-oriented ones. More recently, the relationship between TGRSs and process calculi (such as the π-calculus) as well as linear logic has also been explored. In this paper we describe our experience in using the intermediate compiler target language Dactl based on TGRSs for mapping a variety of programming paradigms of the aforementioned types onto it. In particular, we concentrate on some of the issues that we feel have played an important role in our work (in, say, affecting performance, etc.), the aim being to derive a list of features that we feel every language model which intends to be used as an intermediate representation between (concurrent) high-level languages and (parallel) computer architectures must have.","Compiler target languages, Intermediate representations, Parallel and distributed computing, Language embeddings, Term graph rewriting systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,Andreev RD,,A linguistic approach to user interface design,Interacting with Computers,2001,13,5,581-599,,,,,2001,,0953-5438,https://www.sciencedirect.com/science/article/pii/S0953543801000339;http://dx.doi.org/10.1016/S0953-5438(01)00033-9,10.1016/S0953-5438(01)00033-9,"This paper considers user interface design world (UIDW) as a system of communication lines. It necessitates the adoption of a UI design method, centered on language application. For that reason, this approach to UI design is called linguistic approach. The basic characteristics of communication require the presence of a balanced model of UIDW. The integration approach applied to the proposed balanced model submits for analyzing the following issues: the possibilities of object-oriented (OO) approach for providing a homogeneous platform for UI designing; the potential of OO approach for language implementation. The use of formal description provides a basis for the consideration of these issues. As a result of these considerations, the following conclusions are drawn. A technology can be used for language implementation if it ensures all abstract forms reflected to the language structure: concept – this is the essence of the word; forms based on individual abstraction reflect static relations of one description; forms based on group abstraction provide context description. At present, the OO technology covers a part of the language structure. It ensures the forms of concept and the forms based on individual abstraction. The OO paradigm can be regarded as a foundation of a linguistic approach to UI design when new OO forms are developed. They have to cover the forms of group abstraction.","User interface design, System design, Object-oriented approach, Linguistic approach, Abstract forms of cognition",,,,,,,,,,,,,,,,,,,,,
Journal Article,Mjolsness E,,Towards Measurable Types for Dynamical Process Modeling Languages,Electronic Notes in Theoretical Computer Science,2010,265,,123-144,,,,,2010,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066110000873;http://dx.doi.org/10.1016/j.entcs.2010.08.008,10.1016/j.entcs.2010.08.008,"Process modeling languages such as “Dynamical Grammars” are highly expressive in the processes they model using stochastic and deterministic dynamical systems, and can be given formal semantics in terms of an operator algebra. However such process languages may be more limited in the types of objects whose dynamics is easily expressible. For many applications in biology, the dynamics of spatial objects in particular (including combinations of discrete and continuous spatial structures) should be formalizable at a high level of abstraction. We suggest that this may be achieved by formalizing such objects within a type system endowed with type constructors suitable for complex dynamical objects. To this end we review and illustrate the operator algebraic formulation of heterogeneous process modeling and semantics, extending it to encompass partial differential equations and intrinsic graph grammar dynamics. We show that in the operator approach to heterogeneous dynamics, types require integration measures. From this starting point, “measurable” object types can be enriched with generalized metrics under which approximation can be defined. The resulting measurable and “metricated” types can be built up systematically by type constructors such as vectors, products, and labelled graphs. We find conditions under which functions and quotients can be added as constructors of measurable and metricated types.","biological models, dynamical systems, master equation, measureable type, metricated type, operator algebra, process modeling language, stochastic processes, stochastic semantics",Proceedings of the 26th Conference on the Mathematical Foundations of Programming Semantics (MFPS 2010),,,,,,,,,,,,,,,,,,,,
Book Chapter,"Nederpelt RP,Geuvers JH","Nederpelt RP,Geuvers JH,de Vrijer RC",Twenty-Five Years of Automath Research,,1994,133,,3-54,,Elsevier,,Selected Papers on Automath,1994,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08701988;http://dx.doi.org/10.1016/S0049-237X(08)70198-8,10.1016/S0049-237X(08)70198-8,"Publisher Summary This chapter provides a historical overview of proof systems, leading to a short survey of the Automath project, and a description of recent developments. A proof system which is based on typed lambda calculus but does not treat proofs as formal objects is Higher Order Logic (HOL). The system is not a framework, but supports a version of classical higher order predicate logic. There are also systems for proof development that do not use type theory at all. This chapter presents selected papers for the survey of the contents which are divided in six groups, in accordance with the global character of the topics treated namely motivation and exposition, language definition and special subjects, theory, text examples, verification, and some related topics. It provides some insight in the contents of the different papers, with a view to the aims and ideas of the Automath project. The chapter discusses the contributions of Alonzo Church, the founder of type theory. The Automath project, the related type systems, and the recent developments are discussed.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Shao MW,Yang HZ,Wu WZ",,Knowledge reduction in formal fuzzy contexts,Knowledge-Based Systems,2015,73,,265-275,,,,,2015,,0950-7051,https://www.sciencedirect.com/science/article/pii/S095070511400375X;http://dx.doi.org/10.1016/j.knosys.2014.10.008,10.1016/j.knosys.2014.10.008,"Knowledge reduction is a basic issue in knowledge representation and data mining. Although various methods have been developed to reduce the size of classical formal contexts, the reduction of formal fuzzy contexts based on fuzzy lattices remains a difficult problem owing to its complicated derivation operators. To address this problem, we propose a general method of knowledge reduction by reducing attributes and objects in formal fuzzy contexts based on the variable threshold concept lattices. Employing the proposed approaches, we remove attributes and objects which are non-essential to the structure of a variable threshold concept lattice, i.e., with a given threshold level, the concept lattice constructed from a reduced formal context is made identical to that constructed from the original formal context. Discernibility matrices and Boolean functions are, respectively, employed to compute the attribute reducts and object reducts of the formal fuzzy contexts, by which all the attribute reducts and object reducts of the formal fuzzy contexts are determined without changing the structure of the lattice.","Concept lattices, Discernibility matrices, Formal fuzzy contexts, Knowledge reduction, Variable threshold",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tiller MM,Dantzig JA",,Implementation of design sensitivity analysis and numerical optimization in engineering analysis,Applied Mathematical Modelling,1996,20,11,792-799,,,,,1996,,0307-904X,https://www.sciencedirect.com/science/article/pii/S0307904X96000844;http://dx.doi.org/10.1016/S0307-904X(96)00084-4,10.1016/S0307-904X(96)00084-4,"In this paper we present an approach to integrating optimisation tools with simulation software to achieve user-defined objectives. A formal protocol is presented, including specific definitions of the requirements of the simulator, optimiser, and design interface. A discussion of the mathematical issues and the efficiency of different approaches for computing sensitivities is given. We then discuss the source code modifications necessary to accomplish the integration of simulation and optimisation.","optimization, sensitivity analysis, finite element method, object-oriented programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Diaz M,Owezarski P",,From multimedia models to multimedia transport protocols,Computer Networks and ISDN Systems,1997,29,7,745-758,,,,,1997,,0169-7552,https://www.sciencedirect.com/science/article/pii/S0169755297000718;http://dx.doi.org/10.1016/S0169-7552(97)00071-8,10.1016/S0169-7552(97)00071-8,"This paper presents a new protocol architecture for distributed multimedia systems which includes a new and general protocol layer for the transport of multimedia objects. The proposed protocols are based on the use of two extended timed and time Petri net models that specify the synchronisation requirements of multimedia applications. After presenting these two formal models, it is shown how they have been used to design the general multimedia architecture whose transport layer is based on the concept of a partial order connection, an extension of the classical connection oriented (e.g., TCP) and connectionless (e.g., UDP) transmission concepts.","Distributed multimedia systems, Timed Petri nets, Specification, Modeling, Multimedia information, Time and synchronisation, Multimedia protocols, Partial order connections",Theme issue FORTE'95,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rudolph E,Graubmann P,Grabowski J",,Tutorial on Message Sequence Charts,Computer Networks and ISDN Systems,1996,28,12,1629-1641,,,,,1996,,0169-7552,https://www.sciencedirect.com/science/article/pii/0169755295001220;http://dx.doi.org/10.1016/0169-7552(95)00122-0,10.1016/0169-7552(95)00122-0,"An introduction to the ITU standard language Message Sequence Chart (MSC) is provided. It is pointed out that MSC in many respects is complementary to the ITU specification and design language SDL. MSC in combination with SDL or other languages, now plays a role in nearly all stages of the system development process. Since MSC has been standardized in the same study group as SDL, the language form is quite analogous, e.g. it has a graphical (MSCGR) and a textual (MSCPR) syntax form. The MSC language in the present recommendation Z.120 (MSC'92), comprises basic language elements — instance, message, environment, action, timer, process creation and termination, condition — and structural language elements — “coregion” and “submsc”. It is demonstrated how global and non-global conditions may be used for the composition of MSCs. Whereas in MSC'92 the main emphasis is put on the elaboration of basic concepts and a corresponding formal semantics, in the new MSC version (MSC'96) structural language constructs, essentially composition and object oriented concepts, will play a dominant role. With these new concepts, the power of MSC is enhanced considerably in order to overcome the traditional restriction of MSC to the specification of few selected system runs.","MSC, SDL, Object oriented modelling, Composition techniques, System engineering, Requirement specification",SDL and MSC,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Beringer J,Wandmacher J","Tauber MJ,Ackermann D",Object-Based Action Planning,,1991,2,,135-155,,North-Holland,,Mental Models and Human-Computer Interaction 2,1991,,0923-8433,https://www.sciencedirect.com/science/article/pii/B9780444886026500116;http://dx.doi.org/10.1016/B978-0-444-88602-6.50011-6,10.1016/B978-0-444-88602-6.50011-6,"Current models of human-computer interaction are specialized in either semantic or procedural aspects. An object-based formalization of conceptual tool knowledge is presented which aims to integrate a high level semantic description and the procedural level. The principle of data-abstraction provides explicit links between both levels. An object-based analysis of the user's task world and the system's functionality produces a well defined set of simple tasks. By using a state-oriented definition of the task we are able to represent the task within the same formal model. Therefore, the intermediate levels of semantic action planning, i.e., the transformation of a user's intention into a sequence of simple tasks, can be derived by the object-based description of the functionality of a system.",,,Human Factors in Information Technology,,,,,,,,,,,,,,,,,,,
Journal Article,"Aragón RG,Medina J,Ramírez-Poussa E",,Impact of local congruences in variable selection from datasets,Journal of Computational and Applied Mathematics,2021,,,113416,,,,,2021,,0377-0427,https://www.sciencedirect.com/science/article/pii/S0377042721000352;http://dx.doi.org/10.1016/j.cam.2021.113416,10.1016/j.cam.2021.113416,"Formal concept analysis (FCA) is a useful mathematical tool for obtaining information from relational datasets. One of the most interesting research goals in FCA is the selection of the most representative variables of the dataset, which is called attribute reduction. Recently, the attribute reduction mechanism has been complemented with the use of local congruences in order to obtain robust clusters of concepts, which form convex sublattices of the original concept lattice. Since the application of such local congruences modifies the quotient set associated with the attribute reduction, it is fundamental to know how the original context (attributes, objects and relationship) has been modified in order to understand the impact of the application of the local congruence in the attribute reduction.","Formal concept analysis, Size concept lattice reduction, Congruence relation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dimassi S,Demoly F,Cruz C,Qi HJ,Kim KY,André JC,Gomes S",,An ontology-based framework to formalize and represent 4D printing knowledge in design,Computers in Industry,2021,126,,103374,,,,,2021,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361520306084;http://dx.doi.org/10.1016/j.compind.2020.103374,10.1016/j.compind.2020.103374,"Over the last decade, 4D printing paradigm has received intensive research efforts, whether from researchers in additive manufacturing (AM) or in smart materials (SMs) development. Related research works have thereby generated a large number of ad-hoc solutions with relevant disparate and scattered knowledge. This lack of common core knowledge is mainly due to the multiple involved expertise for fabricating stimulus-reactive structures. The scientific issue of federating and reconciling knowledge is also reinforced especially if such technology must be integrated into the product design process, falling under the field of design for 4D printing. To tackle this challenge, it becomes crucial to formalize and represent knowledge relating AM processes/techniques, SMs behaviours, stimuli and transformation functions with the variety of design objects. In such a context, the paper aims at developing an ontology-based framework for the semantic and logical description of transformable objects in the era of 4D printing for product-process design related purposes. This framework – which is built upon a foundational ontology associated with mereotopology for describing dynamical phenomena called basic formal ontology – consists in introducing a domain ontology equipped with reasoning capabilities supported by description logics for SMs selection and distribution, transformation sequence planning and AM process planning purposes.","4D Printing, Smart materials, Additive manufacturing, Design for 4D printing, Ontology, Description logics",,,,,,,,,,,,,,,,,,,,,
Journal Article,Miculan M,,Developing (Meta)Theory of λ-calculus in the Theory of Contexts1 1Work partially supported by Italian MURST project tosca and EC-WG types,Electronic Notes in Theoretical Computer Science,2001,58,1,37-58,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104002786;http://dx.doi.org/10.1016/S1571-0661(04)00278-6,10.1016/S1571-0661(04)00278-6,"We present a case study on the formal development of a non trivial (meta)theory in the Theory of Contexts using the Coq proof assistant. The methodology underlying the Theory of Contexts for reasoning on systems presented in HOAS is based on an axiomatic syntactic standpoint. We feel that one of the main advantages of this approach, is that it requires a very low logical overhead. The object system we focus on is the lazy, call-by-name λ-calculus (λcbn), both untyped and simply typed. We will see that the formal, fully detailed development of the theory of (λcbn) in the Theory of Contexts introduces a small, sustainable overhead with respect to the proofs “on the paper”. Moreover, this will allow for comparison with similar case studies developed in other approaches to the metatheoretical reasoning in higher-order abstract syntax.","higher-order abstract syntax, induction, logical frameworks",MERLIN 2001: Mechanized Reasoning about Languages with Variable Binding (in connection with IJCAR 2001),,,,,,,,,,,,,,,,,,,,
Journal Article,"Filippi JB,Bisgambiglia P",,JDEVS: an implementation of a DEVS based formal framework for environmental modelling,Environmental Modelling & Software,2004,19,3,261-274,,,,,2004,,1364-8152,https://www.sciencedirect.com/science/article/pii/S136481520300210X;http://dx.doi.org/10.1016/j.envsoft.2003.08.016,10.1016/j.envsoft.2003.08.016,"The development of models using multiple modelling paradigms is necessary to formulate and study current problems in environmental science. To simplify the coupling of those models, a formal basis for a high-level specification of such models must be set up. In this paper, we propose a discrete event system specification (DEVS) based modelling framework as a formal basis in environmental modelling. The formal framework ensures that the models are reusable and interoperable components with well defined interfaces. Moreover, a wide variety of modelling paradigms can be expressed in the DEVS formalism. We also extend the modelling paradigms that can be expressed in the DEVS framework with two techniques: Feedback-DEVS for the specification of supervised-learning models and Vector-DEVS for the specification of models in vector space. JDEVS is the Java implementation of the framework. It enables discrete event, general purpose, object oriented, component based, GIS connected, collaborative, visual simulation model development and execution. A Feedback-DEVS neural-network model and a cellular infiltration model are described as experiments using JDEVS. Those models are later coupled to show the new modelling scenarios enabled by the use of a formal framework and the flexibility of the software.","Discrete event simulation, Environmental modelling, Artificial neural networks, Vector propagation, 3D visualization","Concepts, Methods and Applications in Environmental Model Integration",,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Moellering H,Hogan MR",- Spatial Archive and Interchange Format (SAIF) Canada,,1997,,,95-112,,Pergamon,Oxford,Spatial Database Transfer Standards 2: Characteristics for Assessing Standards and Full Descriptions of the National and International Standards in the World,1997,9780080424330,,https://www.sciencedirect.com/science/article/pii/B9780080424330500101;http://dx.doi.org/10.1016/B978-008042433-0/50010-1,10.1016/B978-008042433-0/50010-1,"Publisher Summary This chapter focuses on the Spatial Archive and Interchange Format (SAIF) in Canada. The SAIF was developed as a means of sharing spatial and spatiotemporal data. The SAIF Standard Schema consists of the definitions of nearly 300 types or classes based on the data model. It includes the formal definition of spatial and temporal objects as well as generic geographic objects. It also includes spatial and temporal relationships, geometry, metadata, and other associated classes and enumerations. The metadata has attributes that provide information regarding referencing, lineage, quality, and updating. SAIF has an extensible, object-oriented language, and SAIF talk, with two components. The first consists of the Class Syntax Notation (CSN), a data definition language used to define data types in both the SAIF Standard Schema and user-defined schemas. Each new user-defined type may be based on the data model directly on the predefined types in the SAIF standard schema or on other user-defined types.",,,International Cartographic Association,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferré S,Cellier P",,Graph-FCA: An extension of formal concept analysis to knowledge graphs,Discrete Applied Mathematics,2020,273,,81-102,,,,,2020,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X19301532;http://dx.doi.org/10.1016/j.dam.2019.03.003,10.1016/j.dam.2019.03.003,"Knowledge graphs offer a versatile knowledge representation, and have been studied under different forms, such as conceptual graphs or RDF graphs in the Semantic Web. A challenge is to discover conceptual structures in those graphs, in the same way as Formal Concept Analysis (FCA) discovers conceptual structures in tables. FCA has been successful for analysing, mining, learning, and exploring tabular data, and our aim is to help transpose those results to graph-based data. Previous several FCA approaches have already addressed relational data, hence graphs, but with various limits. We propose Graph-FCA as an extension of FCA where a dataset is a hypergraph instead of a binary table. We show that it can be formalized simply by replacing objects by tuples of objects. This leads to the notion of “n-ary concept”, whose extent is an n-ary relation of objects, and whose intent is a “projected graph pattern”. In this paper, we formally reconstruct the fundamental results of FCA for knowledge graphs. We describe in detail the representation of hypergraphs, and the operations on them, as they are much more complex than the sets of attributes that they extend. We also propose an algorithm based on a notion of “pattern basis” to generate and display n-ary concepts in a more efficient and more compact way. We explore a few use cases, in order to study the feasibility and usefulness of Graph-FCA. We consider two use cases: workflow patterns in cooking recipes and linguistic structures from parse trees. In addition, we report on experiments about quantitative aspects of the approach.","Formal concept analysis, Knowledge graph, Semantic web, Graph homomorphism",Advances in Formal Concept Analysis: Traces of CLA 2016,,,,,,,,,,,,,,,,,,,,
Journal Article,"Durán F,Meseguer J",,An Extensible Module Algebra For Maude,Electronic Notes in Theoretical Computer Science,1998,15,,174-195,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580012X;http://dx.doi.org/10.1016/S1571-0661(05)80012-X,10.1016/S1571-0661(05)80012-X,"The fact that rewriting logic and Maude are reflective, so that rewriting logic specifications can be manipulated as terms at the metalevel, opens up the possibility of defining an algebra of module composition and transformation operations within the logic. This makes such a module algebra easily modifiable and extensible, enables the implementation of language extensions within Maude, and allows formal reasoning about the module operations themselves. In this paper we discuss in detail the Maude implementation of a specific choice of operations for a module algebra of this type, supporting module operations in the Clear/OBJ tradition as well as the transformation of object-oriented modules into system modules.",,International Workshop on Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Book Chapter,Bobrow DG,"Shrobe HE,the American Association for Artificial Intelligence","Chapter 15 - The Common LISP Object System: An Example of Integrating Programming Paradigms11This paper is based on a talk given at AAAI-86. At that time, CommonLoops was the example used of tight integration of paradigms. Since that time, the Common LISP Object System has emerged as a better example (see the Acknowledgments section of this survey)",,1988,,,619-640,,Morgan Kaufmann,,Exploring Artificial Intelligence,1988,9780934613675,,https://www.sciencedirect.com/science/article/pii/B9780934613675500198;http://dx.doi.org/10.1016/B978-0-934613-67-5.50019-8,10.1016/B978-0-934613-67-5.50019-8,"Publisher Summary A programming paradigm is a supported style of programming with significant advantages for a domain of problems. Many programming paradigms have been added on top of LISP, but few have been tightly integrated. Common LISP Object System (CLOS) is a model of a good integration. CLOS blends the object-oriented programming paradigm smoothly and tightly with the usual procedure-oriented paradigm of LISP. Functions and methods are combined in a more general abstraction. Message passing is invoked via normal LISP function call and methods are viewed as partial descriptions of procedures. LISP data types are integrated with object classes. With these integrations, it is easy to incrementally move a program between the procedure and object-oriented styles. By integrating classes with the LISP type system and using a syntax for method invocation that is identical to the LISP function call, CLOS makes possible a smooth and incremental transition from using only the functional paradigm for user code to using the object paradigm. As a portable system implemented in a widely available base, it allows users the choice of hardware and environments. It allows them a road to the future.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Pilarczyk J,Janeczko W,Sterna R,Kuniecki M",,Are emotional objects visually salient? The Emotional Maps Database,Journal of Visual Communication and Image Representation,2021,79,,103221,,,,,2021,,1047-3203,https://www.sciencedirect.com/science/article/pii/S1047320321001462;http://dx.doi.org/10.1016/j.jvcir.2021.103221,10.1016/j.jvcir.2021.103221,"The visual system prioritizes emotional content in natural scenes, but it is unclear whether emotional objects are systematically more salient. We compare emotional maps - created by averaging multiple manual selections of the most meaningful regions in images of negative, positive, and neutral affective valence - with saliency maps generated by Graph-Based Visual Saliency, Proto-object, and SalGAN models. We found that similarity between emotional and saliency maps is modulated by the scenes’ arousal and valence ratings: the more negative and high-arousing content, the less it was salient. Simultaneously, the negative and high-arousing content was the easiest to identify by the participants, as shown by the highest inter-individual agreement in the selections. Our results support the “affective gap” hypothesis, i.e., decoupling of emotional meaning from image’s formal features. The Emotional Maps Database created for this study, proven useful in gaze fixation prediction, is available online for scientific use.","Meaning maps, Saliency, Emotion, Arousal, Natural scenes, Key objects",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rieder R,Raposo AB,Pinho MS",,A methodology to specify three-dimensional interaction using Petri Nets,Journal of Visual Languages & Computing,2010,21,3,136-156,,,,,2010,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X10000091;http://dx.doi.org/10.1016/j.jvlc.2010.01.002,10.1016/j.jvlc.2010.01.002,"This work presents a methodology to formally model and to build three-dimensional interaction tasks in virtual environments using three different tools: Petri Nets, the Interaction Technique Decomposition taxonomy, and Object-Oriented techniques. User operations in the virtual environment are represented as Petri Net nodes; these nodes, when linked, represent the interaction process stages. In our methodology, places represent all the states an application can reach, transitions define the conditions to start an action, and tokens embody the data manipulated by the application. As a result of this modeling process we automatically generate the core of the application's source code. We also use a Petri Net execution library to run the application code. In order to facilitate the application modeling, we have adapted Dia, a well-known graphical diagram editor, to support Petri Nets creation and code generation. The integration of these approaches results in a modular application, based on Petri Nets formalism that allows for the specification of an interaction task and for the reuse of developed blocks in new virtual environment projects.","Interaction tasks, Petri Nets, Specification, Code generation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Deya A,Schott R",,On stochastic calculus with respect to q-Brownian motion,Journal of Functional Analysis,2018,274,4,1047-1075,,,,,2018,,0022-1236,https://www.sciencedirect.com/science/article/pii/S0022123617303336;http://dx.doi.org/10.1016/j.jfa.2017.08.019,10.1016/j.jfa.2017.08.019,"Following the approach and the terminology introduced in Deya and Schott (2013) [6], we construct a product Lévy area above the q-Brownian motion (for q∈[0,1)) and use this object to study differential equations driven by the process. We also provide a detailed comparison between the resulting “rough” integral and the stochastic “Itô” integral exhibited by Donati-Martin (2003) [7].","Non-commutative stochastic calculus, -Brownian motion, Rough paths theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li J,Ren Y,Mei C,Qian Y,Yang X",,A comparative study of multigranulation rough sets and concept lattices via rule acquisition,Knowledge-Based Systems,2016,91,,152-164,,,,,2016,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705115002786;http://dx.doi.org/10.1016/j.knosys.2015.07.024,10.1016/j.knosys.2015.07.024,"Recently, by combining rough set theory with granular computing, pessimistic and optimistic multigranulation rough sets have been proposed to derive “AND” and “OR” decision rules from decision systems. At the same time, by integrating granular computing and formal concept analysis, Wille’s concept lattice and object-oriented concept lattice were used to obtain granular rules and disjunctive rules from formal decision contexts. So, the problem of rule acquisition can bring rough set theory, granular computing and formal concept analysis together. In this study, to shed some light on the comparison and combination of rough set theory, granular computing and formal concept analysis, we investigate the relationship between multigranulation rough sets and concept lattices via rule acquisition. Some interesting results are obtained in this paper: (1) “AND” decision rules in pessimistic multigranulation rough sets are proved to be granular rules in concept lattices, but the inverse may not be true; (2) the combination of the truth parts of an “OR” decision rule in optimistic multigranulation rough sets is an item of the decomposition of a disjunctive rule in concept lattices; (3) a non-redundant disjunctive rule in concept lattices is shown to be the multi-combination of the truth parts of “OR” decision rules in optimistic multigranulation rough sets; and (4) the same rule is defined with a same certainty factor but a different support factor in multigranulation rough sets and concept lattices. Moreover, algorithm complexity analysis is made for the acquisition of “AND” decision rules, “OR” decision rules, granular rules and disjunctive rules.","Rough set theory, Granular computing, Multigranulation rough set, Concept lattice, Rule acquisition",Three-way Decisions and Granular Computing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liang WY,O’Grady P",,An object-oriented approach to the concurrent engineering of electronics assemblies,Computers in Industry,2002,47,2,239-254,,,,,2002,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361501001440;http://dx.doi.org/10.1016/S0166-3615(01)00144-0,10.1016/S0166-3615(01)00144-0,"An electronics assembly (EA) can be regarded as the backbone of electronic or electro-mechanical products, where its functions are implemented by combining components and their interconnections on a substrate plate. The design of EAs is relatively complex and encompasses the consideration of many diverse considerations. This paper is concerned with the central area of electronic assemblies component selection (EACS), and with considering constraints at this stage to avoid multiple repetitions of the design process. The main task is to take the requirements and constraints, together with a set of possible electronics components, and then to select a subset of these components to satisfy the requirements (functional, physical, …) and constraints, while minimizing or maximizing the objective function. The use of such EACS promises substantial benefits but its successful implementation is hampered by the lack of a suitable formalism, particularly where, as is often the case, participants are geographically separated. The work presented in this paper is focused on how to represent EACS, where the participants may be remote, and how to implement it in a formal and systematic way. A representation formalism is proposed for that purpose. This paper first overviews the EACS process. A formalism for EACS is then presented. An Internet network-based implementation of this formalism is described that uses the Internet to support EACS, and an example is used to illustrate the implementation. The main contributions of this paper are three-fold. First, the design domain of electronics assemblies is described. Second, a formalism for EACS is presented. Third, the use of this formalism is illustrated with an Internet-based implementation showing how the formalism can be used for a specific problem.","Electronics assembly, Design process, Concurrent engineering, Object-oriented approach",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Clavel M,Durán F,Eker S,Lincoln P,Martı́-Oliet N,Meseguer J,Quesada JF",,Maude: specification and programming in rewriting logic,Theoretical Computer Science,2002,285,2,187-243,,,,,2002,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397501003590;http://dx.doi.org/10.1016/S0304-3975(01)00359-0,10.1016/S0304-3975(01)00359-0,"Maude is a high-level language and a high-performance system supporting executable specification and declarative programming in rewriting logic. Since rewriting logic contains equational logic, Maude also supports equational specification and programming in its sublanguage of functional modules and theories. The underlying equational logic chosen for Maude is membership equational logic, that has sorts, subsorts, operator overloading, and partiality definable by membership and equality conditions. Rewriting logic is reflective, in the sense of being able to express its own metalevel at the object level. Reflection is systematically exploited in Maude endowing the language with powerful metaprogramming capabilities, including both user-definable module operations and declarative strategies to guide the deduction process. This paper explains and illustrates with examples the main concepts of Maude's language design, including its underlying logic, functional, system and object-oriented modules, as well as parameterized modules, theories, and views. We also explain how Maude supports reflection, metaprogramming and internal strategies. The paper outlines the principles underlying the Maude system implementation, including its semicompilation techniques. We conclude with some remarks about applications, work on a formal environment for Maude, and a mobile language extension of Maude.","Maude, Rewriting logic, Functional modules, System modules, Parameterization, Reflection, Internal strategies",Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Guizzardi G,Zamborlini V",,Using a trope-based foundational ontology for bridging different areas of concern in ontology-driven conceptual modeling,Science of Computer Programming,2014,96,,417-443,,,,,2014,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642314000896;http://dx.doi.org/10.1016/j.scico.2014.02.022,10.1016/j.scico.2014.02.022,"In recent years, ontology-driven reference models have gained much attention in the literature due to their potential key role in activities such as complex information modeling and semantic interoperability. The engineering process of these conceptual models should account for different phases addressing different areas of concern. In an initial phase of conceptual domain modeling, the target modeling artifacts should be constructed with the goal of maximizing quality attributes such as expressivity and truthfulness to the represented domain in reality. In a subsequent development phase, the resulting domain models can be used to guide the design decisions in the construction of different implementation artifacts addressing different computational concerns. In this paper, we present a philosophically sound, cognitively-oriented and formally characterized foundational theory of objects and tropes (property-instances). Moreover, we use this theory to bring about engineering contributions to both the aforementioned phases of ontology-driven conceptual modeling. Firstly, we show how this theory has been used to (re)design a system of modeling primitives underlying the conceptual domain modeling language OntoUML. Furthermore, we provide precise directives on how to map conceptual domain models in this language to their implementation in less-expressive computationally-oriented codification languages. In particular, we address here a mapping strategy to OWL (Web Ontology Language) that partially preserves the modal-temporal semantics of OntoUML. Finally, we discuss computational support for the proposed approach in terms of conceptual model construction, automatic transformation and temporal querying.","Ontological foundations for conceptual modeling, Conceptual domain modeling, Foundational ontology, Temporal reification, Trope theory",Selected Papers from the Fifth International Conference on Software Language Engineering (SLE 2012),,,,,,,,,,,,,,,,,,,,
Journal Article,"Cellier FE,Zeigler BP,Cutler AH",,Object-Oriented Modeling: Tools and Techniques for Capturing Properties of Physical Systems in Computer Code1,IFAC Proceedings Volumes,1991,24,4,1-10,,,,,1991,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017542408;http://dx.doi.org/10.1016/S1474-6670(17)54240-8,10.1016/S1474-6670(17)54240-8,"Mathematical modeling means the formal encoding of knowledge about a dynamical system. Knowledge can be grouped into behavioral knowledge and structural knowledge. Behavioral knowledge is local knowledge relating to a particular experiment applied to a system or model. Behavioral knowledge is what is generated in a real-world experiment or during a simulation run. Structural knowledge is global knowledge relating to a system or model, irrespective of the experiment that is performed. A model is a formal encoding of structural knowledge of a system. Structural knowledge can be further decomposed into functional knowledge, coupling knowledge, decomposition knowledge, and taxonomic knowledge. In this paper, a methodology is presented that helps to organize the structural knowledge about a system to be described. It enables to encode separately and in an organized fashion functional, coupling, decomposition, and taxonomic knowledge about a system. The methodology lends itself to the implementation of automated procedures for deductive as well as inductive model synthesis necessary for the realization of high-autonomy intelligent control systems. A fairly involved example concludes the paper","Artificial intelligence, decentralized control, event-based control, failure detection, intelligent machines, knowledge abstraction, model synthesis, object-oriented modeling, process control, time-windows","IFAC Symposium on Computer Aided Design in Control Systems, Swansea, UK, 15-17 July 1991",,,,,,,,,,,,,,,,,,,,
Journal Article,"Liu W,Li S",,Reasoning about cardinal directions between extended objects: The NP-hardness result,Artificial Intelligence,2011,175,18,2155-2169,,,,,2011,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370211000981;http://dx.doi.org/10.1016/j.artint.2011.07.005,10.1016/j.artint.2011.07.005,"The cardinal direction calculus (CDC) proposed by Goyal and Egenhofer is a very expressive qualitative calculus for directional information of extended objects. Early work has shown that consistency checking of complete networks of basic CDC constraints is tractable, while reasoning with the CDC in general is NP-hard. This paper shows, however, that if some constraints are unspecified, then consistency checking of incomplete networks of basic CDC constraints is already intractable. This draws a sharp boundary between the tractable and intractable subclasses of the CDC. The result is achieved by a reduction from the well-known 3-SAT problem.","Qualitative spatial reasoning, Cardinal direction calculus, NP-hardness, Consistency checking, Reduction",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Neill CJ,Laplante PA",,Specification of real-time imaging systems using the UML,Real-Time Imaging,2003,9,2,125-137,,,,,2003,,1077-2014,https://www.sciencedirect.com/science/article/pii/S1077201403000196;http://dx.doi.org/10.1016/S1077-2014(03)00019-6,10.1016/S1077-2014(03)00019-6,"Real-time imaging systems are expected to perform at a rate set by the operating environment. This places additional temporal constraints on the implementation, and has led to advances in parallel processing and optimization. The constraints are also applied, however, to the analysis and design models of the system, an aspect that has received far less consideration, particularly outside of academia. It is well understood that the earlier an error is discovered the cheaper the fix and this is taken to the extent that, if an error can be found during design or even analysis, the repair can be several orders of magnitude cheaper. It is therefore an economic imperative that the analysis and design models are sufficiently expressive such that the flaws in the model can be discovered before they are implemented, and this applies equally to real-time constraints. The contribution of this paper is to make the case for the use of the Unified Modeling Language, extended with a rigorous formal method, the Q-model, for the specification and design of real-time imaging systems. To illustrate its utility the proposed approach is examined in comparison with a more traditional approach, Structured Analysis and Design, by way of a case study.","Real-time, Imaging systems, Object-oriented, Formal Method, UML",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wolfengagen VE,Kosikov SV,Slieptsov IO",,A Cognitive Type System Simulation by a Dynamically Typed Language,Procedia Computer Science,2018,145,,641-645,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050918323573;http://dx.doi.org/10.1016/j.procs.2018.11.069,10.1016/j.procs.2018.11.069,The paper considers the problem of ensuring the functional safety of the program by eliminating typing errors. It describes the classification of errors according to the place of their origin and detection and the classification of error detection tools at the stage when the errors are detected. An approach is proposed to improve safety by simulating and using a type system in dynamically typed language that allows identifying and localizing the errors while running the program.,"type systems, debugging, static typing, dynamic typing, type contract, types-as-objects","Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic",,,,,,,,,,,,,,,,,,,,
Journal Article,"Wolfengagen VE,Ismailova LY,Kosikov SV",,The Typing System to Provide Compositional Thinking About Data Flows,Procedia Computer Science,2018,123,,246-251,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050918300395;http://dx.doi.org/10.1016/j.procs.2018.01.038,10.1016/j.procs.2018.01.038,"The paper considers the approach to solving the problem of preventing the information system vulnerability that arises due to the insertion and / or performance of a semantically incorrect script (XSS-vulnerability). The solution of this task suggests modelling the information exchange between active objects. Modelling is supposed to be carried out within the framework of the basic applicative computing system, in which the code fragments can be modelled by applicative objects. An important part of the task is to check the correctness of the scenarios composition, which requires the tools make compositional thinking about data flows, both when they are processed by scripts and contain them. The correctness is proposed to be provided by supporting the fairly strong typing system that excludes incorrect combinations of scenarios. The type system is assumed to be immersed into the applicative environment. The system is proposed to be built on the basis of the homotopy type theory, which ensures, in particular, the introduction of independent and dependent types, as well as the definition of recursion and induction principles for them. Partial approbation of typing constructions is performed with the example of the problem of semantic support for the implementation of the best available technologies (BAT).","problem domain dynamics, Web tangling, semantic, support data flows, type system, ho-motopy theory","8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia",,,,,,,,,,,,,,,,,,,,
Journal Article,Sangiorgi D,,The name discipline of uniform receptiveness,Theoretical Computer Science,1999,221,1,457-493,,,,,1999,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397599000407;http://dx.doi.org/10.1016/S0304-3975(99)00040-7,10.1016/S0304-3975(99)00040-7,"In a process calculus, we say that a name x is uniformly receptive for a process P if:(1) at any time P is ready to accept an input at x, at least as long as there are processes that could send messages at x;(2) the input offer at x is functional, that is, all messages received by P at x are applied to the same continuation. In the π-calculus this discipline is employed, for instance, when modeling functions, objects, higher-order communications, or remote-procedure calls. We formulate the discipline of uniform receptiveness by means of a type system, and then we study its impact on behavioural equivalences and process reasoning. We develop some theory and proof techniques for uniform receptiveness, and illustrate their usefulness on some non-trivial examples.","π-calculus, Types, Uniform receptiveness",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Vidal JR,Guijarro L",,A methodology for developing simulation models of ATM networks in SDL language,Computer Communications,2002,25,3,265-287,,,,,2002,,0140-3664,https://www.sciencedirect.com/science/article/pii/S014036640100367X;http://dx.doi.org/10.1016/S0140-3664(01)00367-X,10.1016/S0140-3664(01)00367-X,"This paper describes a modelling methodology based on formal description techniques (FDTs). This methodology develops simulation models designed to evaluate asynchronous transfer mode (ATM) networks. The purpose of such networks is to integrate multiple communication services by providing a variety of service classes with different characteristics, making a wide range of adaptation protocols and traffic management mechanisms necessary. All these mechanisms and their interactions are usually evaluated by means of simulation, but this requires complex simulation models to be developed. Our proposal is based on specification and description language (SDL), and using its object-oriented capabilities to systematically develop simulation models, including many combinations of the mechanisms under study, to any degree of complexity. In order to demonstrate its use, the simulation results were applied in a significant case study.","Specification and description language, Network modelling, Multilayer simulation, Asynchronous transfer mode, Traffic management",,,,,,,,,,,,,,,,,,,,,
Journal Article,Xu KH,,"A class of bounded functions, a database language and an extended lambda calculus",Theoretical Computer Science,2017,691,,81-106,,,,,2017,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397517305406;http://dx.doi.org/10.1016/j.tcs.2017.07.002,10.1016/j.tcs.2017.07.002,"We develop an approach of partial computations for the lambda calculus. It produces a class of bounded functions (i.e., the co-domains are finite while the domains are possibly infinite), including self-applicable functions. We show that the bounded functions are recursive and have to be represented as lambda terms without head normal form in the lambda calculus. In parallel, we develop a language independently from the lambda calculus. It also represents the class of bounded functions and therefore can produce whatever a Turing machine produces provided that computation has finite time and space. We call such a language a database language because we can use the language to construct and query business objects in database practice. With the bounded functions, we are able to extend the lambda calculus to effectively reduce terms having weak head normal form in a manner similar to how the standard lambda calculus reduces terms that have normal form.","The lambda calculus, Partial computation (approximation), The leftmost reduction strategy, Multiple fixed-point combinators, Visser set, Database",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liang WY,O'Grady P",,An object-oriented formalism for electronics assemblies components selection,Computers & Industrial Engineering,1999,37,1,97-100,,,,,1999,,0360-8352,https://www.sciencedirect.com/science/article/pii/S0360835299000315;http://dx.doi.org/10.1016/S0360-8352(99)00031-5,10.1016/S0360-8352(99)00031-5,"An electronics assembly (EA) is a backbone of electronic or electromechanical products, where its functions are implemented by combining components and their interconnections (conductors) on a substrate plate. The design of EAS is relatively complex and encompasses the consideration of many diverse considerations. This paper is concerned with the central area of electronic assemblies component selection (EACS), and with considering constraints at this stage to avoid multiple repetitions of the design process. The use of such EACS promises substantial benefits but its successful implementation is hampered by the lack of a suitable formalism, particularly where, as is often the case, participants are geographically separated. The work presented in this paper is focused on how to represent EACS, where the participants may be remote, and how to implement it in a formal and systematic way. A representation formalism is proposed for that puspose.","Electronic Assemblies Component Selection, Concurrent Engineering, Geographically Separated, Design Rules",Proceedings of the 24th international conference on computers and industrial engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tichkiewitch S,Véron M",,Methodology and Product Model for Integrated Design Using a Multiview System,CIRP Annals,1997,46,1,81-84,,,,,1997,,0007-8506,https://www.sciencedirect.com/science/article/pii/S000785060760780X;http://dx.doi.org/10.1016/S0007-8506(07)60780-X,10.1016/S0007-8506(07)60780-X,"A methodology of integrated design is presented, based on the co-operative work between the partners of the life-cycle of the product. A product model, which is a link between a knowledge model and a data model, accommodates specific decisions of each participant in a multi-view system. Two exchange modes are available to the users: a formal one is the standard network between computers and gives access to a common product database and an informal one that uses a multi-media network in order to permit dialogue between participants. The prototype of such a design modeller is realized with an object oriented language.","Design, Integration, Product",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Behr N,Krivine J,Andersen JL,Merkle D",,Rewriting theory for the life sciences: A unifying theory of CTMC semantics,Theoretical Computer Science,2021,884,,68-115,,,,,2021,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439752100428X;http://dx.doi.org/10.1016/j.tcs.2021.07.026,10.1016/j.tcs.2021.07.026,"The Kappa biochemistry and the MØD organic chemistry frameworks are amongst the most intensely developed applications of rewriting-based methods in the life sciences to date. A typical feature of these types of rewriting theories is the necessity to implement certain structural constraints on the objects to be rewritten (a protein is empirically found to have a certain signature of sites, a carbon atom can form at most four bonds, ...). In this paper, we contribute a number of original developments that permit to implement a universal theory of continuous-time Markov chains (CTMCs) for stochastic rewriting systems. Our core mathematical concepts are a novel rule algebra construction for the relevant setting of rewriting rules with conditions, both in Double- and in Sesqui-Pushout semantics, augmented by a suitable stochastic mechanics formalism extension that permits to derive dynamical evolution equations for pattern-counting statistics. A second main contribution of our paper is a novel framework of restricted rewriting theories, which comprises a rule-algebra calculus under the restriction to so-called constraint-preserving completions of application conditions (for rules considered to act only upon objects of the underlying category satisfying a globally fixed set of structural constraints). This novel framework in turn renders a faithful encoding of bio- and organo-chemical rewriting in the sense of Kappa and MØD possible, which allows us to derive a rewriting-based formulation of reaction systems including a full-fledged CTMC semantics as instances of our universal CTMC framework. While offering an interesting new perspective and conceptual simplification of this semantics in the setting of Kappa, both the formal encoding and the CTMC semantics of organo-chemical reaction systems as motivated by the MØD framework are the first such results of their kind.","Double-pushout rewriting, Sesqui-pushout rewriting, Rule algebra theory, Stochastic mechanics, Biochemistry, Organic chemistry, Algorithmic cheminformatics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kosiuczenko P,Wirsing M",,Formalizing and Executing Message Sequence Charts via Timed Rewriting,Electronic Notes in Theoretical Computer Science,1999,25,,50-61,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104001318;http://dx.doi.org/10.1016/S1571-0661(04)00131-8,10.1016/S1571-0661(04)00131-8,"Message Sequence Charts (MSC) is a graphical trace language for describing and specifying the communication behaviour of distributed systems by means of message interchange. (Timed) Maude is a formal object-oriented specification language which combines algebraic specification techniques for describing complex data structures with (timed) term rewriting to deal with dynamic behaviour. In this paper we show first how to formalize MSC in Timed Maude. Then we give a translation of timed rewriting to untimed rewrite systems and use this translation to execute Message Sequence Charts with the Elan system, a powerful tool which combines Rewriting Logic with a language of rewriting strategies. We illustrate our approach with the bench mark example of a railroad crossing.",,The 1998 ARO/ONR/NSF/DARPA Monterey Workshop on Engineering Automation for Computer Basesd Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Halpin TA,Proper HA",,Subtyping and polymorphism in object-role modelling,Data & Knowledge Engineering,1995,15,3,251-281,,,,,1995,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9500005D;http://dx.doi.org/10.1016/0169-023X(95)00005-D,10.1016/0169-023X(95)00005-D,"Although Entity-Relationship (ER) modelling techniques are commonly used for information modelling, Object-Role Modelling (ORM) techniques are becoming increasingly popular, partly because they include detailed design procedures providing guidelines for the modeller. As with the ER approach, a number of different ORM techniques exist. In this paper, we propose an integration of two theoretically well founded ORM techniques: FORM and PSM. Our main focus is on a common terminological framework, and on the notion of subtyping. Subtyping has long been an important feature of semantic approaches to conceptual schema design. It is also the concept in which FORM and PSM differ the most in their formalization. The subtyping issue is discussed from three different viewpoints covering syntactical, identification, and population issues. Finally, a wider comparison of approaches to subtyping is made, which encompasses other ER-based and ORM-based information modelling techniques, and highlights how formal subtype definitions facilitate a comprehensive specification of subtype constraints.","Object-role modelling, Conceptual modelling, Information systems, Subtyping, Polymorphism",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Clavel M,Eker S,Lincoln P,Meseguer J",,Principles of Maude,Electronic Notes in Theoretical Computer Science,1996,4,,65-89,,,,,1996,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104000349;http://dx.doi.org/10.1016/S1571-0661(04)00034-9,10.1016/S1571-0661(04)00034-9,"This paper introduces the basic concepts of the rewriting logic language Maude and discusses its implementation. Maude is a wide-spectrum language supporting formal specification, rapid prototyping, and parallel programming. Maude's rewriting logic paradigm includes the functional and object-oriented paradigms as sublanguages. The fact that rewriting logic is reflective leads to novel metaprogramming capabilities that can greatly increase software reusability and adaptability. Control of the rewriting computation is achieved through internal strategy languages defined inside the logic. Maude's rewrite engine is designed with the explicit goal of being highly extensible and of supporting rapid prototyping and formal methods applications, but its semi-compilation techniques allow it to meet those goals with good performance.",,"RWLW96, First International Workshop on Rewriting Logic and its Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"Merunková I,Merunka V",,OBA and BORM Approach in the Organizational Modeling and Simulation of Local Government Processes and Country Planning,Procedia Technology,2013,8,,81-89,,,,,2013,,2212-0173,https://www.sciencedirect.com/science/article/pii/S2212017313000741;http://dx.doi.org/10.1016/j.protcy.2013.11.012,10.1016/j.protcy.2013.11.012,"This paper presents BORM approach as the tool for business process analysis, design and simulation of local government processes and country planning. The first part of this paper discusses the motivation for the application of the finite-state- machines and object-oriented based paradigm to this area of business process modeling. We practically experienced, that this approach saves time and improves the validity and correctness of the business process model of the built information system in specific conditions of agriculture and country planning management of socio-technical systems. In this paper, we plead the idea of necessary specific textual-based formal steps being performed before assembling process diagrams in order to assure better results. The second part describes the pre-diagramming text-based techniques being used before the subsequent modeling, which presented the third part on the example of the living situations among citizens and other participating subjects from small settlements with an emphasis on local government activities and country planning.","organizational modeling and simulation, BORM, text-based techniques, diagramming techniques, country planning, urban sprawl","6th International Conference on Information and Communication Technologies in Agriculture, Food and Environment (HAICTA 2013)",,,,,,,,,,,,,,,,,,,,
Journal Article,Sheu PC,,VLSI design with object-oriented knowledge bases,Computer-Aided Design,1988,20,5,272-280,,,,,1988,,0010-4485,https://www.sciencedirect.com/science/article/pii/0010448588900735;http://dx.doi.org/10.1016/0010-4485(88)90073-5,10.1016/0010-4485(88)90073-5,"One major technology that is needed is the development of a system that can integrate design tools and design databases, and is able to design an entire engineering system based on formal specifications. In this paper, a knowledge engineering framework for designing VLSI computer architectures is introduced. This framework introduces three core concepts: knowledge abstraction, object-oriented design, and very high-level design programming. The input to the system is a descriptive specification of the behaviour of a computing system. The description is then matched against the existing design knowledge in the knowledge base, where the knowledge is abstracted and organized as classes. If a match can be found, the abstract knowledge is instantiated and can be reused; otherwise a heuristic synthesis process will be performed according to the design knowledge stored in the system. In the worst case, the designer goes one level down and decomposes the system into a set of smaller systems, where a structural description among different modules is specified, but only the behavioural specification for each module is given. The process is then repeated until a complete structural description is developed. At the bottom level, the system is designed to support and automate the following tasks: integration of layout design tools; propagation of dynamic changes; propagation and abstraction of performance measurements; incremental design rule checking; and version control.","computer-aided design, VLSI, object-oriented design",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Flower J,Fish A,Howse J",,Euler diagram generation,Journal of Visual Languages & Computing,2008,19,6,675-694,,,,,2008,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X08000049;http://dx.doi.org/10.1016/j.jvlc.2008.01.004,10.1016/j.jvlc.2008.01.004,"Euler diagrams form the basis of many diagrammatic notations used to represent set theoretic relationships in a wide range of contexts including: file system information, statistical data representation, object-oriented modeling, logical specification and reasoning systems, and database search queries. An abstract Euler diagram is a formal abstract description of the information that is to be displayed as a concrete (or drawn) Euler diagram. If the abstract diagram can be visualized, whilst satisfying certain desirable visual properties (called well-formedness conditions), then we say the diagram is drawable. We solve the drawability problem for a given set of well-formedness conditions, identifying the properties which classify a diagram as drawable or undrawable. Furthermore, we present a high level algorithm which enables the generation of a concrete diagram from an abstract diagram, whenever it is drawable.","Euler diagrams, Automatic generation, Drawability, Logic visualization, Data representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hermann F,Ehrig H,Taentzer G",,A Typed Attributed Graph Grammar with Inheritance for the Abstract Syntax of UML Class and Sequence Diagrams,Electronic Notes in Theoretical Computer Science,2008,211,,261-269,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108002636;http://dx.doi.org/10.1016/j.entcs.2008.04.048,10.1016/j.entcs.2008.04.048,"According to the UML Standard 2.0 class and sequence diagrams are defined in a descriptive way by a MOF meta-model and semi-formal constraints. This paper presents a formal and constructive definition of the abstract syntax of UML class and sequence diagrams based on the well-defined theory of typed attributed graph transformation with inheritance and application conditions. The generated language covers all important features of these parts of UML diagrams and is shown to satisfy all of the corresponding constraints by construction. An explicit model transformation demonstrates the close correspondence between the graph grammar and the MOF definition of UML class and sequence diagrams. The graph grammar is validated by well-established benchmarks showing that all important features of the MOF definition of UML are covered. This formal constructive syntax definition of UML class and sequence diagrams is the basis for syntax directed editing, formal analysis, formal operational and denotational semantics and correctness of model transformations.","graph transformation, typed, attributed, inheritance, UML, sequence diagrams, class diagrams, abstract syntax",Proceedings of the Fifth International Workshop on Graph Transformation and Visual Modeling Techniques (GT-VMT 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Jeffrey A,Rathke J",,A fully abstract may testing semantics for concurrent objects,Theoretical Computer Science,2005,338,1,17-63,,,,,2005,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397504006991;http://dx.doi.org/10.1016/j.tcs.2004.10.012,10.1016/j.tcs.2004.10.012,This paper provides a fully abstract semantics for a variant of the concurrent object calculus. We define may testing for concurrent object components and then characterise it using a trace semantics inspired by UML interaction diagrams. The main result of this paper is to show that the trace semantics is fully abstract for may testing. This is the first such result for a concurrent object language.,"Object calculus, Full abstraction, Concurrency",,,,,,,,,,,,,,,,,,,,,
Journal Article,Nuiten J,,Koszul duality for Lie algebroids,Advances in Mathematics,2019,354,,106750,,,,,2019,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870819303603;http://dx.doi.org/10.1016/j.aim.2019.106750,10.1016/j.aim.2019.106750,"This paper studies the role of dg-Lie algebroids in derived deformation theory. More precisely, we provide an equivalence between the homotopy theories of formal moduli problems and dg-Lie algebroids over a commutative dg-algebra of characteristic zero. At the level of linear objects, we show that the category of representations of a dg-Lie algebroid is an extension of the category of quasi-coherent sheaves on the corresponding formal moduli problem. We describe this extension geometrically in terms of pro-coherent sheaves.","Lie algebroid, Formal moduli problem, Koszul duality",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Limongelli C,Temperini M",,Abstract specification of structures and methods in symbolic mathematical computation,Theoretical Computer Science,1992,104,1,89-107,,,,,1992,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759290167E;http://dx.doi.org/10.1016/0304-3975(92)90167-E,10.1016/0304-3975(92)90167-E,"This paper describes a methodology based on the object-oriented programming paradigm, to support the design and implementation of a symbolic computation system. The requirements of the system are related to the specification and treatment of mathematical structures. This treatment is considered from both the numerical and the symbolic points of view. The resulting programming system should be able to support the formal definition of mathematical data structures and methods at their highest level of abstraction, to perform computations on instances created from such definitions, and to handle abstract data structures through the manipulation of their logical properties. Particular consideration is given to the correctness aspects. Some examples of convenient application of the proposed design methodology are presented.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Luckey M,Erwig M,Engels G",,Systematic evolution of model-based spreadsheet applications,Journal of Visual Languages & Computing,2012,23,5,267-286,,,,,2012,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X12000389;http://dx.doi.org/10.1016/j.jvlc.2011.11.009,10.1016/j.jvlc.2011.11.009,"Using spreadsheets is the preferred method to calculate, display or store anything that fits into a table-like structure. They are often used by end users to create applications, although they have one critical drawback—spreadsheets are very error-prone. Recent research has developed methods to reduce this error-proneness by introducing a new way of object-oriented modeling of spreadsheets before using them. These spreadsheet models, termed ClassSheets, are used to generate concrete spreadsheets on the instance level. By this approach sources of errors are reduced and spreadsheet applications become easier to understand. As usual for almost every other application, requirements on spreadsheets change due to the changing environment. Thus, the problem of evolution of spreadsheets arises. The update and evolution of spreadsheets is the uttermost source of errors that may have severe impact. In this paper, we will introduce a model-based approach to spreadsheet evolution by propagating updates on spreadsheet models (i.e. ClassSheets) to spreadsheets. To this end, update commands for the ClassSheet layer are automatically transformed to those for the spreadsheet layer. We describe spreadsheet model update propagation using a formal framework and present an integrated tool suite that allows the easy creation and safe update of spreadsheet models. The presented approach greatly contributes to the problem of software evolution and maintenance for spreadsheets and thus avoids many errors that might have severe impacts.","Model-based, Spreadsheet, Evolution, Update, Propagation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Wöhlke G,,A programming and simulation environment for the karlsruhe dextrous hand,Robotics and Autonomous Systems,1990,6,3,243-263,,,,,1990,,0921-8890,https://www.sciencedirect.com/science/article/pii/092188909090016T;http://dx.doi.org/10.1016/0921-8890(90)90016-T,10.1016/0921-8890(90)90016-T,"In this paper the development of a programming and simulation environment is described, which was especially tailored for programming of multifinger hands. The research has concerned with the programming of the Karlsruhe Dextrous Hand, a non-anthropomorphic three finger gripper with 9 degrees of freedom, which is being developed at our institute. The work presents the results of a task-oriented approach to the object manipulation problem and contains two main parts: a system programming module and an application programming module. This realization supports the interactive generation and evaluation of a hand program using graphical simulation.","Programming environment, Dextrous multifinger hands, Object based programming, Assembly planning, Task decomposition, Parameter transformation, Kinematic and force simulation, Grip and stiffness matrix, Process and workcell model, Database system, Formal programming language, Task compiler and interpreter, Task library",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kamburjan E,Hähnle R,Schön S",,Formal modeling and analysis of railway operations with active objects,Science of Computer Programming,2018,166,,167-193,,,,,2018,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642318302508;http://dx.doi.org/10.1016/j.scico.2018.07.001,10.1016/j.scico.2018.07.001,"We present a comprehensive model of railway operations written in the active object language ABS. The model is based on specifications taken from the rulebooks of Deutsche Bahn AG. It is statically analyzable and executable, hence allows to use static and dynamic analysis within one and the same formalism. We are able to combine aspects of micro- and macroscopic modeling and provide a way to inspect changes in the rulebooks. We illustrate the static analysis capability by a safety analysis based on invariant reasoning that only relies on assumptions about the underlying railway infrastructure instead of explicitly exploring the state space. A concrete infrastructure layout and train schedule can be used as input to the model to examine dynamic properties such as delays. We illustrate the capability for dynamic analysis by demonstrating the effect that different ways of dealing with faulty signals have on delays and propagation of delays.","Railway operations, Active objects, Formal methods, Deductive verification, Distributed systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Burmeister D,Gerlach B,Schrader A",,Formal Definition of the Smart Object Matching Problem,Procedia Computer Science,2018,130,,302-309,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S187705091830396X;http://dx.doi.org/10.1016/j.procs.2018.04.043,10.1016/j.procs.2018.04.043,"Smart objects represent appliances enhanced by digital and interconnectable functionality, which are intended to support users in everyday life. By embedding sensors, these objects become input resp. interaction devices that stimulate the actuators of their own or other smart objects. However, due to a large number of objects to be expected, there also exist a number of challenges for the usability of such devices. In addition to the invisible nature of embedded digital functionality, wireless interconnections and possible changes in connectivity depending on the context, it is often not possible for users to explore the complete functionality of a smart object and interconnect them appropriately. In this paper, we present a dynamic approach for the automated interconnection of smart objects input and output capabilities with reference to the assignment problem. In addition to a formal definition, we present an evaluation of a naive approach and familiar algorithms for this problem.","Smart Objects, Assignment Problem, Self-Description, Self-Organization, Dynamic Assignment","The 9th International Conference on Ambient Systems, Networks and Technologies (ANT 2018) / The 8th International Conference on Sustainable Energy Information Technology (SEIT-2018) / Affiliated Workshops",,,,,,,,,,,,,,,,,,,,
Journal Article,"Amar J,Nagase K",,A unified framework for dynamics and control of tree-type systems using exponential coordinates,Mechanical Systems and Signal Processing,2019,131,,446-468,,,,,2019,,0888-3270,https://www.sciencedirect.com/science/article/pii/S0888327019302134;http://dx.doi.org/10.1016/j.ymssp.2019.03.033,10.1016/j.ymssp.2019.03.033,"This paper proposes a rapid and convenient method to model and control tree-type architecture systems using exponential coordinates. Exponential coordinates have elegant rules on products and derivatives, which allows for a simple definition of joint movements; and are highly effective for modeling complex architectures. The grasping and manipulation of an object by robot manipulators is considered in order to illustrate our modeling and control process. Using the chain matrix representing the system architecture, we derive a unified framework for the manipulator and object dynamics in a closed form fashion. The key benefit of this methodology is its simplicity and flexibility. Using this newly derived form of dynamics, we can conveniently change the system configurations (add/delete joints and links, change direction of joint movements, etc.) from one design to another; this will more accurately satisfy the manipulation requirements and simplify the optimization process for future system and control designs. Simulators can be conveniently constructed by following the formulas derived in the paper. Numerical examples of an arm–hand system are conducted to illustrate the usage of the proposed formulas in modeling, control, and optimization process.","Exponential coordinates, Tree-type system, Dynamics and control, Grasping/manipulation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"de Frutos Escrig D,Marroquín Alonso O",,Ambient Petri Nets,Electronic Notes in Theoretical Computer Science,2003,85,1,39,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105800866;http://dx.doi.org/10.1016/S1571-0661(05)80086-6,10.1016/S1571-0661(05)80086-6,"Both the Ambient Calculus by L. Cardelli and the Elementary Object Systems by R. Valk model the behaviour of mobile systems. The Ambient Calculus is based on the concept of ambient, which is an environment with a given name that is delimited by a boundary, where some internal processes are executed. The main property of these ambients is that they can be moved to a new location thus modeling mobility. Elementary Object Systems are two-level net systems composed of a system net and one or more object nets, which can be seen as high-level token objects of the system net modeling the execution of mobile processes. This paper intends to contribute to the relationship between both frameworks by defining a multilevel extension of Elementary Object Systems, which will be used to provide a denotational semantics of a new process algebra called APBC (Ambient Petri Box Calculus). Such process algebra is an extension of the Petri Box Calculus that includes both ambients and their mobility capabilities, which conversely can be also interpreted as an extension of the Ambient Calculus with the main operations from the PBC.",,"FGC, Foundations of Global Computing, 2nd EATCS Workshop (Satellite Event of ICALP 2003)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhao T,Baker J,Hunt J,Noble J,Vitek J",,Implicit ownership types for memory management,Science of Computer Programming,2008,71,3,213-241,,,,,2008,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642308000300;http://dx.doi.org/10.1016/j.scico.2008.04.001,10.1016/j.scico.2008.04.001,"The Real-time Specification for Java (RTSJ) introduced a range of language features for explicit memory management. While the RTSJ gives programmers fine control over memory use and allows linear allocation and constant-time deallocation, the RTSJ relies upon dynamic runtime checks for safety, making it unsuitable for safety critical applications. We introduce ScopeJ, a statically-typed, multi-threaded, object calculus in which scopes are first class constructs. Scopes reify allocation contexts and provide a safe alternative to automatic memory management. Safety follows from the use of an ownership type system that enforces a topology on run-time patterns of references. ScopeJ’s type system is novel in that ownership annotations are implicit. This substantially reduces the burden for developers and increases the likelihood of adoption. The notion of implicit ownership is particularly appealing when combined with pluggable type systems, as one can apply different type constraints to different components of an application depending on the requirements without changing the source language. In related work we have demonstrated the usefulness of our approach in the context of highly-responsive systems and stream processing.","Real-time Java, RTSJ, Type systems, Memory management, Ownership types",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hintermeier C,Kirchner C,Kirchner H",,Dynamically Typed Computations for Order-sorted Equational Presentations,Journal of Symbolic Computation,1998,25,4,455-527,,,,,1998,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717197901875;http://dx.doi.org/10.1006/jsco.1997.0187,10.1006/jsco.1997.0187,"Equational presentations with ordered sorts encompass partially defined functions and subtyping information in an algebraic framework. In this work we address the problem of computing in order-sorted algebras, with few restrictions on the allowed presentations. We adopt the G-algebra framework, where equational, membership and existence formulas can be expressed, and this provides a complete deduction calculus which incorporates the interaction between all these formulas. To practically deal with this calculus, we introduce an operational semantics for G-algebra using rewrite systems over so-called decorated terms, that has assertions concerning the sort membership of any subterm in its head node. Decorated rewrite rules perform equational replacement, decoration rewrite rules enrich the decorations and record sort information. Therefore we use the semantic sort principle, i.e. equal terms belong to equal sorts, rather than the syntactic sort principle that does not use the equational part of a presentation. In order to have a complete and decidable unification on decorated terms, we restrict to sort-inheritance theories. Then a completion procedure on decorated terms is designed to compute all interactions between equational and membership formulas. When the completion terminates, the resulting set of rewrite rules provides a way to decide equational theorems of the form (t=t′) and typing theorems of the form (t:A). The sort inheritance property is undecidable in general but we propose a test to check it for a given presentation. The test provides information on how to extend the presentation in a model conservative way, in order to obtain sort inheritance.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bennett J,Cooper K,Dai L",,Aspect-oriented model-driven skeleton code generation: A graph-based transformation approach,Science of Computer Programming,2010,75,8,689-725,,,,,2010,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642309000914;http://dx.doi.org/10.1016/j.scico.2009.05.005,10.1016/j.scico.2009.05.005,"Model-driven code generation has been investigated in traditional and object-oriented design paradigms; significant progress has been made. It offers many advantages including the rapid development of high quality code. Errors are reduced and the consistency between the design and the code is retained, in comparison with a purely manual approach. Here, a model-driven code generation approach based on graph transformations for aspect-oriented development is proposed. The approach has two main transformation activities. The first activity transforms a visual (graphical) model of the design into a formal, text-based notation that can be readily processed. The graphical model is created by the software designer and uses a UML profile for aspect-oriented software (i.e., FDAF) to represent aspects and their components. XML is the target notation for this step; the transformation uses the XML meta-model to ensure that the output complies with the language. The second activity transforms the XML model into AspectJ source code. The transformation uses the AspectJ meta-model to ensure the output complies with the language. The transformations from the extended UML model to XML and from XML to AspectJ code are fully automated. The transformation algorithms are based on graph transformations; tool support has been developed. Key technical issues in the approach are discussed, including performance, the amount of code generated, correctness, and adaptability, in addition to a comparison of the proposal with existing alternative approaches. The approach has been validated on three example systems: a banking system, classroom scheduling system, and an insurance system. The banking system example is presented in the paper.","Model-driven development, Aspect-oriented, Automated code generation, Software design, Visual modeling, AspectJ",Designing high quality system/software architectures,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li J,Mei C,Wang J,Zhang X",,Rule-preserved object compression in formal decision contexts using concept lattices,Knowledge-Based Systems,2014,71,,435-445,,,,,2014,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705114003207;http://dx.doi.org/10.1016/j.knosys.2014.08.020,10.1016/j.knosys.2014.08.020,"Rule acquisition is one of the main purposes in the analysis of formal decision contexts. In general, given a formal decision context, some of its objects may not be essential to the rule acquisition. This study investigates the issue of reducing the object set of a formal decision context without losing the decision rule information provided by the entire set of objects. Using concept lattices, we propose a theoretical framework of object compression for formal decision contexts. And under this framework, it is proved that the set of all the non-redundant decision rules obtained from the reduced database is sound and complete with respect to the initial formal decision context. Furthermore, a complete algorithm is developed to compute a reduct of a formal decision context. The analysis of some real-life databases demonstrates that the proposed object compression method can largely reduce the size of a formal decision context and it can remove much more objects than both the techniques of clarified context and row reduced context.","Formal context, Concept lattice, Formal decision context, Object compression, Rule acquisition",,,,,,,,,,,,,,,,,,,,,
Journal Article,Petersen W,,A Set-Theoretical Approach for the Induction of Inheritance Hierarchies,Electronic Notes in Theoretical Computer Science,2004,53,,296-308,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105825903;http://dx.doi.org/10.1016/S1571-0661(05)82590-3,10.1016/S1571-0661(05)82590-3,"An approach for the automatic construction of inheritance hierarchies is presented. It is based on the strict set-theoretical point of view in the mathematical theory of Formal Concept Analysis. The resulting hierarchies are concept lattices. An extension of the approach to the induction of nonmonotonic inheritance networks is also discussed. It turns out that the main ideas of Formal Concept Analysis, i.e. the formal context, the concept lattice and the set of implications, provide three different ways of looking at the data to be represented, each of which provides a different way to solve problems of knowledge representation.",,Proceedings of the joint meeting of the 6th Conference on Formal Grammar and the 7th Conference on Mathematics of Language,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hussain S,Keung J,Sohail MK,Khan AA,Ilahi M",,Automated framework for classification and selection of software design patterns,Applied Soft Computing,2019,75,,1-20,,,,,2019,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494618306173;http://dx.doi.org/10.1016/j.asoc.2018.10.049,10.1016/j.asoc.2018.10.049,"Though, Unified Modeling Language (UML), Ontology, and Text categorization approaches have been used to automate the classification and selection of design pattern(s). However, there are certain issues such as time and effort for formal specification of new patterns, system context-awareness, and lack of knowledge which needs to be addressed. We propose a framework (i.e. Three-phase method) to discuss these issues, which can aid novice developers to organize and select the correct design pattern(s) for a given design problem in a systematic way. Subsequently, we propose an evaluation model to gauge the efficacy of the proposed framework via certain unsupervised learning techniques. We performed three case studies to describe the working procedure of the proposed framework in the context of three widely used design pattern catalogs and 103 design problems. We find the significant results of Fuzzy c-means and Partition Around Medoids (PAM) as compared to other unsupervised learning techniques. The promising results encourage the applicability of the proposed framework in terms of design patterns organization and selection with respect to a given design problem.","Design patterns, Design problems, Unsupervised learning, Text categorization, Feature selection, Supervised learning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Abrams MD,Zelkowitz MV",,Striving for correctness,Computers & Security,1995,14,8,719-738,,,,,1995,,0167-4048,https://www.sciencedirect.com/science/article/pii/0167404895000224;http://dx.doi.org/10.1016/0167-4048(95)00022-4,10.1016/0167-4048(95)00022-4,"In developing information technology, you want assurance that systems are secure and reliable, but you cannot have assurance or security without correctness. We discuss methods used to achieve correctness, focusing on weaknesses and approaches that management might take to increase belief in correctness. Formal methods, simulation, testing, and process modeling are addressed in detail. Structured programming, life-cycle modeling like the spiral model, use of CASE tools, use of formal methods, object-oriented design, reuse of existing code are also mentioned. Reliance on these methods involves some element of belief since no validated metrics on the effectiveness of these methods exist. Suggestions for using these methods as the basis for managerial decisions conclude the paper.","Assurance, Belief, Correctness, Formal methods, Mathematical models, Metrics, Process models, Risk management, Security testing, Simulation, Silver bullets, Trustworthiness",,,,,,,,,,,,,,,,,,,,,
Journal Article,"McCusker G,Santamaria A",,Composing dinatural transformations: Towards a calculus of substitution,Journal of Pure and Applied Algebra,2021,225,10,106689,,,,,2021,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404921000256;http://dx.doi.org/10.1016/j.jpaa.2021.106689,10.1016/j.jpaa.2021.106689,"Dinatural transformations, which generalise the ubiquitous natural transformations to the case where the domain and codomain functors are of mixed variance, fail to compose in general; this has been known since they were discovered by Dubuc and Street in 1970. Many ad hoc solutions to this remarkable shortcoming have been found, but a general theory of compositionality was missing until Petrić, in 2003, introduced the concept of g-dinatural transformations, that is, dinatural transformations together with an appropriate graph: he showed how acyclicity of the composite graph of two arbitrary dinatural transformations is a sufficient and essentially necessary condition for the composite transformation to be in turn dinatural. Here we propose an alternative, semantic rather than syntactic, proof of Petrić's theorem, which the authors independently rediscovered with no knowledge of its prior existence; we then use it to define a generalised functor category, whose objects are functors of mixed variance in many variables, and whose morphisms are transformations that happen to be dinatural only in some of their variables. We also define a notion of horizontal composition for dinatural transformations, extending the well-known version for natural transformations, and prove it is associative and unitary. Horizontal composition embodies substitution of functors into transformations and vice-versa, and is intuitively reflected from the string-diagram point of view by substitution of graphs into graphs. This work represents the first, fundamental steps towards a substitution calculus for dinatural transformations as sought originally by Kelly, with the intention then to apply it to describe coherence problems abstractly. There are still fundamental difficulties that are yet to be overcome in order to achieve such a calculus, and these will be the subject of future work; however, our contribution places us well in track on the path traced by Kelly towards a calculus of substitution for dinatural transformations.","Dinatural transformation, Compositionality, Substitution, Coherence, Petri net",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Romero JR,Vallecillo A,Durán F",,Writing and executing ODP computational viewpoint specifications using Maude,Computer Standards & Interfaces,2007,29,4,481-498,,,,,2007,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548906001309;http://dx.doi.org/10.1016/j.csi.2006.11.004,10.1016/j.csi.2006.11.004,"The Reference Model of Open Distributed Processing (RM-ODP) is a joint standardization effort by ITU-T and ISO/IEC for the specification of large open distributed systems. RM-ODP is becoming increasingly relevant now because the size and complexity of large distributed systems is challenging current software engineering methods and tools, and because international standards have become key to achieve the required interoperability between the different parties and organizations involved in the design and development of complex systems. RM-ODP defines five viewpoints for decomposing the design activity into separate areas of concern. One of the RM-ODP viewpoints, the computational viewpoint, focuses on the basic functionality of the system and its environment, independently of its distribution. Although several notations have been proposed to model the ODP computational viewpoint, either they are not expressive enough to faithfully represent all its concepts, or they tend to suffer from a lack of formal support. In this paper we introduce the use of Maude as a formal notation for writing and executing ODP computational viewpoint specifications. Maude is an executable rewriting logic language specially well suited for the specification of object-oriented open and distributed systems. We show how Maude offers a simple, natural, and accurate way of modeling the ODP computational viewpoint concepts, allows the execution of the specifications produced, and offers good tool support for reasoning about them.","Rewriting logic, Maude, RM-ODP, ODP computational viewpoint, Environment contracts",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Greco S,Rullo P",,Complex-Prolog: A logic database language for handling complex objects,Information Systems,1989,14,1,79-87,,,,,1989,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437989900264;http://dx.doi.org/10.1016/0306-4379(89)90026-4,10.1016/0306-4379(89)90026-4,"The logic language paradigm represents a natural extension of relational databases. However, one of its limitations is the lack of suitable data abstraction mechanisms for modeling complex objects. This paper describes Complex-Prolog, a logic database language that provides facilities for data abstraction, notably, the notions of object identity, class and inheritance. This language was designed as an attempt to integrate concepts from logic programming and semantic data models. A formal definition of Complex-Prolog, interspersed with a number of examples, is given. The paper concludes with a description of its implementation.","Complex objects, databases, inheritance, logic programming, semantic data models",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Carriou V,Boudaoud S,Laforet J,Ayachi FS",,Fast generation model of high density surface EMG signals in a cylindrical conductor volume,Computers in Biology and Medicine,2016,74,,54-68,,,,,2016,,0010-4825,https://www.sciencedirect.com/science/article/pii/S001048251630107X;http://dx.doi.org/10.1016/j.compbiomed.2016.04.019,10.1016/j.compbiomed.2016.04.019,"In the course of the last decade, fast and qualitative computing power developments have undoubtedly permitted for a better and more realistic modeling of complex physiological processes. Due to this favorable environment, a fast, generic and reliable model for high density surface electromyographic (HD-sEMG) signal generation with a multilayered cylindrical description of the volume conductor is presented in this study. Its main peculiarity lies in the generation of a high resolution potential map over the skin related to active Motor Units (MUs). Indeed, the analytical calculus is fully performed in the frequency domain. HD-sEMG signals are obtained by surfacic numerical integration of the generated high resolution potential map following a variety of electrode shapes. The suggested model is implemented using parallel computing techniques as well as by using an object-oriented approach which is comprehensive enough to be fairly quickly understood, used and potentially upgraded. To illustrate the model abilities, several simulation analyses are put forward in the results section. These simulations have been performed on the same muscle anatomy while varying the number of processes in order to show significant speed improvement. Accuracy of the numerical integration method, illustrating electrode shape diversity, is also investigated in comparison to analytical transfer functions definition. An additional section provides an insight on the volume detection of a circular electrode according to its radius. Furthermore, a large scale simulation is introduced with 300MUs in the muscle and a HD-sEMG electrode grid composed of 16×16 electrodes for three constant isometric contractions in 12s. Finally, advantages and limitations of the proposed model are discussed with a focus on perspective works.","Electromyography, HD-sEMG generation model, Frequency domain calculus, Parallel computing",,,,,,,,,,,,,,,,,,,,,
Journal Article,Lee DT,,Evaluating real-time software specification languages,Computer Standards & Interfaces,2002,24,5,395-409,,,,,2002,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548902000661;http://dx.doi.org/10.1016/S0920-5489(02)00066-1,10.1016/S0920-5489(02)00066-1,"In recent years, many notations and methods in real-time software engineering have been proposed. However, thorough experimentation to evaluate these notations and methods has not been carried out. This paper focuses on real-time software engineering specification languages: Unified Modeling Language (UML), Real-Time Object-Oriented Modeling Language (ROOM), Modecharts, statecharts, Mealy and Moore machines, finite state machines, classical logic, Z, ASTRAL, temporal logic, FNLOG, linear logic, Timed Communicating Sequential Processes (TCSP), Temporal Calculus of Communicating Systems (TCCS), ρ1, and Multilevel Specification. The basis for evaluating these software engineering specification languages is by using the Turing machines and Interaction machines. We classify them based on their computational capabilities.","Real-time software engineering, Specification languages, Turing machines, Interaction machines, Unified Modeling Language",,,,,,,,,,,,,,,,,,,,,
Journal Article,Crolard T,,Subtractive logic,Theoretical Computer Science,2001,254,1,151-185,,,,,2001,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397599001243;http://dx.doi.org/10.1016/S0304-3975(99)00124-3,10.1016/S0304-3975(99)00124-3,"This paper is the first part of a work whose purpose is to investigate duality in some related frameworks (cartesian closed categories, lambda-calculi, intuitionistic and classical logics) from syntactic, semantical and computational viewpoints. We start with category theory and we show that any bicartesian closed category with coexponents is degenerated (i.e. there is at most one arrow between two objects). The remainder of the paper is devoted to logical issues. We examine the propositional calculus underlying the type system of bicartesian closed categories with coexponents and we show that this calculus corresponds to subtractive logic: a conservative extension of intuitionistic logic with a new connector (subtraction) dual to implication. Eventually, we consider first-order subtractive logic and we present an embedding of classical logic into subtractive logic.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Scapin E,Spoto F",,Field-sensitive unreachability and non-cyclicity analysis,Science of Computer Programming,2014,95,,359-375,,,,,2014,,0167-6423,https://www.sciencedirect.com/science/article/pii/S016764231400152X;http://dx.doi.org/10.1016/j.scico.2014.03.012,10.1016/j.scico.2014.03.012,"Field-sensitive static analyses of object-oriented code use approximations of the computational states where fields are taken into account, for better precision. This article presents a novel and sound definite analysis of Java bytecode that approximates two strictly related properties: field-sensitive unreachability between program variables and field-sensitive non-cyclicity of program variables. The latter exploits the former for better precision. We build a data-flow analysis based on constraint graphs, whose nodes are program points and whose arcs propagate information according to the semantics of each bytecode instruction. We follow abstract interpretation both to approximate the concrete semantics and to prove our results formally correct. Our analysis has been designed with the goal of improving client analyses such as termination analysis, asserting the non-cyclicity of variables with respect to specific fields.","Data-flow analysis, Interprocedural static analysis, Constraint-based analysis, Field-sensitive analysis, Abstract interpretation",Special Section: ACM SAC-SVT 2013 + Bytecode 2013,,,,,,,,,,,,,,,,,,,,
Journal Article,"Azzolini D,Riguzzi F,Lamma E",,A semantics for Hybrid Probabilistic Logic programs with function symbols,Artificial Intelligence,2021,294,,103452,,,,,2021,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370221000035;http://dx.doi.org/10.1016/j.artint.2021.103452,10.1016/j.artint.2021.103452,"Probabilistic Logic Programming (PLP) is a powerful paradigm for the representation of uncertain relations among objects. Recently, programs with continuous variables, also called hybrid programs, have been proposed and assigned a semantics. Hybrid programs are capable of representing real-world measurements but unfortunately the semantics proposal was imprecise so the definition did not assign a probability to all queries. In this paper, we remedy this and formally define a new semantics for hybrid programs. We prove that the semantics assigns a probability to all queries for a large class of programs.","Probabilistic Logic Programming, Hybrid programs",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Barbot N,Miclet L,Prade H",,Analogy between concepts,Artificial Intelligence,2019,275,,487-539,,,,,2019,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370218301863;http://dx.doi.org/10.1016/j.artint.2019.06.008,10.1016/j.artint.2019.06.008,"Reasoning by analogy plays an important role in human thinking, in exploring parallels between situations. It enables us to explain by comparing, to draw plausible conclusions, or to create new devices or concepts by transposing old ones in new contexts. A basic form of analogy, called Analogical Proportion (AP), describes a particular relation between four objects of the same kind, e.g. “A calf is to a bull as a foal is to a stallion”. It is only recently that researchers have started to study APs in a formal way and to use their properties in different tasks of artificial intelligence (AI). This paper follows this line of research. Specifically, we are interested in giving the definition and some properties of an AP in lattices, a widely used structure in AI. We give general results before focusing on Concept Lattices, with the goal to investigate how analogical reasoning could be introduced in the framework of Formal Concept Analysis (FCA). This leads us to define an AP between formal concepts and to give algorithms to compute them, but also to point to special subcontexts, called analogical complexes. They are themselves organized as a lattice, and we show that they are closely related to APs between concepts, while not needing the complete construction of the lattice. To finish, we relate them to another form of analogy, called Relational Proportion, which involves two universes of discourse, e.g. “Carlsen is to chess as Mozart is to music”, which leads to the more compact way of saying “Carlsen is the Mozart of chess”, which is not anymore a relation between four objects of the same kind, but can be interpreted as well in FCAs framework.","Analogy, Analogical reasoning, Analogical proportion, Analogy in lattices, Formal concept analysis",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Mueller ET,Mueller ET,Chapter 10 - Space,,2015,,,147-165,Second Edition,Morgan Kaufmann,Boston,Commonsense Reasoning (Second Edition),2015,9780128014165,,https://www.sciencedirect.com/science/article/pii/B9780128014165000103;http://dx.doi.org/10.1016/B978-0-12-801416-5.00010-3,10.1016/B978-0-12-801416-5.00010-3,Many instances of commonsense reasoning involve space. We present two event calculus axiomatizations of space: relational space and metric space. We describe how these axiomatizations can be used to solve some sample problems. A closely related issue that we consider is object identity: Two objects observed at different times and locations in space may or may not be the same object.,"Commonsense reasoning, Event calculus, Sspatial reasoning, Reasoning about space and time, Relational space, Metric space, Object identity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Juma N,Dietl W,Tripunitara M",,A computational complexity analysis of tunable type inference for Generic Universe Types,Theoretical Computer Science,2020,814,,189-209,,,,,2020,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397520300761;http://dx.doi.org/10.1016/j.tcs.2020.01.035,10.1016/j.tcs.2020.01.035,"We address questions related to the computational complexity of inferring types for a particular type system, Generic Universe Types (GUT) [1], [2], for Java programs. GUT is useful for many applications, such as program verification [3], thread synchronization, and memory management. However, requiring the programmer to explicitly provide type information is onerous, which motivates the problem of automatically inferring types. In contrast to classical type systems, ownership type systems such as GUT may have multiple typings that satisfy the type system's rules. It is therefore appropriate for the inference to be tunable — that is, the programmer can indicate preferences for certain typings via breakable constraints and/or by partial annotations. A question then is whether efficient algorithms exist for the type inference problem. In this work we establish the following results for the type inference problem for GUT [2]. (1) The tunable type inference problem that allows breakable constraints is NP-hard, (2) an encoding of the problem as boolean satisfiability (SAT), as in prior work, is indeed a polynomial-time reduction, (3) P ≠ NP implies that the problem is not approximable in polynomial time within an approximation ratio of n1−ϵ for any ϵ>0, and (4) while some restricted versions of the problem of practical interest, such as when breakable constraints are forbidden, are in P, others remain NP-hard. Our results justify the prior approach to the problem that is based on reduction to SAT. Apart from these results, given the observation in prior work that instances of the problem that arise in practice appear to be easy, we address the natural question as to what hard instances may look like, and whether they may arise in practice. We identify a class of hard instances of the problem by devising a method to generate such instances starting at instances of the Vertex Cover problem, which is known to be NP-hard. We then analyze the structural properties of such instances as compared to easy instances of similar size. We find that for the classes of instances we consider, certain SAT structural parameters may be predictive of empirical hardness.","Computational complexity, Programming languages, Type inference, Type systems, Object ownership, NP-hardness",,,,,,,,,,,,,,,,,,,,,
Journal Article,Vityaev E,,Consciousness as a logically consistent and prognostic model of reality,Cognitive Systems Research,2020,59,,231-246,,,,,2020,,1389-0417,https://www.sciencedirect.com/science/article/pii/S1389041719304875;http://dx.doi.org/10.1016/j.cogsys.2019.09.021,10.1016/j.cogsys.2019.09.021,"The work demonstrates that brain might reflect the external world causal relationships in the form of a logically consistent and prognostic model of reality, which shows up as consciousness. The paper analyses and solves the problem of statistical ambiguity and provides a formal model of causal relationships as probabilistic maximally specific rules. We suppose that brain makes all possible inferences from causal relationships. We prove that the suggested formal model has a property of an unambiguous inference: from consistent premises we infer a consistent conclusion. It enables a set of all inferences to form a consistent model of the perceived world. Causal relationships may create fixed points of cyclic inter-predictable properties. We consider the “natural” classification introduced by John St. Mill and demonstrate that a variety of fixed points of the objects’ attributes forms a “natural” classification of the external world. Then we consider notions of “natural” categories and causal models of categories, introduced by Eleanor Rosch and Bob Rehder and demonstrate that fixed points of causal relationships between objects attributes, which we perceive, formalize these notions. If the “natural” classification describes the objects of the external world, and “natural” concepts the perception of these objects, then the theory of integrated information, introduced by G. Tononi, describes the information processes of the brain for “natural” concepts formation that reflects the “natural” classification. We argue that integrated information provides high accuracy of the objects identification. A computer-based experiment is provided that illustrates fixed points formation for coded digits.","lustering, Categorization, Natural classification, Natural concepts, Integrated information, Concepts",,,,,,,,,,,,,,,,,,,,,
Journal Article,Pavlovskiy IS,,Using Concepts of Scientific Activity for Semantic Integration of Publications,Procedia Computer Science,2017,103,,370-377,,,,,2017,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050917301242;http://dx.doi.org/10.1016/j.procs.2017.01.123,10.1016/j.procs.2017.01.123,In this article we formulate the position of the contextual approach to the requirements to semantic objects of scientific information integration. Terms of the scientific publication are objects. The homogeneous conceptual models are offered for systematization of terms of the scientific publication and an estimation of its semantic integrity. The example of semantic integration of two scientific publications is given. The applied and researched tasks are defined for the formal and semantic integration of scientific information.,"concepts of scientific activity, integration of scientific information, formal and semantic aspect of integration, homogeneous conceptual model, semantic integrity of the scientific publication","XII International Symposium Intelligent Systems 2016, INTELS 2016, 5-7 October 2016, Moscow, Russia",,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang HH,Gibbins N,Payne TR,Redavid D",,A formal model of the Semantic Web Service Ontology (WSMO),Information Systems,2012,37,1,33-60,,,,,2012,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437911001049;http://dx.doi.org/10.1016/j.is.2011.07.003,10.1016/j.is.2011.07.003,"Semantic Web Service, one of the most significant research areas within the Semantic Web vision, has attracted increasing attention from both the research community and industry. The Web Service Modelling Ontology (WSMO) has been proposed as an enabling framework for the total/partial automation of the tasks (e.g., discovery, selection, composition, mediation, execution, monitoring, etc.) involved in both intra- and inter-enterprise integration of Web services. To support the standardisation and tool support of WSMO, a formal model of the language is highly desirable. As several variants of WSMO have been proposed by the WSMO community, which are still under development, the syntax and semantics of WSMO should be formally defined to facilitate easy reuse and future development. In this paper, we present a formal Object-Z formal model of WSMO, where different aspects of the language have been precisely defined within one unified framework. This model not only provides a formal unambiguous model which can be used to develop tools and facilitate future development, but as demonstrated in this paper, can be used to identify and eliminate errors present in existing documentation.","Semantics Web Service, WSMO, Object-Z",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Thirunarayan K,Kifer M",,A theory of nonmonotonic inheritance based on annotated logic,Artificial Intelligence,1993,60,1,23-50,,,,,1993,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370293900338;http://dx.doi.org/10.1016/0004-3702(93)90033-8,10.1016/0004-3702(93)90033-8,"We propose a logical language for representing networks with nonmonotonic multiple inheritance. The language is based on a variant of annotated logic studied in [5, 6, 17–21]. The use of annotated logic provides a rich setting that allows to disambiguate networks whose topology does not provide enough information to decide how properties are to be inherited. The proposed formalism handles inheritance via strict as well as defeasible links. We provide a formal account of the language, describe its semantics, and show how a unique intended model can be associated with every inheritance specification written in the language. Finally, we present an algorithm that correctly propagates inherited properties according to the given semantics. The algorithm is also complete in the sense that it computes the set of all properties that must be inherited by any given individual object, and then terminates.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Benabbou A,Bahloul SN",,Specification-based Approach for Denotational Semantic of Orthogonal Object/Relational DBMS,Procedia Computer Science,2014,31,,369-378,,,,,2014,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050914004578;http://dx.doi.org/10.1016/j.procs.2014.05.280,10.1016/j.procs.2014.05.280,"The issue of the article is at the crossroads of databases modeling, software engineering and databases verification using formal methods. Development of databases software would be provided with a high-level specification suitable for formal reasoning about correctness properties. Formal specification techniques help discover problems in system requirements, inconsistencies and incompleteness can be resolved. Thus, we see a specified object/relational database management system (ORDBMS) as a compelling challenge. Toward this goal, we propose a formal specification–based approach to describe a denotational semantic of an orthogonal object/relational model, a compiler for SQL3 queries language and an implementation of execution engine of queries over imperative generic finite maps interface. This approach is of functional style based on inductive definitions and a high-order type theory realized within Coq proof assistant. Our work is a preamble step toward a verified ORDBMS.","Formal specification, verification, denotational semantic, databases properties, proof assistant system, query processing.","2nd International Conference on Information Technology and Quantitative Management, ITQM 2014",,,,,,,,,,,,,,,,,,,,
Journal Article,"Justo-López A,López-Morteo G,Flores-Ríos B,García LC",,Process pattern and process capability evaluation model for interoperability in learning object environments,Array,2021,10,,100059,,,,,2021,,2590-0056,https://www.sciencedirect.com/science/article/pii/S2590005621000072;http://dx.doi.org/10.1016/j.array.2021.100059,10.1016/j.array.2021.100059,"The variety of educational resources available on the Internet, the efforts made by educational institutions for the creation of digital content, the wide variety of educational platforms, and the lack of standardized processes in their development, means that the efforts are many but the impact poor. The objective of this research is to provide elements to standardize the development of virtual learning environments and to unify efforts through mechanisms for interoperability. A Reference Model of Processes for Interoperability in Learning Object Environments [RMPI] is presented, including a Process Pattern and an Assessment Model of Process Capability [AMPC], which would serve as an activity guide that educational institutions [HEI] can follow when implementing learning objects environments to make them reusable and beneficial for the users who exchange them. Among the main results are the formal definition of a process pattern, the identification of 115 activities for interoperability in the technical, syntactic, semantic, organizational, educational and cultural dimensions, the formulation of an Evaluation Model for the Capability of Processes and its disposition through a Web application for the self-evaluation of the HEI. The self-evaluation of 6 HEI was carried out following the developed model, which allowed its characterization according to its capacities for interoperability. From the results of this self-evaluation, it was possible to identify activities for the process pattern, to validate the capability levels and to know the vocation of the evaluated HEI.","Interoperability, Learning objects, Software processes",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Quintero E,Salinas P,González-Mendívil E,Ramírez H",,Augmented Reality app for Calculus: A Proposal for the Development of Spatial Visualization,Procedia Computer Science,2015,75,,301-305,,,,,2015,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050915037126;http://dx.doi.org/10.1016/j.procs.2015.12.251,10.1016/j.procs.2015.12.251,"Spatial visualization is a crucial ability to understand and solve real world problems. Typically, important features of visual-spatial abilities in mathematics learning have been the skills required to construct mental models of mathematical objects from teacher drawings or oral descriptions. However, spatial ability is not a static trait but instead a dynamic process which could be fostered through interaction of real and virtual objects. This ability could be enriched with the development of new technologies such as augmented reality. We are part of a team of innovative and educational research aiming to foster mathematical cognitive skills, crucial but generally taken for granted. The purpose of this paper is to present an augmented reality application in order to promote spatial visualization in Calculus courses for engineering students.","Augmented Reality, Calculus, spatial ability, spatial visualization, engineering education.",2015 International Conference Virtual and Augmented Reality in Education,,,,,,,,,,,,,,,,,,,,
Journal Article,"Birkedal L,Møgelberg RE,Petersen RL",,Domain-theoretical models of parametric polymorphism,Theoretical Computer Science,2007,388,1,152-172,,,,,2007,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397507004975;http://dx.doi.org/10.1016/j.tcs.2007.06.016,10.1016/j.tcs.2007.06.016,"We present a domain-theoretical model of parametric polymorphism based on admissible per’s over a domain-theoretical model of the untyped lambda calculus. The model is shown to be a model of Abadi & Plotkin’s logic for parametricity, by the construction of an LAPL-structure as defined by the authors in [L. Birkedal, R.E. Møgelberg, R.L. Petersen, Parametric domain-theoretical models of polymorphic intuitionistic/linear lambda calculus, in: M. Escardó, A. Jung, M. Mislove (Eds.), Proceedings of Mathematical Foundations of Programming Semantics 2005, vol. 155, 2005, pp. 191–217; L. Birkedal, R.E. Møgelberg, R.L. Petersen, Category theoretical models of linear Abadi & Plotkin logic, 2006 (submitted for publication)]. This construction gives formal proof of solutions to a large class of recursive domain equations, which we explicate. As an example of a computation in the model, we explicitly describe the natural numbers object obtained using parametricity. The theory of admissible per’s can be considered a domain theory for (impredicative) polymorphism. By studying various categories of admissible and chain complete per’s and their relations, we discover a picture very similar to that of domain theory.","Parametric polymorphism, Domain theory, Realizability models",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Battistelli D,Bruneau C,Dragos V",,Building a formal model for hate detection in French corpora,Procedia Computer Science,2020,176,,2358-2365,,,,,2020,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050920322092;http://dx.doi.org/10.1016/j.procs.2020.09.299,10.1016/j.procs.2020.09.299,"This paper investigates the development of a formal model in order to analyse online hate in French corpora. Relevant concepts are identified by exploiting several sources: the cognitive foundations of the appraisal theory, according to which people’s emotional response are based on their own evaluative judgments or appraisals of situations, events or objects; a linguistic model of how different kinds of modalities applied to predicative contents are expressed in textual data; several definitions of a hate speech. Based on those inputs, a formal model was developed to describe online hate speech. The model highlights different categories of hate targets and actions, and emphasizes the importance of context for online hate detection.","online hate speech, ontology, semantics",Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020,,,,,,,,,,,,,,,,,,,,
Journal Article,Saxena RK,,Generalized fractional calculus of the Aleph-function involving a general class of polynomials,Acta Mathematica Scientia,2015,35,5,1095-1110,,,,,2015,,0252-9602,https://www.sciencedirect.com/science/article/pii/S0252960215300424;http://dx.doi.org/10.1016/S0252-9602(15)30042-4,10.1016/S0252-9602(15)30042-4,"The object of this article is to study and develop the generalized fractional calculus operators given by Saigo and Maeda in 1996. We establish generalized fractional calculus formulas involving the product of ℵ-function, Appell function F3 and a general class of polynomials. The results obtained provide unification and extension of the results given by Saxena et al. [13], Srivastava and Grag [17], Srivastava et al. [20], and etc. The results are obtained in compact form and are useful in preparing some tables of operators of fractional calculus. On account of the general nature of the Saigo-Maeda operators, ℵ-function, and a general class of polynomials a large number of new and known results involving Saigo fractional calculus operators and several special functions notably H-function, I-function, Mittag-Leffler function, generalized Wright hypergeometric function, generalized Bessel-Maitland function follow as special cases of our main findings.","generalized fractional calculus operators, a general class of polynomials, -function, -function, -function, generalized Wright hypergeometric function, Mittag-Leffler function, generalized Bessel-Maitland function, 26A33, 33E20, 33C45, 33C60, 33C70",,,,,,,,,,,,,,,,,,,,,
Journal Article,Srivastava R,,Classes of series identities and associated hypergeometric reduction formulas,Applied Mathematics and Computation,2009,215,1,118-124,,,,,2009,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300309003907;http://dx.doi.org/10.1016/j.amc.2009.04.041,10.1016/j.amc.2009.04.041,"The main object of the present paper is to investigate some classes of series identities and their applications and consequences leading naturally to several (known or new) hypergeometric reduction formulas. We also indicate how some of these series identities and reduction formulas would yield several series identities which emerged recently in the context of fractional calculus (that is, calculus of integrals and derivatives of any arbitrary real or complex order).","Series identities, Operators of fractional calculus, Gamma function, Fractional differintegral formulas, Generalized hypergeometric functions, Fox–Wright functions, Gauss hypergeometric function, and functions, Hypergeometric transformation formulas, Hypergeometric reduction formulas, Legendre’s duplication formula, Fractional differintegral operator, Cauchy–Goursat integral formula",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Loulergue F,"Joubert GR,Nagel WE,Peters FJ,Walter WV",A rewriting semantics for an event-oriented functional parallel language,,2004,13,,79-86,,North-Holland,,Parallel Computing,2004,,0927-5452,https://www.sciencedirect.com/science/article/pii/S0927545204800133;http://dx.doi.org/10.1016/S0927-5452(04)80013-3,10.1016/S0927-5452(04)80013-3,"Publisher Summary This chapter discusses the design of the core of a parallel programming language called concrete data structure (CDS). It is based on explicitly-distributed concrete data structures and features compositional semantics, higher-order functions and explicitly distributed objects. The denotation semantics is outlined, the (equivalent) operational semantics is presented and a new realization of the latter is given as a rewriting system. The formal operational semantics of CDS is defined, which is fully abstract with respect to the denotational semantics. The operational semantics manipulates memo terms, terms that memorize parts of their evaluation. A memo term is a CDS program term, some of whose syntactic nodes are tagged with tables. The global data structure is a multi-set of tasks together with a function (set of pairs) mapping syntactic nodes of the term being evaluated to tables. There are two main forms of tasks. The first component of tasks is the name of a cell together with the term whose type contains it. The last component of tasks is always a mode, either a value computed for the given cell, a failure marker to indicate that the cell could not be filled, or a request mode.",,,Advances in Parallel Computing,,,,,,,,,,,,,,,,,,,
Journal Article,"Krüger N,Geib C,Piater J,Petrick R,Steedman M,Wörgötter F,Ude A,Asfour T,Kraft D,Omrčen D,Agostini A,Dillmann R",,Object–Action Complexes: Grounded abstractions of sensory–motor processes,Robotics and Autonomous Systems,2011,59,10,740-757,,,,,2011,,0921-8890,https://www.sciencedirect.com/science/article/pii/S0921889011000935;http://dx.doi.org/10.1016/j.robot.2011.05.009,10.1016/j.robot.2011.05.009,"This paper formalises Object–Action Complexes (OACs) as a basis for symbolic representations of sensory–motor experience and behaviours. OACs are designed to capture the interaction between objects and associated actions in artificial cognitive systems. This paper gives a formal definition of OACs, provides examples of their use for autonomous cognitive robots, and enumerates a number of critical learning problems in terms of OACs.","Robotics, Grounding, Reasoning about action and change, Execution monitoring, Machine learning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hartmann S,Link S",,A Membership Algorithm for Functional and Multi-valued Dependencies in the Presence of Lists,Electronic Notes in Theoretical Computer Science,2004,91,,171-194,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066103000197;http://dx.doi.org/10.1016/j.entcs.2003.12.012,10.1016/j.entcs.2003.12.012,"Nested lists are used as a data structure whenever order matters. List types are therefore supported by many advanced data models such as genomic sequence, deductive and object-oriented data models including XML. What impact does the finite list type have on the two most important classes of relational dependencies? The membership problem of functional and multi-valued dependencies in databases supporting base, record and list types is investigated. The problem is to decide whether a functional or multi-valued dependency follows from a given set of functional and multi-valued dependencies. In order to capture different data models at a time, an abstract algebraic approach based on nested attributes and subtyping is taken. This algebraic framework allows to generalise Beeri's well-known membership algorithm in [Transactions on Database Systems 5 (3) (1980) 241] from the relational data model. It is argued that the algorithm presented works correctly and in polynomial time.","Advanced Data Models, Dependencies, Finite Implication Problem, Correctness, Complexity",Proceedings of Computing: The Australasian Theory Symposium (CATS) 2004,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bergstra JA,Middelburg CA",,A thread calculus with molecular dynamics,Information and Computation,2010,208,7,817-844,,,,,2010,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540110000337;http://dx.doi.org/10.1016/j.ic.2010.01.004,10.1016/j.ic.2010.01.004,"We present a theory of threads, interleaving of threads, and interaction between threads and services with features of molecular dynamics, a model of computation that bears on computations in which dynamic data structures are involved. Threads can interact with services of which the states consist of structured data objects and computations take place by means of actions which may change the structure of the data objects. The features introduced include restriction of the scope of names used in threads to refer to data objects. Because that feature makes it troublesome to provide a model based on structural operational semantics and bisimulation, we construct a projective limit model for the theory.","Thread calculus, Thread algebra, Molecular dynamics, Restriction, Projective limit model",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Zwillinger D,Zwillinger D,79 - Operational Calculus*,,1992,,,322-325,Second Edition,Academic Press,,Handbook of Differential Equations (Second Edition),1992,9780127843919,,https://www.sciencedirect.com/science/article/pii/B9780127843919500841;http://dx.doi.org/10.1016/B978-0-12-784391-9.50084-1,10.1016/B978-0-12-784391-9.50084-1,"Publisher Summary This chapter focuses on operational calculus applicable to ordinary differential equations and partial differential equations. It is sometimes easier to solve a differential equation in a transformed space. The use of operational calculus yields a reformulation of the original differential equation. The procedure for operational calculus is that an ordinary differential equation is transformed to a field of operators. The equation in that field is then solved, and then transformed back. In this field, ordinary functions, generalized functions, and differential operators are all treated as objects in a single algebraic structure. The operator field that is used has among other elements, an identity operator (I), a differentiation operator (often denoted by D or s) and an integration operator (often denoted by D−1). The operational calculus is also called the Heaviside calculus. The operational calculus, at its simplest level, has a great similarity with Laplace transforms. It is sometimes difficult to justify the formal steps that are employed in using the operation calculus. One solution is to use a more precisely defined operator, such as the primary operator.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"De Giacomo G,Lespérance Y,Patrizi F",,Bounded situation calculus action theories,Artificial Intelligence,2016,237,,172-203,,,,,2016,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370216300479;http://dx.doi.org/10.1016/j.artint.2016.04.006,10.1016/j.artint.2016.04.006,"In this paper,1 we investigate bounded action theories in the situation calculus. A bounded action theory is one which entails that, in every situation, the number of object tuples in the extension of fluents is bounded by a given constant, although such extensions are in general different across the infinitely many situations. We argue that such theories are common in applications, either because facts do not persist indefinitely or because the agent eventually forgets some facts, as new ones are learned. We discuss various classes of bounded action theories. Then we show that verification of a powerful first-order variant of the μ-calculus is decidable for such theories. Notably, this variant supports a controlled form of quantification across situations. We also show that through verification, we can actually check whether an arbitrary action theory maintains boundedness.","Knowledge representation, Reasoning about action, Situation calculus, Verification",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Mueller ET,Mueller ET,Chapter 5 - The Commonsense Law of Inertia,,2015,,,77-89,Second Edition,Morgan Kaufmann,Boston,Commonsense Reasoning (Second Edition),2015,9780128014165,,https://www.sciencedirect.com/science/article/pii/B978012801416500005X;http://dx.doi.org/10.1016/B978-0-12-801416-5.00005-X,10.1016/B978-0-12-801416-5.00005-X,"A quality of the commonsense world is that objects tend to stay in the same state unless they are affected by events. A book sitting on a table remains on the table unless it is picked up, a light stays on until it is turned off, and a falling object continues to fall until it hits something. This is known as the commonsense law of inertia. We discuss the representation of the commonsense law of inertia in the event calculus. We retrace the development of the discrete event calculus axioms, and we discuss the enforcement of the commonsense law of inertia and the release of fluents from inertia.","Commonsense reasoning, Event calculus, Reasoning about action and change, Commonsense law of inertia, Fframe problem, Frame axioms, Explanation closure axioms",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Elemam E,Bahaa-Eldin AM,Shaker NH,Sobh M",,Formal verification for a PMQTT protocol,Egyptian Informatics Journal,2020,21,3,169-182,,,,,2020,,1110-8665,https://www.sciencedirect.com/science/article/pii/S1110866519302865;http://dx.doi.org/10.1016/j.eij.2020.01.001,10.1016/j.eij.2020.01.001,"The future of Internet of Things (IoT) foresees a world of interconnected people with every physical object in a seamless manner. The security related aspects for the IoT world are still an open field of discussion and research. The Message Queue Telemetry Transport (MQTT) application layer protocol is widely used in IoT networks. Since, MQTT standard has no mandatory requirements regarding the security services, therefore, manipulating the security related issues is different in MQTT platforms. This paper proposes a novel security protocol. It is the Protected Message Queue Telemetry Transport (PMQTT) protocol which is based on MQTT with added cryptographic primitives to offer security services for IoT systems. Moreover, a formal verification for a PMQTT protocol is conducted using the ProVerif cryptographic automated verifier tool to prove that the PMQTT protocol satisfies the intended security properties.","IoT, MQTT, Elliptic Curve Digital Signature Algorithm, Elliptic Curve Diffie Hellman, Formal verification, ProVerif",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kapron BM,Steinberg F",,Type-two polynomial-time and restricted lookahead,Theoretical Computer Science,2020,813,,1-19,,,,,2020,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397519304293;http://dx.doi.org/10.1016/j.tcs.2019.07.003,10.1016/j.tcs.2019.07.003,"This paper provides an alternate characterization of type-two polynomial-time computability, with the goal of making second-order complexity theory more approachable. We rely on the usual oracle machines to model programs with subroutine calls. In contrast to previous results, the use of higher-order objects as running times is avoided, either explicitly or implicitly. Instead, regular polynomials are used. This is achieved by refining the notion of oracle-polynomial-time introduced by Cook. We impose a further restriction on the oracle interactions to force feasibility. Both the restriction as well as its purpose are very simple: it is well-known that Cook's model allows polynomial depth iteration of functional inputs with no restrictions on size, and thus does not guarantee that polynomial-time computability is preserved. To mend this we restrict the number of lookahead revisions, that is the number of times a query can be asked that is bigger than any of the previous queries. We prove that this leads to a class of feasible functionals and that all feasible problems can be solved within this class if one is allowed to separate a task into efficiently solvable subtasks. Formally put: the closure of our class under lambda-abstraction and application includes all feasible operations. We also revisit the very similar class of strongly polynomial-time computable operators previously introduced by Kawamura and Steinberg. We prove it to be strictly included in our class and, somewhat surprisingly, to have the same closure property. This can be attributed to properties of the limited recursion operator: It is not strongly polynomial-time computable but decomposes into two such operations and lies in our class.","Computability in higher types, Feasible functionals, Type-two polynomial time, Oracle Turing machine, Applied lambda-calculus, Recursion on notation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Luo Z,Soloviev S",,"Dependent Coercions1 1This work is partly supported by the UK EPSRC grant on “Subtyping, Inheritance and Reuse” (GR/K79130)",Electronic Notes in Theoretical Computer Science,1999,29,,152-168,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105803147;http://dx.doi.org/10.1016/S1571-0661(05)80314-7,10.1016/S1571-0661(05)80314-7,"A notion of dependent coercion is introduced and studied in the context of dependent type theories. It extends our earlier work on coercive subtyping into a uniform framework which increases the expressive power with new applications. A dependent coercion introduces a subtyping relation between a type and a family of types in that an object of the type is mapped into one of the types in the family. We present the formal framework, discuss its meta-theory, and consider applications such as its use in functional programming with dependent types.",,"CTCS '99, Conference on Category Theory and Computer Science",,,,,,,,,,,,,,,,,,,,
Book Chapter,Tsuiki H,,A Reflective Domain Construction for Type Inheritance and Higher-Order Generics,,1993,4,,151-162,,Elsevier,,Japan Society for Software Science and Technology,1993,,1044-7997,https://www.sciencedirect.com/science/article/pii/B9780120371044500141;http://dx.doi.org/10.1016/B978-0-12-037104-4.50014-1,10.1016/B978-0-12-037104-4.50014-1,"Summary A semantic domain that captures the notions of type inheritance and higher-order generic functions is constructed. Here, a type is defined to inherit another type if a coercion function exists between them. A function is defined as generic if it preserves types and coercions. It is constructed in the category of I-domains (domain with type inheritance), whose objects are mathematical models of domains with hierarchical type structure. Their morphisms are mathematical models of generic functions. This category is Cartesian closed, and domain equations such as M = MB + [M ↕ M] are solvable in this category. In the solution of this equation, the semantics of untyped lambda calculus with generic constants is defined.",,,Advances in Software Science and Technology,,,,,,,,,,,,,,,,,,,
Journal Article,"Liu W,Zhang X,Li S,Ying M",,Reasoning about cardinal directions between extended objects,Artificial Intelligence,2010,174,12,951-983,,,,,2010,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370210000834;http://dx.doi.org/10.1016/j.artint.2010.05.006,10.1016/j.artint.2010.05.006,"Direction relations between extended spatial objects are important commonsense knowledge. Recently, Goyal and Egenhofer proposed a relation model, known as the cardinal direction calculus (CDC), for representing direction relations between connected plane regions. The CDC is perhaps the most expressive qualitative calculus for directional information, and has attracted increasing interest from areas such as artificial intelligence, geographical information science, and image retrieval. Given a network of CDC constraints, the consistency problem is deciding if the network is realizable by connected regions in the real plane. This paper provides a cubic algorithm for checking the consistency of complete networks of basic CDC constraints, and proves that reasoning with the CDC is in general an NP-complete problem. For a consistent complete network of basic CDC constraints, our algorithm returns a ‘canonical’ solution in cubic time. This cubic algorithm is also adapted to check the consistency of complete networks of basic cardinal constraints between possibly disconnected regions.","Qualitative spatial reasoning, Cardinal direction calculus, Connected regions, Consistency checking, Maximal canonical solution",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Danos V,Ehrhard T",,Probabilistic coherence spaces as a model of higher-order probabilistic computation,Information and Computation,2011,209,6,966-991,,,,,2011,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540111000411;http://dx.doi.org/10.1016/j.ic.2011.02.001,10.1016/j.ic.2011.02.001,"We study a probabilistic version of coherence spaces and show that these objects provide a model of linear logic. We build a model of the pure lambda-calculus in this setting and show how to interpret a probabilistic version of the functional language PCF. We give a probabilistic interpretation of the semantics of probabilistic PCF closed terms of ground type. Last we suggest a generalization of this approach, using Banach spaces.","Linear logic, Lambda-calculus, PCF, Denotational semantics, Probabilistic models",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Damm W,Westphal B",,Live and let die: LSC based verification of UML models,Science of Computer Programming,2005,55,1,117-159,,,,,2005,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642304001480;http://dx.doi.org/10.1016/j.scico.2004.05.013,10.1016/j.scico.2004.05.013,"This paper addresses the problem of formal verification of UML models in the semantics of Damm and Josko et al. (Science of Computer Programming, this issue). The problem is twofold in that it requires on the one hand a specification language which is rich enough to express properties about entities that are only created during a run of the system and on the other hand a means to abstract the a priori unbounded state space to a finite one which lends itself to treatment by approved finite state methods. As the specification language, the paper proposes to extend Live Sequence Charts as presented by W. Damm and D. Harel [LSCs: breathing life into message sequence charts, Formal Methods in System Design 19 (1) (2001) 121–141] and J. Klose [Live sequence charts: A graphical formalism for the specification of communication behavior, Ph.D. Thesis, Carl von Ossietzky Universität Oldenburg, 2003] by means of dynamically bound instance lines and equips it with a formal semantics w.r.t. the UML domain. For verification, the paper proposes to transfer to the UML domain the methodology of K.L. McMillan [A methodology for hardware verification using compositional model checking, Science of Computer Programming 37 (2000) 279–309], comprising a first step which is based on results of C.N. Ip and D.L. Dill [Better verification through symmetry, Formal Methods in System Design 9 (1–2) (1996) 41–75] about symmetric data-types and for which F. Xie and J.C. Browne [Integrated state space reduction for model checking executable object-oriented software system designs, in: R.-D. Kutsche, H. Weber (Eds.), FASE, Lecture Notes in Computer Science, vol. 2306, Springer, 2002] coined the term “Query Reduction” and, as second step, an abstract interpretation called “data-type reduction” to construct a finite state over-approximation of the original model for each query. The paper also briefly discusses counter-measures against false-negatives occurring in the over-approximation.",,Formal Methods for Components and Objects: Pragmatic aspects and applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bono V,Damiani F,Giannini P",,"A Calculus for “environment-aware” computation1 1Partially supported by IST-2001-33477 DART, and MURST Cofin'01 NAPOLI Project",Electronic Notes in Theoretical Computer Science,2002,66,3,98-115,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104804183;http://dx.doi.org/10.1016/S1571-0661(04)80418-3,10.1016/S1571-0661(04)80418-3,"We present a calculus for modelling “environment-aware” computations, that is computations that adapt their behaviour according to the capabilities of the environment. The calculus is an imperative, object-based language with extensible objects, equipped with a labelled transition semantics. A notion of bisimulation, lifting to computations a correspondence between the capabilities of different environments, is provided. Bisimulation can be used to prove that a program is “cross-environment”, i.e., it has the same behaviour when run in different environments.",,"F-WAN, Foundations of Wide Area Network Computing (ICALP 2002 Satellite Workshop)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Zou L,Zhang Z,Long J,Zhang H",,A fast incremental algorithm for deleting objects from a concept lattice,Knowledge-Based Systems,2015,89,,411-419,,,,,2015,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705115002762;http://dx.doi.org/10.1016/j.knosys.2015.07.022,10.1016/j.knosys.2015.07.022,"The formal context may not be fixed in a real-life application of formal concept analysis, which means that we have to update the present lattice or compute a new lattice from scratch. In this paper, we propose an efficient incremental algorithm, referred to as FastDeletion, to delete objects from a concept lattice. The algorithm improves two fundamental procedures shared by other algorithms. These two procedures include determining which concepts need to be deleted and fixing the covering relation. We describe the algorithm thoroughly, prove correctness of our improvements, discuss time complexity issues, and present an experimental evaluation of its performance and comparison with another algorithm. Empirical analyses demonstrate that our algorithm is superior when applied to various types of formal contexts.","Formal concept analysis, Concept lattice, Incremental algorithm, Formal context reduction",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Prieto AI,de Romero SS,Srivastava HM",,Some fractional-calculus results involving the generalized Lommel–Wright and related functions,Applied Mathematics Letters,2007,20,1,17-22,,,,,2007,,0893-9659,https://www.sciencedirect.com/science/article/pii/S0893965906000668;http://dx.doi.org/10.1016/j.aml.2006.02.018,10.1016/j.aml.2006.02.018,"In many recent works, several authors have demonstrated the usefulness of fractional-calculus operators in many different directions. The main object of this work is to present a number of key results for the generalized Lommel–Wright and related functions involving the Riemann–Liouville, the Weyl, and such other fractional-calculus operators as those based upon the Cauchy–Goursat Integral Formula. Various particular cases and consequences of our main fractional-calculus results are also considered.","Fractional calculus, Generalized Lommel–Wright function, Fox–Wright -function, Riemann–Liouville operator, Weyl operator, Cauchy–Goursat Integral Formula, Bessel function, and functions, Generalized hypergeometric function",,,,,,,,,,,,,,,,,,,,,
Journal Article,Diaconescu R,,Behavioural specification for hierarchical object composition,Theoretical Computer Science,2005,343,3,305-331,,,,,2005,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397505003646;http://dx.doi.org/10.1016/j.tcs.2005.06.015,10.1016/j.tcs.2005.06.015,Behavioural specification based on hidden (sorted) algebra constitutes one of the most promising recently developed formal specification and verification paradigms for system development. Here we formally introduce novel concepts of behavioural object and equivalence between behavioural objects within the hidden algebra framework. We formally define several object composition operators on behavioural objects corresponding to the hierarchical object composition methodology introduced by CafeOBJ. We study their basic semantical properties and show that our most general form of behavioural object composition with synchronisation has final semantics and a composability property of behavioural equivalence supporting a high reusability of verifications. We also show the commutativity and the associativity of parallel compositions without synchronisation.,"Algebraic specification, Behavioural specification, Hidden algebra, Object composition",Formal Methods for Components and Objects,,,,,,,,,,,,,,,,,,,,
Journal Article,"Atencia M,David J,Euzenat J,Napoli A,Vizzini J",,Link key candidate extraction with relational concept analysis,Discrete Applied Mathematics,2020,273,,2-20,,,,,2020,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X19300952;http://dx.doi.org/10.1016/j.dam.2019.02.012,10.1016/j.dam.2019.02.012,"Linked data aims at publishing data expressed in RDF (Resource Description Framework) at the scale of the worldwide web. These datasets interoperate by publishing links which identify individuals across heterogeneous datasets. Such links may be found by using a generalisation of keys in databases, called link keys, which apply across datasets. They specify the pairs of properties to compare for linking individuals belonging to different classes of the datasets. Here, we show how to recast the proposed link key extraction techniques for RDF datasets in the framework of formal concept analysis. We define a formal context, where objects are pairs of resources and attributes are pairs of properties, and show that formal concepts correspond to link key candidates. We extend this characterisation to the full RDF model including non functional properties and interdependent link keys. We show how to use relational concept analysis for dealing with cyclic dependencies across classes and hence link keys. Finally, we discuss an implementation of this framework.","Formal concept analysis, Relational concept analysis, Linked data, Link key, Data interlinking, Resource description framework",Advances in Formal Concept Analysis: Traces of CLA 2016,,,,,,,,,,,,,,,,,,,,
Book Chapter,Halpin T,Halpin T,1 - Introduction,,2001,,,1-24,,Academic Press,San Diego,Information Modeling and Relational Databases,2001,9781558606722,,https://www.sciencedirect.com/science/article/pii/B978155860672250004X;http://dx.doi.org/10.1016/B978-155860672-2/50004-X,10.1016/B978-155860672-2/50004-X,"Publisher Summary Database management systems (DBMSs) are widely used as a major productivity tool for businesses that are information oriented. For a database to be used effectively, its data should be correct, complete, and efficiently accessed. This requires that the database be well designed. This chapter provides the knowledge of conceptual modeling techniques and presents a brief historical and structural overview of information systems. Designing a database involves building a formal model of the application domain or universe of discourse. The object-role modeling simplifies the analysis and design process by using natural language, intuitive diagrams and examples, and by examining the information in terms of simple or elementary facts. In addition, this chapter summarizes how five generations of computing languages might be used to request a computer to list the name, mass, and moons of each planet, assuming the information is stored in an astronomical database. Hierarchic DBMSs such as IBM's Information Management System are very efficient at handling applications with a hierarchic structure.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,"Hufnagel S,Harbison K,Silva J,Mettala E",,Health care professional workstation: software system construction using DSSA scenario-based engineering process,International Journal of Bio-Medical Computing,1994,34,1,375-386,,,,,1994,,0020-7101,https://www.sciencedirect.com/science/article/pii/0020710194900388;http://dx.doi.org/10.1016/0020-7101(94)90038-8,10.1016/0020-7101(94)90038-8,"This paper describes a new method for the evolutionary determination of user requirements and system specifications called scenario-based engineering process (SEP). Health care professional workstations are critical components of large scale health care system architectures. We suggest that domain-specific software architectures (DSSAs) be used to specify standard interfaces and protocols for reusable software components throughout those architectures, including workstations. We encourage the use of engineering principles and abstraction mechanisms. Engineering principles are flexible guidelines, adaptable to particular situations. Abstraction mechanisms are simplifications for management of complexity. We recommend object-oriented design principles, graphical structural specifications, and formal components' behavioral specifications. We give an ambulatory care scenario and associated models to demonstrate SEP. The scenario uses health care terminology and gives patients' and health care providers' system views. Our goal is to have a threefold benefit. (i) Scenario view abstractions provide consistent interdisciplinary communications. (ii) Hierarchical object-oriented structures provide useful abstractions for reuse, understandability, and long term evolution. (iii) SEP and health care DSSA integration into computer aided software engineering (CASE) environments. These environments should support rapid construction and certification of individualized systems, from reuse libraries.","Scenario-based engineering process (SEP), Software engineering, Domain-specific software architectures (DSSA), Health care systems architecture, Workstations",The Health Care Professional Workstation,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cunha A,Visser J",,Transformation of structure-shy programs with application to XPath queries and strategic functions,Science of Computer Programming,2011,76,6,516-539,,,,,2011,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642310000146;http://dx.doi.org/10.1016/j.scico.2010.01.003,10.1016/j.scico.2010.01.003,"Various programming languages allow the construction of structure-shy programs. Such programs are defined generically for many different datatypes and only specify specific behavior for a few relevant subtypes. Typical examples are XML query languages that allow selection of subdocuments without exhaustively specifying intermediate element tags. Other examples are languages and libraries for polytypic or strategic functional programming and for adaptive object-oriented programming. In this paper, we present an algebraic approach to transformation of declarative structure-shy programs, in particular for strategic functions and XML queries. We formulate a rich set of algebraic laws, not just for transformation of structure-shy programs, but also for their conversion into structure-sensitive programs and vice versa. We show how subsets of these laws can be used to construct effective rewrite systems for specialization, generalization, and optimization of structure-shy programs. We present a type-safe encoding of these rewrite systems in Haskell which itself uses strategic functional programming techniques. We discuss the application of these rewrite systems for XPath query optimization and for query migration in the context of schema evolution.","Algebraic program transformation, Strategic functional programming, XML query languages, Point-free program calculation, Type specialization, Type generalization",Special issue on Partial Evaluation and Program Manipulation (selected paper of PEPM 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Hull R,Su J",,Algebraic and calculus query languages for recursively typed complex objects,Journal of Computer and System Sciences,1993,47,1,121-156,,,,,1993,,0022-0000,https://www.sciencedirect.com/science/article/pii/002200009390022O;http://dx.doi.org/10.1016/0022-0000(93)90022-O,10.1016/0022-0000(93)90022-O,"Algebraic and calculus database query languages for recursively typed complex objects based on the set and tuple constructs are studied. A fundamental characteristic of such complex objects is that, in them, sets may contain members with arbitrarily deep nesting of tuple and/or set constructs. Relative to mappings from flat relations to flat relations, the algebra without while has the expressive power of the algebra on conventional complex objects with non-recursive types. The algebra plus while has the power of the computable queries. The calculus has power equivalent to the arithmetical hierarchy and also to the calculus with countable invention for conventional complex objects. A technical tool, called “domain Turing machine,” is introduced and applied to characterize the expressive power of several classes of relational queries.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Guillemette LJ,Monnier S",,Type-Safe Code Transformations in Haskell,Electronic Notes in Theoretical Computer Science,2007,174,7,23-39,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107002514;http://dx.doi.org/10.1016/j.entcs.2006.10.036,10.1016/j.entcs.2006.10.036,"The use of typed intermediate languages can significantly increase the reliability of a compiler. By type-checking the code produced at each transformation stage, one can identify bugs in the compiler that would otherwise be much harder to find. We propose to take the use of types in compilation a step further by verifying that the transformation itself is type correct, in the sense that it is impossible that it produces an ill typed term given a well typed term as input. We base our approach on higher-order abstract syntax (HOAS), a representation of programs where variables in the object language are represented by meta-variables. We use a representation that accounts for the object language's type system using generalized algebraic data types (GADTs). In this way, the full binding and type structure of the object language is exposed to the host language's type system. In this setting we encode a type preservation property of a CPS conversion in Haskell's type system, using witnesses of a type correctness proof encoded in a GADT.","compilation, program verification, type systems, higher-order abstract syntax",Proceedings of the Programming Languages meets Program Verification (PLPV 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Wasser N,Heydari Tabar A,Hähnle R",,Automated model extraction: From non-deterministic C code to active objects,Science of Computer Programming,2021,204,,102597,,,,,2021,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642320302057;http://dx.doi.org/10.1016/j.scico.2020.102597,10.1016/j.scico.2020.102597,"The C programming language is well-known to have a large amount of underspecified behavior that often results in non-determinism even of sequential programs. In many application areas, not necessarily safety-critical ones, this is highly undesirable. A number of approaches and tools that statically analyze such behavior have been suggested, but they suffer from a high number of false positives and negatives. We present a novel model-based approach to analyzing non-determinism that works by automatic extraction of a faithful model of a given C program in a concurrent active object language. The extracted model renders any non-deterministic behavior of the C program in terms of explicit concurrency. This opens the door to global, semantic analyses. We give a fully formal account of the model extraction process and present an experimental evaluation of its implementation in the model extraction tool C2ABS.","Non-deterministic behavior, Model extraction, Model validation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ruhroth T,Wehrheim H",,Model evolution and refinement,Science of Computer Programming,2012,77,3,270-289,,,,,2012,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642311001298;http://dx.doi.org/10.1016/j.scico.2011.04.007,10.1016/j.scico.2011.04.007,"Software changes during its lifetime. Likewise, software models change during their design time, e.g. by removing, adding or changing operations and classes. This is referred to as model evolution. In a refinement-based approach to software design, we moreover do not deal with a single but with a chain of models (viz. formal specifications), related via refinement. Changes thus need to be consistently made to all specifications in the chain so as to keep the refinement structure. In this paper, we develop co-evolutions of models in the context of the formal method Object-Z. More specifically, given a particular evolution of a specification we show how to construct a corresponding evolution for its refinements such that the refinement relationship is kept. A chain of models can thus be systematically and consistently evolved, while maintaining the given refinement structure.","Evolution, Refinement, Formal methods, Object-Z, Refactoring",Feature-Oriented Software Development (FOSD 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Faitelson D,Welch J,Davies J",,From Predicates to Programs: The Semantics of a Method Language,Electronic Notes in Theoretical Computer Science,2007,184,,171-187,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107004410;http://dx.doi.org/10.1016/j.entcs.2007.03.021,10.1016/j.entcs.2007.03.021,"This paper explains how a declarative method language, based upon the formal notations of Z and B, can be used as a basis for automatic code generation. The language is used to describe the intended effect of operations, or methods, upon the components of an object model; each method is defined by a pair of predicates: a precondition, and a post-condition. Following the automatic incorporation of model invariants, including those arising from class associations, these predicates are extended—again, automatically—to address issues of consistency, definition, and dependency, before being translated into imperative programs. The result is a formal method for transforming object models into complete, working systems.","formal methods, declarative programming, object modelling, weakest preconditions",Proceedings of the Second Brazilian Symposium on Formal Methods (SBMF 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Aït-Kaci H,Podelski A,Goldstein SC",,Order-sorted feature theory unification,The Journal of Logic Programming,1997,30,2,99-124,,,,,1997,,0743-1066,https://www.sciencedirect.com/science/article/pii/S0743106696000532;http://dx.doi.org/10.1016/S0743-1066(96)00053-2,10.1016/S0743-1066(96)00053-2,"Order-sorted feature (OSF) terms provide an adequate representation for objects as flexible records. They are sorted, attributed, possibly nested structures, ordered thanks to a subsort ordering. Sorts definitions offer the functionality of classes imposing structural constraints on objects. These constraints involve variable sorting and equations among feature paths, including self-reference. Formally, sort definitions may be seen as axioms forming an OSF theory. OSF theory unification is the process of normalizing an OSF term taking into account sort definitions, enforcing structural constraints imposed by an OSF theory. It allows objects to inherit, and thus abide by, constraints from their classes. We propose a formal system that logically models record objects with (possibly recursive) class definitions accommodating multiple inheritance. We show that OSF theory unification is undecidable in general. However, we give a set of confluent normalization rules which is complete for detecting the inconsistency of an object with respect to an OSF theory. Furthermore, a subset consisting of all rules but one is confluent and terminating. This yields a practical complete normalization strategy, as well as an effective compilation scheme.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Muro PR,Villarroel JL,Silva M",,A Knowledge Representation Environment for Manufacturing Control Systems Design and Prototyping,IFAC Proceedings Volumes,1990,23,3,471-475,,,,,1990,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017526026;http://dx.doi.org/10.1016/S1474-6670(17)52602-6,10.1016/S1474-6670(17)52602-6,"This paper presents some key ideas of a project on a design environment for manufacturing systems control. It is based on a tool hierarchy which integrates different techniques. The kernel is a knowledge representation language, called KRON, which embeddes three methodologies: frame based representation techniques, object oriented programming and High Level Petri Nets (HLPN). MIKRON, a manufacturing oriented tool, is built on top of KRON. A single model built using MIKRON can be used at different levels of a control hierarchy (coordination, scheduling and planning). It offers the graphic and formal expresion capacity of HLPN, as a mean of systematizing, formalizing the interconnection, synchronization and causal relations, as well as the information flow produced by the activity execution. Facilitates the integration of AI techniques for solving scheduling and planning problems. In addition, this tool supports the model execution and simulation.","Flexible manufacturing, Artificial intelligence, Petri nets, Modeling, Software tool","6th IFAC/IFIP/IFORS/IMACS Symposium on Information Control Problems in Manufacturing Technology 1989, Madrid, Spain, 26-29 September",,,,,,,,,,,,,,,,,,,,
Journal Article,"Anderson C,Giannini P",,Type Checking for JavaScript,Electronic Notes in Theoretical Computer Science,2005,138,2,37-58,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105051340;http://dx.doi.org/10.1016/j.entcs.2005.09.010,10.1016/j.entcs.2005.09.010,"JavaScript is a powerful imperative object based language made popular by its use in web pages. It supports flexible program development by allowing dynamic addition of members to objects. Code is dynamically typed: a runtime access to a non-existing member causes an error. We suggest a static type system for JavaScript that will detect such type errors. Therefore, programmers can benefit from the flexible programming style offered by JavaScript and from the safety offered by a static type system. We demonstrate our type system with a formalism of JavaScript, JS0. Our types are structural. Members of an object type are classified into definite and potential. A potential member becomes definite upon assignment. We outline a proof that our type system is sound.","JavaScript, Scripting Languages, Structural Recursive Types, Type Checking",Proceedings of the Second Workshop on Object Oriented Developments (WOOD 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Barbuti R,Maggiolo-Schettini A,Milazzo P,Pardini G",,Spatial Calculus of Looping Sequences,Theoretical Computer Science,2011,412,43,5976-6001,,,,,2011,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397511000648;http://dx.doi.org/10.1016/j.tcs.2011.01.020,10.1016/j.tcs.2011.01.020,"This paper presents Spatial CLS, an extension of the Calculus of Looping Sequences (CLS) with spatial features. Spatial CLS allows keeping track of the position of biological elements in a continuous space (2D or 3D) as time passes. The movement of elements in the space can be precisely described, and elements can interact when constraints on their positions are satisfied such as, for example, if two elements are close enough. As for CLS, membranes and elements inside them can be directly modeled in the syntax. Spatial CLS allows describing the space occupied by elements and membranes. The space occupied by different objects is always kept disjoint. The validity of this constraint is ensured at all times by the semantics of the calculus. In order to model specific behaviors, the modeler can provide an algorithm to rearrange the position of objects in case of a space conflict. Being an extension of CLS, Spatial CLS provides a simple and powerful syntax, based on rewrite rules, for describing the possible reactions among elements of a system. Moreover, rewrite rules are endowed with a stochastic reaction rate parameter. The aim of Spatial CLS is to enable a more accurate description of those biological processes whose behavior depends on the exact position of the elements. As example applications of the calculus, we present a model of cell proliferation, and a model of the quorum sensing process in Pseudomonas aeruginosa.","Calculus of Looping Sequences, Spatial modeling, Systems biology",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hick JM,Hainaut JL",,Database application evolution: A transformational approach,Data & Knowledge Engineering,2006,59,3,534-558,,,,,2006,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X05001631;http://dx.doi.org/10.1016/j.datak.2005.10.003,10.1016/j.datak.2005.10.003,"While recent data management technologies, such as object oriented techniques, address the problem of database schema evolution, standard information systems currently in use raise challenging evolution problems. This paper examines database evolution from the developer point of view. It shows how requirements changes are propagated to database schemas, to data and to programs through a general strategy. This strategy requires the documentation of database design. When absent, such documentation has to be rebuilt through reverse engineering techniques. Our approach, called DB-MAIN, relies on a generic database model and on transformational paradigm that states that database engineering processes can be modeled by schema transformations. Indeed, a transformation provides both structural and instance mappings that formally define how to modify database structures and contents. We describe both the complete and a simplified approaches, and compare their merits and drawbacks. We then analyze the problem of program modification and describe a CASE tool that can assist developers in their task of system evolution. We illustrate our approach with Biomaze, a biochemical knowledge-based the database of which is rapidly evolving.","Evolution, Database conversion, Schema transformation, History, Reverse engineering, CASE tools",Including: ER 2003,,,,,,,,,,,,,,,,,,,,
Journal Article,"Einarsson ÁM,Hertzum M",,How is learning scaffolded in library makerspaces?,International Journal of Child-Computer Interaction,2020,26,,100199,,,,,2020,,2212-8689,https://www.sciencedirect.com/science/article/pii/S2212868920300271;http://dx.doi.org/10.1016/j.ijcci.2020.100199,10.1016/j.ijcci.2020.100199,"Libraries have adopted makerspaces to promote a maker mindset and skills in using technology. In this paper, we examine how learning is scaffolded in library makerspaces. Based on interviews in fourteen Danish library makerspaces, we identify seven scaffolding approaches across formal, non-formal, and informal learning activities. The scaffolding approaches include topic-driven activities for schools, object-driven events for children and their parents, and community-driven activities, which are mostly attended by adults. We find that in spite of their focus on learning, the makerspaces provide limited scaffolds for skill progression. In addition, the scaffolds must span multiple skills but tend to focus more on the users’ skills in using the available tools than on their skills in defining meaningful projects. A final challenge faced by the makerspaces is that to scaffold community-driven activities, the makerspaces must accept that it is a continual effort to balance community claims to the space against openness to newcomers.","Makerspaces, Scaffolding, Learning, Libraries",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bertolissi C,Baldan P,Cirstea H,Kirchner C",,A Rewriting Calculus for Cyclic Higher-order Term Graphs,Electronic Notes in Theoretical Computer Science,2005,127,5,21-41,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105050127;http://dx.doi.org/10.1016/j.entcs.2005.01.034,10.1016/j.entcs.2005.01.034,"Introduced at the end of the nineties, the Rewriting Calculus (ρ-calculus, for short) is a simple calculus that fully integrates term-rewriting and λ-calculus. The rewrite rules, acting as elaborated abstractions, their application and the obtained structured results are first class objects of the calculus. The evaluation mechanism, generalizing beta-reduction, strongly relies on term matching in various theories. In this paper we propose an extension of the ρ-calculus, handling graph like structures rather than simple terms. The transformations are performed by explicit application of rewrite rules as first class entities. The possibility of expressing sharing and cycles allows one to represent and compute over regular infinite entities. The calculus over terms is naturally generalized by using unification constraints in addition to the standard ρ-calculus matching constraints. This therefore provides us with the basics for a natural extension of an explicit substitution calculus to term graphs. Several examples illustrating the introduced concepts are given.","rewriting calculus, cyclic lambda calculus, term graphs, matching and unification constraints",Proceedings of the 2nd International Workshop on Term Graph Rewriting (TERMGRAPH 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,van den Berg B,,Univalent polymorphism,Annals of Pure and Applied Logic,2020,171,6,102793,,,,,2020,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007220300178;http://dx.doi.org/10.1016/j.apal.2020.102793,10.1016/j.apal.2020.102793,"We show that Martin Hyland's effective topos can be exhibited as the homotopy category of a path category EFF. Path categories are categories of fibrant objects in the sense of Brown satisfying two additional properties and as such provide a context in which one can interpret many notions from homotopy theory and Homotopy Type Theory. Within the path category EFF one can identify a class of discrete fibrations which is closed under push forward along arbitrary fibrations (in other words, this class is polymorphic or closed under impredicative quantification) and satisfies propositional resizing. This class does not have a univalent representation, but if one restricts to those discrete fibrations whose fibres are propositions in the sense of Homotopy Type Theory, then it does. This means that, modulo the usual coherence problems, it can be seen as a model of the Calculus of Constructions with a univalent type of propositions. We will also build a more complicated path category in which the class of discrete fibrations whose fibres are sets in the sense of Homotopy Type Theory has a univalent representation, which means that this will be a model of the Calculus of Constructions with a univalent type of sets.","Impredicative type theory, Realizability, Homotopy type theory, Categorical semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kobayashi I,,Tuple calculus: Formal definition and conversion from first-order calculus,Information Systems,1987,12,4,343-352,,,,,1987,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437987900251;http://dx.doi.org/10.1016/0306-4379(87)90025-1,10.1016/0306-4379(87)90025-1,"In classical database theory, relational calculus has long been used in expressing query formulae and integrity constraints. In fact, relational calculus formulae are much easier to deal with than first-order formulae when evaluating queries and validating database updates in the database environment. In deductive databases, however, first-order calculus is preferred because it is convenient when proof procedures are involved. Since both situations should coexist in advanced information systems, it is very desirable to devise a conversion procedure between relational calculus and first-order calculus. In this paper, interpretation of first-order formulae in the database environment is discussed first, then tuple calculus, an extension of relational calculus, is presented. This extension enables us to describe query formulae and general rules necessary in advanced information systems, in particular, dealing with complex objects. Finally, a conversion algorithm from first-order formulae into tuple calculus formulae is presented. Several application issues are also included.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bouleau N,,Differential calculus for Dirichlet forms: The measure-valued gradient preserved by image,Journal of Functional Analysis,2005,225,1,63-73,,,,,2005,,0022-1236,https://www.sciencedirect.com/science/article/pii/S0022123605000972;http://dx.doi.org/10.1016/j.jfa.2005.02.010,10.1016/j.jfa.2005.02.010,"In order to develop a differential calculus for error propagation of Bouleau [Error Calculus for Finance and Physics, the Language of Dirichlet forms, De Gruyter, Berlin, 2003], we study local Dirichlet forms on probability spaces with carré du champ Γ—i.e. error structures—and we are looking for an object related to Γ which is linear and with a good behaviour by images. For this we introduce a new notion called the measure-valued gradient which is a randomized square root of Γ. The exposition begins with inspecting some natural notions candidate to solve the problem before proposing the measure-valued gradient and proving its satisfactory properties.","Dirichlet form, Gradient, Differential calculus, Error calculus, Gaussian measure",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Steggles LJ,Kosiuczenko P",,A Timed Rewriting Logic Semantics for SDL: A Case Study of the Alternating Bit Protocol,Electronic Notes in Theoretical Computer Science,1998,15,,83-104,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610582554X;http://dx.doi.org/10.1016/S1571-0661(05)82554-X,10.1016/S1571-0661(05)82554-X,"SDL is an industrial standard formal description technique for telecommunication systems. Despite its wide spread use and industrial importance it lacks at present an adequate formal semantics integrating its static, dynamic, and real-time aspects. Timed Rewriting Logic (TRL) is a new variant of Rewriting Logic, an algebraic formalism which allows the dynamic behaviour of systems to be axiomatised using rewrite rules. In TRL rewrite rules can be labelled with time constraints and this provides a means of reasoning about time elapse in real-time systems. TRL has been used to develop an object-oriented specification language Timed Maude for distributed real-time systems. In this paper we demonstrate the expressive power and versatility of Timed Maude by applying it to the definition of a formal semantics for SDL. The semantics we develop captures in an intuitive way the hierarchical structure of SDL specifications and integrates within one formalism the static and dynamic aspects of an SDL system. We demonstrate and motivate the semantics we develop by considering in detail a case study of the bench mark alternating bit protocol. It is a pleasure to thank U. Hinkel, K. Meinke and M. Wirsing for their helpful comments and advice during the preparation of this paper. We also gratefully acknowledge the financial support of the British Council and DAAD which has made this collaborative work possible.",,International Workshop on Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,Broy M,,A semantic and methodological essence of message sequence charts,Science of Computer Programming,2005,54,2,213-256,,,,,2005,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642304000802;http://dx.doi.org/10.1016/j.scico.2004.04.003,10.1016/j.scico.2004.04.003,"Message sequence charts (MSCs) are a technique to describe patterns of interaction between the components of interactive distributed systems by specific interaction diagrams. MSCs have evolved in telecommunication applications, defined as a standard, and have become very popular in the design of software architectures and, generally, of distributed or object-oriented software systems. They are used frequently to describe scenarios of interactions illustrating instances of use cases. Nevertheless, both the semantics of MSCs as a technique of specification and their methodological and technical role in the development process have not been precisely and sufficiently clarified, so far. Also their formalization, although tackled by a number of papers, is not well focused with respect to their methodological usage. In this paper, we suggest a semantic model for MSCs in terms of logical propositions characterizing stream-processing functions. This formalization allows us to apply MSCs as an intuitively clear specification technique with a precisely defined meaning. The MSCs provide, in particular, specifications for the components of a system. Our approach is in contrast to other semantic models for MSCs suggested in the literature (see Ladkin, Leue, in: R.L. Tenney et al. (Eds.), Formal Description Techniques VI, North-Holland, 1994, pp. 301–316, and Formal Aspects of Computing 7 (1995) 473–509) where the meaning of MSCs is explained using state transition machines or traces. We define the meaning of MSCs in a more abstract way by a logical technique specifying the components of a system. By this approach MSCs are used for the decomposition of systems into components. Along these lines, we discuss the systematic application of MSCs in the software development process.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Rudolph E,Grabowski J,Graubmann P","Dssouli R,v. Bochmann G,Lahav Y",Towards a Harmonization of UML-Sequence Diagrams and MSC,,1999,,,193-208,,Elsevier Science B.V.,Amsterdam,SDL '99,1999,9780444502285,,https://www.sciencedirect.com/science/article/pii/B978044450228550014X;http://dx.doi.org/10.1016/B978-044450228-5/50014-X,10.1016/B978-044450228-5/50014-X,"Sequence Diagrams as part of UML play an important role within use case driven object oriented (OO) software engineering. They can be seen as OO variants of the ITU-T standard language Message Sequence Chart (MSC) which is very popular mainly in the telecommunication area. Both notations would benefit from a harmonization. A more formal and powerful notation for Sequence Diagrams may arise, on the one hand. On the other hand, the application area of MSC might be considerably enlarged. In this context, it has to be noted that the acceptance of a language in the OO community essentially depends on a clear visualization of constructs typical for OO modelling. It is argued that Sequence Diagrams can be transformed into MSC diagrams if some enhancements of MSC are introduced. Such a transformation demonstrates the big advantage of MSC concerning composition mechanisms, particularly, in comparison with the rather obscuring branching constructs in Sequence Diagrams. At the same time, such a transformation may be used for a formalization of Sequence Diagrams in UML since MSC has a formal semantics based on process algebra.","MSC, UML, OO, software engineering, distributed systems, real time systems, telecommunication",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferrein A,Lakemeyer G",,Logic-based robot control in highly dynamic domains,Robotics and Autonomous Systems,2008,56,11,980-991,,,,,2008,,0921-8890,https://www.sciencedirect.com/science/article/pii/S0921889008001176;http://dx.doi.org/10.1016/j.robot.2008.08.010,10.1016/j.robot.2008.08.010,"In this paper, we present the robot programming and planning language Readylog, a Golog dialect, which was developed to support the decision making of robots acting in dynamic real-time domains, such as robotic soccer. The formal framework of Readylog, which is based on the situation calculus, features imperative control structures such as loops and procedures, allows for decision-theoretic planning, and accounts for a continuously changing world. We developed high-level controllers in Readylog for our soccer robots in RoboCup’s Middle-size league, but also for service robots and for autonomous agents in interactive computer games. For a successful deployment of Readylog on a real robot it is also important to account for the control problem as a whole, integrating the low-level control of the robot (such as localization, navigation, and object recognition) with the logic-based high-level control. In doing so, our approach can be seen as a step towards bridging the gap between the fields of robotics and knowledge representation.","Reasoning about actions, Planning, Cognitive robotics, RoboCup",Semantic Knowledge in Robotics,,,,,,,,,,,,,,,,,,,,
Journal Article,Sacerdoti Coen C,,Reduction and Conversion Strategies for the Calculus of (co)Inductive Constructions: Part I,Electronic Notes in Theoretical Computer Science,2007,174,10,97-118,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610700401X;http://dx.doi.org/10.1016/j.entcs.2007.02.050,10.1016/j.entcs.2007.02.050,We compare several reduction and conversion strategies for the Calculus of (co)Inductive Constructions by running benchmarks from the library of the Coq proof assistant. All the strategies have been implemented in an independent verifier for the proof objects of Coq that is part of the Matita proof assistant.,"reduction strategy, conversion, calculus of inductive construction, abstract machine",Proceedings of the Sixth International Workshop on Reduction Strategies in Rewriting and Programming (WRS 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"René SS,Graciela FD,Anel ZL",,"Modelo formal para la reestructura de marcos orientados a objetos hacia arquitecturas modelo-vista-adaptador**Citación estilo Chicago Santaolaya-Salgado, René, Olivia Graciela Fragoso-Díaz, Sheydi Anel Zamudio-López. Modelo formal para la reestructura de marcos orientados a objetos hacia arquitecturas modelo-vista-adaptador. Ingeniería Investigación y Tecnología, XV, 02 (2014): 187–198.Citación estilo ISO 690 Santaolaya-Salgado R., Fragoso-Díaz O.G., Zamudio-López S.A. Modelo formal para la reestructura de marcos orientados a objetos hacia arquitecturas modelo-vista-adaptador. Ingeniería Investigación y Tecnología, volumen XV (número 2), abril-junio 2014: 187–198","Ingeniería, Investigación y Tecnología",2014,15,2,187-198,,,,,2014,,1405-7743,https://www.sciencedirect.com/science/article/pii/S1405774314722097;http://dx.doi.org/10.1016/S1405-7743(14)72209-7,10.1016/S1405-7743(14)72209-7,"Resumen La reestructura de código legado puede realizarse con fines diferentes, entre los que se encuentran la migración hacia nuevas tecnologías que faciliten el mantenimiento y la reutilización del código. Los marcos orientados a objetos (frameworks) cuentan con características que, de cierta manera, limitan el reuso de su código. En este trabajo se propone un modelo formal que describe un proceso de reestructura de código legado de marcos orientados a objetos (MOO) hacia código conforme a la arquitectura modelo-vista-adaptador (MVA). Este proceso se lleva a cabo aplicando 11 métodos de reestructura, con el objetivo de separar el código de la lógica del negocio (el modelo), la cual es la parte más reusable del marco, del código que implementa la vista y del código que controla el procesamiento específico de la aplicación. Como resultado, el código legado del marco queda preparado para una migración posterior hacia servicios web. The restructuring of legacy code can be done for different purposes, among which is the migration to new technologies that facilitate the maintenance and code reuse. The frameworks have features that, in some way, limit the reuse of your code. In this paper, we propose a formal model that describes a process of restructuring legacy code object-oriented frameworks (MOO) to code according to the architecture Model-View-Adapter (MVA). This process is carried out using 11 methods of restructuring, with the aim of separating the code from business logic (the model), which is the most reusable framework, the code that implements the view and the code that handles specific processing of the application. As a result, the legacy code of the framework is ready for a subsequent migration to Web services.","marcos orientados a objetos, reuso de , reingeniería de , patrón MVA, modelo formal, Teoría de Modelos, frameworks, software reuse, software reeingeniering, MVA pattern, formal model, Model theory",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Berman JJ,Berman JJ,5 - Classifications and Ontologies,,2018,,,97-135,Second Edition,Academic Press,,Principles and Practice of Big Data (Second Edition),2018,9780128156094,,https://www.sciencedirect.com/science/article/pii/B9780128156094000054;http://dx.doi.org/10.1016/B978-0-12-815609-4.00005-4,10.1016/B978-0-12-815609-4.00005-4,"Information has limited value unless it can take its place within our general understanding of the world. “How does this thing relate to that thing?” is often the central question of scientific efforts. Ontologies are formal systems that relate different information objects into classes and relate classes of information objects to other classes, often as a hierarchical lineage (i.e., classes that have superclasses and subclasses). Scientific analyses of large information resources can be greatly enhanced if every data object in the resource is positioned somewhere within a formal ontology. Using ontologies, scientists can determine whether observations on a single object will apply to other objects in the same class. Similarly, scientists can begin to ask whether observations that hold true for a class of objects will relate to other classes of objects. Basically, ontologies help scientists complete one of their most important tasks; determining how things relate to each other. This chapter will describe how ontologies are constructed, and how they are used for scientific discovery in Big Data resources.","Ontology, Classification, Class, Subclass, Superclass, Class hierarchy, Ontologic competence, Instances, Class object",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kull A,,An Operational Specification Model for Process Control Software,IFAC Proceedings Volumes,1990,23,"8, Part 4",299-302,,,,,1990,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017518406;http://dx.doi.org/10.1016/S1474-6670(17)51840-6,10.1016/S1474-6670(17)51840-6,Operational approach to the process control software (PCS) development consists of two phases - specification phase and transformation phase. This paper concentrates on the specification phase. A formal model - Discrete Event Operational Specification Model (DEOSM) is proposed to represent PCS and its environment as discrete-event dynamic systems. DEOSM consists of concurrent processes connected by unidirectional channels. The representation of processes is close to the object oriented approach that gives us a model closely matching the reality. DEOSM is a good starting point to build around it a CASE tool for PCS development.,"Process control, software development, process models, real time computer systems, parallel processing, discrete-event dynamic systems","11th IFAC World Congress on Automatic Control, Tallinn, 1990 - Volume 4, Tallinn, Finland",,,,,,,,,,,,,,,,,,,,
Journal Article,"Hao F,Pei Z,Yang LT",,Diversified top-k maximal clique detection in Social Internet of Things,Future Generation Computer Systems,2020,107,,408-417,,,,,2020,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X19302195;http://dx.doi.org/10.1016/j.future.2020.02.023,10.1016/j.future.2020.02.023,"Social Internet of Things (SIoT), an IoT where things are autonomously capable of establishing relationships with other smart objects related to humans, allows them to interact within a social structure based on relationships. Importantly, exploiting the social structures of smart objects in SIoT is important for supervision and management of various services. Diversified top-k maximal clique, as a novel social structure, can be used for anomaly detection, and smart community detection from SIoT. However, the scalability of the existing approaches for detecting diversified top-k maximal cliques is becoming a significant challenge faced in the big graph. To this end, this paper proposes a novel diversified top-k maximal clique detection approach based on formal concept analysis. Specifically, we firstly prove the existence of equivalence relation between maximal cliques and equiconcepts which are a class of special concepts where the extent and intent are the same. Based on this equivalence relation, an efficient and innovative approach based on formal concept analysis for identifying diversified top-k maximal cliques is then further presented. Finally, three real-world social network datasets are adopted in experiments for the validation of effectiveness of our approach in SIoT.","SIoT, Maximal clique, Diversified top- maximal clique, Formal concept analysis, Coverage of clique",,,,,,,,,,,,,,,,,,,,,
Journal Article,Gutknecht J,,Active Oberon for .NET: An Exercise in Object Model Mapping,Electronic Notes in Theoretical Computer Science,2001,59,1,123-141,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105804578;http://dx.doi.org/10.1016/S1571-0661(05)80457-8,10.1016/S1571-0661(05)80457-8,"Active Oberon is a substantial evolution of the programming language Oberon. It distinguishes itself by a novel object model and by its integration into the .NET language interoperability framework. The three concepts characterizing Active Oberon are: (a) active object types, (b) a single and unifying notion of abstraction called definition, and (c) a static module construct. These concepts are in fact powerful combinations of concepts: Active objects integrate active behavior with reactive message handling, definitions unify the units of usage, implementation and inheritance, and modules represent both package and static object. The rigid concept of class hierarchy has been sacrificed in Active Oberon to a more flexible concept of aggregation that is based on a generalized IMPLEMENTS relation. The relations IMPORTS and REFINES are used to specify static module dependencies and to derive new definitions from existing ones respectively. This article is a report on a work in progress. We divide our presentation into three parts: (a) A short recall of the history of programming languages developed at the ETH, (b) an extensive conceptual overview of Active Oberon's object model called the Active Object System (AOS), (c) a discussion of the mapping of the AOS into the Common Type System (CTS) exposed by .NET.",,"BABEL'01, First International Workshop on Multi-Language Infrastructure and Interoperability (Satellite Event of PLI 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Kakko R,Länsipuro H,Kujansuu E,Lancia A,Gambirasio A,Ziomas IC,Melas D,Foster PM",,CRAMD—A database for the validation of models used in chemical risk assessment,Journal of Loss Prevention in the Process Industries,1996,9,6,401-411,,,,,1996,,0950-4230,https://www.sciencedirect.com/science/article/pii/S0950423096000319;http://dx.doi.org/10.1016/S0950-4230(96)00031-9,10.1016/S0950-4230(96)00031-9,"This paper summarizes the work carried out in the project ‘DATABASE—a database for validation of models used in chemical risk assessment’ (the DATABASE project). The project was initiated in April 1993 and completed in March 1996. The participants in the project were:•TRI Tecsa Research and Innovation (Italy, formal co-ordinator);•VTT (Finland, scientific co-ordinator);•UMIST University of Manchester, Simon Environmental Technology Centre (UK). The scientist principally responsible for UMIST's contribution was Paul Foster from PMF Assessments (UK);•AUTH LAP Aristotelian University of Thessaloniki, Laboratory of Atmospheric Physics (Greece). The objective of the project was to design and construct a database of experimental data for model validation and development applications. The experimental data were to cover source term and dispersion behaviour over flat and complex terrain and were to be collected from CEC funded research projects and other suitable sources of experimental data. The main results of the project are:•A prototype database containing specially chosen data handling and processing facilities for model validation and development applications has been constructed. The database has been named CRAMD—Chemical Risk Assessment Modelling Database.•The number of data sets which could be incorporated into the database were limited by project resource constraints. Representative examples containing different data formats and experimental measurement techniques were therefore selected in order to demonstrate the data handling and processing capabilities of the CRAMD prototype.•Key design requirements were that the database should be readily accessible and easily extended to cope with new data formats and modelling applications. These were achieved by basing CRAMD on an object-oriented software platform with user access via the Windows-based World Wide Web (WWW) internet connection.•Difficulties were experienced with data collection which exemplify the need for a central EC archiving facility in this work area. Examples were found of data being discarded, lost or poorly documented. There was also a poor response to formal requests to supply data for the database. It is suggested that future CEC funding for experimental and model validation investigations should be conditional on all measurement results which are used or acquired during the work be returned to the CEC in a fully documented, computer readable format for archiving. Clearly, CRAMD could provide a suitable receptacle for such data.","CRAMD, database, OODB (Object Oriented Database), safety engineering, risk, dispersion",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bernardo M,Bontà E,Aldini A",,"Handling communications in process algebraic architectural description languages: Modeling, verification, and implementation",Journal of Systems and Software,2010,83,8,1404-1429,,,,,2010,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412121000052X;http://dx.doi.org/10.1016/j.jss.2010.02.025,10.1016/j.jss.2010.02.025,"Architectural description languages are a useful tool for modeling complex software systems at a high level of abstraction. If based on formal methods, they can also serve for enabling the early verification of various properties such as component coordination and for guiding the synthesis of code correct by construction. This is the case with process algebraic architectural description languages, which are process calculi enhanced with the main architectural concepts. However, the techniques with which those languages have been equipped are mainly conceived to work with synchronous communications only. The objective of this paper is threefold. On the modeling side, we show how to enhance the expressiveness of a typical process algebraic architectural description language by including the capability of representing nonsynchronous communications in such a way that the usability of the original language is preserved. On the verification side, we show how to modify techniques for analyzing the absence of coordination mismatches like the compatibility check for acyclic topologies and the interoperability check for cyclic topologies in such a way that those checks are valid also for nonsynchronous communications. On the implementation side, we show how to generate multithreaded object-oriented software in the presence of synchronous and nonsynchronous communications in such a way that the properties proved at the architectural level are preserved at the code level.","Software architecture, Architectural description languages, Process algebra, Synchronous and nonsynchronous communications, System modeling and verification, Code generation",Performance Evaluation and Optimization of Ubiquitous Computing and Networked Systems,,,,,,,,,,,,,,,,,,,,
Book Chapter,Bench-Capon TJ,Bench-Capon TJ,10 - Some Issues in Knowledge Representation,,1990,,,171-210,,Academic Press,London,Knowledge Representation,1990,9780120864409,,https://www.sciencedirect.com/science/article/pii/B9780120864409500142;http://dx.doi.org/10.1016/B978-0-12-086440-9.50014-2,10.1016/B978-0-12-086440-9.50014-2,"Publisher Summary This chapter discusses some points of similarity between the various paradigms, namely production rules, structured representations as exemplified by frame systems incorporating an inheritance mechanism, and first-order predicate calculus, and reviews a number of areas where the expressive power of these representations seems to be inadequate, and extensions that have been proposed to address the resultant problems. Although the representations have very different surface forms, the entity-attribute-value triples found in production systems, the instance-slot-filler notation of the frame system, and relations with two parameters found in predicate logic, all express precisely the same information, namely that a binary relation holds between two objects in the domain. Predications are, as has always been recognized by formal logic, the typical form of an assertion of a fact about the world, and much knowledge consists of such predications. Therefore, taken as means of describing facts by making predications, the three paradigms are essentially equivalent in expressive power.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Ghelli G,,Divergence of F⩽ type checking,Theoretical Computer Science,1995,139,1,131-162,,,,,1995,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759400037J;http://dx.doi.org/10.1016/0304-3975(94)00037-J,10.1016/0304-3975(94)00037-J,"System F⩽ is an extension of second-order typed lambda calculus, where a subtype hierarchy among types is defined, and bounded second-order lambda abstraction is allowed. This language is a basis for much of the current research on integration of typed functional languages with subtypes and inheritance. An algorithm to perform type checking for F⩽ expressions has been known since the language Fun was defined. The algorithm has been proved complete, by the author and Curien, which means that it is a semi-decision procedure for the type-checking problem. In this paper we show that this algorithm is not a decision procedure, by exhibiting a term which makes it diverge. This result was the basis of Pierce's proof of undecidability of typing for F⩽. We study the behavior of the algorithm to show that our diverging judgement is in some sense contained in any judgement which makes the algorithm diverge. On the basis of this result, and of other results in the paper, we claim that the chances that the algorithm will loop while type-checking a “real program” are negligible. Hence, the undecidability of F⩽ type-checking should not be considered as a reason to prevent the adoption of F⩽ as a basis for defining programming languages of practical interest. Finally, we show the undecidability of an important subsystem of F⩽.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Giraudo S,,"Colored operads, series on colored operads, and combinatorial generating systems",Discrete Mathematics,2019,342,6,1624-1657,,,,,2019,,0012-365X,https://www.sciencedirect.com/science/article/pii/S0012365X19300652;http://dx.doi.org/10.1016/j.disc.2019.02.008,10.1016/j.disc.2019.02.008,"We introduce bud generating systems, which are used for combinatorial generation. They specify sets of various kinds of combinatorial objects, called languages. They can emulate context-free grammars, regular tree grammars, and synchronous grammars, allowing us to work with all these generating systems in a unified way. The theory of bud generating systems uses colored operads. Indeed, an object is generated by a bud generating system if it satisfies a certain equation in a colored operad. To compute the generating series of the languages of bud generating systems, we introduce formal power series on colored operads and several operations on these. Series on colored operads are crucial to express the languages specified by bud generating systems and allow us to enumerate combinatorial objects with respect to some statistics. Some examples of bud generating systems are constructed; in particular to specify some sorts of balanced trees and to obtain recursive formulas enumerating these.","Tree, Formal power series, Combinatorial generation, Grammar, Colored operad",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Gibson P,Méry D","Cavalli A,Sarma A",- Telephone Feature Verification: Translating SDL to TLA +,,1997,,,103-118,,Elsevier Science B.V.,Amsterdam,SDL '97: Time for Testing,1997,9780444828163,,https://www.sciencedirect.com/science/article/pii/B9780444828163500083;http://dx.doi.org/10.1016/B978-044482816-3/50008-3,10.1016/B978-044482816-3/50008-3,"Publisher Summary This chapter reports on the research that arose in response to the need for more formal means of verifying telecom feature systems. The strategy is based on combining object-oriented and temporal logic models in a coherent and complementary manner. This provides a compositional approach to verify systems of interacting telephone features. Specification Description Language (SDL) is commonly used in the early stages of software development. It provides mechanisms for the specification of data structure, data flow, control flow, encapsulation, information hiding, and abstract dependencies, through its support for concurrent objects. The chapter provides a mechanism for translating SDL into a temporal logic of actions (TLA+) specification to provide a proof-theoretical framework. The preservation of properties through the translation is examined within the framework of simple state-sequence semantics. The chapter identifies the strengths and weaknesses of such an approach, and introduces the translation that binds the two different semantics together. The chapter applies translation in the verification of two telephone features and their interaction.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Silva Muñoz L,Grüninger M",,A time-indexed mereology for SUMO,Data & Knowledge Engineering,2019,123,,101724,,,,,2019,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X17303749;http://dx.doi.org/10.1016/j.datak.2019.101724,10.1016/j.datak.2019.101724,"While the period of time during which a subprocess occurs is precisely the time during which the part-whole relation with its main process takes place, part-whole relations between objects do not obey such a rule. The parts of an object can exist before the object is conformed as such, and can survive its dismantlement. In fact, there are no means for knowing when, during the existence of the part and the whole, their parthood relation holds unless an explicit account of time is represented. A time-indexed mereology characterizes how objects gain and lose parts over time by associating a time index to their part-whole relations. Keeping an account of when objects lose or gain parts is necessary for the correct representation of their spatial location and their participation in processes. Upper-level ontologies characterize the properties of the most basic, domain-independent entities, such as time, space, objects and processes. Two upper-level ontologies broadly used are The Descriptive Ontology for Linguistic and Cognitive Engineering (DOLCE) and The Suggested Upper Merged Ontology (SUMO). However, while DOLCE provides a first-order time-indexed mereology for structuring its entities over time, SUMO provides a weaker axiomatization that does not represent the rules that determine how the mereological structure of objects evolve through time in the real world. This work proposes a first-order logic time-indexed mereology for SUMO based on its current representation of objects, time, and temporal location, thereby characterizing how objects gain and lose parts over time. The proposed theory sets the stage for the development of a time-indexed theory of spatial location, and for the representation of temporal restrictions on the participation of objects in processes. The time-indexed mereology of DOLCE and the proposed theory are formally compared, and their relative strength established by using ontology mapping. In order to achieve such a comparison, the representations of time, and temporal location of both upper-level ontologies are also formally compared.","Mereology, Time-indexed mereology, Temporary mereology, Ontology, Upper-level ontology, Foundational ontology, SUMO, DOLCE, Ontology mapping, Change, Mereological change",,,,,,,,,,,,,,,,,,,,,
Journal Article,Hallnäs L,,Partial inductive definitions,Theoretical Computer Science,1991,87,1,115-142,,,,,1991,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397506800071;http://dx.doi.org/10.1016/S0304-3975(06)80007-1,10.1016/S0304-3975(06)80007-1,"An attempt to consider partial definitions of semantically oriented data types will be described. We will in a certain sense think of such data types as inductively defined. A class of inductive definitions will be interpreted as partial definitions: partial inductive definitions. The presentation of such a definition is in itself elementary and the true complexity of the definition will show itself in questions concerning the isolation of totally defined objects. It is the same situation as in the case of partial recursive functions. The basic aim is to investigate the possibility to give direct inductive definitions of semantical notions exploring, so to speak, the structure of the given notion rather than to think of such notions as indirectly presented by a formal system or given by a definition, together with a proof of its correctness, in terms of recursion on some well-founded structure.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Biane P,,Itô’s stochastic calculus and Heisenberg commutation relations,Stochastic Processes and their Applications,2010,120,5,698-720,,,,,2010,,0304-4149,https://www.sciencedirect.com/science/article/pii/S0304414910000256;http://dx.doi.org/10.1016/j.spa.2010.01.016,10.1016/j.spa.2010.01.016,"Stochastic calculus and stochastic differential equations for Brownian motion were introduced by K. Itô in order to give a pathwise construction of diffusion processes. This calculus has deep connections with objects such as the Fock space and the Heisenberg canonical commutation relations, which have a central role in quantum physics. We review these connections, and give a brief introduction to the noncommutative extension of Itô’s stochastic integration due to Hudson and Parthasarathy. Then we apply this scheme to show how finite Markov chains can be constructed by solving stochastic differential equations, similar to diffusion equations, on the Fock space.","Stochastic integrals, Diffusion processes, Heisenberg commutation relations",A tribute to Kiyosi Itô,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zafeiris VE,Poulias SH,Diamantidis NA,Giakoumakis EA",,Automated refactoring of super-class method invocations to the Template Method design pattern,Information and Software Technology,2017,82,,19-35,,,,,2017,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584916301860;http://dx.doi.org/10.1016/j.infsof.2016.09.008,10.1016/j.infsof.2016.09.008,"Context: Implementation inheritance, i.e., overriding of concrete method implementations through subtyping, is prone to potential class contract violations. Call Super is a code pattern that employs implementation inheritance for extending a method’s behaviour. In Call Super the overriding method includes in its body an invocation to the overridden method. Template Method is a design pattern that enables extensions to a multi-step procedure without overriding its concrete implementation. Instead, subclasses provide different variants of the template method’s behaviour through implementation of abstract method definitions (interface inheritance). Objective: This work studies the automated refactoring of Call Super to Template Method, contributing, thus, to replacement of implementation inheritance with interface inheritance. Method: We introduce an algorithm for the discovery of refactoring candidates that is based on an extensive set of refactoring preconditions. Moreover, we specify the source code transformation for refactoring a Call Super instance to Template Method. An implementation of the proposed approach is evaluated on a set of open source Java projects. Results: The evaluation results highlight (a) the frequent occurrence of the Call Super pattern among method overridings, (b) the potential provided by our method for discovery and elimination of several non-trivial Call Super instances and (c) the resulting code improvement, as reflected by the Specialization Index metric and the alignment of refactored code with the programmer’s intent. The application of all refactorings identified on a set of benchmark projects and the successful execution of their test suites provide empirical evidence on the soundness of the refactoring procedure. Runtime performance results support the scalability of the proposed method. Conclusion: The proposed method automates the replacement of implementation inheritance with interface inheritance through refactoring Call Super instances to Template Method. The empirical evaluation of the method supports its applicability, soundness and runtime efficiency.","Call Super, Implementation inheritance, Interface inheritance, Refactoring, Template Method design pattern",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jagannathan S,Vitek J,Welc A,Hosking A",,A transactional object calculus,Science of Computer Programming,2005,57,2,164-186,,,,,2005,,0167-6423,https://www.sciencedirect.com/science/article/pii/S016764230500033X;http://dx.doi.org/10.1016/j.scico.2005.03.001,10.1016/j.scico.2005.03.001,"A transaction defines a locus of computation that satisfies important concurrency and failure properties. These so-called ACID properties provide strong serialization guarantees that allow us to reason about concurrent and distributed programs in terms of higher-level units of computation (e.g., transactions) rather than lower-level data structures (e.g., mutual-exclusion locks). This paper presents a framework for specifying the semantics of a transactional facility integrated within a host programming language. The TFJ calculus, an object calculus derived from Featherweight Java, supports nested and multi-threaded transactions. We give a semantics to TFJ that is parametrized by the definition of the transactional mechanism that permits the study of different transaction models. We give two instantiations: one that defines transactions in terms of a versioning-based optimistic concurrency model, and the other which specifies transactions in terms of a pessimistic two-phase locking protocol, and present soundness and serializability properties for our semantics.","Transactions, Threads, Object calculus, Nesting, Optimistic concurrency, Two-phase locking",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Damiani F,Giannini P",,Alias types for “environment-aware” computations,Electronic Notes in Theoretical Computer Science,2003,82,8,130-150,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104808053;http://dx.doi.org/10.1016/S1571-0661(04)80805-3,10.1016/S1571-0661(04)80805-3,"In previous work with Bono we introduced a calculus for modelling “environment-aware” computations, that is computations that adapt their behavior according to the capabilities of the environment. The calculus is an imperative, object-based language (with extensible objects and primitives for discriminating the presence or absence of attributes of objects) equipped with a small-step operational semantics. In this paper we define a type and effect system for the calculus. The typing judgements specify, via constraints, the shape of environments which guarantees the correct execution of expressions and the typing rules track the effect of expression evaluation on the environment. The type and effect system is sound w.r.t. the operational semantics of the language.",,"WOOD2003, Workshop on Object Oriented Developments (Satellite Event of ETAPS 2003)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Tweedale J,Ichalkaranje N,Sioutis C,Jarvis B,Consoli A,Phillips-Wren G",,Innovations in multi-agent systems,Journal of Network and Computer Applications,2007,30,3,1089-1115,,,,,2007,,1084-8045,https://www.sciencedirect.com/science/article/pii/S108480450600035X;http://dx.doi.org/10.1016/j.jnca.2006.04.005,10.1016/j.jnca.2006.04.005,"This paper outlines an abridged history of agents as a guide for the reader to understand the trends and directions of future agent design. This description includes how agent technologies have developed using increasingly sophisticated techniques. It also indicates the transition of formal programming languages into object-oriented programming and how this transition facilitated a corresponding shift from scripted agents (bots) to agent-oriented designs. The trend shows that applications with agents are increasingly being used to assist humans, either at work or play. Examples include the ubiquitous paper clip, through to wizards, entire applications and even games. The trend also demonstrates that agents vary in the complexity of the problem being solved and their environment. Following the discussion of trends, we briefly look at the origins of agent technology and its principles, which reflects heavily on ‘Intelligence with Interaction’. We further pinpoint how the interaction with humans is one of the critical components of modern Distributed Artificial Intelligence (DAI) and how current applications fail to address this fact. The next generation of agents should focus on human-centric interaction to achieve intelligence. Utilising these advancements, we introduce a new paradigm that uses Intelligent Agents based on a Belief, Desire, and Intention (BDI) architecture to achieve situation awareness in a hostile environment. BDI agents are implemented using the JACK framework, and spawn agents with individual reasoning processes specifically relating to the goals being instigated in its environment. They depend on the environment or superior agents to generate goals for them to act upon. In order to improve the performance of the agents we need to remove this dependency. To this end, it is suggested that JACK can be extended to realise the Observe, Orient, Decide and Act (OODA) loop using feedback from a learning component within a team environment.","Artificial Intelligence (AI), Agent, Multi-Agent Systems (MAS), Distributed Artificial Intelligence (DIA), Belief, Desire, and Intension (BDI), Human–Computer Interface (HCI), Observe, Orient, Decide and Act (OODA), Procedural Reasoning System (PRS), Decision Support System (DSS), Intelligent Decision Support System (IDSS)",,,,,,,,,,,,,,,,,,,,,
Journal Article,Duggan D,,Higher-Order Substitutions,Information and Computation,2001,164,1,1-53,,,,,2001,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540100928876;http://dx.doi.org/10.1006/inco.2000.2887,10.1006/inco.2000.2887,"The λσ-calculus is a concrete λ-calculus of explicit substitutions, designed for reasoning about implementations of λ-calculi. Higher-order abstract syntax is an approach to metaprogramming that explicitly captures the variable-binding aspects of programming language constructs. A new calculus of explicit substitutions for higher-order abstract syntax is introduced, allowing a high-level description of variable binding in object languages while also providing substitutions as explicit programmer-manipulable data objects. The new calculus is termed the λσβ0-calculus, since it makes essential use of an extension of β0-unification (described in another paper). Termination and confluence are verified for the λσβ0-calculus similarly to that for the λσ-calculus, and an efficient implementation is given in terms of first-order renaming substitutions. The verification of confluence makes use of a verified adaptation of Nipkow's higher-order critical pairs lemma to the forms of rewrite rules required for the statement of the λσβ0-calculus.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wolfengagen VE,Ismailova LY,Kosikov SV",,Model of Conversion of Data Objects for Defining the Object-Relation Mapping,Procedia Computer Science,2018,123,,541-546,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050918300838;http://dx.doi.org/10.1016/j.procs.2018.01.082,10.1016/j.procs.2018.01.082,The paper considers the problem of building of the transformable object-relation mapping. It is offered to receive the decision by a semantic method in case of which the formal models of object system and relational system are considered and their interpretations are set. The transformation mappings are considered as a kind of mappings saving interpretations of the given form. Creation of model of converting of data objects on the basis of applicative computing systems is offered. On this basis the models can be received allow compositions of means of converting and also determination and check of global restrictions for the changes of data determined by the given set of methods of converting. Achievement of flexibility requires use parametrization of the considered construction.,"data modelling, lambda-model, data interpretation, data conversion, conceptual modelling, object-relation mapping, transformable mapping","8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia",,,,,,,,,,,,,,,,,,,,
Journal Article,"Srivastava HM,Khan B,Khan N,Tahir M,Ahmad S,Khan N",,Upper bound of the third Hankel determinant for a subclass of q-starlike functions associated with the q-exponential function,Bulletin des Sciences Mathématiques,2021,167,,102942,,,,,2021,,0007-4497,https://www.sciencedirect.com/science/article/pii/S0007449720301123;http://dx.doi.org/10.1016/j.bulsci.2020.102942,10.1016/j.bulsci.2020.102942,"By making use of the concept of basic (or q-) calculus, a subclass S⁎(L,q) of q-starlike functions, which is associated with the q-exponential function, is introduced here in the open unit disk U given byU=z:z∈Cand|z|<1. The main object of this article is to determine the upper bound of the third-order Hankel determinant H3(1) for functions belonging to the q-starlike function class S⁎(L,q). For validity of our results, relevant connections with those in earlier works are also pointed out.","Analytic functions, -derivative (or -difference) operator, Hankel determinant, -starlike functions, -exponential function",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Pardini G,Barbuti R,Maggiolo-Schettini A,Milazzo P,Tini S",,Compositional semantics and behavioural equivalences for reaction systems with restriction,Theoretical Computer Science,2014,551,,1-21,,,,,2014,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397514002898;http://dx.doi.org/10.1016/j.tcs.2014.04.010,10.1016/j.tcs.2014.04.010,"Reaction systems are an abstract model of interactions among biochemical reactions, developed around two opposite mechanisms: facilitation and inhibition. The evolution of a reaction system is driven by the external objects which are sent into the system by the environment at each step. In order to increase the modelling expressiveness of the calculus, we consider an extension of reaction systems with restriction, which allows the hiding of entities, such as those occurring inside membranes. To this purpose, we recently developed the Reaction Algebra, a calculus resembling reaction systems extended with a restriction operator. In the present paper, three equivalent semantics for the Reaction Algebra are presented: a reduction semantics, and two state-abstract compositional semantics. The reduction semantics is meant to capture the behaviour of Reaction Algebra models at a high-level, while the two compositional semantics make the interactive nature of reaction systems explicit. The difference between the two compositional semantics lies in how the behaviour with respect to the contextual entities is described: one uses an extensional description, while the other uses an intensional one. We also define, in the settings of both compositional semantics, a behavioural equivalence subsuming the functional equivalence of reaction systems, which is also shown to be congruence, thus providing a formal ground to the modular description of models. Finally, as an example of application of the techniques developed in the paper, we compare the semantics of two different Reaction Algebra models of the functioning of the lac operon in the E. coli bacterium.","Reaction systems, Reaction Algebra, Structural operational semantics, Behavioural equivalences, Congruence",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bauer A,Plotkin GD,Scott DS",,Cartesian closed categories of separable Scott domains,Theoretical Computer Science,2014,546,,17-29,,,,,2014,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397514001686;http://dx.doi.org/10.1016/j.tcs.2014.02.042,10.1016/j.tcs.2014.02.042,"We classify all sub-cartesian closed categories of the category of separable Scott domains. The classification employs a notion of coherence degree determined by the possible inconsistency patterns of sets of finite elements of a domain. Using the classification, we determine all sub-cartesian closed categories of the category of separable Scott domains that contain a universal object. The separable Scott domain models of the λβ-calculus are then classified up to a retraction by their coherence degrees.","Scott domain, Cartesian closed category, Lambda calculus",Models of Interaction: Essays in Honour of Glynn Winskel,,,,,,,,,,,,,,,,,,,,
Journal Article,"Freund SN,Mitchell JC",,A Type System for Object Initialization In the Java Bytecode Language (summary),Electronic Notes in Theoretical Computer Science,1998,10,,242-245,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105807030;http://dx.doi.org/10.1016/S1571-0661(05)80703-0,10.1016/S1571-0661(05)80703-0,"In the standard Java implementation, a Java language program is compiled to Java bytecode and this bytecode is then interpreted by the Java Virtual Machine. Since bytecode may be written by hand, or corrupted during network transmission, the Java Virtual Machine contains a bytecode verifier that performs a number of consistency checks before code is interpreted. As one-step towards a formal specification of the verifier, we describe a precise specification of a subset of the bytecode language dealing with object creation and initialization.",,"HOOTS II, Second Workshop on Higher-Order Operational Techniques in Semantics",,,,,,,,,,,,,,,,,,,,
Journal Article,"Sahraoui AE,Ould-Kaddour N",,Control software prototyping,Computers in Industry,1992,20,3,327-334,,,,,1992,,0166-3615,https://www.sciencedirect.com/science/article/pii/016636159290081W;http://dx.doi.org/10.1016/0166-3615(92)90081-W,10.1016/0166-3615(92)90081-W,"Prototyping is practiced in all fields of engineering. It has recently been introduced in software engineering. Designing a piece of software is an activity requiring an important intellectual effort. The development of a reliable and maintainable software system is not an easy task. “The activity of a programmer is two fold: scientific and artistic”, (Booch, 1986). Programming discipline requires some formal theories and some applied principles. The common techniques are structured design, object-oriented design, and mathematical concepts. This is the scientific aspect. The artistic aspect is the design of software components in relation to data and algorithms. It is this duality that makes programming so interesting and such an intellectual challenge.","Software engineering, Control, Prototyping, Petrinets, Ada, Modula-2",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Klímek J,Nečaský M",,On Inheritance in Conceptual Modeling for XML,Procedia Computer Science,2012,10,,54-61,,,,,2012,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050912003687;http://dx.doi.org/10.1016/j.procs.2012.06.011,10.1016/j.procs.2012.06.011,"Modern information systems may exploit numerous XML formats for communication. Each message may have its own XML format for data representation which causes problems with evolution of their schemas. Manual change management of the XML formats may be error-prone and time consuming. We tackled this problem in our previous work with the introduction of a formal two level conceptual model for XML which interconnects multiple XML schemas describing parts of a common problem domain on a conceptual level. This allows for well-deﬁned and automated change management of XML schemas. In this paper, we extend our previous work with inheritance modeling. Because inheritance is common in XML schemas and conceptual models in general, its modeling is needed and makes our conceptual model more usable in real world situations. There are two basic types of inheritance when it comes to modeling: structural and conceptual inheritance. We discuss the differences and how these two types need to be reﬂected in our model.","XML schema modeling, model driven architecture, inheritance, conceptual model",ANT 2012 and MobiWIS 2012,,,,,,,,,,,,,,,,,,,,
Journal Article,Wegner P,,Interactive foundations of computing,Theoretical Computer Science,1998,192,2,315-351,,,,,1998,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397597001540;http://dx.doi.org/10.1016/S0304-3975(97)00154-0,10.1016/S0304-3975(97)00154-0,"The claim that interactive systems have richer behavior than algorithms is surprisingly easy to prove. Turing machines cannot model interaction machines (which extend Turing machines with interactive input/output) because interaction is not expressible by a finite initial input string. Interaction machines extend the Chomsky hierarchy, are modeled by interaction grammars, and precisely capture fuzzy concepts like open systems and empirical computer science. Computable functions cannot model real-world behavior because functions are too strong an abstraction, sacrificing the ability to model time and other real-world properties to realize formal tractability. Part I of this paper examines extensions to interactive models for algorithms, machines, grammars, and semantics, while Part II considers the expressiveness of different forms of interaction. Interactive identity machines are already more powerful than Turing machines, while noninteractive parallelism and distribution are algorithmic. The extension of Turing to interaction machines parallels that of the lambda to the pi calculus. Asynchronous and nonserializable interaction are shown to be more expressive than sequential interaction (multiple streams are more expressive than a single stream). In Part III, it is shown that interaction machines cannot be described by sound and complete first-order logics (a form of Godel incompleteness), and that incompleteness is inherently necessary to realize greater expressiveness. In the final section the robustness of interactive models in expressing open systems, programming in the large, graphical user interfaces, and agent-oriented artificial intelligence is compared to the robustness of Turing machines. Less technical discussion of these ideas may be found in [25–27]. Applications of interactive models to coordination, objects and components, patterns and frameworks, software engineering, and AI are examined elsewhere [28,29]. The propositions P1-P36 embody the principal claims, while observations 01 through 040 provide additional insights.","Turing machines, Interaction, Coordination, Time, On-line algorithms, Grammars, Process models, Games, Logic, Models, Incompleteness, Constraints, Emergent behavior, Empirical computer science",,,,,,,,,,,,,,,,,,,,,
Journal Article,Tenreiro Machado J,,Fractional generalization of memristor and higher order elements,Communications in Nonlinear Science and Numerical Simulation,2013,18,2,264-275,,,,,2013,,1007-5704,https://www.sciencedirect.com/science/article/pii/S1007570412003048;http://dx.doi.org/10.1016/j.cnsns.2012.07.014,10.1016/j.cnsns.2012.07.014,Fractional calculus generalizes integer order derivatives and integrals. Memristor systems generalize the notion of electrical elements. Both concepts were shown to model important classes of phenomena. This paper goes a step further by embedding both tools in a generalization considering complex-order objects. Two complex operators leading to real-valued results are proposed. The proposed class of models generate a broad universe of elements. Several combinations of values are tested and the corresponding dynamical behavior is analyzed.,"Fractional calculus, Memristor, Device modeling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Di Stefano A,Pappalardo G,Santoro C,Tramontana E",,A framework for the design and automated implementation of communication aspects in multi-agent systems,Journal of Network and Computer Applications,2007,30,3,1136-1152,,,,,2007,,1084-8045,https://www.sciencedirect.com/science/article/pii/S1084804506000373;http://dx.doi.org/10.1016/j.jnca.2006.04.007,10.1016/j.jnca.2006.04.007,"This paper presents REFCON, a framework for the automated development of Agent Communication Contexts (ACCs) in multi-agent systems (MASs). ACCs are intended to capture the interaction requirements of a MAS. A formal specification framework is first presented, aimed at modelling an ACC as a set of rules for filtering and filling messages, based on their contents, and the names and roles of the exchanging agents. A XML-based specification language is then introduced, which encodes the specification formalism for the sake of its computer processing. Finally, an object-oriented software architecture capable of supporting ACC-based MAS development is presented. REFCON key characteristic is that it allows a seamless integration of ACC support (even) into an existing MAS, at run-time, independently of the agent platform used for the implementation. This is made possible by a layered software architecture based on computational reflection, a technology that allows transparent evolution and adaptation of existing systems. The REFCON framework is also dynamic, in the two-fold sense that it is capable of both adding new rules and handling multiple contexts, which it can easily switch among, at run-time. The ACC-based design of an example MAS for document sharing is briefly discussed, as a demonstration of the principles put forward.","Multi-agent systems, Software engineering, Computational reflection, Agent contexts, Agent communication languages",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wolfengagen V,Ismailova L,Kosikov S,Babushkin D",,"Modeling spread, interlace and interchange of information processes with variable domains",Cognitive Systems Research,2021,66,,21-29,,,,,2021,,1389-0417,https://www.sciencedirect.com/science/article/pii/S1389041720300905;http://dx.doi.org/10.1016/j.cogsys.2020.10.016,10.1016/j.cogsys.2020.10.016,"In this paper a semantic metalanguage is developed and designed to study the occurrence, spread and safe interaction of semantic processes in information modeling systems, including cognitive interference. An approach to construe a semantic network is proposed and based on a computational model in which both nodes and arcs are information processes. Concepts are represented by intensional objects within the framework of theories without types, and they, in turn, are considered as special counterparts of typed theories. Similar mixing was used in model studies for lambda calculus. To a contrast with them, in this paper, information processes correspond to parameterized metadata objects, which are variable domain constructs. Transformations of variable domains correspond to the spread of the process. Directional transformation provides the generation of metadata targets in the form of parameterized concepts. This simulates the development of the process, which corresponds to the spread of cognitive interference and allows the interpretation of a hidden time factor. The emerging model is purely process based and provides such a conceptual framework. The possibility of coding this framework with a system of interdependent lambda terms is reflected.","Information process, Cognitive interference, Quantum shift learning, Natural computing",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Anaya-Vera S,Cordero-Dávila A",,Fast and exact diffraction integral calculus: A comparison with fresnel approximation,Optik,2020,208,,164470,,,,,2020,,0030-4026,https://www.sciencedirect.com/science/article/pii/S0030402620303041;http://dx.doi.org/10.1016/j.ijleo.2020.164470,10.1016/j.ijleo.2020.164470,"In Lens-less Digital Holographic Microscopy1, 2, 3, amplitude and phase of an object can be recovered from the irradiance of a diffraction pattern. To do this, an iterative algorithm with constrictions is applied, which is based on the calculation of diffraction patterns between two fixed planes. In one dimension and for N pixels on each straight line segment, we must calculate N2 values of the impulse response function, h, in order to evaluate the optical field on N pixels along another straight line segment. By using translation and permutation symmetries of h, and without any approximation, in this paper we will show that to calculate the diffraction pattern over N pixels we need only N values of h. Adding to this, if iterations are applied between two pixel lines, the N values of h are calculated only one time, and then we achieved a significative reduction in calculation time. Finally, our exact calculations were compared with Fresnel diffraction patterns reported by Goodman4, and we found that when distance between object and diffraction planes diminishes then the diffraction pattern irradiance differences are increased up to 53 % with respect to Fresnel approximation.","Optics, Diffraction, Mathematical methods in physics, Numerical approximation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Saiti E,Danelakis A,Theoharis T",,Cross-time registration of 3D point clouds,Computers & Graphics,2021,99,,139-152,,,,,2021,,0097-8493,https://www.sciencedirect.com/science/article/pii/S0097849321001357;http://dx.doi.org/10.1016/j.cag.2021.07.005,10.1016/j.cag.2021.07.005,"Registration is a ubiquitous operation in visual computing and constitutes an important pre-processing step for operations such as 3D object reconstruction, retrieval and recognition. Particularly in cultural heritage (CH) applications, registration techniques are essential for the digitization and restoration pipelines. Cross-time registration is a special case where the objects to be registered are instances of the same object after undergoing processes such as erosion or restoration. Traditional registration techniques are inadequate to address this problem with the required high accuracy for detecting minute changes; some are extremely slow. A deep learning registration framework for cross-time registration is proposed which uses the DeepGMR network in combination with a novel down-sampling scheme for cross-time registration. A dataset especially designed for cross-time registration is presented (called ECHO) and an extensive evaluation of state-of-the-art methods is conducted for the challenging case of cross-time registration.","3D registration, Alignment, Cross-time, Retrieval, Cultural heritage, Erosion",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Slaoui M,Tudor CA",,Behavior with respect to the Hurst index of the Wiener Hermite integrals and application to SPDEs,Journal of Mathematical Analysis and Applications,2019,479,1,350-383,,,,,2019,,0022-247X,https://www.sciencedirect.com/science/article/pii/S0022247X19305050;http://dx.doi.org/10.1016/j.jmaa.2019.06.031,10.1016/j.jmaa.2019.06.031,"We consider the Wiener integral with respect to a d-parameter Hermite process with Hurst multi-index H=(H1,..,Hd)∈(12,1)d and we analyze the limit behavior in distribution of this object when the components of H tend to 1 and/or 12. As examples, we focus on the solution to the stochastic heat equation with additive Hermite noise and to the Hermite Ornstein-Uhlenbeck process.","Wiener chaos, Hermite process, Stochastic heat equation, Fractional Brownian motion, Multiple stochastic integrals, Malliavin calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,Prediger S,,Formal concept analysis for general objects,Electronic Notes in Discrete Mathematics,1999,2,,76-93,,,,,1999,,1571-0653,https://www.sciencedirect.com/science/article/pii/S1571065304000162;http://dx.doi.org/10.1016/S1571-0653(04)00016-2,10.1016/S1571-0653(04)00016-2,"General objects are classes of individual objects that are considered to be extents of concepts of a formal context. In this paper, different contexts with general objects are defined and their conceptual structure and relation to other contexts is analyzed with methods of Formal Concept Analysis.",,"OSDA98, Ordinal and Symbolic Data Analysis",,,,,,,,,,,,,,,,,,,,
Journal Article,Prediger S,,Formal Concept Analysis for general objects,Discrete Applied Mathematics,2003,127,2,337-355,,,,,2003,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X02002536;http://dx.doi.org/10.1016/S0166-218X(02)00253-6,10.1016/S0166-218X(02)00253-6,"General objects are classes of individual objects that are considered to be extents of concepts of a formal context. In this paper, different contexts with general objects are defined and their conceptual structure and relation to other contexts is analyzed with methods of Formal Concept Analysis.","Formal Concept Analysis, Qualitative data analysis, Ordinal data analysis, Individuation, General objects","Ordinal and Symbolic Data Analysis (OSDA '98), Univ. of Massachusetts, Amherst, Sept. 28-30, 1998.",,,,,,,,,,,,,,,,,,,,
Journal Article,"Müller K,Sebastian HJ",,Intelligent systems for engineering design and configuration problems,European Journal of Operational Research,1997,100,2,315-326,,,,,1997,,0377-2217,https://www.sciencedirect.com/science/article/pii/S0377221796002925;http://dx.doi.org/10.1016/S0377-2217(96)00292-5,10.1016/S0377-2217(96)00292-5,"This article describes an approach to engineering design and configuration problems which was developed in order to enrich existing design and configuration support systems with more intelligent abilities. The main idea is to integrate knowledge-based methods with multi-criteria decision making and fuzzy logic. Such hybrid type systems show some important advantages, e.g. object oriented and declarative type of knowledge representation, making design or configuration decisions by solving a multi-criteria decision making problem and dealing with imprecision by using several concepts of fuzzy logic. The concepts and approaches have been implemented in the KONWERK modular tool kit for engineering design and configuration problems. We will focus to the description of imprecision in KONWERK in particular to the Fuzzy MADM module of KONWERK, and we will illustrate our approach using the application ‘preliminary design of future space launch systems’.","Intelligent systems, Engineering design, Fuzzy logic, Multi-criteria decision making",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li B,Sun X,Keung J",,FCA–CIA: An approach of using FCA to support cross-level change impact analysis for object oriented Java programs,Information and Software Technology,2013,55,8,1437-1449,,,,,2013,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584913000360;http://dx.doi.org/10.1016/j.infsof.2013.02.003,10.1016/j.infsof.2013.02.003,"Background Software Change Impact Analysis (CIA) is an essential technique in software engineering to identifying the potential influences of a change, or determining change entities to accomplish such a change. The results derived, in many cases, ambiguous for the software maintainers, introduces the problem of unclear starting point of these impacted entities. Objective In an attempt to address this issue, this work proposes a novel approach for cross-level CIA, producing a ranked list of potentially impacted methods derived from class-level changes. Moreover, the approach of ranking the impact results is expected to be effective for maintainers to distinguish the probability of the impacted methods to be false-positives. Such results provide an eclectic approach for CIA. Method The approach, FCA–CIA, uses formal concept analysis (FCA) to produce an intermediate representation of the program based on the static analysis of the source code. The representation is called Lattice of Class and Method Dependence (LoCMD). FCA–CIA takes the changed classes in the change set as a whole, and determines the reachable set from the changed classes on the LoCMD. Based on the hierarchical property of the LoCMD, the impacted methods are ranked according to the impact factor metric which corresponds to the priority of these methods to be inspected. Result Empirical evaluations on four real-world software projects demonstrate the effectiveness of the impact factor metric and the FCA–CIA technique. The result shows the predicted impacted methods with higher impact factor values are more likely to be affected by the changes. Our study also shows that the FCA–CIA technique generates more accurate impact set than the JRipples and ICP coupling based CIA technique.","Formal concept analysis, Change impact analysis, Lattice of class and method dependence, Impact factor",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Stepp RE,Michalski RS",,Conceptual clustering of structured objects: A goal-oriented approach,Artificial Intelligence,1986,28,1,43-69,,,,,1986,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370286900305;http://dx.doi.org/10.1016/0004-3702(86)90030-5,10.1016/0004-3702(86)90030-5,"Conceptual clustering is concerned with problems of grouping observed entities into conceptually simple classes. Earlier work on this subject assumed that the entities and classes are described in terms of a priori given multi-valued attributes. This research extends the previous work in three major ways: •- entities are characterized as compound objects requiring structural descriptions.•- relevant descriptive concepts (attributes and relations) are not necessarily given a priori but can be determined through reasoning about the goals of classification.•- inference rules are used to derive useful high-level descriptive concepts from the initially provided low-level concepts. The created classes are described using Annotated Predicate Calculus (APC), which is a typed predicate calculus with additional operators. Relevant descriptive concepts appropriate for characterizing entities are determined by tracing links in a Goal Dependency Network (GDN) that represents relationships between goals, subgoals, and related attributes. An experiment comparing results from the program cluster/s that implements the classification generation process and results obtained from people indicates that the proposed method might offer a plausible cognitive model of classification processes as well as an engineering solution to the problems of automatic classification generation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Roslovtsev V,,"Architecture for Modular Type System for Information Systems Based on Relational-Applicative Technologies ⁎⁎The work is supported by Russian Foundation for Basic Research, project No 17-07-01553",Procedia Computer Science,2018,123,,386-392,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050918300619;http://dx.doi.org/10.1016/j.procs.2018.01.060,10.1016/j.procs.2018.01.060,"In the recent years a tendency in information systems development has manifested itself to use a (meta)data framework. While using software frameworks (user interface elements and engines, whole functional subsystems) has been common practice for decades by now, it is only relatively recently that developers began more and more often to shift away from relying on static subject domain conceptual schemes. This is in response partly to the tendency of growth of subject domain model in conceptual diversity, and partly in attempt to capture the shifting nature of subject domains. In this paper we describe an architecture and supporting data structures for a reusable engine that allows describing concepts, storing data objects with respect to the conceptual structure, and controllable modification of data and concepts.","Modular Type System, Information Systems, Relational-Applicative Objects","8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia",,,,,,,,,,,,,,,,,,,,
Journal Article,"Jiménez-Pastor A,Pillwein V",,A computable extension for D-finite functions: DD-finite functions,Journal of Symbolic Computation,2019,94,,90-104,,,,,2019,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717118300890;http://dx.doi.org/10.1016/j.jsc.2018.07.002,10.1016/j.jsc.2018.07.002,Differentiably finite (D-finite) formal power series form a large class of useful functions for which a variety of symbolic algorithms exists. Among these methods are several closure properties that can be carried out automatically. We introduce a natural extension of these functions to a larger class of computable objects for which we prove closure properties. These are again algorithmic. This extension can be iterated constructively preserving the closure properties.,"Holonomic functions, Closure properties, Formal power series",,,,,,,,,,,,,,,,,,,,,
Journal Article,Bowman H,,Preface: Volume 43,Electronic Notes in Theoretical Computer Science,2001,43,,162-163,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105810539;http://dx.doi.org/10.1016/S1571-0661(05)81053-9,10.1016/S1571-0661(05)81053-9,"Formal Methods Elsewhere A Satellite Workshop of FORTE-PSTV-2000 devoted to applications of formal methods to areas other than communication protocols and software engineering A wide variety of formal models, languages and methods have been developed in the last two decades for supporting the specification, design, verification, implementation and testing of computer networks and distributed software systems. These include CCS, pi-calculus, timed and stochastic process algebra, VDM, Z, B, Automata and Timed Automata, Petri Nets, Statecharts, Logics, TLA, Message Sequence Charts, ADT's, OBJ, Larch, formal Object-Oriented approaches, the international standards Estelle, LOTOS, SDL, ASN.1 and TTCN, and others. Formal specification languages have been designed to support the description of system structure and behaviour in terms of concepts such as event occurrence, observation and experiment, temporal ordering, causality, cooperation and synchronisation among entities, non determinism, concurrency and parallelism, state changes and invariants, and others. While considerable experience has been gained in the application of formal methods to the areas for which they were initially conceived, the high abstraction level of these concepts suggests that they could play an important role in several other disciplines such as chemistry, biology, physics and even arts, humanites and social sciences. After two decades of ‘traditional’ applications, during which the initial gap between the excessive optimism of academic supporters and the skepticism of industrial detractors have been substantially reduced, often leading to a positive and constructive attitude towards their adoption, formal methods are perhaps ready to spread out of their native territory and, at the turn of the decade and millenium, invade new exciting areas of research, thus providing a much wider exploitation of the huge intellectual investment behind their definition. In fact, it is often the case that a technique designed with a particular application in mind, turns out to perform better and to be more useful in a context other than the originally intended one. For more information on the spectrum of topics within the remit of the FM-Elsewhere initiative, see this web page. A list of existing “Elsewhere” applications of formal methods can also be accessed at this web page. The FM-Elsewhere workshop, co-located with FORTE-PSTV-2000 in Pisa, was a forum for researchers interested in the application of formal methods, as identified above, to virtually any area of research, except communication protocols and software engineering. The talks included in the workshop covered the spectrum of FM-Elsewhere areas. In particular, applications of formal methods to all the following areas were considered, safety analysis of cockpit interfaces;solving games and puzzles using state space exploration techniques;modelling theories of the mind;usability anaylsis of human computer interfaces;formal definition of linguistic systems; andmodelling in mechanics and physics. Thanks should be made to a number of people. Firstly, FM-Elsewhere 2000 was fortunate to have two celebrated invited speakers, John Rushby who spoke on how model checking techniques can be used in analysing cockpit interfaces; andProfessor David Duce who spoke on using state based specification techniques to model cognitive systems. Secondly, we would like to thank the workshop sponsors - The Computing Laboratory at the University of Kent at Canterbury and CNR-Istituto CNUCE, in Pisa. Thirdly, the workshop benefited from the reviewing efforts of the workshop committee. Tommaso Bolognesi (CNR/I.E.I. at Pisa, Italy)Howard Bowman (Univ. of Kent at Canterbury, UK)Alan Dix (aQtive Limited, UK)David Duce (Rutherford Appleton Laboratory, UK)David Duke (University of York, UK)Giorgio Faconti (CNR/CNUCE at Pisa, Italy)Chris Johnson (University of Glasgow, UK)Peter Johnson (University of Bath, UK)Peter B. Ladkin (University of Bielefeld, Germany)Scott Smolka (State University of New York at Stony Brook, US)Graziella Tonfoni (University of Bologna, Italy and The George Washington Unversity, US)Ken Turner (University of Stirling, UK) Finally, thanks should go to Professor Mike Mislove for his help during the proceedings editorial process and to Kerry Riches for her help in preparing the participants proceedings.",,Formal Methods Elsewhere (a Satellite Workshop of FORTE-PSTV-2000 devoted to applications of formal methods to areas other than communication protocols and software engineering),,,,,,,,,,,,,,,,,,,,
Journal Article,"Arnaud JB,Ducasse S,Denker M,Teruel C",,Handles: Behavior-propagating first class references for dynamically-typed languages,Science of Computer Programming,2015,98,,318-338,,,,,2015,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642314003359;http://dx.doi.org/10.1016/j.scico.2014.07.011,10.1016/j.scico.2014.07.011,"Controlling object graphs and giving specific semantics to references (such as read-only, ownership, scoped sharing) have been the focus of a large body of research in the context of static type systems. Controlling references to single objects and to graphs of objects is essential to build more secure systems, but is notoriously hard to achieve in the absence of static type systems. In this article we embrace this challenge by proposing a solution to the following question: What is an underlying mechanism that can support the definition of properties (such as revocable, read-only, lent) at the reference level in the absence of a static type system? We present handles: first-class references that propagate behavioral change dynamically to the object subgraph during program execution. In this article we describe handles and show how handles support the implementation of read-only references and revocable references. Handles have been fully implemented by modifying an existing virtual machine and we report their costs.","Security, Dynamic language, First class references, Language design",Special Issue on Advances in Dynamic Languages,,,,,,,,,,,,,,,,,,,,
Journal Article,Giraudo S,,Tree series and pattern avoidance in syntax trees,"Journal of Combinatorial Theory, Series A",2020,176,,105285,,,,,2020,,0097-3165,https://www.sciencedirect.com/science/article/pii/S0097316520300777;http://dx.doi.org/10.1016/j.jcta.2020.105285,10.1016/j.jcta.2020.105285,"A syntax tree is a planar rooted tree where internal nodes are labeled on a graded set of generators. There is a natural notion of occurrence of contiguous pattern in such trees. We describe a way, given a set of generators G and a set of patterns P, to enumerate the trees constructed on G and avoiding P. The method is built around inclusion-exclusion formulas forming a system of equations on formal power series of trees, and composition operations of trees. This does not require particular conditions on the set of patterns to avoid. We connect this result to the theory of nonsymmetric operads. Syntax trees are the elements of such free structures, so that any operad can be seen as a quotient of a free operad. Moreover, in some cases, the elements of an operad can be seen as trees avoiding some patterns. Relying on this, we use operads as devices for enumeration: given a set of combinatorial objects we want enumerate, we endow it with the structure of an operad, understand it in term of trees and pattern avoidance, and use our method to count them. Several examples are provided.","Tree, Pattern avoidance, Enumeration, Formal power series, Operad",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lopes AM,Tenreiro Machado JA,Pinto CM,Galhano AM",,Fractional dynamics and MDS visualization of earthquake phenomena,Computers & Mathematics with Applications,2013,66,5,647-658,,,,,2013,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122113000953;http://dx.doi.org/10.1016/j.camwa.2013.02.003,10.1016/j.camwa.2013.02.003,"This paper analyses earthquake data in the perspective of dynamical systems and fractional calculus (FC). This new standpoint uses Multidimensional Scaling (MDS) as a powerful clustering and visualization tool. FC extends the concepts of integrals and derivatives to non-integer and complex orders. MDS is a technique that produces spatial or geometric representations of complex objects, such that those objects that are perceived to be similar in some sense are placed on the MDS maps forming clusters. In this study, over three million seismic occurrences, covering the period from January 1, 1904 up to March 14, 2012 are analysed. The events are characterized by their magnitude and spatiotemporal distributions and are divided into fifty groups, according to the Flinn–Engdahl (F–E) seismic regions of Earth. Several correlation indices are proposed to quantify the similarities among regions. MDS maps are proven as an intuitive and useful visual representation of the complex relationships that are present among seismic events, which may not be perceived on traditional geographic maps. Therefore, MDS constitutes a valid alternative to classic visualization tools for understanding the global behaviour of earthquakes.","Fractional calculus, Multidimensional scaling, Seismic events, Correlation indices",Fractional Differentiation and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li K,Chen PY,Yan E",,Challenges of measuring software impact through citations: An examination of the lme4 R package,Journal of Informetrics,2019,13,1,449-461,,,,,2019,,1751-1577,https://www.sciencedirect.com/science/article/pii/S1751157718304796;http://dx.doi.org/10.1016/j.joi.2019.02.007,10.1016/j.joi.2019.02.007,"The rise of software as a research object is mirrored by increasing interests in quantitative studies of scientific software. However, inconsistent citation practices have led most existing studies of this type to base their analysis of software impact on software name mentions, as identified in full-text publications. Despite its limitations, citation data exists in much greater quantities and covers a broader array of scientific fields than full-text data, and thus can support investigations with much wider scope. This paper aims to analyze the extent to which citation data can be used to reconstruct the impact of software. Specifically, we identify the variety of citable objects related to the lme4 R package and examine how the package’s impact is dispersed across these objects. Our results shed light on a little-discussed challenge of using citation data to measure software impact: even within the category of formal citation, the same software object might be cited in different forms. We consider the implications of this challenge and propose a method to reconstruct the impact of lme4 through its citations nonetheless.","Software citation, Citable object, lme4",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Copot C,Burlacu A,Ionescu CM,Lazar C,De Keyser R",,A fractional order control strategy for visual servoing systems,Mechatronics,2013,23,7,848-855,,,,,2013,,0957-4158,https://www.sciencedirect.com/science/article/pii/S095741581300161X;http://dx.doi.org/10.1016/j.mechatronics.2013.09.003,10.1016/j.mechatronics.2013.09.003,"In this paper, a control strategy based on fractional calculus for visual servoing systems is proposed. The image-based control strategy is designed using a point features based fractional-order PI controller. A real-time visual servoing system, composed of a manipulator robot with 6 degrees of freedom (d.o.f.) with an eye-in-hand camera, is used for performance evaluation of the proposed control strategy. The image acquisition and processing, together with the computing of the image-based control law are implemented in MATLAB. Using planar static objects, real-time experiments are conducted and the results reveal that the image-based fractional-order PI controller outperforms the conventional image-based integer-order PI controller.","Fractional calculus, Robotics, Visual servoing, Image processing","1. Fractional Order Modeling and Control in Mechatronics 2. Design, control, and software implementation for distributed MEMS (dMEMS)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Bodei C,Chessa S,Galletta L",,Measuring security in IoT communications,Theoretical Computer Science,2019,764,,100-124,,,,,2019,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397518307205;http://dx.doi.org/10.1016/j.tcs.2018.12.002,10.1016/j.tcs.2018.12.002,"More smart objects and more applications on the Internet of Things (IoT) mean more security challenges. In IoT security is crucial but difficult to obtain. On the one hand the usual trade-off between highly secure and usable systems is more impelling than ever; on the other hand security is considered a feature that has a cost often unaffordable. Therefore, IoT designers not only need tools to assess possible risks and to study countermeasures, but also methodologies to estimate their costs. Here, we present a methodology, based on the process calculus IoT-LySa, to infer quantitative measures on evolution of systems. The derived quantitative evaluation is exploited to establish the cost of the possible security countermeasures, in terms of time and energy.","Internet of Things, Security, Cost evaluation",Selected papers of ICTCS 2016 (The Italian Conference on Theoretical Computer Science (ICTCS),,,,,,,,,,,,,,,,,,,,
Journal Article,"Long Z,Meng H,Li T,Li S",,Compact geometric representation of qualitative directional knowledge,Knowledge-Based Systems,2020,195,,105616,,,,,2020,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705120300848;http://dx.doi.org/10.1016/j.knosys.2020.105616,10.1016/j.knosys.2020.105616,"To effectively and efficiently deal with large-scale spatial data is critical for applications in the age of information technology. Compact representation of spatial knowledge is one of the emerging research techniques that contribute to this capability. In this article, we consider the problem of compactly representing qualitative directional relations between extended objects, modelled in the Cardinal Direction Calculus (CDC) of Goyal and Egenhofer. For a large dataset of regions, this approach first constructs a simplified geometry for each region, which preserves CDC relations between regions, and then represents each simplified geometry compactly, so that the storage size is small while retrieving CDC relations from the representation is still reasonably fast. More specifically, the method called necessary cut is used to construct simple geometries, and the two methods, viz. the polygon representation and the rectangle representation, are devised to compactly represent the constructed geometries in cubic time w.r.t. the size of the corresponding simple geometry. Theoretical analyses demonstrate that the two representations, especially the rectangle representation, are promising to have small storage size. Moreover, our empirical evaluations on real-world datasets show that, for each dataset the new approach can produce a rectangle representation that has dominant performance against the state of the art techniques in reducing the storage size of the relations, while the average efficiency of retrieving CDC relations based on the rectangle representation is about the same as the fastest method in the literature.","Qualitative spatial representation, Cardinal Direction Calculus, Compact representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,McKinley R,,Canonical proof nets for classical logic,Annals of Pure and Applied Logic,2013,164,6,702-732,,,,,2013,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007212000838;http://dx.doi.org/10.1016/j.apal.2012.05.007,10.1016/j.apal.2012.05.007,"Proof nets provide abstract counterparts to sequent proofs modulo rule permutations; the idea being that if two proofs have the same underlying proof-net, they are in essence the same proof. Providing a convincing proof-net counterpart to proofs in the classical sequent calculus is thus an important step in understanding classical sequent calculus proofs. By convincing, we mean that (a) there should be a canonical function from sequent proofs to proof nets, (b) it should be possible to check the correctness of a net in polynomial time, (c) every correct net should be obtainable from a sequent calculus proof, and (d) there should be a cut-elimination procedure which preserves correctness. Previous attempts to give proof-net-like objects for propositional classical logic have failed at least one of the above conditions. In Richard McKinley (2010) [22], the author presented a calculus of proof nets (expansion nets) satisfying (a) and (b); the paper defined a sequent calculus corresponding to expansion nets but gave no explicit demonstration of (c). That sequent calculus, called LK⁎ in this paper, is a novel one-sided sequent calculus with both additively and multiplicatively formulated disjunction rules. In this paper (a self-contained extended version of Richard McKinley (2010) [22]), we give a full proof of (c) for expansion nets with respect to LK⁎, and in addition give a cut-elimination procedure internal to expansion nets – this makes expansion nets the first notion of proof-net for classical logic satisfying all four criteria.","Proof nets, Identity of proofs, Classical logic, Cut elimination",Classical Logic and Computation 2010(CLAC 2010),,,,,,,,,,,,,,,,,,,,
Book Chapter,Mueller ET,Mueller ET,Chapter 7 - Continuous Change,,2015,,,117-126,Second Edition,Morgan Kaufmann,Boston,Commonsense Reasoning (Second Edition),2015,9780128014165,,https://www.sciencedirect.com/science/article/pii/B9780128014165000073;http://dx.doi.org/10.1016/B978-0-12-801416-5.00007-3,10.1016/B978-0-12-801416-5.00007-3,"Discrete change is change that is limited to a countable, usually finite, set of timepoints. We represent discrete change in the event calculus using effect axioms. In a number of commonsense domains ranging from the physical to the mental, we find continuous change. Examples of continuous change include the change in the height of a falling object, the location of a projectile, the water level of a filling bathtub, the volume of a balloon in the process of inflation, the frequency of a siren, the hunger level of an animal, and the anger level of a person. In the discrete event calculus, time is limited to the integers; there we speak of gradual change. We discuss the representation of continuous change and gradual change in the event calculus. We retrace the development of Trajectory. We discuss the use of trajectory and antitrajectory axioms.","Commonsense reasoning, Eevent calculus, Reasoning about action and change, Continuous change, Gradual change",,,,,,,,,,,,,,,,,,,,,
Journal Article,Walukiewicz I,,Deciding low levels of tree-automata hierarchy,Electronic Notes in Theoretical Computer Science,2002,67,,61-75,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104805413;http://dx.doi.org/10.1016/S1571-0661(04)80541-3,10.1016/S1571-0661(04)80541-3,"The paper concerns hierarchy of indices of finite automata over infinite objects. This hierarchy corresponds exactly to the hierarchy of alternations of least and greatest fixpoints in the mu-calculus. It is also connected to quantifier hierarchies in monadic second-order logic. The open question is to find a procedure that given a regular tree language decides its level in the index hierarchy. Here, decision procedures are presented for low levels of the hierarchy. It is shown that these procedures have optimal complexity.","finite automata, quantifier hierarchy, mu-calculus, fixpoint","WoLLIC'2002, 9th Workhop on Logic, Language, Information and Computation",,,,,,,,,,,,,,,,,,,,
Journal Article,Gray JW,,Semantics of the typed λ-calculus with substitution in a cartesian closed category,Journal of Pure and Applied Algebra,1993,89,1,107-126,,,,,1993,,0022-4049,https://www.sciencedirect.com/science/article/pii/002240499390089C;http://dx.doi.org/10.1016/0022-4049(93)90089-C,10.1016/0022-4049(93)90089-C,"Two versions of semantics of the typed λ-calculus with substitution are given. The first uses a global environments object which is the domain of all interpreted terms, while the second uses individual environments objects for each term. The algebraic properties of the environments object(s) play a central role in showing that the interpretation function is invariant under the operational semantics given by substitution.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang Z,Qu H,Wu Z,Yang H,Du Q",,Formal representation of 3D structural geological models,Computers & Geosciences,2016,90,,10-23,,,,,2016,,0098-3004,https://www.sciencedirect.com/science/article/pii/S0098300416300322;http://dx.doi.org/10.1016/j.cageo.2016.02.007,10.1016/j.cageo.2016.02.007,"The development and widespread application of geological modeling methods has increased demands for the integration and sharing services of three dimensional (3D) geological data. However, theoretical research in the field of geological information sciences is limited despite the widespread use of Geographic Information Systems (GIS) in geology. In particular, fundamental research on the formal representations and standardized spatial descriptions of 3D structural models is required. This is necessary for accurate understanding and further applications of geological data in 3D space. In this paper, we propose a formal representation method for 3D structural models using the theory of point set topology, which produces a mathematical definition for the major types of geological objects. The spatial relationships between geologic boundaries, structures, and units are explained in detail using the 9-intersection model. Reasonable conditions for describing the topological space of 3D structural models are also provided. The results from this study can be used as potential support for the standardized representation and spatial quality evaluation of 3D structural models, as well as for specific needs related to model-based management, query, and analysis.","Formal representation, Geological model, 9-intersection model, Spatial relation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Poletykin AG,Promyslov VG",,Formal Hierarchical Model of Security of the Upper Level of Instrumentation & Control System of a Nuclear Power Plant,IFAC Proceedings Volumes,2013,46,9,2145-2150,,,,,2013,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016346146;http://dx.doi.org/10.3182/20130619-3-RU-3018.00322,10.3182/20130619-3-RU-3018.00322,The present paper considers a formal hierarchical model of the cybersecurity policy of the digital upper unit level system of (UULS) of the nuclear power plant (NPP). The relations and transfer of the access rights between the subjects and objects of the model are analyzed. The standard NPP UULS is characterized by way of example of the UULS developed at the Trapeznikov Institute of Control Sciences (Russian Academy of Sciences) for the NPP's and of its simplified cybersecurity model.,"cybersecurity, formal modeling, digital control systems, transfer of rights","7th IFAC Conference on Manufacturing Modelling, Management, and Control",,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang PY,Lin S,Tu ST",,A survey of fractional-calculus approaches to the solutions of the Bessel differential equation of general order,Applied Mathematics and Computation,2007,187,1,544-555,,,,,2007,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300306012069;http://dx.doi.org/10.1016/j.amc.2006.09.005,10.1016/j.amc.2006.09.005,"In a remarkably large number of recent works, one can find the emphasis upon (and demonstrations of) the usefulness of fractional-calculus operators in the derivation of (explicit) particular solutions of significantly general families of linear ordinary and partial differential equations of the second and higher orders. The main object of this presentation is to survey some earlier investigations of this simple fractional-calculus approach to the solutions of the classical Bessel differential equation of general order and to show how it would lead naturally to several interesting consequences which include (for example) an alternative derivation of the complete power-series solutions obtainable usually by the Frobenius method. The underlying analysis presented here is based chiefly upon some of the general theorems on (explicit) particular solutions of a certain family of linear ordinary fractional differintegral equations with polynomial coefficients.","Operators of fractional-calculus, Bessel differential equation, Fuchsian (and non-Fuchsian) differential equations, Differintegral equations, (Ordinary and partial) linear differential equations, Polynomial coefficients, Frobenius method, Power-series solutions, Bessel functions, Trigonometric function, Integro-differential equations, Hypergeometric representations","Proceedings of the International Symposium on Analytic Function Theory, Fractional Calculus and Their Applications in Honour of Professor H.M. Srivastava on his Sixty-Fifth Birth Anniversary",,,,,,,,,,,,,,,,,,,,
Journal Article,"Manjarrés Riesco A,Martı́nez Tomás R,Mira Mira J",,A customisable framework for the assessment of therapies in the solution of therapy decision tasks,Artificial Intelligence in Medicine,2000,18,1,57-82,,,,,2000,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365799000299;http://dx.doi.org/10.1016/S0933-3657(99)00029-9,10.1016/S0933-3657(99)00029-9,"In current medical research, a growing interest can be observed in the definition of a global therapy-evaluation framework which integrates considerations such as patients preferences and quality-of-life results. In this article, we propose the use of the research results in this domain as a source of knowledge in the design of support systems for therapy decision analysis, in particular with a view to application in oncology. We discuss the incorporation of these considerations in the definition of the therapy-assessment methods involved in the solution of a generic therapy decision task, described in the context of AI software development methodologies such as CommonKADS. The goal of the therapy decision task is to identify the ideal therapy, for a given patient, in accordance with a set of objectives of a diverse nature. The assessment methods applied are based either on data obtained from statistics or on the specific idiosyncrasies of each patient, as identified from their responses to a suite of psychological tests. In the analysis of the therapy decision task we emphasise the importance, from a methodological perspective, of using a rigorous approach to the modelling of domain ontologies and domain-specific data. To this aim we make extensive use of the semi-formal object oriented analysis notation UML to describe the domain level.","Therapy decision task, Heuristic-multiattribute methods, Quality of life measures in health",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kannan SR,Devi R,Ramathilagam S,Hong TP,Ravikumar A",,Robust fuzzy clustering algorithms in analyzing high-dimensional cancer databases,Applied Soft Computing,2015,35,,199-213,,,,,2015,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494615003427;http://dx.doi.org/10.1016/j.asoc.2015.05.035,10.1016/j.asoc.2015.05.035,"Due to uncertainty value of objects in microarray gene expression high dimensional cancer database, finding available subtypes of cancers is considered as challenging task. Researchers have invented mathematical assisted clustering techniques in clustering relevant gene expression of cancer subtypes, but the techniques have failed to provide proper outcome results with less error. Hence, it is an essential one in finding efficient computational clustering techniques to cluster the high dimensional gene expression cancer database for perfect diagnosis of cancer subtypes. This paper presents robust clustering techniques to identify perfect similarity between the uncertain objects of high dimensional cancer database. In order to obtain the robust clustering techniques, this paper incorporates both membership functions of fuzzy c-means and possibilistic c-means. In addition, this paper presents prototype initialization algorithm to avoid random initialization of initial prototypes. Benchmarks datasets were used to show the effectiveness of the proposed methods. The proposed methods were successfully implemented with microarray high dimensional gene expression cancer databases to separate available subtypes of cancer regions. The clustering accuracies of proposed and existed clustering methods indicate that the proposed methods are superior to the existed methods.","Fuzzy C-means, Kernel distances, Uncertain objects, Cancer databases",,,,,,,,,,,,,,,,,,,,,
Journal Article,Ohori A,,Semantics of types for database objects,Theoretical Computer Science,1990,76,1,53-91,,,,,1990,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397590900127;http://dx.doi.org/10.1016/0304-3975(90)90012-7,10.1016/0304-3975(90)90012-7,"A number of data models for complex database objects have been proposed. Unfortunately, these data models have not been well integrated in type systems of programming languages. This paper develops a mathematical theory for types and domains of databases that can serve as a “bridge” between complex data models and type systems of programming languages. Based on this framework, a concrete type system for complex database objects and its semantic domain are constructed. The type system allows arbitrarily complex structures that can be constructed by labeled records, labeled disjoint unions, finite sets and recursion, covering most of the proposed complex database objects. Moreover, its semantic domain is a proper generalization of the relational model to those complex structures. In addition to standard operations that can be found in programming languages, join and projection are available as polymorphically typed computable functions on arbitrary complex objects. It is then shown that both the type system and the semantic domain can be uniformly integrated in an ML-like programming language. This leads us to develop a database programming language that supports rich data structures and powerful operations for databases while enjoying desirable features of modern type systems of programming languages including polymorphism and static type inference.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Navratil G,Frank AU",,Processes in a cadastre,"Computers, Environment and Urban Systems",2004,28,5,471-486,,,,,2004,,0198-9715,https://www.sciencedirect.com/science/article/pii/S0198971503001091;http://dx.doi.org/10.1016/j.compenvurbsys.2003.11.003,10.1016/j.compenvurbsys.2003.11.003,"A cadastre is a system of major importance for economy and planning. A cadastre provides data on land. It is the basis for legal aspects like ownership as well as fiscal aspects like taxation of land. The cadastre also provides data for planning assignments (for example, boundaries of constructions, land use, and soil). Storage and update of these data require a complex system that had been developed in Austria during more than 100 years. Understanding, using, and improving a cadastre requires knowledge on the cadastral processes. The problems a cadastre must solve are important to understand the needs for a cadastre. It is also important to understand the processes of a cadastre to see how a cadastre works. These processes define the way a cadastre handles data and what prerequisites the data must fulfil to be accepted by the cadastre. Improving a system requires analysis of the processes. The user wants to work with a cadastre. He needs processes that meet his demands. Improving the efficiency of the processes, therefore, improves the efficiency of the cadastre directly because then the user will be satisfied (his work will be done better or faster). The paper discusses the tasks of a cadastre. The starting point is the needs of users (owners, government and many others). The needs define the tasks and the data needed to fulfil the tasks. The next step is the definition of the processes to fulfil the tasks. The paper then formalizes these processes. Finally, implementations for two different cadastral systems prove the general validity of the processes.","Cadastre, Land registration, Processes, Object-oriented, Formal model",Cadastral Systems III,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang PY,Lin S,Srivastava HM",,Explicit solutions of Jacobi and Gauss differential equations by means of operators of fractional calculus,Applied Mathematics and Computation,2008,199,2,760-769,,,,,2008,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300307010661;http://dx.doi.org/10.1016/j.amc.2007.10.037,10.1016/j.amc.2007.10.037,"Judging by the remarkably large number of recent publications on fractional calculus and its applications in several widely diverse areas of mathematical, physical and engineering sciences, the current popularity and importance of the subject of fractional calculus cannot be overemphasized. Motivated by some of these potentially useful developments, many authors have recently demonstrated the usefulness of fractional calculus in the derivation of explicit particular solutions of a number of linear ordinary and partial differential equations of the second and higher orders. The main object of the present paper is to show how several interesting contributions on this subject, involving a certain class of ordinary differential equations associated with (for example) the celebrated Gauss and Jacobi differential equations, can be obtained (in a unified manner) by suitably applying some general theorems on explicit particular solutions of a family of linear ordinary fractional differintegral equations.","Fractional calculus, Gauss differential equations, Jacobi differential equations, Gauss hypergeometric function, Generalized Leibniz rule, Analytic functions, Fractional differintegral equations, Ordinary and partial differential equations, Index law, Linearity property, Principal value, Bessel differential equation, Legendre’s differential equation, Power-series solutions, Hypergeometric representations, Euler transformation, Jacobi functions and Jacobi polynomials, Analytic continuation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Menon MS,Ananthasuresh GK,Ghosal A",,Natural motion of one-dimensional flexible objects using minimization approaches,Mechanism and Machine Theory,2013,67,,64-76,,,,,2013,,0094-114X,https://www.sciencedirect.com/science/article/pii/S0094114X1300075X;http://dx.doi.org/10.1016/j.mechmachtheory.2013.04.003,10.1016/j.mechmachtheory.2013.04.003,"For one-dimensional flexible objects such as ropes, chains, hair, the assumption of constant length is realistic for large-scale 3D motion. Moreover, when the motion or disturbance at one end gradually dies down along the curve defining the one-dimensional flexible objects, the motion appears “natural”. This paper presents a purely geometric and kinematic approach for deriving more natural and length-preserving transformations of planar and spatial curves. Techniques from variational calculus are used to determine analytical conditions and it is shown that the velocity at any point on the curve must be along the tangent at that point for preserving the length and to yield the feature of diminishing motion. It is shown that for the special case of a straight line, the analytical conditions lead to the classical tractrix curve solution. Since analytical solutions exist for a tractrix curve, the motion of a piecewise linear curve can be solved in closed-form and thus can be applied for the resolution of redundancy in hyper-redundant robots. Simulation results for several planar and spatial curves and various input motions of one end are used to illustrate the features of motion damping and eventual alignment with the perturbation vector.","Flexible body simulation, Length-preserving natural motion, Optimization, Tractrix, Hyper-redundant robots",,,,,,,,,,,,,,,,,,,,,
Journal Article,Hennessy M,,A survey of location calculi,Electronic Notes in Theoretical Computer Science,1998,16,2,97,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104001197;http://dx.doi.org/10.1016/S1571-0661(04)00119-7,10.1016/S1571-0661(04)00119-7,"The pi-calculus is a very expressive process description language in which the only transmittable datatype is that of (communication channel) names. Recently extensions of the pi-calculus have emerged in which this datatype of names is more structured; in addition to the normal pi-calculus use, a name may also refer to a location or site in a distributed system, or refer to a distributed object. In this talk I will give a brief survey of these extensions, focusing in particular on some open research issues.",,"EXPRESS '98, Fifth International Workshop on Expressiveness in Concurrency (Satellite Workshop of CONCUR '98)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Helsen S,Thiemann P",,Syntactic Type Soundness for the Region Calculus,Electronic Notes in Theoretical Computer Science,2001,41,3,1-19,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104808703;http://dx.doi.org/10.1016/S1571-0661(04)80870-3,10.1016/S1571-0661(04)80870-3,"The region calculus of Tofte and Talpin is an annotated polymorphically typed lambda calculus which makes memory allocation and deallocation explicit. It is intended as an intermediate language in a compiler for ML-like languages. The region annotations are obtained by static region and effect inference, which makes it an attractive alternative for garbage collection. Soundness of the region and effect system is crucial to guarantee safe deallocation of regions, i.e. deallocation should only take place for objects which are provable dead. Tofte and Talpin have proved type soundness of the region calculus using rule-based co-induction. This proof is quite complicated and not very intuitive. Much of the problem lies in the low-level big-step operational semantics which involves manipulations of an explicit store and which has a co-inductive definition. In this paper, we present a small-step operational semantics for the region calculus, based on syntactic rewriting. We prove type soundness following the approach of Wright and Felleisen, leading to very simple inductive proofs.",,"HOOTS 2000, 4th International Workshop on Higher Order Operational Techniques in Semantics (Satellite to PLI 2000)",,,,,,,,,,,,,,,,,,,,
Book Chapter,Conrad E,Conrad E,Chapter 8 - Domain 8: Application Development Security,,2011,,,129-145,,Syngress,Boston,Eleventh Hour CISSP,2011,9781597495660,,https://www.sciencedirect.com/science/article/pii/B9781597495660000084;http://dx.doi.org/10.1016/B978-1-59749-566-0.00008-4,10.1016/B978-1-59749-566-0.00008-4,"Publisher Summary This chapter explores how to develop software that is robust and secure. It covers programming fundamentals such as compiled versus interpreted languages as well as procedural and object-oriented programming languages. As computers have become more powerful and ubiquitous, the process and methods used to create software have grown and changed. As software has grown in complexity, programming has increasingly become a team effort. Team-based projects require project management: to provide a framework with deliverables and milestones, to divvy up tasks, direct team communication, evaluate and report progress, and deliver a final product. Application development models such as the Waterfall Model, the Spiral Model, eXtreme Programming (XP), and others are also discussed. Ultimately, large application development projects may closely resemble projects that have nothing to do with software, such as widget production or bridge building. Development methods such as the Waterfall and Spiral Models are often close cousins to non-programming models. They can be thought of as project management methods, with additional features to support code writing. The chapter also describes common software vulnerabilities, ways to test for them, and maturity frameworks to assess the maturity of the programming process and provides ways to improve it. The use of a formal methodology for developing software followed by a rigorous testing regimen is best practice. The five steps of the Capability Maturity Model (CMM) mimic the process most programming organizations follow, from informal to mature, always seeking improvement: initial, repeatable, defined, managed, and optimized.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Najm E,Stefani JB","Parker KR,Rose GA",Dynamic Configuration in LOTOS,,1992,,,201-216,,Elsevier,Amsterdam,"Formal Description Techniques, IV",1992,9780444894021,,https://www.sciencedirect.com/science/article/pii/B9780444894021500242;http://dx.doi.org/10.1016/B978-0-444-89402-1.50024-2,10.1016/B978-0-444-89402-1.50024-2,"Distributed Systems offer new challenges and and new opportunities for the application of Formal Description Techniques (FDTs). Dynamic Reconfigurtion of Systems (either predicted or spontaneous) is one of the major issues to be addressed. The process part of LOTOS is based on a CCS-like process calculus, and, as such, lacks the basic dynamic reconfiguration capabilities. Such capabilities are naturally mirrored in Object Based languages and in Milner's & al π-calculus. In the paper, we demonstrate that when one considers Full LOTOS, i.e., LOTOS including Act One and Value-Passing, these capabilities can be modelled. OL1 is a simple language designed to exhibit the essential dynamic characteristics of object-based languages. A semantics preserving translation of OL1 into LOTOS is given. A major “byproduct” of this translation is the definition of a new specification style for LOTOS: the object-based style.",,,IFIP Transactions C: Communication Systems,,,,,,,,,,,,,,,,,,,
Journal Article,Winkel R,,Generalized Bernstein Polynomials and Bézier Curves: An Application of Umbral Calculus to Computer Aided Geometric Design,Advances in Applied Mathematics,2001,27,1,51-81,,,,,2001,,0196-8858,https://www.sciencedirect.com/science/article/pii/S0196885801907262;http://dx.doi.org/10.1006/aama.2001.0726,10.1006/aama.2001.0726,The umbral calculus is used to generalize Bernstein polynomials and Bézier curves. This adds great geometric flexibility to these fundamental objects of computer aided geometric design while retaining their basic properties.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Korobko AV,Penkova TG",,On-line analytical processing based on formal concept analysis,Procedia Computer Science,2010,1,1,2311-2317,,,,,2010,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050910002607;http://dx.doi.org/10.1016/j.procs.2010.04.259,10.1016/j.procs.2010.04.259,An approach to analytical decision making support based on integration of OLAP technology and Formal Concept Analysis is suggested in this paper. The base of domain OLAP modeling is considered. The construction of an analytical model with expert knowledge as a lattice of formal cube-concepts is described formally. The use of the suggested approach for constructing an analytical model of municipal procurement procedures is represented. The constructed integral analytical model of domain includes all possible combinations of analyzed objects and gives opportunity ad-hoc manipulation of them.,"Decision making support, On-line analytical processing, Formal concept analysis, Municipal procurement, OLAP",ICCS 2010,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ren R,Wei L",,The attribute reductions of three-way concept lattices,Knowledge-Based Systems,2016,99,,92-102,,,,,2016,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705116000757;http://dx.doi.org/10.1016/j.knosys.2016.01.045,10.1016/j.knosys.2016.01.045,"Three-way concept analysis is a newly proposed area of formal concept analysis from which one can obtain both the inclusion decision and the exclusion decision. In general, given a context, some attributes may not be essential in three-way concept analysis, such as forming three-way concept lattice. So in this paper, we study the attribute reductions of three-way concept lattices in order to make the data easily be understood. Firstly, based on different criteria generated from object-induced three-way concept (OE-concept), four kinds of attribute reductions are proposed. The four reductions together embody different characteristics of a formal context and can be used in different occasions. Secondly, we discuss their relationships, including their advantages and disadvantages and the relationships among consistent sets and among the cores. Thirdly, based on attribute-induced three-way concept (AE-concept), we also give four attribute-induced three-way attribute reductions and discuss their relationships. Finally, the approaches to computing these attribute reductions are presented and the obtained results are demonstrated and verified by an empirical case. In this paper, we systematically investigate the attribute reductions of three-way concept lattices which enriches the study of formal concept analysis.","Three-way concept, Attribute reduction, Irreducible element, Object-induced three-way object concept, Attribute-induced three-way attribute concept, Discernibility attribute set",,,,,,,,,,,,,,,,,,,,,
Journal Article,Michel O,,Design and implementation of 812: A declarative data-parallel language,Computer Languages,1996,22,2,165-179,,,,,1996,,0096-0551,https://www.sciencedirect.com/science/article/pii/S0096055196000124;http://dx.doi.org/10.1016/S0096-0551(96)00012-4,10.1016/S0096-0551(96)00012-4,"In this article we advocate a declarative approach to data-parallelism to provide both parallelism expressiveness and efficient execution of data intensive applications. 812, an experimental language combining features of collection and stream oriented languages in a declarative framework, is presented. A new structure, the web, allows the programmer to write programmes as mathematical expressions and to implicitly express data and control parallelism. The first part of this paper proposes a classification of the various expressions of parallelism in programming languages. We show that hybrid execution models combining both data and control parallelism are possible and necessary to get an effective speedup. We sketch the advantage of the declarative style with respect to parallelism expression (application side) and exploitation (compiler side). In the second part we describe the 812 language and the concepts of collection, stream and web. A web is a multi-dimensional object that represents the successive values of a structured set of variables. Some 812 programmes are given to show the relevance of the web data structure for simulation applications (a resolution of O.D.P.E. and a simulation in artificial life). Examples of 812 programmes, involving the dynamic creation and destruction of webs, are also given. Such programmes are necessary for simulations of growing systems. In the third part, the implementation of a compiler restricted to the static part of the language is described. We focus on the process of web equations compilation towards a virtual SIMD machine. We also present the clock calculus, the scheduling inference and the distribution of the computations among the processing elements of a parallel computer.","data-parallelism, declarative languages, collection-oriented languages, synchronous data-flow, recursive collection, data-distribution and scheduling",Parallel Logic Programming,,,,,,,,,,,,,,,,,,,,
Journal Article,"Park KB,Choi SH,Kim M,Lee JY",,Deep learning-based mobile augmented reality for task assistance using 3D spatial mapping and snapshot-based RGB-D data,Computers & Industrial Engineering,2020,146,,106585,,,,,2020,,0360-8352,https://www.sciencedirect.com/science/article/pii/S0360835220303193;http://dx.doi.org/10.1016/j.cie.2020.106585,10.1016/j.cie.2020.106585,"This paper proposes a new deep learning-based mobile AR for intelligent task assistance by conducting 3D spatial mapping without pre-registration using AR markers, which can match virtual AR objects to their corresponding physical objects automatically and accurately using single snapshot-based RGB-D data. Firstly, the proposed approach applies a deep learning-based instance segmentation method to the snapshot-based RGB-D data to detect real object instances and to segment their surrounding regions in 3D point cloud data. Then, an iterative closest point (ICP) algorithm is used to perform a 3D spatial mapping between the segmented point cloud of the real object and its corresponding virtual model. Therefore, the virtual information can be seamlessly and automatically synchronized with its corresponding real object. To prove the effectiveness of the proposed method, we performed comparative experiments quantitatively and qualitatively, which evaluated the accuracy, basic task performance, and usability. Experimental results verify that the proposed deep learning-based 3D spatial mapping approach is more accurate and more suitable for mobile AR-based visualization and interaction than previous studies. We have also implemented several applications in actual working situations, which verifies the applicability and extensibility of the proposed approach.","Mobile augmented reality (AR), Spatial mapping, Deep learning-based AR, Task assistance",,,,,,,,,,,,,,,,,,,,,
Book Chapter,van Benthem Jutting LS,"Nederpelt RP,Geuvers JH,de Vrijer RC",A Normal Form Theorem in a λ-Calculus with Types,,1994,133,,371-374,,Elsevier,,Selected Papers on Automath,1994,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08702155;http://dx.doi.org/10.1016/S0049-237X(08)70215-5,10.1016/S0049-237X(08)70215-5,"Publisher Summary This chapter discusses a normal form theorem in a λ–calculus with types. In a λ–calculus closely resembling Automath, every correct expression has a normal form. The proof proceeds along the lines and uses a norm. Every expression in Automath has a normal form. This theorem makes it possible to decide whether two expressions are “equal”. It can be deduced that two expressions are “equal” if they have the same normal form. This helps in proving that correctness of Automath expressions is decidable. Intuitively, expressions may be thought of as denoting objects. The expressions are: 3–expressions, 2–expressions, and 1–expressions. Intuitively 3–expressions denote mathematical object, 2–expressions denote classes to which mathematical objects belong, and 1–expressions denote superclasses to which classes belong. Every mathematical object belongs to exactly one class and every class to exactly one superclass. A correct expression does not contain free variables or undefined constants.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Bottreau A,Bucchianico AD,Loeb DE",,Computer algebra and Umbral Calculus,Discrete Mathematics,1998,180,1,65-72,,,,,1998,,0012-365X,https://www.sciencedirect.com/science/article/pii/S0012365X97001088;http://dx.doi.org/10.1016/S0012-365X(97)00108-8,10.1016/S0012-365X(97)00108-8,Rota's Umbral Calculus uses sequences of Sheffer polynomials to count certain combinatorial objects. We review this theory and some of its generalizations in light of our computer implementation (Maple V.3). A Mathematica version of this package is being developed in parallel.,05A40,Proceedings of the 7th Conference on Formal Power Series and Algebraic Combinatorics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shivhare R,Kumar CA",,On the Cognitive Process of Abstraction,Procedia Computer Science,2016,89,,243-252,,,,,2016,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050916311164;http://dx.doi.org/10.1016/j.procs.2016.06.051,10.1016/j.procs.2016.06.051,"Concepts are the basic elements of propositions. Concepts can be best understood as constituted by its subset of objects (Extent) and subset of attributes (Intent). Psychological capacities of human mind for example, learning, thinking, memorizing can be performed by concepts and their association. In this paper, we will explain how human will be able to generalize concrete concepts of Formal Concept Analysis into abstract concepts. In particular, we model the functionalities of concept algebra by making use of Formal Concept Analysis; we illustrate the proposed model with experiments on sample context. This model simulates the thinking process of human mind.","Abstraction, Cognitive Informatics, Concept Algebra, Formal Concept Analysis.","Twelfth International Conference on Communication Networks, ICCN 2016, August 19– 21, 2016, Bangalore, India Twelfth International Conference on Data Mining and Warehousing, ICDMW 2016, August 19-21, 2016, Bangalore, India Twelfth International Conference on Image and Signal Processing, ICISP 2016, August 19-21, 2016, Bangalore, India",,,,,,,,,,,,,,,,,,,,
Journal Article,"Chen KY,Srivastava HM",,Some Infinite Series and Functional Relations That Arose in the Context of Fractional Calculus,Journal of Mathematical Analysis and Applications,2000,252,1,376-388,,,,,2000,,0022-247X,https://www.sciencedirect.com/science/article/pii/S0022247X00970793;http://dx.doi.org/10.1006/jmaa.2000.7079,10.1006/jmaa.2000.7079,Several interesting infinite series relations were derived recently by applying such operators of fractional calculus as the familiar Riemann–Liouville fractional differintegral operator 0Dμz of (real or complex) order μ. The main object of this paper is to present much simpler alternative derivations of substantially more general families of infinite series relations without using fractional calculus. Some relevant connections among various known results are also provided.,"fractional calculus, Psi (or Digamma) functions, generalized hypergeometric functions, functional relations, -functions, Mellin–Barnes contour integral",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Muro PR,Villarroel JL,Silva M","Puente EA,Nemes L",A KNOWLEDGE REPRESENTATION ENVIRONMENT FOR MANUFACTURING CONTROL SYSTEMS DESIGN AND PROTOTYPING,,1990,,,471-475,,Pergamon,Oxford,Information Control Problems in Manufacturing Technology 1989,1990,9780080370231,,https://www.sciencedirect.com/science/article/pii/B9780080370231500832;http://dx.doi.org/10.1016/B978-0-08-037023-1.50083-2,10.1016/B978-0-08-037023-1.50083-2,"This paper presents some key ideas of a project on a design environment for manufacturing systems control. It is based on a tool hierarchy which integrates different techniques. The kernel is a knowledge representation language, called KRON, which embeddes three methodologies: frame based representation techniques, object oriented programming and High Level Petri Nets (HLPN). MIKRON, a manufacturing oriented tool, is built on top of KRON. A single model built using MIKRON can be used at different levels of a control hierarchy (coordination, scheduling and planning). It offers the graphic and formal expresion capacity of HLPN, as a mean of systematizing, formalizing the interconnection, synchronization and causal relations, as well as the information flow produced by the activity execution. Facilitates the integration of AI techniques for solving scheduling and planning problems. In addition, this tool supports the model execution and simulation.",,,IFAC Symposia Series,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferro N,Silvello G",,NESTOR: A formal model for digital archives,Information Processing & Management,2013,49,6,1206-1240,,,,,2013,,0306-4573,https://www.sciencedirect.com/science/article/pii/S0306457313000502;http://dx.doi.org/10.1016/j.ipm.2013.05.001,10.1016/j.ipm.2013.05.001,"Archives are an extremely valuable part of our cultural heritage since they represent the trace of the activities of a physical or juridical person in the course of their business. Despite their importance, the models and technologies that have been developed over the past two decades in the Digital Library (DL) field have not been specifically tailored to archives. This is especially true when it comes to formal and foundational frameworks, as the Streams, Structures, Spaces, Scenarios, Societies (5S) model is. Therefore, we propose an innovative formal model, called NEsted SeTs for Object hieRarchies (NESTOR), for archives, explicitly built around the concepts of context and hierarchy which play a central role in the archival realm. NESTOR is composed of two set-based data models: the Nested Sets Model (NS-M) and the Inverse Nested Sets Model (INS-M) that express the hierarchical relationships between objects through the inclusion property between sets. We formally study the properties of these models and prove their equivalence with the notion of hierarchy entailed by archives. We then use NESTOR to extend the 5S model in order to take into account the specific features of archives and to tailor the notion of digital library accordingly. This offers the possibility of opening up the full wealth of DL methods and technologies to archives. We demonstrate the impact of NESTOR on this problem through three example use cases.","Foundation, Digital archive, Digital library, Hierarchy, Set-based model, Application",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Zhu H,Zhu H,6 - Typical Architectural Styles,,2005,,,135-172,,Butterworth-Heinemann,Oxford,Software Design Methodology,2005,9780750660754,,https://www.sciencedirect.com/science/article/pii/B9780750660754500091;http://dx.doi.org/10.1016/B978-075066075-4/50009-1,10.1016/B978-075066075-4/50009-1,"Publisher Summary This chapter analyzes a number of software architectural styles. Data flow is a software architectural style that is widely used in various application domains where data processing plays a significant role. The pipe-and-filter architectural style is a special case of data flow style. In the data flow, architecture components are highly independent. There is no global control of the components' behavior. The architectural style of independent components has attracted increasing interest recently for its strong support to software reuse and evolution due to its ease of integration of components into a system. It has a number of sub-types of style including communicating processes, event-based implicit invocation, and multi-agent systems. Call-and-return architecture is the dominant architectural style in large systems. This is directly supported by the classical and current programming paradigms. A number of subtypes of the style have emerged including main-program-and-subroutine with shared data, layered systems, abstract data types, and object–oriented systems. The data-centered architecture refers to systems in which the access and update of a widely accessed data-store is an apt description.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li J,Wong DW",,STModelViz: A 3D spatiotemporal GIS using a constraint-based approach,"Computers, Environment and Urban Systems",2014,45,,34-49,,,,,2014,,0198-9715,https://www.sciencedirect.com/science/article/pii/S0198971514000180;http://dx.doi.org/10.1016/j.compenvurbsys.2014.02.002,10.1016/j.compenvurbsys.2014.02.002,"Advances in data acquisition techniques and model simulations produce increasing volume of 3D spatiotemporal data. However, existing systems provide limited capabilities to manage such data. This paper reports an effort to design and implement a prototype system for 3D spatiotemporal data. Due to the complexity of such data, the ability to verify their integrity is central to the data management system. We adopted a constraint-based approach which addresses data integrity explicitly. In the article, we define constraint conditions, formulate constraints using a formal language we have extended and evaluate constraints using enhanced computational algorithms. We focus on a set of relational integrity constraints pertaining to the spatial, temporal and spatiotemporal properties of 3D spatiotemporal data. We extended the Object Constraint Language (OCL) to handle spatiotemporal (ST) objects. ST–OCL is used to describe and record constraints. Constraints expressed by ST–OCL statements are evaluated by the enhanced algorithms to identify different topological relations between 3D spatiotemporal objects. The prototype system demonstrates how a constraint-based approach can be used to develop DBMS capabilities in managing 3D spatiotemporal objects. Using the dynamic repartitioning of airspace sectors as an application example, we show that the capabilities of the prototype to manage 3D spatiotemporal objects can be customized for specific domain applications.","3D spatiotemporal system, Constraints, Data integrity, Query, Object Constraint Language",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Riehl E,Verity D",,Homotopy coherent adjunctions and the formal theory of monads,Advances in Mathematics,2016,286,,802-888,,,,,2016,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870815003503;http://dx.doi.org/10.1016/j.aim.2015.09.011,10.1016/j.aim.2015.09.011,"In this paper, we introduce a cofibrant simplicial category that we call the free homotopy coherent adjunction and characterise its n-arrows using a graphical calculus that we develop here. The hom-spaces are appropriately fibrant, indeed are nerves of categories, which indicates that all of the expected coherence equations in each dimension are present. To justify our terminology, we prove that any adjunction of quasi-categories extends to a homotopy coherent adjunction and furthermore that these extensions are homotopically unique in the sense that the relevant spaces of extensions are contractible Kan complexes. We extract several simplicial functors from the free homotopy coherent adjunction and show that quasi-categories are closed under weighted limits with these weights. These weighted limits are used to define the homotopy coherent monadic adjunction associated to a homotopy coherent monad. We show that each vertex in the quasi-category of algebras for a homotopy coherent monad is a codescent object of a canonical diagram of free algebras. To conclude, we prove the quasi-categorical monadicity theorem, describing conditions under which the canonical comparison functor from a homotopy coherent adjunction to the associated monadic adjunction is an equivalence of quasi-categories. Our proofs reveal that a mild variant of Beck's argument is “all in the weights”—much of it independent of the quasi-categorical context.","Adjunction, Homotopy coherence, Quasi-categories, Monad, Monadicity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mironov A,Morozov A,Morozov A,Sleptsov A",,Gaussian distribution of LMOV numbers,Nuclear Physics B,2017,924,,1-32,,,,,2017,,0550-3213,https://www.sciencedirect.com/science/article/pii/S0550321317302791;http://dx.doi.org/10.1016/j.nuclphysb.2017.08.016,10.1016/j.nuclphysb.2017.08.016,"Recent advances in knot polynomial calculus allowed us to obtain a huge variety of LMOV integers counting degeneracy of the BPS spectrum of topological theories on the resolved conifold and appearing in the genus expansion of the plethystic logarithm of the Ooguri–Vafa partition functions. Already the very first look at this data reveals that the LMOV numbers are randomly distributed in genus (!) and are very well parameterized by just three parameters depending on the representation, an integer and the knot. We present an accurate formulation and evidence in support of this new puzzling observation about the old puzzling quantities. It probably implies that the BPS states, counted by the LMOV numbers can actually be composites made from some still more elementary objects.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Martínez-Planell R,Trigueros M",,Students’ understanding of Riemann sums for integrals of functions of two variables,The Journal of Mathematical Behavior,2020,59,,100791,,,,,2020,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312320300559;http://dx.doi.org/10.1016/j.jmathb.2020.100791,10.1016/j.jmathb.2020.100791,"In this paper we report on a study of how students understand some of the most fundamental ideas of Riemann integrals of functions of two variables. We apply Action-Process-Object-Schema (APOS) Theory to pose a preliminary genetic decomposition (GD), conjecturing mental constructions that students would need to relate Riemann sums to integrals of functions of two variables over rectangles. The genetic decomposition is informed by the researchers’ classroom experience, findings of a previous study that applied semiotic representation theory, and by a study on integrals of functions of one variable. We pay particular attention to the case of an integral of a continuous function over a rectangle and the simplest partition possible, that consisting only of the rectangle itself. We then explore students’ geometrical understanding of the relation between the single termfa,bΔxΔy, where a,b is a point on the rectangle, and the double integral over the rectangle. We tested the GD by performing student interviews with 10 students who had just finished taking a lecture-based multivariable calculus course. The findings underscore the importance of each of the mental constructions described in the genetic decomposition and suggests that students have difficulty in some mental constructions that may commonly be assumed to be obvious during instruction.","Riemann sums, Calculus, APOS, Double integrals, Function of two variables, Genetic decomposition",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lin S,Tsai YS,Wang PY",,Explicit solutions of a certain class of associated Legendre equations by means of fractional calculus,Applied Mathematics and Computation,2007,187,1,280-289,,,,,2007,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300306011623;http://dx.doi.org/10.1016/j.amc.2006.08.152,10.1016/j.amc.2006.08.152,"In recent years, many authors have demonstrated the usefulness of fractional calculus in the derivation of particular solutions of a number of linear ordinary and partial differential equations of the second and higher orders. The main object of the present paper is to show how several recent contributions on this subject, involving a certain class of associated Legendre equations, can be obtained (in a unified manner) by suitably applying some general theorems on particular solutions of a certain family of linear ordinary fractional differintegral equations.","Fractional calculus, Legendre equations, Generalized Leibniz rule, Analytic functions, Differintegral equations, Ordinary and partial differential equations, Index law, Linearity property, Principal value, Bessel’s equation, Power-series solutions, Legendre polynomials","Proceedings of the International Symposium on Analytic Function Theory, Fractional Calculus and Their Applications in Honour of Professor H.M. Srivastava on his Sixty-Fifth Birth Anniversary",,,,,,,,,,,,,,,,,,,,
Journal Article,"Widynski N,Dubuisson S,Bloch I",,Fuzzy spatial constraints and ranked partitioned sampling approach for multiple object tracking,Computer Vision and Image Understanding,2012,116,10,1076-1094,,,,,2012,,1077-3142,https://www.sciencedirect.com/science/article/pii/S1077314212001038;http://dx.doi.org/10.1016/j.cviu.2012.07.002,10.1016/j.cviu.2012.07.002,"While particle filters are now widely used for object tracking in videos, the case of multiple object tracking still raises a number of issues. Among them, a first, and very important, problem concerns the exponential increase of the number of particles with the number of objects to be tracked, that can make some practical applications intractable. To achieve good tracking performances, we propose to use a Partitioned Sampling method in the estimation process with an additional feature about the ordering sequence in which the objects are processed. We call it Ranked Partitioned Sampling, where the optimal order in which objects should be processed and tracked is estimated jointly with the object state. Another essential point concerns the modeling of possible interactions between objects. As another contribution, we propose to represent these interactions within a formal framework relying on fuzzy sets theory. This allows us to easily model spatial constraints between objects, in a general and formal way. The association of these two contributions was tested on typical videos exhibiting difficult situations such as partial or total occlusions, and appearance or disappearance of objects. We show the benefit of using conjointly these two contributions, in comparison to classical approaches, through multiple object tracking and articulated object tracking experiments on real video sequences. The results show that our approach provides less tracking errors than those obtained with the classical Partitioned Sampling method, without the need for increasing the number of particles.","Multiple object tracking, Particle filter, Fuzzy spatial constraints, Partitioned Sampling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lopes AM,Tenreiro Machado JA",,Multidimensional scaling analysis of generalized mean discrete-time fractional order controllers,Communications in Nonlinear Science and Numerical Simulation,2021,95,,105657,,,,,2021,,1007-5704,https://www.sciencedirect.com/science/article/pii/S1007570420304871;http://dx.doi.org/10.1016/j.cnsns.2020.105657,10.1016/j.cnsns.2020.105657,The dynamics of discrete-time fractional order control systems depends on the method used for implementing the fractional derivatives and integrals. A reliable numerical approach adopts the generalized mean of the continuous to discrete conversion. The extra freedom provided by the proposed method must be carefully optimized by the user. This paper investigates the use of multidimensional scaling for evaluating and visualizing the performance of generalized mean discrete-time fractional controllers. Two alternative performance indices are adopted for comparing the time and frequency responses of the controlled system when adopting different combinations of the parameters. Numerical experiments with a fractional PID and two linear plants demonstrate the feasibility of the method for comparing and visualizing multiple test cases.,"Fractional calculus, Fractional derivative, PID control, Numerical methods",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chen MP,Srivastava HM",,Fractional calculus operators and their applications involving power functions and summation of series,Applied Mathematics and Computation,1997,81,2,287-304,,,,,1997,,0096-3003,https://www.sciencedirect.com/science/article/pii/S009630039500310X;http://dx.doi.org/10.1016/S0096-3003(95)00310-X,10.1016/S0096-3003(95)00310-X,"Many earlier works on the subject of fractional calculus contain interesting accounts of the theory and applications of fractional calculus operators in a number of areas of mathematical analysis (such as ordinary and partial differential equations, integral equations, summation of series, etc.). The main object of this paper is to examine rather systematically (and extensively) some of the most recent contributions on the applications of fractional calculus operators involving power functions and in finding the sums of several interesting families of infinite series. Various other classes of infinite sums found in the mathematical literature by these (or other) means, and their validity or hitherto unnoticed connections with some known results, are also considered.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Csaba ölveczky P,Meseguer J",,"Real-Time Maude: A Tool for Simulating and Analyzing Real-Time and Hybrid Systems1 1Supported by DARPA through Rome Laboratories Contract F30602-C-0312, by Office of Naval Research Contract N00014-99-C-0198, and by National Science Foundation Grant CCR-9900334",Electronic Notes in Theoretical Computer Science,2000,36,,361-382,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105801343;http://dx.doi.org/10.1016/S1571-0661(05)80134-3,10.1016/S1571-0661(05)80134-3,"Rewriting logic can be used to specify a wide range of real-time and hybrid systems under a variety of time models, including discrete and dense time models. The Real-Time Maude tool, built on top of the Maude rewriting logic language, supports specification of real-time and hybrid systems in timed modules and timed object-oriented modules, which are transformed into equivalent Maude modules. The tool then supports execution of such specifications in several rewrite modes, corresponding to different criteria for advancing time. Besides system simulation by default execution in a given rewrite mode, the tool has a library of execution strategies and commands that can search all the possible computations from an initial state, within given rewrite mode and search bounds, to partially model check desired properties, including properties expressible in a class of linear time timed temporal logic formulas. The paper discusses the tool's theoretical basis, its specification language, and its library of evaluation and search strategies. The user can add new formal analysis strategies to the library, as illustrated by a scheduling case study. We also summarize our experience with applications and our future plans.",,The 3rd International Workshop on Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Andrews GE,Paule P,Riese A",,MacMahon’s Partition Analysis: The Omega Package,European Journal of Combinatorics,2001,22,7,887-904,,,,,2001,,0195-6698,https://www.sciencedirect.com/science/article/pii/S019566980190527X;http://dx.doi.org/10.1006/eujc.2001.0527,10.1006/eujc.2001.0527,"In his famous book ‘Combinatory Analysis’ MacMahon introduced Partition Analysis (‘Omega Calculus’) as a computational method for solving problems in connection with linear homogeneous diophantine inequalities and equations. The object of this paper is to show that partition analysis is ideally suited for being implemented in computer algebra. To this end we have developed the computer algebra packageOmega. In addition to an introduction to basic facts of ‘Omega Calculus’, we present a number of applications that illustrate the usage of the package.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Duce DA,Duke DJ,ten Hagen PJ,Herman I,Reynolds GJ",,Formal methods in the development of premo,Computer Standards & Interfaces,1995,17,5,491-509,,,,,1995,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899500023N;http://dx.doi.org/10.1016/0920-5489(95)00023-N,10.1016/0920-5489(95)00023-N,"ISO/IEC JTC1/SC24 are developing a standard for the presentation of multimedia objects, called Premo (Presentation Environments for Multimedia Objects). Premo is a multipart standard, the most well-defined parts of which, at the time of writing, are at the stage of Committee Draft. This paper describes how formal description techniques are being used in the development of the Premo standard, shadowing the development of the standard itself. The approach taken uses a combination of Z and Object-Z. The motivation and merits of this approach are discussed, and illustrated with a description of some fundamental concepts of the Premo object model.",", Formal methods, Multimedia, Object models, Active objects, Z, Object-Z",Formal Description Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,"Flajolet P,Zimmermann P,Van Cutsem B",,A calculus for the random generation of labelled combinatorial structures,Theoretical Computer Science,1994,132,1,1-35,,,,,1994,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397594902267;http://dx.doi.org/10.1016/0304-3975(94)90226-7,10.1016/0304-3975(94)90226-7,"A systematic approach to the random generation of labelled combinatorial objects is presented. It applies to structures that are decomposable, i.e., formally specifiable by grammars involving set, sequence, and cycle constructions. A general strategy is developed for solving the random generation problem with two closely related types of methods: for structures of size n, the boustrophedonic algorithms exhibit a worst-case behaviour of the form O(n log n); the sequential algorithms have worst case O(n2), while offering good potential for optimizations in the average case. The complexity model is in terms of arithmetic operations and both methods appeal to precomputed numerical table of linear size that can be computed in time O(n2). A companion calculus permits systematically to compute the average case cost of the sequential generation algorithm associated to a given specification. Using optimizations dictated by the cost calculus, several random generation algorithms of the sequential type are developed; most of them have expected complexity 1/2n log n, and are thus only slightly superlinear. The approach is exemplified by the random generation of a number of classical combinatorial structures including Cayley trees, hierarchies, the cycle decomposition of permutations, binary trees, functional graphs, surjections, and set partitions.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Castellani I,Palamidessi C",,"Preface: Volume 16, Issue 2",Electronic Notes in Theoretical Computer Science,1998,16,2,171-172,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805663;http://dx.doi.org/10.1016/S1571-0661(05)80566-3,10.1016/S1571-0661(05)80566-3,"This volume contains the Proceedings of the fifth EXPRESS workshop. The workshop was held in Nice, France, on 7 September 1998, as a satellite event to CONCUR '98. The EXPRESS workshops aim at bringing together researchers interested in the relations between various formal systems, particularly in the field of Concurrency. More specifically, they focus on the comparison between programming concepts (such as concurrent, functional, imperative, logic and object-oriented programming) and between mathematical models of computation (such as process algebras, Petri nets, event structures, modal logics, rewrite systems etc.) on the basis of their relative expressive power. These workshops were originally held as meetings of the HCM project EXPRESS, which has been active with the same focus from January 1994 till December 1997. The first three workshops were held respectively in Amsterdam (1994, chaired by Frits Vaandrager), Tarquinia (1995, chaired by Rocco de Nicola), and Dagstuhl (1996, chaired by Ursula Goltz, Frits Vaandrager and Rocco de Nicola). The fourth workshop, which took place in Santa Margherita Ligure in 1997 and was co-chaired by Catuscia Palamidessi and Joachim Parrow, was organized as a conference with a call for papers and a significant attendance from outside the project. The fifth workshop, EXPRESS '98, was again organised as a (one day) conference, and was also meant as an occasion to discuss on the inheritance of the Express project and possible directions of future research. We had 17 submissions, out of which we selected 7 for inclusion in these proceedings (41%). Additionally, this collection contains the contribution of the two invited speakers, Matthew Hennessy (University of Sussex, UK) and P.S. Thiagarajan (SPIC Mathematical Institute, IN). We would like to thank the authors of the submitted papers, the invited speakers, and the members of the program committee for their contribution to both the meeting and this volume. We also would like to thank INRIA for their help with the local organization, and Michael Mislove for his help with the editing of the proceedings. EXPRESS '98 Programme CommitteeIlaria Castellani (co-chair, INRIA)Catuscia Palamidessi (co-chair, PSU)Luca Aceto (Aalborg Univ.)Roberto Amadio (Univ. Marseille)Eike Best (Oldenburg Univ.)Steve Brookes (CMU)Philippe Darondeau (INRIA)Rocco De Nicola (Univ. Firenze)Jan Willem Klop (CWI)Patrick Lincoln (SRI)Frits Vaandrager (Nijmegen Univ.)Glynn Winskel (Aarhus Univ.) 17 October 1998, Ilaria Castellani and Catuscia Palamidessi",,"EXPRESS '98, Fifth International Workshop on Expressiveness in Concurrency (Satellite Workshop of CONCUR '98)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Salinas de Romero S,Srivastava HM",,Some applications of fractional calculus involving summation of infinite series,Applied Mathematics and Computation,1998,90,2,129-142,,,,,1998,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300397003949;http://dx.doi.org/10.1016/S0096-3003(97)00394-9,10.1016/S0096-3003(97)00394-9,"A significantly large number of earlier works on the subject of fractional calculus give interesting accounts of the theory and applications of fractional calculus operators in many different areas of mathematical analysis (such as ordinary and partial differential equations, integral equations, special functions, summation of series, et cetera). The main object of the present paper is to examine rather systematically (and extensively) some of the most recent contributions on the applications of fractional calculus operators in finding the sums of an interesting family of infinite series. Various further generalizations, relevant to the present investigation, are also given.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Valette E,Demesure G,El-Haouzi HB,Pannequin R",,Formal and modelling frameworks for Social Holonic Control Architectures,Computers in Industry,2021,132,,103521,,,,,2021,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361521001287;http://dx.doi.org/10.1016/j.compind.2021.103521,10.1016/j.compind.2021.103521,"For decades now, manufacturing systems have grown in size and complexity. Between new consumption habits and hypercompetitive markets, manufacturing systems have started a race towards the industry of the future. Still, many technological and societal issues are paving their way: connectivity, resilience and human integration being among the most critical ones. The idea of this paper is to bring a new framework to help answering these issues by bringing resilience to systems, improving their interoperability, enhancing Data acquisition, transmission & processing, enabling the establishment hierarchical levels among agents, or by facilitating the system acceptance by human agents and the human integration within the system. To this end, this article brings a new formal framework for Social Holonic Control Architectures, based on an analysis of the existing literature. An UML-based modelling framework will equally be proposed to ease understanding and implementation of this new Social Holonic Control Architecture, illustrated by a concrete application on a small-scale Multi-Agent System.","Social holonic control architectures, Industry 4.0, Social relationships, Multi-agent system, UML modelling framework",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Xiu L,Wu J,Liu Z,Ma J,Fan X,Ji H",,Welding distortion control technology in CFETR vacuum vessel,Fusion Engineering and Design,2020,160,,111851,,,,,2020,,0920-3796,https://www.sciencedirect.com/science/article/pii/S0920379620303999;http://dx.doi.org/10.1016/j.fusengdes.2020.111851,10.1016/j.fusengdes.2020.111851,"The vacuum vessel is very important component for China Fusion Engineering Test Reactor (CFETR), it is a double-layer shell structure with complex contour. The vacuum vessel is mainly formed by welding, which requires high precision of forming dimension. Welding distortion brings difficulties to the forming dimension control of vacuum vessel, so it is necessary to control the welding distortion in the progress of vacuum vessel welding. In this paper, many kinds of welding distortion control methods used in CFETR vacuum vessel manufacturing are introduced, and the application objects and key technology of each welding distortion control method are given. To accumulate experience for the formal CFETR vacuum vessel construction, and provide reference for other similar engineering construction.","CFETR, Vacuum vessel, Welding distortion, Inherent strain",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Sips HJ,van Reeuwijk K","Joubert GR,Nagel WE,Peters FJ,Walter WV",An integrated annotation and compilation framework for task and data parallel programming in Java,,2004,13,,111-118,,North-Holland,,Parallel Computing,2004,,0927-5452,https://www.sciencedirect.com/science/article/pii/S0927545204800170;http://dx.doi.org/10.1016/S0927-5452(04)80017-0,10.1016/S0927-5452(04)80017-0,"Publisher Summary This chapter discusses a unified model to describe data and task parallelism in an object oriented language. The approach allows compile-time and run-time techniques to be combined. Statements, expressions, types, declarations, formal parameters, and the entire program can be annotated with pragmas. Spar provides a general annotation mechanism. An annotation consists of a list of pragmas. These pragmas allow the user to give the compiler information about the program, and give hints for efficient compilation. By convention, a pragma does not influence the behavior of a program; it only improves the efficiency of the program in terms of execution time, memory use, or any other measure. To help the compiler with the parallelization of a program, the user may annotate a program with pragmas to specify the distribution of data, or the place where a block of code is executed. Titanium provides vectors, multidimensional arrays, iteration ranges, and a foreach statement comparable to those in Spar. In most cases, the Spar version of these constructs is more general. They explicitly state that their foreach is not intended for parallelization. Titanium supports iterations over arbitrary sets; moreover these iteration ranges are “first-class citizens”, they can be handled and modified independent of any loop statements. Spar's iteration ranges are more general than the rectangular iteration sets of Titanium, and can be implemented just as efficiently.",,,Advances in Parallel Computing,,,,,,,,,,,,,,,,,,,
Journal Article,"Cao Y,Huang Z,Ke C,Xie J,Wang J",,A topology-aware access control model for collaborative cyber-physical spaces: Specification and verification,Computers & Security,2019,87,,101478,,,,,2019,,0167-4048,https://www.sciencedirect.com/science/article/pii/S0167404818310861;http://dx.doi.org/10.1016/j.cose.2019.02.013,10.1016/j.cose.2019.02.013,"In collaborative environment, distributed multiple cyber-physical spaces interoperate with each other aiming to provide an intelligent spatial environment for their users to conduct their collaborative activities. Subjects and objects roam in the physical and cyber spaces among domains to support the completion of the activities. These dynamic behaviors bring great challenges to security issue. The actions of roaming subjects and roaming objects need to be specified and checked against security requirements of constituent domains. However, the existing inter-domain access control models was proposed for the traditional information system and focus on the cyber security. They cannot deal with the intricacies of cross-domain access requests in cyber-physical spaces. In this paper, we propose a formal inter-domain model to specify cyber-physical access control policies and a model checking approach to ensure security requirements hold in these policies. We first present a formal definition of the topology configuration to capture the environment characteristics of the cyber-physical spaces. It provides important contextual information for the access control system. Then, based on topology attributes defined in the topology configuration, a topology-aware inter-domain access control model TA-CPAC is proposed. It can adjust the permission assignment adaptively to react to the behaviors changes of subjects and objects. Next, the topology configuration and TA-CPAC model are formalized by the use of bigraphs and bigraphs reactive systems respectively, which allows us to utilize the model checking technology to reason about that whether the behaviors of roaming subjects and objects satisfy security requirements of all constituent domains. Finally, the effectiveness of our approach is evaluated by a collaborative scenario in a smart city.","Cross-domain authorization, Access control, Cyber-physical space, Bigraphs, Model checking",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Choi SH,Kim M,Lee JY",,Situation-dependent remote AR collaborations: Image-based collaboration using a 3D perspective map and live video-based collaboration with a synchronized VR mode,Computers in Industry,2018,101,,51-66,,,,,2018,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361517305419;http://dx.doi.org/10.1016/j.compind.2018.06.006,10.1016/j.compind.2018.06.006,"The development of the Internet and smart devices has made it possible to support remote collaborations, which allows the expert and the worker to share information and co-work together in various and dispersed industrial fields. However, collaborations that exchange only audio and video information have limitations in the guided instruction of tasks, training of workers, and understanding of the situation. As augmented reality (AR) technology is considered to provide a more intuitive and immersive visualization and interaction in physical workspaces, many research works have been conducted to integrate AR into remote collaboration. Usually, there are two different types of AR collaboration depending on the shared media: 1) image-based AR collaboration and 2) live video-based AR collaboration. However, most of the previous research works cannot effectively support not only visual augmentation suitable for the situation but also accurate and effective annotations in the shared AR space. In this paper, we propose a situation-dependent remote AR collaboration approach that can selectively support either image- or live video-based AR collaborations: 1) image-based AR collaboration using a 3D perspective map and 2) live video-based AR collaboration with a synchronized VR mode. In particular, in the case of a certain situation with a limited network connection or limited HW/SW capabilities of the smart device, the image-based AR collaboration is more preferred. However, existing approaches cannot provide an integrated AR space from shared images. The proposed image-based AR collaboration enables to construct a 3D perspective map from the shared images taken in three or more directions, which can provide an integrated AR space for more effective AR annotations for remote collaboration. In the case of a normal situation without such problems, the live video-based AR collaboration should be supported. However, previous works have inherent problems such as inaccurate and mismatched AR annotations when the viewpoint of the live video is changed. The proposed live video-based AR collaboration with a synchronized VR mode can provide more effective and accurate 3D annotations by synchronizing virtual objects with physical objects. In particular, the VR mode can provide a complementing VR view of the AR-based physical space. In addition, through quantitative and qualitative experimental evaluation, we have conducted comparative studies with previous works. The results of this research show that the approach presented in this research has higher qualitative evaluation such as human behavior and task usability, as well as higher quantitative evaluation such as task performance and accuracy. Therefore, it is expected that the proposed approach can provide more user-oriented collaboration that considers user's situation and device performance in various industrial applications.","Remote collaboration, Augmented reality, Visual annotation, Image-based AR collaboration, Live video-based AR collaboration",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kahn MG,Tu S,Fagan LM",,TQuery: A context-sensitive temporal query language,Computers and Biomedical Research,1991,24,5,401-419,,,,,1991,,0010-4809,https://www.sciencedirect.com/science/article/pii/001048099190016P;http://dx.doi.org/10.1016/0010-4809(91)90016-P,10.1016/0010-4809(91)90016-P,"Users of electronic medical databases request pertinent information by recasting their clinical questions into a formal database query language. Because the query language is the user's only access to the data, the query language must be powerful enough to enable users to express their data requirements. However, a competing need is for the query language to be restrictive enough so that queries can have unambiguous semantics and the query processor can generate correct answers. We describe a query language, called TQuery, that was designed specifically to formulate database queries that are dependent on temporal and contextual relationships. TQuery specifications express contextual constraints without the need to explicitly reference calendar dates. TQuery is the database query language used to retrieve patient data from an object-oriented electronic patient medical-record system called rhe temporal network (TNET). TNET and TQuery were developed to support the real-time temporal reasoning and representation needs of a LISP workstation-based medical expert system.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kyas M,Fecher H,de Boer FS,Jacob J,Hooman J,van der Zwaag M,Arons T,Kugler H",,Formalizing UML Models and OCL Constraints in PVS,Electronic Notes in Theoretical Computer Science,2005,115,,39-47,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104053150;http://dx.doi.org/10.1016/j.entcs.2004.09.027,10.1016/j.entcs.2004.09.027,"The Object Constraint Language (OCL) is the established language for the specification of properties of objects and object structures in UML models. One reason that it is not yet widely adopted in industry is the lack of proper and integrated tool support for OCL. Therefore, we present a prototype tool, which analyzes the syntax and semantics of OCL constraints together with a UML model and translates them into the language of the theorem prover PVS. This defines a formal semantics for both UML and OCL, and enables the formal verification of systems modeled in UML. We handle the problematic fact that OCL is based on a three-valued logic, whereas PVS is only based on a two valued one.","OCL, PVS, Formal Verification, Formal Semantics, UML",Proceedings of the Second Workshop on Semantic Foundations of Engineering Design Languages (SFEDL 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Garousi V,Fernandes JM",,Highly-cited papers in software engineering: The top-100,Information and Software Technology,2016,71,,108-128,,,,,2016,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584915001871;http://dx.doi.org/10.1016/j.infsof.2015.11.003,10.1016/j.infsof.2015.11.003,"Context According to the search reported in this paper, as of this writing (May 2015), a very large number of papers (more than 70,000) have been published in the area of Software Engineering (SE) since its inception in 1968. Citations are crucial in any research area to position the work and to build on the work of others. Identification and characterization of highly-cited papers are common and are regularly reported in various disciplines. Objective The objective of this study is to identify the papers in the area of SE that have influenced others the most as measured by citation count. Studying highly-cited SE papers helps researchers to see the type of approaches and research methods presented and applied in such papers, so as to be able to learn from them to write higher quality papers which will likely receive high citations. Method To achieve the above objective, we conducted a study, comprised of five research questions, to identify and classify the top-100 highly-cited SE papers in terms of two metrics: total number of citations and average annual number of citations. Results By total number of citations, the top paper is \A metrics suite for object-oriented design\""",cited 1817 times and published in 1994. By average annual number of citations,"the top paper is \""QoS-aware middleware for Web services composition\""","cited 154.2 times on average annually and published in 2004. Conclusion It is concluded that it is important to identify the highly-cited SE papers and also to characterize the overall citation landscape in the SE field. We hope that this paper will encourage further discussions in the SE community towards further analysis and formal characterization of the highly-cited SE papers.""","Software engineering, Highly-cited papers, Top cited, Most cited, Most frequently cited, Bibliometrics",,,,,,,,,,,,,,,,,,
Journal Article,"Tu ST,Wu TC,Srivastava HM",,Commutativity of the Leibniz rules in fractional calculus,Computers & Mathematics with Applications,2000,40,2,303-312,,,,,2000,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122100001620;http://dx.doi.org/10.1016/S0898-1221(00)00162-0,10.1016/S0898-1221(00)00162-0,"Many earlier works on the subject of fractional calculus (that is, differentiation and integration of an arbitrary real or complex order) provide interesting accounts of the theory and applications of fractional calculus operators in several areas of mathematical analysis (such as ordinary and partial differential equations, integral equations, special functions, summation of series, etc.). The main object of this sequel to the aforementioned works is to examine rather closely the commutativity of the familiar Leibniz rules for fractional calculus and its various consequences. Some generalizations of a recent result of Tu, Chyan and Wu [1], involving fractional integration of powers of the logarithmic functions, are also considered.","Fractional calculus, Psi (or Digamma) function, Leibniz rules, Hypergeometric functions, Analytic continuation formulas, Hypergeometric transformations, Jacobi polynomials, Hypergeometric representations, Hypergeometric polynomials",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Corradini F,Muzi C,Re B,Rossi L,Tiezzi F",,Formalising and animating multiple instances in BPMN collaborations,Information Systems,2022,103,,101459,,,,,2022,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437919305113;http://dx.doi.org/10.1016/j.is.2019.101459,10.1016/j.is.2019.101459,"The increasing adoption of modelling methods contributes to a better understanding of the flow of processes, from the internal behaviour of a single organisation to a wider perspective where several organisations exchange messages. In this regard, BPMN collaborations provide a suitable modelling abstraction. Even if this is a widely accepted notation, only a limited effort has been expended in formalising its semantics, especially for what it concerns the interplay among control features, data handling and exchange of messages in scenarios requiring multiple instances of interacting participants. In this paper, we face the problem of providing a formal semantics for BPMN collaborations including elements dealing with multiple instances, i.e., multi-instance pools and sequential/parallel multi-instance tasks. For an accurate account of these features, it is necessary to consider the data perspective of collaboration models, thus supporting data objects, data collections and data stores, and different execution modalities of tasks concerning atomicity and concurrency. Beyond defining a novel formalisation, we also provide a BPMN collaboration animator tool, named MIDA, faithfully implementing the formal semantics. MIDA can also support designers in debugging multi-instance collaboration models.","BPMN 2.0, Multiple instances, Data, Formal semantics, Animation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kumar K,List F,Pop IS,Radu FA",,Formal upscaling and numerical validation of unsaturated flow models in fractured porous media,Journal of Computational Physics,2020,407,,109138,,,,,2020,,0021-9991,https://www.sciencedirect.com/science/article/pii/S0021999119308435;http://dx.doi.org/10.1016/j.jcp.2019.109138,10.1016/j.jcp.2019.109138,"In this work, we consider a mathematical model for describing flow in an unsaturated porous medium containing a fracture. Both the flow in the fracture as well as in the matrix blocks are governed by Richards' equation coupled by natural transmission conditions. Using formal asymptotics, we derive upscaled models as the limit of vanishing ε, the ratio of the width and length of the fracture. Our results show that the ratio of porosities and permeabilities in the fracture to matrix determine, to the leading order of approximation, the appropriate effective model. In these models the fracture is a lower dimensional object for which different transversally averaged models are derived depending on the ratio of the porosities and permeabilities of the fracture and respective matrix blocks. We obtain a catalogue of effective models which are validated by numerical computations.","Richards' equation, Fractured porous media, Upscaling, Unsaturated flow in porous media",,,,,,,,,,,,,,,,,,,,,
Journal Article,Aouf MK,,Certain subclasses of p-valent starlike functions defined by using a differential operator,Applied Mathematics and Computation,2008,206,2,867-875,,,,,2008,,0096-3003,https://www.sciencedirect.com/science/article/pii/S009630030800708X;http://dx.doi.org/10.1016/j.amc.2008.09.048,10.1016/j.amc.2008.09.048,"The object of this paper is to introduce two interesting subclasses Tn∗(p,q,α,β,γ) and Cn(p,q,α,β,γ) of p-valent starlike functions defined by using a differential operator. We obtain coefficient estimates and distortion theorems for functions belonging to these classes. The radii of convexity for functions belonging to these classes are also determined. Finally, several applications involving an integral operator and certain fractional calculus operator are also considered.","p-Valent functions, Starlike, Convex, Differential operator, Fractional calculus","Includes Special issue on Modeling, Simulation, and Applied Optimization (ICMSAO-07",,,,,,,,,,,,,,,,,,,,
Journal Article,"Bezem M,Hovland D,Truong H",,A type system for counting instances of software components,Theoretical Computer Science,2012,458,,29-48,,,,,2012,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397512007414;http://dx.doi.org/10.1016/j.tcs.2012.07.032,10.1016/j.tcs.2012.07.032,"We identify an abstract language for component software based on process algebra. Besides the usual operators for sequential, alternative and parallel composition, it has primitives for instantiating components and for deleting instances of components. We define an operational semantics for our language and give a type system in which types express quantitative information on the components involved in the execution of the expressions of the language. Included in this information is for each component the maximum number of instances that are simultaneously active during the execution of the expression. The type system is compositional by the novel use of ‘deficit types’. The type inference algorithm runs in time quadratic in the size of the input. We consider extensions of the language with loops and tail recursion, and with a scope mechanism. We illustrate the approach with some examples, one on UML diagram refinement and one on counting objects on the free store in C++.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Arusoaie A,Lucanu D,Rusu V",,Towards a K Semantics for OCL,Electronic Notes in Theoretical Computer Science,2014,304,,81-96,,,,,2014,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066114000401;http://dx.doi.org/10.1016/j.entcs.2014.05.004,10.1016/j.entcs.2014.05.004,"We give a formal definition to a significant subset of the Object Constraint Language (ocl) in the K framework. The chosen subset includes the usual arithmetical, Boolean (including quantifiers), and string expressions; collection expressions (including iterators and navigation); and pre/post conditions for methods. Being executable, our definition provides us, for free, with an interpreter for the chosen subset of ocl. It can be used for free in K definitions of languages having ocl as a component We illustrate some of the advantages of K by comparing our semantical definition of ocl with the official semantics from the language's standard. We also report on a tool implementing our definition that users can try online.","Object constraint language, Formal executable semantics, semantic framework",Proceedings of the Second International Workshop on the K Framework and its Applications (K 2011).,,,,,,,,,,,,,,,,,,,,
Journal Article,Ciancarini P,,Parallel programming with logic languages: A survey,Computer Languages,1992,17,4,213-239,,,,,1992,,0096-0551,https://www.sciencedirect.com/science/article/pii/009605519290013D;http://dx.doi.org/10.1016/0096-0551(92)90013-D,10.1016/0096-0551(92)90013-D,"Formal properties of logic languages are largely studied; however, their impact on the practice of software design and programming is currently minimal. In this paper we survey some interesting representatives of the family of logic languages aiming at comparing the different capabilities they offer for designing and programming parallel systems. The logic languages Prolog, Aurora, Flat Concurrent Prolog, Parlog, GHC, and DeltaProlog were chosen, because a suitable set of relevant examples has been published, mostly by the language designers themselves. A number of sample programs is used to expose and compare the languages with respect to their object oriented programming capabilities for multiprocess coordination, interprocess communication, and resource management. Special attention is devoted also to metaprogramming as well, seen as a useful technique for specifying and building the operating environments of the languages themselves. The paper ends with a discussion on positive and negative features found comparing these languages, and indicates some guidelines to be followed in the design of new logic languages.","Concurrent languages, Language design, Logic programming, Metaprogramming",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Maxim L,Schürmann J",,Plethysm and cohomology representations of external and symmetric products,Advances in Mathematics,2020,375,,107373,,,,,2020,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870820304011;http://dx.doi.org/10.1016/j.aim.2020.107373,10.1016/j.aim.2020.107373,"We prove refined generating series formulae for characters of (virtual) cohomology representations of external products of suitable coefficients, e.g., (complexes of) constructible or coherent sheaves, or (complexes of) mixed Hodge modules on spaces such as (possibly singular) complex quasi-projective varieties. These formulae generalize our previous results for symmetric and alternating powers of such coefficients, and apply also to other Schur functors. The proofs of these results are reduced via an equivariant Künneth formula to a more general generating series identity for abstract characters of tensor powers V⊗n of an element V in a suitable symmetric monoidal category A. This abstract approach applies directly also in the equivariant context for spaces with additional symmetries (e.g., finite group actions, finite order automorphisms, resp., endomorphisms), as well as for introducing an abstract plethysm calculus for symmetric sequences of objects in A.","Plethysm, External and symmetric products, Pre-lambda structure, Adams operation, Characters of representations, Schur functor",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Korshunova O,Promyslov V",,Take-Grant hierarchical Model for Digital Control System,IFAC Proceedings Volumes,2013,46,9,1073-1078,,,,,2013,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016344329;http://dx.doi.org/10.3182/20130619-3-RU-3018.00323,10.3182/20130619-3-RU-3018.00323,A formal security hierarchical take-grant model for digital control system is discussed. A simplified security policy for nuclear power plant digital control system is formulated. The realization of formal security model for the proposed security policy is given.,"security, infrastructure object, take-grant, digital control system","7th IFAC Conference on Manufacturing Modelling, Management, and Control",,,,,,,,,,,,,,,,,,,,
Journal Article,"Amaral WC,Bingulac SP,Ferreira PA,Fontanini W,Gomide FA",,A Knowledge Based Environment for Computer Aided Control Engineering,IFAC Proceedings Volumes,1988,21,8,359-364,,,,,1988,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017549794;http://dx.doi.org/10.1016/S1474-6670(17)54979-4,10.1016/S1474-6670(17)54979-4,"Computer Aided Control Engineering is addressed in the context of an integrated environment. A set of functional requirements is stated as a basis for the development of a software structure which can be viewed as a composite object consisting of design, analysis, specification, validation and implementation tools, as well as a problem oriented language, a information structure and a knowledge base to assist the user in the problem formulation and solving tasks and other usual support tools that are part of CACE environments. The aim is to develop an efficient, modern, integrated and powerful environment for control and systems engineering education, research and development. The paper not only presents the basic requirements but also a logical structure for such an environment, describing its characteristics in terms of the methodological context, conceptual modeling, formal problem oriented languages, knowledge representation. Presently, the proposed environment is being developed, and experiments with a prototype expert system have been made to enrich and validate the ideas herein discussed.","Control theory, Artificial Intelligence, Knowledge-based systems","4th IFAC Symposium on computer aided Design in Control Systems 1988, Beijing, PRC, 23-25 August",,,,,,,,,,,,,,,,,,,,
Book Chapter,de Vrijer RC,"Nederpelt RP,Geuvers JH,de Vrijer RC","Big Trees in a λ-Calculus with λ-Expressions as Types**Reprinted from: Böhm, C., ed., λ-Calculus and Computer Science Theory, p. 252-271, by courtesy of Springer-Verlag, Heidelberg",,1994,133,,469-492,,Elsevier,,Selected Papers on Automath,1994,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08702180;http://dx.doi.org/10.1016/S0049-237X(08)70218-0,10.1016/S0049-237X(08)70218-0,"Publisher Summary This chapter illustrates the transition from the type structure of traditional type theory; the typed λ–calculus exhibited in, to the types, and considers constructive versions of propositional and predicate logic. The abstract term system λλ is a close relative of the Automath family of languages. Types depend on objects and the type assignments are themselves treated as theorems in λλ. In the investigation of normalization and decidability properties of these languages, λλ came up as a natural generalization of AUT–QE, the language currently in use for mechanical proof checking at the Automath project. An informal account of the system λλ and its relation to other systems are also discussed. The formal description of λλ is also provided. For every expression, “big trees” (BT) in λλ are well founded which implies that every expression is strongly normalizable. The strategy of the proof of BT will be to define an extension λλ – p of λλ, by adding an extra rule of term formation for ordered pairs. The main results and proof that the BT is well founded are proved with the help of various theorems.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Orhan H,Kamali M",,Fractional calculus and some properties of certain starlike functions with negative coefficients,Applied Mathematics and Computation,2003,136,2,269-279,,,,,2003,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300302000371;http://dx.doi.org/10.1016/S0096-3003(02)00037-1,10.1016/S0096-3003(02)00037-1,"A certain subclass Tγ(n,p,λ,α) of starlike functions in the unit disk is introduced. The main object of this paper is to derive several interesting properties of functions belonging to the class Tγ(n,p,λ,α). Various distortion inequalities for fractional calculus of functions in the Tγ(n,p,λ,α) are also given.","Fractional calculus, Starlike functions, Hadamard product, Fractional integrals and derivatives, Analytic functions",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Bourlès H,Bourlès H,4 - Tensor Calculus on Manifolds,,2019,,,131-172,,Elsevier,,Fundamentals of Advanced Mathematics V3,2019,9781785482502,,https://www.sciencedirect.com/science/article/pii/B9781785482502500047;http://dx.doi.org/10.1016/B978-1-78548-250-2.50004-7,10.1016/B978-1-78548-250-2.50004-7,"Abstract: Tensor calculus was the culmination of pioneering work by B. Christoffel and G. Ricci, in 1869 and 1887–1896, respectively. It reached maturity in a joint publication by Ricci-Curbastro and Levi-Cività in 1900. It is difficult to overstate its importance as a field – general relativity could not exist without it. Tensor calculus plays an essential role in every area of physics; it is also crucial for continuum mechanics and many other engineering sciences, and it, of course, lies at the heart of differential geometry. Section 4.2 of this chapter is purely algebraic (with some algebraic topology in section 4.2.6). The mathematical objects that physicists call tensors are more precisely tensor fields; they are only introduced in section 4.3. Historically, “tensors” were presented to students as exotic mathematical millipedes of the form tj1, …, jpi1, …, ip (or more briefly) that behave in a certain way under change of coordinates (see [4.3, 4.4]). This stemmed from the decision to only define the components of the tensor (see [4.2]). As a result, students could complete an entire course of tensor calculus without finding a satisfactory answer to the question: “But what actually is a tensor?” We will, of course, choose a different approach by defining tensor fields before attempting to study them.","Banach spaces, Covector field, Differential form over a chain, Exterior algebra, Interior products, Metrics, Pseudo-Riemannian manifolds, Symmetric tensors, Tensor Calculus on Manifolds, Vector fields",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Toro M,Tanter É",,Abstracting gradual references,Science of Computer Programming,2020,197,,102496,,,,,2020,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642320301052;http://dx.doi.org/10.1016/j.scico.2020.102496,10.1016/j.scico.2020.102496,"Gradual typing is an effective approach to integrate static and dynamic typing, which supports the smooth transition between both extremes via the imprecision of type annotations. Gradual typing has been applied in many scenarios such as objects, subtyping, effects, ownership, typestates, information-flow typing, parametric polymorphism, etc. In particular, the combination of gradual typing and mutable references has been explored by different authors, giving rise to four different semantics—invariant, guarded, monotonic and permissive references. These semantics were specially crafted to reflect different design decisions with respect to precision and efficiency tradeoffs. Since then, progress has been made in the formulation of methodologies to systematically derive gradual counterparts of statically-typed languages, but these have not been applied to study mutable references. In this article, we explore how the Abstracting Gradual Typing (AGT) methodology, which has been shown to be effective in a variety of settings, applies to mutable references. Starting from a standard statically-typed language with references, we systematically derive with AGT a novel gradual language, called λREF˜. We establish the properties of λREF˜; in particular, it is the first gradual language with mutable references that is proven to satisfy the gradual guarantee. We then compare λREF˜ with the main four existing approaches to gradual references, and show that the application of AGT does justify one of the proposed semantics: we formally prove that the treatment of references in λREF˜ corresponds to the guarded semantics, by presenting a bisimilation with the coercion semantics of Herman et al. In the process, we uncover that any direct application of AGT yields a gradual language that is not space-efficient. We consequently adjust the dynamic semantics of λREF˜ to recover space efficiency. We then show how to extend λREF˜ to support both monotonic and permissive references as well. Finally, we provide the first proof of the dynamic gradual guarantee for monotonic references. As a result, this paper sheds further light on the design space of gradual languages with mutable references and contributes to deepening the understanding of the AGT methodology.","Gradual typing, Mutable references, Abstract interpretation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dhara KK,Leavens GT",,Weak Behavioral Subtyping for Types with Mutable Objects,Electronic Notes in Theoretical Computer Science,1995,1,,91-113,,,,,1995,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104800069;http://dx.doi.org/10.1016/S1571-0661(04)80006-9,10.1016/S1571-0661(04)80006-9,"This paper studies the question of when one abstract data type (ADT) is a behavioral subtype of another, and proposes a model-theoretic notion of weak behavioral subtyping. Weak behavioral subtyping permits supertype abstraction to be a sound and modular reasoning principle in a language with mutation and limited forms of aliasing. The necessary restrictions on aliasing can be statically checked. Weak behavioral subtyping allows types with mutable objects to be subtypes of types with immutable objects.",,"MFPS XI, Mathematical Foundations of Programming Semantics, Eleventh Annual Conference",,,,,,,,,,,,,,,,,,,,
Journal Article,Stachowitz RA,,A formal framework for describing and classifying semantic data models,Information Systems,1985,10,1,77-96,,,,,1985,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437985900110;http://dx.doi.org/10.1016/0306-4379(85)90011-0,10.1016/0306-4379(85)90011-0,"The current lack of a classification system for Semantic Data Models (SDMs) is the result of their dependence on standard predicate calculus, which is limited in expressive power. Consequently, many issues in Database Theory cannot adequately be expressed, such as: temporal concepts (before/after insert/update/delete), the triple: true, false, unknown “facts”, existent and non-existent “objects” (null), private and “overlapping” Databases with—potentially—conflicting data, i.e. “possible” and “shared” worlds. The classification framework presented is based on systems of logic with greater expressive power than predicate calculus. In these logics, factual, semantic or intensional, modal, and probabilistic statements can be expressed. Two general classification criteria are established: 1.(a) what can be modelled or expressed in the SDM?2.(b) what can be derived or deduced in the SDM? The descriptive and classificatory apparatus developed provides a satisfactory framework for representing and explaining the topics above and other theoretical issues, such as “open-world assumption” vs “closed-world assumption”, “null-objects” vs “unknown objects”. The individual features are applied to the analysis and comparison of five Database Models, among them Codd's RM/T and Abrial's binary model. The adequacy of the criteria is further shown by demonstrating that the descriptive features used by Tsichritzis/Lochovsky in Data Models are contained (as a proper subset) in the framework. The paper concludes with an outlook on inductive systems.","relational data models, semantic data models, formal classification criteria, semantic classification framework, modelling power, deductive power, predicate calculus, manysorted logics, intensional logics, modal logics, entailment logics, declarative logics, procedural logics, meta-language representations, model sets, model systems, null objects, unknown objects, unknown facts, negative facts, possible worlds, integrity constraints, integrity constraint representations",,,,,,,,,,,,,,,,,,,,,
Journal Article,Irmak H,,Some families of p-valently analytic functions established by fractional derivatives and their certain consequences,Applied Mathematics and Computation,2011,218,3,822-826,,,,,2011,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300311000853;http://dx.doi.org/10.1016/j.amc.2011.01.058,10.1016/j.amc.2011.01.058,"The main object of this investigation is to reveal some relations between certain families of p-valently analytic functions established by fractional calculus, and to point their various consequences out.","Unit open disk, Analytic and -valent functions, Starlikeness, Convexity, Close-to-convexity, Fractional derivative, Principal values, Inequalities",Special Issue in Honour of Hari M. Srivastava on his 70th Birth Anniversary,,,,,,,,,,,,,,,,,,,,
Journal Article,"Brijlall D,Ndlazi NJ",,Analysing engineering students’ understanding of integration to propose a genetic decomposition,The Journal of Mathematical Behavior,2019,55,,100690,,,,,2019,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312318300452;http://dx.doi.org/10.1016/j.jmathb.2019.01.006,10.1016/j.jmathb.2019.01.006,"This paper reports on a study which explored engineering students’ understanding of the techniques of integration in calculus. There were 30 first year engineering students who participated in the project. The concepts were covered as part of a mathematics course at a university of technology in South Africa. Activity sheets, constructed with tasks based on integration were administered to the participants. Their written responses, which were used to identify the mental constructions of these concepts, were analysed using APOS (Action-Process-Object-Schema) theory and interviews were carried out to clarify the written responses. The discussions and written work indicated that students exhibit procedural tendencies in integration and that students could not define both definite and indefinite integrals. These findings raised some didactical implications for higher education and also provided applications of genetic decomposition design and modification.","Integral calculus, APOS theory, Genetic decomposition",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Pooley R,Wilcox P","Pooley R,Wilcox P",Chapter 4 - The importance of process,,2004,,,49-59,,Butterworth-Heinemann,Oxford,Applying UML,2004,9780750656832,,https://www.sciencedirect.com/science/article/pii/B9780750656832500048;http://dx.doi.org/10.1016/B978-075065683-2/50004-8,10.1016/B978-075065683-2/50004-8,"Publisher Summary This chapter describes the importance of process in unified modeling language (UML). The means to tackle problems are what are formally referred to as processes, methods and/or methodologies. They describe the structure of the approach undertaken to solve a problem. A process, method, or methodology is a way of formalizing common sense and best practice. Structured systems analysis and design methodology (SSADM), rational unified process (RUP), waterfall, soft systems methodology (SSM), object oriented process, environment, and notation (OPEN), catalysis, rapid application development (RAD), and extreme programming (XP) are some major example of processes and methodologies that are briefly discussed in the chapter. The key benefits of the processes and methodologies are summarized in the “benefits of using an established approach” information box in the chapter. Some of the main influencing factors in choosing a particular process or methodology include company doctrine, customer influence, standard development, and personal bias. An organization may have a policy that determines a commitment to use a particular methodology. The policy may be a standard one in the public domain, or may often be a company's own variation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Pérez Rodríguez M,,Deformation of formal schemes through local homology,Journal of Algebra,2016,445,,78-102,,,,,2016,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869315004391;http://dx.doi.org/10.1016/j.jalgebra.2015.07.041,10.1016/j.jalgebra.2015.07.041,"We define the cotangent complex of a morphism f:X→Y of locally noetherian formal schemes as an object in the derived category D−(X) through local homology. We discuss its basic properties and establish the basics results of a deformation theory, providing a characterization of smooth and étale morphisms. This leads to simpler lifting results depending on a differential module, for a class of non-smooth morphism of usual schemes. We also give descriptions of the cotangent complex in the case of regular closed immersions and complete intersection morphisms of formal schemes.","Formal scheme, Cotangent complex, Lifting, Deformation, Local homology",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Papaodysseus C,Arabadjis D,Exarhos M,Rousopoulos P,Zannos S,Panagopoulos M,Papazoglou-Manioudaki L",,Efficient solution to the 3D problem of automatic wall paintings reassembly,Computers & Mathematics with Applications,2012,64,8,2712-2734,,,,,2012,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122112005147;http://dx.doi.org/10.1016/j.camwa.2012.08.003,10.1016/j.camwa.2012.08.003,"This paper introduces a new approach for the automated reconstruction- reassembly of fragmented objects having one surface near to plane, on the basis of the 3D representation of their constituent fragments. The whole process starts by 3D scanning of the available fragments. The obtained representations are properly processed so that they can be tested for possible matches. Next, four novel criteria are introduced, that lead to the determination of pairs of matching fragments. These criteria have been chosen so as the whole process imitates the instinctive reassembling method dedicated scholars apply. The first criterion exploits the volume of the gap between two properly placed fragments. The second one considers the fragments’ overlapping in each possible matching position. Criteria 3,4 employ principles from calculus of variations to obtain bounds for the area and the mean curvature of the contact surfaces and the length of contact curves, which must hold if the two fragments match. The method has been applied, with great success, both in the reconstruction of objects artificially broken by the authors and, most importantly, in the virtual reassembling of parts of wall paintings belonging to the Mycenaic civilization (c.1300 BC.), excavated in a highly fragmented condition in Tyrins, Greece","Fragmented objects reassembly, Wall paintings reconstruction, Pattern matching, 3D pattern analysis, Geometry, Calculus of variations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kwuida L,Kuitché RS,Temgoua RE",,On the size of ∃-generalized concept lattices,Discrete Applied Mathematics,2020,273,,205-216,,,,,2020,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X19301283;http://dx.doi.org/10.1016/j.dam.2019.02.035,10.1016/j.dam.2019.02.035,"Formal Concept Analysis (FCA) offers several tools for qualitative data analysis. One possibility is to group objects that share common attributes together and get a concept lattice that describes the data. Quite often the size of this concept lattice is very large. Many authors have investigated methods to reduce the size of this lattice. In Kwuida et al. (2014) the authors consider putting together some attributes to reduce the size of the attribute sets. But this reduction does not always carry over to the set of concepts. They provided some counter examples where the size of the concept lattice increases by one after putting two attributes together, and asked the following question: “How many new concepts can be generated by an ∃-generalization on just two attributes?” The present paper provides a family of contexts for which the size increases on more than one concept after putting solely two attributes together.","Formal concept analysis, Concept lattices, Generalizing attributes",Advances in Formal Concept Analysis: Traces of CLA 2016,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mukherji M,Kafura D",,A process-calculus-based abstraction for coordinating multi-agent groups,Theoretical Computer Science,1998,192,2,287-314,,,,,1998,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397597001539;http://dx.doi.org/10.1016/S0304-3975(97)00153-9,10.1016/S0304-3975(97)00153-9,"Coordination, the act of imposing a desired behavior on a group of autonomous, independently conceived agents, has been an important issue in the design and development of software systems, both process-based and object-based. In this paper, the Calculus of Coordinating Environments (CCE) is proposed to study coordination as the behavioral union of coordinated and coordinating agents. In CCE, the behavior of coordinated components is expressed as agents in the Calculus of Communicating Systems (CCS) and the behavior of coordinators is expressed as agents (called CE agents) of an extension of CCS. Two composition rules that capture the interaction among CE agents and CCS agents are provided. The applicability of the new formalism is shown by specifying two simple coordination problems in CCE.","CCS, Coordination, Object composition",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lin S,Ling WC,Nishimoto K,Srivastava HM",,A simple fractional-calculus approach to the solutions of the Bessel differential equation of general order and some of its applications,Computers & Mathematics with Applications,2005,49,9,1487-1498,,,,,2005,,0898-1221,https://www.sciencedirect.com/science/article/pii/S089812210500163X;http://dx.doi.org/10.1016/j.camwa.2004.09.009,10.1016/j.camwa.2004.09.009,"In many recent works, several authors demonstrated the usefulness of fractional calculus operators in the derivation of (explicit) particular solutions of a significantly large number of linear ordinary and partial differential equations of the second and higher orders. The main object of the present paper is to show how this simple fractional-calculus approach to the solutions of the classical Bessel differential equation of general order would lead naturally to several interesting consequences which include (for example) an alternative investigation of the power-series solutions obtainable usually by the Frobenius method. The methodology presented here is based largely upon some of the general theorems on (explicit) particular solutions of a certain family of linear ordinary fractional differintegral equations.","Fractional calculus, Bessel differential equation, Fuchsian (and non-Fuchsian) equations, Differentegral equations, Linear (ordinary and partial) differential equations, Index law, Linearity property, Generalized Leibniz rule, Frobenius method, Power-series solutions, Bessel functions, Trigonometric functions",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ayrault P,Hardin T,Pessaux F",,Development Life-cycle of Critical Software Under FoCaL,Electronic Notes in Theoretical Computer Science,2009,243,,15-31,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109002254;http://dx.doi.org/10.1016/j.entcs.2009.07.003,10.1016/j.entcs.2009.07.003,"Before their installation, critical systems must be assessed by an independent authority, who ensures that software components are really compliant with a set of requirements described in standards. Such standards describe the framework and the rules to be strictly followed along the development process. Moreover high levels of safety highly recommand the use of formal methods. In this paper, we examine how the FoCaL development environment can help to fulfil these requirements and to ease assessment. This tool aims to help all stages of critical software development, at least when formal methods are required (step-by-step specification and implementation, properties expressed by first-order formulae, proofs helped by automatic tool). Upon our experience as either software safety assessor or researchers in software engineering and formal methods, we propose a development life cycle adapted to the FoCaL specificity and compliant with independent assessment requirements, through a complete example. We show how features such as inheritance, late binding, redefinition, parametrisation, encapsulation and declarations/definitions, properties/theorems, whole development checked by an independent proof assistant and partially automatic documentation can be used to improve the global safety and the re-use of software components.","formal methods, assessment, software life-cycle,",Proceedings of the 2nd International Workshop on Harnessing Theories for Tool Support in Software (TTSS 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Konstantinidis S,Moreira N,Reis R",,Partial derivatives of regular expressions over alphabet-invariant and user-defined labels,Theoretical Computer Science,2021,870,,103-120,,,,,2021,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397520307544;http://dx.doi.org/10.1016/j.tcs.2020.12.029,10.1016/j.tcs.2020.12.029,"We are interested in regular expressions that represent word relations in an alphabet-invariant way—for example, the set of all word pairs (u,v) where v is a prefix of u independently of what the alphabet is. Current software systems of formal language objects do not have a mechanism to define such objects. Labelled graphs (transducers and automata) with alphabet-invariant and user-defined labels were considered in a recent paper. In this paper we study derivatives of regular expressions over labels (atomic objects) in some set B. These labels can be any strings as long as the strings represent subsets of a certain monoid. We show that the number of partial derivatives of any type B regular expression is linearly bounded, and that one can define partial derivative labelled graphs, whose transition labels can be elements of another label set X as long as X and B refer to the same monoid. We also show how to use derivatives directly to decide whether a given word is in the language of a regular expression over set specs. Set specs and pairing specs are label sets allowing one to express languages and relations over large alphabets in a natural and concise way such that many algorithms work directly on these labels without the need to expand these labels to linear or quadratic size expressions.","Alphabet-invariant expressions, Regular expressions, Partial derivatives, Automata, Monoids",Special Issue on Implementation and Application of Automata,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rossi GB,Crenna F",,A formal theory of the measurement system,Measurement,2018,116,,644-651,,,,,2018,,0263-2241,https://www.sciencedirect.com/science/article/pii/S0263224117306978;http://dx.doi.org/10.1016/j.measurement.2017.10.062,10.1016/j.measurement.2017.10.062,"Measurement aims at obtaining a numerical description of objects/events/persons in the real world by means of a measuring system. Measurement is widely used as a key way for obtaining high quality information from the real world, across disciplines. In the present day, there is growing consensus in holding that measurement is characterized by the use of something that qualifies as a “measuring system”. Therefore, we discuss sufficient conditions for an empirical system to qualify as a measuring system and we present a formal model of the measuring system, in terms of empirical relations among objects to be measured and the measuring device. The theory applies to all the main structures of metrological interest – order, difference, intensive and extensive, and we hope that this may help to fill a gap in these studies. We also briefly address practical applications of the theory, including calibration, modelling of measuring devices and performance statement.","Measurement science, Measurement system, Modelling in measurement",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Qingsong Z,Keong KC,Sing NW",,Convex object based volume visualization: a formal proof and example,Computers & Graphics,2001,25,5,857-873,,,,,2001,,0097-8493,https://www.sciencedirect.com/science/article/pii/S0097849301001273;http://dx.doi.org/10.1016/S0097-8493(01)00127-3,10.1016/S0097-8493(01)00127-3,"In this paper, we provide formal definitions for object space, space subdivision and ray tracing. We also introduce concept models such as ordered space subdivisions and ordered visualization. From these works, we can evaluate the correctness and performance of our space subdivision scheme for volume visualization. With these definitions, we also analyze some established space subdivision approaches such as uniform space subdivision and octree based space subdivision. In this paper, we suggest a new subdivision strategy, the convex object based subdivision scheme, which can be more efficient in generating the convex objects for ordered visualization.","Volume visualization, Ray tracing, Space subdivision, Ordered space subdivision, Ordered visualization",Mixed realities - beyond conventions,,,,,,,,,,,,,,,,,,,,
Journal Article,Moshier MA,,On the relationship between compact regularity and Gentzen's cut rule,Theoretical Computer Science,2004,316,1,113-136,,,,,2004,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397504000805;http://dx.doi.org/10.1016/j.tcs.2004.01.027,10.1016/j.tcs.2004.01.027,"The patch topology on a stably compact space, generalizing the Lawson topology on a domain, is a coreflection of stably compact spaces in compact regular spaces. This paper investigates compact regularity and the patch coreflection in multilingual sequent calculus (MLS), which can be regarded as a category of predicative representations of stably compact spaces. An object of MLS is a certain sort of generalization of the positive fragment of Gentzen's sequent calculus. We show that an object of MLS represents a compact regular space if and only if every sequent arises as an instance of Gentzen's cut rule with complete freedom to choose the placement of the cut formula. The relationship between compact regularity and Gentzen's cut rule is further explicated by the patch coreflection in MLS. The construction is a universal solution (up to a certain equivalence of tokens) to the problem of adding opposites to a logic, i.e., tokens that obey Gentzen's rules for negation. In the spectral case, this is equivalent to adding Boolean complements. The paper closes by considering the full subcategory of MLS consisting of objects with opposites. By taking contrapositives of sequents, we obtain an anti-involution on morphisms making this category equivalent to the Freyd/Scedrov allegory of compact regular spaces and closed binary relations. Moreover, the category of “maps” of this allegory is predicatively equivalent to the image of the patch functor.","Sequent calculus, Predicativity, Compact regular locales, Stone duality",Recent Developments in Domain Theory: A collection of papers in honour of Dana S. Scott,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jouannaud JP,Kirchner C,Kirchner H,Mégrelis A",,"Programming with equalities, subsorts, overloading, and parametrization in OBJ",The Journal of Logic Programming,1992,12,3,257-279,,,,,1992,,0743-1066,https://www.sciencedirect.com/science/article/pii/074310669290027Z;http://dx.doi.org/10.1016/0743-1066(92)90027-Z,10.1016/0743-1066(92)90027-Z,"obj is a declarative language, with mathematical semantics given by order-sorted equational logic and an operational semantics based on order-sorted term rewriting. obj also has user-definable abstract data types with mixfix syntax and a flexible type system that supports overloading and subtypes. In addition, obj has a powerful generic module mechanism, including nonexecutable “theories” as well as executable “objects”, plus “module expressions” that construct whole subsystems. Design and implementation choices for the obj interpreter are described here in detail.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cheng L,Shuiping Y,Jing Q,Shengcheng Y,Xun M,Yi L",,A Scenario Representation Model for Emergency Decision Support,Procedia Computer Science,2017,107,,301-305,,,,,2017,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050917303848;http://dx.doi.org/10.1016/j.procs.2017.03.109,10.1016/j.procs.2017.03.109,"In this paper, a scenario representation model for emergency decision-making support is developed. It consists two components which are formal description of object and formal description of emergency status related to the object. Conceptual architecture of the model is also discussed. Advantages of this scenario representation model lies in four aspects: flexibility in describing dynamic evolution of emergencies; helping in define certain scenario and clarify its boundary; universal representation which contributes to similarity assessment. Moreover, the scenario representation model developed in this paper helps in evaluating emergency severity and effectiveness of decisions.","scenario representation model, scenario-based reasoning, emergency decision support system",Advances in Information and Communication Technology: Proceedings of 7th International Congress of Information and Communication Technology (ICICT2017),,,,,,,,,,,,,,,,,,,,
Journal Article,"Anaya-Vera S,Cordero-Dávila A",,Fast and exact diffraction integral calculus: A comparison with fresnel approximation,Optik,2020,208,,164470,,,,,2020,,0030-4026,https://www.sciencedirect.com/science/article/pii/S0030402620303041;http://dx.doi.org/10.1016/j.ijleo.2020.164470,10.1016/j.ijleo.2020.164470,"In Lens-less Digital Holographic Microscopy1, 2, 3, amplitude and phase of an object can be recovered from the irradiance of a diffraction pattern. To do this, an iterative algorithm with constrictions is applied, which is based on the calculation of diffraction patterns between two fixed planes. In one dimension and for N pixels on each straight line segment, we must calculate N2 values of the impulse response function, h, in order to evaluate the optical field on N pixels along another straight line segment. By using translation and permutation symmetries of h, and without any approximation, in this paper we will show that to calculate the diffraction pattern over N pixels we need only N values of h. Adding to this, if iterations are applied between two pixel lines, the N values of h are calculated only one time, and then we achieved a significative reduction in calculation time. Finally, our exact calculations were compared with Fresnel diffraction patterns reported by Goodman4, and we found that when distance between object and diffraction planes diminishes then the diffraction pattern irradiance differences are increased up to 53 % with respect to Fresnel approximation.","Optics, Diffraction, Mathematical methods in physics, Numerical approximation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Roslovtsev V,,"Building Semantic Technologies Based on Relational-Applicative Foundations ⁎⁎The work is supported by Russian Foundation for Basic Research, project No 17-07-01553",Procedia Computer Science,2018,123,,393-402,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050918300620;http://dx.doi.org/10.1016/j.procs.2018.01.061,10.1016/j.procs.2018.01.061,"We present a formal framework for semantic data representation and processing. Our approach is based on first merging relational and applicative approaches and then augmenting the merge with means allowing to view and manipulate data objects from semantic perspective. Our results at this point are primarily applicable in information systems development, where an engine for object description is called for. Which is the case when, for example, the exact conceptual scheme of the subject domain is unknown, may vary over time or/and consists of too big a number of entities and relationships. The framework may also be of interest from the perspective of implementing semantic features in relational database managements systems.","Relational-Applicative, Applicative Computing, Databases, Information Systems, Data Semantics","8th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2017 (Eighth Annual Meeting of the BICA Society), held August 1-6, 2017 in Moscow, Russia",,,,,,,,,,,,,,,,,,,,
Journal Article,Orhan H,,A new class of analytic functions with negative coefficients,Applied Mathematics and Computation,2003,138,2,531-543,,,,,2003,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300302001765;http://dx.doi.org/10.1016/S0096-3003(02)00176-5,10.1016/S0096-3003(02)00176-5,"A subclass Pγ(n,λ,α,r) of analytic functions in the unit disc is introduced. The object of the present paper is to show some properties of functions belonging to the class Pγ(n,λ,α,r). Further, the distortion inequalities for fractional calculus of functions in Pγ(n,λ,α,r) are given.","Univalent functions, Hadamart product, Fractional calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Stock-Homburg RM,Heald SL,Holthaus C,Gillert NL,von Hippel E",,"Need-solution pair recognition by household sector individuals: Evidence, and a cognitive mechanism explanation",Research Policy,2021,50,8,104068,,,,,2021,,0048-7333,https://www.sciencedirect.com/science/article/pii/S0048733320301463;http://dx.doi.org/10.1016/j.respol.2020.104068,10.1016/j.respol.2020.104068,"Problem-solving by everyday individuals is thought to occur as a two-step process. First, an individual identifies or formulates a problem, followed by entering into a subsequent search to find the best solution. Here, however, we consider an alternative process that everyday individuals may use for solution finding first theorized by von Hippel and von Krogh (2016). Specifically, von Hippel and von Krogh proposed that everyday individuals may sometimes discover a solution and the need it satisfies simultaneously without the need for apriori problem formation, a cognitive process they called “need-solution pair recognition”. Utilizing a rich literature from psychology and neuroscience, we propose that seemingly spontaneous discoveries found by need-solution pair recognition are natural products of the object recognition system and its underlying mechanisms. This view asserts that on encountering an object and reasoning how it might be used (i.e. functional object understanding), an individual's perception of an object may culminate in recognizing the object as a solution, and in some cases, as a solution to a problem previously unknown to him or her, thus bypassing formal problem-formulation and active solution searching entirely. To empirically test this view, we manipulated the ability of everyday individuals to functionally reason about objects while we examined the spontaneous occurrence of solutions found by either need-solution pair recognition or traditional problem-first problem-solving. Consistent with our hypothesized mechanism, our results indicate that need-solution pair recognition occurs more frequently when constraints on functional object understanding are reduced. That is, we found that needsolution pair discoveries outpaced solutions found from traditional problem solving, in environments with unfamiliar objects, where participants were not directed to solve specific problems. Our results provide clear evidence that everyday individuals in the household sector do not always innovate through traditional problem-solving processes, but instead may arrive at solutions as they recognize and reason about objects. Implications for research and practice in household innovation, and for innovation more generally are considered.","Need-solution pairs, Insight, Object understanding, Solution finding, Problem-solving, Creativity","Treading New Ground in Household Sector Innovation Research: Scope, Emergence, Business Implications, and Diffusion",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Borgo S,Vieu L",Meijers A,Artefacts in Formal Ontology,,2009,,,273-307,,North-Holland,Amsterdam,Philosophy of Technology and Engineering Sciences,2009,,1878-9846,https://www.sciencedirect.com/science/article/pii/B978044451667150015X;http://dx.doi.org/10.1016/B978-0-444-51667-1.50015-X,10.1016/B978-0-444-51667-1.50015-X,"Publisher Summary This chapter illustrates ontological systems, hereafter referred to as ontologies, which satisfy the two main requirements of being formal and foundational. Ontology is formal if it is expressed in a logic language endowed with clear semantics (for instance, in model-theoretic terms as first-order predicate logic). This choice is not determined by application concerns (at least, not primarily), it emphasizes the relevance that semantic transparency has in this domain. By foundational ontologies one means those knowledge systems that focus on very general and basic concepts (like object, event, state, quality) and relations (such as constitution, participation, dependence, parthood). Often, the term formal ontology is used to cover both the requirements, thus reminding us of Husserl's distinction between formal logic and formal ontology. In this specific meaning, formal ontology is the study of the interconnections between entities, properties, parts, wholes and collectives. These are considered to be “formal” because they can be exemplified by objects in all domains of reality. To take another perspective, one can say that formal ontology is the study of formal (logical) systems which are: general, since they include the most usable and widely applicable concepts; reliable, as they are logical theories with clear semantics, a rich axiomatization and carefully analyzed formal consequences (theorems); and well organized, because they are based on philosophical principles the choice of which is explicitly motivated and remains independent from particular domains.",,,Handbook of the Philosophy of Science,,,,,,,,,,,,,,,,,,,
Journal Article,Prasad KV,,A Prospectus for Mobile Broadcasting Systems,Electronic Notes in Theoretical Computer Science,2006,162,,295-300,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106004506;http://dx.doi.org/10.1016/j.entcs.2005.12.096,10.1016/j.entcs.2005.12.096,"Computer messages are often broadcast over ethernets, and sent point-to-point between them: globally asynchronous, locally synchronous (GALS). This paradigm is captured here by a primitive calculus, MBS (mobile broadcasting systems). MBS processes talk in rooms by local broadcast, and walk between rooms at unspecified speeds. Names are like object names in the π-calculus, but its “get/put b on channel a” becomes in MBS “go to a and hear/say b”. Speakers wait for departing processes, who are grouped by destination, and walkers can enter only silent rooms. These rules, and a primitive to make a room wait for a walker from a given room, seem adequate for programming.","Process calculus, broadcast communication, process mobility, ethernet, GALS","Proceedings of the Workshop \Essays on Algebraic Process Calculi\"" (APC 25)""",,,,,,,,,,,,,,,,,,,,
Journal Article,"Ehlmann BK,Rishe N,Shi J",,The formal specification of ORN semantics,Information and Software Technology,2000,42,3,159-170,,,,,2000,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584999000518;http://dx.doi.org/10.1016/S0950-5849(99)00051-8,10.1016/S0950-5849(99)00051-8,"Object Relationship Notation (ORN) is a declarative scheme that permits a variety of common types of relationships to be conveniently defined to a Database Management System (DBMS), thereby allowing the DBMS to automatically enforce their semantics. Though first proposed for object DBMSs, ORN is applicable to any data model that represents binary entity-relationships or to any DBMS that implements them. In this paper, we first describe ORN semantics informally as has been done in previous papers. We then provide a formal specification of these semantics using the Z-notation. Specifying ORN semantics via formal methods gives ORN a solid mathematical foundation. The semantics are defined in the context of an abstract database of sets and relations in a recursive manner that is precise, unambiguous, and noncircular.","Object relationship notation, Data modeling, Formal methods",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Abadi M,Cardelli L",,A Theory of Primitive Objects: Untyped and First-Order Systems,Information and Computation,1996,125,2,78-102,,,,,1996,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540196900243;http://dx.doi.org/10.1006/inco.1996.0024,10.1006/inco.1996.0024,"We introduce simple object calculi that support method override and object subsumption. We give an untyped calculus, typing rules, and equational rules. We illustrate the expressiveness of our calculi and the pitfalls that we avoid.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Baltag A,Coecke B,Sadrzadeh M",,Algebra and Sequent Calculus for Epistemic Actions,Electronic Notes in Theoretical Computer Science,2005,126,,27-52,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105000824;http://dx.doi.org/10.1016/j.entcs.2004.11.012,10.1016/j.entcs.2004.11.012,"We introduce an algebraic approach to Dynamic Epistemic Logic. This approach has the advantage that: (i) its semantics is a transparent algebraic object with a minimal set of primitives from which most ingredients of Dynamic Epistemic Logic arise, (ii) it goes with the introduction of non-determinism, (iii) it naturally extends beyond boolean sets of propositions, up to intuitionistic and non-distributive situations, hence allowing to accommodate constructive computational, information-theoretic as well as non-classical physical settings, and (iv) introduces a structure on the actions, which now constitute a quantale. We also introduce a corresponding sequent calculus (which extends Lambek calculus), in which propositions, actions as well as agents appear as resources in a resource-sensitive dynamic-epistemic logic.","dynamic epistemic logic, quantale, module, resources",Proceedings of the 2nd International Workshop on Logic and Communication in Multi-Agent Systems (2004),,,,,,,,,,,,,,,,,,,,
Journal Article,Sinot FR,,Token-Passing Nets: Call-by-Need for Free,Electronic Notes in Theoretical Computer Science,2006,135,3,129-139,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106000934;http://dx.doi.org/10.1016/j.entcs.2005.09.027,10.1016/j.entcs.2005.09.027,"Recently, encodings in interaction nets of the call-by-name and call-by-value strategies of the λ-calculus have been proposed. The purpose of these encodings was to bridge the gap between interaction nets and traditional abstract machines, which are both used to provide lower-level specifications of strategies of the λ-calculus, but in radically different ways. The strength of these encodings is their simplicity, which comes from the simple idea of introducing an explicit syntactic object to represent the flow of evaluation. In particular, no artifact to represent boxes is needed. However, these encodings purposefully follow as closely as possible the implemented strategies, call-by-name and call-by-value, hence do not benefit from the ability of interaction nets to easily represent sharing. The aim of this note is to show that sharing can indeed be achieved without adding any structure. We thus present the call-by-need strategy following the same philosophy, which is indeed not any more complicated than call-by-name. This continues the task of bridging the gap between interaction nets and abstract machines, thus pushing forward a more uniform framework for implementations of the λ-calculus.","-calculus, call-by-name, call-by-value, interaction net",Proceedings of the First International Workshop on Developments in Computational Models (DCM 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Wolfengagen V,Ismailova L,Kosikov S",,Capturing information processes with variable domains,Procedia Computer Science,2020,169,,276-283,,,,,2020,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050920303008;http://dx.doi.org/10.1016/j.procs.2020.02.177,10.1016/j.procs.2020.02.177,"An approach to the construction of a computational model in which information processes are presented in the framework of theories without types, and they, in turn, are considered as special parts of typed theories, is proposed. Similar mixing was used in model studies for lambda-calculus. In contrast to them, in the present work, information processes correspond to parameterized metadata objects, which are variable domain constructs. Transformations of variable domains correspond to the spread of the process. Directional transformation provides the generation of metadata targets in the form of parameterized concepts. This simulates the evolving of the process, which allows the interpretation of the hidden time factor. The emerging model is purely process-based and provides a conceptual framework. The possibility of coding this framework with a system of interdependent lambda-terms is shown.","semantic information processing, computational model, variable domains","Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA",,,,,,,,,,,,,,,,,,,,
Journal Article,"Salinas P,González-Mendívil E,Quintero E,Ríos H,Ramírez H,Morales S",,The Development of a Didactic Prototype for the Learning of Mathematics through Augmented Reality,Procedia Computer Science,2013,25,,62-70,,,,,2013,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050913012131;http://dx.doi.org/10.1016/j.procs.2013.11.008,10.1016/j.procs.2013.11.008,"This work applies Augmented Reality technology in the educational process through a didactic prototype that promotes visualization skills related to the learning of mathematical content. An initial prototype has been designed and built with the purpose of arriving at 3 dimensional objects performing specific actions, in space and time, executed with 2 dimensional objects. The AR production of mathematical objects with which student may interact offers the opportunity to mentally record the process through which they are generated, favoring visualization skills. In the initial academic phase, an analysis of the first three college calculus courses was carried out. The objective was the identification of a transversal content suitable to be developed in AR environment. Once this content was established and discussed, the conceptualization of the prototype was carried out, identifying first the platform of technological and human resources available for the project. The technical phase was focused on developing the AR technology prototype around the didactic design concept. The adjustment decisions in this process were based around the academic-technical integration meetings. A pilot experience for exploratory purposes was developed with Mathematics I for engineering students during May 2013. The aim was to describe the actions the prototype encourages from the students and to capitalize these results to determine limitations and reaches of this first prototype, from a didactically and technically point of view. The pilot experience confirms that AR technology in education increases the current motivation to learn by students. The work aims to study about the development of didactic resources that serve students in the learning of a visual and tangible mathematics.","Mathematics, Calculus, learning, Didactic prototype, Augmented reality",2013 International Conference on Virtual and Augmented Reality in Education,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hillebrand GG,Kanellakis PC,Mairson HG",,Database Query Languages Embedded in the Typed Lambda Calculus,Information and Computation,1996,127,2,117-144,,,,,1996,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540196900553;http://dx.doi.org/10.1006/inco.1996.0055,10.1006/inco.1996.0055,"We investigate the expressive power of the typedλ-calculus when expressing computations over finite structures, i.e., databases. We show that the simply typedλ-calculus can express various database query languages such as the relational algebra, fixpoint logic, and the complex object algebra. In our embeddings, inputs and outputs areλ-terms encoding databases, and a program expressing a query is aλ-term which types when applied to an input and reduces to an output. Our embeddings have the additional property that PTIME computable queries are expressible by programs that, when applied to an input, reduce to an output in a PTIME sequence of reduction steps. Under our database input-output conventions, all elementary queries are expressible in the typedλ-calculus and the PTIME queries are expressible in the order-5 (order-4) fragment of the typedλ-calculus (with equality).",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Osswald R,,Classifying Classification,Electronic Notes in Theoretical Computer Science,2004,53,,260,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105825873;http://dx.doi.org/10.1016/S1571-0661(05)82587-3,10.1016/S1571-0661(05)82587-3,"Different types of linguistic classification, ranging from simple inheritance hierarchies to systemic networks, are classified algebraically and order-theoretically. To this end, classifications are reformulated as observational theories. Classifications that do not involve disjunction correspond to Horn theories, whose generic universe ordered by specialization is known to be a Scott domain. Several subtypes of Horn theories, corresponding to simple inheritance with exclusions, are classified with respect to their domains. Systemic classification is shown to have a flat domain. In particular, every finite systemic classification can be translated into a Horn theory. The infinite case turns out to be more subtle since non-equivalent observational theories may induce isomorphic specialization orders.",,Proceedings of the joint meeting of the 6th Conference on Formal Grammar and the 7th Conference on Mathematics of Language,,,,,,,,,,,,,,,,,,,,
Journal Article,"Camacho C,Llana L,Núñez A",,Cost-related interface for software product lines,Journal of Logical and Algebraic Methods in Programming,2016,85,"1, Part 2",227-244,,,,,2016,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220815000917;http://dx.doi.org/10.1016/j.jlamp.2015.09.009,10.1016/j.jlamp.2015.09.009,"Software Product Lines modeling improves software development processes by automating system debugging and analysis. The objective of this paper focuses on extending the formal framework SPLA to represent features such as cost objects and comparisons between products in terms of production costs. We illustrate this extension with a practical example by modeling the creation of valid run-lists for Chef, a widely used configuration management tool. Also, we execute our formal specification in a distributed system using SCOOP and we provide strategies to optimize the effort required to compute a SPLA term.","Software product lines, Cost models, Formal methods, Feature models, Chef.io, Run-list",Formal Methods for Software Product Line Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,Sergeyev YD,,"Numerical point of view on Calculus for functions assuming finite, infinite, and infinitesimal values over finite, infinite, and infinitesimal domains","Nonlinear Analysis: Theory, Methods & Applications",2009,71,12,e1688-e1707,,,,,2009,,0362-546X,https://www.sciencedirect.com/science/article/pii/S0362546X09002946;http://dx.doi.org/10.1016/j.na.2009.02.030,10.1016/j.na.2009.02.030,"The goal of this paper consists of developing a new (more physical and numerical in comparison with standard and non-standard analysis approaches) point of view on Calculus with functions assuming infinite and infinitesimal values. It uses recently introduced infinite and infinitesimal numbers being in accordance with the principle ‘The part is less than the whole’ observed in the physical world around us. These numbers have a strong practical advantage with respect to traditional approaches: they are representable at a new kind of a computer–the Infinity Computer–able to work numerically with all of them. An introduction to the theory of physical and mathematical continuity and differentiation (including subdifferentials) for functions assuming finite, infinite, and infinitesimal values over finite, infinite, and infinitesimal domains is developed in the paper. This theory allows one to work with derivatives that can assume not only finite but infinite and infinitesimal values, as well. It is emphasized that the newly introduced notion of the physical continuity allows one to see the same mathematical object as a continuous or a discrete one, in dependence on the wish of the researcher, i.e., as it happens in the physical world where the same object can be viewed as a continuous or a discrete in dependence on the instrument of the observation used by the researcher. Connections between pure mathematical concepts and their computational realizations are continuously emphasized through the text. Numerous examples are given.","Infinite and infinitesimal numbers and numerals, Infinite and infinitesimal functions and derivatives, Physical and mathematical notions of continuity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fernandez-Chaves D,Ruiz-Sarmiento JR,Petkov N,Gonzalez-Jimenez J",,"ViMantic, a distributed robotic architecture for semantic mapping in indoor environments",Knowledge-Based Systems,2021,232,,107440,,,,,2021,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705121007024;http://dx.doi.org/10.1016/j.knosys.2021.107440,10.1016/j.knosys.2021.107440,"Semantic maps augment traditional representations of robot workspaces, typically based on their geometry and/or topology, with meta-information about the properties, relations and functionalities of their composing elements. A piece of such information could be: fridges are appliances typically found in kitchens and employed to keep food in good condition. Thereby, semantic maps allow for the execution of high-level robotic tasks in an efficient way, e.g. “Hey robot, Store the leftover salad”. This paper presents ViMantic, a novel semantic mapping architecture for the building and maintenance of such maps, which brings together a number of features as demanded by modern mobile robotic systems, including: (i) a formal model, based on ontologies, which defines the semantics of the problem at hand and establishes mechanisms for its manipulation; (ii) techniques for processing sensory information and automatically populating maps with, for example, objects detected by cutting-edge CNNs; (iii) distributed execution capabilities through a client–server design, making the knowledge in the maps accessible and extendable to other robots/agents; (iv) a user interface that allows for the visualization and interaction with relevant parts of the maps through a virtual environment; (v) public availability, hence being ready to use in robotic platforms. The suitability of ViMantic has been assessed using Robot@Home, a vast repository of data collected by a robot in different houses. The experiments carried out consider different scenarios with one or multiple robots, from where we have extracted satisfactory results regarding automatic population, execution times, and required size in memory of the resultant semantic maps.","Semantic maps, Robotic architecture, Mobile robots, Unity 3D, ROS, Object detection, Detectron2, Robot@Home",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Davies J,Crichton C,Crichton E,Neilson D,Sørensen IH",,"Formality, Evolution, and Model-driven Software Engineering",Electronic Notes in Theoretical Computer Science,2005,130,,39-55,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105002148;http://dx.doi.org/10.1016/j.entcs.2005.03.004,10.1016/j.entcs.2005.03.004,"This paper introduces an approach to software development in which a series of working implemen- tations are generated automatically from a series of formal specifications. The implementations are data stores, communicating through standard protocols. The specifications are precise object models, in which operations are described in terms of pre- and post-conditions. The approach is evolutionary, in the sense that the specification may evolve while the system is in use, in response to changes in requirements, and any changes to the specification are automatically reflected in the structure of the implementation, and in the representation of any data currently stored.","model-driven, object modelling, formal methods",Proceedings of the Brazilian Symposium on Formal Methods (SBMF 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Gottifredi S,Tamargo LH,García AJ,Simari GR",,Arguing about informant credibility in open multi-agent systems,Artificial Intelligence,2018,259,,91-109,,,,,2018,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370218300778;http://dx.doi.org/10.1016/j.artint.2018.03.001,10.1016/j.artint.2018.03.001,"This paper proposes the use of an argumentation framework with recursive attacks to address a trust model in a collaborative open multi-agent system. Our approach is focused on scenarios where agents share information about the credibility (informational trust) they have assigned to their peers. We will represent informants' credibility through credibility objects which will include not only trust information but also the informant source. This leads to a recursive setting where the reliability of certain credibility information depends on the credibility of other pieces of information that should be subject to the same analysis. Credibility objects are maintained in a credibility base which can have information in conflict. In this scenario, we will formally show that our proposal will produce a partially ordered credibility relation; such relation contains the information that can be justified by an argumentation process.","Argumentation, Multi-agent system, Trust, Credibility orders",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sampaio A,Mota A,Ramos R",,Class and Capsule Refinement in UML for Real Time,Electronic Notes in Theoretical Computer Science,2004,95,,23-51,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104050133;http://dx.doi.org/10.1016/j.entcs.2004.04.004,10.1016/j.entcs.2004.04.004,"We propose refinement laws for the top level design elements of Real Time UML (UML-RT): classes and capsules. These laws can be used to develop concrete design models from abstract analysis models. Laws for introducing and decomposing classes and capsules are presented. Standard data refinement techniques are adapted for classes, and process refinement techniques for capsules. We also propose techniques for behavioural inheritance of classes and capsules. Soundness is briefly addressed by relating UML-RT elements to OhCircus, a formal unified language of classes and processes. To illustrate the overall strategy, we develop a detailed design of an operating system resource scheduler from a high-level analysis model.","Class refinement, process refinement, behavioral inheritance, laws for UML-RT",Proceedings of the Brazilian Workshop on Formal Methods,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bancilhon F,Khoshafian S",,A calculus for complex objects,Journal of Computer and System Sciences,1989,38,2,326-340,,,,,1989,,0022-0000,https://www.sciencedirect.com/science/article/pii/0022000089900056;http://dx.doi.org/10.1016/0022-0000(89)90005-6,10.1016/0022-0000(89)90005-6,,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lirola AG,y González-barcia FF,Molinero FG",,Application of Formal Description Techniques to Real-Time Scheduling,IFAC Proceedings Volumes,1992,25,11,253-258,,,,,1992,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017501573;http://dx.doi.org/10.1016/S1474-6670(17)50157-3,10.1016/S1474-6670(17)50157-3,"In this paper we describe a study about the applicability of Formal Description Techniques like LOTOS to analyse and validate real-time subsystems. The Basic Priority Inheritance scheduling algorithm has been specified using the Formal Description Technique LOTOS. With the help of the specification, validation tests have been derived and applied to an independent VLSI implementation of the mentioned algorithm embedded in an Ada tasking co-processor. With this experience it has been shown that Formal Description Technique LOTOS can be applied to specify real-time subsystems and therefore to develop and validate them.",,"IFAC Workshop on Real Time Programming (WRTP'92), Bruges, Belgium, 23-26 June 1992",,,,,,,,,,,,,,,,,,,,
Journal Article,Lettieri G,,An Abstract Interpretation framework for genotype elimination algorithms,Theoretical Computer Science,2012,436,,87-105,,,,,2012,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397512002940;http://dx.doi.org/10.1016/j.tcs.2012.03.032,10.1016/j.tcs.2012.03.032,"We apply Abstract Interpretation to the problem of genotype elimination in pedigrees. First, we give a formalization of some existing algorithms that try to remove from pedigrees all genotypes that violate the Mendelian rules of inheritance. The formalization enables the application of the Abstract Interpretation technique to the problem. We then introduce a particular abstraction, parameterized on given partitions of the set of genotypes. We instantiate this abstraction in order to obtain two existing algorithms for Allele Consolidation, thus giving a formal proof of their correctness. Moreover, the second of these two algorithms is shown to be an example of a forward complete abstraction.","Abstract Interpretation, Pedigrees, Genotype elimination",,,,,,,,,,,,,,,,,,,,,
Journal Article,Koepf W,,Power series in computer algebra,Journal of Symbolic Computation,1992,13,6,581-603,,,,,1992,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717110800124;http://dx.doi.org/10.1016/S0747-7171(10)80012-4,10.1016/S0747-7171(10)80012-4,"Formal power series (FPS) of the form Σk=0∞ak(x−x0)k are important in calculus and complex analysis. In some Computer Algebra Systems (CASs) it is possible to define an FPS by direct or recursive definition of its coefficients. Since some operations cannot be directly supported within the FPS domain, some systems generally convert FPS to finite truncated power series (TPS) for operations such as addition, multiplication, division, inversion and formal substitution. This results in a substantial loss of information. Since a goal of Computer Algebra is — in contrast to numerical programming — to work with formal objects and preserve such symbolic information, CAS should be able to use FPS when possible. There is a one-to-one correspondence between FPS with positive radius of convergence and corresponding analytic functions. It should be possible to automate conversion between these forms. Among CASs only Macsyma provides a procedure powerseries to calculate FPS from analytic expressions in certain special cases, but this is rather limited. Here we give an algorithmic approach for computing an FPS for a function from a very rich family of functions including all of the most prominent ones that can be found in mathematical dictionaries except those where the general coefficient depends on the Bernoulli, Euler, or Eulerian numbers. The algorithm has been implemented by the author and A. Rennoch in the CAS Mathematica, and by D. Gruntz in Maple. Moreover, the same algorithm can sometimes be reversed to calculate a function that corresponds to a given FPS, in those cases when a certain type of ordinary differential equation can be solved.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferreira NM,Machado JA,Galhano AM,Cunha JB",,FRACTIONAL CONTROL OF TWO ARMS WORKING IN COOPERATION,IFAC Proceedings Volumes,2006,39,11,355-360,,,,,2006,,1474-6670,https://www.sciencedirect.com/science/article/pii/S147466701536523X;http://dx.doi.org/10.3182/20060719-3-PT-4902.00060,10.3182/20060719-3-PT-4902.00060,This paper analyzes the performance of two cooperative robot manipulators. It is studied the implementation of fractional-order algorithms in the position/force control of two robots holding an object. The experiments reveal that fractional algorithms lead to performances superior to classical integer-order controllers.,"Cooperative robots, fractional calculus, control",2nd IFAC Workshop on Fractional Differentiation and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Calegari D,Mossakowski T,Szasz N",,Heterogeneous verification in the context of model driven engineering,Science of Computer Programming,2016,126,,3-30,,,,,2016,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642316000472;http://dx.doi.org/10.1016/j.scico.2016.02.003,10.1016/j.scico.2016.02.003,"In some cases it may be useful to represent a problem in many logical domains, since they provide different perspectives for addressing formal verification. However, the maintenance of multiple representations in separate domains can be expensive if there is neither automated assistance nor a clear formal relation between these domains. We have addressed this problem in the context of Model-Driven Engineering (MDE). We defined solid foundations of a theoretical environment for formal verification using heterogeneous verification approaches. The environment is based on the Theory of Institutions which provides a sound basis for representing MDE elements and a way for specifying translations from these elements to other domains used for verification. In this paper we present how this environment can be supported in practice within the Heterogeneous Tool Set (Hets). Hets supports heterogeneous specifications and provides capabilities for monitoring the overall correctness of a heterogeneous proof. We first extend the theoretical environment with the inclusion of an institution for the Object Constraint Language (OCL), and then we define semantic-preserving translations from the OCL-constrained MDE elements to a core language of Hets. With this we can verify basic properties of our specification, and then use the existent connections between logical domains within Hets for broadening the spectrum of domains in which complementary verification properties can be addressed.","Verification, Formal methods, Model-Driven Engineering, Theory of Institutions, Heterogeneous Tool Set",Selected Papers from the 17th Brazilian Symposium on Formal Methods (SBMF 2014),,,,,,,,,,,,,,,,,,,,
Journal Article,"Smith G,McComb T",,Refactoring Real-time Specifications,Electronic Notes in Theoretical Computer Science,2008,214,,359-380,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108003599;http://dx.doi.org/10.1016/j.entcs.2008.06.016,10.1016/j.entcs.2008.06.016,"This paper presents an approach to refactoring real-time specifications written using Real-Time Object-Z. This allows implementation components such as clocks and sensors, not necessarily present in an initial abstract specification, to be introduced via a sequence of refinement steps. The approach, based on similar work for Object-Z, is enabled by a semantics of object instantiation and operation synchronisation introduced in this paper. Means of refining synchronising operations to reflect the timing and causality constraints of an implementation are also presented.","Refactoring, formal development, real-time embedded systems, refinement, Real-Time Object-Z",Proceedings of the 13th BAC-FACS Refinement Workshop (REFINE 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,Berline C,,From computation to foundations via functions and application: The λ-calculus and its webbed models,Theoretical Computer Science,2000,249,1,81-161,,,,,2000,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397500000578;http://dx.doi.org/10.1016/S0304-3975(00)00057-8,10.1016/S0304-3975(00)00057-8,"Church's λ-calculus is an enthralling object of mathematical and logical study, born in 1930 as the mathematical theory of functions as rules, and invented for foundational purposes. λ-calculus gave rise to the first (and the most elegant) mathematical definition of computable functions and inspired the main theorems of recursion theory. It came back on the scene in the 1960s with the development of programming theory. A capital contribution of λ-calculus to this subject is that it allows the mathematical expression and development of the Curry–Howard correspondence between proofs and programs, which generates deep and active research. The first aim of this paper is to introduce λ-calculus to a mathematical audience with no previous knowledge of it. After giving a brief insight to the conceptual and practical importance of typed calculi we will concentrate on untyped λ-calculus, which is logic free, has the most powerful expressive power and can be more easily described. In the second and main part of the paper we give an elementary, algebraic, and bottom-up presentation of its useful classes of models, which are powersets built from adequate “webs”. We focus on two methods: completion of partial webs (for building models) and reducibility (for studying them). In the third part we try to give evidence that the study of models is interesting per se. We survey or raise a lot of natural questions which arise when one tries to develop a model theory for untyped λ-calculus, in the sense of a general study of the relations between its models and its equational extensions, and we illustrate them with many recent results. Finally, we give a sketchy presentation of Grue's map theory, which is a common foundation for Mathematics, Logic and Computer Science, based on λ-calculus and, hence, on the notion of function and application (instead of sets and membership). MT fulfills Church's original aim and its consistency can be proved by exhibiting webbed models for it.","-calculus, Models of untyped -calculus, Webbed models, Equational extensions of -calculus, Map theory, Graph models",Modern Algebra,,,,,,,,,,,,,,,,,,,,
Journal Article,Watanabe H,,Coarse-grained information in formal theory of measurement,Measurement,2005,38,4,295-302,,,,,2005,,0263-2241,https://www.sciencedirect.com/science/article/pii/S0263224105001065;http://dx.doi.org/10.1016/j.measurement.2005.09.005,10.1016/j.measurement.2005.09.005,"Measurement procedure is not determined only by measured objects, but is subject to various factors such as adopted instruments, and hence, the result of measurement reflects, as well as quantitative aspect of measured objects, the influence of those additional factors, one of which is the degree of the fineness of observation. The present paper is an effort to introduce this subject into a formal framework of measurement science. First, the nature of information obtained by nominal scale is examined, and in what sense the nominal scale is informative is clarified. Then, information obtained by coarse nominal measurement, where some symbols are put into one group as the same symbol, is discussed, and a possible approach to group-formation procedure as a model of coarse observation of objects is proposed. Information-theoretical interdependence is often measured by using entropy function. However, the results suggest that the average entropy is rather a suitable measure of the degree of interdependence.","Measurement science, Nominal scale, Interdependence, Minimum entropy, Pattern recognition",The logical and philosophical aspects of measurement,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang Z,ter Hofstede AH,Ouyang C,Wynn M,Wang J,Zhu X",,How to guarantee compliance between workflows and product lifecycles?,Information Systems,2014,42,,195-215,,,,,2014,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437914000246;http://dx.doi.org/10.1016/j.is.2014.01.006,10.1016/j.is.2014.01.006,"Product lifecycle management (PLM) systems are widely used in the manufacturing industry. A core feature of such systems is to provide support for versioning of product data. As workflow functionality is increasingly used in PLM systems, the possibility emerges that the versioning transitions for product objects as encapsulated in process models do not comply with the valid version control policies mandated in the objects’ actual lifecycles. In this paper we propose a solution to tackle the (non-)compliance issues between processes and object version control policies. We formally define the notion of compliance between these two artifacts in product lifecycle management and then develop a compliance checking method which employs a well-established workflow analysis technique. This forms the basis of a tool which offers automated support to the proposed approach. By applying the approach to a collection of real-life specifications in a main PLM system, we demonstrate the practical applicability of our solution to the field.","Product lifecycle management, Workflow management, Verification, Process model, Compliance",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhang J,Karkee M,Zhang Q,Zhang X,Yaqoob M,Fu L,Wang S",,Multi-class object detection using faster R-CNN and estimation of shaking locations for automated shake-and-catch apple harvesting,Computers and Electronics in Agriculture,2020,173,,105384,,,,,2020,,0168-1699,https://www.sciencedirect.com/science/article/pii/S0168169919327073;http://dx.doi.org/10.1016/j.compag.2020.105384,10.1016/j.compag.2020.105384,"In order to address the challenge of labor shortages, and to reduce costs of apple harvesting, a targeted shake-and-catch technique is being developed at Washington State University for fresh market apple harvesting. This technique is showing promising results for some varieties of apples trained to a formal, fruiting wall tree architecture. However, the operators are still required to manually engage the shaker on target branches. To further improve the shake-and-catch apple harvesting system, a multi-class object detection algorithm was developed in this study for automatically detecting apples, branches and trunks in the natural environment using a Faster R-CNN (Regions-Convolutional Neural Network) model. This study deployed transfer learning and fine-tuning for the pre-trained networks (Alexnet, VGG16 and VGG19) and activated the feature of different layers to realize the detection of these objects. The Precision and Recall (PR) curve, F1-score and mean Average Precision (mAP) were used to evaluate the performance of Faster R-CNN in detecting different object classes. VGG19 achieved the highest mAP of 82.4%, which was 10.8% higher than Alexnet and 0.4% higher than VGG16 respectively. The computational time consumed by the entire algorithm was also assessed in this study; Faster R-CNN completed the detection of one image, on average, in 0.45 s. Based on the multi-class object detection results, a polynomial fitting method was used to predict the skeleton equation of branches and trunks. The average Goodness of Fit (R2), Root Mean Squared Error (RMSE) and correlation coefficient (r) between the predicted and reference skeleton were calculated to represent the accuracy of skeleton fitting. VGG16 and VGG19 both achieved higher accuracy than Alexnet for the skeleton fitting of branches and trunks. An algorithm was then developed to estimate shaking locations on the branches using the results of previous steps. Compared with the human experts’ input, a total of 72.7% of shaking locations estimated by the algorithm were considered appropriate. This study provided a foundation and possibility for developing a fully automated shake-and-catch apple harvesting system.","Shake-and-catch apple harvesting, Faster R-CNN, Multi-class object detection, Skeleton equation fitting, Shaking location estimation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zamorski M,Zięba M,Klukowski P,Nowak R,Kurach K,Stokowiec W,Trzciński T",,Adversarial autoencoders for compact representations of 3D point clouds,Computer Vision and Image Understanding,2020,193,,102921,,,,,2020,,1077-3142,https://www.sciencedirect.com/science/article/pii/S107731422030014X;http://dx.doi.org/10.1016/j.cviu.2020.102921,10.1016/j.cviu.2020.102921,"Deep generative architectures provide a way to model not only images but also complex, 3-dimensional objects, such as point clouds. In this work, we present a novel method to obtain meaningful representations of 3D shapes that can be used for challenging tasks, including 3D points generation, reconstruction, compression, and clustering. Contrary to existing methods for 3D point cloud generation that train separate decoupled models for representation learning and generation, our approach is the first end-to-end solution that allows to simultaneously learn a latent space of representation and generate 3D shape out of it. Moreover, our model is capable of learning meaningful compact binary descriptors with adversarial training conducted on a latent space. To achieve this goal, we extend a deep Adversarial Autoencoder model (AAE) to accept 3D input and create 3D output. Thanks to our end-to-end training regime, the resulting method called 3D Adversarial Autoencoder (3dAAE) obtains either binary or continuous latent space that covers a much broader portion of training data distribution. Finally, our quantitative evaluation shows that 3dAAE provides state-of-the-art results for 3D points clustering and 3D object retrieval.","Adversarial Autoencoders, Point Clouds, Deep Learning, Representation Learning, Neural Networks, Adversarial Learning",,,,,,,,,,,,,,,,,,,,,
Journal Article,Matsuoka S,,Weak typed Böhm theorem on IMLL,Annals of Pure and Applied Logic,2007,145,1,37-90,,,,,2007,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007206000881;http://dx.doi.org/10.1016/j.apal.2006.06.001,10.1016/j.apal.2006.06.001,"In the Böhm theorem workshop on Crete, Zoran Petric called Statman’s “Typical Ambiguity theorem” the typed Böhm theorem. Moreover, he gave a new proof of the theorem based on set-theoretical models of the simply typed lambda calculus. In this paper, we study the linear version of the typed Böhm theorem on a fragment of Intuitionistic Linear Logic. We show that in the multiplicative fragment of intuitionistic linear logic without the multiplicative unit 1 (for short IMLL) the weak typed Böhm theorem holds. The system IMLL exactly corresponds to the linear lambda calculus with multiplicative pairing. The system IMLL also exactly corresponds to the free symmetric monoidal closed category without the unit object. As far as we know, our separation result is the first one with regard to these systems in a purely syntactical manner.","Linear logic, Separation, Proof nets, Graph isomorphisms",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Philippou A,Walker D",,On transformations of concurrent-object programs,Theoretical Computer Science,1998,195,2,259-289,,,,,1998,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397597002223;http://dx.doi.org/10.1016/S0304-3975(97)00222-3,10.1016/S0304-3975(97)00222-3,Transformation rules which increase the scope for concurrent activity within systems prescribed by programs of concurrent-object languages are given. Their correctness is proved on the basis of a semantic definition by translation to an extension of the π-calculus. The main theoretical development concerns the notions of confluence and partial confluence of processes.,,Concurrency Theory,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shao MW,Leung Y,Wang XZ,Wu WZ",,Granular reducts of formal fuzzy contexts,Knowledge-Based Systems,2016,114,,156-166,,,,,2016,,0950-7051,https://www.sciencedirect.com/science/article/pii/S095070511630394X;http://dx.doi.org/10.1016/j.knosys.2016.10.010,10.1016/j.knosys.2016.10.010,"Knowledge reduction is one of the key issues in knowledge discovery and data mining. During the construction of a concept lattice, it has been recognized that computational complexity is a major obstacle in deriving all the concept from a database. In order to improve the computational efficiency, it is necessary to preprocess the database and reduce its size as much as possible. Focusing on formal fuzzy contexts, we introduce in the paper the notions of granular consistent sets and granular reducts and propose granular reduct methods in the sense of reducing the attributes. With the proposed approaches, the attributes that are not essential to all the object concepts can be removed without loss of knowledge and, consequently, the computational complexity of constructing the concept lattice is reduced. Furthermore, the relationship between the granular reducts and the classification reducts in a formal fuzzy context is investigated.","Concept lattice, Crisp-fuzzy concept, Granular reduct, Ordered relation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lin S,Tu ST,Srivastava HM",,Certain classes of ordinary and partial differential equations solvable by means of fractional calculus,Applied Mathematics and Computation,2002,131,2,223-233,,,,,2002,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300301001394;http://dx.doi.org/10.1016/S0096-3003(01)00139-4,10.1016/S0096-3003(01)00139-4,"Recently, many workers demonstrated the usefulness of fractional calculus in the derivation of particular solutions of a considerably large number of linear ordinary and partial differential equations of the second and higher orders. The main object of the present paper is to show how readily some recent contributions on this subject by S.-T. Tu, K. Nishimoto, S.-J. Jaw, and S.-D. Lin [Hiroshima Math. J. 23 (1993) 63–77] (and by other workers) can be obtained by suitably applying some general theorems on particular solutions of a certain family of linear ordinary and partial fractional differintegral equations.","Fractional calculus, Differintegral equations, Generalized Leibniz rule, Analytic functions, Integral curves, Ordinary and partial differential equations, Index law, Linearity property, Principal value",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"de Champlain M,Patrick BG","de Champlain M,Patrick BG",chapter 4 - Unified Type System,,2003,,,55-82,,Morgan Kaufmann,San Francisco,C# 2.0,2003,9780121674519,,https://www.sciencedirect.com/science/article/pii/B9780121674519500046;http://dx.doi.org/10.1016/B978-012167451-9/50004-6,10.1016/B978-012167451-9/50004-6,"Publisher Summary This chapter presents the C# unified type system including reference and value types, literals, conversions, boxing/unboxing, the root object class, and two important predefined classes for arrays and strings. In C#, types fall into one of two main categories: reference and value. Reference types represent hidden pointers to objects that have been created and allocated on the heap. The value types in C# are most closely related to the basic data types of most programming languages. However, unlike C++ and Java, all value types of C# derive from the object class. Hence, instances of these types can be used in much the same fashion as instances of reference types. The four subsections including simple (or primitive) value types, nullable types, structures, and enumerations are presented, which provide a complete picture of the value types in C#. In the early 1990s, Java reintroduced the notion of the object root class but continued to exclude simple types from the hierarchy.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,"Probert RL,Chen Y,Ghazizadeh B,Sims DP,Cappa M",,Formal verification and validation for e-commerce: theory and best practices,Information and Software Technology,2003,45,11,763-777,,,,,2003,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584903000715;http://dx.doi.org/10.1016/S0950-5849(03)00071-5,10.1016/S0950-5849(03)00071-5,"In this paper, we describe a formal, model-driven, CORBA-based approach to developing and testing e-commerce systems. We indicate advantages and limitations of formal verification techniques using the Specification and Description Language (SDL), and relate the CORBA-based distributed object architecture to standard test methods and TTCN, the international standard test language. Finally, we enumerate industrial challenges and best practices at one of the electronic commerce software test organizations in IBM, and suggest a strategy for adapting formal test methods to the evolving industrial e-commerce test process.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Galić Z,Baranović M,Križanović K,Mešković E",,Geospatial data streams: Formal framework and implementation,Data & Knowledge Engineering,2014,91,,1-16,,,,,2014,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X14000160;http://dx.doi.org/10.1016/j.datak.2014.02.002,10.1016/j.datak.2014.02.002,"A spatio-temporal database manages spatio-temporal objects and supports corresponding query languages. Today, the term moving objects databases is used as a synonym for spatio-temporal databases managing spatial objects with a continuously changing geospatial location and/or extent. Recent advances in wireless communication, miniaturization of spatially enabled devices and global navigation satellite systems (GNSS) services have resulted in a large number of novel application domains. Applications in these novel domains (geo-sensor networks, moving objects tracking, real-time traffic analysis, etc.) process huge volumes of continuous data streams, i.e. data sets that are produced incrementally over time, rather than those available in full before the processing begins. Several data stream management systems (DSMSs) have been developed to manage this data. Since they are mainly based on a relational paradigm, they do not support geospatial data. Therefore, there is an urgent need for geospatial data stream management, ranging from real-time monitoring and alerting to long-term analysis of processed geospatial data. In this paper we present a formal framework consisting of data types and operations needed to support geospatial data in data streams. It can be used as a basis either for implementation of a completely new geospatial DSMS, or for extending available open source products and research prototypes. We leverage the work on abstract data types from spatio-temporal databases, present an implementation based on user-defined aggregate functions and illustrate embedding into an SQL-like language.","Cross-disciplinary applications, Data models, Data streaming, Query, Spatial/temporal data streams",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Qiu Q,Zhou X,Zhao J,Yang Y,Tian S,Wang J,Liu J,Liu H",,From sketch BIM to design BIM: An element identification approach using Industry Foundation Classes and object recognition,Building and Environment,2021,188,,107423,,,,,2021,,0360-1323,https://www.sciencedirect.com/science/article/pii/S0360132320307903;http://dx.doi.org/10.1016/j.buildenv.2020.107423,10.1016/j.buildenv.2020.107423,"Building Information Modelling (BIM) is a promising technology for building lifecycle management. Currently, BIM has been extensively used in both the sketch design (sketch) and detailed design (design) stages. Due to different purposes and different BIM tools, the reusability of sketch BIM models in the design stage is still challenging. To address this issue, this study proposes a building element identification scheme using a segmentation-aggregation strategy, termed EI-SA. Since Industry Foundation Classes (IFC) is the international standard of BIM, the EI-SA is built according to the IFC specification. Firstly, the element identification Problem is formally defined, followed by the overall framework of the EI-SA. Then, a presentation-level BIM segmentation algorithm is developed to divide a sketch BIM model into slices of geometric representations. Thirdly, a representation aggregation scheme is proposed to solve the element identification problem. The representation aggregation scheme employs a triangle-triangle intersection to detect the geometric connection and an object recognition algorithm to identify elements. Finally, experiments were conducted on several sketch BIM models. The experiment results showed that the EI-SA identified 82.22% elements on average, which verified the effectiveness of the EI-SA. To the best of our knowledge, this study is the first to solve the building element identification problem according to IFC. The proposed EI-SA will bridge the gap between sketch BIM models and design BIM models, smooth the reusability of data from the sketch stage to downstream stages, and improve the design efficiency by avoiding the re-designing of building elements.","Building information modelling (BIM), Element identification, Industry Foundation Classes (IFC), Sketch BIM, Design BIM, Object recognition",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Muravyov SV,Savolainen V",,Special interpretation of formal measurement scales for the case of multiple heterogeneous properties,Measurement,2001,29,3,209-223,,,,,2001,,0263-2241,https://www.sciencedirect.com/science/article/pii/S0263224100000403;http://dx.doi.org/10.1016/S0263-2241(00)00040-3,10.1016/S0263-2241(00)00040-3,"A formal model of measurement is constructed and its components are outlined in this paper. An integrated hierarchical formal four-level structure which allows description of the multiple heterogeneous properties of a complex object under measurement is developed in order to have a uniform tool for the selection of specific scales for the measurement of these properties. A special treatment of a measurement scale defined on the space of the object states is offered, and corresponding structures of basic types of scales are explained permitting to take into consideration distances between relations on these states. Our approach can serve as the uniform formalised basis for development of measuring systems and algorithms of their operation in various application areas which are characterised by heterogeneous and many-dimensional properties of objects under investigation.","Measurement theory, Multiple properties, Conjoint measurements, Subjective measurements",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Gilula M,Gilula M,Chapter 3 - Key-Object Data Model,,2016,,,19-39,,Morgan Kaufmann,Boston,Structured Search for Big Data,2016,9780128046319,,https://www.sciencedirect.com/science/article/pii/B9780128046319000030;http://dx.doi.org/10.1016/B978-0-12-804631-9.00003-0,10.1016/B978-0-12-804631-9.00003-0,"The key-object concept is further developed in this chapter. It presents an abstract key-object data model based on hereditarily-finite sets – a mathematical structure having the finite set as the only constructor. The key-object model is a generalization of the relational model where data objects – key-object instances – can be arbitrarily structured and multivalued, and the phenomenon of multiple values receives its formal explication. Sets of key-object instances form data stores, which can be viewed as analogs of relational tables and databases at the same time. Particularly, tables correspond to flat homogeneous data stores and databases correspond to flat data stores. Under this analogy, the same query could be addressed to all tables in all databases and the response could be formed as the union of responses returned from each table.","relational model, data model, data store, flat data store, homogeneous data store, hereditarily-finite sets, relational operation, restriction, join, projection",,,,,,,,,,,,,,,,,,,,,
Journal Article,Donnelly M,,"A formal theory for reasoning about parthood, connection, and location",Artificial Intelligence,2004,160,1,145-172,,,,,2004,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370204001134;http://dx.doi.org/10.1016/j.artint.2004.06.003,10.1016/j.artint.2004.06.003,"In fields such as medicine, geography, and mechanics, spatial reasoning involves reasoning about entities that may coincide without overlapping. Some examples are: cavities and invading particles, passageways and valves, geographic regions and tropical storms. The purpose of this paper is to develop a formal theory of spatial relations for domains that include coincident entities. The core of the theory is a clear distinction between mereotopological relations, such as parthood and connection, and relative location relations, such as coincidence. To guide the development of the formal theory, I construct mathematical models in which nontrivial relative location relations are defined.","Spatial reasoning, Mereotopology, Formal ontology, Physical objects, Holes",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Häußler M,Borrmann A",,Model-based quality assurance in railway infrastructure planning,Automation in Construction,2020,109,,102971,,,,,2020,,0926-5805,https://www.sciencedirect.com/science/article/pii/S0926580519303279;http://dx.doi.org/10.1016/j.autcon.2019.102971,10.1016/j.autcon.2019.102971,"A primary motive for adopting the methodology Building Information Modeling (BIM) in planning processes is to improve planning accuracy, cost security, and in turn quality. Up to now, however, a generally applicable, standardized means of validating design quality has been lacking. To address this shortcoming, this article presents 14 quality parameters in the domains of clash detection, semantics as well as quantities and costs, that apply to the field of infrastructure planning. The sets of rules outlined in the article are adaptable and extendable in order to respond flexibly to different model structures. The investigation focuses on how important and recurring tests can be carried out automatically and how to make the results analyzable in a transparent and standardized manner. The proposed concept thoroughly extends well-known methods such as attribute testing and clash detection analysis of the 3D model. Doing so, the paper presents a set of novel methods for quality assurance, including 4D clash detection and checks for semantic-geometric coherence. The paper discusses in detail: the influence of modeling errors on clash detection, the difference of 3D and 4D clashes, formal methods for checking the correct linkage between 3D BIM and the bill of quantities, formal approaches for checking the semantic-geometric coherence of BIM objects. The quality assurance concept presented in the article concludes with a standardized evaluation for the individual quality criteria using a school grading system, traffic light, and percentage scale. Finally, the concept is applied in a comprehensive case study on a large-scale infrastructure project and the results of the formal quality assessment are presented.","BIM, Infrastructure, Quality, Consistency, Railway, Design, Clash detection, nD modeling quality assurance",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Berman JJ,Berman JJ,Chapter 3 - Ontologies and Semantics,,2013,,,35-48,,Morgan Kaufmann,Boston,Principles of Big Data,2013,9780124045767,,https://www.sciencedirect.com/science/article/pii/B9780124045767000034;http://dx.doi.org/10.1016/B978-0-12-404576-7.00003-4,10.1016/B978-0-12-404576-7.00003-4,"Information has very limited value unless it can take its place within our general understanding of the world. When a financial analyst learns that the price of a stock has suddenly dropped, he cannot help but wonder if the drop of a single stock reflects conditions in other stocks in the same industry. If so, the analyst may check to ensure that other industries are following a downward trend. He may wonder whether the downward trend represents a shift in the national or global economies. Answering the basic question “How does this thing relate to that thing?” is often the central goal of a scientific effort. Ontologies are formal systems that relate different information objects into classes and relate classes of information objects to other classes, often as a hierarchical lineage (i.e., classes have superclasses and subclasses). Scientific analyses of large information resources can be greatly enhanced if every data object in the resource is positioned somewhere within a formal ontology. Scientists can determine whether observations on a single object will apply to other objects in the same class. Similarly, scientists can begin to ask whether observations that hold true for a class of objects will relate to other classes of objects. Basically, an ontology can help scientists do one of their most important tasks—determining how things relate to each other. This chapter will describe how ontologies are constructed and how they are used for scientific discovery in Big Data resources.","ontology, classification, class, subclass, superclass, class hierarchy, ontologic competence, instances, class object, meaning, triple",,,,,,,,,,,,,,,,,,,,,
Journal Article,Baldamus M,,Compositional Constructor Interpretation over Coalgebraic Models for the π—Calculus,Electronic Notes in Theoretical Computer Science,2000,33,,13-41,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105803421;http://dx.doi.org/10.1016/S1571-0661(05)80342-1,10.1016/S1571-0661(05)80342-1,"The π-calculus and its variants are one of the most important subjects in the field of process algebra. Researchers in the coalgebra community have taken account of that by developing a family of related final coalgebra models for the π-calculus. None of these models has, however, been given with interpretations of the π-calculus constructors as operations on semantic domains. The present paper introduces such interpretations over final coalgebra models for the π-calculus. These models do not exactly belong to the realm of the already existing work. Rather, we emphasise the distinction between a a ground model and a full model: The ground model is fully abstract with respect to a form of π-calculus ground bisimulation; the full model is built on top of the ground model and is fully abstract with respect to the congruence derived from that ground bisimulation. Also, every semantic object is a 3-tuple with a direct representation of its transformation under renamings. A straightforward adaption of Rutten and Turi's mixed terms technique then yields compositional interpretations of most constructors of the π-calculus on the ground level. These interpretations can be lifted to the full level, again yielding compositionality. Because input prefixing does not preserve ground bisimilarity, this π-calculus constructor cannot be interpreted compositionally strictly on the ground level. It is therefore given an independent interpretation over the full model.",,"CMCS'2000, Coalgebraic Methods in Computer Science",,,,,,,,,,,,,,,,,,,,
Journal Article,Olderog ER,,Automatic Verification of Combined Specifications: An Overview,Electronic Notes in Theoretical Computer Science,2008,207,,3-16,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108001874;http://dx.doi.org/10.1016/j.entcs.2008.03.082,10.1016/j.entcs.2008.03.082,"This paper gives an overview of results of the project “Beyond Timed Automata” carried out in the Collaborative Research Center AVACS (Automatic Verification and Analysis of Complex Systems) of the Universities of Oldenburg, Freiburg, and Saarbrücken. We discuss how properties of high-level specifications of real-time systems combining the dimensions of process behaviour, data, and time can be automatically verified, exploiting recent advances in semantics, constraint-based model checking, and decision procedures for complex data. As specification language we consider CS-OZ-DC, which integrates concepts from Communicating Sequential Processes (CSP), Object-Z (OZ), and Duration Calculus (DC). Our approach to automatic verification of CSP-OZ-DC rests on a compositional semantics of this languages in terms of Phase-Event-Automata. These can be translated into Transition Constraint Systems which serve as an input language of an abstract refinement model checker called ARMC which can handle constraints covering both real-time and infinite data. This is demonstrated by a case study concerning emergency messages in the European Train Control System (ETCS). For CSP-OZ-DC we also discuss a UML profile and tool support.","Real-time systems, complex data, CSP, Object-Z, Duration Calculus, model checking, abstraction refinement, UML profile, tool support",Proceedings of the 1st International Workshop on Harnessing Theories for Tool Support in Software (TTSS 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Gruer JP,Hilaire V,Koukam A,Rovarini P",,Heterogeneous formal specification based on Object-Z and statecharts: semantics and verification,Journal of Systems and Software,2004,70,1,95-105,,,,,2004,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121202001619;http://dx.doi.org/10.1016/S0164-1212(02)00161-9,10.1016/S0164-1212(02)00161-9,"This work presents a specification language, called OZS, based on two formalisms: Object-Z and the statecharts. Such a specification style facilitates the modeling of systems with both reactive and functional aspects. The accent is placed on OZS semantics so as to give formal foundations to verification and simulation of OZS models. Every OZS model has a transition system as its semantic interpretation. Untimed and timed versions of the OZS semantics are presented. Both transition system models of an OZS class can be used for verification purposes by model checking. In this work, a real-word example is treated and the resulting specification is model-checked by using the Stanford Temporal Prover environment from Stanford.","Object-Z, Statecharts, Transition systems, Model-checking",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"van Slooten K,Brinkkemper S","Prakash N,Rolland C,Pernici B",A Method Engineering Approach to Information Systems Development,,1993,,,167-186,,North-Holland,Amsterdam,Information System Development Process,1993,,0926-5473,https://www.sciencedirect.com/science/article/pii/B9780444815941500167;http://dx.doi.org/10.1016/B978-0-444-81594-1.50016-7,10.1016/B978-0-444-81594-1.50016-7,"Method Engineering is introduced as an approach to configure project specific methods for the development of information systems. We propose to support method engineering with a formal procedure to configure development scenarios from project characterizations. The project characterization is defined by a number of project contingency factors and determines the interest of aspects considered during the development of information systems. Process-, information-, behaviour-, organization-, and problem-oriented aspects constitute one dimension of a framework facilitating the selection of fragments of methods as components of the required scenario. The other dimension of the framework consists of two levels for the analysis and design process related to the levels of decomposition of the object system, or universe of discourse. Also, a development strategy is derived from the project characterization which means selecting a route map for information systems development. The available fragments of methods, and the route maps, will be stored in what we call a method base.",,,IFIP Transactions A: Computer Science and Technology,,,,,,,,,,,,,,,,,,,
Journal Article,"Törö M,Zhu J,Leung V",,Design of universal personal computing using SDL,Computer Communications,2000,23,12,1124-1134,,,,,2000,,0140-3664,https://www.sciencedirect.com/science/article/pii/S0140366499002418;http://dx.doi.org/10.1016/S0140-3664(99)00241-8,10.1016/S0140-3664(99)00241-8,"Universal Personal Computing (UPC) is a novel concept to support nomadic computing on the Internet. UPC enables mobile users to access their personalized computing environment anywhere on the Internet using any available terminals. The system is modeled as distributed objects using Common Object Request Broker Architecture (CORBA) to facilitate their distribution, interfacing, and integration. We have chosen the Specification and Description Language (SDL) for our system design. Through several iterations, we refine the specification and verify the correctness of the design. The final version serves as the basis for system implementation. The SDL specification allows a direct derivation of object interface description in Interface Definition Language (IDL). Finally some implementation issues are discussed.","Common Object Request Broker Architecture, Formal specification, Formal verification, User mobility, Specification and Description Language",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chiaselotti G,Gentile T,Infusino F",,Knowledge pairing systems in granular computing,Knowledge-Based Systems,2017,124,,144-163,,,,,2017,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705117301260;http://dx.doi.org/10.1016/j.knosys.2017.03.008,10.1016/j.knosys.2017.03.008,"In Pawlak’s theory of information systems, one has a collection of objects and knows the values of any object with respect a certain class of properties, usually called attributes. An implicit assumption of this theory is that the difference between the nature of objects and attributes is well outlined. In our paper we generalize the concept of information system by analyzing the case in which there is no a priori distinction in the nature of objects and attributes and, hence, both the interpretations are admissible. We call the structure arising in the previous context knowledge pairing system. We study the indiscernibility relations induced in both the admissible interpretations by means of up-down operators, in such a way to have a direct analogy with the extent and intent operators used in Formal Context Analysis. In particular, we investigate three models of knowledge pairing systems arising from real contexts and modeled respectively by graphs, digraphs and hypergraphs. We show the real convenience to use the notion of knowledge pairing system focusing on interpretation of this structure and discussing the two admissible perspectives obtained by avoiding the difference between the roles of objects and attributes.","Information tables, Rough sets, Graphs, Hypergraphs, Attribute dependency, Reducts, Subset operators, Granular computing, Directed graphs",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Belohlavek R,Vychodil V",,Discovery of optimal factors in binary data via a novel method of matrix decomposition,Journal of Computer and System Sciences,2010,76,1,3-20,,,,,2010,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000009000415;http://dx.doi.org/10.1016/j.jcss.2009.05.002,10.1016/j.jcss.2009.05.002,"We present a novel method of decomposition of an n×m binary matrix I into a Boolean product A○B of an n×k binary matrix A and a k×m binary matrix B with k as small as possible. Attempts to solve this problem are known from Boolean factor analysis where I is interpreted as an object–attribute matrix, A and B are interpreted as object–factor and factor–attribute matrices, and the aim is to find a decomposition with a small number k of factors. The method presented here is based on a theorem proved in this paper. It says that optimal decompositions, i.e. those with the least number of factors possible, are those where factors are formal concepts in the sense of formal concept analysis. Finding an optimal decomposition is an NP-hard problem. However, we present an approximation algorithm for finding optimal decompositions which is based on the insight provided by the theorem. The algorithm avoids the need to compute all formal concepts and significantly outperforms a greedy approximation algorithm for a set covering problem to which the problem of matrix decomposition is easily shown to be reducible. We present results of several experiments with various data sets including those from CIA World Factbook and UCI Machine Learning Repository. In addition, we present further geometric insight including description of transformations between the space of attributes and the space of factors.","Binary matrix decomposition, Factor analysis, Binary data, Formal concept analysis, Concept lattice",Special Issue on Intelligent Data Analysis,,,,,,,,,,,,,,,,,,,,
Journal Article,"Thomsen B,Abramsky S",,A fully abstract denotational semantics for the calculus of higher-order communicating systems,Theoretical Computer Science,2001,254,1,557-589,,,,,2001,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397500002814;http://dx.doi.org/10.1016/S0304-3975(00)00281-4,10.1016/S0304-3975(00)00281-4,"In this paper we study the Calculus of Higher Order Communicating Systems (CHOCS) (Thomsen, Proc. of POPL’89, ACM, 1989, pp. 143–154; Inform. Comput. 116(1) (1995) 38–57) in a denotational setting. We present a construction of a denotational semantics for CHOCS which resides in a domain constructed using the standard constructions of separated sum, Cartesian product, the Plotkin power domain constructor and recursively defined domains. We show, under mild restrictions, that the denotational semantics and the operational semantics of CHOCS are fully abstract. We have previously proved using bisimulation arguments that processes as first class objects are powerful enough to simulate recursion. However, the proof is very long and tedious. To demonstrate the power of the denotational approach we use it to obtain a very simple proof of the simulation of recursion result.","Higher-order communicating systems, Processes as first class objects, Denotational semantics, Fully abstract",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cioni G,Colagrossi A,Miola A",,A Sequent Calculus for Automated Reasoning in Symbolic Computation Systems,Journal of Symbolic Computation,1995,19,1,175-199,,,,,1995,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717185710115;http://dx.doi.org/10.1006/jsco.1995.1011,10.1006/jsco.1995.1011,"In this paper the problem of reasoning on properties of mathematical objects is considered in the context of symbolic computation. Automated reasoning mechanisms are proposed as a new basic computing tool in a symbolic computation system. These mechanisms are aimed to support the semantical correctness of a computation by allowing for verification of properties of mathematical objects introduced in the system and for generation and abduction of new properties of mathematical objects resulting from computations. The main objective of this paper is to define an extended sequent calculus to deal with generative and abductive logic problems, as well as with verificative problems, within a single methodological and computational environment. The implementation aspects of the proposed automated reasoning apparatus are also discussed. Examples of execution are presented and possible further applications are hinted.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Van den Bussche J,Van Gucht D,Vansummeren S",,Well-definedness and semantic type-checking for the nested relational calculus,Theoretical Computer Science,2007,371,3,183-199,,,,,2007,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397506008644;http://dx.doi.org/10.1016/j.tcs.2006.11.007,10.1016/j.tcs.2006.11.007,"The well-definedness problem for a programming language consists of checking, given an expression and an input type, whether the semantics of the expression is defined for all inputs adhering to the input type. A related problem is the semantic type-checking problem which consists of checking, given an expression, an input type, and an output type whether the expression always returns outputs adhering to the output type on inputs adhering to the input type. Both problems are undecidable for general-purpose programming languages. In this paper we study these problems for the Nested Relational Calculus, a specific-purpose database query language. We also investigate how these problems behave in the presence of programming language features such as singleton coercion and type tests.","Complex objects, Query equivalence, Semantic type-checking, Well-definedness",Database Theory,,,,,,,,,,,,,,,,,,,,
Journal Article,Bĕlohlávek R,,Concept lattices and order in fuzzy logic,Annals of Pure and Applied Logic,2004,128,1,277-298,,,,,2004,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007204000168;http://dx.doi.org/10.1016/j.apal.2003.01.001,10.1016/j.apal.2003.01.001,"The theory of concept lattices (i.e. hierarchical structures of concepts in the sense of Port-Royal school) is approached from the point of view of fuzzy logic. The notions of partial order, lattice order, and formal concept are generalized for fuzzy setting. Presented is a theorem characterizing the hierarchical structure of formal fuzzy concepts arising in a given formal fuzzy context. Also, as an application of the present approach, Dedekind–MacNeille completion of a partial fuzzy order is described. The approach and results provide foundations for formal concept analysis of vague data—the propositions “object x has attribute y”, which form the input data to formal concept analysis, are now allowed to have also intermediate truth values, meeting reality better.","Fuzzy logic, Concept lattice, Formal concept analysis, Fuzzy order",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Amato G,Coppola M,Gnesi S,Scozzari F,Semini L",,Modeling Web Applications by the Multiple Levels of Integrity Policy,Electronic Notes in Theoretical Computer Science,2006,157,2,167-185,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106002520;http://dx.doi.org/10.1016/j.entcs.2005.12.053,10.1016/j.entcs.2005.12.053,"We propose a formal method to validate the reliability of a web application, by modeling interactions among its constituent objects. Modeling exploits the recent “Multiple Levels of Integrity” mechanism which allows objects with dynamically changing reliability to cooperate within the application. The novelty of the method is the ability to describe systems where objects can modify their own integrity level, and react to such changes in other objects. The model is formalized with a process algebra, properties are expressed using the ACTL temporal logic, and can be verified by means of a model checker. Any instance of the above model inherits both the established properties and the proof techniques. To substantiate our proposal we consider several case-studies of web applications, showing how to express specific useful properties, and their validation schemata. Examples range from on-line travel agencies, inverted Turing test to detect malicious web-bots, to content cross-validation in peer to peer systems.","Formal Methods, Model Checking, Process Algebra, Temporal Logic",Proceedings of the International Workshop on Automated Specification and Verification of Web Sites (WWV 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Sadri MJ,Asaar MR",,An anonymous two-factor authentication protocol for IoT-based applications,Computer Networks,2021,199,,108460,,,,,2021,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128621004151;http://dx.doi.org/10.1016/j.comnet.2021.108460,10.1016/j.comnet.2021.108460,"Internet of things (IoT) allows people to establish a real-time connection with physical objects. To fulfill this lifelong ambition, the infrastructure of Wireless Sensor Networks (WSNs) plays a pivotal role. However, the public channel that is used by the sensors and users can imperil the security of their connection. Accordingly, many authentication protocol have been proposed to preserve the integrity and confidentiality of the transmitted messages. In this paper, we examine Wu et al.’s protocol as one of the most state-of-the-art protocols and prove that it is susceptible to sensor capture attack, user trace attack, and DoS attack, also it cannot provide forward secrecy. To mitigate these weaknesses, we propose our protocol and analyze that with both formal and informal methods to show that it is secure against various known attacks such as sensor and user trace, sensor capture, offline password guessing, and replay attacks. Finally, we evaluate our protocol in terms of security features and communication and computation costs. The results show that our protocol not only is more secure than other existing protocols but also reduces 62.1% of the computation cost and 30.76% of the communication cost in comparison with the costs of Wu et al.’s protocol.","IoT, WSNs, BAN logic, ROR model",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Brachman RJ,Levesque HJ","Brachman RJ,Levesque HJ",Chapter 14 - Actions,,2004,,,285-303,,Morgan Kaufmann,San Francisco,Knowledge Representation and Reasoning,2004,9781558609327,,https://www.sciencedirect.com/science/article/pii/B9781558609327500996;http://dx.doi.org/10.1016/B978-155860932-7/50099-6,10.1016/B978-155860932-7/50099-6,"Publisher Summary This chapter explores reasoning about action along with the study how beliefs about a changing world that can be represented in a dialect of first-order logic (FOL) called the situation calculus. This is not the only way to represent a changing world, but it is a simple and powerful way to do so. It also naturally lends itself to various sorts of reasoning, including planning. One way of thinking about change is to imagine being in a certain static situation and having an action move to the person from that situation to a new situation. The situation calculus is a dialect of FOL in which such situations and actions are explicitly taken to be objects in the domain. The chapter also defines the object of the puzzle that is to move the tiles within the grid so that each tile ends up at its correct location.",,,The Morgan Kaufmann Series in Artificial Intelligence,,,,,,,,,,,,,,,,,,,
Journal Article,Asher N,,"Selectional restrictions, types and categories",Journal of Applied Logic,2014,12,1,75-87,,,,,2014,,1570-8683,https://www.sciencedirect.com/science/article/pii/S1570868313000608;http://dx.doi.org/10.1016/j.jal.2013.08.002,10.1016/j.jal.2013.08.002,The expressions of a language distinguish between many different types of objects. These types can affect how the meanings of these expressions combine. This paper provides a formal picture of the process of meaning combination in a richly typed framework.,"Lexical semantics, Compositional semantics, Type theory",Logic Categories Semantics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Auvolat A,Frey D,Raynal M,Taïani F",,Byzantine-tolerant causal broadcast,Theoretical Computer Science,2021,885,,55-68,,,,,2021,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397521003662;http://dx.doi.org/10.1016/j.tcs.2021.06.021,10.1016/j.tcs.2021.06.021,"Causal broadcast is a communication abstraction built on top of point-to-point send/receive networks that ensures that any two messages whose broadcasts are causally related (as captured by Lamport's “happened before” relation) are delivered in their sending order. Several causal broadcast algorithms have been designed for failure-free and crash-prone asynchronous message-passing systems. This article first gives a formal definition of a causal broadcast abstraction in the presence of Byzantine processes, in the form of two equivalent characterizations, and then presents a simple causal broadcast algorithm that implements it. The main difficulty in the design and the proof of this algorithm comes from the very nature of Byzantine faults: Byzantine processes may have arbitrary behavior, and the algorithm must ensure that correct processes (i) maintain a coherent view of causality and (ii) are never prevented from communicating between themselves. To this end, the algorithm is built modularly, namely it works on top of any Byzantine-tolerant reliable broadcast algorithm. Due to this modularity, the proposed algorithm is easy to understand and inherits the computability assumptions (notably the maximal number of processes that may be Byzantine) and the message/time complexities of the underlying reliable broadcast on top of which it is built.","Algorithm, Asynchronous message-passing system, Byzantine process, Causal message delivery, Fault-tolerance, Modularity, Reliable broadcast, Simplicity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee YC,Eastman CM,Solihin W,See R",,Modularized rule-based validation of a BIM model pertaining to model views,Automation in Construction,2016,63,,1-11,,,,,2016,,0926-5805,https://www.sciencedirect.com/science/article/pii/S0926580515002319;http://dx.doi.org/10.1016/j.autcon.2015.11.006,10.1016/j.autcon.2015.11.006,"Diverse domain experts have defined the Industry Foundation Classes (IFC) Model View Definition (MVD), which encompasses their specialized requirements for building data exchanges and reflects practical construction processes. However, once an IFC file, a neutral format, is mapped with the specifications of the MVD through the export and import features of building information modeling (BIM) authoring tools, end-users find it challenging to validate the IFC file with regard to conformance to the data exchange requirements of the applied MVD. In addition, software vendors have trouble identifying the causes of errors regarding model views when they debug numerous mappings of native models to be translated into the IFC schema. To address these challenges, this research suggests a robust MVD validation process using a modularized validation platform that evaluates an IFC instance file according to diverse types of rule sets of MVDs. To extract rule templates that consist of ten types of rule logic this research employs the MVD of the precast concrete domain. Using the identified rule logic and checking structures, the MVD validation tool, which includes an object-oriented checking method and the IFC server ActiveX component, allows users to define various types of rule sets and validate an IFC instance file with regard to compliance with the syntax and semantics specified in the modularized concepts of the MVD.","Building information modeling (BIM), Model view definition (MVD), Industry Foundation Classes (IFC), Rule-based checking, Interoperability",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Altintaş O,Irmak H,Srivastava HM",,Fractional calculus and certain starlike functions with negative coefficients,Computers & Mathematics with Applications,1995,30,2,9-15,,,,,1995,,0898-1221,https://www.sciencedirect.com/science/article/pii/0898122195000738;http://dx.doi.org/10.1016/0898-1221(95)00073-8,10.1016/0898-1221(95)00073-8,"A certain subclass T(n,p,λ,α) of starlike functions in the unit disk is introduced. The object of the present paper is to derive several interesting properties of functions belonging to the class T(n,p,λ,α). Various distortion inequalities for fractional calculus of functions in the class T(n,p,λ,α) are also given.","Fractional calculus, Starlike functions, Analytic functions, Extremal function, Hadamard product, Cauchy-Schwarz inequality, Simply-connected region, Fractional integrals, Fractional derivatives",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Damm W,Josko B,Pnueli A,Votintseva A",,A discrete-time UML semantics for concurrency and communication in safety-critical applications,Science of Computer Programming,2005,55,1,81-115,,,,,2005,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642304001479;http://dx.doi.org/10.1016/j.scico.2004.05.012,10.1016/j.scico.2004.05.012,"We define a subset krtUML of UML which is rich enough to express such modelling entities of UML, used in real-time applications, as active objects, dynamic object creation and destruction, dynamically changing communication topologies, combinations of synchronous and asynchronous communication, and shared memory usage through object attributes. We define a formal interleaving semantics for this kernel language by associating with each model M∈krtUML a symbolic transition system STS(M). We briefly outline how to compile models of industrial systems making use of generalisation hierarchies, weak and strong aggregation, and hierarchical state-machines into krtUML. The main aim of the paper is to provide an executable semantics for krtUML suitable for the formal verification of temporal model properties with existing model-checking tools.",,Formal Methods for Components and Objects: Pragmatic aspects and applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Calcagno C,Helsen S,Thiemann P",,Syntactic Type Soundness Results for the Region Calculus,Information and Computation,2002,173,2,199-221,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540101931128;http://dx.doi.org/10.1006/inco.2001.3112,10.1006/inco.2001.3112,"The region calculus of Tofte and Talpin is a polymorphically typed lambda calculus with annotations that make memory allocation and deallocation explicit. It is intended as an intermediate language for implementing Hindley-Milner typed functional languages such as ML without traditional trace-based garbage collection. Static region and effect inference can be used to annotate a statically typed ML program with memory management primitives. Soundness of the calculus with respect to the region and effect system is crucial to guarantee safe deallocation of regions, i.e., deallocation should only take place for objects which are provably dead. The original soundness proof by Tofte and Talpin requires a complex co-inductive safety relation. In this paper, we present two small-step operational semantics for the region calculus and prove their type soundness with respect to the region and effect system. Following the standard syntactic approach of Wright, Felleisen, and Harper, we obtain simple inductive proofs. The first semantics is store-less. It is simple and elegant and gives rise to perspicuous proofs. The second semantics provides a store-based model for the region calculus. Albeit slightly more complicated, its additional expressiveness allows us to model operations on references with destructive update. A pure fragment of both small-step semantics is then proven equivalent to the original big-step operational approach of Tofte and Talpin. This leads to an alternative soundness proof for their evaluation-style formulation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bui H,Pierson HA,Nurre SG,Sullivan KM",,Tool Path Planning Optimization for Multi-Tool Additive Manufacturing,Procedia Manufacturing,2019,39,,457-464,,,,,2019,,2351-9789,https://www.sciencedirect.com/science/article/pii/S2351978920304601;http://dx.doi.org/10.1016/j.promfg.2020.01.389,10.1016/j.promfg.2020.01.389,"Additive manufacturing (AM) has revolutionized the way industries manufacture and prototype products. A significant drawback that prevents 3D printing from being widely implemented in large-scale production is cycle time. This issue has been improved by allowing multiple collaborating printheads to print different parts of the same object simultaneously. However, little formal research has been done to support the aforementioned approach, and current implementations have room for improvement in terms of both makespan and mechanical properties. A new toolpath optimization methodology is proposed in this research to fill this need. The objectives are to create a collision-free infill toolpath for each printhead while maintaining the mechanical performance and geometric accuracy of the printed object. The methodology utilizes the combination of tabu search and novel collision detection and resolution algorithms, TS-CCR. The performance of the TS-CCR is analyzed and compared with the current industry standard.","additive manufacturing, optimization, toolpath planning","25th International Conference on Production Research Manufacturing Innovation: Cyber Physical Manufacturing August 9-14, 2019 | Chicago, Illinois (USA)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Yan Y,Ren J,Sun G,Zhao H,Han J,Li X,Marshall S,Zhan J",,Unsupervised image saliency detection with Gestalt-laws guided optimization and visual attention based refinement,Pattern Recognition,2018,79,,65-78,,,,,2018,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320318300517;http://dx.doi.org/10.1016/j.patcog.2018.02.004,10.1016/j.patcog.2018.02.004,"Visual attention is a kind of fundamental cognitive capability that allows human beings to focus on the region of interests (ROIs) under complex natural environments. What kind of ROIs that we pay attention to mainly depends on two distinct types of attentional mechanisms. The bottom-up mechanism can guide our detection of the salient objects and regions by externally driven factors, i.e. color and location, whilst the top-down mechanism controls our biasing attention based on prior knowledge and cognitive strategies being provided by visual cortex. However, how to practically use and fuse both attentional mechanisms for salient object detection has not been sufficiently explored. To the end, we propose in this paper an integrated framework consisting of bottom-up and top-down attention mechanisms that enable attention to be computed at the level of salient objects and/or regions. Within our framework, the model of a bottom-up mechanism is guided by the gestalt-laws of perception. We interpreted gestalt-laws of homogeneity, similarity, proximity and figure and ground in link with color, spatial contrast at the level of regions and objects to produce feature contrast map. The model of top-down mechanism aims to use a formal computational model to describe the background connectivity of the attention and produce the priority map. Integrating both mechanisms and applying to salient object detection, our results have demonstrated that the proposed method consistently outperforms a number of existing unsupervised approaches on five challenging and complicated datasets in terms of higher precision and recall rates, AP (average precision) and AUC (area under curve) values.","Background connectivity, Gestalt laws guided optimization, Image saliency detection, Feature fusion, Human vision perception",,,,,,,,,,,,,,,,,,,,,
Journal Article,Stump A,,Imperative LF Meta-Programming,Electronic Notes in Theoretical Computer Science,2008,199,,149-159,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108000832;http://dx.doi.org/10.1016/j.entcs.2007.11.017,10.1016/j.entcs.2007.11.017,"Logical frameworks have enjoyed wide adoption as meta-languages for describing deductive systems. While the techniques for representing object languages in logical frameworks are relatively well understood, languages and techniques for meta-programming with them are much less so. This paper presents work in progress on a programming language called Rogue-Sigma-Pi (RSP), in which general programs can be written for soundly manipulating objects represented in the Edinburgh Logical Framework (LF). The manipulation is sound in the sense that, in the absence of runtime errors, any putative LF object produced by a well-typed RSP program is guaranteed to type check in LF. An important contribution is an approach for soundly combining imperative features with higher-order abstract syntax. The focus of the paper is on demonstrating RSP through representative LF meta-programs.","Meta-Programming, Logical Frameworks, Rewriting Calculus",Proceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages (LFM 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Dotti FL,Duarte LM,Foss L,Ribeiro L,Russi D,dos Santos OM",,An Environment for the Development of Concurrent Object-Based Applications,Electronic Notes in Theoretical Computer Science,2005,127,1,3-13,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105001015;http://dx.doi.org/10.1016/j.entcs.2004.12.026,10.1016/j.entcs.2004.12.026,"Object-Based Graph Grammars (OBGG) is a formal specification language suitable for modeling concurrent object-based systems. On previous work we have mainly discussed the language along with case studies and analysis techniques (model checking and simulation) for systems described in OBGG. In this paper we present the set of tools we have developed and/or integrated to build an environment for the development of concurrent object-based systems. With this environment, we support the specification and analysis of concurrent object-based systems specified using OBGG.","Edition, verification, simulation, code generation",Proceedings of the International Workshop on Graph-Based Tools (GraBaTs 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Qian T,Wei L,Qi J",,Constructing three-way concept lattices based on apposition and subposition of formal contexts,Knowledge-Based Systems,2017,116,,39-48,,,,,2017,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705116304270;http://dx.doi.org/10.1016/j.knosys.2016.10.033,10.1016/j.knosys.2016.10.033,"Three-way concept analysis provides a new model to make three-way decisions. Its basic structure can be shown by the three-way concept lattices. Thus, how to construct three-way concept lattices is an important issue in the three-way concept analysis. This paper proposes approaches to create the three-way concept lattices of a given formal context. First, we can transform the given formal context and its complementary context into new formal contexts which are isomorphic to the given formal context and its complementary context respectively. And then, Type I-combinatorial context and Type II-combinatorial context are defined, which are apposition and subposition of these new formal contexts, respectively. Second, we prove that the concept lattice of Type I-combinatorial context is isomorphic to object-induced three-way concept lattice and the concept lattice of Type II-combinatorial context is isomorphic to attribute-induced three-way concept lattice of the given formal context. And then, the approaches of creating the three-way concept lattices are proposed based on the concept lattices of Type I-combinatorial context and Type I-combinatorial context. Finally, we give the corresponding algorithms of constructing three-way concept lattices based on the above approaches and conduct several experiments to illustrate the efficient of proposed algorithms.","Three-way concept lattice, Three-way decision, Apposition, Subposition",,,,,,,,,,,,,,,,,,,,,
Journal Article,"McCrosky C,Dutta D",,A type-theoretic semantics of arrays,Applied Mathematics Letters,1990,3,1,83-87,,,,,1990,,0893-9659,https://www.sciencedirect.com/science/article/pii/089396599090073K;http://dx.doi.org/10.1016/0893-9659(90)90073-K,10.1016/0893-9659(90)90073-K,"A type-theoretic definition of nested, heterogeneous arrays is given. A subtype relationship is defined for this domain, and subtype polymorphic inheritance is established.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Amaral WC,Bingulac SP,Ferreira PA,Fontanini W,Gomide FA",Zhen-Yu C,A KNOWLEDGE BASED ENVIRONMENT FOR COMPUTER AIDED CONTROL ENGINEERING,,1989,,,359-364,,Pergamon,Oxford,Computer Aided Design in Control Systems 1988,1989,9780080357386,,https://www.sciencedirect.com/science/article/pii/B9780080357386500628;http://dx.doi.org/10.1016/B978-0-08-035738-6.50062-8,10.1016/B978-0-08-035738-6.50062-8,"Computer Aided Control Engineering is addressed in the context of an integrated environment. A set of functional requirements is stated as a basis for the development of a software structure which can be viewed as a composite object consisting of design, analysis, specification, validation and implementation tools, as well as a problem oriented language, a information structure and a knowledge base to assist the user in the problem formulation and solving tasks and other usual support tools that are part of CACE environments. The aim is to develop an efficient, modem, integrated and powerful environment for control and systems engineering education, research and development. The paper not only presents the basic requirements but also a logical structure for such an environment, describing its characteristics in terms of the methodological context, conceptual modeling, formal problem oriented languages, knowledge representation. Presently, the proposed environment is being developed, and experiments with a prototype expert system have been made to enrich and validate the ideas herein discussed.",,,IFAC Symposia Series,,,,,,,,,,,,,,,,,,,
Journal Article,Westphal B,,LSC Verification for UML Models with Unbounded Creation and Destruction,Electronic Notes in Theoretical Computer Science,2006,144,3,133-145,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106000648;http://dx.doi.org/10.1016/j.entcs.2006.01.009,10.1016/j.entcs.2006.01.009,"The approaches to automatic formal verification of UML models known up to now require a finite bound on the number of objects existing at each point in time. In [W. Damm, B. Westphal, Live and let die: LSC-based verification of UML-models, Science of of Computer Programming 55 (2005) 117–159] we have observed that the class of hardware systems with replicated components studied by McMillan [K.L. McMillan, A methodology for hardware verification using compositional model checking, Science of Computer Programming 37 (2000) 279–309] is equivalent to the class of systems where the only source of infiniteness is unbounded creation and destruction of objects, i.e. where all data-types except for object identities are finite. Exploiting the symmetry of UML models induced by objects being instances of classes, the restriction to finite bounds can be overcome applying [K.L. McMillan, A methodology for hardware verification using compositional model checking, Science of Computer Programming 37 (2000) 279–309]. In this paper we report on experiences from an evaluation of this approach within the UML Verifi- cation Environment (UVE) [I. Schinz, T. Toben, C. Mrugalla and B. Westphal, The Rhapsody UML Verification Environment, in: J.R. Cuellar and Z. Liu, editors, Proceedings SEFM 2004 (2004), pp. 174–183], a state-of-the-art tool for formal verification of UML models using Live Sequence Charts (LSC) [W. Damm, D. Harel, LSCs: Breathing Life into Message Sequence Charts, Formal Methods in System Design 19 (2001) 45–80] for requirements specification.","Formal Verification, Infinite-state, UML, LSC",Proceedings of the Workshop on Software Model Checking (SoftMC 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,Talcott CL,,A Formal Framework for Interactive Agents,Electronic Notes in Theoretical Computer Science,2008,203,3,95-106,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108003034;http://dx.doi.org/10.1016/j.entcs.2008.04.088,10.1016/j.entcs.2008.04.088,"This paper proposes a formal framework and architecture for specification and analysis of interactive agents. The framework can be used to explore the design space, study features of different points in the design space, and to develop executable specifications of specific agents and study their interactions with the environment. A long term goal is development of reasoning principles specialized to different regions of the design space.","interaction, coordination, distributed object reflection, policy, autonomy",Proceedings of the Workshop on the Foundations of Interactive Computation (FInCo 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Menon MS,Gurumoorthy B,Ghosal A",,Efficient simulation and rendering of realistic motion of one-dimensional flexible objects,Computer-Aided Design,2016,75-76,,13-26,,,,,2016,,0010-4485,https://www.sciencedirect.com/science/article/pii/S0010448516000154;http://dx.doi.org/10.1016/j.cad.2016.02.003,10.1016/j.cad.2016.02.003,"In gross motion of flexible one-dimensional (1D) objects such as cables, ropes, chains, ribbons and hair, the assumption of constant length is realistic and reasonable. The motion of the object also appears more natural if the motion or disturbance given at one end attenuates along the length of the object. In an earlier work, variational calculus was used to derive natural and length-preserving transformation of planar and spatial curves and implemented for flexible 1D objects discretized with a large number of straight segments. This paper proposes a novel idea to reduce computational effort and enable real-time and realistic simulation of the motion of flexible 1D objects. The key idea is to represent the flexible 1D object as a spline and move the underlying control polygon with much smaller number of segments. To preserve the length of the curve to within a prescribed tolerance as the control polygon is moved, the control polygon is adaptively modified by subdivision and merging. New theoretical results relating the length of the curve and the angle between the adjacent segments of the control polygon are derived for quadratic and cubic splines. Depending on the prescribed tolerance on length error, the theoretical results are used to obtain threshold angles for subdivision and merging. Simulation results for arbitrarily chosen planar and spatial curves whose one end is subjected to generic input motions are provided to illustrate the approach.","One-dimensional flexible body, Natural motion, Control polygon, Approximate length preservation, Subdivision, Merging",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ni S,Zhuang Y,Gu J,Huo Y",,A formal model and risk assessment method for security-critical real-time embedded systems,Computers & Security,2016,58,,199-215,,,,,2016,,0167-4048,https://www.sciencedirect.com/science/article/pii/S0167404816000079;http://dx.doi.org/10.1016/j.cose.2016.01.005,10.1016/j.cose.2016.01.005,"Risk assessment at the early stage of software development can effectively reduce potential security flaws in the software, thus reduce the cost of testing and maintenance. However, there are very few standardized risk assessment methods toward the design models of security-critical RTESs (real-time embedded systems). This paper defines a formal model called OMR (Object–Message–Role) using Z notation for the security-critical RTESs. Comparing with the existing models for RTESs, OMR is able to specify both the functional and security aspects of the system as an integrated model, which directly provides the input for risk assessment. A risk assessment method RAMES (risk assessment method for embedded systems) based on OMR is then proposed. RAMES is complianced with the risk management process standardized by ISO 31000. To perform the risk analysis in RAMES, an algorithm RAOMR is designed based on the analysis of the message flows and security constraints in OMR. The illustration of a case study shows that RAMES is able to evaluate the risk level of the system model, and locate the high-risky objects and messages.","Risk assessment, Security, Real-time embedded systems, Formal method, Z notation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Marín-Lora C,Chover M,Sotoca JM,García LA",,A game engine to make games as multi-agent systems,Advances in Engineering Software,2020,140,,102732,,,,,2020,,0965-9978,https://www.sciencedirect.com/science/article/pii/S096599781930376X;http://dx.doi.org/10.1016/j.advengsoft.2019.102732,10.1016/j.advengsoft.2019.102732,"Video games are applications that present design patterns that resemble multi-agent systems. Game objects or actors are like autonomous agents that interact with each other to describe complex systems. The purpose of this work is to develop a game engine to build games as multi-agent systems. The actors or game engine agents have a set of properties and behaviour rules with the end to interact with the environment of the game. The behaviour definition is established through a formal semantic based on predicate logic. The proposed engine tries to fulfil the basic requirements of the multi-agent systems, by adjusting the characteristics of the system, without affecting its potential. Finally, a set of games are introduced to validate the operation and possibilities of the engine.","Game development, Game engine, Multi-agent system",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Machado JA,Lopes AM",,On the mathematical modeling of soccer dynamics,Communications in Nonlinear Science and Numerical Simulation,2017,53,,142-153,,,,,2017,,1007-5704,https://www.sciencedirect.com/science/article/pii/S1007570417301338;http://dx.doi.org/10.1016/j.cnsns.2017.04.024,10.1016/j.cnsns.2017.04.024,"This paper addresses the modeling and dynamical analysis of soccer teams. Two modeling perspectives based on the concepts of fractional calculus are adopted. In the first, the power law behavior and fractional-order integration are explored. In the second, a league season is interpreted in the light of a system where the teams are represented by objects (particles) that evolve in time and interact (collide) at successive rounds with dynamics driven by the outcomes of the matches. The two proposed models embed implicitly details of players and coaches, or strategical and tactical maneuvers during the matches. Therefore, the scale of observation focuses on the teams behavior in the scope of the observed variables. Data characterizing two European soccer leagues in the season 2015–2016 are adopted and processed. The model leads to the emergence of patterns that are analyzed and interpreted.","Discrete systems, Complex systems, Sport dynamics, Power law, Multidimensional scaling, Fractional calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bittner T,Donnelly M",,Logical properties of foundational relations in bio-ontologies,Artificial Intelligence in Medicine,2007,39,3,197-216,,,,,2007,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365706001928;http://dx.doi.org/10.1016/j.artmed.2006.12.005,10.1016/j.artmed.2006.12.005,"Summary Objective We compare the advantages of specifying the semantics of foundational relations in bio-medical terminology systems using different types of formal deductive systems: first-order logic (FOL) and description logics (DLs). Method As our focus example, we use a terminology whose basic terms are supposed to designate proper parthood relations, subdivision relations, and surrounded-by relations. Each type of relation captures an important and distinct aspect of the spatial organization of anatomical structures: the general part-whole structure (proper parthood), the division of salient anatomical objects into discrete, tree-like structures (subdivision-of), and the nesting of anatomical objects into containers (surrounded-by). We show that all three types of relations are strict partial orderings (i.e., asymmetric and transitive). Ontologies whose purpose is to specify the semantics of terms referring to these types of relations must include axioms strong enough to formally distinguish among them. We compare the extent to which axioms characterizing proper parthood, subdivision, and surrounded-by relations can be represented in first-order logic and various description logics. Conclusions The development of bio-medical ontologies requires a rigorous formal analysis of foundational relations. Different kinds of formal tools may be used in this process. Ideally, an analysis in a highly expressive language, such as first-order logic, should be worked out in conjunction with analyses in less expressive but computationally tractable deductive systems such as description logics.","Biomedical ontologies, Formal ontology, Mereology, Axiomatic theories, Description logic",Ontological Foundations for Biomedical Sciences,,,,,,,,,,,,,,,,,,,,
Journal Article,"Deslandres V,Pierreval H",,Knowledge acquisition issues in the design of decision support systems in quality control,European Journal of Operational Research,1997,103,2,296-311,,,,,1997,,0377-2217,https://www.sciencedirect.com/science/article/pii/S0377221797001215;http://dx.doi.org/10.1016/S0377-2217(97)00121-5,10.1016/S0377-2217(97)00121-5,"Implementation of formal quality policy in manufacturing environments requires extensive knowledge in many different fields: (1) knowledge of the problems that can be found; (2) knowledge of the methods and procedures that can definitively improve the process; (3) knowledge of the quality techniques that can be used; and (4) how to implement these techniques in manufacturing environments. Different experts are able to provide such knowledge, ranging from operators to quality engineers which for example provide knowledge about specialised quality tools. Intelligent decision support systems (DSS) can be used to make quality expertise available to people who face quality problems every day. However, these systems are difficult to elaborate especially due to the acquisition and modelling tasks, considered as the bottleneck of intelligent systems development. Based on our experience of DSS development in the quality area, we propose here to analyze and classify the knowledge necessary to develop advisory systems for quality applications (e.g. process diagnosis, selection of quality tools and configuration of quality tools). Elicitation methods which have been proved successful for extracting quality knowledge are presented as well as guidelines for the design of acquisition sheets. Then we propose to describe the subsets of knowledge in a unified structure, which can be further implemented by the use of object-oriented formalism and rules. The structure greatly facilitates the design of advisory quality systems in manufacturing environments.","Quality decision support systems, Quality control knowledge, Quality experts, Knowledge-based systems, Acquisition methodologies, Elicitation techniques",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aboamer Y,Kracht M",,Representing Meaning of Arabic Sentence Dynamically and more Smoothly,Procedia Computer Science,2018,142,,321-327,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S187705091832194X;http://dx.doi.org/10.1016/j.procs.2018.10.490,10.1016/j.procs.2018.10.490,"This paper presents work in progress on the formal representation of the meanings of Arabic sentences. It, specifically, deals with two limitations in the current approaches to Arabic sentence representation, namely, object identification and variable naming. Generally, the amount of work and research devoted to this area is very limited due to its high complexity. These limited attempts have adopted, either a Montagovian formalization, or a unification-based formalism. However, the two approaches have drawbacks. Montague’s framework has been criticized for its inadequacy to handle the anaphoric pronouns. The discourse representation theory (DRT) has provided a solution for this problem by the systematic use of free variables. However, the choice of names of the variables has remained problematic. That is, taking the set union on the set of markers, the idea of Henk Zeevat, means that the discourse representation structures (DRSs), containing the same names of variables, are taken to refer to the same object. Consequently, one should be extremely careful, whenever choosing these names. Instead, we adopt the so-called referent system, as proposed by Kees Vermeulen, in which the sets of variables are made disjoint, and the names of the variables are assigned locally, instead of assigning them globally in Zeevat’s approach. This original form of referent system fits well with a specific word order, namely SVO, because the renaming process is based on syntax. Arabic is characterized by a flexible word order, which restricts the role played by directionality in the renaming process. Consequently, we make some modifications to referent systems to associate variables in the DRSs with morphosyntactic information. This means that variables are identified if and only if morphosyntactic information matches.","Referent Systems, Dynamic semantic, Formal Representation of Meaning, Compositionality, Arabic NLP",Arabic Computational Linguistics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shoham Y,McDermott D",,Problems in formal temporal reasoning,Artificial Intelligence,1988,36,1,49-61,,,,,1988,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370288900781;http://dx.doi.org/10.1016/0004-3702(88)90078-1,10.1016/0004-3702(88)90078-1,"Ever since its introduction by McCarthy and Hayes in 1969, the so-called frame problem has been the object of much fascination and debate. Although it was defined in the narrow context of the situation calculus, a specific temporal formalism, it was clear from the start that it is in fact a manifestation of some fundamental problem in temporal reasoning. Our aim in this informal paper is to identify the general form of certain classes of problems that arise in formal temporal reasoning. We argue that problems such as the frame problem arise from the conflicting desires to reason both rigorously and efficiently about the future. This conflict does not depend on the particular underlying temporal formalism. In particular, we identify two formalism-independent problems, called the qualification problem and the extended prediction problem, which subsume the frame problem. To illustrate the fact that these problems are indeed inherent to the prediction task and not to a particular formalism, we show that they arise in two distinct frameworks: classical mechanics, and Hayes' histories notation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Schürmann C,Despeyroux J,Pfenning F",,Primitive recursion for higher-order abstract syntax,Theoretical Computer Science,2001,266,1,1-57,,,,,2001,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397500004187;http://dx.doi.org/10.1016/S0304-3975(00)00418-7,10.1016/S0304-3975(00)00418-7,"Higher-order abstract syntax is a central representation technique in logical frameworks which maps variables of the object language into variables of the meta-language. It leads to concise encodings, but is incompatible with functions defined by primitive recursion or proofs by induction. In this paper we propose an extension of the simply typed lambda-calculus with iteration and case constructs which preserves the adequacy of higher-order abstract syntax encodings. The well-known paradoxes are avoided through the use of a modal operator which obeys the laws of S4. In the resulting calculus many functions over higher-order representations can be expressed elegantly. Our central technical result, namely that our calculus is conservative over the simply typed lambda-calculus, is proved by a rather complex argument using logical relations. We view our system as an important first step towards allowing the methodology of LF to be employed effectively in systems based on induction principles such as ALF, Coq, or NuPrl, leading to a synthesis of currently incompatible paradigms.","Typed lambda calculus, Higher-order abstract syntax, Primitive recursion, Modal logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ricci A,Viroli M,Cimadamore M",,Prototyping Concurrent Systems with Agents and Artifacts: Framework and Core Calculus,Electronic Notes in Theoretical Computer Science,2008,194,4,111-132,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108002077;http://dx.doi.org/10.1016/j.entcs.2008.03.102,10.1016/j.entcs.2008.03.102,"More and more aspects of concurrency and concurrent programming are becoming part of mainstream programming and software engineering, due to several factors such as the widespread availability of multi-core / parallel architectures and Internet-based systems. Besides the typical fine-grained support currently provided, however, we seek in this paper for an higher-level approach. We present simpA, a library-based extension of Java which provides programmers with agent and artifact abstractions on top of the basic OO layer, as a means to organise and structure concurrent applications. To pave the way towards identifying a true language extension for simpA, we define a core calculus of agents and artifacts, by suitabling mixing techniques coming from object-orientation and concurrency theory.","multiprogramming, agents and artifacts, Multiagent systems, concurrent programming, core calculi",Proceedings of the 6th International Workshop on the Foundations of Coordination Languages and Software Architectures (FOCLASA 2007),,,,,,,,,,,,,,,,,,,,
Book Chapter,Maeder RE,Maeder RE,Chapter One - Introduction,,1994,,,3-15,,Academic Press,,The Mathematica® Programmer,1994,9780124649903,,https://www.sciencedirect.com/science/article/pii/B9780124649903500074;http://dx.doi.org/10.1016/B978-0-12-464990-3.50007-4,10.1016/B978-0-12-464990-3.50007-4,"Publisher Summary Mathematica (symbolic computation system) is a programming language that differs from traditional similar programming language. It is a large language with many built-in functions. This becomes possible by using only rewrite rules as the underlying mechanism for implementing all other programming constructs. Such a language is also interactive and, therefore, easy to use. It is not necessary to compile functions or to embed them into a main program to use them. There are no procedures, functions, or subroutines in Mathematica. An important difference from traditional procedural languages concerns the treatment of formal parameters of functions or procedures. It is easy to emulate C-style procedure parameters. On the other hand, parameter passing by reference (var parameters in PASCAL, pointers in C, references in C++) is also possible. Pattern matching and term rewriting represent the fundamental principle of Mathematica's evaluator. All other programming constructs are implemented in terms of it. It is especially useful for implementing rules corresponding to transformations from a handbook of formulae. This by-product programming language can commit commonly identified programming styles like functional programming, structural operations, logic programming, abstract data types, object-oriented programming, and modularization.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Boyer RS,Moore JS","Boyer RS,Moore JS",4 - A Precise Description of the Logic,,1988,,,93-141,,Academic Press,,A Computational Logic Handbook,1988,9780121229528,,https://www.sciencedirect.com/science/article/pii/B9780121229528500081;http://dx.doi.org/10.1016/B978-0-12-122952-8.50008-1,10.1016/B978-0-12-122952-8.50008-1,"Publisher Summary This chapter presents the precise description of the logic. The set of variable and function symbols is influenced by conventions of half a dozen different Lisp systems. The set of axioms is unnecessarily large from the purely logical viewpoint. A general purpose quantifier over finite domains is provided; even though recursively defined functions suffice. An interpreter for the logic is embedded in the logic, and every new function symbol must be axiomatically tied to the interpreter. The metalanguage is greatly complicated by the necessity of describing the correspondence between terms and objects. Using the formal syntax, one presents the axioms and rules of inference for propositional calculus with equality, the foundation of theory. Next one embeds propositional calculus and equality in the term structure of the logic by defining functional analogs of the propositional operators. One completes the set of axioms by defining general purpose quantifier function, which—much like the mapping functions of Lisp—includes among its arguments objects denoting terms that are evaluated with the interpreter.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Ayres RF,,A simple and powerful type system for programming languages,Journal of Systems and Software,2004,73,2,301-311,,,,,2004,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121203002607;http://dx.doi.org/10.1016/j.jss.2003.09.011,10.1016/j.jss.2003.09.011,"A type system serves to guarantee that programs mix data of distinct types only as allowed by programmer declared rules. For example, a function declaration corresponds to one of these rules, providing a way to mix data of distinct types, possibly producing data of another type as a result. A type system also discovers the type of each (sub)expression throughout a program. This paper introduces a type system where types are parts of speech, and all relations among types are represented by a grammar, a grammar whose rules are written in terms of the types. In order to resolve types, i.e., discover which type each (sub)expression is, the type grammar may be used to parse a given program, as a second pass. A brief, Polish postfix programming language rich in types is presented, called the type grammar, as well as a way to translate down from a more natural syntax. We show how to extend the type grammar with new rules based on program declarations. By parsing with this postfix type grammar, unrestricted overloading (more powerful than Java’s) and unrestricted programmer-defined coercions (in some ways more powerful than multiple inheritance) may be implemented and understood in a straightforward manner. To realize these, a powerful parser like Earley’s efficient context-free parser, or others, which tolerate ambiguity efficiently, are required. We conclude by showing how a pair of coercions, in a cycle, proves useful.",,Applications of statistics in software engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Meyer B,Nerson JM,Ko SH",,Showing programs on a screen,Science of Computer Programming,1985,5,,111-142,,,,,1985,,0167-6423,https://www.sciencedirect.com/science/article/pii/0167642385900085;http://dx.doi.org/10.1016/0167-6423(85)90008-5,10.1016/0167-6423(85)90008-5,"We present a strategy and algorithms for displaying a meaningful view of structured objects such as programs on a screen of limited size. The methods introduced here are language-independent; they were developed for the implementation of Cépage, a structural editor making full use of modern display technology. The algorithms are linear with respect to the number of nodes in the syntax tree. We use a formal model of the screen allocation, the ‘calculus of windows’, which makes it possible to reason about the display process at a proper level of abstraction. A systematic approach was followed, in which a number of ‘invariants’ and ‘attributes’ were defined before the actual construction of the algorithms and data structures, and served as a basis for their development; the paper describes the methodology used and includes a semi-formal correctness proof of the main algorithm, which involves mutually recursive procedures.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ibrahim RW,Sokół J",,On a new class of analytic function derived by a fractional differential operator,Acta Mathematica Scientia,2014,34,5,1417-1426,,,,,2014,,0252-9602,https://www.sciencedirect.com/science/article/pii/S025296021460093X;http://dx.doi.org/10.1016/S0252-9602(14)60093-X,10.1016/S0252-9602(14)60093-X,"Making use of the fractional differential operator, we impose and study a new class of analytic functions in the unit disk (type fractional differential equation). The main object of this paper is to investigate inclusion relations, coefficient bound for this class. Moreover, we discuss some geometric properties of the fractional differential operator.","analytic function, fractional calculus, fractional differential operator, univalent function, unit disk, bounded turning function",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Meredith LG,Radestock M",,A Reflective Higher-order Calculus,Electronic Notes in Theoretical Computer Science,2005,141,5,49-67,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105051893;http://dx.doi.org/10.1016/j.entcs.2005.05.016,10.1016/j.entcs.2005.05.016,"The π-calculus is not a closed theory, but rather a theory dependent upon some theory of names. Taking an operational view, one may think of the π-calculus as a procedure that when handed a theory of names provides a theory of processes that communicate over those names. This openness of the theory has been exploited in π-calculus implementations, where ancillary mechanisms provide a means of interpreting of names, e.g. as tcp/ip ports. But, foundationally, one might ask if there is a closed theory of processes, i.e. one in which the theory of names arises from and is wholly determined by the theory of processes. Here we present such a theory in the form of an asynchronous message-passing calculus built on a notion of quoting. Names are quoted processes, and as such represent the code of a process, a reification of the syntactic structure of the process as an object for process manipulation. Name- passing in this setting becomes a way of passing the code of a process as a message. In the presence of a dequote operation, turning the code of a process into a running instance, this machinery yields higher-order characteristics without the introduction of process variables. As is standard with higher-order calculi, replication and/or recursion is no longer required as a primitive operation. Somewhat more interestingly, the introduction of a process constructor to dynamically convert a process into its code is essential to obtain computational completeness, and simultaneously supplants the function of the ν operator. In fact, one may give a compositional encoding of the ν operator into a calculus featuring dynamic quote as well as dequote.","concurrency, message-passing, process calculus, reflection",Proceedings of the Workshop on the Foundations of Interactive Computation (FInCo 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Balaban M,Eyal A",,DFL – a dialog based integration of concept and rule reasoners,Data & Knowledge Engineering,2001,38,3,301-334,,,,,2001,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X01000325;http://dx.doi.org/10.1016/S0169-023X(01)00032-5,10.1016/S0169-023X(01)00032-5,"Description logics (DLs) are subsets of first-order logic (FOL), designed for reasoning about class-based knowledge. Their expressive power is deliberately restricted, so as to enable efficient inference. A DL reasoner or knowledge base is intended to be embedded as a special purpose component in a heterogeneous knowledge base. Therefore, the development of integration frameworks of DLs and other forms of reasoning is essentially important. In this paper, we introduce a formal scheme for the integration of information sources for which a combined declarative semantics is not available. The integration is defined by a syntactic compositional semantics, and implemented by a dialog process in which the independent reasoners make their failures public. This scheme is used to formalize the integration of a DL reasoner with an expressive rule reasoner (for which a combined declarative semantics is not known). It is implemented in the DFL system, that integrates a DL reasoner and an F-Logic rule reasoner. The integrated system gives rise to a rich dialog between its components, since the DL inferences can trigger new rule inferences, and rule inferences can trigger new DL inferences. The DFL system is the first to support a true dialog between a DL and a rule reasoners, that operate under different semantical policies, e.g., the open world assumption (OWA) for the DL reasoner, and the closed world assumption (CWA) for the rule reasoner. This architecture generalizes all existing hybrids of descriptions and rules.","Integrated systems, Description logics, Rule base, Object-oriented systems, F-Logic, Compositional semantics, Closed-world reasoning, Open-world reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Guo L,Keigher W",,On differential Rota–Baxter algebras,Journal of Pure and Applied Algebra,2008,212,3,522-540,,,,,2008,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404907001557;http://dx.doi.org/10.1016/j.jpaa.2007.06.008,10.1016/j.jpaa.2007.06.008,"A Rota–Baxter operator of weight λ is an abstraction of both the integral operator (when λ=0) and the summation operator (when λ=1). We similarly define a differential operator of weight λ that includes both the differential operator (when λ=0) and the difference operator (when λ=1). We further consider an algebraic structure with both a differential operator of weight λ and a Rota–Baxter operator of weight λ that are related in the same way that the differential operator and the integral operator are related by the First Fundamental Theorem of Calculus. We construct free objects in the corresponding categories. In the commutative case, the free objects are given in terms of generalized shuffles, called mixable shuffles. In the noncommutative case, the free objects are given in terms of angularly decorated rooted forests. As a byproduct, we obtain structures of a differential algebra on decorated and undecorated planar rooted forests.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Andrew G,Carolyn P,Andrew T",,Preface: Volume 10,Electronic Notes in Theoretical Computer Science,1998,10,,1,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580684X;http://dx.doi.org/10.1016/S1571-0661(05)80684-X,10.1016/S1571-0661(05)80684-X,"This issue of ENTCS is an unrefereed conference record of talks presented at the Second Workshop on Higher Order Operational Techniques in Semantics (HOOTS II) held at Stanford University, December 8-11, 1997. The meeting was organised by A. Gordon, A. Pitts and C. Talcott with generous sponsorship from Harlequin Ltd, NSF and ONR. The first HOOTS workshop was held October 28-30, 1995 as part of the University of Cambridge Isaac Newton Institute research programme on Semantics of Computation (July-Dec 1995). The study of operational techniques for higher-order languages is now a thriving area, with much research activity going on world-wide. An important open problem is a theory of program equivalence for languages with higher-order features, including functions and objects. Techniques for defining and reasoning about equivalence and other properties of higher-order programs have emerged in distinct communities, including the concurrency, functional programming and type theory communities. The purpose of the HOOTS workshops was to bring researchers from these communities together to discuss current trends in the theory of operational semantics, its application to higher-order languages and its connection with more established semantic techniques. Papers presented at HOOTS II covered a broad range of topics: •techniques such as bisimulation and logical relations for reasoning about contextual equivalence•alternative program relations such as operational subsumption, and evaluation rules for program contexts•operational models including adaptation of big-step evaluation semantics to provide capabilities of small-step and denotational semantics forms, flow graphs, and history dependent automata•higher-order programming calculi including: imperative call-by-need lambda calculus, action calculi, process calculi for reasoning about mobility and security, interaction of actors and pi calculus agents•approaches to program analysis and verification, including: logics for control flow analysis, monadic type systems, and diagramatic specification notation for actor systems;•programming environment tools such a type systems for Java byte-code, and higher-order program units for modularity. Programs and participants lists for HOOTS I and II and other information about HOOTS, past and future can be found here",,"HOOTS II, Second Workshop on Higher-Order Operational Techniques in Semantics",,,,,,,,,,,,,,,,,,,,
Book Chapter,Easwaran K,"Bandyopadhyay PS,Forster MR",The Varieties of Conditional Probability,,2011,7,,137-148,,North-Holland,Amsterdam,Philosophy of Statistics,2011,,1878-9846,https://www.sciencedirect.com/science/article/pii/B9780444518620500046;http://dx.doi.org/10.1016/B978-0-444-51862-0.50004-6,10.1016/B978-0-444-51862-0.50004-6,"Publisher Summary The term “probability” is applied to many diverse phenomena, and the existence of a branch of mathematics called “probability theory” suggests that these diverse phenomena can all be understood as applications of the same formal system. Although the different interpretations of probability have many similarities, this similarity is not exact, even at the purely formal level. This chapter shows that the bearers of probability in the propensity, subjective, and logical interpretations of probability are distinct classes of objects, and that this changes the mathematical relations that must hold between conditional and unconditional probabilities. The principles connecting different interpretations of probability have natural modifications that allow the objects of the functions to be different and different relations between conditional and unconditional probability to hold in each.",,,Handbook of the Philosophy of Science,,,,,,,,,,,,,,,,,,,
Journal Article,"Cervesato I,Scedrov A",,Relating State-Based and Process-Based Concurrency through Linear Logic,Electronic Notes in Theoretical Computer Science,2006,165,,145-176,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106005202;http://dx.doi.org/10.1016/j.entcs.2006.05.043,10.1016/j.entcs.2006.05.043,"This paper has the purpose of reviewing some of the established relationships between logic and concurrency, and of exploring new ones. Concurrent and distributed systems are notoriously hard to get right. Therefore, following an approach that has proved highly beneficial for sequential programs, much effort has been invested in tracing the foundations of concurrency in logic. The starting points of such investigations have been various idealized languages of concurrent and distributed programming, in particular the well-established state-transformation model inspired to Petri nets and multiset rewriting, and the prolific process-based models such as the π-calculus and other process algebras. In nearly all cases, the target of these investigations has been linear logic, a formal language that supports a view of formulas as consumable resources. In the first part of this paper, we review some of these interpretations of concurrent languages into linear logic. In the second part of the paper, we propose a completely new approach to understanding concurrent and distributed programming as a manifestation of logic, which yields a language that merges those two main paradigms of concurrency. Specifically, we present a new semantics for multiset rewriting founded on an alternative view of linear logic. The resulting interpretation is extended with a majority of linear connectives into the language of ω-multisets. This interpretation drops the distinction between multiset elements and rewrite rules, and considerably enriches the expressive power of standard multiset rewriting with embedded rules, choice, replication, and more. Derivations are now primarily viewed as open objects, and are closed only to examine intermediate rewriting states. The resulting language can also be interpreted as a process algebra. For example, a simple translation maps process constructors of the asynchronous π-calculus to rewrite operators, while the structural equivalence corresponds directly to logically-motivated structural properties of ω-multisets (with one exception).","Linear logic, multiset rewriting, process algebra","Proceedings of the 13th Workshop on Logic, Language, Information and Computation (WoLLIC 2006)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Xin SQ,Chen S,Zhao J,Pan Z",,Measuring length and girth of a tubular shape by quasi-helixes,Computers & Graphics,2014,38,,392-398,,,,,2014,,0097-8493,https://www.sciencedirect.com/science/article/pii/S0097849313001787;http://dx.doi.org/10.1016/j.cag.2013.10.037,10.1016/j.cag.2013.10.037,"Length and girth are central to measure the size of tube shaped objects. This paper extends circular helical curves to general tubular shapes and proposes a novel method for measuring their length and girth. We call the extended circular helixes quasi-helical curves. A formal definition, as well as a set of practical algorithms for quasi-helixes, is presented in this paper. Experimental results demonstrate that our method is fast, intrinsic, insensitive to noises, invariant to triangulation and resolution. Furthermore, quasi-helical curves can also be used in classifying 3D shapes and designing vector fields on surfaces of revolution.","Quasi-helix, Tube shaped objects, Geodesic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee SK,Whang KY",,VOQL*: A Visual Object Query Language With Inductively Defined Formal Semantics,Journal of Visual Languages & Computing,2001,12,4,413-433,,,,,2001,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X01902046;http://dx.doi.org/10.1006/jvlc.2001.0204,10.1006/jvlc.2001.0204,"The visual object query language (VOQL) recently proposed for object databases has been successful in visualizing path expressions and set-related conditions, and providing formal semantics. However, VOQL has several problems. Due to unrealistic assumptions, only set-related conditions can be represented in VOQL. Due to lack of the explicit language construct for the notion of variables, queries are often awkward and less intuitive. In this paper, we propose VOQL*, which extends VOQL to remove these drawbacks. We introduce the notion of visual variables and refine the syntax and semantics of VOQL based on visual variables. We carefully design the language constructs of VOQL*to reflect the syntax of OOPC, so that the constructs such as visual variables, visual elements, simple terms, structured terms,basic formulas , formulas, and query expressions in VOQL*are hierarchically and inductively constructed as those of OOPC. Most important, we formally define the semantics of each language construct of VOQL*by induction using OOPC. Because of the well-defined syntax and semantics, queries in VOQL*are clear, concise, and intuitive. We also provide an effective procedure to translate queries in VOQL*into those in OOPC. We believe that VOQL*is the first visual query language with the well-defined syntax reflecting the syntactic structure of logic and semantics formally defined by induction.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hong SN,Mannino MV,Greenberg B",,"Measurement theoretic representation of large, diverse model bases: The unified modeling language LU",Decision Support Systems,1993,10,3,319-340,,,,,1993,,0167-9236,https://www.sciencedirect.com/science/article/pii/016792369390066C;http://dx.doi.org/10.1016/0167-9236(93)90066-C,10.1016/0167-9236(93)90066-C,"The philosophy and features of the Unified Modeling Language LU are presented with emphasis on the support of large, diverse model bases. We argue that measurement theory stressing homomorphic mappings from empirical to mathematical systems is an ideal foundation for integrated modeling environments. Homomorphic mappings are an integral part of the semantics of the LU and motivate a number of language features that support large, diverse model bases. The LU provides a separate but uniform representation of domain worlds and mathematical systems known as model types. Domain worlds are composed of empirical objects, relations, and functions organized into classes and attributes, while model types are defined by standard queries and a rich collection of assumptions. To emphasize the importance of homomorphic mappings, unification constraints combine common patterns of domain and mathematical knowledge in model templates. Reusability and incremental refinement are supported by inheritance based on partial order relations for classes, attributes, assumptions, and model types. Together, the semantic foundation and language features provide a practical and formal knowledge representation for large, diverse model bases.","Modeling language, Measurement theory, Formal semantics, Homomorphism, Knowledge representation and organization",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Jesseph DM,"Grattan-Guinness I,Cooke R,Corry L,Crépel P,Guicciardini N","Chapter 8 - George Berkeley, The analyst (1734)",,2005,,,121-130,,Elsevier Science,Amsterdam,Landmark Writings in Western Mathematics 1640-1940,2005,9780444508713,,https://www.sciencedirect.com/science/article/pii/B9780444508713500899;http://dx.doi.org/10.1016/B978-044450871-3/50089-9,10.1016/B978-044450871-3/50089-9,"Publisher Summary George Berkeley's work, “The analyst,” is a criticism of the calculus, in both its Newtonian and Leibnizian formulations, arguing that the foundations of the calculus are incoherent and the reasoning employed in it is inconsistent. Berkeley's powerful objections provoked numerous responses, and the task of replying to them set the agenda for much of British mathematics in the 1730s and 1740s. George Berkeley is best known for his contributions in philosophy, and more specifically for denying the existence of matter and propounding the idealistic thesis that only minds and ideas exist, so that in the case of “sensible objects” esse est percipi, or to be is to be perceived. The Principles failed to be the success for which Berkeley had hoped. Avoiding any talk of motion or acceleration, he worked out an approach to fluxions that considers only finite differences of magnitudes and bears a surprisingly strong resemblance to the modern view of the calculus. Although Paman's work was little read, both he and Maclaurin provided responses to the analyst that show Berkeley was right about fundamental obscurities in the calculus while also indicating how to overcome them.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Halpin T,Halpin T,"6 - Value, Set-Comparison, and Subtype Constraints",,2001,,,215-276,,Academic Press,San Diego,Information Modeling and Relational Databases,2001,9781558606722,,https://www.sciencedirect.com/science/article/pii/B9781558606722500099;http://dx.doi.org/10.1016/B978-155860672-2/50009-9,10.1016/B978-155860672-2/50009-9,"Publisher Summary This chapter deals with the sixth step of the conceptual schema design procedure, which covers three kinds of constraints: value, set-comparison, and subtype. Set-comparison constraints are of three kinds: subset, equality, and exclusion. These declare whether the population of one role sequence must be included in, be equal to, or be mutually exclusive with the population of another. Subtyping allows declaring how types are related and refines the ability to declare precisely what kinds of objects play what roles. Subtype connections among a family of compatible object types are displayed in a directed, acyclic subtype graph. In object-role modeling, subtypes are introduced to declare that one or more roles are played only by that subtype. The process of introducing subtypes is called specialization. Subtypes inherit all the roles of their supertypes, as well as having at least one specific role. Input forms often provide a set of conditional instructions that indicate the conditions under which particular entries on the form are needed. Such instructions can also be used to deduce the subtyping constraints.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,Zawadowski M,,The formal theory of monoidal monads,Journal of Pure and Applied Algebra,2012,216,8,1932-1942,,,,,2012,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404912000692;http://dx.doi.org/10.1016/j.jpaa.2012.02.030,10.1016/j.jpaa.2012.02.030,"We give a 3-categorical, purely formal argument explaining why on the category of Kleisli algebras for a lax monoidal monad, and dually on the category of Eilenberg–Moore algebras for an oplax monoidal monad, we always have a natural monoidal structures. The key observation is that the 2-category of lax monoidal monads in any 2-category D with finite products is isomorphic to the 2-category of monoidal objects with oplax morphisms in the 2-category of monads with lax morphisms in D. We explain at the end of the paper that a similar phenomenon occurs in many other situations.",,Special Issue devoted to the International Conference in Category Theory `CT2010',,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang PY,Lin S,Srivastava HM",,Remarks on a simple fractional-calculus approach to the solutions of the bessel differential equation of general order and some of its applications,Computers & Mathematics with Applications,2006,51,1,105-114,,,,,2006,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122105004517;http://dx.doi.org/10.1016/j.camwa.2005.03.021,10.1016/j.camwa.2005.03.021,"In a remarkably large number of recent works, one can find the emphasis upon (and demonstrations of) the usefulness of fractional calculus operators in the derivation of (explicit) particular solutions of significantly general families of linear ordinary and partial differential equations of the second and higher orders. The main object of the present paper is to continue our investigation of this simple fractional-calculus approach to the solutions of the classical Bessel differential equation of general order and to show how it would lead naturally to several interesting consequences which include (for example) an alternative derivation of the complete power-series solutions obtainable usually by the Frobenius method. The underlying analysis presented here is based chiefly upon some of the general theorems on (explicit) particular solutions of a certain family of linear ordinary fractional differintegral equations with polynomial coefficients.","Operators of fractional calculus, Bessel differential equation, Fuchsian (and non-Fuchsian) differential equations, Differintegral equations, (ordinary and partial) Linear differential equations, Polynomial coefficients, Frobenius method, Power-series solutions, Bessel functions, Trigonometric functions, Integro-differential equations, Hypergeometric representations",,,,,,,,,,,,,,,,,,,,,
Journal Article,Glodeanu CV,,Exploring Users' Preferences in a Fuzzy Setting,Electronic Notes in Theoretical Computer Science,2014,303,,37-57,,,,,2014,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066114000292;http://dx.doi.org/10.1016/j.entcs.2014.02.003,10.1016/j.entcs.2014.02.003,"We propose a new method for modelling users' preferences on attributes that contain more than one trait. Starting with a data set the users have to enter a sort of order on the attributes in form of formulas corresponding to their preferences. Based on this order they only receive the relevant formal concepts, i.e., “object-attribute clusters”, where relevant corresponds to the users' point of view. The preference modelling is done within the framework of Formal Fuzzy Concept Analysis. This has numerous advantages. First, the relevant information is contained in a complete lattice, the concept lattice, that allows the users to browse among their preferences. This lattice may be used for further data analysis by applying different methods from Formal Concept Analysis. Second, we can investigate the computation of non-redundant bases for the entered formulas. Since the users are allowed to enter the formulas, these may be redundant. The base offers a better overview of the preferences and thus the formulas can be altered more easily.","Formal Concept Analysis, Fuzzy data, Data reduction, -closure operators","Proceedings of the Workshop on Algebra, Coalgebra and Topology (WACT 2013)",,,,,,,,,,,,,,,,,,,,
Journal Article,Taentzer G,,Visual Modeling of Distributed Object Systems by Graph Transformation,Electronic Notes in Theoretical Computer Science,2002,51,,304-318,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104802123;http://dx.doi.org/10.1016/S1571-0661(04)80212-3,10.1016/S1571-0661(04)80212-3,"A visual modeling technique for distributed object systems based on graph transformation is presented. It includes the graphical description of the network and its dynamic reconfiguration as well as the component interfaces and local object systems and their behavior. Typical issues in distributed systems like remote object interaction, object migration and replication, communication and synchronization are expressible in this technique. The notation is close to UML. It extends the UML notation where needed. Using graph transformation as underlying formal framework, distributed behavior is designed in a way that consistency of the network, as well as of all object and data structures involved, is ensured.",,GETGRATS Closing Workshop,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hsiao CT,Chahine G,Gumerov N",,Application of a Hybrid Genetic/Powell Algorithm and a Boundary Element Method to Electrical Impedance Tomography,Journal of Computational Physics,2001,173,2,433-454,,,,,2001,,0021-9991,https://www.sciencedirect.com/science/article/pii/S0021999101968664;http://dx.doi.org/10.1006/jcph.2001.6866,10.1006/jcph.2001.6866,An optimization method based on a genetic algorithm (GA) and a boundary element method is applied to solve an electrical impedance tomography problem. The scheme is applied to reconstruct highly irregular shapes and to image and count objects inside a host medium of different impedance. A Pareto multiobjective optimization method is applied to improve the performance of the GA. Comparisons between the GA and a calculus-based method for selected test problems show that the calculus-based method outperforms the GA in simple cases but that for more complex cases the GA reaches the correct solution whereas the calculus-based method does not. A hybrid scheme that we developed combining a calculus-based method and the GA is shown to be the most efficient and robust even when applied to the complex cases we tested. The sensitivity of the current scheme is evaluated in the presence of noise.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Giordano L,Gliozzi V,Olivetti N,Pozzato GL",,A non-monotonic Description Logic for reasoning about typicality,Artificial Intelligence,2013,195,,165-202,,,,,2013,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370212001269;http://dx.doi.org/10.1016/j.artint.2012.10.004,10.1016/j.artint.2012.10.004,"In this paper we propose a non-monotonic extension of the Description Logic ALC for reasoning about prototypical properties and inheritance with exceptions. The resulting logic, called ALC+Tmin, is built upon a previously introduced (monotonic) logic ALC+T that is obtained by adding a typicality operator T to ALC. The operator T is intended to select the “most normal” or “most typical” instances of a concept, so that knowledge bases may contain subsumption relations of the form T(C)⊑D (“T(C) is subsumed by D”), expressing that typical C-members are instances of concept D. From a knowledge representation point of view, the monotonic logic ALC+T is too weak to perform inheritance reasoning. In ALC+Tmin, in order to perform non-monotonic inferences, we define a “minimal model” semantics over ALC+T. The intuition is that preferred or minimal models are those that maximize typical instances of concepts. By means of ALC+Tmin we are able to infer defeasible properties of (explicit or implicit) individuals. We also present a tableau calculus for deciding ALC+Tmin entailment that allows to give a complexity upper bound for the logic, namely that query entailment is in co-NExpNP.","Description Logics, Non-monotonic reasoning, Tableau calculi, Prototypical reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Conti S,Focardi M,Iurlano F",,Existence of strong minimizers for the Griffith static fracture model in dimension two,"Annales de l'Institut Henri Poincaré C, Analyse non linéaire",2019,36,2,455-474,,,,,2019,,0294-1449,https://www.sciencedirect.com/science/article/pii/S0294144918300751;http://dx.doi.org/10.1016/j.anihpc.2018.06.003,10.1016/j.anihpc.2018.06.003,"We consider the Griffith fracture model in two spatial dimensions, and prove existence of strong minimizers, with closed jump set and continuously differentiable deformation fields. One key ingredient, which is the object of the present paper, is a generalization to the vectorial situation of the decay estimate by De Giorgi, Carriero, and Leaci. This is based on replacing the coarea formula by a method to approximate SBDp functions with small jump set by Sobolev functions, and is restricted to two dimensions. The other two ingredients will appear in companion papers and consist respectively in regularity results for vectorial elliptic problems of the elasticity type and in a method to approximate in energy GSBDp functions by SBVp ones.","Calculus of variations, Functions of bounded deformation, Existence, Fracture mechanics, Griffith's model",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lin S,Tu ST,Srivastava HM",,A unified presentation of certain families of non-Fuchsian differential equations via fractional calculus operators,Computers & Mathematics with Applications,2003,45,12,1861-1870,,,,,2003,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122103900071;http://dx.doi.org/10.1016/S0898-1221(03)90007-1,10.1016/S0898-1221(03)90007-1,"In recent years, many authors demonstrated the usefulness of fractional calculus operators in the derivation of (explicit) particular solutions of a number of linear ordinary and partial differential, equations of the second and higher orders. The main object of the present paper is to show how readily some recent contributions on this subject by several workers, involving various interesting classes of non-Fuchsian differential equations (including, for example, the Fukuhara and Tricomi equations and the celebrated Bessel and Whittaker equations), can be obtained (in a unified manner) by suitably applying some general theorems on (explicit) particular solutions of a certain family of linear ordinary fractional differintegral equations.","Fractional calculus, Fuchsian (and non-Fuchsian) differential equations, Generalized Leibniz rule, Analytic functions, Differintegral equations, Ordinary and partial differential equations, Index law, Linearity property, Whittaker (and modified Whittaker) equations, Fukuhara equation, Tricomi equation, Bessel equation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Coquand T,,Space of valuations,Annals of Pure and Applied Logic,2009,157,2,97-109,,,,,2009,,0168-0072,https://www.sciencedirect.com/science/article/pii/S016800720800122X;http://dx.doi.org/10.1016/j.apal.2008.09.003,10.1016/j.apal.2008.09.003,"The general framework of this paper is a reformulation of Hilbert’s program using the theory of locales, also known as formal or point-free topology [P.T. Johnstone, Stone Spaces, in: Cambridge Studies in Advanced Mathematics, vol. 3, 1982; Th. Coquand, G. Sambin, J. Smith, S. Valentini, Inductively generated formal topologies, Ann. Pure Appl. Logic 124 (1–3) (2003) 71–106; G. Sambin, Intuitionistic formal spaces–a first communication, in: D. Skordev (Ed.), Mathematical Logic and its Applications, Plenum, New York, 1987, pp. 187–204]. Formal topology presents a topological space, not as a set of points, but as a logical theory which describes the lattice of open sets. The application to Hilbert’s program is then the following. Hilbert’s ideal objects are represented by points of such a formal space. There are general methods to “eliminate” the use of points, close to the notion of forcing and to the “elimination of choice sequences” in intuitionist mathematics, which correspond to Hilbert’s required elimination of ideal objects. This paper illustrates further this general program on the notion of valuations. They were introduced by Dedekind and Weber [R. Dedekind, H. Weber, Theorie des algebraischen Funktionen einer Veränderlichen, J. de Crelle t. XCII (1882) 181–290] to give a rigorous presentation of Riemann surfaces. It can be argued that it is one of the first example in mathematics of point-free representation of spaces [N. Bourbaki, Eléments de Mathématique. Algèbre commutative, Hermann, Paris, 1965, Chapitre 7]. It is thus of historical and conceptual interest to be able to represent this notion in formal topology.","Constructive mathematics, Formal topology, Prüfer domain",Kurt Gödel Centenary Research Prize Fellowships,,,,,,,,,,,,,,,,,,,,
Journal Article,"Leathrum JF,Liburdy KA",,Formal test specifications in IEEE POSIX,Computer Standards & Interfaces,1995,17,5,603-614,,,,,1995,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899500015M;http://dx.doi.org/10.1016/0920-5489(95)00015-M,10.1016/0920-5489(95)00015-M,"The role of formal methods is examined in the context of the process of developing and adopting open standards. Against the broad backdrop of concerns for improving the quality of standards, issues of conformance assessment, test specification, and test methodology guidelines are considered. The experience gained from the attempts to formalize the test specifications for POSIX 2003.5 is presented as lessons learned. The tradeoffs associated with the various formal methods are considered in terms of the properties of common semantic model for assertions languages. The intent here is to collect the common features in a form that provides insights on issues such as encapsulation and inheritance of specifications, inter-operation semantics, state and control structures for assertions, and name space management conventions.","Assertion languages, Semantics, Formal specifications, Test specifications, POSIX",Formal Description Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,"MacLachlan L,Jowers I",,Exploration of multi-material surfaces as weighted shapes,Graphical Models,2016,83,,28-36,,,,,2016,,1524-0703,https://www.sciencedirect.com/science/article/pii/S1524070315000387;http://dx.doi.org/10.1016/j.gmod.2015.07.002,10.1016/j.gmod.2015.07.002,"The introduction of multi-material additive manufacturing makes it possible to fabricate objects with varying material properties, leading to new types of designs that exhibit interesting and complicated behaviours. But, computational design methods typically focus on the structure and geometry of designed objects, and do not incorporate material properties or behaviour. This paper explores how material properties can be included in computational design, by formally modelling them as weights in shape computations. Shape computations, such as shape grammars, formalise the description and manipulations of pictorial representation in creative design processes. The paper explores different ways that material properties can be formally modelled as weights, and presents examples in which multi-material surfaces are modelled as weighted planes, giving rise to flexible behaviours that can be considered in design exploration.","Additive manufacturing, Shape computation, Design",SIGGRAPH Asia Workshop on Creative Shape Modeling and Design,,,,,,,,,,,,,,,,,,,,
Journal Article,"Karolinsky E,Stolin A,Tarasov V",,Equivariant quantization of Poisson homogeneous spaces and Kostant's problem,Journal of Algebra,2014,409,,362-381,,,,,2014,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869314001963;http://dx.doi.org/10.1016/j.jalgebra.2014.03.033,10.1016/j.jalgebra.2014.03.033,"We find a partial solution to the longstanding problem of Kostant concerning description of the so-called locally finite endomorphisms of highest weight irreducible modules. The solution is obtained by means of its reduction to a far-reaching extension of the quantization problem. While the classical quantization problem consists in finding ⋆-product deformations of the commutative algebras of functions, we consider the case when the initial object is already a noncommutative algebra, the algebra of functions within q-calculus.","Quantized universal enveloping algebra, Kostant's problem, Highest weight module, Equivariant quantization, Reduced fusion element",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mansky S,Gunter EL",,Safety of a Smart Classes-Used Regression Test Selection Algorithm,Electronic Notes in Theoretical Computer Science,2020,351,,51-73,,,,,2020,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066120300402;http://dx.doi.org/10.1016/j.entcs.2020.08.004,10.1016/j.entcs.2020.08.004,"Regression Test Selection (RTS) algorithms select which tests to rerun on revised code, reducing the time required to check for newly introduced errors. An RTS algorithm is considered safe if and only if all deselected tests would have unchanged results. In this paper, we present a formal proof of safety of an RTS algorithm based on that used by Ekstazi [Gligoric, M., L. Eloussi and D. Marinov, Practical regression test selection with dynamic file dependencies, in: Proceedings of the 2015 International Symposium on Software Testing and Analysis, ISSTA 2015 (2015), p. 211–222. URL https://doi.org/10.1145/2771783.2771784], a Java library for regression testing. Ekstazi's algorithm adds print statements to JVM code in order to collect the names of classes used by a test during its execution on a program. When the program is changed, tests are only rerun if a class they used changed. The main insight in their algorithm is that not all uses of classes must be noted, as many necessarily require previous uses, such as when using an object previously created. The algorithm we formally define and prove safe here uses an instrumented semantics to collect touched classes in an even smaller set of locations. We identify problems with Ekstazi's current collection location set that make it not safe, then present a modified set that will make it equivalent to our safe set. The theorems given in this paper have been formalized in the theorem prover Isabelle over JinjaDCI [Mansky, S. and E. L. Gunter, Dynamic class initialization semantics: A jinja extension, in: Proceedings of the 8th ACM SIGPLAN International Conference on Certified Programs and Proofs, CPP 2019 (2019), p. 209–221. URL https://doi.org/10.1145/3293880.3294104], a semantics for a subset of Java and JVM including dynamic class initialization and static field and methods. We instrumented JinjaDCI's JVM semantics by giving a general definition for Collection Semantics, small-step semantics instrumented to collect information during execution. We also give a formal general definition of RTS algorithms, including a definition of safety.","interactive theorem proving, regression test selection, small-step semantics, Java","Proceedings of LSFA 2020, the 15th International Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2020)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Morrison R,Connor RCH,Cutts QI,Kirby GNC,Stemple D",,Mechanisms for controlling evolution in persistent object systems,Microprocessors and Microsystems,1993,17,3,173-181,,,,,1993,,0141-9331,https://www.sciencedirect.com/science/article/pii/014193319390047B;http://dx.doi.org/10.1016/0141-9331(93)90047-B,10.1016/0141-9331(93)90047-B,"Persistent programming is concerned with the creation and manipulation of data with arbitrary lifetimes. A requirement of such systems is that the data (including programs) must be capable of evolving and that evolution should be within the control of the application's programmer. This paper discusses some recent developments in persistent programming that enable controlled evolution. The areas discussed are: the use of type systems, the use of reflection and a new style of programming, only available in persistent object systems, called hyper-programming.","persistence, evolution, type systems, constraint checking, linguistic reflection, hyper-programming",,,,,,,,,,,,,,,,,,,,,
Journal Article,Tiu A,,A Logic for Reasoning about Generic Judgments,Electronic Notes in Theoretical Computer Science,2007,174,5,3-18,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107002289;http://dx.doi.org/10.1016/j.entcs.2007.01.016,10.1016/j.entcs.2007.01.016,"This paper presents an extension of a proof system for encoding generic judgments, the logic FOλΔ∇ of Miller and Tiu, with an induction principle. The logic FOλΔ∇ is itself an extension of intuitionistic logic with fixed points and a “generic quantifier”, ∇, which is used to reason about the dynamics of bindings in object systems encoded in the logic. A previous attempt to extend FOλΔ∇ with an induction principle has been unsuccessful in modeling some behaviours of bindings in inductive specifications. It turns out that this problem can be solved by relaxing some restrictions on ∇, in particular by adding the axiom B≡∇x.B, where x is not free in B. We show that by adopting the equivariance principle, the presentation of the extended logic can be much simplified. Cut-elimination for the extended logic is stated, and some applications in reasoning about an object logic and a simply typed λ-calculus are illustrated.","Proof theory, higher-order abstract syntax, logical frameworks",Proceedings of the First International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice (LFMTP 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Fernyhough J,Cohn AG,Hogg DC",,Constructing qualitative event models automatically from video input,Image and Vision Computing,2000,18,2,81-103,,,,,2000,,0262-8856,https://www.sciencedirect.com/science/article/pii/S0262885699000232;http://dx.doi.org/10.1016/S0262-8856(99)00023-2,10.1016/S0262-8856(99)00023-2,"We describe an implemented technique for generating event models automatically based on qualitative reasoning and a statistical analysis of video input. Using an existing tracking program which generates labelled contours for objects in every frame, the view from a fixed camera is partitioned into semantically relevant regions based on the paths followed by moving objects. The paths are indexed with temporal information so objects moving along the same path at different speeds can be distinguished. Using a notion of proximity based on the speed of the moving objects and qualitative spatial reasoning techniques, event models describing the behaviour of pairs of objects can be built, again using statistical methods. The system has been tested on a traffic domain and learns various event models expressed in the qualitative calculus which represent human observable events. The system can then be used to recognise subsequent selected event occurrences or unusual behaviours.","Qualitative event models, Video input, Tracking program, Scene analysis, Qualitiative spatial reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ribeiro L,dos Santos OM,Dotti FL,Foss L",,Correct transformation: From object-based graph grammars to PROMELA,Science of Computer Programming,2012,77,3,214-246,,,,,2012,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642311000979;http://dx.doi.org/10.1016/j.scico.2011.03.010,10.1016/j.scico.2011.03.010,"Model transformation is an approach that, among other advantages, enables the reuse of existing analysis and implementation techniques, languages and tools. The area of formal verification makes wide use of model transformation because the cost of constructing efficient model checkers is extremely high. There are various examples of translations from specification and programming languages to the input languages of prominent model checking tools, like SPIN. However, this approach provides a safe analysis method only if there is a guarantee that the transformation process preserves the semantics of the original specification/program, that is, that the transformation is correct. Depending on the source and/or target languages, this notion of correctness is not easy to achieve. In this paper, we tackle this problem in the context of Object-Based Graph Grammars (OBGG). OBGG is a formal language suitable for the specification of distributed systems, with a variety of tools and techniques centered around the transformation of OBGG models. We describe in details the model transformation from OBGG models to PROMELA, the input language of the SPIN model checker. Amongst the contributions of this paper are: (a) the correctness proof of the transformation from OBGG models to PROMELA; (b) a generalization of this process in steps that may be used as a guide to prove the correctness of transformations from different specification/programming languages to PROMELA.","Graph grammars, Model transformation, PROMELA, Correctness",Feature-Oriented Software Development (FOSD 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Biernacka M,Danvy O,Støvring K",,Program Extraction From Proofs of Weak Head Normalization,Electronic Notes in Theoretical Computer Science,2006,155,,169-189,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106001939;http://dx.doi.org/10.1016/j.entcs.2005.11.056,10.1016/j.entcs.2005.11.056,"We formalize two proofs of weak head normalization for the simply typed lambda-calculus in first-order minimal logic: one for normal-order reduction, and one for applicative-order reduction in the object language. Subsequently we use Kreisel's modified realizability to extract evaluation algorithms from the proofs, following Berger; the proofs are based on Tait-style reducibility predicates, and hence the extracted algorithms are instances of (weak head) normalization by evaluation, as already identified by Coquand and Dybjer.","program extraction, normalization by evaluation, weak head normalization",Proceedings of the 21st Annual Conference on Mathematical Foundations of Programming Semantics (MFPS XXI),,,,,,,,,,,,,,,,,,,,
Journal Article,Radko O,,A bicovariant differential algebra of a quantum group,Reports on Mathematical Physics,1999,43,1,313-322,,,,,1999,,0034-4877,https://www.sciencedirect.com/science/article/pii/S0034487799800408;http://dx.doi.org/10.1016/S0034-4877(99)80040-8,10.1016/S0034-4877(99)80040-8,"A bicovariant differential algebra of four basic objects (coordinate functions, differential 1-forms, Lie derivatives and inner derivations) within a differential calculus on a quantum group is shown to be produced by a direct application of the cross-product construction to the Woronowicz differential complex, whose Hopf algebra properties account for the bicovariance of the algebra. A correspondence with classical differential calculus, including Cartan identity, and some other useful relations are considered. An explicit construction of a bicovariant differential algebra on GLq(N) is given and its (co)module properties are discussed.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Honsell F,Della Rocca SR",,An approximation theorem for topological lambda models and the topological incompleteness of lambda calculus,Journal of Computer and System Sciences,1992,45,1,49-75,,,,,1992,,0022-0000,https://www.sciencedirect.com/science/article/pii/002200009290040P;http://dx.doi.org/10.1016/0022-0000(92)90040-P,10.1016/0022-0000(92)90040-P,"It is well known that a reflexive object in the Cartesian closed category of complete partial orders and Scott-continuous functions is a model of λ-calculus (briefly a topological model). A topological model, through the interpretation function, induces a λ-theory, i.e., a congruence relation on λ-terms closed under α- and β-reduction. It is natural to ask if all possible λ-theories are induced by a topological model, i.e., if topological models are complete w.r.t. λ-calculus. The authors prove an Approximation Theorem, which holds in all topological models. Using this theorem, they analyze some topological models and their induced λ-theories, and they exhibit a λ-theory which cannot be induced by a topological model. So they prove that topological models are not complete w.r.t. λ-calculus.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Browna KN,McMahon CA,Williams JH",,Describing process plans as the formal semantics of a language of shape,Artificial Intelligence in Engineering,1996,10,2,153-169,,,,,1996,,0954-1810,https://www.sciencedirect.com/science/article/pii/0954181095000259;http://dx.doi.org/10.1016/0954-1810(95)00025-9,10.1016/0954-1810(95)00025-9,"A method of formalising manufacturing information for use in the design process is presented. The method uses a grammar of shape and its formal semantics to describe the set of objects manufacturable by a given process, to generate objects from that set, and to describe corresponding process plans for the manufacture of those objects. The grammar thus defines a search space for generative process planning, and the semantics provide an interpretation of the results of a search in that space.","machining, process planning, grammar, shape, semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yan E,Song J,Ren Y,Zheng C,Mi B,Hong W",,Construction of three-way attribute partial order structure via cognitive science and granular computing,Knowledge-Based Systems,2020,197,,105859,,,,,2020,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705120302239;http://dx.doi.org/10.1016/j.knosys.2020.105859,10.1016/j.knosys.2020.105859,"Partial order formal structure analysis (POFSA), as an emerging model of concept cognitive learning, has been extensively used in the field of knowledge processing. However, along with the development of information storage and network technology, the knowledge that people can master is growing dramatically, and it is difficult to effectively process the expanding knowledge just through one single theory. Therefore, this paper explores the construction method of a three-way attribute partial order structure (APOS) via multi granularity by incorporating the ideas of three-way decision (3WD) and granular computing (GrC) into the theory of POFSA. First, for a specific formal context, by taking object set as the whole domain and using attributes and their respective extensions to constitute granule, granular layers can be formed based on the binary relations of equivalence or compatibility between granules. Then, according to the partial order relations between the granules of different granular layers, the corresponding granular structure APOS can be generated. Finally, using the idea of 3WD to reasonably eliminate the cross connections between different branches of APOS, a three-way APOS via multi granularity can be constructed. In addition, based on the generation algorithm of the three-way APOS, the knowledge processing of several data sets from UCI have been conducted and discussed. Through discussion and experiment, it can be concluded that, the three-way APOS via multi granularity can not only improve the efficiency of knowledge processing, but also make the results of knowledge processing more reasonable.","Partial order structure, Concept cognitive learning, Three-way decision, Granular computing, Cognitive science, Artificial intelligence",,,,,,,,,,,,,,,,,,,,,
Journal Article,"dos Santos Soares M,Julia S",,Centralized Architecture for Real Time Scheduling of Batch Systems,IFAC Proceedings Volumes,2004,37,4,485-490,,,,,2004,,1474-6670,https://www.sciencedirect.com/science/article/pii/S147466701736161X;http://dx.doi.org/10.1016/S1474-6670(17)36161-X,10.1016/S1474-6670(17)36161-X,"The objective of this article is to present a centralized architecture based on a collaboration diagram and on a p-time Petri net model for real time scheduling of production systems. The main idea consists of proposing a software architecture which depends on an object whose purpose is to centralize all the interactions between the different software objects. The internal behaviour of the central object is represented by a p-time Petri net model which shows the global behaviour of the entire system. A specialized inference mechanism called token player is then applied to the p-time Petri net model for the real time scheduling. In particular, for the Petri net fragments involved in conflict situations, symbolic dates assigned to tokens are calculated using a non-conventional (max;+) algebra based on the sequent calculus of Linear Logic. These dates are used to solve conflict situations off-line on an implicit manner in such a way that the resource conflicts can be treated in real time at the central object level. The approach is illustrated through an example of Real Time System used at the global coordination level of a Batch System.","Object modelling, Petri-nets, Scheduling, Real Time Systems, Batch Systems","11th IFAC Symposium on Information Control Problems in Manufacturing (INCOM 2004), Salvador, Brazil, 5-7 April 2004",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Paul JM,Thomas DE","Jerraya AA,Wolf W",Chapter 15 - Models of Computation for Systems-on-Chips,,2005,,,431-463,,Morgan Kaufmann,San Francisco,Multiprocessor Systems-on-Chips,2005,,1875-9661,https://www.sciencedirect.com/science/article/pii/B9780123852519500311;http://dx.doi.org/10.1016/B978-012385251-9/50031-1,10.1016/B978-012385251-9/50031-1,"Publisher Summary This chapter describes system modeling and its relationship to models of computation. It compares several different models of computation and evaluates their usefulness at various stages in system design. It also describes the modeling environment for software and hardware (MESH) environment for hardware and software modeling. Models of computation (MoCs) are abstract representations of computing systems. Computer modeling can be separated into three areas—formal MoCs, computer artifacts, and computer design tools. A formal MoC is generally considered to be one with a mathematical basis. Simulations of formal models may be more efficient for large systems; however, the properties of formal models permit the representation of the system to be manipulated purely mathematically. Computer artifacts are the objects of computer architects. They include software, hardware, or both. Design tools are computer programs that are used to assist the construction of instances of computers as well as the conceptualization of computer artifacts. Design tools may be considered synonymous with design artifacts because they are objects, or entities, used to facilitate the design process. They may have a formal mathematical basis.",,,Systems on Silicon,,,,,,,,,,,,,,,,,,,
Journal Article,Duggan D,,Finite subtype inference with explicit polymorphism,Science of Computer Programming,2001,39,1,57-92,,,,,2001,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642300000137;http://dx.doi.org/10.1016/S0167-6423(00)00013-7,10.1016/S0167-6423(00)00013-7,"Finite subtype inference occupies a middle ground between Hindley–Milner-type inference (as in ML) and subtype inference with recursively constrained types. It refers to subtype inference where only finite types are allowed as solutions. This approach avoids some open problems with general subtype inference, and has practical motivation where recursively constrained types are not appropriate. This paper presents algorithms for finite subtype inference, including checking for entailment of inferred types against explicitly declared polymorphic types. This resolves for finite types a problem that is still open for recursively constrained types. Some motivation for this work, particularly for finite types and explicit polymorphism, is in providing subtype inference for first-class container objects with polymorphic methods.",,Static Program Analysis (SAS'98),,,,,,,,,,,,,,,,,,,,
Journal Article,"Fairchild K,Meredith G,Wexelblat A",,A formal structure for automatic icons,Interacting with Computers,1989,1,2,131-140,,,,,1989,,0953-5438,https://www.sciencedirect.com/science/article/pii/0953543889900210;http://dx.doi.org/10.1016/0953-5438(89)90021-0,10.1016/0953-5438(89)90021-0,"The paper presents a formal structure for describing icons and their relations to objects. Icons are mappings from icon space, which deals with representational properties, to object space, which deals with computational objects. The nature of this mapping is formally described. An extension called automatic icons is proposed. The automatic-icon model subsumes currently-used static and animated icons and gives powerful and flexible new tools we call automatic icons. Some applications of automatic icons, and a tool built by the authors to help system designers create automatic icons, are described. The processes outlined in this paper are the subject of a pending patent.","user interface design, icons, automatic icons, formal structure",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kim S,Kim DK,Lu L,Kim S,Park S",,A feature-based approach for modeling role-based access control systems,Journal of Systems and Software,2011,84,12,2035-2052,,,,,2011,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121211000926;http://dx.doi.org/10.1016/j.jss.2011.03.084,10.1016/j.jss.2011.03.084,"Abstract Role-based access control (RBAC) is a popular access control model for enterprise systems due to its flexibility and scalability. There are many RBAC features available, each providing a different function. Not all features are needed for an RBAC system. Depending on the requirements, one should be able to configure features on a need basis, which reduces development complexity and thus fosters development. However, there have not been suitable methods that enable systematic configuration of RBAC features for system development. This paper presents an approach for configuring RBAC features using a combination of feature modeling and UML modeling. Feature modeling is used for capturing the structure of features and configuration rules, and UML modeling is used for defining the semantics of features. RBAC features are defined based on design principles of partial inheritance and compatibility, which facilitates feature composition and verification. We demonstrate the approach using a banking application and present tool support developed for the approach.","Feature modeling, Role-based access control, UML",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cervesato I,Scedrov A",,Relating state-based and process-based concurrency through linear logic (full-version),Information and Computation,2009,207,10,1044-1077,,,,,2009,,0890-5401,https://www.sciencedirect.com/science/article/pii/S089054010900100X;http://dx.doi.org/10.1016/j.ic.2008.11.006,10.1016/j.ic.2008.11.006,"This paper has the purpose of reviewing some of the established relationships between logic and concurrency, and of exploring new ones. Concurrent and distributed systems are notoriously hard to get right. Therefore, following an approach that has proved highly beneficial for sequential programs, much effort has been invested in tracing the foundations of concurrency in logic. The starting points of such investigations have been various idealized languages of concurrent and distributed programming, in particular the well established state-transformation model inspired by Petri nets and multiset rewriting, and the prolific process-based models such as the π-calculus and other process algebras. In nearly all cases, the target of these investigations has been linear logic, a formal language that supports a view of formulas as consumable resources. In the first part of this paper, we review some of these interpretations of concurrent languages into linear logic and observe that, possibly modulo duality, they invariably target a small semantic fragment of linear logic that we call LVobs. In the second part of the paper, we propose a new approach to understanding concurrent and distributed programming as a manifestation of logic, which yields a language that merges those two main paradigms of concurrency. Specifically, we present a new semantics for multiset rewriting founded on an alternative view of linear logic and specifically LVobs. The resulting interpretation is extended with a majority of linear connectives into the language of ω-multisets. This interpretation drops the distinction between multiset elements and rewrite rules, and considerably enriches the expressive power of standard multiset rewriting with embedded rules, choice, replication, and more. Derivations are now primarily viewed as open objects, and are closed only to examine intermediate rewriting states. The resulting language can also be interpreted as a process algebra. For example, a simple translation maps process constructors of the asynchronous π-calculus to rewrite operators. The language of ω-multisets forms the basis for the security protocol specification language MSR 3. With relations to both multiset rewriting and process algebra, it supports specifications that are process-based, state-based, or of a mixed nature, with the potential of combining verification techniques from both worlds. Additionally, its logical underpinning makes it an ideal common ground for systematically comparing protocol specification languages.","Linear logic, Concurrency, Multiset rewriting, Process algebra, Security protocols","Special issue: 13th Workshop on Logic, Language, Information and Computation (WoLLIC 2006)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Vivas JL,Yoshida N",,Dynamic Channel Screening in the Higher Order π-Calculus,Electronic Notes in Theoretical Computer Science,2002,66,3,170-184,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104804213;http://dx.doi.org/10.1016/S1571-0661(04)80421-3,10.1016/S1571-0661(04)80421-3,"Recently programming languages have been designed to support mobile code, i.e. higher-order code that is transferred from a remote location or domain and executed within the local environment. This may expose the internal interfaces and objects within a location to attacks by mobile code. In this work, we propose an extension of notations based on the Higher-Order π-calculus with primitive operators, called screening operators, whose role is to protect internal interfaces by dynamically restricting the visibility of channels. The usefulness of these operators is illustrated by applications involving resource access control. We show how restrictions on resource access control can be enforced dynamically in terms of screening operators, and contrast it with an alternative approach in which restrictions on the behaviour of processes are based on the notion of process type [17] and intended to be checked statically.",,"F-WAN, Foundations of Wide Area Network Computing (ICALP 2002 Satellite Workshop)",,,,,,,,,,,,,,,,,,,,
Journal Article,Allouche JP,,Transcendence of formal power series with rational coefficients,Theoretical Computer Science,1999,218,1,143-160,,,,,1999,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397598002564;http://dx.doi.org/10.1016/S0304-3975(98)00256-4,10.1016/S0304-3975(98)00256-4,"We give algebraic proofs of transcendence over Q(X) of formal power series with rational coefficients, by using inter alia reduction modulo prime numbers, and the Christol theorem. Applications to generating series of languages and combinatorial objects are given.","Transcendental formal power series, Binomial series, Automatic sequences, -Lucas sequences, Chomsky-Schützenberger theorem",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Harichandran VS,Walnycky D,Baggili I,Breitinger F",,CuFA: A more formal definition for digital forensic artifacts,Digital Investigation,2016,18,,S125-S137,,,,,2016,,1742-2876,https://www.sciencedirect.com/science/article/pii/S1742287616300366;http://dx.doi.org/10.1016/j.diin.2016.04.005,10.1016/j.diin.2016.04.005,"The term “artifact” currently does not have a formal definition within the domain of cyber/digital forensics, resulting in a lack of standardized reporting, linguistic understanding between professionals, and efficiency. In this paper we propose a new definition based on a survey we conducted, literature usage, prior definitions of the word itself, and similarities with archival science. This definition includes required fields that all artifacts must have and encompasses the notion of curation. Thus, we propose using a new term – curated forensic artifact (CuFA) – to address items which have been cleared for entry into a CuFA database (one implementation, the Artifact Genome Project, abbreviated as AGP, is under development and briefly outlined). An ontological model encapsulates these required fields while utilizing a lower-level taxonomic schema. We use the Cyber Observable eXpression (CybOX) project due to its rising popularity and rigorous classifications of forensic objects. Additionally, we suggest some improvements on its integration into our model and identify higher-level location categories to illustrate tracing an object from creation through investigative leads. Finally, a step-wise procedure for researching and logging CuFAs is devised to accompany the model.","Forensic artifact, Digital forensics, CybOX, Curated forensic artifact, CuFA, Artifact definition, Survey, Cyber forensics, Taxonomy, Ontology",,,,,,,,,,,,,,,,,,,,,
Journal Article,Schwartz DG,,Dynamic reasoning with qualified syllogisms,Artificial Intelligence,1997,93,1,103-167,,,,,1997,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370297000209;http://dx.doi.org/10.1016/S0004-3702(97)00020-9,10.1016/S0004-3702(97)00020-9,"A qualified syllogism is a classical Aristotelean syllogism that has been “qualified” through the use of fuzzy quantifiers, likelihood modifiers, and usuality modifiers, e.g., “Most birds can fly; Tweety is a bird; therefore, it is likely that Tweety can fly.” This paper introduces a formal logic Q of such syllogisms and shows how this may be employed in a system of nonmonotonic reasoning. In process are defined the notions of path logic and dynamic reasoning system (DRS). The former is an adaptation of the conventional formal system which explicitly portrays reasoning as an activity that takes place in time. The latter consists of a path logic together with a multiple-inheritance hierarchy. The hierarchy duplicates some of the information recorded in the path logic, but additionally provides an extralogical specificity relation. The system uses typed predicates to formally distinguish between properties and kinds of things. The effectiveness of the approach is demonstrated through analysis of several “puzzles” that have appeared previously in the literature, e.g., Tweety the Bird, Clyde the Elephant, and the Nixon Diamond. It is also outlined how the DRS framework accommodates other reasoning techniques—in particular, predicate circumscription, a “localized” version of default logic, a variant of nonmonotonic logic, and reason maintenance. Furthermore it is seen that the same framework accomodates a new formulation of the notion of unless. A concluding section discusses the relevance of these systems to the well-known frame problem.","Default reasoning, Dynamic reasoning systems, Fuzzy likelihood, Fuzzy probabilities, Fuzzy quantifiers, Multiple inheritance, Nonmonotonic reasoning, Qualified syllogisms, The frame problem, Unless",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wu X,Huang Y",,Adaptive fractional-order non-singular terminal sliding mode control based on fuzzy wavelet neural networks for omnidirectional mobile robot manipulator,ISA Transactions,2021,,,,,,,,2021,,0019-0578,https://www.sciencedirect.com/science/article/pii/S0019057821001841;http://dx.doi.org/10.1016/j.isatra.2021.03.035,10.1016/j.isatra.2021.03.035,"This paper studies a novel adaptive fractional-order non-singular terminal sliding mode (FO-NTSM) control strategy for omnidirectional mobile robot manipulator (OMRM) with unknown parameters and external disturbances. Firstly, we adopt the fuzzy wavelet neural networks (FWNNs) to estimate the dynamic uncertainty of the OMRM because it has superior function approximation capability. Secondly, we design the adaptive NTSM controller to attenuate external disturbances by virtue of adjusting the weights of the FWNNs online. Moreover, we obtain a fractional-order (FO) control criterion, which speed up the convergence of the algorithm. In addition, we prove the globally robust stability of the OMRM control system through a designed Lyapunov function. Finally, simulation and experiment researches indicate the feasible and validity of the presented method.","FO, NTSM, Omnidirectional mobile robot manipulator, Fuzzy wavelet neural networks",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Stephanopoulos G,Henning G,Leone H",,MODEL.LA. A modeling language for process engineering—I. The formal framework,Computers & Chemical Engineering,1990,14,8,813-846,,,,,1990,,0098-1354,https://www.sciencedirect.com/science/article/pii/009813549087040V;http://dx.doi.org/10.1016/0098-1354(90)87040-V,10.1016/0098-1354(90)87040-V,"A modeling language (MODEL.LA.) has been constructed for the interactive or automatic definition of models for processing systems. It is based on six modeling elements and 11 semantic relationships obeying basic axioms of transitivity, monotonicity, commutativity and merging. Its syntax can be described by an extended BNF (Backus—Naur Form). The structure of process models is depicted by specific digraphs, which are symbolically constructed by algorithmic procedures driven by the context of the modeling activity. MODEL.LA. can generate models of processing systems: (a) at various levels of abstraction; (b) capturing qualitative, semiquantitative and quantitative knowledge; (c) with complete documentation of the modeling context (assumptions, simplifications, process engineering task). Its object-oriented modularity makes it extensible and easily maintainable. Although a large part of MODEL.LA. is domain-independent, its vocabulary and syntax is specific to process engineering activities such as: process development, design, control and operations. A language for modeling processing systems, called MODEL.LA., has been presented. Realizing the limitations of the previous procedural attempts, it is based on an object-oriented, declarative approach. The language has been designed to be capable of: (i) expressing all points of interest assumed to be needed in modeling processing systems; (ii) representing processing systems at any level of detail; (iii) generating automatically the set of basic mathematical relationships that are describing the model components; and (iv) offering explicit documentation of all the assumptions that give rise to a particular model. It can be viewed as a very high-level special-purpose language, that moves the user several levels away from the inherent programming language (e.g. LISP, as in this case, Pascal or C). MODEL.LA. complies with all the requirements that were proposed for its design. Its basic strengths are its modularity and its inherent capability of controlling complexity by breaking down complex systems into smaller, less complex pieces. In fact, the specification of a model-class involves the subsequent specification and characterization of all its components. This idea is recursively applied throughout the definition process. Thus, it is very similar to what we usually do when we describe processing systems in natural languages. Another important feature of this language is its extensibility. At a very simple level, the ability to characterize a processing system can be extended by incorporating a richer terminal vocabulary. Also, its modularity makes possible the incorporation of new blocks in the definition of a class; blocks that may describe other aspects, that presently are not considered. If the incorporation of new modeling points of view requires the definition of new classes of modeling elements, it can be done in a straightforward manner.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Talcott CL,,Coordination Models Based on a Formal Model of Distributed Object Reflection,Electronic Notes in Theoretical Computer Science,2006,150,1,143-157,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106001046;http://dx.doi.org/10.1016/j.entcs.2005.12.028,10.1016/j.entcs.2005.12.028,"We propose a family of models of coordination of distributed object systems representing different views, with refinement relations between the different views. We start with distributed objects interacting via asynchronous message passing. The semantics of such a system is a set of event partial orders (event diagrams) giving the interactions during possible system executions. A global coordination requirement is a constraint on the allowed event diagrams. A system coordination specification consists of a meta-level coordinator that controls message delivery in the system according to a given global policy. The system-wide coordination can be refined/distributed using coordinators for disjoint subsystems that communicate with their peers to enforce the global policy. By a further transformation the meta-level can be replaced by systematically transformed base-level objects communicating via a controller object. The coordination models are formalized in rewriting logic using the Reflective Russian Dolls model of distributed object reflection. The general ideas are illustrated with several examples.","coordination, distributed object reflection, policy, event diagram","Proceedings of the First International Workshop on Methods and Tools for Coordinating Concurrent, Distributed and Mobile Systems (MTCoord 2005)",,,,,,,,,,,,,,,,,,,,
Journal Article,Curtin B,,Inheritance of hyper-duality in imprimitive Bose–Mesner algebras,Discrete Mathematics,2008,308,14,3003-3017,,,,,2008,,0012-365X,https://www.sciencedirect.com/science/article/pii/S0012365X07006462;http://dx.doi.org/10.1016/j.disc.2007.08.025,10.1016/j.disc.2007.08.025,"We prove the following result concerning the inheritance of hyper-duality by block and quotient Bose–Mesner algebras associated with a hyper-dual pair of imprimitive Bose–Mesner algebras. Let M and M˜ denote Bose–Mesner algebras. Suppose there is a hyper-duality ψ from the subconstituent algebra of M with respect to p to the subconstituent algebra of M˜ with respect to p˜. Also suppose that M is imprimitive with respect to a subset I of Hadamard idempotents, so M˜ is dual imprimitive with respect to the subset Ψ(I) of primitive idempotents, where Ψ:M→M˜ is the formal duality associated with ψ. Let B denote the block Bose–Mesner algebra of M on the block containing p, and let Q˜ denote the quotient Bose–Mesner algebra of M˜ with respect to Ψ(I). Then there is a hyper-duality from the subconstituent algebra of B with respect to p to the subconstituent algebra of Q˜ with respect to p˜.","Block Bose–Mesner algebra, Quotient Bose–Mesner algebra, Subconstituent algebra, Terwilliger algebra","Conference on Association Schemes, Codes and Designs",,,,,,,,,,,,,,,,,,,,
Journal Article,"Hess C,Schlieder C",,Ontology-based verification of core model conformity in conceptual modeling,"Computers, Environment and Urban Systems",2006,30,5,543-561,,,,,2006,,0198-9715,https://www.sciencedirect.com/science/article/pii/S0198971505000840;http://dx.doi.org/10.1016/j.compenvurbsys.2005.08.009,10.1016/j.compenvurbsys.2005.08.009,"Reference models, often called core models are developed in various application domains. Until now, no computational support exists for the task of verifying the conformity between such core models and their domain models. The approach developed at Bamberg University uses Semantic Web technologies to examine whether or not a domain model is a derivation of a core model. This ontology-based conformity verification supports an iterative modeling process in which core or domain models are modified. Inference services as provided by ontologies can be used to analyze the relationships between core and domain models. For example, it is possible to formally prove which specific relations hold between two types of models and compare the result with the intentions of the domain experts involved in the modeling. As a consequence, knowledge not explicitly represented is revealed. In case that the domain model does not conform to the core model, an interpretation of the inference results is provided in ordinary language giving the domain experts hints on how to modify either the core model, the domain model or both. We evaluated our approach by applying it to a core model and a domain, hence national model from the cadastral domain. Conformity was verified between the core cadastral model proposed by [Lemmen, C., van der Molen, P., van Oosterom, P., Ploeger, H., Quak, W., Stoter, J., et al. (2003). A modular standard for the cadastral domain. In Proceedings of digital earth 2003: Information resources for global sustainability: knowledge, networks, technology, economy, society, natural and human resources, policy and strategy. Brno, Czech Republic, pp. 108–117] and the Greek cadastral model [Tzani, A. (2003). Object-oriented modeling of the Greek Cadastre. Master’s thesis, School of Rural and Surveying Engineering of Aristotle University of Thessaloniki], which both are results of research activities related to the European COST Action G9 “Modeling Real Property Transactions”. Although our approach to conformity verification was only evaluated with the cadastral models, it can be used for conformity verification in various applications domains due to its generality.","Conformity verification, Schema evolution, Ontological modeling",Cadastral Systems IV,,,,,,,,,,,,,,,,,,,,
Journal Article,"Belgharbi K,Boufaida M",,Towards a Distributed Landmarks based Approach for the Localization and Discovery of Things on the Internet,Procedia Computer Science,2014,32,,935-940,,,,,2014,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050914007145;http://dx.doi.org/10.1016/j.procs.2014.05.514,10.1016/j.procs.2014.05.514,"With the democratization of the internet of things, the information systems are becoming pervasive. In order to improve the transparency of pervasive information systems, we suggest a process based on the use of the formal analysis of concepts for the incremental construction of landmark directories. The landmark directories permit to label and localize rapidly the object containing the services appropriate for a given request in a pervasive environment.The selection is based on landmarks which are a combination of contextual and conceptual characteristics chosen on the basis of a mathematical formalism known as Galois Lattice. Our approach is illustrated via an application of an alarm system to help detect and manage the risks in order to avoid disasters and reduce their consequences in case they occur.","Pervasive computing, Internet of things, A formal concept analysis, Landmark, Discovery of things.","The 5th International Conference on Ambient Systems, Networks and Technologies (ANT-2014), the 4th International Conference on Sustainable Energy Information Technology (SEIT-2014)",,,,,,,,,,,,,,,,,,,,
Journal Article,Caromel D,,From Theory to Practice in Distributed Component Systems,Electronic Notes in Theoretical Computer Science,2007,182,,33-38,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107003842;http://dx.doi.org/10.1016/j.entcs.2006.12.042,10.1016/j.entcs.2006.12.042,"This paper summarizes the keynote talk given at FACS'06, Formal Aspect of Component Systems, Prague, September 2006. The paper provides both an overview and a perspective of the papers cited in the reference. To achieve effective distributed components, we rely on an active object model, from which we build asynchronous and distributed components that feature various valuable properties. We will emphasize how important it is to rely on a precise and formal programming model, and how practical component systems can benefits from theoretical inputs.","Asynchrony, distributed components, determinism, Open Source, Grid computing",Proceedings of the Third International Workshop on Formal Aspects of Component Software (FACS 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Guo L,Huang F,Li Q,Zhang GQ",,Power contexts and their concept lattices,Discrete Mathematics,2011,311,18,2049-2063,,,,,2011,,0012-365X,https://www.sciencedirect.com/science/article/pii/S0012365X1100197X;http://dx.doi.org/10.1016/j.disc.2011.04.033,10.1016/j.disc.2011.04.033,"We introduce a framework for the study of formal contexts and their lattices induced by the additional structure of self-relations on top of the traditional incidence relation. The induced contexts use subsets as objects and attributes, hence the name power context and power concept. Six types of new incidence relations are introduced by taking into account all possible combinations of universal and existential quantifiers as well as the order of the quantifications in constructing the lifted power contexts. The structure of the power concept lattice is investigated through projection mappings from the baseline objects and attributes to those of the power context, respectively. We introduce the notions of extensional consistency and intensional consistency, corresponding to the topological notions of continuity in the analogous setting when concepts are viewed as closed sets. We establish Galois connections for these notions of consistency. We further introduce the notion of faithfulness for the first type of lifted incidence relation based on the fact that it can be equivalently characterized by a concept-faithful morphism. We also present conditions under which the power concept lattice serves as a factor lattice of the base concept lattice.","Formal concept analysis, Power context, Concept lattice, Extensional consistency, Intensional consistency, Faithfulness",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liu M,Shao M,Zhang W,Wu C",,Reduction method for concept lattices based on rough set theory and its application,Computers & Mathematics with Applications,2007,53,9,1390-1410,,,,,2007,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122107001022;http://dx.doi.org/10.1016/j.camwa.2006.03.040,10.1016/j.camwa.2006.03.040,"Rough set theory and formal concept analysis are two complementary mathematical tools for data analysis. In this paper, we study the reduction of the concept lattices based on rough set theory and propose two kinds of reduction methods for the above concept lattices. First, we present the sufficient and necessary conditions for justifying whether an attribute and an object are dispensable or indispensable in the above concept lattices. Based on the above justifying conditions, we propose a kind of multi-step attribute reduction method and object reduction method for the concept lattices, respectively. Then, on the basis of the defined discernibility functions of the concept lattices, we propose a kind of single-step reduction method for the concept lattices. Additionally, the relations between the attribute reduction of the concept lattices in FCA and the attribute reduction of the information system in rough set theory are discussed in detail. At last, we apply the above multi-step attribute reduction method for the concept lattices based on rough set theory to the reduction of the redundant premises of the multiple rules used in the job shop scheduling problem. The numerical computational results show that the reduction method for the concept lattices is effective in the reduction of the multiple rules.","Formal context, Concept lattice, Rough set, Attribute reduction, Object reduction, Scheduling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mordukhovich BS,Nam NM",,Variational analysis of extended generalized equations via coderivative calculus in Asplund spaces,Journal of Mathematical Analysis and Applications,2009,350,2,663-679,,,,,2009,,0022-247X,https://www.sciencedirect.com/science/article/pii/S0022247X08005647;http://dx.doi.org/10.1016/j.jmaa.2008.05.068,10.1016/j.jmaa.2008.05.068,"This paper is devoted to the development of variational analysis and generalized differentiation in the framework of Asplund spaces. We mainly concern the study of a special class of set-valued mapping given in the formS(x)=y∈Y|0∈F(x,y)+Q(x,y),x∈X, where both F and Q are set-valued mappings between Asplund spaces. Models of this type are associated with solutions maps to the so-called (extended) generalized equations and play a significant role in many aspects of variational analysis and its applications to optimization, stability, control theory, etc. In this paper we conduct a local variational analysis of such extended solution maps S and their remarkable specifications based on dual-space generalized differential constructions of the coderivative type. The major part of our analysis revolves around coderivative calculus largely developed and implemented in this paper and then applied to establishing verifiable conditions for robust Lipschitzian stability of extended generalized equations and related objects.","Variational analysis, Asplund spaces, Generalized differentiation, Coderivatives, Generalized equations, Lipschitzian stability","The Interplay Between Measure Theory, Topology and Functional Analysis",,,,,,,,,,,,,,,,,,,,
Journal Article,Goeman H,,Towards a theory of (self) applicative communicating processes: a short note,Information Processing Letters,1990,34,3,139-142,,,,,1990,,0020-0190,https://www.sciencedirect.com/science/article/pii/002001909090092C;http://dx.doi.org/10.1016/0020-0190(90)90092-C,10.1016/0020-0190(90)90092-C,"In this paper a direct combination of the λ-calculus with concepts from concurrency is introduced. Abstraction and (self) application from the λ-calculus are maintained as primitive constructs in the combined calculus, which incorporates also notions of (non)deterministic choice, concurrent and sequential composition, communication, encapsulation, and hiding as in process algebra (CCS, etc.). In this setting λ is just an arbitrary port name without any special role. We give an operational semantics to the combined calculus, where process application appears as a generalisation of function application. The combined calculus has great expressive power: recursive constructs appear through self application and data objects are just component processes in concurrent constructs.","Concurrency, process algebra, process calculi, λ-calculus, abstraction, communication, (self) application",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tu ST,Lin S,Huang YT,Srivastava HM",,Solutions of a certain class of fractional differintegral equations,Applied Mathematics Letters,2001,14,2,223-229,,,,,2001,,0893-9659,https://www.sciencedirect.com/science/article/pii/S0893965900001403;http://dx.doi.org/10.1016/S0893-9659(00)00140-3,10.1016/S0893-9659(00)00140-3,"Recently, several authors demonstrated the usefulness of fractional calculus in obtaining particular solutions of a number of such familiar second-order differential equations as those associated with Gauss, Legendre, Jacobi, Chebyshev, Coulomb, Whittaker, Euler, Hermite, and Weber equations. The main object of this paper is to show how some of the latest contributions on the subject by Tu et al. [1], involving the associated Legendre, Euler, and Hermite equations, can be presented in a unified manner by suitably appealing to a general theorem on particular solutions of a certain class of fractional differintegral equations.","Fractional calculus, Differintegral equations, Associated Legendre equations, Euler equations, Hermite equations, Generalized Leibniz rule",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sun H,Fan W,Shen W,Xiao T",,Ontology-based interoperation model of collaborative product development,Journal of Network and Computer Applications,2012,35,1,132-144,,,,,2012,,1084-8045,https://www.sciencedirect.com/science/article/pii/S1084804511000506;http://dx.doi.org/10.1016/j.jnca.2011.02.012,10.1016/j.jnca.2011.02.012,"The reuse of existing systems is an important objective of High Level Architecture (HLA) based collaborative product development systems. However, in order to reuse an existing system, its interoperation interface has to be modified so as to comply with the objective and interaction representations defined in a corresponding Federation Object Model (FOM). Such modifications imply added time and effort, which diminishes the efficiency of system reuse in collaborative product development. This paper presents a heavy-weighted ontology-based construction method for interoperation models to support the reuse of subsystems in various collaborative contexts. In this method ontologies are used to specify the semantics of object classes and interaction classes in subsystems in a formal and computer readable fashion. In doing so, a Formal Concept Analysis (FCA) like construction method is introduced to establish the original interoperation ontology from scratch. An automatic transforming method from Simulation Object Model (SOM) into interoperation ontology is also described to make existing HLA based systems easy to adopt this approach. Then a consistency verification method is introduced to guarantee the consistency of the interoperation ontologies. A case study is used to demonstrate the feasibility of the proposed method. As a human-friendly modeling method, compared with existing interoperation modeling methods the proposed method is more flexible, efficient and reliable.","Collaborative Product development, HLA-High level architecture, Ontology",Collaborative Computing and Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,Cheong H,,Translating JSON Schema logics into OWL axioms for unified data validation on a digital manufacturing platform,Procedia Manufacturing,2019,28,,183-188,,,,,2019,,2351-9789,https://www.sciencedirect.com/science/article/pii/S2351978918313726;http://dx.doi.org/10.1016/j.promfg.2018.12.030,10.1016/j.promfg.2018.12.030,"JSON (JavaScript Object Notation) is a prevalent data format used in cloud-based platforms that support composable digital manufacturing workflows. The current work presents a method to translate the logics found in JSON Schema into OWL axioms, in order to facilitate ontology-based unified data validation with JSON data. The specific contributions of this paper include the demonstration of using a formal ontology for the logic translation and data validation, a technique for disambiguating implicit relations found in JSON Schema as explicit OWL properties, and mapping JSON Schema validation keywords to equivalent OWL expressions.","JSON, JSON Schema, OWL, Ontology, Mapping, Axiom translation, Data validation","7th International conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2018)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Ahmad A,Xavier J,Santos-Victor J,Lima P",,3D to 2D bijection for spherical objects under equidistant fisheye projection,Computer Vision and Image Understanding,2014,125,,172-183,,,,,2014,,1077-3142,https://www.sciencedirect.com/science/article/pii/S1077314214000824;http://dx.doi.org/10.1016/j.cviu.2014.04.004,10.1016/j.cviu.2014.04.004,"The core problem addressed in this article is the 3D position detection of a spherical object of known-radius in a single image frame, obtained by a dioptric vision system consisting of only one fisheye lens camera that follows equidistant projection model. The central contribution is a bijection principle between a known-radius spherical object’s 3D world position and its 2D projected image curve, that we prove, thus establishing that for every possible 3D world position of the spherical object, there exists a unique curve on the image plane if the object is projected through a fisheye lens that follows equidistant projection model. Additionally, we present a setup for the experimental verification of the principle’s correctness. In previously published works we have applied this principle to detect and subsequently track a known-radius spherical object.","Equidistant projection, Fisheye lens, Spherical object detection, Omnidirectional vision, 3D detection",,,,,,,,,,,,,,,,,,,,,
Journal Article,Marberg E,,Bialgebras for Stanley symmetric functions,Discrete Mathematics,2020,343,4,111778,,,,,2020,,0012-365X,https://www.sciencedirect.com/science/article/pii/S0012365X19304601;http://dx.doi.org/10.1016/j.disc.2019.111778,10.1016/j.disc.2019.111778,"We construct a non-commutative, non-cocommutative, graded bialgebra Π with a basis indexed by the permutations in all finite symmetric groups. Unlike the formally similar Malvenuto–Poirier–Reutenauer Hopf algebra, this bialgebra does not have finite graded dimension. After giving formulas for the product and coproduct, we show that there is a natural morphism from Π to the algebra of quasi-symmetric functions, under which the image of a permutation is its associated Stanley symmetric function. As an application, we use this morphism to derive some new enumerative identities. We also describe analogues of Π for the other classical types. In these cases, the relevant objects are module coalgebras rather than bialgebras, but there are again natural morphisms to the quasi-symmetric functions, under which the image of a signed permutation is the corresponding Stanley symmetric function of type B, C, or D.","Bialgebras, Stanley symmetric functions, Coxeter groups, Permutations, Combinatorial coalgebras",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Garcia LF,Abel M,Perrin M,dos Santos Alvarenga R",,The GeoCore ontology: A core ontology for general use in Geology,Computers & Geosciences,2020,135,,104387,,,,,2020,,0098-3004,https://www.sciencedirect.com/science/article/pii/S0098300419306284;http://dx.doi.org/10.1016/j.cageo.2019.104387,10.1016/j.cageo.2019.104387,"Domain ontologies assume the role of representing, in a formal way, a consensual knowledge of a community over a domain. This task is especially difficult in a wide domain like Geology, which is composed of diversified science resting on a large variety of conceptual models that were developed over time. The meaning of the concepts used by the various professionals often depends on the particular vision that they have of a domain according to their background and working habits. Ontology development in Geology thus necessitates a drastic elucidation of the concepts and vocabulary used by geologists. This article intends to contribute to solving these difficulties by proposing a core ontology named GeoCore Ontology resting on the BFO top ontology, specially designed for describing scientific fields. GeoCore Ontology contains well-founded definitions of a limited set of general concepts within the Geology field that are currently considered by all geologists whatever their skill. It allows modelers to separately consider a geological object, the substance that constitutes it, the boundaries that limit it and the internal arrangement of the matter inside it. The core ontology also allows the description of the existentially dependent qualities attached to a geological object and the geological process that generated it in a particular geological age. This small set of formally defined and described concepts combined with concepts from BFO provides a backbone for deriving by subsumption more specialized geological concepts and also constitutes a baseline for integrating different existent domain ontologies within the Geology domain. The GeoCore ontology and the methodology that we used for building it, provide solutions for unveiling major misunderstanding regarding the concepts that are commonly used for formulating geological interpretations. This will facilitate the communication of this information to external Geology users and its integration in domain applications.","GeoCore ontology, Core ontology, Geological knowledge, Ontology engineering, BFO top-level ontology, Knowledge modeling",,,,,,,,,,,,,,,,,,,,,
Journal Article,Brown CE,,Encoding Functional Relations in Scunak,Electronic Notes in Theoretical Computer Science,2007,174,5,127-139,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107002368;http://dx.doi.org/10.1016/j.entcs.2007.01.022,10.1016/j.entcs.2007.01.022,"We describe how a set-theoretic foundation for mathematics can be encoded in the new system Scunak. We then discuss an encoding of the construction of functions as functional relations in untyped set theory. Using the dependent type theory of Scunak, we can define object level application and lambda abstraction operators (in the spirit of higher-order abstract syntax) mediating between functions in the (meta-level) type theory and (object-level) functional relations. The encoding has also been exported to Automath and Twelf.","Set Theory, Dependent Type Theory, Proof Irrelevance, Formal Mathematics",Proceedings of the First International Workshop on Logical Frameworks and Meta-Languages: Theory and Practice (LFMTP 2006),,,,,,,,,,,,,,,,,,,,
Book Chapter,Craig W,"Addison JW,Henkin L,Tarski A","BOOLEAN NOTIONS EXTENDED TO HIGHER DIMENSIONS11The criterion below of being local, semilocal, or continuous, or at any rate a closely related criterion, was suggested to me by Scott, Keisler, and Ryll-Nard-zewski, respectively. This study was carried out under Grants G-19286 and GP-1850 of the National Science Foundation. (Added March 23, 1964: Localness also occurs as a criterion in Fraïssé [56a], p. 69.)",,2014,,,55-69,,North-Holland,,The Theory of Models,2014,9780720422337,,https://www.sciencedirect.com/science/article/pii/B9780720422337500137;http://dx.doi.org/10.1016/B978-0-7204-2233-7.50013-7,10.1016/B978-0-7204-2233-7.50013-7,"Publisher Summary This chapter discusses Boolean notions extended to higher dimensions. Boole was concerned with sets of dimension or rank 1 and operations on these. Peirce's calculus of binary relations and the classical predicate calculus are sometimes regarded as extensions of Boole's work to dimension 2 and to higher dimensions, respectively. These two calculi fail to distinguish operations with a certain simple kind of behavior from others which involve (at least more strongly) the totality of objects in the given universe A. Now the Boolean operations, i.e., those generated by substitution from complementation and intersection applied to sets of dimension 1. A more cautious extension of the notion of a relation is the notion of a set of sequences whose length does not exceed a finite bound. Indeed, since the symmetric difference of bounded sets is bounded (as has been stressed to me by William Hanf), the extension is minimal for embedding the ILR -semialgebras in Boolean rings.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,"Halpin T,Evans K,Hallock P,Maclean B","Halpin T,Evans K,Hallock P,Maclean B","6 - Configuring, manipulating, and reusing ORM models",,2003,,,121-131,,Morgan Kaufmann,San Francisco,Database Modeling,2003,9781558609198,,https://www.sciencedirect.com/science/article/pii/B9781558609198500096;http://dx.doi.org/10.1016/B978-155860919-8/50009-6,10.1016/B978-155860919-8/50009-6,"Publisher Summary This chapter discusses the configuration, manipulation, and reuse of object-role modeling (ORM) models. ORM modeling solution tool applies various default settings to determine how it displays the user interface and how it reacts to certain user commands. These settings can be changed to suit the personal preferences by entering personal choices in the Database Modeling Preferences dialog. To access this dialog, Database > Options > Modeling should be chosen from the main menu. The dialog includes Fact Editor and ORM Diagram panes for setting ORM preferences. The other two panes deal with preferences for the logical modeling solution. The Object type name field allows controlling the base default name for new object types. By default, this is “Object.” The Append ordinal check box is used to append numbers 2, 3, etc., to the default names of second and later object types. In an ORM schema, object types may be connected by predicates and/or subtype relationships. Graphically, a predicate is depicted as a named sequence of one or more role boxes and a subtype relationship is depicted as an arrow from subtype to super type. Each object type is either an entity type or a value type and is defined in exactly one model. It is possible to define an object type or predicate in one model and then reference it from one or more other models.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,Vasylchenko A,,Towards the logic of projective identification,Journal of Applied Logic,2015,13,3,197-214,,,,,2015,,1570-8683,https://www.sciencedirect.com/science/article/pii/S1570868315000476;http://dx.doi.org/10.1016/j.jal.2015.03.008,10.1016/j.jal.2015.03.008,"This paper is devoted to the ‘logic of the unconscious’ and its application to the analysis of projective intentionality in psychoanalysis. Subjective assumptions concerning the existence and identity of intentional objects are often unconscious. They result from personal experience through its assimilation and transformation in further psychological (e.g. defensive) processes. Formal aspects of these subjective assumptions and their influence on our judgment and action have been studied by a number of psychoanalytic authors, in particular by Silvano Arieti, Ignacio Matte-Blanco and their followers who tried to develop ‘logic of the unconscious’. My project consists in the reformulation, clarification and elaboration of the logic of the unconscious using contemporary modal and relevant logics, in particular Graham Priest's logic of intentionality. An important advantage of this logic is that it allows for truth indeterminacy and paraconsistency of the propositional content of intentional states. In this article I explore the logic of projective identification, which I assume plays the central role in the logic of the unconscious. Special attention is given to the logical analysis of the notion of an internal object, and to a logical reconstruction of the fantasy of projective identification.","Logic of intentionality, Logic of the unconscious, Object relations theory, Projective identification",,,,,,,,,,,,,,,,,,,,,
Journal Article,Holtkamp R,,A Pseudo-Analyzer Approach to Formal Group Laws Not of Operad Type,Journal of Algebra,2001,237,1,382-405,,,,,2001,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869300985661;http://dx.doi.org/10.1006/jabr.2000.8566,10.1006/jabr.2000.8566,"Formal group schemes, associated to affine group schemes or Lie groups by completion, can be described by classical formal group laws. More generally, cogroup objects in categories of complete algebras (e.g., associative) are described by group laws for operads or analyzers. M. Lazard has introduced analyzers to study formal group laws and group law chunks (truncated formal power series). A main example of a type of generalized formal group laws not given by an operad or analyzer are group laws corresponding to noncommutative complete Hopf algebras. To cover this case and other types of group laws, pseudo-analyzers are introduced. We point out differences to the (quadratic) operad case; e.g., there is no classification of group laws by Koszul duality. On the other hand we show how pseudo-analyzer cohomology can be used to describe extension of group law chunks.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Weigand H,van den Heuvel WJ",,Cross-organizational workflow integration using contracts,Decision Support Systems,2002,33,3,247-265,,,,,2002,,0167-9236,https://www.sciencedirect.com/science/article/pii/S0167923602000155;http://dx.doi.org/10.1016/S0167-9236(02)00015-5,10.1016/S0167-9236(02)00015-5,"Enterprises are lining up into virtual enterprises to meet the ever-increasing customer's demands in a more flexible and effective way than before. Hence, the business processes as well as supporting workflow systems need to be tightly embedded into streamlined, virtual value chains that can transcend organizational boundaries. It is generally recognized that the combination of workflow with business-object component technology provides the required solution. However, today's widespread business workflow modeling techniques suffer from an object bias, ignoring the most essential coordination vehicle in the enterprise: communication, and the resulting commitments. In this paper, we present contracts that encapsulate (formal) commitments laid down as a set of obligations to coordinate and control the interaction between business workflows. We use the business contract specification language XLBC to formally link the Component Definition Language (CDL) specification of business object-based workflow systems. XLBC is an extension of the Formal Language for Business Communication (FLBC) and a framework for the semantics of XLBC transactions is described. Finally, we indicate a feasible implementation architecture on the basis of an emerging internet-enabled business process architecture, ebXML and Trading Partner Agreements (TPAs).","Workflow integration, Contracts, Deontic logic, FLBC, TPA, ebXML",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kochubei AN,,Quasi-holonomic modules in positive characteristic,Journal of Algebra,2006,302,2,826-844,,,,,2006,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869306002523;http://dx.doi.org/10.1016/j.jalgebra.2006.04.025,10.1016/j.jalgebra.2006.04.025,"We study modules over the Carlitz ring, a counterpart of the Weyl algebra in analysis over local fields of positive characteristic. It is shown that some basic objects of function field arithmetic, like the Carlitz module, Thakur's hypergeometric polynomials, and analogs of binomial coefficients arising in the function field version of umbral calculus, generate quasi-holonomic modules. This class of modules is, in many respects, similar to the class of holonomic modules in the characteristic zero theory.","-Linear function, Quasi-holonomic module, Quasi-holonomic function, Carlitz derivative",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dar T,Joskowicz L,Rivlin E",,Understanding mechanical motion: From images to behaviors,Artificial Intelligence,1999,112,1,147-179,,,,,1999,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370299000405;http://dx.doi.org/10.1016/S0004-3702(99)00040-5,10.1016/S0004-3702(99)00040-5,"We present an algorithm for producing behavior descriptions of planar fixed axes mechanical motions from image sequences using a formal behavior language. The language, which covers the most important class of mechanical motions, symbolically captures the qualitative aspects of objects that translate and rotate along axes that are fixed in space. The algorithm exploits the structure of these motions to robustly recover the objects behaviors. It starts by identifying the independently moving objects, their motion parameters, and their variation with respect to time using normal optical flow analysis, iterative motion segmentation, and motion parameter estimation. It then produces a formal description of their behavior by identifying individual uniform motion events and simultaneous motion changes, and parsing them with a motion grammar. We demonstrate the algorithm on three sets of image sequences: mechanisms, everyday situations, and a robot manipulation scenario.","Image sequence analysis, Function-based analysis, Qualitative reasoning, Mechanical motion, Mechanical devices",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Berardi D,Calvanese D,De Giacomo G",,Reasoning on UML class diagrams,Artificial Intelligence,2005,168,1,70-118,,,,,2005,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370205000792;http://dx.doi.org/10.1016/j.artint.2005.05.003,10.1016/j.artint.2005.05.003,"UML is the de-facto standard formalism for software design and analysis. To support the design of large-scale industrial applications, sophisticated CASE tools are available on the market, that provide a user-friendly environment for editing, storing, and accessing multiple UML diagrams. It would be highly desirable to equip such CASE tools with automated reasoning capabilities, such as those studied in Artificial Intelligence and, in particular, in Knowledge Representation and Reasoning. Such capabilities would allow to automatically detect relevant formal properties of UML diagrams, such as inconsistencies or redundancies. With regard to this issue, we consider UML class diagrams, which are one of the most important components of UML, and we address the problem of reasoning on such diagrams. We resort to several results developed in the field of Knowledge Representation and Reasoning, regarding Description Logics (DLs), a family of logics that admit decidable reasoning procedures. Our first contribution is to show that reasoning on UML class diagrams is EXPTIME-hard, even under restrictive assumptions; we prove this result by showing a polynomial reduction from reasoning in DLs. The second contribution consists in establishing EXPTIME-membership of reasoning on UML class diagrams, provided that the use of arbitrary OCL (first-order) constraints is disallowed. We get this result by using DLRifd, a very expressive EXPTIME-decidable DL that has been developed to capture typical features of conceptual and object-oriented data models. The last contribution has a more practical flavor, and consists in a polynomial encoding of UML class diagrams in the DL ALCQI, which essentially is the most expressive DL supported by current state-of-the-art DL-based reasoning systems. Though less expressive than DLRifd, the DL ALCQI preserves enough semantics to keep reasoning about UML class diagrams sound and complete. Exploiting such an encoding, one can use current DL-based reasoning systems as core reasoning engines for a next generation of CASE tools, that are equipped with reasoning capabilities on UML class diagrams.","Knowledge representation, Description logics, UML class diagrams, Computational complexity, Verification, CASE tools",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li N,Mu Y,Susilo W,Varadharajan V",,Shared RFID ownership transfer protocols,Computer Standards & Interfaces,2015,42,,95-104,,,,,2015,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548915000616;http://dx.doi.org/10.1016/j.csi.2015.05.003,10.1016/j.csi.2015.05.003,"Radio Frequency Identification (RFID) has been widely adopted in practice for objects identification. The ownership of an object can be represented by the ownership of the RFID tag attached to the object. An ownership could be shared among different parties and should be transferable. Although many RFID ownership transfer protocols were proposed, a shared ownership transfer protocol remains as a daunting task with absence of a trusted party. In this paper, we propose the first provably secure shared ownership transfer protocol, which requires merely hashing computations and has a constant key size.","RFID security, Ownership transfer, Security protocol",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Qi J,Qian T,Wei L",,The connections between three-way and classical concept lattices,Knowledge-Based Systems,2016,91,,143-151,,,,,2016,,0950-7051,https://www.sciencedirect.com/science/article/pii/S095070511500310X;http://dx.doi.org/10.1016/j.knosys.2015.08.006,10.1016/j.knosys.2015.08.006,"The model of three-way concept lattices, a novel model for widely used three-way decisions, is an extension of classical concept lattices in formal concept analysis. This paper systematically analyses the connections between two types of three-way concept lattices (object-induced and attribute-induced three-way concept lattices) and classical concept lattices. The relationships are discussed from the viewpoints of elements, sets and orders, respectively. Furthermore, the necessary and sufficient conditions used to construct three-way concepts on the basis of classical concepts are proved, the algorithms building three-way concept lattices on the basis of classical concept lattices are presented. The obtained results are finally demonstrated and verified by examples.","Three-way concept lattices, Three-way concepts, Three-way decisions, Formal concept analysis, Concept lattices",Three-way Decisions and Granular Computing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Salahuddin T,Haouari F,Islam F,Ali R,Al-Rasbi S,Aboueata N,Rezk E,Jaoua A",,Breast cancer image classification using pattern-based Hyper Conceptual Sampling method,Informatics in Medicine Unlocked,2018,13,,176-185,,,,,2018,,2352-9148,https://www.sciencedirect.com/science/article/pii/S2352914818301084;http://dx.doi.org/10.1016/j.imu.2018.07.002,10.1016/j.imu.2018.07.002,"The increase in biomedical data has given rise to the need for developing data sampling techniques. With the emergence of big data and the rise of popularity of data science, sampling or reduction techniques have been assistive to significantly hasten the data analytics process. Intuitively, without sampling techniques, it would be difficult to efficiently extract useful patterns from a large dataset. However, by using sampling techniques, data analysis can effectively be performed on huge datasets, to produce a relatively small portion of data, which extracts the most representative objects from the original dataset. However, to reach effective conclusions and predictions, the samples should preserve the data behavior. In this paper, we propose a unique data sampling technique which exploits the notion of formal concept analysis. Machine learning experiments are performed on the resulting sample to evaluate quality, and the performance of our method is compared with another sampling technique proposed in the literature. The results demonstrate the effectiveness and competitiveness of the proposed approach in terms of sample size and quality, as determined by accuracy and the F1-measure.","Data sampling, Formal concept analysis, Breast cancer, Machine learning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hull R,Su J",,On the expressive power of database queries with intermediate types,Journal of Computer and System Sciences,1991,43,1,219-267,,,,,1991,,0022-0000,https://www.sciencedirect.com/science/article/pii/0022000091900365;http://dx.doi.org/10.1016/0022-0000(91)90036-5,10.1016/0022-0000(91)90036-5,"The set-height of a complex object type is defined to be its level of nesting of the set construct. In a query of the complex object calculus which maps a database D to an output type T, an intermediate type is a type which is used by some variable of the query, but which is not present in D or T. For each k, i ⩾ 0 we define CALCk,i to be the family of calculus queries mapping from and to types with set-height ⩽ k and using intermediate types with set-height ⩽i. In particular, CALC0.0 is the classical relational calculus, and CALC0.1 is equivalent to the family of second-order (relational) queries. Several results concerning these families of languages are obtained. A primary focus is on the families CALC0, i, which map relations to relations. Upper and lower bounds in terms of hyper-exponential time and space on the complexity of these families are provided. The CALC0, i hierarchy does not collapse with respect to expressive power. The union ∪0 ⩽ iCALC0, i is exactly the family of elementary queries, i.e., queries with hyper-exponential complexity. The expressive power of queries from the complex object calculus interpreted using semantics based on the use of arbitrarily large finite or infinite set of invented values is studied. Under these semantics, the expressive power of the relational calculus is not increased, and the CALC0, i hierarchy collapses at CALC0.1. In general, queries with these semantics may not be computable. We also consider an alternative semantics which yields a family of queries equivalent to the computable queries.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Caprotti O,Oostdijk M",,Formal and Efficient Primality Proofs by Use of Computer Algebra Oracles,Journal of Symbolic Computation,2001,32,1,55-70,,,,,2001,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717101904572;http://dx.doi.org/10.1006/jsco.2001.0457,10.1006/jsco.2001.0457,"This paper focuses on how to use Pocklington’s criterion to produce efficient formal proof-objects for showing primality of large positive numbers. First, we describe a formal development of Pocklington’s criterion, done using the proof assistant Coq. Then we present an algorithm in which computer algebra software is employed as oracle to the proof assistant to generate the necessary witnesses for applying the criterion. Finally, we discuss the implementation of this approach and tackle the proof of primality for some of the largest numbers expressible in Coq.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bonacchi A,Fantechi A,Bacherini S,Tempestini M",,Validation process for railway interlocking systems,Science of Computer Programming,2016,128,,2-21,,,,,2016,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642316300053;http://dx.doi.org/10.1016/j.scico.2016.04.004,10.1016/j.scico.2016.04.004,"An interlocking system monitors the status of the objects in a railway yard, allowing or denying the movement of trains, in accordance with safety rules. The high number of complex interlocking rules that guarantee the safe movements of independent trains in a large station makes the verification of such systems a complex task, which needs to be addressed in conformance with EN50128 safety guidelines. In this paper we show how the problem has been addressed by a manufacturer at the final validation stage of production interlocking systems, by means of a model extraction procedure that creates a model of the internal behaviour, to be exercised with the planned test suites, in order to reduce the high costs of direct validation of the target system. The same extracted model is then subject to formal verification experiments, employing an iterative verification process implementing slicing and CEGAR-like techniques, defined to address the typical complexity of this application domain.","Railway interlocking systems, System validation, Model-based testing, Formal methods, Model checking",Special issue on Automated Verification of Critical Systems (AVoCS’14),,,,,,,,,,,,,,,,,,,,
Journal Article,Imine A,,Component-Based Specification of Collaborative Objects,Electronic Notes in Theoretical Computer Science,2007,168,,175-190,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107000357;http://dx.doi.org/10.1016/j.entcs.2006.08.027,10.1016/j.entcs.2006.08.027,"A collaborative object represents a data type (such as a text document or a spreadsheet) designed to be shared by multiple geographically separated users. In order to improve performance and availability of data in such a distributed context, each user has a local copy of the shared objects, upon which he may perform updates. Locally executed updates are then transmitted to the other users. So, the updates are applied in different orders at different copies of the collaborative object. This replication potentially leads, however, to divergent (i.e. different) copies. The Operational Transformation (OT) approach provides an interesting solution for copies divergence. Indeed, every collaborative object has an algorithm which transforms the remote update according to local concurrent ones. But this OT algorithm needs to fulfill two conditions in order to ensure the convergence. Proving the correctness of OT algorithms is very complex and error prone without the assistance of a theorem prover. In the present work, we propose a compositional method for specifying complex collaborative objects. The most important feature of our method is that designing an OT algorithm for the composed collaborative object can be done by reusing the OT algorithms of component collaborative objects. By using our method, we can start from correct small collaborative objects which are relatively easy to handle and incrementally combine them to build more complex collaborative objects.","CSCW, groupware systems, component-based design, formal methods",Proceedings of the Second International Workshop on Views on Designing Complex Architectures (VODCA 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Hytönen T,McIntosh A,Portal P",,Kato's square root problem in Banach spaces,Journal of Functional Analysis,2008,254,3,675-726,,,,,2008,,0022-1236,https://www.sciencedirect.com/science/article/pii/S0022123607003953;http://dx.doi.org/10.1016/j.jfa.2007.10.006,10.1016/j.jfa.2007.10.006,"Let L be an elliptic differential operator with bounded measurable coefficients, acting in Bochner spaces Lp(Rn;X) of X -valued functions on Rn. We characterize Kato's square root estimates ‖Lu‖p≂‖∇u‖p and the H∞-functional calculus of L in terms of R-boundedness properties of the resolvent of L, when X is a Banach function lattice with the UMD property, or a noncommutative Lp space. To do so, we develop various vector-valued analogues of classical objects in Harmonic Analysis, including a maximal function for Bochner spaces. In the special case X=C, we get a new approach to the Lp theory of square roots of elliptic operators, as well as an Lp version of Carleson's inequality.","Kato's square root problem, Elliptic operators with bounded measurable coefficients, -functional calculus, Vector-valued harmonic analysis, UMD spaces, Maximal function, Carleson's inequality",,,,,,,,,,,,,,,,,,,,,
Journal Article,Masuoka A,,Formal groups and unipotent affine groups in non-categorical symmetry,Journal of Algebra,2007,317,1,226-249,,,,,2007,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869307001652;http://dx.doi.org/10.1016/j.jalgebra.2007.03.006,10.1016/j.jalgebra.2007.03.006,"As is well known, in characteristic zero, the Lie algebra functor gives two category equivalences, one from the formal groups to the finite-dimensional Lie algebras, and the other from the unipotent algebraic affine groups to the finite-dimensional nilpotent Lie algebras. We prove these category equivalences in a quite generalized framework, proposed by Gurevich [D.I. Gurevich, The Yang–Baxter equation and generalization of formal Lie theory, Soviet Math. Dokl. 33 (1986) 758–762] and later by Takeuchi [M. Takeuchi, Survey of braided Hopf algebras, in: N. Andruskiewitsch, et al. (Eds.), New Trends in Hopf Algebra Theory, in: Contemp. Math., vol. 267, Amer. Math. Soc., Providence, RI, 2000, pp. 301–324], of vector spaces with non-categorical symmetry. We remove the finiteness restriction from the objects, by using the terms of Hopf algebras and Lie coalgebras.","Hopf algebra, Lie algebra, Lie coalgebra, Formal group, Unipotent affine group",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Little EG,Rogova GL",,Designing ontologies for higher level fusion,Information Fusion,2009,10,1,70-82,,,,,2009,,1566-2535,https://www.sciencedirect.com/science/article/pii/S1566253508000377;http://dx.doi.org/10.1016/j.inffus.2008.05.006,10.1016/j.inffus.2008.05.006,"The purpose of higher level fusion is to produce contextual understanding of the states of the environment and prediction of their impact in relation to specific goals of decision makers. One of the main challenges of designing higher level fusion processes is to provide a formal structure of domain-specific types of entities, attributes, situations, and the relations between them for reasoning about situations and threats. This paper presents an attempt at confronting this challenge by describing a process for building formal ontologies that combines a top–down philosophical perspective (from the most abstract levels to domain-specific levels) with a bottom-up application-based perspective (from domain-specific levels to the most abstract levels). The main focus of this paper is to provide a conceptual framework for formally capturing various sorts of complex relation-types, which can serve as a means for a more thorough decomposition of objects, attributes/properties, events, processes, and relations, necessary for higher level fusion processing.","Higher level fusion, Ontology, Relations, Mereotopology, Basic formal ontology (BFO), Postdisaster environment",Special Issue on High-level Information Fusion and Situation Awareness,,,,,,,,,,,,,,,,,,,,
Journal Article,"Berio G,Vernadat FB",,Formal foundations for a process/resource approach in manufacturing systems behaviour modelling,IFAC Proceedings Volumes,1999,32,2,4888-4893,,,,,1999,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017568330;http://dx.doi.org/10.1016/S1474-6670(17)56833-0,10.1016/S1474-6670(17)56833-0,"The paper provides formal foundations for a specification model for manufacturing systems behaviour modelling. This is achieved by using the idea of “synchronisation of languages” and previous work on state-charts and Object Petri Nets. Consistently with this approach, the re-use of existing models in the context of enterprise engineering is stressed out and the use of standard methods for combining models is advocated to make it effective.","Petri-nets, State-charts, Process models, Formal description techniques, Behaviour modelling, Concurrent systems, Manufacturing systems, Discrete-event systems","14th IFAC World Congress 1999, Beijing, Chia, 5-9 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Xue C,Dong L,Liu J",,Enterprise information system structure optimization based on time property with improved immune genetic algorithm and binary tree,Computers & Mathematics with Applications,2012,63,7,1155-1168,,,,,2012,,0898-1221,https://www.sciencedirect.com/science/article/pii/S089812211101087X;http://dx.doi.org/10.1016/j.camwa.2011.12.032,10.1016/j.camwa.2011.12.032,"This paper deals with how to optimize enterprise information system (EIS) structure based on time property. Once the EIS structure is formally represented, the time property corresponding to EIS structure expression can be obtained. Thus, aiming at the minimum time property, the EIS structure can be optimized. To this end, first, the formal representation of EIS structure based on object-based knowledge mesh (OKM) and binary tree is proposed. Second, different time properties corresponding to various structures are defined and clarified. Then, the optimal model of EIS structure is constructed. And then, the EIS structure model is optimized by the improved immune genetic algorithm (IGA) based on binary tree, niche algorithm and self-adaptive operators, and the steps of the improved IGA are presented in detail as well. Finally, the EIS structure optimization based on time property is illustrated by an example, which verifies the proposed approach.","Enterprise information system, Optimization, Time property, Object-based knowledge mesh, Binary tree, Improved immune genetic algorithm",,,,,,,,,,,,,,,,,,,,,
Journal Article,Nguyen DT,,Mackey–Glass equation driven by fractional Brownian motion,Physica A: Statistical Mechanics and its Applications,2012,391,22,5465-5472,,,,,2012,,0378-4371,https://www.sciencedirect.com/science/article/pii/S0378437112005109;http://dx.doi.org/10.1016/j.physa.2012.06.013,10.1016/j.physa.2012.06.013,In this paper we introduce a fractional stochastic version of the Mackey–Glass model which is a potential candidate to model objects in biology and finance. By a semi-martingale approximate approach we find an semi-analytical expression for the solution.,"Mackey–Glass equation, Fractional Brownian motion, Malliavin calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Srivastava HM,Aouf MK",,Some applications of fractional calculus operators to certain subclasses of prestarlike functions with negative coefficients,Computers & Mathematics with Applications,1995,30,1,53-61,,,,,1995,,0898-1221,https://www.sciencedirect.com/science/article/pii/0898122195000679;http://dx.doi.org/10.1016/0898-1221(95)00067-9,10.1016/0898-1221(95)00067-9,"The object of the present paper is to prove various distortion theorems for the fractional calculus of functions in the subclasses R[α,β] and C[α,β] consisting of prestarlike and normalized analytic functions with negative coefficients. Furthermore, distortion theorems involving a generalized fractional integral operator for functions in the subclasses R[α,β] and C[α,β] are given.","Fractional calculus, Prestarlike functions, Analytic functions, Distortion theorems, Integral operator, Starlike functions, Convex functions, Hadamard product, Fractional derivatives, Fractional integrals, Simply-connected region, Pochhammer symbol",,,,,,,,,,,,,,,,,,,,,
Journal Article,Foissy L,,Free and cofree Hopf algebras,Journal of Pure and Applied Algebra,2012,216,2,480-494,,,,,2012,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404911001745;http://dx.doi.org/10.1016/j.jpaa.2011.07.010,10.1016/j.jpaa.2011.07.010,"We first prove that a graded, connected, free and cofree Hopf algebra is always self-dual. Then, we prove that two graded, connected, free and cofree Hopf algebras are isomorphic if and only if they have the same Poincaré–Hilbert formal series. If the characteristic of the base field is zero, we prove that the Lie algebra of the primitive elements of such an object is free, and we deduce a characterization of the formal series of free and cofree Hopf algebras by a condition of growth of the coefficients. We finally show that two graded, connected, free and cofree Hopf algebras are isomorphic as (nongraded) Hopf algebras if and only if the Lie algebras of their primitive elements have the same number of generators.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Pientka B,,Functional Programming With Higher-order Abstract Syntax and Explicit Substitutions,Electronic Notes in Theoretical Computer Science,2007,174,7,41-60,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107002526;http://dx.doi.org/10.1016/j.entcs.2006.10.037,10.1016/j.entcs.2006.10.037,"This paper sketches a foundation for programming with higher-order abstract syntax and explicit substitutions based on contextual modal type theory [Aleksandar Nanevski, Frank Pfenning, and Brigitte Pientka. Contextual modal type theory. submitted, 2005]. Contextual modal types not only allows us to cleanly separate the representation of data objects from computation, but allow us to recurse over data objects with free variables. In this paper, we extend these ideas even further by adding first-class contexts and substitutions so that a program can pass and access code with free variables and an explicit environment, and link them in a type-safe manner. We sketch the static and operational semantics of this language, and give several examples which illustrate these features.","Logical frameworks, type systems",Proceedings of the Programming Languages meets Program Verification (PLPV 2006),,,,,,,,,,,,,,,,,,,,
Journal Article,"Grumbach S,Vianu V",,Tractable Query Languages for Complex Object Databases,Journal of Computer and System Sciences,1995,51,2,149-167,,,,,1995,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000085710586;http://dx.doi.org/10.1006/jcss.1995.1058,10.1006/jcss.1995.1058,"The expressiveness and complexity of several calculus-based query languages for complex objects are considered. Unlike previous investigations, we are concerned with the complexity of queries on databases of complex objects, rather than flat databases. This raises new issues specific to complex objects. For instance, it is shown that the way the database makes use of its higher-order types has direct impact on query complexity. The use of fixpoint operators is shown to yield languages well-behaved with respect to complexity and expressiveness. In particular, an extension of the fixpoint queries to complex objects is shown to express precisely the PTIME queries, under the assumption that the database makes \full\"" use of all its types. Similar results involve range-restricted queries.""",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mulder F,Voorbraak F",,A formal description of tactical plan recognition,Information Fusion,2003,4,1,47-61,,,,,2003,,1566-2535,https://www.sciencedirect.com/science/article/pii/S1566253502001021;http://dx.doi.org/10.1016/S1566-2535(02)00102-1,10.1016/S1566-2535(02)00102-1,"Plan recognition can roughly be described as the problem of finding the plan(s) underlying the observed behaviour of agent(s). Of course, usually, the observed behaviour and available background knowledge does not determine the underlying plan, and therefore one can typically at best generate (reasonable) plan hypotheses. Traditionally, plan recognition has been studied, formalized and implemented in areas like story understanding and user modelling. In this paper, we propose a formal definition of tactical plan recognition, i.e. the recognition of enemy plans. We will focus on military applications, where this task of tactical plan recognition is crucial, but this task is relevant for every application where one has to deal with intelligent adversial agents. Tactical plan recognition differs from traditional plan recognition in a number of ways. For example, an enemy will often try to avoid making his plans known. We will not pay much explicit attention to this feature. We will focus on another important characteristic feature of tactical plan recognition, namely that the identity of the observed enemy objects, for which plans are to be recognized, may be unknown. A consequence of this is that it is typically not known which observations originate from the same objects. Our formalization of plan recognition is based on classical abduction. The concepts of classical abduction can readily be applied to plan recognizers for identified observations, as has been done by Lin and Goebel [18] and Bauer and Paul [7]. However, for tactical plan recognition some adaptations have to be made. Here the plan recognizer will not only have to generate plan hypotheses, but also assignment hypotheses, which correspond to formal links of objects to observations. A choice for an assignment is essentially a decision concerning the question which observations originate from the same objects. For observations with stochastic variables the probability of an assignment hypothesis is calculated, rather than the probability of the plan hypotheses. For this, Reid’s multiple hypothesis tracking formula can be adapted to calculate the assignment hypothesis probability.","Tactical plan recognition, Multiple hypothesis tracking, Abduction",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lu EJ,Hsieh CJ",,A relation metadata extension for SCORM Content Aggregation Model,Computer Standards & Interfaces,2009,31,5,1028-1035,,,,,2009,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548908001529;http://dx.doi.org/10.1016/j.csi.2008.09.036,10.1016/j.csi.2008.09.036,"To increase the interchangeability and reusability of learning objects, Advanced Distributed Learning Initiative suggested a set of metadata in SCORM Content Aggregation Model to describe learning objects and express relationships between learning objects. However, the suggested relations defined in the metadata of the SCORM CAM are limited. To resolve the problem, new relations were proposed by researchers. Unfortunately, some of the relations are redundant and even inappropriate. In addition, the usability of these relations has never been formally studied. Therefore, in this paper, we summarized and analyzed existing relations, removed duplicated relations, and developed a new relation metadata extension for SCORM CAM. Also, we surveyed 145 students in attempt to understand whether or not the proposed relations can increase their learning effectiveness. The results of the survey showed that learners agreed that the proposed relations are helpful.","CAM, SCORM, Ontology, Metadata, e-Learning","Specification, Standards and Information Management for Distributed Systems",,,,,,,,,,,,,,,,,,,,
Journal Article,"Adda M,Abdelaziz J,Mcheick H,Saad R",,Toward an Access Control Model for IOTCollab,Procedia Computer Science,2015,52,,428-435,,,,,2015,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050915008091;http://dx.doi.org/10.1016/j.procs.2015.05.009,10.1016/j.procs.2015.05.009,"The increase in Internet-connected physical devices offers new possibilities and opportunities. This Internet of Things (IoT) fosters the development of new platforms, services and applications that connect the physical world (represented by physical objects) to the virtual world (represented by the Internet). The work presented here proposes a study of role and attribute-based access control models that tackle the security concerns of our already developed data sharing framework. The framework introduced a formal theoretical model, the IOTCollab domain specific language, and an integrated development environment that implements this model. We have extended this framework by completing the formal theoretical model with access control capabilities.","IOTCollab, Internet of Things, Security, Access Control ;","The 6th International Conference on Ambient Systems, Networks and Technologies (ANT-2015), the 5th International Conference on Sustainable Energy Information Technology (SEIT-2015)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Srivastava HM,Saigo M,Owa S",,A class of distortion theorems involving certain operators of fractional calculus,Journal of Mathematical Analysis and Applications,1988,131,2,412-420,,,,,1988,,0022-247X,https://www.sciencedirect.com/science/article/pii/0022247X88902156;http://dx.doi.org/10.1016/0022-247X(88)90215-6,10.1016/0022-247X(88)90215-6,The object of the present paper is to investigate a general class of fractional integral operators involving the Gauss hypergeometric function. Several interesting distortion theorems for various subclasses of analytic and univalent functions are proved in terms of these operators of fractional calculus. Some special cases of the results presented here are also indicated.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee CY,Srivastava HM,Yueh WC",,Explicit solutions of some linear ordinary and partial fractional differintegral equations,Applied Mathematics and Computation,2003,144,1,11-25,,,,,2003,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300302003892;http://dx.doi.org/10.1016/S0096-3003(02)00389-2,10.1016/S0096-3003(02)00389-2,"In recent years, many authors demonstrated the usefulness of some fractional calculus operators in the derivation of (explicit) particular solutions of a significantly large number of linear ordinary and partial differential equations of the second and higher orders. The main object of the present paper is to show how readily several recent contributions on this subject, involving second- as well as third-order linear ordinary and partial differential equations, can be obtained (in a unified manner) by appropriately applying some general theorems on (explicit) particular solutions of a certain family of linear ordinary and partial fractional differintegral equations.","Fractional calculus, Differintegral equations, (Ordinary and partial) linear differential equations, Analytic (regular) functions, Index law, Generalized Leibniz rule",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kluźniak F,Miłkowska M",,Spill — A logic language for writing testable requirements specifications,Science of Computer Programming,1997,28,2,193-223,,,,,1997,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642396000214;http://dx.doi.org/10.1016/S0167-6423(96)00021-4,10.1016/S0167-6423(96)00021-4,"A requirements specification is the first formal description of a program. Formal methods of program construction can be practically useful only when the requirements specification can be shown to be adequate. This must be done by informal means: inspection and testing. Current specification languages do not easily support both inspection and testing. We propose a specification language, Spill, which has been designed with the express purpose of providing such support. Our language is based on the ideas of logic programming, and can be thought of as both an extended and a restricted version of pure Prolog. A specification written in Spill can be read as a declarative, precise description of the properties of the specified object. The description can be used as a starting point in the formal derivation of a program. At the same time the specification is testable — it can be treated as a program that allows the user to test whether the object so described would indeed have the desired properties, i.e., whether the formal specification corresponds to the intuitively-understood intentions.","Requirements, Specifications, Validation, Logic programming","Formal Specifications: Foundations, Methods, Tools and Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"Hsieh TM,Lin S,Srivastava HM",,Some relationships between certain families of ordinary and fractional differential equations,Computers & Mathematics with Applications,2003,46,10,1483-1492,,,,,2003,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122103901854;http://dx.doi.org/10.1016/S0898-1221(03)90185-4,10.1016/S0898-1221(03)90185-4,"In recent years, many authors demonstrated the usefulness of fractional calculus operators in the derivation of (explicit) particular solutions of a number of linear ordinary and partial differential equations of the second and higher orders. In particular, by making use of the operators of fractional calculus based upon the Cauchy-Goursat integral formula, a certain family of nearly-simple harmonic vibration equations was considered systematically in a series of papers which appeared quite recently. The main object of the present sequel to all these earlier works is to investigate some relationships between such families of fractional differential equations and certain classes of ordinary differential equations. A preliminary interpretation of this family of nearly-simple harmonic vibration equations by means of an example involving linear electric circuits is also provided.","Fractional calculus, Ordinary and fractional differential equations, Cauchy-Goursat integral formula, Principal value, Generalized Leibniz rule, Analytic functions, Differintegral equations, Ordinary and partial differential equations, Index law, Linearity property, Fuchsian (and non-Fuchsian) differential equations, Simple harmonic vibration equations, Nearly-simple harmonic vibration equations, Linear electric circuits, Fractional differential equations with constant coefficients",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Holm T,Jørgensen P",,"Generalised friezes and a modified Caldero–Chapoton map depending on a rigid object, II",Bulletin des Sciences Mathématiques,2016,140,4,112-131,,,,,2016,,0007-4497,https://www.sciencedirect.com/science/article/pii/S0007449715000366;http://dx.doi.org/10.1016/j.bulsci.2015.05.001,10.1016/j.bulsci.2015.05.001,"It is an important aspect of cluster theory that cluster categories are “categorifications” of cluster algebras. This is expressed formally by the (original) Caldero–Chapoton map X which sends certain objects of cluster categories to elements of cluster algebras. Let τc→b→c be an Auslander–Reiten triangle. The map X has the salient property that X(τc)X(c)−X(b)=1. This is part of the definition of a so-called frieze, see [1]. The construction of X depends on a cluster tilting object. In a previous paper [14], we introduced a modified Caldero–Chapoton map ρ depending on a rigid object; these are more general than cluster tilting objects. The map ρ sends objects of sufficiently nice triangulated categories to integers and has the key property that ρ(τc)ρ(c)−ρ(b) is 0 or 1. This is part of the definition of what we call a generalised frieze. Here we develop the theory further by constructing a modified Caldero–Chapoton map, still depending on a rigid object, which sends objects of sufficiently nice triangulated categories to elements of a commutative ring A. We derive conditions under which the map is a generalised frieze, and show how the conditions can be satisfied if A is a Laurent polynomial ring over the integers. The new map is a proper generalisation of the maps X and ρ.","Auslander–Reiten triangle, Categorification, Cluster algebra, Cluster category, Cluster tilting object, Rigid object",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Deduran JA,Kalla SL,Srivastava HM",,Fractional Calculus and the Sums of Certain Families of Infinite Series,Journal of Mathematical Analysis and Applications,1995,190,3,738-754,,,,,1995,,0022-247X,https://www.sciencedirect.com/science/article/pii/S0022247X85711079;http://dx.doi.org/10.1006/jmaa.1995.1107,10.1006/jmaa.1995.1107,"Although the concept of fractional calculus can be traced back to l′Hôpital′s naive (three centuries old) curiosity about the meaning of Leibniz′s nth derivative notation dny/dxn when n = 12, and many monumental works on the subject of fractional calculus have since appeared (and are still appearing) in the mathematical literature, the five-volume work published recently by K. Nishimoto [\Fractional Calculus","\"" Vols. I-IV",1984,1987,1989,"1991; \""An Essence of Nishimoto′s Fractional Calculus (Calculus in the 21st Century): Integrations and Differentiations of Arbitrary Order","\"" 1991] contains an interesting account of the theory and applications of fractional calculus in a number of areas of mathematical analysis (such as ordinary and partial differential equations",summation of series,et cetera). The main object of the present paper is to examine rather systematically some of the most recent contributions by Nishimoto et al. (cf.,e.g.,[J. College Engrg. Nihon Univ. Ser. B 32 (1991),7-13,15-21,23-30; J. Fractional Calculus1 (1992),"7-16]; see also [\""Fractional Calculus","\"" Vol. IV",1991; J. College Engrg. Nihon Univ. Ser. B33 (1992),1-8]),L. Galué et al. [J. Fractional Calculus 1 (1992),17-21],and others on the use of fractional calculus in finding the sums of numerous interesting families of infinite series. Various other classes of infinite sums found in the literature without using fractional calculus,and their hitherto unnoticed connections with certain known results,"are also considered."""
Journal Article,"Vasconcelos VT,Lopes L,Silva F",,Distribution and Mobility with Lexical Scoping in Process Calculi,Electronic Notes in Theoretical Computer Science,1998,16,3,189-204,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104001422;http://dx.doi.org/10.1016/S1571-0661(04)00142-2,10.1016/S1571-0661(04)00142-2,"We propose a simple model of distribution for mobile processes, independent of the underlying calculus. Conventional processes compute within sites; inter-site computation is achieved by message sending and object migration, both obeying a lexical scope. We focus on the semantics of networks, on programming practice, and on physical realization with current technology.",,"HLCL '98, 3rd International Workshop on High-Level Concurrent Languages (Satellite Workshop of CONCUR '98)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Traoré I,Aredo D,Ye H",,An integrated framework for formal development of open distributed systems,Information and Software Technology,2004,46,5,281-286,,,,,2004,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584903001952;http://dx.doi.org/10.1016/j.infsof.2003.09.012,10.1016/j.infsof.2003.09.012,"This paper contributes to the discussion on issues related to the formal development of open distributed systems (ODSs). Deficiencies of traditional formal notations in this setting are highlighted. We argue that there is no single formalism exhibiting all the features required to capture properties of ODSs. As a solution, we propose an integrated development framework that involves two notations: the Unified Modeling Language and the Prototype Verification System. We discuss the motivation for the choice of these notations, provide an overview of a CASE tool we have developed to support the proposed framework, and present a case study to demonstrate usability of our approach.","Formal methods, Open distributed systems, Unified Modeling Language, Prototype Verification System, Multi-formalism, Object-orientated programming","Special Issue on Software Engineering, Applications, Practices and Tools from the ACM Symposium on Applied Computing 2003",,,,,,,,,,,,,,,,,,,,
Journal Article,"Gottlob G,Schrefl M,Stumptner M",,Selective inheritance of attribute values in relational databases,Discrete Applied Mathematics,1992,40,2,187-216,,,,,1992,,0166-218X,https://www.sciencedirect.com/science/article/pii/0166218X9290029A;http://dx.doi.org/10.1016/0166-218X(92)90029-A,10.1016/0166-218X(92)90029-A,"Selective inheritance dependencies, or SIDs, are introduced to capture formally the inheritance of attribute values between tuples of any relation over a given relation scheme. It is shown that the membership problem, i.e., the question whether a SID is implied by a set of other SIDs, is NP-complete. Furthermore, a complete axiomatization for the implication problem of SIDs is given. Then, SIDs and functional dependencies (FDs) are studied together. SIDs and FDs together imply no other FDs than those already implied by the FDs alone. Although simple axiomatizations exist for FDs and SIDs separately, no k-ary axiomatization, i.e., no axiomatization in which every rule is k-ary for some fixed k, can fully describe the interaction between FDs and SIDs.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Candel CJ,Sevilla Ruiz D,García-Molina JJ",,A unified metamodel for NoSQL and relational databases,Information Systems,2021,,,101898,,,,,2021,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437921001149;http://dx.doi.org/10.1016/j.is.2021.101898,10.1016/j.is.2021.101898,"The Database field is undergoing significant changes. Although relational systems are still predominant, the interest in NoSQL systems is continuously increasing. In this scenario, polyglot persistence is envisioned as the database architecture to be prevalent in the future. Therefore, database tools and systems are evolving to support several data models. Multi-model database tools normally use a generic or unified metamodel to represent schemas of the data model that they support. Such metamodels facilitate developing database utilities, as they can be built on a common representation. Also, the number of mappings required to migrate databases from a data model to another is reduced, and integrability is favored. In this paper, we present the U-Schema unified metamodel able to represent logical schemas for the four most popular NoSQL paradigms (columnar, document, key–value, and graph) as well as relational schemas. We will formally define the mappings between U-Schema and the data model defined for each database paradigm. How these mappings have been implemented and validated will be discussed, and some applications of U-Schema will be shown. To achieve flexibility to respond to data changes, most of NoSQL systems are “schema-on-write,” and the declaration of schemas is not required. Such an absence of schema declaration makes structural variability possible, i.e., stored data of the same entity type can have different structure. Moreover, data relationships supported by each data model are different; For example, document stores have aggregate objects but not relationship types, whereas graph stores offer the opposite. Through the paper, we will show how all these issues have been tackled in our approach. As far as we know, no proposal exists in the literature of a unified metamodel for relational and the NoSQL paradigms which describes how each individual data model is integrated and mapped. Our metamodel goes beyond the existing proposals by distinguishing entity types and relationship types, representing aggregation and reference relationships, and including the notion of structural variability. Our contributions also include developing schema extraction strategies for schemaless systems of each NoSQL data model, and tackling performance and scalability in the implementation for each store.","Unified metamodel, NoSQL databases, Schemaless, Schema inference, Model-driven engineering",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lisle IG,Huang SL",,Algorithmic calculus for Lie determining systems,Journal of Symbolic Computation,2017,79,,482-498,,,,,2017,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717116300025;http://dx.doi.org/10.1016/j.jsc.2016.03.002,10.1016/j.jsc.2016.03.002,"The infinitesimal symmetries of differential equations (DEs) or other geometric objects provide key insight into their analytical structure, including construction of solutions and of mappings between DEs. This article is a contribution to the algorithmic treatment of symmetries of DEs and their applications. Infinitesimal symmetries obey a determining system L of linear homogeneous partial differential equations, with the property that its solution vector fields form a Lie algebra L. We exhibit several algorithms that work directly with the determining system without solving it. A procedure is given that can decide if a system specifies a Lie algebra L, if L is abelian and if a system L′ specifies an ideal in L. Algorithms are described that compute determining systems for transporter, Lie product and Killing orthogonal subspace. This gives a systematic calculus for Lie determining systems, enabling computation of the determining systems for normalisers, centralisers, centre, derived algebra, solvable radical and key series (derived series, lower/upper central series). Our methods thereby give algorithmic access to new geometrical invariants of the symmetry action.","Determining equations, Lie symmetry, Lie algebra, Structure constants, Differential elimination, Algorithm",,,,,,,,,,,,,,,,,,,,,
Journal Article,Worthington J,,A bialgebraic approach to automata and formal language theory,Annals of Pure and Applied Logic,2012,163,7,745-762,,,,,2012,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007211001412;http://dx.doi.org/10.1016/j.apal.2011.09.019,10.1016/j.apal.2011.09.019,"A bialgebra is a structure which is simultaneously an algebra and a coalgebra, such that the algebraic and coalgebraic parts are compatible. Bialgebras are usually studied over a commutative ring. In this paper, we apply the defining diagrams of algebras, coalgebras, and bialgebras to categories of semimodules and semimodule homomorphisms over a commutative semiring. We then treat automata as certain representation objects of algebras and formal languages as elements of dual algebras of coalgebras. Using this perspective, we demonstrate many analogies between the two theories. Finally, we show that there is an adjunction between the category of “algebraic” automata and the category of deterministic automata. Using this adjunction, we show that K-linear automaton morphisms can be used as the sole rule of inference in a complete proof system for automaton equivalence.","Automata, Bialgebra, Semimodule, Nondeterminism",The Symposium on Logical Foundations of Computer Science 2009,,,,,,,,,,,,,,,,,,,,
Book Chapter,Levi I,"Barcan Marcus R,Dorn GJ,Weingartner P",Probability Exists (But Just Barely)!,,1986,114,,367-385,,Elsevier,,"Logic, Methodology and Philosophy of Science VII",1986,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X09707013;http://dx.doi.org/10.1016/S0049-237X(09)70701-3,10.1016/S0049-237X(09)70701-3,"Publisher Summary The chapter discusses the fact that probability exists—but just barely. It is incredible that all applications of the calculus of probability in the natural and social sciences are representations and evaluations of subjective attitudes. Quantum mechanics is not a description of opinion, nor are statistical mechanics and genetics. Both the probability and the possibility assessments are expressions of states of judgment, which are neither true nor false. Probabilistic concepts are used in scientific applications to represent conditions under which objects and systems respond in various ways to experimentation. Stochastic attributions, like attributions of dispositions of dispositions, abilities and compulsions, are predications of properties to objects. Statistical probability is construed according to the Venn–von Mises approach to interpreting statistical probability and the Kolmogorov–Cramer–Braithwaite approach. Approaches along the lines of Kolmogorov–Cramer–Braithwaite are to be preferred because they seek to understand statistical probability by—namely, (1) articulating the formal requirements for a stochastic model and (2) offering an account of the epistemic or evidential connections between hypothesis about statistical probability and hypothesis about test behavior.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Puchianu CM,Bautu E",,Conceptual and Ontological Modeling of In-Vehicle Life-logging Software Systems,Procedia Computer Science,2020,176,,2635-2644,,,,,2020,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050920322158;http://dx.doi.org/10.1016/j.procs.2020.09.304,10.1016/j.procs.2020.09.304,"In-vehicle software systems that contain interconnected lifelogging components such as in-vehicle infotainment systems, smartphones, On Board Diagnostics (OBD) devices or wearable devices, operate with very large volumes of data. To manage the complexity and big volume of data, it is necessary to analyze the data and build models. Our goal, in this paper, is to build suitable models for in-vehicle lifelogging data, in the context of vehicle information standardization. To this aim, we build conceptual and ontological models for the data that is transmitted between the lifelogging components of an in-vehicle system, by applying conceptualization and abstraction mechanisms. Conceptual models can be built considering three viewpoints: functional, architectural, and behavioral. In this paper, we constructed a facet of the architectural view that contains the Unified Modeling Language (UML) classes and the relationships between them. Next, we designed and implemented the class diagram and generated each type of message in JavaScript Object Notation (JSON) format. In order to model the data and their semantics, we built an application ontology in Web Ontology Language (OWL). The consistency of this ontology was verified in Protégé. The ontology was further generated in the JavaScript Object Notation for Linked Data (JSON-LD) format, which provides us with a formal format of the messages transmitted between the components of the in-vehicle system. The resulting ontology is used in the persistence layer of the in-vehicle system we are developing.","In-vehicle system, Conceptual modeling, Ontological modeling, Software",Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020,,,,,,,,,,,,,,,,,,,,
Book Chapter,Mueller ET,Mueller ET,Chapter 1 - Introduction,,2015,,,1-16,Second Edition,Morgan Kaufmann,Boston,Commonsense Reasoning (Second Edition),2015,9780128014165,,https://www.sciencedirect.com/science/article/pii/B9780128014165000012;http://dx.doi.org/10.1016/B978-0-12-801416-5.00001-2,10.1016/B978-0-12-801416-5.00001-2,"We introduce the subject of automating commonsense reasoning. The key issues of commonsense reasoning include: representation; objects, properties, events, and time; object identity; reasoning; effects of events; context-sensitive events; nondeterministic effects; concurrent events; space; indirect effects; preconditions; the commonsense law of inertia; delayed effects; continuous change; release from the commonsense law of inertia; triggered events; default reasoning; mental states; and reasoning types. Any method for automated commonsense reasoning must address representation, commonsense entities, commonsense domains, commonsense phenomena, and reasoning. We give a brief history of commonsense reasoning. We review logical and nonlogical methods for commonsense reasoning. We introduce the event calculus, and we review the advantages and disadvantages of logic for automated commonsense reasoning.","Commonsense reasoning, Knowledge representation, History of research on commonsense reasoning, Event calculus, Key issues of commonsense reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,Elgueta J,,"2-Cosemisimplicial objects in a 2-category, permutohedra and deformations of pseudofunctors",Journal of Pure and Applied Algebra,2004,191,3,223-264,,,,,2004,,0022-4049,https://www.sciencedirect.com/science/article/pii/S002240490400009X;http://dx.doi.org/10.1016/j.jpaa.2003.12.007,10.1016/j.jpaa.2003.12.007,"In this paper we take up again the deformation theory for K-linear pseudofunctors initiated in Elgueta (Adv. Math. 182 (2004) 204–277). We start by introducing a notion of 2-cosemisimplicial object in an arbitrary 2-category and analyzing the corresponding coherence question, where the permutohedra make their appearance. We then describe a general method to obtain usual cochain complexes of K-modules from (enhanced) 2-cosemisimplicial objects in the 2-category CatK of small K-linear categories and prove that the deformation complex X•(F) introduced in Elgueta (to appear) can be obtained by this method from a 2-cosemisimplicial object that can be associated to F. Finally, using this 2-cosemisimplicial object of F and a generalization to the context of K-linear categories of the deviation calculus introduced by Markl and Stasheff for K-modules (J. Algebra 170 (1994) 122), it is shown that the obstructions to the integrability of an nth-order deformation of F indeed correspond to cocycles in the third cohomology group H3(X•(F)), a question which remained open in Elgueta (Adv. Math. 182 (2004) 204–277).",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Nisar KS,Purohit SD,Mondal SR",,Generalized fractional kinetic equations involving generalized Struve function of the first kind,Journal of King Saud University - Science,2016,28,2,167-171,,,,,2016,,1018-3647,https://www.sciencedirect.com/science/article/pii/S1018364715000750;http://dx.doi.org/10.1016/j.jksus.2015.08.005,10.1016/j.jksus.2015.08.005,In recent paper Dinesh Kumar et al. developed a generalized fractional kinetic equation involving generalized Bessel function of first kind. The object of this paper is to derive the solution of the fractional kinetic equation involving generalized Struve function of the first kind. The results obtained in terms of generalized Struve function of first kind are rather general in nature and can easily construct various known and new fractional kinetic equations.,"Fractional kinetic equations, Fractional calculus, Special functions, Laplace transforms, Generalized Struve function of the first kind",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li X,Liu F,Li A,Xu L",,Business Negotiation based on Extenics,Procedia Computer Science,2018,139,,521-528,,,,,2018,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050918319070;http://dx.doi.org/10.1016/j.procs.2018.10.238,10.1016/j.procs.2018.10.238,"The core needs of business negotiation are to achieve the goals expected by the negotiating parties, however, the goals of both parties are often conflicting. The conflict extended the negotiation cycle and even led to the breakdown of negotiations. The rapid accumulation of big data in the Internet environment has brought new opportunities for the intelligent research of business negotiations. In this paper, we use Extenics to describe the problem conflicts in business negotiation with a formal model. Through the systematic analysis of the relevant elements of negotiation deadlock, the negotiation object and conditions are respectively analyzed by formal divergence, correlation, implication and extensibility. The new win-win negotiation strategy is finally obtained by five basic transformations and the quantitative evaluation of the correlation function. The essence of the extension business negotiation is to seek the win-win solution from the seemingly unsolvable impossible. The practical application shows that the extension business negotiation provides a new method for the negotiation of multi-source data, information and knowledge, and helps the negotiators to reach a win-win agreement.","Business negotiation, Extenics, Conflict resolution, Win-win solution, Knowledge management",6th International Conference on Information Technology and Quantitative Management,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bruni C,Iacoviello D,Koch G,Lucchetti M",,Filtering image sequences from a moving object and the edge detection problem,Computers & Mathematics with Applications,2006,51,3,559-578,,,,,2006,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122105005225;http://dx.doi.org/10.1016/j.camwa.2005.07.015,10.1016/j.camwa.2005.07.015,"In this paper, we consider the problem of filtering sequences of images taken from moving objects, with the aim of recovering information about the object itself as well as its underlying motion. We first provide a formal description of the admissible classes of images and (possibly nonrigid) motions, and of the functional relationship between the original image and the observed one (blurring and noisy effects). We then focus on the problem of edge detection, assuming full information about the motion. We propose a procedure that includes a preliminary preprocessing of the measured image, aimed to localize the detection problem and to improve the signal-to-noise ratio. Then, the edge identification is accomplished by an algorithm which implements recursive linear quadratic estimation and hypothesis testing. Finally, the procedure is tested against simulated and real data.","Edge detection, Moving objects, Nonrigid motionl Recursive estimation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gyssens M,Hellings J,Paredaens J,Van Gucht D,Wijsen J,Wu Y",,Calculi for symmetric queries,Journal of Computer and System Sciences,2019,105,,54-86,,,,,2019,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000018305713;http://dx.doi.org/10.1016/j.jcss.2019.04.003,10.1016/j.jcss.2019.04.003,"Symmetric queries are introduced as queries on a sequence of sets of objects the result of which does not depend on the order of the sets. An appropriate data model is proposed, and two query languages are introduced, QuineCALC and SyCALC. They are correlated with the symmetric Boolean respectively relational functions. The former correlation yields an incidence-based normal form for QuineCALC queries. More generally, we propose counting-only queries as those SyCALC queries the result of which only depends on incidence information, and characterize them as quantified Boolean combinations of QuineCALC queries. A normal form is proposed for them too. It turns out to be undecidable whether a SyCALC query is counting-only, but decidable whether a counting-only query is a QuineCALC query. Finally, some classical decidability problems are considered which are shown to be undecidable for SyCALC, but decidable for QuineCALC and counting-only queries.","Bag of sets data model, Symmetric query, Two-sorted first-order logic, Two-sorted relational calculus, Symmetric Boolean function, Symmetric relational function, Counting-only query, Normal form, Expressibility, Satisfiability",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li Y,Wang Y",,Planning-based knowing how: A unified approach,Artificial Intelligence,2021,296,,103487,,,,,2021,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370221000382;http://dx.doi.org/10.1016/j.artint.2021.103487,10.1016/j.artint.2021.103487,"Various logical notions of know-how have been recently proposed and studied in the literature based on different types of epistemic planning in different frameworks. This paper proposes a unified logical framework to incorporate the existing and some new notions of know-how. We define the semantics of the know-how operator using a unified notion of epistemic planning with parameters of different types of plans specified by a programming language. Surprisingly, via a highly unified completeness proof, we show that all the ten intuitive notions of plans discussed in this paper lead to exactly the same know-how logic, which is proven to be decidable. We also show that over finite models, the know-how logic based on knowledge-based plans requires an extension with an axiom capturing the compositionality of the plans. In the context of epistemic planning, our axiomatization results reveal the core principles behind the very idea of epistemic planning, independent of the particular notion of plans. Moreover, since epistemic planning can be expressed by the know-how modality in our object language, we can greatly generalize the planning problems that can be solved formally by model checking various formulas in our language.","Epistemic planning, Know-how, Epistemic logic, Conformant planning, Contingent planning, Knowledge-based programs",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Järvelin K,Niemi T",,An entity-based approach to query processing in relational databases: Part I: Entity type representation,Data & Knowledge Engineering,1993,10,2,117-150,,,,,1993,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9390006B;http://dx.doi.org/10.1016/0169-023X(93)90006-B,10.1016/0169-023X(93)90006-B,"An entity-based query interface to relational databases is developed. The interface combines some object-oriented features with the strengths of universal relation DBMSs (UR-DBMSs) by a value-oriented high-level representation of complex entity types. It enhances logical data independence by hiding their implementation in a relational database. The abstraction level of the entity representation lies between the relations of the relational model and the universal relation. This allows higher level expressions than the relational model but avoids the weaknesses of the UR-DBMSs. The interface supports a declarative entity-based query language of the level of Quel (described in Part II). The key features of the interface are: (1) the entity type representation and associated operations which allow the derivation of the entity types of the results of entity-based queries, and (2) and unambiguous and optimizing solution to the query interpretation problem of UR-DBMSs. The interface constructs equivalent RA expressions for entity queries to be evaluated by relational DBMSs (RDBMSs). The interface is specified in a formal and general way. It has essential benefits, which support further processing of query results, improve query efficiency, clarify query semantics, enhance logical data independence, and allow use of existing RDBMS software by interfacing them to the entity level processing in a systematic way. It separates the entity type and relational levels into different domains and integrates them together through a well-defined interface. The interface exploits fully and easily the optimization capabilities of universal relation-based systems. The entity types provide the users with a high-level and natural view of the database. The users express their queries in terms of the entity types. This simplifies the expression of complex queries considerably w.r.t. conventional query systems. The interface exploits this knowledge in an effective way.","Universal relation databases, complex entity types, data modelling, ambiguity resolution",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ali H,Badshah N,Chen K,Khan GA",,A variational model with hybrid images data fitting energies for segmentation of images with intensity inhomogeneity,Pattern Recognition,2016,51,,27-42,,,,,2016,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320315003106;http://dx.doi.org/10.1016/j.patcog.2015.08.022,10.1016/j.patcog.2015.08.022,"Level set functions based variational image segmentation models provide reliable methods to capture boundaries of objects/regions in a given image, provided that the underlying intensity has homogeneity. The case of images with essentially piecewise constant intensities is satisfactorily dealt with in the well-known work of Chan–Vese (2001) and its many variants. However for images with intensity inhomogeneity or multiphases within the foreground of objects, such models become inadequate because the detected edges and even phases do not represent objects and are hence not meaningful. To deal with such problems, in this paper, we have proposed a new variational model with two fitting terms based on regions and edges enhanced quantities respectively from multiplicative and difference images. Tests and comparisons will show that our new model outperforms two previous models. Both synthetic and real life images are used to illustrate the reliability and advantages of our new model.","Image segmentation, Calculus of variations, Level set method, Partial differential equations, Edges, Objects",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hull R,Su J",,Deductive query languages for recursively typed complex objects,The Journal of Logic Programming,1998,35,3,231-261,,,,,1998,,0743-1066,https://www.sciencedirect.com/science/article/pii/S0743106697100097;http://dx.doi.org/10.1016/S0743-1066(97)10009-7,10.1016/S0743-1066(97)10009-7,"Deductive database query languages for recursively typed complex objects based on the set and tuple constructs are studied. A fundamental characteristic of such complex objects is that in them, sets may contain members with arbitrarily deep nesting of tuple and set constructs. Relative to mappings from flat relations to flat relations, two extensions of COL in this context (with stratified semantics and inflationary semantics, respectively) are shown to have the expressive power of computable queries. Although the deductive calculus of Bancilhon and Khoshafian has the ability to simulate Turing machines, when restricted to flat input and output its expressive power is characterized by a weak variant of the conjunctive queries.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Davies and J,Crichton C",,Concurrency and Refinement in the Unified Modeling Language,Electronic Notes in Theoretical Computer Science,2002,70,3,217-243,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105804943;http://dx.doi.org/10.1016/S1571-0661(05)80494-3,10.1016/S1571-0661(05)80494-3,"This paper shows how a formal notion of refinement may be defined for models, and model components, expressed in the Unified Modeling Language (UML). A formal, behavioural semantics is given to combinations of class, object, and state diagrams, using the notation of Communicating Sequential Processes (CSP); this semantics is adequate for the analysis of concurrent, communicating behaviour, and induces a notion of refinement for UML based upon existing notions of traces and failures refinement for CSP.",,"REFINE 2002, The BCS FACS Refinement Workshop (Satellite Eventof FLoC 2002)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Eysink TH,Dijkstra S,Kuper J",,Cognitive processes in solving variants of computer-based problems used in logic teaching,Computers in Human Behavior,2001,17,1,1-19,,,,,2001,,0747-5632,https://www.sciencedirect.com/science/article/pii/S0747563200000388;http://dx.doi.org/10.1016/S0747-5632(00)00038-8,10.1016/S0747-5632(00)00038-8,"The effect of two instructional variables, visualisation and manipulation of objects, in learning to use the logical connective, conditional, was investigated. Instructions for 66 first-year social science students were varied in the computer-based learning environment Tarski's World, designed for teaching first-order logic (Barwise & Etchemendy, 1992. The language of first-order logic: including the Microsoft Windows program Tarski's World 4.0 for use with IBM-compatible computers. Stanford, CA: CSLI). For all instructional conditions, the scores on the transfer tests showed a significant increase in understanding the conditional. Visualisation, operationalised as presenting only formal expressions or a geometrical reality in addition to these, showed no differences on the transfer test. If only presented formal expressions, about half of the participants needed to make drawings of the objects, especially when the problems increased in complexity. The manipulation condition, in which the participants could either construct a geometrical world or were presented a fixed world, significantly influenced the participants' cognitive processes in solving the logic problems. The students worked affirmatively and were tempted to stay in familiar situations. The results support the authors' view that visualisation facilitates cognitive processing. Moreover, the results are congruent with Piaget's theory of the development of knowledge of formal science concepts from the action with objects.","Logical reasoning, Problem solving, Cognitive processes, Computer-based instruction, Visualisation, Manipulation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kang X,Miao D",,A study on information granularity in formal concept analysis based on concept-bases,Knowledge-Based Systems,2016,105,,147-159,,,,,2016,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705116300946;http://dx.doi.org/10.1016/j.knosys.2016.05.005,10.1016/j.knosys.2016.05.005,"As one of mature theories, formal concept analysis (FCA) possesses remarkable mathematical properties, but it may generate massive concepts and complicated lattice structure when dealing with large-scale data. With a view to the fact that granular computing (GrC) can significantly lower the difficulty by selecting larger and appropriate granulations when processing large-scale data or solving complicated problems, the paper introduces GrC into FCA, it not only helps to expand the extent and intent of classical concept, but also can effectively reduce the time complexity and space complexity of FCA in knowledge acquisition to some degree. In modeling, concept-base, as a kind of low-level knowledge, plays an important role in the whole process of information granularity. Based on concept-base, attribute granules, object granules and relation granules in formal contexts are studied. Meanwhile, supremum and infimum operations are introduced in the precess of information granularity, whose biggest distinction from traditional models is integrating the structural information of concept lattice. In addition, the paper also probes into reduction, core, and implication rules in granularity formal contexts. Theories and examples verify the reasonability and effectiveness of the conclusions drawn in the paper. In short, the paper not only can be viewed as an effective means for the expansion of FCA, but also is an attempt for the fusion study of the two theories.","Concept lattice, Granularity, Concept-bases, Concept similarity",,,,,,,,,,,,,,,,,,,,,
Journal Article,Paterno' F,,A Theory of User-interaction Objects,Journal of Visual Languages & Computing,1994,5,3,227-249,,,,,1994,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X84710123;http://dx.doi.org/10.1006/jvlc.1994.1012,10.1006/jvlc.1994.1012,"A general theory is presented which formally describes user interface systems that manage communications between users and applications. Its purpose is to provide the formal semantics of a large spectrum of user interface systems by means of interaction objects which have been mathematically defined. The main features of this approach are that the relationships between input and output functionalities are completely addressed, and these systems are uniformly described by a multilayered composition of interaction objects derived from a specific architectural model for basic interactions with users. Within the framework thus obtained we make comparisons between different instances of interactive visual environments in order to establish whether their behaviour is equivalent at least for some aspects, and we give examples of properties that can be investigated.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Trček D,,Lightweight protocols and privacy for all-in-silicon objects,Ad Hoc Networks,2013,11,5,1619-1628,,,,,2013,,1570-8705,https://www.sciencedirect.com/science/article/pii/S1570870513000255;http://dx.doi.org/10.1016/j.adhoc.2013.02.005,10.1016/j.adhoc.2013.02.005,"Pervasive computing is already becoming a reality and one crucial consequence of this fact is endangered privacy. Now taking into account typical properties of pervasive computing devices, which are weak computing power and stringent energy or power consumption limitations, lightweight solutions are a must. This especially holds true for all-in-silicon objects like radio frequency identification tags, or RFIDs. Many solutions in this area are called lightweight, but being lightweight requires conformance to quantitative requirements using certain metrics. A solution that adheres to such requirements is a new privacy enabling protocol for RFIDs that outperforms other architecturally similar protocols, and this presents the first contribution of this paper. Further, privacy is not only a matter of technical solutions, but increasingly so a matter of organizational processes. This fact calls for further addressing of supporting its formal treatment in business contexts. This paper provides a basis for formal addressing of privacy from business processes perspective, and this is its second main contribution.","Wireless sensor networks, RFID technology, Security, Privacy, Lightweight protocols, Security policies",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Niwiński D,Walukiewicz I",,Games for the μ-calculus,Theoretical Computer Science,1996,163,1,99-116,,,,,1996,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397595001360;http://dx.doi.org/10.1016/0304-3975(95)00136-0,10.1016/0304-3975(95)00136-0,"Given a formula of the propositional μ-calculus, we construct a tableau of the formula and define an infinite game of two players of which one wants to show that the formula is satisfiable, and the other seeks the opposite. The strategy for the first player can be further transformed into a model of the formula while the strategy for the second forms what we call a refutation of the formula. Using Martin's Determinacy Theorem, we prove that any formula has either a model or a refutation. This completeness result is a starting point for the completeness theorem for the μ-calculus to be presented elsewhere. However, we argue that refutations have some advantages of their own. They are generated by a natural system of sound logical rules and can be presented as regular trees of the size exponential in the size of a refuted formula. This last aspect completes the small model theorem for the μ-calculus established by Emerson and Jutla (1988). Thus, on a more practical side, refutations can be used as small objects testifying incorrectness of a program specification expressed by a μ-formula, we illustrate this point by an example.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bastide R,Navarre D,Palanque P",,A tool-supported design framework for safety critical interactive systems,Interacting with Computers,2003,15,3,309-328,,,,,2003,,0953-5438,https://www.sciencedirect.com/science/article/pii/S0953543803000110;http://dx.doi.org/10.1016/S0953-5438(03)00011-0,10.1016/S0953-5438(03)00011-0,"This paper presents a design framework for safety critical interactive systems, based on a formal description technique called the ICO (Interactive Cooperative Object) formalism. ICO allows for describing, in a formal way, all the components of highly interactive (also called post-WIMP) applications. The framework is supported by a case tool called PetShop allowing for editing, verifying and executing the formal models. The first section describes why such user interfaces are challenging for most description techniques, as well as the state of the art in this field. Section 3 presents a development process dedicated to the framework. Then, we use a case study in order to recall the basic concepts of the ICO formalism and the recent extensions added in order to take into account post-WIMP interfaces' specificities. Section 5 presents the case tool PetShop and how the case study presented in the previous section has been dealt with. Lastly, we show how PetShop can be used for interactive prototyping.","Interactive cooperative object, Interface, PetShop",Computer-Aided Design of User Interface,,,,,,,,,,,,,,,,,,,,
Journal Article,"Braud A,Dolques X,Huchard M,Le Ber F",,Generalization effect of quantifiers in a classification based on relational concept analysis,Knowledge-Based Systems,2018,160,,119-135,,,,,2018,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705118303198;http://dx.doi.org/10.1016/j.knosys.2018.06.011,10.1016/j.knosys.2018.06.011,"Relational Concept Analysis (RCA) has been designed to classify sets of objects described by attributes and relations between these objects. This is achieved by iterating on Formal Concept Analysis (FCA). It can be used to discover knowledge patterns and implication rules in multi-relational datasets. The classification output by RCA is a family of lattices whose graphical representation facilitates the analysis by an expert. However, RCA comes with specific complexity issues. It iterates on the building of interconnected concept lattices, so that each concept in a lattice might be the cause of generating other concepts in other lattices. In complex analyses, it relies on the successive choice of scaling operators which affects the size and the understandability of the results. These operators are based on a set of quantifiers which are studied in this paper: we indeed focus on the comparison of scaling quantifiers and highlight a generality relation between them. Our theoretical proposition is complemented by an experimental evaluation of the exploration space size, based on a real dataset upon watercourses. This work is intended for data analysts, to provide them with an overview on the different strategies offered by RCA.","Relational data exploration, Relational concept analysis, Generality relation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mordecai Y,Crawley EF",,Conceptual State Analysis,Procedia Computer Science,2021,185,,274-281,,,,,2021,,1877-0509,https://www.sciencedirect.com/science/article/pii/S187705092101111X;http://dx.doi.org/10.1016/j.procs.2021.05.029,10.1016/j.procs.2021.05.029,"Conceptual State Analysis (CSA) is the process of defining, exploring, and reasoning about state attributes and state spaces in complex system architectures. Model-Based State Analysis enhances CSA with formal modeling and analysis methods. We propose a process for generating the state vector of a given system architecture, based on a graph representation of the architecture’s model in Object-Process Methodology. A robust graph data structure that represents the model is queried to produce the architecture’s state space. The process facilitates analysis, reasoning, and model revision based on improved understanding of state vectors and state spaces. State attribute refinements within the model allow for model validity, viability, and reusability as the architecture evolves, with multiple agents, attributes, and attribute state values. The CSA approach advocates and facilitates careful, dynamic, and interactive state space exploration in lieu of exhaustive upfront enumeration of state space permutations. The results can be fed into other analysis, simulation, or visualization tools. We demonstrate CSA on driver assistance technology.","Conceptual State Analysis, Model Based State Analysis, Model Based Systems Architecting, Graph Data Structures","Big Data, IoT, and AI for a Smarter Future",,,,,,,,,,,,,,,,,,,,
Journal Article,"Qin H,Wang H,Johnson AL",,A RFBSE model for capturing engineers’ useful knowledge and experience during the design process,Robotics and Computer-Integrated Manufacturing,2017,44,,30-43,,,,,2017,,0736-5845,https://www.sciencedirect.com/science/article/pii/S0736584516300977;http://dx.doi.org/10.1016/j.rcim.2016.08.004,10.1016/j.rcim.2016.08.004,"Reuse of designers’ knowledge and experience of solving problems during the engineering design process holds the key to increase efficiency of decision making in future projects. An important part of this useful knowledge and experience is the interpretation of data and information about design objects and processes as well as the generation of new information for decision-making. However, previous studies on knowledge representation models have mainly focused on developing a structure to describe the knowledge about design objects and design processes while a systematic method that can effectively integrate knowledge about design objects and knowledge about problem-solving strategies is still missing. To fill this gap, a RFBSE knowledge representation model for capturing useful design knowledge and experience for future reuse is developed and evaluated in this study. This paper describes the key elements of this model, explains the rationale of using particular elements, and discusses the evaluation of the model using an engineering design example.","Knowledge capture, Knowledge representation, Knowledge model, Engineering design, Knowledge reuse",,,,,,,,,,,,,,,,,,,,,
Journal Article,Hayashi S,,Mathematics based on incremental learning—Excluded middle and inductive inference,Theoretical Computer Science,2006,350,1,125-139,,,,,2006,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397505006468;http://dx.doi.org/10.1016/j.tcs.2005.10.019,10.1016/j.tcs.2005.10.019,"Learning theoretic aspects of mathematics and logic have been studied by many authors. They study how mathematical and logical objects are algorithmically “learned” (inferred) from finite data. Although they study mathematical objects, the objective of the studies is learning. In this paper, a mathematics whose foundation itself is learning theoretic will be introduced. It is called Limit-Computable Mathematics. It was originally introduced as a means for “Proof Animation”, which is expected to make interactive formal proof development easier. Although the original objective was not learning theoretic at all, learning theory is indispensable for our research. It suggests that logic and learning theory are related in a still unknown but deep new way.","Learning theory, Constructive logic, The law of excluded middle",Algorithmic Learning Theory (ALT 2002),,,,,,,,,,,,,,,,,,,,
Journal Article,"Barboni E,Martinie C,Navarre D,Palanque P,Winckler M",,Bridging the gap between a behavioural formal description technique and a user interface description language: Enhancing ICO with a graphical user interface markup language,Science of Computer Programming,2014,86,,3-29,,,,,2014,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642313000993;http://dx.doi.org/10.1016/j.scico.2013.04.001,10.1016/j.scico.2013.04.001,"In the last years, User Interface Description Languages (UIDLs) appeared as a suitable solution for developing interactive systems. In order to implement reliable and efficient applications, we propose to employ a formal description technique called ICO (Interactive Cooperative Object) that has been developed to cope with complex behaviours of interactive systems including event-based and multimodal interactions. So far, ICO is able to describe most of the parts of an interactive system, from functional core concerns to fine grain interaction techniques, but, even if it addresses parts of the rendering, it still not has means to describe the effective rendering of such interactive system. This paper presents a solution to overcome this gap using markup languages. A first technique is based on the Java technology called JavaFX and a second technique is based on the emergent UsiXML language for describing user interface components for multi-target platforms. The proposed approach offers a bridge between markup language based descriptions of the user interface components and a robust technique for describing behaviour using ICO modelling. Furthermore, this paper highlights how it is possible to take advantage from both behavioural and markup language description techniques to propose a new model-based approach for prototyping interactive systems. The proposed approach is fully illustrated by a case study using an interactive application embedded into interactive aircraft cockpits.","Model-based approaches, User interface description language, Formal description techniques, Behavioural modelling, Graphical user interface markup language",Special issue on Software Support for User Interface Description Languages (UIDL 2011),,,,,,,,,,,,,,,,,,,,
Journal Article,"Marinov M,Zheliazkova I",,An interactive tool based on priority semantic networks,Knowledge-Based Systems,2005,18,2,71-77,,,,,2005,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705104000504;http://dx.doi.org/10.1016/j.knosys.2004.08.001,10.1016/j.knosys.2004.08.001,"The main advantages of the semantic networks as formalism for knowledge representation are well known: simplicity, naturalness, visionless, and clarity. However, they have the following disadvantages: poor representation of arbitrary relations, insufficient expressiveness, unclear semantics, difficult implementation of some operations, and difficult control of the inheritance. In the present paper, the formal definition of a new kind of semantic network, called Priority Semantic Network (PSN) is given. On this basis, an algorithm of transformation of PSN into a list of concepts and semantic links is presented. The architecture and user interface of a tool, in which this algorithm is embedded, are also discussed.","Priority semantic networks, Knowledge representation and processing, An interactive tool",,,,,,,,,,,,,,,,,,,,,
Journal Article,Benczúr A,,The evolution of human communication and the information revolution — A mathematical perspective,Mathematical and Computer Modelling,2003,38,7,691-708,,,,,2003,,0895-7177,https://www.sciencedirect.com/science/article/pii/S0895717703900550;http://dx.doi.org/10.1016/S0895-7177(03)90055-0,10.1016/S0895-7177(03)90055-0,"In my paper, human communication is placed into the center of informatics. The typical schema of elementary communication and communication in information systems is discussed by natural and formal schemas. The schemas are used to explain the main characteristics of the epochs of the evolution of human communication and the key effect of dramatic change in communication due to the very fast development of information technology. The main lows of two mathematical theories, namely Shannon's information theory and the Kolmogorov algorithmic entropy, are explained together with their roles in communication. The coincidence of the two entropies on very large objects is proved. The difference between large, algorithmically generated, compressible objects and the typical, uncompressible random objects is visually demonstrated by black and white colorings. The interesting self-interference of random colorings is shown and explained.","Communication, Information systems, Information theory, Kolmogorov complexity, Randomness",Hungarian Applied Mathematics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Attali I,Caromel D,Henrio L,Del Aguila FL",,Secured Information Flow for Asynchronous Sequential Processes,Electronic Notes in Theoretical Computer Science,2007,180,1,17-34,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107003131;http://dx.doi.org/10.1016/j.entcs.2005.05.045,10.1016/j.entcs.2005.05.045,"We present in this article a precise security model for data confidentiality in the framework of ASP (Asynchronous Sequential Processes). ASP is based on active objects, asynchronous communications, and data-flow synchronizations. We extend it with security levels attached to activities (active objects) and transmitted data. We design a security model that guarantees data confidentiality within an application; this security model takes advantages of both mandatory and discretionary access models. We extend the semantics of ASP with predicate conditions that provide a formal security framework, dynamically checking for unauthorized information flows. As a final result, all authorized communication paths are secure: no disclosure of information can happen. This theoretically-founded contribution may have a strong impact on distributed object-based applications, that are more and more present and confidentiality-demanding on the Internet, it also arises a new issue in data confidentiality: authorization of secured information flow transiting (by the mean of futures) through an unsecured component.","Access control, distribution, objects, futures",Proceedings of the International Workshop on Security and Concurrency (SecCo 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Khambhammettu H,Boulares S,Adi K,Logrippo L",,A framework for risk assessment in access control systems,Computers & Security,2013,39,,86-103,,,,,2013,,0167-4048,https://www.sciencedirect.com/science/article/pii/S0167404813000552;http://dx.doi.org/10.1016/j.cose.2013.03.010,10.1016/j.cose.2013.03.010,"We describe a framework for risk assessment specifically within the context of risk-based access control systems, which make authorization decisions by determining the security risk associated with access requests and weighing such security risk against operational needs together with situational conditions. Our framework estimates risk as a product of threat and impact scores. The framework that we describe includes four different approaches for conducting threat assessment: an object sensitivity-based approach, a subject trustworthiness-based approach and two additional approaches which are based on the difference between object sensitivity and subject trustworthiness. We motivate each of the four approaches with a series of examples. We also identify and formally describe the properties that are to be satisfied within each approach. Each of these approaches results in different threat orderings, and can be chosen based on the context of applications or preference of organizations. We also propose formulae to estimate the threat of subject–object accesses within each of the four approaches of our framework. We then demonstrate the application of our threat assessment framework for estimating the risk of access requests, which are initiated by subjects to perform certain actions on data objects, by using the methodology of NIST Special Publication 800-30. We show that risk estimates for access requests actually differ based on the threat assessment approach that has been chosen. Therefore, organizations must make prudent judgement while selecting a threat assessment function for risk-based access control systems.","Security, Access control, Risk, Threat, Impact",27th IFIP International Information Security Conference,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ruta A,Li Y",,Learning pairwise image similarities for multi-classification using Kernel Regression Trees,Pattern Recognition,2012,45,4,1396-1408,,,,,2012,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320311004134;http://dx.doi.org/10.1016/j.patcog.2011.09.028,10.1016/j.patcog.2011.09.028,"We are often faced with the problem of distinguishing between visually similar objects that share the same general appearance characteristics. As opposed to object categorization, this task is focused on capturing fine image differences in a pose-dependent fashion. Our research addresses this particular family of problems and is centered around the concept of learning from example pairs. Formally, we construct a parameterized visual similarity function optimally separating the pairs of images that depict the objects of the same class or identity from the pairs representing different object classes/identities. It combines various image distances that are quantified by comparing local descriptor responses at the corresponding locations in both paired images. To find the best combinations, we train ensembles of so-called Kernel Regression Trees which model the desired similarity function as a hierarchy of fuzzy decision stumps. The obtained function is then used within a k-NN-like framework to address complex multi-classification problems. Through the experiments with several image datasets we demonstrate the numerous advantages of the proposed approach: high classification accuracy, scalability, ease of interpretation and the independence of the feature representation.","Visual similarity, Learning from example pairs, Object recognition, Kernel Regression Trees",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Belohlavek R,Dvořák J,Outrata J",,Fast factorization by similarity in formal concept analysis of data with fuzzy attributes,Journal of Computer and System Sciences,2007,73,6,1012-1022,,,,,2007,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000007000384;http://dx.doi.org/10.1016/j.jcss.2007.03.016,10.1016/j.jcss.2007.03.016,"We present a method of fast factorization in formal concept analysis (FCA) of data with fuzzy attributes. The output of FCA consists of a partially ordered collection of clusters extracted from a data table describing objects and their attributes. The collection is called a concept lattice. Factorization by similarity enables us to obtain, instead of a possibly large concept lattice, its factor lattice. The elements of the factor lattice are maximal blocks of clusters which are pairwise similar to degree exceeding a user-specified threshold. The factor lattice thus represents an approximate version of the original concept lattice. We describe a fuzzy closure operator the fixed points of which are just clusters which uniquely determine the blocks of clusters of the factor lattice. This enables us to compute the factor lattice directly from the data without the need to compute the whole concept lattice. We present theoretical solution and examples demonstrating the speed-up of our method.","Tabular data, Clustering, Formal concept analysis, Fuzzy attributes, Similarity, Factorization",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Sutton I,Sutton I,Chapter 9 - Formal Safety Analysis,,2014,,,267-317,Second Edition,William Andrew Publishing,Oxford,Offshore Safety Management (Second Edition),2014,9780323262064,,https://www.sciencedirect.com/science/article/pii/B9780323262064000095;http://dx.doi.org/10.1016/B978-0-323-26206-4.00009-5,10.1016/B978-0-323-26206-4.00009-5,"This chapter describes an approach to Formal Safety Analysis (FSA) that can be used regardless of the safety management system being used (for example, SEMS or Safety Case). Topics covered include the development and use of philosophies, the elements of an FSA, the need for an Assumptions Register, and the role of Quantitative Risk Analysis (QRA), particularly Fault Tree and Event Tree Analysis. Also covered are layout, flare and radiation analysis, material handling (dropped objects), fire and gas detection and control, dispersion analysis, escape and evacuation, and non-hydrocarbon chemicals. Some health topics, such as noise management, are described. The chapter concludes with a discussion of offshore Human Factors management, including Valve Criticality Analysis.","Formal Safety Analysis (FSA), deck type, dropped objects, Quantitative Risk Assessment (QRA), Fault Tree Analysis (FTA), Event Tree Analysis (ETA), Manual Alarm Call Points (MAC), Emergency Systems Survivability (EER), Human Factors (HFE), Technique for Human Error Rate Prediction (THERP)",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Seong DS,Kim HS,Park KH",,Formal definition and entropy calculation of hierarchical attributed random graph,Pattern Recognition Letters,1992,13,8,545-555,,,,,1992,,0167-8655,https://www.sciencedirect.com/science/article/pii/016786559290089I;http://dx.doi.org/10.1016/0167-8655(92)90089-I,10.1016/0167-8655(92)90089-I,"For the representation of a complex object, the object is decomposed into several parts, and it is described by these decomposed parts and their relations. In general, the parts can be the primitive elements that can not be decomposed further, or still can be decomposed into their subparts. Therefore, the hierarchical description method is very natural and the hierarchical description is represented by a hierarchical graph whose vertices represent either primitive elements or graphs. These graohs also have vertices which contain primitive elements or graphs. When some uncertainty exists in the hierarchical description of a complex object either due to noise or minor deformation, a probabilistic description of the object ensemble is necessary. For this purpose, in this paper, we formally define the hierarchical attributed random graph and derive the equations for the entropy calculation of the hierarchical random graph.","Hierarchical attributed random graph, hierarchical description, entropy",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Najm E,Stefani JB",,A formal semantics for the ODP computational model,Computer Networks and ISDN Systems,1995,27,8,1305-1329,,,,,1995,,0169-7552,https://www.sciencedirect.com/science/article/pii/016975529400032O;http://dx.doi.org/10.1016/0169-7552(94)00032-O,10.1016/0169-7552(94)00032-O,"The ODP computational model is an essential part of the ODP Reference Model that provides an abstract, language-independent programming framework for open distributed systems. This paper presents a formal operational semantics for an essential subset of the ODP computational model. The semantics takes the form of a rewriting theory that provides a generic and abstract true-concurrency semantics for the ODP computational model.","Open distributed processing, ODP, Distributed systems, Computational model, Operational semantics, Object-based systems, Object-based programming",ISO Reference Model for Open Distributed Processing,,,,,,,,,,,,,,,,,,,,
Journal Article,Sol HG,,Conflicting experiences with DSS,Decision Support Systems,1987,3,3,203-211,,,,,1987,,0167-9236,https://www.sciencedirect.com/science/article/pii/0167923687901758;http://dx.doi.org/10.1016/0167-9236(87)90175-8,10.1016/0167-9236(87)90175-8,"The concept of DSS is clearly attracting a lot of interest. Although this should be welcomed, it does not signify that the concept is well-defined and well-established. Above, we may observe that empirical evidence on the effectiveness of DSS is not overwhelmingly positive, and is often conflicting. Many DSS focus on problem-solving, not on problem-identification. Many DSS are constructed around aggregated data, separated from primary, transaction processing data. However, it is shown in several studies that use of this type of data may be dangerous for decision-making. With regard to the model component of many decision-making. With regard to the model component ‘equation’ type. These models are only applicable under the assumption that the equations can be filled in and that they give a valid description of reality. This assumption seems to hold only in a very few case. A way out can be found in the application of models of the discrete event or ‘process’ type. A frequently encountered approach for the development of DSS is an evolutionary, step-wise one. However, such an approach is not necessarily converging. Especially personalized DSS demand a strong project management to avoid a chaos of hardware, software, personal files and models. Decentralization of decision-making and computing does not guarantee a better co-ordination of the workstations of individual information workers. We propose to use the concept DSS in a more narrow sense of an environment to support decision making, encompassing a language system, a knowledge system and a problem processing system. The language system is based on an object-oriented representation form. The problem processing system and the knowledge system bear heavily on the process type system specification.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Toben T,Rakow JH",,Safety and Precision of Spatial Context Models for Autonomous Systems,Electronic Notes in Theoretical Computer Science,2013,297,,75-88,,,,,2013,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066113000868;http://dx.doi.org/10.1016/j.entcs.2013.12.006,10.1016/j.entcs.2013.12.006,"A safe (i.e. collision-free) and efficient movement of a mobile autonomous system requires a correct assessment of the vehiclesʼ environment. In many systems, the spatial context is represented by means of an occupancy grid, that is, a partitioning of a two-dimensional area into finitely many cells where each cell maintains a probabilistic estimation of being occupied by some object. Often, this representation is complemented by dedicated information regarding the detected objects. We instantiate a generic framework based on a formal notion of abstraction for characterising the safety and precision of such kind of spatial context models. In this approach, the sensory perception corresponds to an abstraction function, and the concretisation function reflects the loss of information with respect to the real environment. We show that this method is able to derive both qualitative and quantitative measures for different variants of spatial context models.","Autonomous Systems, Spatial Context Models, Safety Requirements",Proceedings of the first workshop on Hybrid Autonomous Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Filipović I,O’Hearn P,Rinetzky N,Yang H",,Abstraction for concurrent objects,Theoretical Computer Science,2010,411,51,4379-4398,,,,,2010,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397510005001;http://dx.doi.org/10.1016/j.tcs.2010.09.021,10.1016/j.tcs.2010.09.021,"Concurrent data structures are usually designed to satisfy correctness conditions such as sequential consistency or linearizability. In this paper, we consider the following fundamental question: What guarantees are provided by these conditions for client programs? We formally show that these conditions can be characterized in terms of observational refinement. Our study also provides a new understanding of sequential consistency and linearizability in terms of abstraction of dependency between computation steps of client programs.","Linearizability, Sequential consistency, Observational equivalence, Observational refinement",European Symposium on Programming 2009,,,,,,,,,,,,,,,,,,,,
Journal Article,Kim JY,,Extinction of elastic wave energy due to scattering in a viscoelastic medium,International Journal of Solids and Structures,2003,40,17,4319-4329,,,,,2003,,0020-7683,https://www.sciencedirect.com/science/article/pii/S0020768303002415;http://dx.doi.org/10.1016/S0020-7683(03)00241-5,10.1016/S0020-7683(03)00241-5,"Forward scattering theorem for elastic longitudinal and shear wave scatterings by an arbitrary-shaped three-dimensional object embedded in a viscoelastic medium is derived. It is shown that the formulae for extinction cross-sections of an object in an energy-absorbing medium are formally the same with those of the object in the lossless elastic medium. Numerical calculations are executed for the longitudinal wave scattering in an epoxy matrix by a spherical inclusion with different material properties. The condition of negative extinction is examined with the causality constraint on the viscoelastic medium taken into account. It is found that the negative extinction occurs in the Rayleigh limit when the attenuation of the medium is sufficiently high and, more restrictedly, the wave speed in the object is larger than that in the medium, while it occurs less likely in the high frequency range considered in this paper (0<ka<100).","Scattering, Forward scattering theorem, Extinction cross-section, Viscoelastic materials",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Scott D,Kanger S,Lambda Calculus and Recursion Theory (Preliminary Version),,1975,82,,154-193,,Elsevier,,Proceedings of the Third Scandinavian Logic Symposium,1975,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08707304;http://dx.doi.org/10.1016/S0049-237X(08)70730-4,10.1016/S0049-237X(08)70730-4,"Publisher Summary This chapter discusses that the connection with recursive functions is not at all like that of the combinatory arithmetic, because the integers are taken as primitive rather than as defined. This is hardly a defect, because the aim is to construct a model out of known objects. Further, what is taken as primitive in the corresponding formal language is a very brief selection of arithmetic notions—just the ones that would naturally present themselves—and the combinators are then used to define everything else. Because no combinator is excluded, the iterators previously used to introduce integers can be studied as well in the present context. Thus, nothing has been lost, but much has been gained, because now the possibility of a real cooperation can be seen between arithmetic (and later set-theoretic) notions and those of the λ-calculus. Because the original program of relative combinatory logic could never be carried out, these connections were never clear before.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Ortin F,Labrador MA,Redondo JM",,A hybrid class- and prototype-based object model to support language-neutral structural intercession,Information and Software Technology,2014,56,2,199-219,,,,,2014,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584913001778;http://dx.doi.org/10.1016/j.infsof.2013.09.002,10.1016/j.infsof.2013.09.002,"Context Dynamic languages have turned out to be suitable for developing specific applications where runtime adaptability is an important issue. Although .Net and Java platforms have gradually incorporated features to improve their support of dynamic languages, they do not provide intercession for every object or class. This limitation is mainly caused by the rigid class-based object model these platforms implement, in contrast to the flexible prototype-based model used by most dynamic languages. Objective Our approach is to provide intercession for any object or class by defining a hybrid class- and prototype-based object model that efficiently incorporates structural intercession into the object model implemented by the widespread .Net and Java platforms. Method In a previous work, we developed and evaluated an extension of a shared-source implementation of the .Net platform. In this work, we define the formal semantics of the proposed reflective model, and modify the existing implementation to include the hybrid model. Finally, we assess its runtime performance and memory consumption, comparing it to existing approaches. Results Our platform shows a competitive runtime performance compared to 9 widespread systems. On average, it performs 73% and 61% better than the second fastest system for short- and long-running applications, respectively. Besides, it is the JIT-compiler approach that consumes less average memory. The proposed approach of including a hybrid object-model into the virtual machine involves a 444% performance improvement (and 65% less memory consumption) compared to the existing alternative of creating an extra software layer (the DLR). When none of the new features are used, our platform requires 12% more execution time and 13% more memory than the original .Net implementation. Conclusion Our proposed hybrid class- and prototype-based object model supports structural intercession for any object or class. It can be included in existing JIT-compiler class-based platforms to support common dynamic languages, providing competitive runtime performance and low memory consumption.","Structural intercession, Duck typing, Prototype-based object model, Reflection, Virtual machine, Dynamic languages",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Riehl E,Verity D",,The 2-category theory of quasi-categories,Advances in Mathematics,2015,280,,549-642,,,,,2015,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870815001577;http://dx.doi.org/10.1016/j.aim.2015.04.021,10.1016/j.aim.2015.04.021,"In this paper we re-develop the foundations of the category theory of quasi-categories (also called ∞-categories) using 2-category theory. We show that Joyal's strict 2-category of quasi-categories admits certain weak 2-limits, among them weak comma objects. We use these comma quasi-categories to encode universal properties relevant to limits, colimits, and adjunctions and prove the expected theorems relating these notions. These universal properties have an alternate form as absolute lifting diagrams in the 2-category, which we show are determined pointwise by the existence of certain initial or terminal vertices, allowing for the easy production of examples. All the quasi-categorical notions introduced here are equivalent to the established ones but our proofs are independent and more “formal”. In particular, these results generalise immediately to model categories enriched over quasi-categories.","Quasi-categories, 2-Category theory, Formal category theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,"dos Santos OM,Dotti FL,Ribeiro L",,Verifying Object-Based Graph Grammars,Electronic Notes in Theoretical Computer Science,2004,109,,125-136,,,,,2004,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104052144;http://dx.doi.org/10.1016/j.entcs.2004.02.061,10.1016/j.entcs.2004.02.061,"Object-Based Graph Grammars (OBGG) is a formal language suitable for the specification of distributed systems. On previous work, a translation from OBGG models to PROMELA (the input language of the SPIN model checker) was defined, enabling the verification of OBGG models using SPIN. This paper builds on these results, where we extend the approach for property specification and define an approach to interpret PROMELA traces as OBGG derivations, generating graphical counter-examples for properties that are not true for an OBGG model.","Graph grammars, model checking, visualization of traces",Proceedings of the Workshop on Graph Transformation and Visual Modelling Techniques (GT-VMT 2004),,,,,,,,,,,,,,,,,,,,
Book Chapter,"Jagger J,Perry N,Sestoft P","Jagger J,Perry N,Sestoft P",11 - Types,,2007,,,159-180,,Morgan Kaufmann,Burlington,Annotated C# Standard,2007,9780123725110,,https://www.sciencedirect.com/science/article/pii/B9780123725110500175;http://dx.doi.org/10.1016/B978-012372511-0.50017-5,10.1016/B978-012372511-0.50017-5,"Publisher Summary Divided into three main categories, the types of the C# language are value types, reference types, and type-parameter types. Type parameters are part of generics, and a fourth category of types, pointers, is available only in unsafe code. Value types differ from reference types as variables of the value types directly contain their data, whereas variables of the reference types store references to their data, the latter being known as objects. With reference types, it is possible for two variables to reference the same object, and thus possible for operations on one variable to affect the object referenced by the other variable. With value types, the variables each have their own copy of the data, and it is not possible for operations on one to affect the other. C#'s type system is unified such that a value of any type can be treated as an object. Every type in C# directly or indirectly derives from the object class type, and object is the ultimate base class of all types. Values of reference types are treated as objects simply by viewing the values as type objects. Values of value types are treated as objects by performing boxing and unboxing operations. A value type is either a struct type or an enumeration type. C# provides a set of predefined struct types called the simple types. The simple types are identified through reserved words. All value types implicitly inherit from class objects. It is not possible for any type to derive from a value type, and value types are thus implicitly sealed.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"ter Hofstede AH,van der Weide TP",,Expressiveness in conceptual data modelling,Data & Knowledge Engineering,1993,10,1,65-100,,,,,1993,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9390020P;http://dx.doi.org/10.1016/0169-023X(93)90020-P,10.1016/0169-023X(93)90020-P,"Conceptual data modelling techniques aim at the representation of data at a high level of abstraction. The Conceptualisation Principle states that only those aspects are to be represented that deal with the meaning of the Universe of Discourse. Conventional conceptual data modelling techniques, as e.g. ER or NIAM, have to violate the Conceptualisation Principle when dealing with objects with a complex structure. In order to represent these objects conceptually irrelevant choices have to be made. It is even worse: sometimes the Universe of Discouse has to be adapted to suit the modelling technique. These objects typically occur in domains as meta-modelling, hypermedia and CAD/CAM. In this paper extensions to an existing data modelling technique (NIAM) will be discussed and formally defined, that make it possible to naturally represent objects with complex structures without having to violate the Conceptualisation Principle. These extensions will be motivated from a practical point of view by examples and from a theoretical point of view by a comparison with the expressive power of formal set theory and grammar theory.","Conceptual data modelling, hypertext, object-role models, ER, NIAM, identification",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Horst J,Messina E,Kramer T,Huang HM",,Precise Definition of Software Component Specifications,IFAC Proceedings Volumes,1997,30,4,145-150,,,,,1997,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017436275;http://dx.doi.org/10.1016/S1474-6670(17)43627-5,10.1016/S1474-6670(17)43627-5,"A set of generic specification categories is presented which can be used to comprehensively define any software component within a certain class. With these categories as a template, a specific set of formal specifications can be generated for each component. Specifications for a particular component (an algorithm that estimates the position and orientation of a physical object using visual sensing) have been defined in EXPRESS, an information modeling language. A few example natural language specifications are presented for this particular component.","Components, Computer vision, Formal languages, Formal specification, Software engineering, Software metrics, Software performance, Software specification, Software tools","7th IFAC Symposium on Computer Aided Control Systems Design (CACSD '97), Gent, Belgium, 28-30 April",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Lirola AG,Fournón y Gonzalez-Barcia F,Molinero FG","Boullart L,de La Puente JA",Application of Formal Description Techniques to Real-Time Scheduling,,1992,,,253-258,,Pergamon,Oxford,Real-Time Programming 1992,1992,9780080418940,,https://www.sciencedirect.com/science/article/pii/B9780080418940500459;http://dx.doi.org/10.1016/B978-0-08-041894-0.50045-9,10.1016/B978-0-08-041894-0.50045-9,"In this paper we describe a study about the applicability of Formal Description Techniques like LOTOS to analyse and validate real-time subsystems. The Basic Priority Inheritance scheduling algorithm has been specified using the Formal Description Technique LOTOS. With the help of the specification, validation tests have been derived and applied to an independent VLSI implementation of the mentioned algorithm embedded in an Ada tasking co-processor. With this experience it has been shown that Formal Description Technique LOTOS can be applied to specify real-time subsystems and therefore to develop and validate them.",,,IFAC Postprint Volume,,,,,,,,,,,,,,,,,,,
Journal Article,"Schellnhuber HJ,Seyler A",,Fractional differentiation of devil's staircases,Physica A: Statistical Mechanics and its Applications,1992,191,1,491-500,,,,,1992,,0378-4371,https://www.sciencedirect.com/science/article/pii/0378437192905739;http://dx.doi.org/10.1016/0378-4371(92)90573-9,10.1016/0378-4371(92)90573-9,"Modern nonlinear dynamics abounds in mathematical objects with bizarre shapes and properties. It is argued that fractional calculus provides powerful tools for the description of such “monstrosities”. The application of generalized differintegration to devil's staircases is discussed in detail. On the basis of these results, an extension of the conventional classification scheme for phase transitions, introducing fractional order, is proposed.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jung H,Wiltse H,Wiberg M,Stolterman E",,"Metaphors, materialities, and affordances: Hybrid morphologies in the design of interactive artifacts",Design Studies,2017,53,,24-46,,,,,2017,,0142-694X,https://www.sciencedirect.com/science/article/pii/S0142694X17300467;http://dx.doi.org/10.1016/j.destud.2017.06.004,10.1016/j.destud.2017.06.004,"As materiality of interactive artifacts is diversified with integrated physical and digital materials, metaphoric design approaches in Human–Computer Interaction (HCI) go beyond resembling the appearance of physical objects, exploring novel materials and forms of interactive artifacts. The hybrid materialities and forms of artifacts influence how interactivity is perceived, reframing the concept of affordances according to its evolving relationship to metaphors and materialities. By conceptualizing interactive forms in their surface, behavioral and systemic aspects, we examine multifaceted roles of metaphors in HCI from concealing and revealing a formal system to expanding and reifying its meaning; and propose a morphologic perspective on affordances as an invitation for making variations of interactive forms by compositing multiple design resources.","design rationale, design theory, interaction design, interface design, materialities",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jörg B,Waddington S,Jones R,Trowell S",,Harmonising Research Reporting in the UK – Experiences and Outputs from UKRISS,Procedia Computer Science,2014,33,,207-214,,,,,2014,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050914008242;http://dx.doi.org/10.1016/j.procs.2014.06.034,10.1016/j.procs.2014.06.034,"The Jisc-funded UK Research Information Shared Service (UKRISS) project investigated the reporting of research information across the UK HE sector and assessed the feasibility of a national infrastructure based on CERIF with the objective of increasing the efficiency, productivity and reporting quality across the sector. A core reporting profile was developed that would enable harmonised reporting on RCUK-funded research, taking into account the HE-BCI survey as well as REF reporting elements. In this paper we describe the UKRISS modelling approach and provide some insight into the UKRISS reporting objects to support understanding of their formal CERIF representations, i.e. the selection of underlying CERIF entities; the challenges with managing objects and aggregations in CERIF. Example data extracts demonstrate the work.","UKRISS, CERIF, Research Reporting, Standardisation, Research Results","12th International Conference on Current Research Information Systems, CRIS 2014",,,,,,,,,,,,,,,,,,,,
Journal Article,"Harrison-Trainor M,Holliday WH,Icard TF",,Inferring probability comparisons,Mathematical Social Sciences,2018,91,,62-70,,,,,2018,,0165-4896,https://www.sciencedirect.com/science/article/pii/S0165489617301154;http://dx.doi.org/10.1016/j.mathsocsci.2017.08.003,10.1016/j.mathsocsci.2017.08.003,"The problem of inferring probability comparisons between events from an initial set of comparisons arises in several contexts, ranging from decision theory to artificial intelligence to formal semantics. In this paper, we treat the problem as follows: beginning with a binary relation ≿ on events that does not preclude a probabilistic interpretation, in the sense that ≿ has extensions that are probabilistically representable, we characterize the extension ≿+ of ≿ that is exactly the intersection of all probabilistically representable extensions of ≿. This extension ≿+ gives us all the additional comparisons that we are entitled to infer from ≿, based on the assumption that there is some probability measure of which ≿ gives us partial qualitative information. We pay special attention to the problem of extending an order on states to an order on events. In addition to the probabilistic interpretation, this problem has a more general interpretation involving measurement of any additive quantity: e.g., given comparisons between the weights of individual objects, what comparisons between the weights of groups of objects can we infer?","Qualitative probability, Comparative probability, Imprecise representability, Sets of probability measures, Additive measurement",,,,,,,,,,,,,,,,,,,,,
Journal Article,Gottfried B,,The systematic design of visual languages applied to logical reasoning,Journal of Visual Languages & Computing,2015,28,,212-225,,,,,2015,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X15000063;http://dx.doi.org/10.1016/j.jvlc.2015.02.001,10.1016/j.jvlc.2015.02.001,"Visual languages are distinguished by a number of graphical objects and their relations, usually arranged in the two-dimensional plane. While objects and relations are syntactical containers which are used to represent some information, the question arises how to systematically treat all possible syntactical containers given the richness and complexity of the underlying geometry. This paper adopts the intersection paradigm applied in the context of spatial reasoning, which ensures the systematic identification of all conceivable well-formed diagrams. This allows the exhaustive analysis of a visual language. As an example, it is shown how this method enables a thorough understanding of the relations of the graphical elements of linear diagrams which represent monadic first-order logic. The consideration of indeterminate sets even demonstrates the effectiveness of this approach for a representation that includes a total of 512 relations.","Visual languages, Diagrammatic representations, Linear diagrams, Set space diagrams, First-order logic, Spatial reasoning, Intersection calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee SU,Sun J,Dobbie G,Li YF",,A Z Approach in Validating ORA-SS Data Models,Electronic Notes in Theoretical Computer Science,2006,157,1,95-109,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106002374;http://dx.doi.org/10.1016/j.entcs.2006.01.025,10.1016/j.entcs.2006.01.025,"The rapid growth of the World Wide Web has resulted in more data being accessed over the Internet. In turn there is an increase in the use of semistructured data, which plays a crucial role in many web applications particularly with the introduction of XML and its related technologies. This increase in use makes the design of good semistructured data structures essential. The Object Relationship Attribute model for Semistructured data (ORA-SS) is a graphical notation for designing and representing semistructured data. In this paper, we demonstrate an approach to formally validate the ORA-SS data models in order to enhance the correctness of semistructured data design. A mathematical semantics for the ORA-SS notation is defined using the Z formal language, and further validation processes are carried out to check the correctness of the semistructured data models at both the schema and instance levels.","Semistructured data, ORA-SS data model, Formal specification and verification, Z specification language",Proceedings of the Third International Workshop on Software Verification and Validation (SVV 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,Koch A,,Monogenic Hopf algebras over discrete valuation rings with low ramification,Journal of Algebra,2005,286,2,405-420,,,,,2005,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869305000359;http://dx.doi.org/10.1016/j.jalgebra.2004.12.019,10.1016/j.jalgebra.2004.12.019,"Let K be an extension of Qp with absolute ramification index 1<e⩽p−1. Let R=OK and let k be the residue field of R. We show that any monogenic finite abelian local Hopf algebra with local dual lifts to R, and we construct all such lifts. For H an R-Hopf algebra arising from one of these lifts, we realize SpecH as the kernel of an isogeny of one-dimensional formal groups. We then obtain a complete list of fields L for which L/K is an H⊗K-Galois object.","Hopf algebra, Formal group, Ramified extension",,,,,,,,,,,,,,,,,,,,,
Journal Article,Arigoni AO,,Elementarity in Describing Formal Properties for the Classification of Objects,IFAC Proceedings Volumes,1983,16,13,191-196,,,,,1983,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017620317;http://dx.doi.org/10.1016/S1474-6670(17)62031-7,10.1016/S1474-6670(17)62031-7,"In this paper, semiotic interations among descriptions of formal properties are analyzed. The main result is showing the possibility of attaining to at least one elementary form in describing, formally, any given property. Elementarity required for measuring the degree of presence, in specific objects, of simple properties which can be inferred on the basis of empirically ascertainable composite properties in the objects themselves.","- Elementarily, formal properties, classification, measure of significativity","IFAC Symposium on Fuzzy Information, Knowledge Representation and Decision Analysis, Marseille, France, 19-21 July, 1983",,,,,,,,,,,,,,,,,,,,
Journal Article,"Bryant T,Evans A",,Formalizing the Object Management Group's Core Object Model,Computer Standards & Interfaces,1995,17,5,481-489,,,,,1995,,0920-5489,https://www.sciencedirect.com/science/article/pii/092054899500018P;http://dx.doi.org/10.1016/0920-5489(95)00018-P,10.1016/0920-5489(95)00018-P,"Standards come in many different forms, to fulfil many different purposes. In general, however, in a fast changing field, a standard — whether de facto or de jure — emerges and survives if it offers some basis for effective but constrained development, reducing uncertainty and risk [1]. In the field of Object Orientation (hereafter OO) the OMG has sought to control change and variety through numerous standard-like and other consensus building activities. This has proved difficult, given the time needed to establish consensus, and the immediate and pressing demands of the market. The idea of a conceptual core model was proposed early on in OO development, and OMG have sought to establish it at the heart of its programme and perspective. In recent years, however, the development of models such as CORBA, and a host of other extensions have far outstripped the original core. Rather than jettisoning the core object model, the OMG Object Model Subcommittee is now seeking a revision and more rigorous restatement of the key concepts in order that future OO innovations and extensions can be inter-related and reconciled through an agreed and unambiguous standard. Our paper establishes the background to this project, and explains the rationale and benefits of this use of formal notations in standardization.","Formal notations, Methods integration, Object orientation, Standards",Formal Description Techniques,,,,,,,,,,,,,,,,,,,,
Journal Article,Wang RJ,,Non-circular proofs and proof realization in modal logic,Annals of Pure and Applied Logic,2014,165,7,1318-1338,,,,,2014,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007214000359;http://dx.doi.org/10.1016/j.apal.2014.04.004,10.1016/j.apal.2014.04.004,"In this paper a complete proper subclass of Hilbert-style S4 proofs, named non-circular, will be determined. This study originates from an investigation into the formal connection between S4, as Logic of Provability and Logic of Knowledge, and Artemov's innovative Logic of Proofs, LP, which later developed into Logic of Justification. The main result concerning the formal connection is the realization theorem, which states that S4 theorems are precisely the formulas which can be converted to LP theorems with proper justificational objects substituting for modal knowledge operators. We extend this result by showing that on the proof level, non-circular proofs are exactly the class of S4 proofs which can be realized to LP proofs. In turn, this study provides an alternative algorithm to achieve the realization theorem, and a novel logical system, called S4Δ, is introduced, which, under an adequate interpretation, is worth studying for its own sake.","Justification logic, Timed modal epistemic logic, Modal logic, Realization theorem, Hilbert-style proofs",,,,,,,,,,,,,,,,,,,,,
Journal Article,Miller D,,Encoding Generic Judgments: Preliminary results,Electronic Notes in Theoretical Computer Science,2001,58,1,59-78,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104002798;http://dx.doi.org/10.1016/S1571-0661(04)00279-8,10.1016/S1571-0661(04)00279-8,"Operational semantics is often presented in a rather syntactic fashion using relations specified by inference rules or equivalently by clauses in a suitable logic programming language. As it is well known, various syntactic details of specifications involving bound variables can be greatly simplified if that logic programming language has term-level abstractions (λ-abstraction) and proof-level abstractions (eigenvariables) and the specification encodes object-level binders using λ-terms and universal quantification. We shall attempt to extend this specification setting to include the problem of specifying not only relations capturing operational semantics, such as one-step evaluation, but also properties and relations about the semantics, such as simulation. Central to our approach is the encoding of generic object-level judgments (universally quantified formulas) as suitable atomic meta-level judgments. We shall encode both the one-step transition semantics and simulation of (finite) π-calculus to illustrate our approach.",,MERLIN 2001: Mechanized Reasoning about Languages with Variable Binding (in connection with IJCAR 2001),,,,,,,,,,,,,,,,,,,,
Journal Article,"Basov N,Kholodova D",,Networks of context: Three-layer socio-cultural mapping for a Verstehende network analysis,Social Networks,2021,,,,,,,,2021,,0378-8733,https://www.sciencedirect.com/science/article/pii/S0378873321000253;http://dx.doi.org/10.1016/j.socnet.2021.03.003,10.1016/j.socnet.2021.03.003,"What social ties are and how they operate depends on the cultural context constitutive of their meaning. Pursuing an explanatory account for the cultural embeddedness of social ties, we draw on Verstehende sociology and rely on in-depth insight into subjective perceptions developed by social network actors throughout their practice to represent symbolic and material contexts of social ties structurally. We put forward a new mixed data collection and processing approach that ethnographically maps interconnected three-layer socio-cultural networks of individuals, signs, and material objects. Opening cultural contexts to application of formal and statistical techniques, this approach allows for an 'interpretive explanation' of social ties. Illustrating the approach with our own longitudinal study of five European art groups, we discuss the peculiarities of three-layer socio-cultural data collection and processing, the new discoveries enabled, the challenges encountered, the solutions we came up with, and the utility of this approach for conducting 'Verstehende network analysis' in various fields of application.","network analysis, Three-layer socio-cultural network, Network data, Mixed method, Cultural context",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Antonescu P,Vasiliu LA,Antonescu O",,Model of a Biomechanism for Five-Finger Hand,IFAC Proceedings Volumes,1995,28,24,245-250,,,,,1995,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017465578;http://dx.doi.org/10.1016/S1474-6670(17)46557-8,10.1016/S1474-6670(17)46557-8,"In the present work is analyzed the five-finger biomechanism resembling in its structure, operation and aesthetic aspect to the human. hand. The fingers articulations are equated to revolute pairs, keeping the same orientation of the rotation axis, as in the case of the human model. The operating system is the same for all the five fingers, by tendon-cable following as real as possible the natural model of the hand. The operation at the hand opening is performed by a tendon settled at the outer part of the finger and with three tendons settled at its inner part. There is presented a calculus algorithm of the forces in tendons which are necessary for an object having a cylindrical form and a given mass. As the body, having a weight G, is considered to be grasped with all the five fingers, is introduced a coefficient k. representing the share of each finger at the total effort of prehension. As an example of calculus where was considered the thumb-middle finger and the thumb-opposable for which the numerical geometric-mechanical parameters were considered.","biomechanism, grasping/orientation mechanism, driving system, friction/loading coefficient, actuator, dynamic calculus, adherence, reaction, static equilibrium","3rd IFAC/IFIP/IFORS Workshop on Intelligent Manufacturing Systems 1995 (IMS '95), Bucharest, Romania, 24-26 October",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Osis J,Donins U","Osis J,Donins U",Chapter 9 - Object State Change and Transition Analysis,,2017,,,225-231,,Elsevier,Boston,Topological UML Modeling,2017,9780128054765,,https://www.sciencedirect.com/science/article/pii/B9780128054765000095;http://dx.doi.org/10.1016/B978-0-12-805476-5.00009-5,10.1016/B978-0-12-805476-5.00009-5,"Object state change and transition analysis is an activity within Topological UML modeling process following structure analysis and design activity. It is based on the state diagram development. Event-driven software systems continuously wait for occurrence of some external or internal events. When such event is received and recognized, the system reacts by performing corresponding computations which may include generation of events that trigger computation in other components. The response to the received event depends on the current state of the system and underlying objects and can include a change of state leading to a state transition. The state changes and transitions within a system are formally analyzed by using Topological Functioning Model (TFM). It captures system functioning specification in the form of topological space consisting of functional features and cause-and-effect relationships among them and is represented in a form of directed graph. The functional features together with topological relationships contain the necessary information to create state diagram which reflects the state changes within system.","Object state change, object state transition, state diagram",,Computer Science Reviews and Trends,,,,,,,,,,,,,,,,,,,
Journal Article,"Pothos EM,Trueblood JS",,Structured representations in a quantum probability model of similarity,Journal of Mathematical Psychology,2015,64-65,,35-43,,,,,2015,,0022-2496,https://www.sciencedirect.com/science/article/pii/S0022249614000832;http://dx.doi.org/10.1016/j.jmp.2014.12.001,10.1016/j.jmp.2014.12.001,"Recently, Busemeyer et al. (2011) presented a model for how the conjunction fallacy (Tversky & Kahneman, 1983) emerges, based on the principles of quantum probability (QP) theory. Pothos et al. (2013) extended this model to account for the main similarity findings of Tversky (1977), which have served as a golden standard for testing novel theories of similarity. However, Tversky’s (1977) empirical findings did not address the now established insight that, in comparing two objects, overlap in matching parts of the objects tends to have a greater impact on their similarity, than overlap in non-matching parts. We show how the QP similarity model can be directly extended to accommodate structure in similarity comparisons. Smolensky’s et al.’s (2014) proposal for modeling structure in linguistic representations, with tensor products, can be adapted ‘as is’ with the QP similarity model. The formal properties of the extended QP similarity model are analyzed, some indicative fits are presented, and, finally, a novel prediction is developed.","Quantum probability theory, Similarity, Representation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Watanabe S,"Mayer-Wolf E,Merzbach E,Shwartz A",Donsker's δ-functions in the Malliavin calculus,,1991,,,495-502,,Academic Press,,Stochastic Analysis,1991,9780124810051,,https://www.sciencedirect.com/science/article/pii/B9780124810051500326;http://dx.doi.org/10.1016/B978-0-12-481005-1.50032-6,10.1016/B978-0-12-481005-1.50032-6,"Publisher Summary This chapter presents Donsker's δ-functions in the Malliavin calculus. Dirac δ-function is a well-defined mathematical object in the Schwartz theory of distributions. The chapter discusses a satisfactory disintegration theory on the foliation of submanifolds imbedded in the Wiener space and describes the exact Sobolev spaces, to which Donsker's δ-functions belong. It reviews notions and results in the Malliavin calculus relevant to Donsker's δ-functions.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Peleg M,Boxwala AA,Bernstam E,Tu S,Greenes RA,Shortliffe EH",,Sharable Representation of Clinical Guidelines in GLIF: Relationship to the Arden Syntax,Journal of Biomedical Informatics,2001,34,3,170-181,,,,,2001,,1532-0464,https://www.sciencedirect.com/science/article/pii/S1532046401910160;http://dx.doi.org/10.1006/jbin.2001.1016,10.1006/jbin.2001.1016,"Clinical guidelines are intended to improve the quality and cost effectiveness of patient care. Integration of guidelines into electronic medical records and order-entry systems, in a way that enables delivery of patient-specific advice at the point of care, is likely to encourage guideline acceptance and effectiveness. Among the methodologies for modeling guidelines and medical decision rules, the Arden Syntax for Medical Logic Modules and the GuideLine Interchange Format version 3 (GLIF3) emphasize the importance of sharing encoded logic across different medical institutions and implementation platforms. These two methodologies have similarities and differences; in this paper we clarify their roles. Both methods can be used to support sharing of medical knowledge, but they do so in complementary situations. The Arden Syntax is suitable for representing individual decision rules in self-contained units called Medical Logic Modules (MLMs), which are usually implemented as event-driven alerts or reminders. In contrast, GLIF3 is designed for encoding complex multistep guidelines that unfold over time. As a consequence, GLIF3 has several mechanisms for complexity management and additional constructs that may require overhead unnecessary for expressing simple alerts and reminders. Unlike the Arden Syntax, GLIF3 encourages a top-down process of guideline modeling consisting of three levels that are created in order: Level 1 comprises a human-readable flowchart of clinical decisions and actions. Level 2 comprises a computable specification that can be verified for logical consistency and completeness; and Level 3 comprises an implementable specification that includes information required for local adaptation of guideline logic as well as for mapping guideline variables onto institutional medical records. A major emphasis of the current GLIF3 development process has been to create the computable specification that formally represents medical decision and eligibility criteria. We based GLIF3's formal expression language on the Arden Syntax's logic grammar, making the necessary extensions to the Arden Syntax's data structures and operators to support GLIF3's object-oriented data model. We discuss why the process of generating a set of MLMs from a GLIF-encoded guideline cannot be automated, why it can result in information loss, and why simple medical rules are best represented as individual MLMs. We thus show that the Arden Syntax and GLIF3 play complementary roles in representing medical knowledge for clinical decision support.","GLIF, Arden Syntax, clinical guidelines, computer-interpretable guidelines, knowledge representation.",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Palamidessi C,Parrow J",,Foreword: Volume 7,Electronic Notes in Theoretical Computer Science,1997,7,,1-2,,,,,1997,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580461X;http://dx.doi.org/10.1016/S1571-0661(05)80461-X,10.1016/S1571-0661(05)80461-X,"One of the main research objectives of computer science is the development of formal methods for the design and implementation of concurrent programming languages. A most prominent feature of this research area is the proliferation of programming concepts arising from imperative programming, logic programming, functional programming, object-oriented programming, constraint programming, and the various formalizations thereof. The Human Capital and Mobility project EXPRESS has aimed at a general understanding of the interconnections and relations between formal systems for concurrency, ranging from programming languages to axiom systems and rewrite systems. More specifically, we have compared programming concepts and formalisms on the basis of their relative expressive power. The results obtained in our project are steps towards classifying the variety of concurrent programming languages, and may provide a formal basis for their design and implementation. The partners of EXPRESS have been the CWI (Amsterdam), the University of Utrecht, the University of Florence, the University of Aalborg, the University of Nijmegen, the Swedish Institute of Computer Science, the University of Genoa, the University of Rome “La Sapienza”, the University of Hildesheim, the University of Amsterdam, INRIA Sophia Antipolis, INRIA Rennes, and the University of Sussex. External partners associated to the project were the State University of New York at Stony Brook, the University at Cornell (USA), the Weizmann Institute (Israel) and the McGill University (Canada). The project ran for four years 1993-1997. Each year the project partners met at a workshop, disseminating the latest results. The last of these, EXPRESS'97 at Santa Margherita Ligure, Italy, 8-12 September 1997, was also open to the scientific community. Apart from the ordinary EXPRESS presentations we had a general call for papers from outside the project. Among the submissions we selected 13 papers from presentation, which are collected in these proceedings. Additionally we had 7 invited speakers: Ralph Back, Jean-Jacques Levy, Eugenio Moggi, Ugo Montanari, Amir Pnueli, Vaughan Pratt, and Colin Stirling. Some of the invited speakers also offered a contribution to the proceedings. We would like to thank the EXPRESS members, the invited speakers, the authors of the submitted papers, and the members of the program committee for their contribution to both the meeting and this volume. We also would like to thank Elisabetta Ferrando for help with the local organization and Michael Mislove for editorial help with the proceedings. Catuscia Palamidessi, University of Genova, Italy Joachim Parrow, Royal Institute of Technology, Stockholm, Sweden EXPRESS'97 Programme Committee Luca Aceto (Aalborg) Eike Best (Oldenburg) Frank de Boer (Utrecht) Ilaria Castellani (Sophia Antipolis) Philippe Darondeau (Rennes) Rocco De Nicola (Florence) Ursula Goltz (Hildesheim) Jan Willem Klop (CWI) Catuscia Palamidessi (co-chair)(Genoa) Joachim Parrow (co-chair)(Stockholm) Frits Vaandrager (Nijmegen)",,EXPRESS'97,,,,,,,,,,,,,,,,,,,,
Journal Article,Padgham L,,Defeasible inheritance: A lattice based approach,Computers & Mathematics with Applications,1992,23,6,527-541,,,,,1992,,0898-1221,https://www.sciencedirect.com/science/article/pii/089812219290122X;http://dx.doi.org/10.1016/0898-1221(92)90122-X,10.1016/0898-1221(92)90122-X,"We describe here a model for inheritance reasoning based on the notion that a type can be described by two basic sets of characteristics—those that are necessary for the type and those that are typical for the type. All possible combinations of characteristics form a boolean lattice in which type descriptors can be placed relative to one another. Common lattice properties (such as transitivity of ]) combined with a default assumption operation form the basis for a theory of defeasible reasoning in inheritance networks. This paper gives a careful, but informal overview of the model, with several examples and many diagrams. For a more formal treatment, the interested reader is referred to the final chapters of [1]. The model allows a natural representation and a clean reasoning mechanism, at the same time as it adequately captures many of our intuitions regarding conclusions. It is also able to express some interesting nuances which are not available in other theories.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Meng Y,Huang Z,Shen G,Ke C",,A security policy model transformation and verification approach for software defined networking,Computers & Security,2021,100,,102089,,,,,2021,,0167-4048,https://www.sciencedirect.com/science/article/pii/S016740482030362X;http://dx.doi.org/10.1016/j.cose.2020.102089,10.1016/j.cose.2020.102089,"Software-defined networking (SDN) has been increasingly utilized to enforce the security of complex networks. However SDN-based security enforcement mechanisms rely heavily on some specific security policies containing underlying network information. Facing the increasingly complex and huge SDN networks, we urgently need a novel security policy management mechanism which can be completely transparent to any underlying network information. That is it can permit network managers to define the high-level security policy model without containing any underlying information, and by means of model transformation, high-level security policy model can be automatically transformed into its corresponding lower-level security policy model containing underlying information. Moreover, we must ensure the system model of data plane updated by the low-level security policy model can hold all of security properties defined in high-level security policy model. Based on these insights, we propose a security policy model transformation and verification approach for SDN in this paper. We first specify the security policies used in SDN networks as a formal security policy model (SPM). Then we establish the system model of SDN’s data plane and the mapping rules between the policy objects of SPM and the system objects of system model of data plane. Based on these mapping rules, we propose a security policy model transformation mechanism which transforms SPM into the low-level security policy model, RSPM. In order to verify the system model of data plane updated by RSPM can hold all of security properties defined in SPM, we propose a security policy verification mechanism based on model checking techniques and a group of validation conditions. Finally, we utilize a comprehensive case to illustrate the feasibility of this approach.","SDN, Security policy model, Model transformation, Security policy verification, Model checking",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Alejandra Segura N,Salvador-Sánchez,García-Barriocanal E,Prieto M",,An empirical analysis of ontology-based query expansion for learning resource searches using MERLOT and the Gene ontology,Knowledge-Based Systems,2011,24,1,119-133,,,,,2011,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705110001267;http://dx.doi.org/10.1016/j.knosys.2010.07.012,10.1016/j.knosys.2010.07.012,"This paper proposes an expansion of queries based on formal domain ontologies in the context of the search for learning resources in repositories. The expansion process uses the relation types that are represented in these models; common ontological relations, and ontological relations specific to domain and traditional terminology relations, typical of thesauri. The tests were conducted using Gene ontology as the knowledge base and MERLOT is used as the test repository. The results of this study case indicate that, at similar levels of precision, expanded queries improve levels of novelty and coverage compared to the original query (without expansion), i.e. expanded queries allow the user to retrieve relevant objects, which might not be obtained without expansion.","Query expansion, Ontology, Learning object, Repositories, e-Learning, Learning resources",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Feng L,Soon SH,Tsui LY",,Structure modeling and context-free grammar: Exploring a new approach for surface boundary construction,Computers & Graphics,1997,21,6,777-785,,,,,1997,,0097-8493,https://www.sciencedirect.com/science/article/pii/S0097849397000575;http://dx.doi.org/10.1016/S0097-8493(97)00057-5,10.1016/S0097-8493(97)00057-5,"The geometry of an object is formed by its surface boundary over a topological structure. In a companion paper we proposed a deformable volume model in conjunction with an isosurface evaluation in a new approach to surface boundary construction. This paper further discusses the new approach, concentrating on modeling the topological structure of objects. We propose a formal method to describe the topology of objects using a Context-Free Grammar Gpd. Such topology descriptions can be interpreted by a Push-Down Automaton Mtg to generate template objects with the desired topological structures. The template objects will be refined to match the geometry of actual objects.",,Graphics in Electronic Printing and Publishing,,,,,,,,,,,,,,,,,,,,
Journal Article,Kharchenko VK,,Constants of coordinate differential calculi defined by Yang–Baxter operators,Journal of Algebra,2003,267,1,96-129,,,,,2003,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869303003375;http://dx.doi.org/10.1016/S0021-8693(03)00337-5,10.1016/S0021-8693(03)00337-5,"We investigate in details a first order differential calculus with right partial derivatives set up by a not necessarily invertible Yang–Baxter operator. The optimal algebra for this calculus has a natural structure of a braided Hopf algebra and it is isomorphic to the quantum symmetric algebra. The induced to the optimal algebra and to the free cover algebra calculi are right covariant. They are bicovariant if and only if the related braiding is involutive. By means of the P.M. Cohn theory we show that the subalgebra of constants for the cover free differential algebra is a free algebra and an ad-invariant left coideal. If the given algebra is finitely generated then every differential left ideal is generated by constants, a noncommutative Taylor series decomposition formula is valid, and the category of locally nilpotent modules over the operator algebra is semisimple with the only simple object that is isomorphic to the optimal algebra as a module. We find a necessary and sufficient condition for a 1-form to be a complete differential.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Baugh JW,,Using formal methods to specify the functional properties of engineering software,Computers & Structures,1992,45,3,557-570,,,,,1992,,0045-7949,https://www.sciencedirect.com/science/article/pii/004579499290440B;http://dx.doi.org/10.1016/0045-7949(92)90440-B,10.1016/0045-7949(92)90440-B,"This paper describes the use of formal methods in specifying the functional properties of engineering software components, an approach that enables one to deal more effectively with the complexities of large-scale engineering software systems. Because they are formal objects, these specifications can be manipulated using ordinary mathematics, validated with respect to formal requirements, and shown to satisfy properties such as consistency and completeness. In addition, their concise and unambiguous nature makes them suitable for both communication and commentary, which are not possible with substantial program texts. We present detailed examples of formally defined abstract data types, and discuss the role and potential benefits of formal specifications in engineering program design.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Boiten E,Bowman H,Derrick J,Linington P,Steen M",,Viewpoint consistency in ODP,Computer Networks,2000,34,3,503-537,,,,,2000,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128600001146;http://dx.doi.org/10.1016/S1389-1286(00)00114-6,10.1016/S1389-1286(00)00114-6,"Open Distributed Processing (ODP) is a joint ITU/ISO standardisation framework for constructing distributed systems in a multi-vendor environment. Central to the ODP approach is the use of viewpoints for specification and design. Inherent in any viewpoint approach is the need to check and manage the consistency of viewpoints. In previous work we have described techniques for consistency checking, refinement, and translation between viewpoint specifications, in particular for LOTOS and Z/Object-Z. Here we present an overview of our work, motivated by a case study combining these techniques in order to show consistency between viewpoints specified in LOTOS and Object-Z.","Open Distributed Processing, Viewpoint consistency, Formal methods, Object-Z, LOTOS",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Anantaram C,Nagaraja G,Nori KV",,Verification of accuracy of rules in a rule based system,Data & Knowledge Engineering,1998,27,2,115-138,,,,,1998,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X98000093;http://dx.doi.org/10.1016/S0169-023X(98)00009-3,10.1016/S0169-023X(98)00009-3,"Verification of Rule Based Systems has largely concentrated on checking the consistency, conciseness and completeness of the rulebase. However, the accuracy of rules vis-à-vis the knowledge that they represent, is not addressed, with the result that a large amount of testing has to be done to validate the system. For any reasonably-sized rulebase it becomes difficult to know the adequacy and completeness of the test-cases. In case a particular test-case is omitted the chances of an inaccurate rule remaining undetected increases. We discuss this issue and define a notion of accuracy of rules. We take the view that a rule represents a concept of the domain and in the scenario of Formal Concept Analysis, works on objects and attribute-value space. We then present a mechanism to measure the level of accuracy using the Rough Set Theory. In this framework, accuracy can be computed as a ratio of the objects definitely selected by the rule (the lower approximation) to the objects possibly selected by the rule (the upper approximation) with respect to the concept that it encodes. Our algorithm and its implementation for PROLOG clauses is discussed.","Verification, Rule based system, Accuracy of rules, Formal concept analysis, Rough sets",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee M,Cho W,Kim S,Park S,Kim JH",,Segmentation of interest region in medical volume images using geometric deformable model,Computers in Biology and Medicine,2012,42,5,523-537,,,,,2012,,0010-4825,https://www.sciencedirect.com/science/article/pii/S0010482512000169;http://dx.doi.org/10.1016/j.compbiomed.2012.01.005,10.1016/j.compbiomed.2012.01.005,"In this paper, we present a new segmentation method using the level set framework for medical volume images. The method was implemented using the surface evolution principle based on the geometric deformable model and the level set theory. And, the speed function in the level set approach consists of a hybrid combination of three integral measures derived from the calculus of variation principle. The terms are defined as robust alignment, active region, and smoothing. These terms can help to obtain the precise surface of the target object and prevent the boundary leakage problem. The proposed method has been tested on synthetic and various medical volume images with normal tissue and tumor regions in order to evaluate its performance on visual and quantitative data. The quantitative validation of the proposed segmentation is shown with higher Jaccard's measure score (72.52%–94.17%) and lower Hausdorff distance (1.2654mm–3.1527mm) than the other methods such as mean speed (67.67%–93.36% and 1.3361mm–3.4463mm), mean-variance speed (63.44%–94.72% and 1.3361mm–3.4616mm), and edge-based speed (0.76%–42.44% and 3.8010mm–6.5389mm). The experimental results confirm that the effectiveness and performance of our method is excellent compared with traditional approaches.","Medical volume images segmentation, Geometric deformable model, Calculus of variation principle, Level set method, Hybrid speed function",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ray I,Kumar M",,Towards a location-based mandatory access control model,Computers & Security,2006,25,1,36-44,,,,,2006,,0167-4048,https://www.sciencedirect.com/science/article/pii/S016740480500101X;http://dx.doi.org/10.1016/j.cose.2005.06.007,10.1016/j.cose.2005.06.007,"With the growing use of wireless networks and mobile devices, we are moving towards an era where location information will be necessary for access control. The use of location information can be used for enhancing the security of an application, and it can also be exploited to launch attacks. For critical applications, such as the military, a formal model for location-based access control is needed that increases the security of the application and ensures that the location information cannot be exploited to cause harm. In this paper, we show how the mandatory access control (MAC) model can be extended to incorporate the notion of location. We also show how the different components in the MAC model are related with location and how this location information can be used to determine whether a subject has access to a given object. This model is suitable for military applications consisting of static and dynamic objects, where location of a subject and object must be considered before granting access.","Access control, Bell-Lapadula model",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mendizabal OM,Dotti FL,Ribeiro L",,Stochastic Object-Based Graph Grammars,Electronic Notes in Theoretical Computer Science,2007,184,,151-170,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107004409;http://dx.doi.org/10.1016/j.entcs.2007.03.020,10.1016/j.entcs.2007.03.020,"Object-Based Graph Grammar (OBGG) is a formal visual language suited to the specification of asynchronous distributed systems based on message passing. Model-checking of OBGG models is currently supported and a series of case studies have been developed. However, in many situations one has to evaluate non-functional aspects like availability and performance of the system under consideration. In such cases, a stochastic analysis of the system is desired. This paper is a first contribution to the stochastic analysis of OBGG models. OBGG models with occurrence rates associated to rules are translated to Stochastic Automata Networks (SAN). SAN is a Markov Chain equivalent formalism having as advantage its modularity in terms of representation and a compact mathematical solution, allowing the analysis of models with larger state space.","Object-based graph grammar, asynchronous system, Stochastics Automata Network",Proceedings of the Second Brazilian Symposium on Formal Methods (SBMF 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Krinitskiy M,Grashchenkov K,Tilinina N,Gulev S",,Tracking of atmospheric phenomena with artificial neural networks: a supervised approach,Procedia Computer Science,2021,186,,403-410,,,,,2021,,1877-0509,https://www.sciencedirect.com/science/article/pii/S187705092101053X;http://dx.doi.org/10.1016/j.procs.2021.04.209,10.1016/j.procs.2021.04.209,"Tracking of atmospheric phenomena, such as Tropical Cyclones (TC) and Polar Mesocyclones (PMC), — is a frequently performed task in the climate sciences. It is a crucial part of any climatic or short-period study since the occurrence and characteristics of a phenomenon at some moment carries significantly less information compared to its evolution. In some cases of synoptic-scale phenomena, this problem has established well-developed solutions (e.g., for extratropical cyclones, ETC). However, in the majority of other cases, there are no reliable tracking algorithms at the moment. In this study, we present the generic framework for the tracking of atmospheric phenomena of an arbitrary kind in the source data of nearly arbitrary origin. The core entity of our approach is the function of dissimilarity of representations of a phenomenon in two subsequent data frames which is learned under supervision of an artificial neural network. As an implementation of the proposed approach, we present the results of the tracking of Tropical Cyclones and Polar Mesocyclones. We demonstrate the success of our approach in terms of formal metric MOTA (Multiple Object Tracking Accuracy) and the empirical distributions of key lifecycle characteristics of TC and PMC.","Artificial neural networks, Atmospheric phenomena tracking, Deep Learning, Polar Mesocyclones, Polar Lows, Supervised Metric Learning","14th International Symposium \Intelligent Systems""",,,,,,,,,,,,,,,,,,,,
Journal Article,"Ker AD,Nickau H,Luke Ong CH",,Innocent game models of untyped λ-calculus,Theoretical Computer Science,2002,272,1,247-292,,,,,2002,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397500003534;http://dx.doi.org/10.1016/S0304-3975(00)00353-4,10.1016/S0304-3975(00)00353-4,"We present a new denotational model for the untyped λ-calculus, using the techniques of game semantics. The strategies used are innocent in the sense of Hyland and Ong (Inform. and Comput., to appear) and Nickau (Hereditarily Sequential Functionals: A Game-Theoretic Approach to Sequentiality, Shaker-Verlag, 1996. Dissertation, Universität Gesamthochschule Siegen, Shaker-Verlag, 1996), but the traditional distinction between “question” and “answer” moves is removed. We first construct models D and DREC as global sections of a reflexive object in the categories A and AREC of arenas and innocent and recursive innocent strategies, respectively. We show that these are sensible λη-algebras but are neither extensional nor universal. We then introduce a new representation of innocent strategies in an economical form. We show a strong connexion between the economical form of the denotation of a term in the game models and a variable-free form of the Nakajima tree of the term. Using this we show that the definable elements of DREC are precisely what we call effectively almost-everywhere copycat (EAC) strategies. The category AEAC with these strategies as morphisms gives rise to a λη-model DEAC which we show has the same expressive power as D∞, i.e. the equational theory of DEAC is the maximal consistent sensible theory H∗. We show that the model DEAC is sensible, order-extensional and universal (i.e. every strategy is the denotation of some λ-term). To our knowledge this is the first syntax-free model of the untyped λ-calculus with the universality property.","Game semantics, Innocent strategies, Untyped -calculus",Theories of Types and Proofs 1997,,,,,,,,,,,,,,,,,,,,
Journal Article,Dicosmo R,,Second Order Isomorphic Types: A Proof Theoretic Study on Second Order λ-Calculus with Surjective Pairing and Terminal Object,Information and Computation,1995,119,2,176-201,,,,,1995,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540185710851;http://dx.doi.org/10.1006/inco.1995.1085,10.1006/inco.1995.1085,"We investigate invertible terms and isomorphic types in the second order lambda calculus extended with surjective pairs and terminal (or Unit) type. These two topics are closely related: on one side, the study of invertibility is a necessary tool for the characterization of isomorphic types; on the other hand, we need the notion of isomorphic types to study the typed invertible terms. The result of our investigation is twofold: we give a constructive characterization of the invertible terms, extending previous work by Dezani and Bruce-Longo, and a decidable equational theory of the isomorphisms of types which hold in all models of the calculus, which is a conservative extension to the second order case of the results previously achieved for the case of first order typed calculi. Via the Curry-Howard correspondence, this work also provides a decision procedure for strong equivalence of formulae in second order intuitionistic positive propositional logic, that is suitable to search equivalent proofs in automated deduction systems.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ryan PY,Schneider SA",,An attack on a recursive authentication protocol A cautionary tale,Information Processing Letters,1998,65,1,7-10,,,,,1998,,0020-0190,https://www.sciencedirect.com/science/article/pii/S0020019097001804;http://dx.doi.org/10.1016/S0020-0190(97)00180-4,10.1016/S0020-0190(97)00180-4,We describe an attack on a recursive authentication protocol proposed by John Bull of APM. The protocol is an implementation of a more abstract design that was analysed by Paulson and shown to establish session keys in a secure manner. The fact that Bull's implementation nevertheless fails to be secure in this sense provides an object lesson on how careful one has to be in interpreting the results of a formal analysis.,"Authentication, Security, Protocol vulnerabilities, Formal analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sunitha EV,Samuel P",,Object constraint language for code generation from activity models,Information and Software Technology,2018,103,,92-111,,,,,2018,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584916304190;http://dx.doi.org/10.1016/j.infsof.2018.06.010,10.1016/j.infsof.2018.06.010,"Context Achieving hundred percent automation in code generation process from Unified Modeling Language (UML) models will make a drastic advancement in software industry. UML does not use a fully formalized semantics. So it leads to ambiguity during automatic implementation of UML models. These ambiguities can be avoided to a large extent using Object Constraint Language (OCL). OCL is formal and user friendly which is also familiar to industry people. Objective This paper examines how to improve the code generation from UML models, with the help of Object Constraint Language. It also explores the possibilities to incorporate OCL in UML activity models and generate code from the OCL enhanced activity diagrams. Method Meta models for the association of OCL expressions with the UML activity diagram is proposed in the paper. OCL expressions are added as part of the UML activity models to improve the code generation and to specify assertions and behavior. Moreover a tool, called ActivityOCLKode, is implemented which follows the algorithm for code generation. The algorithm is depicted in the text. Results The tool which is implemented based on the proposed method gives a promising result. More than 80% of source code is generated using the tool. In addition, the average execution time for our approach is only 11.46 ms. Conclusion The meta model proposed in the paper gives the strong theoretical back ground to attach OCL statements with each element in the UML activity diagrams. The proposed method of code generation will improve the productivity of the software industries, since it reduces the software development effort and time. Since UML and OCL are commonly used in software industry, our method is easily adaptable by software programmers in industry.","Code generation, UML, XML, OCL, Activity diagram",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Srivastava HM,Hussain MA",,Fractional integration of the H-function of several variables,Computers & Mathematics with Applications,1995,30,9,73-85,,,,,1995,,0898-1221,https://www.sciencedirect.com/science/article/pii/089812219500148R;http://dx.doi.org/10.1016/0898-1221(95)00148-R,10.1016/0898-1221(95)00148-R,The main object of the present paper is to derive a number of key formulas for the fractional integration of the multivariable H-function (which is defined by a multiple contour integral of Mellin-Barnes type). Each of the general Eulerian integral formulas (obtained in this paper) are shown to yield interesting new results for various families of generalized hypergeometric functions of several variables. Some of these applications of the key formulas would provide potentially useful generalizations of known results in the theory of fractional calculus.,"Fractional integration, -functions of one and more variables, Gamma and Beta functions, Eulerian integrals, Mellin-Barnes contour integrals, Binomial expansion, Appell functions, (Srivastava-Daoust) generalized Lauricella function, Fractional calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Huang T,Russell S",,Object identification: a Bayesian analysis with application to traffic surveillance,Artificial Intelligence,1998,103,1,77-93,,,,,1998,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370298000678;http://dx.doi.org/10.1016/S0004-3702(98)00067-8,10.1016/S0004-3702(98)00067-8,"Object identification—the task of deciding that two observed objects are in fact one and the same object—is a fundamental requirement for any situated agent that reasons about individuals. Object identity, as represented by the equality operator between two terms in predicate calculus, is essentially a first-order concept. Raw sensory observations, on the other hand, are essentially propositional—especially when formulated as evidence in standard probability theory. This paper describes patterns of reasoning that allow identity sentences to be grounded in sensory observations, thereby bridging the gap. We begin by defining a physical event space over which probabilities are defined. We then introduce an identity criterion, which selects those events that correspond to identity between observed objects. From this, we are able to compute the probability that any two objects are the same, given a stream of observations of many objects. We show that the appearance probability, which defines how an object can be expected to appear at subsequent observations given its current appearance, is a natural model for this type of reasoning. We apply the theory to the task of recognizing cars observed by cameras at widely separated sites in a freeway network, with new heuristics to handle the inevitable complexity of matching large numbers of objects and with online learning of appearance probability models. Despite extremely noisy observations, we are able to achieve high levels of performance.","Object identification, Matching, Data association, Bayesian inference, Traffic surveillance",Artificial Intelligence 40 years later,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kononov DA,Kul'ba VV,Sbubin AN",,Stability of Socioeconomic Systems: Scenario Investigation Methodology,IFAC Proceedings Volumes,2001,34,21,79-84,,,,,2001,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017330240;http://dx.doi.org/10.1016/S1474-6670(17)33024-0,10.1016/S1474-6670(17)33024-0,"We introduce a new scientific project, which supposes to create a new effective semiautomatic tool. It's expected to be used for analysis and synthesis of complex social and economical systems. A new principle named «scenario methodology» was developed in order to create this tool. We unite two main concepts: system analysis and the subject-object methodology to describe behavior of the system object. It was constructed formalized event, situation, scenario, principles and methods to define topological structures, create scenario characters, and indicate its properties. There constructed a spectrum of scenario spaces to represent different management fields: technical, technological, organization, economical, lawful and etc. It was defined scenario operations in scenario space. Thus, scenario calculus was created.","Scenario Methodology, Scenario Stability","8th IFAC Conference on Social Stability: The Challenge of Technology Development (SWIIS '01), Vienna, Austria, 27-29 September 2001",,,,,,,,,,,,,,,,,,,,
Journal Article,"Legarda-Saenz R,Brito-Loeza C,Rivera M,Espinosa-Romero A",,Variational method for integrating radial gradient field,Optics and Lasers in Engineering,2014,63,,53-57,,,,,2014,,0143-8166,https://www.sciencedirect.com/science/article/pii/S0143816614001596;http://dx.doi.org/10.1016/j.optlaseng.2014.06.014,10.1016/j.optlaseng.2014.06.014,"We propose a variational method for integrating information obtained from circular fringe pattern. The proposed method is a suitable choice for objects with radial symmetry. First, we analyze the information contained in the fringe pattern captured by the experimental setup and then move to formulate the problem of recovering the wavefront using techniques from calculus of variations. The performance of the method is demonstrated by numerical experiments with both synthetic and real data.","Fringe analysis, Image reconstruction techniques, Phase retrieval",,,,,,,,,,,,,,,,,,,,,
Journal Article,Wehrheim H,,Slicing techniques for verification re-use,Theoretical Computer Science,2005,343,3,509-528,,,,,2005,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397505003701;http://dx.doi.org/10.1016/j.tcs.2005.06.020,10.1016/j.tcs.2005.06.020,"In this paper we discuss which properties of a formally verified component are preserved when the component is changed due to an adaption to a new use. More specifically, we will investigate when a temporal logic property of an Object-Z class is preserved under a modification or extension of the class with new features. To this end, we use the slicing technique from program analysis which provides us with a representation of the dependencies within the class in the form of a program dependence graph. This graph can be used to determine the effect of a change to the class's behaviour and thus to the validity of a temporal logic formula.","Verification, Slicing, Temporal logic, Object-Z",Formal Methods for Components and Objects,,,,,,,,,,,,,,,,,,,,
Book Chapter,Fraser CG,"Grattan-Guinness I,Cooke R,Corry L,Crépel P,Guicciardini N","Chapter 19 - Joseph Louis Lagrange, Théorie des fonctions analytiques, first edition (1797)",,2005,,,258-276,,Elsevier Science,Amsterdam,Landmark Writings in Western Mathematics 1640-1940,2005,9780444508713,,https://www.sciencedirect.com/science/article/pii/B9780444508713501005;http://dx.doi.org/10.1016/B978-044450871-3/50100-5,10.1016/B978-044450871-3/50100-5,"Publisher Summary Based upon Craig G. Fraser, Lagrange both popularized and extended his view that the differential and integral calculus could be based solely on assuming the Taylor expansion of a function in an infinite power series and on algebraic manipulations thereafter. He also made some applications to problems in geometry and mechanics. An important and under-appreciated contribution of the history of mathematics is to provide insight into the foundations of a mathematical theory by identifying the characteristics of historically earlier formulations of the theory. The conceptual relativism of scientific theories over history is one of the major findings of the history of science since Thomas Kuhn. In this respect, history of mathematics possesses a special interest lacking in the history of other branches of science, because earlier mathematical theories are enduring objects of technical interest and even of further development. Finally, even after the consolidation of Cauchy's arithmetical foundation, Lagrange's emphasis on the algorithmic, operational character of the calculus continued to inform writers of textbooks as well as non-mathematicians such as engineers and physicists who used calculus in their research and teaching.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zervas P,Sampson DG",,The effect of users' tagging motivation on the enlargement of digital educational resources metadata,Computers in Human Behavior,2014,32,,292-300,,,,,2014,,0747-5632,https://www.sciencedirect.com/science/article/pii/S0747563213002185;http://dx.doi.org/10.1016/j.chb.2013.06.026,10.1016/j.chb.2013.06.026,"The emerging Web 2.0 applications have allowed new ways of characterizing digital educational resources, which moves from the expert-based descriptions relying on formal classification systems such as the IEEE Learning Object Metadata (LOM) to a less formal user-based tagging. This alternative way of characterizing digital educational resources is commonly referred to as social tagging, whereas the collection of tags created by the different users individually is referred to as folksonomy. As a result, a number of studies have been reported in the field of Technology-enhanced Learning (TeL) which provide evidence that social tagging has the potential to enlarge metadata descriptions, as well as the formal structured vocabularies with additional terms derived by the resulted folksonomy but more in depth studies are needed regarding this enlargement process. Thus, one issue to investigate further is the possible influence of users’ tagging motivation to the resulted enlarged metadata descriptions. In this paper we aim to investigate this issue by first proposing a methodology that aims to evaluate whether users’ tagging motivation can influence (a) the enlargement of educational resources possible descriptions compared to the anticipated creators’ descriptions and (b) the resulted folksonomy compared with formal structured vocabularies used by the creators of the educational resources and then, apply it to an existing LOR with more than 3,000 science education resources, 434 taggers and 14,707 social tags. Our experiments provided evidence that taggers with a specific type of tagging motivation can produce tags that are significantly different from formal metadata generated by the creators of the educational resources.","Educational resources, Social tagging, Folksonomy, User tagging motivation, Evaluation methodology, Evaluation results",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hsiung PA,Lin SW",,Automatic synthesis and verification of real-time embedded software for mobile and ubiquitous systems,"Computer Languages, Systems & Structures",2008,34,4,153-169,,,,,2008,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842407000206;http://dx.doi.org/10.1016/j.cl.2007.06.002,10.1016/j.cl.2007.06.002,"Currently available application frameworks that target the automatic design of real-time embedded software are poor in integrating functional and non-functional requirements for mobile and ubiquitous systems. In this work, we present the internal architecture and design flow of a newly proposed framework called Verifiable Embedded Real-Time Application Framework (VERTAF), which integrates three techniques namely software component-based reuse, formal synthesis, and formal verification. Component reuse is based on a formal unified modeling language (UML) real-time embedded object model. Formal synthesis employs quasi-static and quasi-dynamic scheduling with multi-layer portable efficient code generation, which can output either real-time operating systems (RTOS)-specific application code or automatically generated real-time executive with application code. Formal verification integrates a model checker kernel from state graph manipulators (SGM), by adapting it for embedded software. The proposed architecture for VERTAF is component-based which allows plug-and-play for the scheduler and the verifier. The architecture is also easily extensible because reusable hardware and software design components can be added. Application examples developed using VERTAF demonstrate significantly reduced relative design effort as compared to design without VERTAF, which also shows how high-level reuse of software components combined with automatic synthesis and verification increases design productivity.","Application framework, Code generation, Real-time embedded software, Formal synthesis, Formal verification, Scheduling, Software components, UML modeling",Embedded Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,Karhumäki J,,Reachability via Cooperating Morphisms,Electronic Notes in Theoretical Computer Science,2008,223,,15-27,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610800491X;http://dx.doi.org/10.1016/j.entcs.2008.12.028,10.1016/j.entcs.2008.12.028,"The goal of this presentation is to analyze the equality mechanism of cooperating morphisms of free monoids, and to point out that the reachability questions lead to the undecidability and easy characterizations of recursively enumerable languages. In particular, we aim to show, which subconstructions are needed in such results. Moreover, we recall that in some cases the undecidability of the reachability is achieved although the sets of all reachable objects are simple, or more formally, regular languages.","morphisms, equality languages, recursively enumerable languages, reachability problems",Proceedings of the Second Workshop on Reachability Problems in Computational Models (RP 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Rocha C,Muñoz C",,Synchronous set relations in rewriting logic,Science of Computer Programming,2014,92,,211-228,,,,,2014,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642313001652;http://dx.doi.org/10.1016/j.scico.2013.07.008,10.1016/j.scico.2013.07.008,"This paper presents a mathematical foundation and a rewriting logic infrastructure for the execution and property verification of synchronous set relations. The mathematical foundation is given in the language of abstract set relations. The infrastructure, which is written in the Maude system, enables the synchronous execution of a set relation provided by the user. By using the infrastructure, algorithm verification techniques such as reachability analysis and model checking, already available in Maude for traditional asynchronous rewriting, are automatically available to synchronous set rewriting. In this way, set-based synchronous languages and systems such as those built from agents, components, or objects can be naturally specified and simulated, and are also amenable to formal verification in the Maude system. The use of the infrastructure and some of its Maude-based verification capabilities are illustrated with an executable operational semantics of the Plan Execution Interchange Language (PLEXIL), a synchronous language developed by NASA to support autonomous spacecraft operations.","Synchronous set relations, Synchronous semantics, Rewriting logic, Formal simulation and verification, PLEXIL",Selected papers from the Brazilian Symposium on Formal Methods (SBMF 2011),,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee C,Jeon J,Park Y",,Monitoring trends of technological changes based on the dynamic patent lattice: A modified formal concept analysis approach,Technological Forecasting and Social Change,2011,78,4,690-702,,,,,2011,,0040-1625,https://www.sciencedirect.com/science/article/pii/S004016251000274X;http://dx.doi.org/10.1016/j.techfore.2010.11.010,10.1016/j.techfore.2010.11.010,"The strategic importance of monitoring technological changes is highlighted given the ever faster pace and increasing complexity of technological innovation. In this respect, patent citation analysis has been the most frequently adopted tool among others. However, patent citation analysis is subject to certain drawbacks that stem from only consideration of citing-cited information and time lags between citing and cited patents. This study proposes a formal concept analysis (FCA)-based approach to developing a dynamic patent lattice that can analyze complex relations among patents and monitor trends of technological changes. The FCA is a mathematical tool for grouping objects with shared properties based on the lattice theory. The distinct strengths of FCA, vis-á-vis other methods, lie in structuring and displaying the relations among objects from a massive amount of data. For the purpose of technology monitoring, the FCA is modified to take into account time periods and changes of patent keywords. A patent context is first constructed with the aid of domain experts and text mining technique. Two types of dynamic patent lattices are then developed by executing the modified FCA algorithm. A case study of laser technology in lithography for semiconductor manufacturing shows that the suggested dynamic patent lattice has considerable advantages over conventional patent citation maps in terms of visualization and informative power.","Technology monitoring, Technology intelligence, Patent analysis, Formal concept analysis, Dynamic patent lattice",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Clévenot F,Nain P,Ross KW",,Stochastic fluid models for cache clusters,Performance Evaluation,2005,59,1,1-18,,,,,2005,,0166-5316,https://www.sciencedirect.com/science/article/pii/S0166531604000549;http://dx.doi.org/10.1016/j.peva.2004.05.006,10.1016/j.peva.2004.05.006,"Clusters of Web caches are extensively used by different types of organizations, including companies, universities, ISPs, and CDNs. To model Web caches, we must account for two types of stochastic events: objects being pulled into/out of the cache cluster at random times, and caches going up and down at random times. Detailed stochastic models of such complex systems quickly become intractable. In this paper we propose a stochastic fluid model which captures the salient characteristics of a cache cluster. The stochastic fluid model replaces the object arrivals to the cluster and departures (object modification/expiration) with a fluid flow, but maintains the up/down dynamics of the original system. The model can be applied to a variety of cluster routing policies, and provides a simple means to estimate the hit rate. We compare the results of the stochastic fluid model with that of a simulation of the real system. We find the fluid model to not only be a close approximation, but also to exhibit the key qualitative properties of the original system. We conclude that stochastic fluid models show great potential in modeling a variety of content distribution systems.","Web caching, Fluid models, Stochastic processes, Palm calculus",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Bělohlávek R,"Demicco RV,Klir GJ",Chapter 7 - Formal Concept Analysis in Geology,,2004,,,191-237,,Academic Press,Burlington,Fuzzy Logic in Geology,2004,9780124151468,,https://www.sciencedirect.com/science/article/pii/B978012415146850010X;http://dx.doi.org/10.1016/B978-012415146-8/50010-X,10.1016/B978-012415146-8/50010-X,"Publisher Summary When humans formulate their knowledge about some domain of interest, they usually recognize objects and their properties. Objects and attributes (properties) are, indeed, primary phenomena when the physical world is observed. When experts start exploring an unknown area of interest, their first step is to identify relevant objects and their attributes. Then, experts identify what objects have which attributes. With this object-attribute knowledge at hand, experts can start further investigations such as various kinds of relationships among attributes and a natural classification scheme. Attributes can be useful in devising suitable criteria according to which the objects relevant to the domain may be naturally classified. In addition, it is often found that, to get an insightful view into the domain of interest, a reasonable conceptual system is required to be established—that is, a collection of concepts (specific to the domain) with basic relationships among the concepts.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Saxena RK,Mathai AM,Haubold HJ",,On generalized fractional kinetic equations,Physica A: Statistical Mechanics and its Applications,2004,344,3,657-664,,,,,2004,,0378-4371,https://www.sciencedirect.com/science/article/pii/S0378437104008131;http://dx.doi.org/10.1016/j.physa.2004.06.048,10.1016/j.physa.2004.06.048,"In a recent paper, Saxena et al. (Astro Phys. Space Sci. 282 (2002) 281) developed solutions of generalized fractional kinetic equations in terms of Mittag–Leffler functions. The object of the present paper is to derive the solution of further generalized fractional kinetic equations. Their relation to fundamental laws of physics is briefly discussed. Results are obtained in a compact form in terms of generalized Mittag–Leffler functions and a number of representations of these functions, which are widely distributed in the literature, are compiled for the first time.","Kinetic equation, Functional calculus, Special functions, Nuclear reactions","Proceedings of the International Workshop on 'Trends and perspectives in extensive and non-extensive statistical mechanics', in honor of the 60th birthday of Constantino Tsallis",,,,,,,,,,,,,,,,,,,,
Journal Article,Zakharevich I,,The K-theory of assemblers,Advances in Mathematics,2017,304,,1176-1218,,,,,2017,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870816311720;http://dx.doi.org/10.1016/j.aim.2016.08.045,10.1016/j.aim.2016.08.045,"In this paper we introduce the notion of an assembler, which formally encodes “cutting and pasting” data. An assembler has an associated K-theory spectrum, in which π0 is the free abelian group of objects of the assembler modulo the cutting and pasting relations, and in which the higher homotopy groups encode further geometric invariants. The goal of this paper is to prove structural theorems about this K-theory spectrum, including analogs of Quillen's localization and dévissage theorems. We demonstrate the uses of these theorems by analyzing the assembler associated to the Grothendieck ring of varieties and the assembler associated to scissors congruence groups of polytopes.","K-theory, Scissors-congruence, Category theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,Sakaguchi K,,Program extraction for mutable arrays,Science of Computer Programming,2020,191,,102372,,,,,2020,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642319301650;http://dx.doi.org/10.1016/j.scico.2019.102372,10.1016/j.scico.2019.102372,"We present a lightweight method to represent, verify, and extract efficient programs involving mutable arrays in the Coq proof assistant. Our method mainly consists of a library for handling mutable arrays and an improved extraction plugin. Our library provides a monadic domain specific language for modeling computations involving mutable arrays, a simple reasoning method based on the Ssreflect extension and the Mathematical Components library, and an extraction method to efficient OCaml programs using in-place updates. Our extraction plugin improves the performance of our extracted programs, or more appropriately, through the application of simple program transformations for purely functional programs, it reduces both construction and destruction costs of inductive and coinductive objects and function call costs. As concrete applications for our method, we provide efficient implementations, correctness proofs, and benchmarks of the union–find data structure and the quicksort algorithm.","Interactive theorem proving, Formally verified software, The Coq proof assistant, Program extraction, Program transformation and optimization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wu D,Tian Y,Ng KW,Datta A",,Stochastic analysis of the interplay between object maintenance and churn,Computer Communications,2008,31,2,220-239,,,,,2008,,0140-3664,https://www.sciencedirect.com/science/article/pii/S0140366407002873;http://dx.doi.org/10.1016/j.comcom.2007.08.008,10.1016/j.comcom.2007.08.008,"Due to the prevalence of peer dynamics (i.e., churn), object maintenance becomes a fundamental issue in peer-to-peer storage systems. Although quite a few prototypes have been designed and implemented, they lack theoretical analysis to shed light on how the system evolves under churn and how to configure the system properly. The performance of peer-to-peer storage systems under churn (e.g., storage capacity, bandwidth usage, bandwidth spike, etc.) also become unclear. In this paper, we develop a simple model based on stochastic differential equations, with which we can analytically study the time-evolution of peer-to-peer storage systems under churn, and the interplay between object maintenance and churn. Different from previous Markovian analysis, we provide closed-form terms to capture the time-evolution of the storage system, and formally derive its related performance metrics under different maintenance strategies. Our analytical results provide valuable directions on the optimization of peer-to-peer storage systems, e.g., reducing bandwidth usage, provisioning for bandwidth spike, improving system capacity. Besides analytical studies, our theoretical results are also validated by extensive simulations.","Peer-to-peer storage system, Object maintenance, Churn",Special Issue: Foundation of Peer-to-Peer Computing,,,,,,,,,,,,,,,,,,,,
Journal Article,Zhang MH,,Data types with errors and exceptions,Theoretical Computer Science,1992,105,2,275-299,,,,,1992,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759290303W;http://dx.doi.org/10.1016/0304-3975(92)90303-W,10.1016/0304-3975(92)90303-W,"Ming-Hua Zhang (1988) has proposed a new specification method for data types based on second-order logic. Now we show that errors and exceptions are included directly in the specifications from the beginning. In our approach errors are not objects but indicate that some formulas are false. Unlike errors, exceptions are special objects. The error, error propagation, error recovery and exception can all be precisely defined and the fundamental results about them can be deduced from the specification by predicate calculus.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Frisch AM,Allen JF","Mylopolous J,Brodie M",Knowledge Retrieval as Limited Inference,,1989,,,444-451,,Morgan Kaufmann,San Francisco (CA),Readings in Artificial Intelligence and Databases,1989,9780934613538,,https://www.sciencedirect.com/science/article/pii/B9780934613538500327;http://dx.doi.org/10.1016/B978-0-934613-53-8.50032-7,10.1016/B978-0-934613-53-8.50032-7,"ABSTRACT Artificial intelligence reasoning systems commonly employ a knowledge base module that stores a set of facts expressed in a representation language and provides facilities to retrieve these facts. A retriever could range from a simple pattern matcher to a complete logical inference system. In practice, most fall in between these extremes, providing some forms of inference but not others. Unfortunately, most of these retrievers are not precisely defined. We view knowledge retrieval as a limited form of inference operating on the stored facts. This paper is concerned with our method of using first-order predicate calculus to formally specify a limited inference mechanism and to a lesser extent with the techniques for producing an efficient program that meets the specification. Our ideas are illustrated by developing a simplified version of a retriever used in the knowledge base of the Rochester Dialog System. The interesting property of this retriever is that it performs typical semantic network inferences such as inheritance but not arbitrary logical inferences such as modus ponens.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Reynolds JC,Plotkin GD",,On Functors Expressible in the Polymorphic Typed Lambda Calculus,Information and Computation,1993,105,1,1-29,,,,,1993,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540183710370;http://dx.doi.org/10.1006/inco.1993.1037,10.1006/inco.1993.1037,"Given a model of the polymorphic typed lambda calculus based upon a Cartesian closed category K, there will be functors from K to K whose action on objects can be expressed by type expressions and whose action on morphisms can be expressed by ordinary expressions. We show that if T is such a functor then there is a weak initial T-algebra and if, in addition, K possesses equalizers of all subsets of its morphism sets, then there is an initial T-algebra. These results are used to establish the impossibility of certain models, including those in which types denote sets and S → S′ denotes the set of all functions from S to S′.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mitropolskiy YA,Samoylenko VH,Matarazzo G",,On asymptotic solutions to delay differential equation with slowly varying coefficients,"Nonlinear Analysis: Theory, Methods & Applications",2003,52,3,971-988,,,,,2003,,0362-546X,https://www.sciencedirect.com/science/article/pii/S0362546X02001475;http://dx.doi.org/10.1016/S0362-546X(02)00147-5,10.1016/S0362-546X(02)00147-5,"The object of this paper is to study a problem of construction of an approximate solution to the second-order weakly nonlinear ordinary delay differential equation with slowly varying coefficients. Based on asymptotic techniques of nonlinear mechanics, an algorithm for asymptotic integration of differential equation under consideration is given for the general case. Its efficiency is demonstrated by Duffing-type systems with delay as example.","Asymptotic solutions, Delay differential equations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chávez-Bosquez O,Pozos-Parra P",,"The Latin American laws of correct nutrition: Review, unified interpretation, model and tools",Computers in Biology and Medicine,2016,70,,67-79,,,,,2016,,0010-4825,https://www.sciencedirect.com/science/article/pii/S0010482515004126;http://dx.doi.org/10.1016/j.compbiomed.2015.12.019,10.1016/j.compbiomed.2015.12.019,"Background: The “Laws of Correct Nutrition”: the Law of Quantity, the Law of Quality, the Law of Harmony and the Law of Adequacy, provide the basis of a proper diet, i.e. one that provides the body with the energy required and nutrients it needs for daily activities and maintenance of vital functions. For several decades, these Laws have been the basis of nourishing menus designed in Latin America; however, they are stated in a colloquial language, which leads to differences in interpretation and ambiguities for non-experts and even experts in the field. Methods: We present a review of the different interpretations of the Laws and describe a consensus. We represent concepts related to nourishing menu design employing the Unified Modeling Language (UML). We formalize the Laws using the Object Constraint Language (OCL). We design a nourishing menu for a particular user through enforcement of the Laws. Results: We designed a domain model with the essential elements to plan a nourishing menu and we expressed the necessary constraints to make the model׳s behavior conform to the four Laws. We made a formal verification and validation of the model via USE (UML-based Specification Environment) and we developed a software prototype for menu design under the Laws. Conclusion: Diet planning is considered as an art but consideration should be given to the need for a set of strict rules to design adequate menus. Thus, we model the “Laws of Nutrition” as a formal basis and standard framework for this task.","Laws of Nutrition, Domain model, Diet planning, Menu planning, Unified Modeling Language (UML), Object Constraint Language (OCL), Software, Model validation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lucchi R,Bravetti M,Gorrieri R",,A formal approach for checking security properties in SecSpaces1 1Work partially supported by MEFISTO Progetto “Metodi Formali per la Sicurezza e il Tempo” and Microsoft Research Europe,Electronic Notes in Theoretical Computer Science,2003,85,3,54-70,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104806844;http://dx.doi.org/10.1016/S1571-0661(04)80684-4,10.1016/S1571-0661(04)80684-4,"SecSpaces is a Linda-like coordination model whose aim is to provide a support for secure coordination in Open System applications. Substantially it provides a methodology to restrict the access to the objects stored in the shared dataspace. In this paper we introduce a formal language for representing systems interacting via SecSpaces primitives and its operational semantics. Moreover in this context we consider a notion of observational equivalence, namely testing equivalence. In order to evaluate the adequacy of the model for limiting the access to the shared dataspace, we present some examples of interaction protocols that can be used to obtain some security properties (e.g., authentication or privacy of a datum).",,"SecCo'03, First International Workshop on Security Issues in Coordination Models, Languages, and Systems (Satellite Event for ICALP 2003)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Golden B,Aiguier M,Krob D",,Modeling of complex systems II: A minimalist and unified semantics for heterogeneous integrated systems,Applied Mathematics and Computation,2012,218,16,8039-8055,,,,,2012,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300312000860;http://dx.doi.org/10.1016/j.amc.2012.01.048,10.1016/j.amc.2012.01.048,"The purpose of this paper is to contribute to a unified formal framework for complex systems modeling. To this aim, we define a unified semantics for systems including integration operators. We consider complex systems as functional blackboxes (with internal states), whose structure and behaviors can be constructed through a recursive integration of heterogeneous components. We first introduce formal definitions of time (allowing to deal uniformly with both continuous and discrete times) and data (allowing to handle heterogeneous data), and introduce a generic synchronization mechanism for dataflows. We then define a system as a mathematical object characterized by coupled functional and states behaviors. This definition is expressive enough to capture the functional behavior of any real system with sequential transitions. We finally provide formal operators for integrating systems and show that they are consistent with the classical definitions of those operators on transfer functions which model real systems.","Complex systems, Systems modeling, Systems semantics, Systems Engineering, Systems integration, Timed Mealy machine, Hybrid time, Non-standard analysis",Special Issue dedicated to the international workshop \Infinite and Infinitesimal in Mathematics,"Computing and Natural Sciences\""""",,,,,,,,,,,,,,,,,,,
Journal Article,"Díaz-Dorado E,Suárez-García A,Carrillo CJ,Cidrás J",,Optimal distribution for photovoltaic solar trackers to minimize power losses caused by shadows,Renewable Energy,2011,36,6,1826-1835,,,,,2011,,0960-1481,https://www.sciencedirect.com/science/article/pii/S0960148110005562;http://dx.doi.org/10.1016/j.renene.2010.12.002,10.1016/j.renene.2010.12.002,"The typical design of photovoltaic facilities with photovoltaic solar trackers is achieved using a squared or diagonal distribution of the trackers. In general, this is a good distribution for harvesting most solar radiation. However, these facilities can be affected by shadows of environmental objects like buildings, vegetation, etc. In this paper, a metaheuristic method based on evolution strategies is presented for calculating the best location of each tracker on a building of irregular shape, considering the shadows caused by obstacles and photovoltaic trackers. The evolution strategies will use the energy readings obtained by a photovoltaic tracker distribution to look for the best location. In the calculus of the energy, solar charts are used to combine the solar radiation received and shadows suffered by the tracker for each solar position.","Evolutionary computation, Photovoltaic Systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,Suciu D,,Bounded fixpoints for complex objects,Theoretical Computer Science,1997,176,1,283-328,,,,,1997,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397596002939;http://dx.doi.org/10.1016/S0304-3975(96)00293-9,10.1016/S0304-3975(96)00293-9,"We study a query language for complex-object databases, which is designed to (1) express only tractable queries, and (2) be as expressive over flat relations as first-order logic with fixpoints. The language is obtained by extending the nested relational algebra, NRA, with a “bounded fixpoint” operator. Similar to results for flat relations, all tractable queries over ordered databases are expressible in this language. The main result consists in proving that this language is a conservative extension of the first-order logic with fixpoints, or of the while-queries, (depending on the interpretation of the bounded fixpoint: inflationary or partial). That is, a query from flat relations to flat relations is expressible in our language if and only if it is expressible in first-order logic with fixpoints, or in the while-queries, respectively. The proof technique for this theorem uses indexes to encode complex objects into flat relations. It can serve as basis for an implementation method of complex objects databases in terms of relational databases, which works well for queries expressed both with fixpoints and with bounded fixpoint. We also define a complex object logical calculus with fixpoints and prove that its range-restricted fragment is equivalent to NRA with bounded fixpoints.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Yi-Luen Do E,,Design sketches and sketch design tools,Knowledge-Based Systems,2005,18,8,383-405,,,,,2005,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705105000705;http://dx.doi.org/10.1016/j.knosys.2005.07.001,10.1016/j.knosys.2005.07.001,"In early stages of design architects often use sketching and diagramming to perform formal and functional reasoning. Design sketches are an external representation aid for visualization and evaluation of the spatial arrangements of artifacts. Symbols and configurations are used in design sketches to define context and object arrangements. This paper argues the need to study design drawing, reports the findings from empirical studies of design drawings, and describes the software systems implemented to support intention inference and automated activation of knowledge-based design tools to support design.","Architectural objects, Empirical studies, Knowledge-based design tools",Computational Approaches for Early Stages of Design,,,,,,,,,,,,,,,,,,,,
Journal Article,Rutten JJ,,Coinductive Counting: Bisimulation in Enumerative Combinatorics (Extended Abstract),Electronic Notes in Theoretical Computer Science,2002,65,1,286-304,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104803694;http://dx.doi.org/10.1016/S1571-0661(04)80369-4,10.1016/S1571-0661(04)80369-4,The recently developed coinductive calculus of streams finds here a further application in enumerative combinatorics. A general methodology is developed to solve a wide variety of basic counting problems in a uniform way: (1) the objects to be counted are enumerated by means of an infinite (weighted) automaton; (2) the automaton is minimized by means of the quantitative notion of stream bisimulation; (3) the minimized automaton is used to compute an expression (in terms of stream constants and operators) that represents the stream of all counts.,,"CMCS'2002, Coalgebraic Methods in Computer Science (Satellite Event of ETAPS 2002)",,,,,,,,,,,,,,,,,,,,
Journal Article,Lamarche F,,Quantitative domains and infinitary algebras,Theoretical Computer Science,1992,94,1,37-62,,,,,1992,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397592903238;http://dx.doi.org/10.1016/0304-3975(92)90323-8,10.1016/0304-3975(92)90323-8,"We describe a class of models of the lambda calculus that generalize and simplify the quantitative domains of Girard (1988). Their salient feature is that these domains “do not have enough points”, in the sense that a map of domains is not entirely determined by its value on the points, i.e. the morphisms from the terminal object of the category. We construct a universal domain whose structure is particularly simple, and describe some of the features of the untyped lambda calculus associated to it. Finally, we show how linear logic can be interpreted in these domains, and construct another category of domains that supports linear logic.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bera B,Das AK,Sutrala AK",,Private blockchain-based access control mechanism for unauthorized UAV detection and mitigation in Internet of Drones environment,Computer Communications,2021,166,,91-109,,,,,2021,,0140-3664,https://www.sciencedirect.com/science/article/pii/S0140366420320119;http://dx.doi.org/10.1016/j.comcom.2020.12.005,10.1016/j.comcom.2020.12.005,"Drones, which are also known as Unmanned Aerial Vehicles (UAVs), are very useful in delivering the packages, and real-time object detection and tracking with minimal human interference. However, there may be several security threats in such an environment, for instance, a malicious user can spy unauthorized drones, transfer malicious packages, or even damage the network reliability that can have direct impact on drones control. This may lead to a potential threat for people, governments, and business sectors. To deal with these issues, in this paper, we propose a novel access control scheme for unauthorized UAV detection and mitigation in an Internet of Drones (IoD) environment, called ACSUD-IoD. With the help of the blockchain-based solution incorporated in ACSUD-IoD, the transactional data having both the normal secure data from a drone (UAV) to the Ground Station Server (GSS) and the abnormal (suspected) data for detection of unauthorized UAVs by the GSS are stored in private blockchain, that are authentic and genuine. As a result, the Big data analytics can be performed on the authenticated transactional data stored in the blockchain. Through the detailed security analysis including formal security under the broadly-accepted Real-Or-Random (ROR) model, formal security verification using the widely-applied Automated Validation of Internet Security Protocols and Applications (AVISPA) tool and non-mathematical security analysis show the robustness of the proposed scheme against a number of potential attacks needed in an IoD environment. The testbed experiments for various cryptographic primitives using the broadly-accepted Multiprecision Integer and Rational Arithmetic Cryptographic Library (MIRACL) have been performed under both server and Raspberry PI 3 configurations. Furthermore, a detailed comparative analysis among the proposed scheme and other existing competing schemes shows the efficacy and more robustness as compared to the existing schemes. Finally, the blockchain-based practical demonstration shows the effectiveness of the proposed scheme.","Internet of drones (IoD), UAV detection and mitigation, Access control, Blockchain, Security, AVISPA",,,,,,,,,,,,,,,,,,,,,
Journal Article,Chaitin GJ,,Information-theoretic incompleteness,Applied Mathematics and Computation,1992,52,1,83-101,,,,,1992,,0096-3003,https://www.sciencedirect.com/science/article/pii/009630039290099M;http://dx.doi.org/10.1016/0096-3003(92)90099-M,10.1016/0096-3003(92)90099-M,"We propose an improved definition of the complexity of a formal axiomatic system: this is now taken to be the minimum size of a self-delimiting program for enumerating the set of theorems of the formal system. Using this new definition, we show (a) that no formal system of complexity n can exhibit a specific object with complexity greater than n+c, and (b) that a formal system of complexity n can determine, at most, n + c scattered bits of the halting probability ω. We also present a short, self-contained proof of (b).",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Pons C,Garcia D",,A Lightweight Approach for the Semantic Validation of Model Refinements,Electronic Notes in Theoretical Computer Science,2008,220,1,43-61,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108004428;http://dx.doi.org/10.1016/j.entcs.2008.11.005,10.1016/j.entcs.2008.11.005,"Model Driven Engineering proposes the use of models at different levels of abstraction. Step by step validation of model refinements is necessary to guarantee the correctness of the final product with respect to its initial models. But, given that accurate validation activities require the application of formal modeling languages with a complex syntax and semantics and need to use complex formal analysis tools, they are rarely used in practice. In this article we describe a lightweight validation approach that does not require the use of third-party (formal) languages. The approach makes use of the standard OCL as the only visible formalism, so that refinements can be checked by using tools that are fully understood by the MDE community. Additionally, for the efficient evaluation of the refinement conditions a hybrid strategy that combines model checking, testing and theorem proving is implemented. Correctness and complexity of the proposal are empirically validated by means of the development of case studies and a comparison with the Alloy analyzer.","modeling, refinement, model transformation, Object Constraint Language, OCL, MOF, UML, validation, testing, model checking",Proceedings of the Fourth Workshop on Model Based Testing (MBT 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,Kapus-Kolar M,,An action refinement operator for E-LOTOS with true concurrency,Computer Standards & Interfaces,2009,31,1,77-87,,,,,2009,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548907001122;http://dx.doi.org/10.1016/j.csi.2007.11.008,10.1016/j.csi.2007.11.008,"Action refinement is an important operation in the hierarchical synthesis of concurrent systems. We propose an action refinement operator for E-LOTOS, a standard process-algebraic language for formal specification of real-time, concurrent and reactive systems. As the first step towards giving E-LOTOS a multitude of refinement operators supporting a variety of strategies for event relationship inheritance, we propose an operator which seems both useful and simple to implement. When the operator is applied to an E-LOTOS process, it modifies its enhanced event structure, i.e. its recently defined true concurrency model. The operator allows multiple alternative implementations even for urgent events and properly reflects the fact that gate actions of E-LOTOS processes are in the general case abstractions of distributed data generation procedures.","Process algebra, Action refinement, True concurrency, E-LOTOS",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Awodey S,Forssell H",,First-order logical duality,Annals of Pure and Applied Logic,2013,164,3,319-348,,,,,2013,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007212001807;http://dx.doi.org/10.1016/j.apal.2012.10.016,10.1016/j.apal.2012.10.016,"From a logical point of view, Stone duality for Boolean algebras relates theories in classical propositional logic and their collections of models. The theories can be seen as presentations of Boolean algebras, and the collections of models can be topologized in such a way that the theory can be recovered from its space of models. The situation can be cast as a formal duality relating two categories of syntax and semantics, mediated by homming into a common dualizing object, in this case 2. In the present work, we generalize the entire arrangement from propositional to first-order logic, using a representation result of Butz and Moerdijk. Boolean algebras are replaced by Boolean categories presented by theories in first-order logic, and spaces of models are replaced by topological groupoids of models and their isomorphisms. A duality between the resulting categories of syntax and semantics, expressed primarily in the form of a contravariant adjunction, is established by homming into a common dualizing object, now Sets, regarded once as a boolean category, and once as a groupoid equipped with an intrinsic topology. The overall framework of our investigation is provided by topos theory. Direct proofs of the main results are given, but the specialist will recognize toposophical ideas in the background. Indeed, the duality between syntax and semantics is really a manifestation of that between algebra and geometry in the two directions of the geometric morphisms that lurk behind our formal theory. Along the way, we give an elementary proof of Butz and Moerdijkʼs result in logical terms.","First-order logic, Categorical logic, Topos theory, Topological semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,Bhattacharjee PR,,Addressing some issues of Ray Optics on the basis of the newly discovered generalized vectorial laws of reflection and refraction,Optik,2013,124,23,6250-6254,,,,,2013,,0030-4026,https://www.sciencedirect.com/science/article/pii/S0030402613006281;http://dx.doi.org/10.1016/j.ijleo.2013.05.014,10.1016/j.ijleo.2013.05.014,"This paper addresses a few issues concerning Ray Optics on the basis of the newly discovered generalized vectorial laws of reflection and refraction. Along with confirming the validity of the principle of reversibility of light, the present study confirms the existing relationship between object distance and image distance in case of reflection by a plane mirror. General novel relations between real distance and apparent distance in case of image formation due to refraction also resulted from the present study. Finally novel treatment has been offered to deal with the problem of refraction through a parallel-sided slab of a refracting material on the basis of the aforesaid generalized vectorial law of refraction.","Reflection, Refraction, Vector algebra, Vector calculus",,,,,,,,,,,,,,,,,,,,,
Journal Article,Grimson WE,,The combinatorics of object recognition in cluttered environments using constrained search,Artificial Intelligence,1990,44,1,121-165,,,,,1990,,0004-3702,https://www.sciencedirect.com/science/article/pii/000437029090100E;http://dx.doi.org/10.1016/0004-3702(90)90100-E,10.1016/0004-3702(90)90100-E,"The problem of recognizing rigid objects from noisy sensory data has been successfully attacked in previous work by using a constrained search approach. Empirical investigations have shown the method to be very effective when recognizing and localizing isolated objects, but less effective when dealing with occluded objects where much of the sensory data arises from objects other than the one of interest. When clustering techniques such as the Hough transform are used to isolate likely subspaces of the search space, empirical performance in cluttered scenes improves considerably. In this note, we establish formal bounds on the combinatorics of this approach. Under some simple assumptions, we show that the expected complexity of recognizing isolated objects is quadratic in the number of model and sensory fragments, but that the expected complexity of recognizing objects in cluttered environments is exponential in the size of the correct interpretation. We also provide formal bounds on the efficacy of using the Hough transform to preselect likely subspaces, showing that the problem remains exponential, but that in practical terms the size of the problem is significantly decreased.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Möller B,,Geographic wayfinders and space-time algebra,Journal of Logical and Algebraic Methods in Programming,2019,104,,274-302,,,,,2019,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220817302031;http://dx.doi.org/10.1016/j.jlamp.2019.02.003,10.1016/j.jlamp.2019.02.003,"Time Geography is a framework for describing reachable points in a (static) spatio-temporal environment. While originally devised to facilitate reasoning about an individual's or a population's living conditions, it was later adapted to many other applications. A wayfinder is an entity that moves through a space-time continuum with possible obstacles. We show how to model the pertinent notions in relational algebra (and, more abstractly, in modal semirings) with box and diamond operators. Admissible or undesired regions can be described as Boolean combinations of primitive regions such as the set of all points reachable by forward or backward movement from a given region or starting point. To derive results about the region blocked by the union of two regions we introduce an abstract algebraic view of coordinates that is largely independent of dimensional and metric aspects and thus very general. Moreover, the approach lends itself quite well to machine-supported proofs.","Time geography, Moving objects, Obstacle analysis, Formal algebraic semantics, Modal operators, Modal semirings",,,,,,,,,,,,,,,,,,,,,
Journal Article,Schneider M,,Spatial Plateau Algebra for implementing fuzzy spatial objects in databases and GIS: Spatial plateau data types and operations,Applied Soft Computing,2014,16,,148-170,,,,,2014,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494613004249;http://dx.doi.org/10.1016/j.asoc.2013.11.021,10.1016/j.asoc.2013.11.021,"Many geographical applications have to deal with spatial objects that reveal an intrinsically vague or fuzzy nature. A spatial object is fuzzy if locations exist that cannot be assigned completely to the object or to its complement. Spatial database systems and Geographical Information Systems (GIS) are currently unable to cope with this kind of data. Based on an available abstract data model of fuzzy spatial data types for fuzzy points, fuzzy lines, and fuzzy regions that leverages fuzzy set theory and fuzzy point set topology, this article proposes a Spatial Plateau Algebra that provides spatial plateau data types as an implementation of fuzzy spatial data types. Each spatial plateau object consists of a finite number of crisp counterparts that are all adjacent or disjoint to each other, are associated with different membership values, and hence form different plateaus. The formal framework and the implementation are based on well known, exact models and implementations of crisp spatial data types. Spatial plateau operations as geometric operations on spatial plateau objects are expressed as a combination of geometric operations on the underlying crisp spatial objects. This article offers a conceptually clean foundation for implementing a database extension for fuzzy spatial objects and their operations, and demonstrates the embedding of these new data types as attribute data types in a database schema as well as the incorporation of fuzzy spatial operations into a database query language.","Spatial fuzziness, Spatial vagueness, Fuzzy spatial object, Spatial plateau object, Spatial plateau operation, Executable specification",,,,,,,,,,,,,,,,,,,,,
Journal Article,"El-Sappagh S,Elmogy M,Riad AM",,A fuzzy-ontology-oriented case-based reasoning framework for semantic diabetes diagnosis,Artificial Intelligence in Medicine,2015,65,3,179-208,,,,,2015,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365715000925;http://dx.doi.org/10.1016/j.artmed.2015.08.003,10.1016/j.artmed.2015.08.003,"Objective Case-based reasoning (CBR) is a problem-solving paradigm that uses past knowledge to interpret or solve new problems. It is suitable for experience-based and theory-less problems. Building a semantically intelligent CBR that mimic the expert thinking can solve many problems especially medical ones. Methods Knowledge-intensive CBR using formal ontologies is an evolvement of this paradigm. Ontologies can be used for case representation and storage, and it can be used as a background knowledge. Using standard medical ontologies, such as SNOMED CT, enhances the interoperability and integration with the health care systems. Moreover, utilizing vague or imprecise knowledge further improves the CBR semantic effectiveness. This paper proposes a fuzzy ontology-based CBR framework. It proposes a fuzzy case-base OWL2 ontology, and a fuzzy semantic retrieval algorithm that handles many feature types. Material This framework is implemented and tested on the diabetes diagnosis problem. The fuzzy ontology is populated with 60 real diabetic cases. The effectiveness of the proposed approach is illustrated with a set of experiments and case studies. Results The resulting system can answer complex medical queries related to semantic understanding of medical concepts and handling of vague terms. The resulting fuzzy case-base ontology has 63 concepts, 54 (fuzzy) object properties, 138 (fuzzy) datatype properties, 105 fuzzy datatypes, and 2640 instances. The system achieves an accuracy of 97.67%. We compare our framework with existing CBR systems and a set of five machine-learning classifiers; our system outperforms all of these systems. Conclusion Building an integrated CBR system can improve its performance. Representing CBR knowledge using the fuzzy ontology and building a case retrieval algorithm that treats different features differently improves the accuracy of the resulting systems.","Case-based reasoning, Knowledge based system, Fuzzy ontology, Semantic retrieval, Diabetes diagnosis, Standard SNOMED CT terminology",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lack S,Street R",,The formal theory of monads II,Journal of Pure and Applied Algebra,2002,175,1,243-265,,,,,2002,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404902001378;http://dx.doi.org/10.1016/S0022-4049(02)00137-8,10.1016/S0022-4049(02)00137-8,"We give an explicit description of the free completion EM(K) of a 2-category K under the Eilenberg–Moore construction, and show that this has the same underlying category as the 2-category Mnd(K) of monads in K. We then demonstrate that much of the formal theory of monads can be deduced using only the universal property of this completion, provided that one is willing to work with EM(K) as the 2-category of monads rather than Mnd(K). We also introduce the wreaths in K; these are the objects of EM(EM(K)), and are to be thought of as generalized distributive laws. We study these wreaths, and give examples to show how they arise in a variety of contexts.",,Special Volume celebrating the 70th birthday of Professor Max Kelly,,,,,,,,,,,,,,,,,,,,
Journal Article,Harth A,,VisiNav: A system for visual search and navigation on web data,Journal of Web Semantics,2010,8,4,348-354,,,,,2010,,1570-8268,https://www.sciencedirect.com/science/article/pii/S1570826810000600;http://dx.doi.org/10.1016/j.websem.2010.08.001,10.1016/j.websem.2010.08.001,"Abstract Web standards such as RDF (Resource Description Framework) facilitate data integration over large number of sources. The resulting interlinked datasets describe objects, their attributes and links to other objects. Such datasets are amenable for queries beyond traditional keyword search and for visualisation beyond a simple list of links to documents. Given that data integrated from the open web exhibits enormous variety in scope and structure, the mechanisms for interacting with such data have to be generic and agnostic to the vocabularies used. Ideally, a system operating on web data is easy to use without upfront training. To this end, we present VisiNav, a system based on an interaction model designed to easily search and navigate large amounts of web data (the current system contains over 18.5m RDF triples aggregated from 70k sources). In this paper we introduce a formal query model comprising four atomic operations over object-structured datasets: keyword search, object focus, path traversal, and facet specification. From these atomic operations, users incrementally assemble complex queries that yield trees of objects as result. These results can then be either directly visualised or exported to application programs or online services for further processing. The current system provides detail, list, and table views for arbitrary types of objects; and timeline and map visualisations for temporal and spatial aspects of objects.","Web data, Exploratory search, Faceted navigation, Semantic search, Visual analytics, Structured data search",Semantic Web Challenge 2009 User Interaction in Semantic Web research,,,,,,,,,,,,,,,,,,,,
Journal Article,de Brock EO,,Declarative semantics of transactions in ORM,Information Systems,2016,60,,85-94,,,,,2016,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437916300849;http://dx.doi.org/10.1016/j.is.2016.03.005,10.1016/j.is.2016.03.005,"In order to specify databases completely at the conceptual level, conceptual database specification languages should contain a data definition (sub)language (DDL), for specifying data structures (+constraints), a data retrieval (sub)language (DRL), for specifying queries, as well as a (declarative) data manipulation (sub)language (DML), for specifying transactions. Object Role Modeling (ORM) is a powerful method for designing and querying database models at the conceptual level. By means of verbalization the application is also described in natural language as used by domain experts, for communication and validation purposes. ORM currently comprises a DDL and a DRL (ConQuer). However, the ORM-method does not yet contain an expressive DML for specifying transactions at the conceptual level. In an earlier paper we designed a syntactic extension of the ORM-method with a DML for specifying transactions at the conceptual level in a purely declarative way. For all transactions we proposed syntaxes, verbalizations, and diagrams. However, we did not give a formal semantics then. The purpose of this paper is to add a clear, formal and purely declarative semantics to the proposed ORM-transactions. The paper also formally defines rollbacks and illustrates everything with examples (including a solution to a well-known transaction specification problem). The extension of ORM with an expressive set of completely declaratively specified transactions makes ORM complete as a database specification method at the conceptual level.","Transaction modeling, Transaction language design, Semantics, Rollback, ORM-method, Transaction verbalization",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kuribayashi K,,On the levels of maps and topological realization of objects in a triangulated category,Journal of Pure and Applied Algebra,2012,216,4,752-765,,,,,2012,,0022-4049,https://www.sciencedirect.com/science/article/pii/S002240491100212X;http://dx.doi.org/10.1016/j.jpaa.2011.08.009,10.1016/j.jpaa.2011.08.009,"The level of a module over a differential graded algebra measures the number of steps required to build the module in an appropriate triangulated category. Based on this notion, we introduce a new homotopy invariant of spaces over a fixed space, called the level of a map. Moreover, we provide a method to compute the invariant for spaces over a K-formal space. This enables us to determine the level of the total space of a bundle over the 4-dimensional sphere with the aid of Auslander–Reiten theory for spaces due to Jørgensen. We also discuss the problem of realizing an indecomposable object in the derived category of the sphere by the singular cochain complex of a space. The Hopf invariant provides a criterion for the realization.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ritter E,Pym D,Wallen L",,On the intuitionistic force of classical search,Theoretical Computer Science,2000,232,1,299-333,,,,,2000,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397599001784;http://dx.doi.org/10.1016/S0304-3975(99)00178-4,10.1016/S0304-3975(99)00178-4,"The combinatorics of classical propositional logic lies at the heart of both local and global methods of proof-search enabling the achievement of least-commitment search. Extension of such methods to the predicate calculus, or to non-classical systems, presents us with the problem of recovering this least-commitment principle in the context of non-invertible rules. One successful approach is to view the non-classical logic as a perturbation on search in classical logic and characterize when a least-commitment (classical) search yields sufficient evidence for provability in the (non-classical) logic. This technique has been successfully applied to both local and global methods at the cost of subsidiary searches and is the analogue of the standard treatment of quantifiers via skolemization and unification. In this paper, we take a type-theoretic view of this approach for the case in which the non-classical logic is intuitionistic. We develop a system of realizers (proof-objects) for sequents in classical propositional logic (the types) by extending Parigot's λμ-calculus, a system of realizers for classical free deduction (cf. natural deduction). Our treatment of disjunction exploits directly the multiple-conclusioned form of LK as opposed to the single-conclusioned form of LJ. Consequently, it requires the addition of another binding operator, called ν, to λμ. This choice is motivated by our concern to reflect the properties of classical proof-search in the system of realizers. Using this framework, we illustrate the sense in which intuitionistic search can be viewed as a perturbation on classical search. As an application, we develop a proof procedure based on the natural extension of the notion of uniform proof to the multiple-conclusioned classical sequent calculus Harrop fragment of intuitionistic logic. This paper develops the proof-theoretic aspects of the approach.","Classical search, Intuitionistic logic, -calculus, Uniform proof",,,,,,,,,,,,,,,,,,,,,
Journal Article,Wille R,,Concept lattices and conceptual knowledge systems,Computers & Mathematics with Applications,1992,23,6,493-515,,,,,1992,,0898-1221,https://www.sciencedirect.com/science/article/pii/0898122192901207;http://dx.doi.org/10.1016/0898-1221(92)90120-7,10.1016/0898-1221(92)90120-7,"“Concept Lattice” is the central notion of “Formal Concept Analysis”, a new area of research which is based on a set-theoretical model for concepts and conceptual hierarchies. This model yields not only a new approach to data analysis but also methods for formal representation of conceptual knowledge. These methods are outlined on three levels. First, basics on concept lattices are explained starting from simple data contexts which consist of a binary relation between objects and attributes indicating which object has which attribute. On the second level, conceptual relationships are discussed for data matrices which assign attribute values to each of the given objects. Finally, a mathematical model for conceptual knowledge systems is described. This model allows us to study mathematically the representation, inference, acquisition, and communication of conceptual knowledge.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cansado A,Henrio L,Madelaine E",,Transparent First-class Futures and Distributed Components,Electronic Notes in Theoretical Computer Science,2010,260,,155-171,,,,,2010,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066109005180;http://dx.doi.org/10.1016/j.entcs.2009.12.036,10.1016/j.entcs.2009.12.036,"Futures are special kind of values that allow the synchronisation of different processes. Futures are in fact identifiers for promised results of function calls that are still awaited. When the result is necessary for the computation, the process is blocked until the result is returned. We are interested in this paper in transparent first-class futures, and their use within distributed components. We say that futures are transparent if the result is automatically and implicitly awaited upon the first access to the value; and that futures are first-class if they can be transmitted between components as usual objects. Thus, because of the difficulty to identify future objects, analysing the behaviour of components using first-class transparent futures is challenging. This paper contributes with first a static representation for futures, second a means to detect local deadlocks in a component system with first class futures, and finally extensions to interface definitions in order to avoid such deadlocks.","Hierarchical components, distributed asynchronous components, formal verification, behavioural specification, model-checking, specification language",Proceedings of the 5th International Workshop on Formal Aspects of Component Software (FACS 2008),,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee JK,Lee J,Jeong YS,Sheward H,Sanguinetti P,Abdelmohsen S,Eastman CM",,Development of space database for automated building design review systems,Automation in Construction,2012,24,,203-212,,,,,2012,,0926-5805,https://www.sciencedirect.com/science/article/pii/S0926580512000441;http://dx.doi.org/10.1016/j.autcon.2012.03.002,10.1016/j.autcon.2012.03.002,"This paper presents the design and implementation of space database for developing automated building design review systems. We have developed a set of four software modules for reviewing different aspects of a specific building type — US Courthouses. IFC (Industry Foundation Classes) provides the common building model schema from which these analyses are carried out. Space objects, like other BIM-building objects, can carry their information-rich space objects and space use semantics internally to the model; we have used instead external space database to an easily supported information base. We describe the problem of space database, how space objects can be automatically organized and classified within BIM systems based on their space database, and our reflection on best practices learned from application development. All the research and development features noted in this paper are implemented in a software plug-in module that constitutes a subset of other pre-processing operations and design review systems.","Building information modeling (BIM), Space database, Space semantics, BIM pre-processing, Building design review, Design rule checking, Industry Foundation Classes (IFC)",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferretti C,Mauri G,Păun G,Zandron C",,On three variants of rewriting P systems,Theoretical Computer Science,2003,301,1,201-215,,,,,2003,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397502005819;http://dx.doi.org/10.1016/S0304-3975(02)00581-9,10.1016/S0304-3975(02)00581-9,"We continue here the study of P systems with string objects processed by rewriting rules, by investigating some questions which are classic in formal language theory: leftmost derivation, conditional use of rules (permitting and forbidding conditions), relationships with language families in Chomsky and Lindenmayer hierarchies.","Membrane computing, Regulated rewriting, Chomsky hierarchy, Lindenmayer systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Beaubouef T,Petry FE,Ladner R",,Spatial data methods and vague regions: A rough set approach,Applied Soft Computing,2007,7,1,425-440,,,,,2007,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494605000839;http://dx.doi.org/10.1016/j.asoc.2004.11.003,10.1016/j.asoc.2004.11.003,"Uncertainty management has been considered essential for real world applications, and spatial data and geographic information systems in particular require some means for managing uncertainty and vagueness. Rough sets have been shown to be an effective tool for data mining and uncertainty management in databases. The 9-intersection, region connection calculus (RCC) and egg–yolk methods have proven useful for modeling topological relations in spatial data. In this paper, we apply rough set definitions for topological relationships based on the 9-intersection, RCC and egg–yolk models for objects with broad boundaries. We show that rough sets can be used to express and improve on topological relationships and concepts defined with these models.","Rough sets, Spatial data, Uncertainty, Vague regions",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ekenberg L,Johannesson P",,A framework for determining design correctness,Knowledge-Based Systems,2004,17,7,249-262,,,,,2004,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705104000462;http://dx.doi.org/10.1016/j.knosys.2004.07.003,10.1016/j.knosys.2004.07.003,"Quality is one of the main concerns in today's systems and software development and use. One important instrument in verification is the use of formal methods, which means that requirements and designs are analyzed formally to determine their relationships. Furthermore, since professional software design is to an increasing extent a distributed process, the issue of integrating different systems to an entity is of great importance in modern system development and design. Various candidates for formalizing system development and integration have prevailed, but very often, particularly for dynamic conflict detection, these introduce non-standard objects and formalisms, leading to severe confusion, both regarding the semantics and the computability. In contrast to such, we introduce a framework for defining requirement fulfillment by designs, detecting conflicts of various kinds as well as integration of heterogeneous schemata. The framework introduced transcends ordinary logical consequence, as it takes into account static and dynamic aspects of design consistency and, in particular, the specific features of the state space of a specification. Another feature of the approach is that it provides a unifying framework for design conflict analysis and schema integration.","Schema integration, Conflict detection, Legacy system, Formal methods, Software development",Special issue on Legacy systems and software change,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kara E,Traquair M,Simsek M,Kantarci B,Khan S",,Holistic design for deep learning-based discovery of tabular structures in datasheet images,Engineering Applications of Artificial Intelligence,2020,90,,103551,,,,,2020,,0952-1976,https://www.sciencedirect.com/science/article/pii/S0952197620300440;http://dx.doi.org/10.1016/j.engappai.2020.103551,10.1016/j.engappai.2020.103551,"Extracting data from tabular structures contained within product datasheets is crucial in many contexts, particularly in the management and optimization of supply chains that serve various industries. In order to minimize human intervention, table detection and table structure detection form the essential functionality. However, a self-contained holistic solution to extract the tables as well as their columns and rows in not readily available. To address this challenge, This study presents a new formal procedure that consists of the following sequence: table detection, structure segmentation and holistic tabular structure detection on documents. The proposed table detection model outperforms the state-of-the-art solutions by achieving a recall value of 1.0 and a precision of more than 0.99 on public competition datasets. Furthermore, this work introduces a judging mechanism and an agreement-based post-processing procedure to incorporate hand-crafted rules into the deep learning models. Though the individual components achieve a new state-of-the-art F1-Score, when integrated the best achieved F-measure for the holistic system is 0.89.","Deep learning, Image processing, Document processing, Table detection, Tabular data extraction, Page object detection, Structure detection",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Costagliola G,Delucia A,Orefice S,Polese G",,A Classification Framework to Support the Design of Visual Languages,Journal of Visual Languages & Computing,2002,13,6,573-600,,,,,2002,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X0290234X;http://dx.doi.org/10.1006/jvlc.2002.0234,10.1006/jvlc.2002.0234,"An important step in the design of visual languages is the specification of the graphical objects and the composition rules for constructing feasible visual sentences. The presence of different typologies of visual languages, each with specific graphical and structural characteristics, yields the need to have models and tools that unify the design steps for different types of visual languages. To this aim, in this paper we present a formal framework of visual language classes. Each class characterizes a family of visual languages based upon the nature of their graphical objects and composition rules. The framework has been embedded in the Visual Language Compiler–Compiler (VLCC), a graphical system for the automatic generation of visual programming environments.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Snaprud M,Jörgl HP,Kaindl H",,A Frame-Based Representation of the System Identification Procedure,IFAC Proceedings Volumes,1993,26,"2, Part 4",1101-1106,,,,,1993,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017486411;http://dx.doi.org/10.1016/S1474-6670(17)48641-1,10.1016/S1474-6670(17)48641-1,"A frame-based representation of the identification process of linear systems (ID-loop) for the purpose of automation has been developed. A formal representation was elaborated not only for the steps of the ID-loop themselves, but also for the detailed dependencies between the steps. A description of its features and the lessons learned in the course of its development are presented in this paper. The ID-loop is modelled as a sequence of steps. A generic step has been designed in order to use inheritance in the representation. The relevant data have been modelled and structured. The ontology in the frame-based representation is outlined. A hypertextbased tool has been developed to support the process of knowledge acquisition. The evolution of the knowledge representation from an informal to a formal one using a semiformal mediating representation is described.","System identification, knowledge-based systems, frame-based knowledge representation, hypertext","12th Triennal Wold Congress of the International Federation of Automatic control. Volume 4 Applications II, Sydney, Australia, 18-23 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Jahangard-Rafsanjani A,Mirian-Hosseinabadi SH",,Lightweight formalization and validation of ORM models,Journal of Logical and Algebraic Methods in Programming,2015,84,4,534-549,,,,,2015,,2352-2208,https://www.sciencedirect.com/science/article/pii/S235222081500019X;http://dx.doi.org/10.1016/j.jlamp.2015.03.001,10.1016/j.jlamp.2015.03.001,"ORM (Object Role Modeling) is a rich and popular conceptual modeling method. ORM has been used for data modeling, ontology engineering, modeling business rules, XML-Schemes and data warehouses, requirements engineering and web forms. Automated reasoning like satisfiability testing allows developers to detect modeling mistakes in the early stages of development. In this paper we propose a lightweight formalization of the ORM meta-model in Alloy. Using this meta-model as a toolkit one can easily specify ORM models in Alloy and verify various properties on them using the Alloy Analyzer. In order to achieve scalability, we use the cardinality of concepts to model their population. This increases the scalability of the approach dramatically. To show an application of the meta-model we formalize some unsatisfiability patterns and check them on the Alloy representation of the ORM model.","Formal specification, Object-role modeling, Satisfiability checking",Automated Specification and Verification of Web Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Srivastava HM,Chandel RC,Vishwakarma PK",,Fractional Derivatives of Certain Generalized Hypergeometric Functions of Several Variables,Journal of Mathematical Analysis and Applications,1994,184,3,560-572,,,,,1994,,0022-247X,https://www.sciencedirect.com/science/article/pii/S0022247X84712212;http://dx.doi.org/10.1006/jmaa.1994.1221,10.1006/jmaa.1994.1221,The main object of the present paper is to derive a number of key formulas for the fractional derivatives of the multivariable H-function (which is defined by a multiple contour integral of Mellin-Barnes type). Each of these formulas can be shown to yield interesting new results for various classes of generalized hypergeometric functions of several variables. Some of these applications of the key formulas provide potentially useful generalizations of known results in the theory of fractional calculus.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kim S,Kim DK,Lu L,Song E",,Building hybrid access control by configuring RBAC and MAC features,Information and Software Technology,2014,56,7,763-792,,,,,2014,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584914000378;http://dx.doi.org/10.1016/j.infsof.2014.02.003,10.1016/j.infsof.2014.02.003,"Context Role-Based Access Control (RBAC) and Mandatory Access Control (MAC) are widely used access control models. They are often used together in domains where both data integrity and information flow are concerned. However, there is little work on techniques for building hybrid access control of RBAC and MAC. Objective In this work, we present a systematic approach for developing a hybrid access control model using feature modeling with the aim of reducing development complexity and error-proneness. Method In the approach, RBAC and MAC are defined in terms of features based on partial inheritance. Features are then configured for specific access control requirements of an application. Configured features are composed homogeneously and heterogeneously to produce a hybrid access model for the application. The resulting hybrid model is then instantiated in the context of the application to produce an initial design model supporting both RBAC and MAC. We evaluate the approach using a hospital system and present its tool support. Results RBAC and MAC features that are specifically configured for the application are systematically incorporated into a design model. The heterogeneous features of RBAC and MAC are not only present in the resulting model, but also semantically composed for seamless integration of RBAC and MAC. Discharging the proof obligations of composition rules to the resulting model proves its correctness. The successful development of the prototype demonstrates its practicality. Conclusion Features in the access control domain are relatively small in size and are suitable to be defined as design building blocks. The formal definition of partial inheritance and composition methods in the presented approach enables precisely specifying access control features and feature configuration, which paves the way for systematic development of a hybrid access control model in an early development phase.","Feature modeling, Hybrid access control, MAC, RBAC, UML",,,,,,,,,,,,,,,,,,,,,
Journal Article,Leroux P,,Ennea-algebras,Journal of Algebra,2004,281,1,287-302,,,,,2004,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869304003357;http://dx.doi.org/10.1016/j.jalgebra.2004.06.022,10.1016/j.jalgebra.2004.06.022,"A generalisation of a recent work of M. Aguiar and J.-L. Loday on quadrialgebras called t-ennea-algebras constructed over dendriform trialgebras is proposed. Such algebras allow the construction of nested dendriform trialgebras and are related to pre-Lie algebras, t-infinitesimal bialgebras and t-Baxter operators. We also show that the augmented free t-ennea-algebra has a structure of connected Hopf algebra. In the last part, we use Baxter operators to produce formal deformations of dendriform algebras, quadrialgebras and ennea-algebras. Examples and relations of this work to combinatorial objects are given.","Nested dendriform trialgebras, -ennea-algebras, Quadri-algebras, -Baxter operators, -infinitesimal bialgebras, Left pre-Lie algebras, Operads, Connected Hopf algebras, Formal deformations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Miller P,Becker A,Kalé L",,Using shared arrays in message-driven parallel programs,Parallel Computing,2012,38,1,66-74,,,,,2012,,0167-8191,https://www.sciencedirect.com/science/article/pii/S0167819111001360;http://dx.doi.org/10.1016/j.parco.2011.10.005,10.1016/j.parco.2011.10.005,"This paper describes a safe and efficient combination of the object-based message-driven execution and shared array parallel programming models. In particular, we demonstrate how this combination engenders the composition of loosely coupled parallel modules safely accessing a common shared array. That loose coupling enables both better flexibility in parallel execution and greater ease of implementing multi-physics simulations. As a case study, we describe how the parallelization of a new method for molecular dynamics simulation benefits from both of these advantages. We also describe a system of typed handle objects that embed some of the determinacy constraints of the Multiphase Shared Array programming model in the C++ type system, to catch some violations at compile time. The combined programming model communicates in terms of these handles as a natural means of detecting and preventing errors.","Parallel programming models, Composition, Distributed shared arrays, Asynchronous execution",Extensions for Next-Generation Parallel Programming Models,,,,,,,,,,,,,,,,,,,,
Journal Article,"Khoshafian S,Briggs T",,Schema design and mapping strategies for persistent object models,Information and Software Technology,1988,30,10,606-616,,,,,1988,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584988901176;http://dx.doi.org/10.1016/0950-5849(88)90117-6,10.1016/0950-5849(88)90117-6,"A formal model is presented for a conceptual schema of persistent object models that support a strong notion of object identity. The object constructors in the model are sets, tuples, and disjunct. The databases that correspond to such schemata are graph-structured object spaces. These conceptual object spaces are mapped onto physical object spaces, which are typically forests of trees. The characteristics of the physical schemata are discussed and an algorithm to transform a conceptual schema into a physical schema is given.","object space, object identity, object models, schema design, mapping strategies",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aiash M,Loo J",,An integrated authentication and authorization approach for the network of information architecture,Journal of Network and Computer Applications,2015,50,,73-79,,,,,2015,,1084-8045,https://www.sciencedirect.com/science/article/pii/S1084804514001349;http://dx.doi.org/10.1016/j.jnca.2014.06.004,10.1016/j.jnca.2014.06.004,"Several projects propose an information centric approach to the network of the future. Such an approach makes efficient content distribution possible by making information retrieval host-independent and integration into the network storage for caching information. Requests for particular content can, thus, be satisfied by any host or server holding a copy. One well-established approach of information centric networks is the Network of Information (NetInf) architecture, developed as part of the EU FP7 project SAIL. The approach is based on the Publish/Subscribe model, where hosts can join a network, publish data, and subscribe to publications. The NetInf introduces two main stages namely, the Publication and Data Retrieval through which hosts publish and retrieve data. Also, a distributed Name Resolution System (NRS) has been introduced to map the data to its publishers. The NRS is vulnerable to masquerading and content poisoning attacks through invalid data registration. Therefore, the paper proposes a Registration stage to take place before the publication and data retrieval stage. This new stage will identify and authenticate hosts before being able to access the NetInf system. Furthermore, the Registration stage uses (cap)abilities-based access policy to mitigate the issue of unauthorized access to data objects. The proposed solutions have been formally verified using formal methods approach.","Network of information, Information centric networks, Formal methods, Authentication, Authorization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Küster Filipe Bowles J,Caminati MB",,Correct composition in the presence of behavioural conflicts and dephasing,Science of Computer Programming,2020,185,,102323,,,,,2020,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642318301072;http://dx.doi.org/10.1016/j.scico.2019.102323,10.1016/j.scico.2019.102323,"Scenarios of execution are commonly used to specify partial behaviour and interactions between different objects and components in a system. To avoid overall inconsistency in specifications, various automated methods have emerged in the literature to compose scenario-based models. In recent work, we have shown how the theorem prover Isabelle/HOL can be combined with an SMT solver to detect inconsistencies between sequence diagrams and, only in their absence, generate the behavioural composition. In this paper, we exploit this combination further and present an efficient approach that generates all valid composed traces giving us an equivalent representation of the conflict-free valid composed model. In addition, we show a novel way to prove the correctness of the computed results, and compare this method with the implementation and verification done within Isabelle alone. To reduce the complexity of our technique, we consider priority constraints and a notion of dephased models, i.e., models which start execution at different times. This work has been inspired by a problem from a medical domain where different clinical guidelines for chronic conditions may be applied to the same patient at different points in time. We illustrate the approach with a realistic example from this domain.","Formal methods, SMT solver, Theorem prover, Model composition, Optimisation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yu B,Sen R,Jeong DH",,An integrated framework for managing sensor data uncertainty using cloud computing,Information Systems,2013,38,8,1252-1268,,,,,2013,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437911001736;http://dx.doi.org/10.1016/j.is.2011.12.003,10.1016/j.is.2011.12.003,"In recent years, an increasing number of data-intensive applications deal with continuously changing data objects (CCDOs), such as data streams from sensors and tracking devices. In these applications, the underlying data management system must support new types of spatiotemporal queries that refer to the spatiotemporal trajectories of the CCDOs. In contrast to traditional data objects, CCDOs have continuously changing attributes. Therefore, the spatiotemporal relation between any two CCDOs can change over time. This problem can be more complicated, since the CCDO trajectories are associated with a degree of uncertainty at every point in time. This is due to the fact that databases can only be discretely updated. The paper formally presents a comprehensive framework for managing CCDOs with insights into the spatiotemporal uncertainty problem and presents an original parallel-processing solution for efficiently managing the uncertainty using the map-reduce platform of cloud computing.","Spatiotemporal Databases, Map-reduce, Cloud computing, Sensors, GPS, Parallel processing",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Riehl E,Verity D",,Fibrations and Yoneda's lemma in an ∞-cosmos,Journal of Pure and Applied Algebra,2017,221,3,499-564,,,,,2017,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404916301001;http://dx.doi.org/10.1016/j.jpaa.2016.07.003,10.1016/j.jpaa.2016.07.003,"We use the terms ∞-categories and ∞-functors to mean the objects and morphisms in an ∞-cosmos: a simplicially enriched category satisfying a few axioms, reminiscent of an enriched category of fibrant objects. Quasi-categories, Segal categories, complete Segal spaces, marked simplicial sets, iterated complete Segal spaces, θn-spaces, and fibered versions of each of these are all ∞-categories in this sense. Previous work in this series shows that the basic category theory of ∞-categories and ∞-functors can be developed only in reference to the axioms of an ∞-cosmos; indeed, most of the work is internal to the homotopy 2-category, a strict 2-category of ∞-categories, ∞-functors, and natural transformations. In the ∞-cosmos of quasi-categories, we recapture precisely the same category theory developed by Joyal and Lurie, although our definitions are 2-categorical in natural, making no use of the combinatorial details that differentiate each model. In this paper, we introduce cartesian fibrations, a certain class of ∞-functors, and their groupoidal variants. Cartesian fibrations form a cornerstone in the abstract treatment of “category-like” structures a la Street and play an important role in Lurie's work on quasi-categories. After setting up their basic theory, we state and prove the Yoneda lemma, which has the form of an equivalence between the quasi-category of maps out of a representable fibration and the quasi-category underlying the fiber over its representing element. A companion paper will apply these results to establish a calculus of modules between ∞-categories, which will be used to define and study pointwise Kan extensions along ∞-functors.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Seki H,Nagao M",,Parallel algorithms for enumerating closed patterns from multi-relational data,Discrete Applied Mathematics,2018,249,,120-134,,,,,2018,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X18301884;http://dx.doi.org/10.1016/j.dam.2018.03.080,10.1016/j.dam.2018.03.080,"This paper presents parallel algorithms for enumerating closed patterns from multi-relational data. In multi-relational data mining (MRDM), patterns are represented in logical formulae, and involve multiple tables (relations) from a relational database. Since the expressive framework of MRDM makes the task of pattern mining costly compared with the conventional itemset mining, we propose parallel algorithms for computing closed patterns on multi-core processors. In particular, we present new load-balancing strategies which try to fully exploit the task-parallelism intrinsic in the search process of the problem, and give some experimental results, which show the effectiveness of the proposed methods. We then apply our proposed methods to compute closed patterns, a.k.a. concept intents, for binary object-attribute relational data, and show by experiments that the performance of our method is comparable to the existing method.","Multi-relational data mining, Formal concept analysis, Closed patterns, Parallel algorithm, Load-balancing",Concept Lattices and Applications: Recent Advances and New Opportunities,,,,,,,,,,,,,,,,,,,,
Journal Article,Biskup J,,Boyce–Codd normal form and object normal forms,Information Processing Letters,1989,32,1,29-33,,,,,1989,,0020-0190,https://www.sciencedirect.com/science/article/pii/0020019089900653;http://dx.doi.org/10.1016/0020-0190(89)90065-3,10.1016/0020-0190(89)90065-3,"Ascribing uniqueness and independent existence to objects we formally define these properties for relational database schemes with functional dependencies. Arguing that minimal left-hand sides of functional dependencies should be considered as objects we introduce object normal forms. Finally, showing that object normal forms and Boyce–Codd normal form are closely related, we provide new insight into the achievements of the Boyce–Codd normal form.","Relational database, functional dependencies, schema design, normal forms, objects, Boyce–Codd normal form, object normal form",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bobbie PO,Papazoglou M",,Clustering PROLOG programs for distributed computations,Journal of Systems and Software,1991,16,3,205-218,,,,,1991,,0164-1212,https://www.sciencedirect.com/science/article/pii/016412129190015X;http://dx.doi.org/10.1016/0164-1212(91)90015-X,10.1016/0164-1212(91)90015-X,"A knowledge base (KB) is a collection of factual information pertaining to the objects of specialized domains or application areas. KB information may be acquired and represented using language paradigms which are based on formalisms of predicate calculus. Usually, the domains are not necessarily distinct due to the interrelatedness of the components of the problem or interdependency of the objects. Therefore, this interdependency could generate long search paths or references to the KB objects, particularly for large KB data. However, KB data can be reorganized into groups or clusters using some common relational information of the data objects. The reorganization process isolates the data into clusters and localizes the interdependency within the clusters. Therefore, the clusters offer opportunities for mapping the data into distributed or parallel processing environments to facilitate computational efficiency. This article focuses on methods for structuring, partitioning, and clustering logic-based KB data (rules and facts) for distributed computations.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Purvis M,Cranefield S,Ward R,Nowostawski M,Carter D,Bush G",,A multi-agent system for the integration of distributed environmental information,Environmental Modelling & Software,2003,18,6,565-572,,,,,2003,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815203000318;http://dx.doi.org/10.1016/S1364-8152(03)00031-8,10.1016/S1364-8152(03)00031-8,"This paper describes a multi-agent platform to be used for the integration of environmental information that may be distributed over a network. The system is designed to work as a collection of collaborating agents. Information sources are encapsulated as data source agents (DSAs) that accept messages in an agent communication language. Here we describe how queries can be entered into the system and information collected from multiple sources. A key component of the query module is the planner agent, which takes a query and transforms it first to a calculus, then to an algebraic expression in order to break it into subqueries which an executor agent can send to the DSAs. As part of this process, the query is translated from user-level ontologies to lower level ontologies relevant to the DSAs. Query results need not be returned within an ACL message, but may instead be represented by a Common Object Request Broker Architecture (CORBA) object reference which may be used to obtain the result set. The architecture and operation of these agent components is described and an example is presented of how environmental information can be queried.","Environmental information systems, Distributed systems, Information integration",Applying Computer Research to Environmental Problems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Michieli U,Zanuttigh P",,Knowledge distillation for incremental learning in semantic segmentation,Computer Vision and Image Understanding,2021,205,,103167,,,,,2021,,1077-3142,https://www.sciencedirect.com/science/article/pii/S1077314221000114;http://dx.doi.org/10.1016/j.cviu.2021.103167,10.1016/j.cviu.2021.103167,"Deep learning architectures have shown remarkable results in scene understanding problems, however they exhibit a critical drop of performances when they are required to learn incrementally new tasks without forgetting old ones. This catastrophic forgetting phenomenon impacts on the deployment of artificial intelligence in real world scenarios where systems need to learn new and different representations over time. Current approaches for incremental learning deal only with image classification and object detection tasks, while in this work we formally introduce incremental learning for semantic segmentation. We tackle the problem applying various knowledge distillation techniques on the previous model. In this way, we retain the information about learned classes, whilst updating the current model to learn the new ones. We developed four main methodologies of knowledge distillation working on both output layers and internal feature representations. We do not store any image belonging to previous training stages and only the last model is used to preserve high accuracy on previously learned classes. Extensive experimental results on the Pascal VOC2012 and MSRC-v2 datasets show the effectiveness of the proposed approaches in several incremental learning scenarios.","Incremental learning, Continual learning, Semantic segmentation, Catastrophic forgetting, Knowledge distillation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Eijkhout V,,"International Conference on Computational Science, ICCS 2012 A Theory of Data Movement in Parallel Computations",Procedia Computer Science,2012,9,,236-245,,,,,2012,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050912001469;http://dx.doi.org/10.1016/j.procs.2012.04.025,10.1016/j.procs.2012.04.025,"We propose a set-theoretic model for parallelism. The model is based on separate distributions of data and work. The major theoretic result is that communication can then be derived by formal reasoning. While the model has an immediate interpretation in distributed memory parallelism, we show that it can also accomodate multicore shared memory programming, as well as clusters with accelerators. The model gives rise in a natural way to objects that resemble the VecScatter construct in the PETSc library, or active messages in such packages as Charm++. Thus we argue that the model offers the prospect of an abstract programming system that can be compiled down to proven high-performance constructs.","Parallel Programming, Programming models","Proceedings of the International Conference on Computational Science, ICCS 2012",,,,,,,,,,,,,,,,,,,,
Journal Article,Garner R,,Combinatorial structure of type dependency,Journal of Pure and Applied Algebra,2015,219,6,1885-1914,,,,,2015,,0022-4049,https://www.sciencedirect.com/science/article/pii/S002240491400200X;http://dx.doi.org/10.1016/j.jpaa.2014.07.015,10.1016/j.jpaa.2014.07.015,"We give an account of the basic combinatorial structure underlying the notion of type dependency. We do so by considering the category of generalised algebraic theories in the sense of Cartmell, and exhibiting it as the category of algebras for a monad on a presheaf category. The objects of the presheaf category encode the basic judgements of a dependent sequent calculus, while the action of the monad encodes the deduction rules; so by giving an explicit description of the monad, we obtain an explicit account of the combinatorics of type dependency. We find that this combinatorics is controlled by a particular kind of decorated ordered tree, familiar from computer science and from innocent game semantics. Furthermore, we find that the monad at issue is of a particularly well-behaved kind: it is local right adjoint in the sense of Street–Weber. In future work, we will use this fact to describe nerves for dependent type theories, and to study the coherence problem for dependent type theory using the tools of two-dimensional monad theory.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wazid M,Das AK,Bhat K V,Vasilakos AV",,LAM-CIoT: Lightweight authentication mechanism in cloud-based IoT environment,Journal of Network and Computer Applications,2020,150,,102496,,,,,2020,,1084-8045,https://www.sciencedirect.com/science/article/pii/S108480451930356X;http://dx.doi.org/10.1016/j.jnca.2019.102496,10.1016/j.jnca.2019.102496,"Internet of Things (IoT) becomes a new era of the Internet, which consists of several connected physical smart objects (i.e., sensing devices) through the Internet. IoT has different types of applications, such as smart home, wearable devices, smart connected vehicles, industries, and smart cities. Therefore, IoT based applications become the essential parts of our day-to-day life. In a cloud-based IoT environment, cloud platform is used to store the data accessed from the IoT sensors. Such an environment is greatly scalable and it supports real-time event processing which is very important in several scenarios (i.e., IoT sensors based surveillance and monitoring). Since some applications in cloud-based IoT are very critical, the information collected and sent by IoT sensors must not be leaked during the communication. To accord with this, we design a new lightweight authentication mechanism in cloud-based IoT environment, called LAM-CIoT. By using LAM-CIoT, an authenticated user can access the data of IoT sensors remotely. LAM-CIoT applies efficient “one-way cryptographic hash functions” along with “bitwise XOR operations”. In addition, fuzzy extractor mechanism is also employed at the user's end for local biometric verification. LAM-CIoT is methodically analyzed for its security part through the formal security using the broadly-accepted “Real-Or-Random (ROR)” model, formal security verification using the widely-used “Automated Validation of Internet Security Protocols and Applications (AVISPA)” tool as well as the informal security analysis. The performance analysis shows that LAM-CIoT offers better security, and low communication and computation overheads as compared to the closely related authentication schemes. Finally, LAM-CIoT is evaluated using the NS2 network simulator for the measurement of network performance parameters that envisions the impact of LAM-CIoT on the network performance of LAM-CIoT and other schemes.","Internet of Things (IoT), Cloud computing, Authentication, Key agreement, Security, AVISPA simulation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gadeyne K,Pinte G,Berx K",,Describing the design space of mechanical computational design synthesis problems,Advanced Engineering Informatics,2014,28,3,198-207,,,,,2014,,1474-0346,https://www.sciencedirect.com/science/article/pii/S1474034614000329;http://dx.doi.org/10.1016/j.aei.2014.03.004,10.1016/j.aei.2014.03.004,"An important challenge in mechatronic system design is to select a feasible system architecture that satisfies all requirements. This article describes (i) the necessary concepts that a system architect needs to be able to formally and declaratively describe the design space of mechanical design synthesis problems, thereby minimizing accidental complexity; (ii) how a Domain Specific Language based on the SysML modeling language and the Object Constraint Language (OCL) can be used to create this model of the design space; and (iii) an iterative process to come up with a formal model of the design space. This model describes the design space independent of any (knowledge of a) particular solving technology for the Design Space Exploration. Furthermore, the information in the model allows to select the most appropriate solving strategy for a particular design synthesis problem. The different concepts are illustrated on the example of automated synthesis of a gearbox.","Gearbox architecture, Design Space Exploration, Configuration design, Variant design, Computational design synthesis, Embodiment design",Multiview Modeling for Mechatronic Design,,,,,,,,,,,,,,,,,,,,
Book Chapter,"van Hee KM,Somers LJ,Voorhoeve M","Sol HG,Van Hee KM",A FORMAL FRAMEWORK FOR DYNAMIC MODELLING OF INFORMATION SYSTEMS,,1991,,,227-236,,North-Holland,Amsterdam,Dynamic Modelling of Information Systems,1991,9780444889232,,https://www.sciencedirect.com/science/article/pii/B9780444889232500112;http://dx.doi.org/10.1016/B978-0-444-88923-2.50011-2,10.1016/B978-0-444-88923-2.50011-2,"Abstract An information system (IS) maintains information about some other system, called object system. In the first phase of information systems development, the object system, the IS environment and the IS itself must be described. These descriptions must be formal in order to avoid incompleteness or ambiguity. A formal description can be interpreted by a machine, leading to a simulation model or prototype of the described system. We present a formal framework for describing systems, called ExSpect. This framework consists of a metamodel akin to Petri nets for representing dynamic systems and a functional part for the definition of data structures and functions. The framework is supported by a software tool for creating, checking and interpreting the described systems. The present paper concentrates on using ExSpect for feasibility study, requirements engineering, cost-benefit analysis and change analysis of the object system.","Dynamic modelling, formal specification, prototyping, simulation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Vivarès F,,Modelling Jackson's programming method,Science of Computer Programming,1993,20,3,173-204,,,,,1993,,0167-6423,https://www.sciencedirect.com/science/article/pii/016764239390013F;http://dx.doi.org/10.1016/0167-6423(93)90013-F,10.1016/0167-6423(93)90013-F,"The aim of this paper is to present a modelling scheme for programming methods and to illustrate it on Jackson's programming method. We first give a formal semantics to the objects of this method and we model the basic strategy of matching trees in order to build a program structure. In the next section we study how to support a formal development, its automatization, and the building of a formal specification within the scope of our model. Then an example is developed. The last section addresses alternative strategies suggested by the method in order to solve clash problems, where the basic strategy fails. Boundary and ordering clash situations are presented and their strategies are modelled.","Method, formal development, modelling, Jackson's method, structure clashes, rational transduction",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Yeun YS,Yang YS",,Design knowledge representation and control for the structural design of ships,Knowledge-Based Systems,1997,10,2,121-132,,,,,1997,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705197000208;http://dx.doi.org/10.1016/S0950-7051(97)00020-8,10.1016/S0950-7051(97)00020-8,"Our main concern is to identify the major issues related to representing and controlling design knowledge for large scale structures such as ships in routine parametric redesign. In our view, the most difficult problems can occur in the complexity of representing the design object and the need for a formal way of describing rules for classification that play the most important role in providing design expertise used for the structural design of ships. Hence, we present a complex object-based knowledge representation whose key feature is that the contents of all the knowledge-base, including the design process, are expressed only by objects and classes. Also, we devise an inference mechanism, called the CORE (complex object-based inference) mechanism, that is based on a hypothesis-object. To illustrate how the CORE mechanism works in a realistic domain, design systems for the deck structure and midship section of bulk cargo ships are implemented, and some running examples are presented.","Ship structural design, Complex object-based knowledge representation, Complex object-based inference mechanism, Hypothesis-object",,,,,,,,,,,,,,,,,,,,,
Journal Article,Stefański TP,,On possible applications of media described by fractional-order models in electromagnetic cloaking,Communications in Nonlinear Science and Numerical Simulation,2021,99,,105827,,,,,2021,,1007-5704,https://www.sciencedirect.com/science/article/pii/S1007570421001386;http://dx.doi.org/10.1016/j.cnsns.2021.105827,10.1016/j.cnsns.2021.105827,"The purpose of this paper is to open a scientific discussion on possible applications of media described by fractional-order (FO) models (FOMs) in electromagnetic cloaking. A 2-D cloak based on active sources and the surface equivalence theorem is simulated. It employs a medium described by FOM in communication with sources cancelling the scattered field. A perfect electromagnetic active cloak is thereby demonstrated with the use of a finite-difference time-domain method combined with a simulation algorithm of non-monochromatic wave propagation in the media described by FOM. The application of constitutive relations based on FOMs in Maxwell’s equations provides solutions which correspond to the results reported for the time-fractional diffusion-wave equation, which is non-relativistic, like the classical diffusion equation. This property is employed in the presented cloaking scheme for communication with active current sources around the cloak, which cancel the scattered field of an object inside the cloak. Although in the real world perfect invisibility is impossible to obtain due to the constraint of light speed, it is possible to obtain a perfect cloak in theoretical considerations by using FO formulation of electromagnetism. It is worth noticing that numerous literature sources experimentally confirm the existence of electromagnetic media described by FOMs; hence, the presented numerical results should hopefully stimulate further investigations related to applications of FOMs in electromagnetic cloaking.","Electromagnetic cloaking, Wave propagation, Maxwell’s equations, Fractional calculus",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Stroyan KD,Stroyan KD,"CHAPTER 10 - Velocity, Acceleration and Calculus",,1993,,,161-168,,Academic Press,,Calculus Using Mathematica,1993,9780126729719,,https://www.sciencedirect.com/science/article/pii/B9780126729719500153;http://dx.doi.org/10.1016/B978-0-12-672971-9.50015-3,10.1016/B978-0-12-672971-9.50015-3,"Publisher Summary This chapter explores the connection between first and second order derivatives and basic mechanics. This is a non-graphical way to use and view these mathematical ideas, but they can also be related to graphs. The chapter provides a synoptic view of the connection between velocity and acceleration in terms of the principles of calculus. Physicists make an important distinction between speed and velocity. Velocity is speed plus direction, while speed is only the instantaneous time rate of change of distance traveled. When an object moves along a line, there are only two directions so velocity can simply be represented by speed with a sign, + or –.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Smolka G,Ait-Kaci H",,Inheritance hierarchies: Semantics and unification,Journal of Symbolic Computation,1989,7,3,343-370,,,,,1989,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717189800161;http://dx.doi.org/10.1016/S0747-7171(89)80016-1,10.1016/S0747-7171(89)80016-1,Inheritance hierarchies are introduced as a means of representing taxonomicallyorganized data. The hierarchies are built up from so-called feature types that are ordered by subtyping and whose elements are records. Every feature type comes with a set of features prescribing fields of its record elements. So-called feature terms are available to denote subsets of feature types. Feature unification is introduced as an operation that decides whether two feature terms have a nonempty intersection and computes a feature term denoting the intersection. We model our inheritance hierarchies as algebraic specifications in ordersortedequational logic using initial algebra semantics. Our framework integrates feature types whose elements are obtained as records with constructor types whose elements are obtained by constructor application. Unification in these hierarchies combines record unification with order-sorted term unification and is presented as constraint solving. We specify a unitary unification algorithm by a set of simplification rules and prove its soundness and completeness with respect to the model-theoretic semantics.,,Unification: Part 1,,,,,,,,,,,,,,,,,,,,
Journal Article,Fersi G,,A Distributed and Flexible Architecture for Internet of Things,Procedia Computer Science,2015,73,,130-137,,,,,2015,,1877-0509,https://www.sciencedirect.com/science/article/pii/S187705091503519X;http://dx.doi.org/10.1016/j.procs.2015.12.058,10.1016/j.procs.2015.12.058,"The great breakthrough in technological devices has lead to the migration of actual Internet to the Internet of Things. There are merely trillions of smart dynamic objects that will be connected to the Internet and that interact and collaborate together independently from any physical location. This progress necessitates the proposal of an adequate architecture and routing process. In this paper, we propose a novel design and overlay architecture that fulfills the Internet of Things requirements. This approach is mainly based on Distributed Hash Table protocols to afford the required flexiblity and to handle efficiently mobility and churn cases. We present also a formal study that proves the efficiency of our proposed architecture.","Internet of Things, architecture, design, DHT",International Conference on Advanced Wireless Information and Communication Technologies (AWICT 2015),,,,,,,,,,,,,,,,,,,,
Journal Article,"Hancock P,Hyvernat P",,Programming interfaces and basic topology,Annals of Pure and Applied Logic,2006,137,1,189-239,,,,,2006,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007205000710;http://dx.doi.org/10.1016/j.apal.2005.05.022,10.1016/j.apal.2005.05.022,"A pattern of interaction that arises again and again in programming is a “handshake”, in which two agents exchange data. The exchange is thought of as provision of a service. Each interaction is initiated by a specific agent—the client or Angel—and concluded by the other—the server or Demon. We present a category in which the objects—called interaction structures in the paper—serve as descriptions of services provided across such handshaken interfaces. The morphisms—called (general) simulations—model components that provide one such service, relying on another. The morphisms are relations between the underlying sets of the interaction structures. The proof that a relation is a simulation can serve (in principle) as an executable program, whose specification is that it provides the service described by its domain, given an implementation of the service described by its codomain. This category is then shown to coincide with the subcategory of “generated” basic topologies in Sambin’s terminology, where a basic topology is given by a closure operator whose induced sup-lattice structure need not be distributive; and moreover, this operator is inductively generated from a basic cover relation. This coincidence provides topologists with a natural source of examples for non-distributive formal topology. It raises a number of questions of interest both for formal topology and programming. The extra structure needed to make such a basic topology into a real formal topology is then interpreted in the context of interaction structures.","Constructive type theory, Predicate transformers, Simulation, Formal topology",,,,,,,,,,,,,,,,,,,,,
Journal Article,Landragin F,,"Visual perception, language and gesture: A model for their understanding in multimodal dialogue systems",Signal Processing,2006,86,12,3578-3595,,,,,2006,,0165-1684,https://www.sciencedirect.com/science/article/pii/S0165168406001368;http://dx.doi.org/10.1016/j.sigpro.2006.02.046,10.1016/j.sigpro.2006.02.046,"The way we see the objects around us determines speech and gestures we use to refer to them. The gestures we produce structure our visual perception. The words we use have an influence on the way we see. In this manner, visual perception, language and gesture present multiple interactions between each other. The problem is global and has to be tackled as a whole in order to understand the complexity of reference phenomena and to deduce a formal model. This model may be useful for any kind of human–machine dialogue system that focuses on deep comprehension. We show how a referring act takes place in a contextual subset of objects. This subset is called ‘reference domain’ and is implicit. It can be deduced from a lot of clues. Among these clues are those which come from the visual context and those which come from the multimodal utterance. We present the ‘multimodal reference domain’ model that takes these clues into account and that can be exploited in a multimodal dialogue system when interpreting.","Multimodal communication, Visual perception, Pointing gesture, Natural language processing, Reference to objects, Salience, Interpretation modeling",Special Section: Multimodal Human-Computer Interfaces,,,,,,,,,,,,,,,,,,,,
Journal Article,"Carchiolo V,Malgeri M,Mangioni G",,TTL: a modular language for hardware/software systems design,Journal of Computer and System Sciences,2003,66,2,293-315,,,,,2003,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000003000023;http://dx.doi.org/10.1016/S0022-0000(03)00002-3,10.1016/S0022-0000(03)00002-3,"The development of tools for the design of both hardware and software systems draws great benefits from the use of formal methods, especially if they offer a descriptive capacity which covers real applications. On the basis of the T-LOTOS language, a language called TTL has been developed, which adds new constructs and tools to the high expressiveness of the original language, thus making it suitable for the specification of hardware and software systems of real complexity. Some of the extension proposed and presented cover the aspects of modularization of the specification, the introduction of an iterative construct and a first move to object paradigma. An extensive example of the use of TTL is presented to show its characteristics. The features of TTL have been widely tested in the development of a framework for codesign.","Formal description techniques, Codesign",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kock A,,Taylor series calculus for ring objects of line type,Journal of Pure and Applied Algebra,1978,12,3,271-293,,,,,1978,,0022-4049,https://www.sciencedirect.com/science/article/pii/0022404987900065;http://dx.doi.org/10.1016/0022-4049(87)90006-5,10.1016/0022-4049(87)90006-5,,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Igor T,Sergey D,Ilya K",,Soft computing models in an intellectual open-pit mines transport control system,Procedia Computer Science,2017,120,,411-416,,,,,2017,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050917324699;http://dx.doi.org/10.1016/j.procs.2017.11.257,10.1016/j.procs.2017.11.257,"This article focuses on the development of control mechanisms of open pit mine robotized transport system. Method for the state of the technological roads identification with the use of fuzzy inference mechanisms is discussed. The structure of the control system is presented. The possibilities of the use of telemetry data for a wide range of important technological problems, which, anyway, are reduced to problems of interpretation of the data, object identification, forecasting of parameters and the interaction of robotic agents control are discussed. The examples of the formal setting of some of these problems which based on the soft computing are presented. Considered in detail the problem of identification of the open pit mine roadway. The procedure for organizing and conducting dump truck onboard experiments is described. The features of the main control parameters are analyzed. The mechanism of using the telemetry data processing in common with fuzzy inference tools is presented. The main stages of the experiment telemetry data processing are described.","open pit mine, mining, transport system robotized objects, identification, evaluation of the mining road state, telemetry data, fuzzy inference, learning mechanisms","9th International Conference on Theory and Application of Soft Computing, Computing with Words and Perception, ICSCCW 2017, 22-23 August 2017, Budapest, Hungary",,,,,,,,,,,,,,,,,,,,
Journal Article,"Wu TC,Leu SH,Tu ST,Srivastava HM",,A certain class of infinite sums associated with Digamma functions,Applied Mathematics and Computation,1999,105,1,1-9,,,,,1999,,0096-3003,https://www.sciencedirect.com/science/article/pii/S009630039810098X;http://dx.doi.org/10.1016/S0096-3003(98)10098-X,10.1016/S0096-3003(98)10098-X,"The sums of several interesting families of infinite series were recently expressed in terms of the Psi (or Digamma) functions. The main object of this paper is to present a further generalization of two such classes of infinite sums which were considered earlier by Al-Saqabi et al. (J. Math. Anal. Appl. 159 (1991) 361–372). Some other results, relevant to the present investigation, are also indicated.","Psi (or Digamma) function, Fractional calculus, Gauss hypergeometric function, Leibniz rule, Polygamma function, Hurwitz Zeta function",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Deng Z,Xiang Y",,Multistep planning for crowdsourcing complex consensus tasks,Knowledge-Based Systems,2021,231,,107447,,,,,2021,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705121007097;http://dx.doi.org/10.1016/j.knosys.2021.107447,10.1016/j.knosys.2021.107447,"Crowdsourcing receives massive vote information from non-expert workers, for finishing tasks that can hardly be handled by current technology of machine intelligence. Massive vote information and non-expert workers bring serious issues of labor costs and the efficiency of crowdsourcing. This paper focuses on the tasks, classifying objects in images or videos into a set of given candidates by letting workers vote on a set of options that characterize these candidates. Designing a good asking strategy, i.e., setting up the order of presenting the options to a worker and asking the worker whether an option is true or false, is one starting point to save labor costs and enhance efficiency of deciding the correct answer from the candidates. We propose the problem of determining the time steps of vote collection before stopping to set up the asking strategy. In terms of this problem, we establish a single-step collection based partially observable Markov decision process (POMDP) to analyze how a vote influences the whole system, for instance, influences the belief over each option. Formally define the multistep collection problem as the timed decision (TD) problem. We propose the MC-EVA algorithm based on Monte Carlo sampling to solve the TD problem. Evaluate the MC-EVA algorithm over three simple but typical cases and a real-world Galaxy Zoo 2 project. Experiments show MC-EVA’s great superiority in runtime over the state-of-the-art single-step collection algorithm, and its superiority in effectiveness than other multistep collection algorithms; show its labor cost saving and enhanced efficiency with the use of calculated asking strategies.","Crowdsourcing, POMDPs, Consensus tasks, Asking strategies, Timed decision (TD) problem, Monte Carlo sampling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Artikis A,Sergot M,Pitt J",,An executable specification of a formal argumentation protocol,Artificial Intelligence,2007,171,10,776-804,,,,,2007,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370207000707;http://dx.doi.org/10.1016/j.artint.2007.04.008,10.1016/j.artint.2007.04.008,"We present a specification, in the action language C+, of Brewka's reconstruction of a theory of formal disputation originally proposed by Rescher. The focus is on the procedural aspects rather than the adequacy of this particular protocol for the conduct of debate and the resolution of disputes. The specification is structured in three separate levels, covering (i) the physical capabilities of the participant agents, (ii) the rules defining the protocol itself, specifying which actions are ‘proper’ and ‘timely’ according to the protocol and their effects on the protocol state, and (iii) the permissions, prohibitions, and obligations of the agents, and the sanctions and enforcement strategies that deal with non-compliance. Also included is a mechanism by which an agent may object to an action by another participant, and an optional ‘silence implies consent’ principle. Although comparatively simple, Brewka's protocol is thus representative of a wide range of other more complex argumentation and dispute resolution procedures that have been proposed. Finally, we show how the ‘Causal Calculator’ implementation of C+ can be used to animate the specification and to investigate and verify properties of the protocol.","Argumentation, Disputation, Protocol, Norm, Multi-agent system, Specification, Action language",Argumentation in Artificial Intelligence,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rodenacker K,Bischoff P",,Quantification of tissue sections: Graph theory and topology as modelling tools,Pattern Recognition Letters,1990,11,4,275-284,,,,,1990,,0167-8655,https://www.sciencedirect.com/science/article/pii/016786559090066B;http://dx.doi.org/10.1016/0167-8655(90)90066-B,10.1016/0167-8655(90)90066-B,"Tissue sections consist of distributed objects, the nuclear profiles. A methodological tool box is presented, based on graph theory and topology, to describe formally the arrangement of such objects, to define agglomerations of objects in a hierarchical manner and to compute quantitative features for every object. For a set of tissue sections (conisates) from the cervix uteri, a model description and an evaluation are given.","Morphology, morphometry, graph theory, topology, histometry, modelling, pathology, image processing",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li S,Li X",,Study on Generation of Fault Trees from Altarica Models,Procedia Engineering,2014,80,,140-152,,,,,2014,,1877-7058,https://www.sciencedirect.com/science/article/pii/S1877705814011631;http://dx.doi.org/10.1016/j.proeng.2014.09.070,10.1016/j.proeng.2014.09.070,"With the increasing scale and complexity of modern systems, traditional safety analysis methods such as FTA, FMEA seem inconvenient to use. Automated safety analysis based on formal models has become popular. In this paper, we took the Altarica data-flow language as the research object, and specified how to extract failure logic relations from Altarica component models and system models to generate fault trees (FTs), and proved its validity through instance verification. Fault tree generation method proposed in this paper would provide a basis for the development of automated safety analysis tools based on Altarica.","Altarica, Altarica data-flow, fault tree, safety",3rd International Symposium on Aircraft Airworthiness (ISAA 2013),,,,,,,,,,,,,,,,,,,,
Journal Article,"Bodei C,Degano P,Nielson F,Riis Nielson H",,Static Analysis for the π-Calculus with Applications to Security,Information and Computation,2001,168,1,68-92,,,,,2001,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540100930207;http://dx.doi.org/10.1006/inco.2000.3020,10.1006/inco.2000.3020,"Control Flow Analysis is a static technique for predicting safe and computable approximations to the set of values that the objects of a program may assume during its execution. We present an analysis for the π-calculus that shows how names will be bound to actual channels at run time. The result of our analysis establishes a super-set of the set of channels to which a given name may be bound and of the set of channels that may be sent along a given channel. Besides a set of rules that permits one to validate a given solution, we also offer a constructive procedure that builds solutions in low polynomial time. Applications of our analysis include establishing two simple security properties of processes. One example is that P has no leaks: P offers communication to the external environment through public channels only and confines its secret channels within itself. The other example is connected to the no read-up/no write-down property of Bell and LaPadula: once processes are given levels of security clearance, we check that a process at a high level never sends channels to processes at a lower level.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Clementini E,Di Felice P,Califano G",,Composite regions in topological queries,Information Systems,1995,20,7,579-594,,,,,1995,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799500031X;http://dx.doi.org/10.1016/0306-4379(95)00031-X,10.1016/0306-4379(95)00031-X,"Spatial data are at the core of many scientific information systems. The design of suitable query languages for spatial data retrieval and analysis is still an issue on the cutting edge of research. The primary requirement of these languages is to support spatial operators. Unfortunately, current systems support only simplified abstractions of geographic objects based on simple regions which are usually not sufficient to deal with the complexity of the geographic reality. Composite regions, which are regions made up of several components, are necessary to overcome those limits. The paper introduces a two-level formal model suitable for representing topological relationships among composite regions. The contribution gives the needed formal background for adding composite regions inside a spatial query language with the purpose of answering topological queries on complex geographic objects.","Composite Regions, Topological Relationships, Spatial Query Languages, Extensible Database Systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,Miller D,,Forum: A multiple-conclusion specification logic,Theoretical Computer Science,1996,165,1,201-232,,,,,1996,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759600045X;http://dx.doi.org/10.1016/0304-3975(96)00045-X,10.1016/0304-3975(96)00045-X,"The theory of cut-free sequent proofs has been used to motivate and justify the design of a number of logic programming languages. Two such languages, λProlog and its linear logic refinement, Lolli [15], provide for various forms of abstraction (modules, abstract data types, and higher-order programming) but lack primitives for concurrency. The logic programming language, LO (Linear Objects) [2] provides some primitives for concurrency but lacks abstraction mechanisms. In this paper we present Forum, a logic programming presentation of all of linear logic that modularly extends λProlog, Lolli, and LO. Forum, therefore, allows specifications to incorporate both abstractions and concurrency. To illustrate the new expressive strengths of Forum, we specify in it a sequent calculus proof system and the operational semantics of a programming language that incorporates references and concurrency. We also show that the meta theory of linear logic can be used to prove properties of the object-languages specified in Forum.",,Fourth International Conference on Algebraic and Logic Programming,,,,,,,,,,,,,,,,,,,,
Journal Article,Niculescu V,,Cost-efficient parallel programs based on set-distributions for polynomial interpolation,Journal of Parallel and Distributed Computing,2007,67,8,935-946,,,,,2007,,0743-7315,https://www.sciencedirect.com/science/article/pii/S0743731507000615;http://dx.doi.org/10.1016/j.jpdc.2007.04.005,10.1016/j.jpdc.2007.04.005,"The paper presents parallel algorithms for Lagrange and Hermite interpolation methods formally derived from specifications, and using set-distributions. Set-distributions are based on set-valued mappings, and they assign a data object to more than one process. The derivation from specifications assures the correctness, and the set-distributions assure the efficiency of the programs. The obtained parallel algorithms have very good time complexities and speeds-up, and they are also cost-efficient. We consider the number of processes p to be a parameter of the algorithms, so, bounded parallelism is considered. The derivation of the algorithms is not ruled by any particular interconnection network. The possible mappings on different networks could be evaluated. The performance analysis is done considering a full-connected network, and other two interconnection networks: hypercube and multi-mesh hypercube, which preserve the cost-efficiency of the algorithms.","Parallel computation, Polynomial interpolation, Lagrange, Hermite, Data-distribution, Complexity, Cost, Efficiency, Formal derivation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lv X,He F,Yan X,Wu Y,Cheng Y",,Integrating selective undo of feature-based modeling operations for real-time collaborative CAD systems,Future Generation Computer Systems,2019,100,,473-497,,,,,2019,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X18323033;http://dx.doi.org/10.1016/j.future.2019.05.021,10.1016/j.future.2019.05.021,"In collaborative editing systems, selective undo is a fundamental function that allows dispersed users to undo any executed operation in the history. Most selective undo mechanisms have been applied in collaborative editing systems with simple objects (plain text or image). However, how to provide a selective undo mechanism for collaborative editing systems with complex objects (feature-based CAD model) has been a technical challenge. This paper proposes a novel CRDT (Conflict-free Replicated Data Type)-based selective undo mechanism for feature-based Co-CAD (Collaborative CAD) systems. Firstly, a selective undo framework is presented to integrate (do/undo) operations. Secondly, three constraint relations of (do/undo) operations are defined and feature-based conflict detection conditions are proposed to detect the three constraint relations. Thirdly, a CRDT-based conflict resolution approach is proposed to integrate (do/undo) operations. Fourthly, collaborative case studies illustrate how the selective undo mechanism works and achieves consistent results. Finally, the complexities in theory are analyzed and the formal proofs are provided to verify the correctness.","Consistency maintenance, OT (operational transformation), CRDT, Selective undo, Co-CAD",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fernández M,Gabbay MJ",,Nominal rewriting,Information and Computation,2007,205,6,917-965,,,,,2007,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540106001635;http://dx.doi.org/10.1016/j.ic.2006.12.002,10.1016/j.ic.2006.12.002,"Nominal rewriting is based on the observation that if we add support for α-equivalence to first-order syntax using the nominal-set approach, then systems with binding, including higher-order reduction schemes such as λ-calculus beta-reduction, can be smoothly represented. Nominal rewriting maintains a strict distinction between variables of the object-language (atoms) and of the meta-language (variables or unknowns). Atoms may be bound by a special abstraction operation, but variables cannot be bound, giving the framework a pronounced first-order character, since substitution of terms for variables is not capture-avoiding. We show how good properties of first-order rewriting survive the extension, by giving an efficient rewriting algorithm, a critical pair lemma, and a confluence theorem for orthogonal systems.","Binders, -Conversion, First and higher-order rewriting, Confluence",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aisbett J,Gibbon G",,A tunable distance measure for coloured solid models,Artificial Intelligence,1994,65,1,143-164,,,,,1994,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370294900396;http://dx.doi.org/10.1016/0004-3702(94)90039-6,10.1016/0004-3702(94)90039-6,"People are willing to rank simple objects of different shape and colour on the basis of “similarity”. If machines are to reason about structure, this comparison process must be formalized. That is, a distance measure between formal object representations must be defined. If the machine is reasoning with information to be presented to a human, the distance measure needs to accord with human notions of object similarity. Since our perception of similarity is subjective and strongly influenced by situation, the measure should be tunable to particular users and contexts. This paper describes a distance measure between solid models which incorporates heuristics of the mental mappings humans use to compare objects. The first step is to formally represent objects in a way that reflects human visual segmentations. We use a modified boundary representation scheme in colour + physical space. The next step is to define a family of maps between these representations, motivated by considerations of how humans match shapes. The distance between two objects is essentially the cost of the lowest-cost map between them. The cost of a map incorporates a geometric measure of the smooth deformation required of edges and faces, a feature measure based on visually significant singular points, and a topological measure based on correspondence of visually significant vertices, edges and faces. Tunable features of the match are: the relative cost of ignoring parts of objects; the treatment of colour; and whether or not the distance measure is required to be rotation invariant. An important application for such distance measures is to the development of user-friendly query of CAD and image databases. Query-by-example depends on implementation of a concept of likeness between object models in the database which, to be useful, must reflect the user's concepts. Another important application for distance measures is in automatic recognition of objects into classes whose members are not identical, so that the concept that “this object is like object X” is required. In the common situation that classes are based on human perceptions of visual similarity, the distance measure between the class prototype and the object to be classified should reflect those human perceptions.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hameed K,Khan A,Ahmed M,Goutham Reddy A,Rathore MM",,Towards a formally verified zero watermarking scheme for data integrity in the Internet of Things based-wireless sensor networks,Future Generation Computer Systems,2018,82,,274-289,,,,,2018,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X17322756;http://dx.doi.org/10.1016/j.future.2017.12.009,10.1016/j.future.2017.12.009,"The Internet of Things (IoT) is an emerging paradigm in which billions of devices communicate, thus producing and exchanging information related to real world objects (things). Sensor nodes are specialized nodes for handling transmission of a large volume of data in situations where the source nodes communicate with base stations (BS) via a set of intermediate nodes. Applications based on WSN claim that integrity and trustworthiness are the key aspects as the data received from source nodes is the major source for BS to take critical decisions. To establish the trustworthiness between sensor node and BS, a novel zero watermarking scheme is proposed in this paper. In order to ensure integrity and trustworthiness, our proposed scheme embeds a watermark in original data before it is transmitted to BS which is responsible for verifying the watermark embedded with data. We have compared proposed scheme with existing Asymmetric Cryptography (ACT) and Reversible Watermarking (RW) schemes based on the performance parameters such as computational overhead and the energy utilization. Analysis results suggest that proposed scheme can handle multiple attacks on data and watermark such as data deletion, data modification, and data insertion attack. Moreover, our experimental results demonstrate that the presented scheme is lightweight, computationally efficient, and better in energy utilization. A formal verification for proof of correctness using high level Petri nets (HLPNs) is also provided to verify the claims of our work.","Zero watermarking, Data integrity, Sensor networks, High level Petri nets(HLPN)",,,,,,,,,,,,,,,,,,,,,
Journal Article,Lazarević MP,,Elements of mathematical phenomenology of self-organization nonlinear dynamical systems: Synergetics and fractional calculus approach,International Journal of Non-Linear Mechanics,2015,73,,31-42,,,,,2015,,0020-7462,https://www.sciencedirect.com/science/article/pii/S0020746214002273;http://dx.doi.org/10.1016/j.ijnonlinmec.2014.11.011,10.1016/j.ijnonlinmec.2014.11.011,"The modern dynamical systems of various physical natures, such as natural, social, economic, and technical ones, are complexes of various subsystems. They are connected by processes of intensive dynamic interaction and exchange of energy, matter, and information and incorporate nonlinear dynamics, memory, complicated transients, bifurcation and chaotic motion modes. Particularly, synergetics as a very young discipline deals with complex systems, i.e. it is concerned with the spontaneous formation of macroscopic spatial, temporal, or functional structures of systems via self-organization and is associated with systems composed of many subsystems, which may be of quite different natures. Synergetics take into account deterministic processes as treated in the dynamic systems theory including bifurcation theory, catastrophy theory, as well as basic notions of the chaos theory and develops its own approaches. Here, the fundamental basis of nonlinear theory of system׳s synthesis based on synergetics as well as fractional calculus approach in modern control theory together with its application will be presented. The difference of synergetic approach from the classical scientific methods is in identification of the fundamental role of self-organization in nonlinear dynamic systems and it is necessary to keep the conceptual correspondence to the main qualities of self-organization: nonlinearity—open systems—coherence. Synergetic approach is based on the natural homeostatic-conservation of the internal qualities of the dynamic systems of various natures. Namely, Russian scientist A.A. Kolesnikov developed a novel synergetic approach based on the ideas of modern mathematics, cybernetics, and synergetics to the synthesis of control systems for nonlinear, multidimensional and multilinked dynamic systems of various natures. The synergetic approach to control theory (synergetic control theory-SCT) is a novel nonlinear control method where the nonlinearities of a system are considered in the control design and a systematic design procedures. The invariants (synergies) and attractors, introduced as the main element of SCT, allow establishing direct link to the energy conservation laws, i.e. to the fundamental qualities of various objects. So, invariants, self-organization, and cascade synthesis are the fundamental notions of the SCT determining its essence, novelty, and content. Also, fractional calculus (FC) has a long history of three hundred years, over which a firm theoretical foundation has been established. All fractional operators consider the entire history of the process being considered, thus being able to model the non-local and distributed effects often encountered in natural and technical phenomena and they provide an excellent instrument for description of the memory, heredity, non-locality, self-similarity, and stochasticity of various materials and processes. Fractional dynamics can be encountered in various nonlinear dynamical systems such as visco-elastic materials, electrochemical processes, thermal systems, transmission and acoustics, chaos and fractals, biomechanical systems, and many others. The fractional dynamic systems with nonlinear control represent a relatively new class of applications of the FC which certified the FC as being a fundamental tool in describing the dynamics of complex systems as well as in advanced nonlinear control theory.","Phenomenology, Synergetics, Self-organization, Invariants, Nonlinear systems, Fractional calculus",Elements of mathematical phenomenology and phenomenological mapping in non-linear dynamics,,,,,,,,,,,,,,,,,,,,
Journal Article,Plotkin G,,On a Question of H. Friedman,Information and Computation,1996,126,1,74-77,,,,,1996,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540196900358;http://dx.doi.org/10.1006/inco.1996.0035,10.1006/inco.1996.0035,"In this paper we answer a question of Friedman, providing anω-separable model M of theλβη-calculus. There therefore exists anα-separable model for anyα⩾0. The model M permits no non-trivial enrichment as a partial order; neither does it permit an enrichment as a category with an initial object. The open term model embeds in M: by way of contrast we provide a model which cannot embed in any non-trivial model separating all pairs of distinct elements",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Amer A,Dubois E,Mitiche A",,Rule-based real-time detection of context-independent events in video shots,Real-Time Imaging,2005,11,3,244-256,,,,,2005,,1077-2014,https://www.sciencedirect.com/science/article/pii/S1077201405000021;http://dx.doi.org/10.1016/j.rti.2004.12.001,10.1016/j.rti.2004.12.001,"The purpose of this paper is to investigate a real-time system to detect context-independent events in video shots. We test the system in video surveillance environments with a fixed camera. We assume that objects have been segmented (not necessarily perfectly) and reason with their low-level features, such as shape, and mid-level features, such as trajectory, to infer events related to moving objects. Our goal is to detect generic events, i.e., events that are independent of the context of where or how they occur. Events are detected based on a formal definition of these and on approximate but efficient world models. This is done by continually monitoring changes and behavior of features of video objects. When certain conditions are met, events are detected. We classify events into four types: primitive, action, interaction, and composite. Our system includes three interacting video processing layers: enhancement to estimate and reduce additive noise, analysis to segment and track video objects, and interpretation to detect context-independent events. The contributions in this paper are the interpretation of spatio-temporal object features to detect context-independent events in real time, the adaptation to noise, and the correction and compensation of low-level processing errors at higher layers where more information is available. The effectiveness and real-time response of our system are demonstrated by extensive experimentation on indoor and outdoor video shots in the presence of multi-object occlusion, different noise levels, and coding artifacts.",,Special Issue on Video Object Processing,,,,,,,,,,,,,,,,,,,,
Book Chapter,Curzon P,"Claesen LJ,Gordon MJ",Deriving Correctness Properties of Compiled Code,,1993,,,327-346,,North-Holland,Amsterdam,Higher Order Logic Theorem Proving and its Applications,1993,9780444898807,,https://www.sciencedirect.com/science/article/pii/B9780444898807500279;http://dx.doi.org/10.1016/B978-0-444-89880-7.50027-9,10.1016/B978-0-444-89880-7.50027-9,"When developing safety critical software, it is the correctness of the object code that is paramount. However, it is desirable to perform formal verification on the source code. We have combined a derived programming logic with a verified compiler for a generic subset of the Vista structured assembly language. We show how correctness properties of object code can be formally derived from corresponding correctness properties of the source program which have been proved using the programming logic. The work described has been performed using the HOL system and so is machine checked.",,,IFIP Transactions A: Computer Science and Technology,,,,,,,,,,,,,,,,,,,
Journal Article,"Damiand G,Solnon C,de la Higuera C,Janodet JC,Samuel É",,Polynomial algorithms for subisomorphism of nD open combinatorial maps,Computer Vision and Image Understanding,2011,115,7,996-1010,,,,,2011,,1077-3142,https://www.sciencedirect.com/science/article/pii/S1077314211000816;http://dx.doi.org/10.1016/j.cviu.2010.12.013,10.1016/j.cviu.2010.12.013,"Combinatorial maps describe the subdivision of objects in cells, and incidence and adjacency relations between cells, and they are widely used to model 2D and 3D images. However, there is no algorithm for comparing combinatorial maps, which is an important issue for image processing and analysis. In this paper, we address two basic comparison problems, i.e., map isomorphism, which involves deciding if two maps are equivalent, and submap isomorphism, which involves deciding if a copy of a pattern map may be found in a target map. We formally define these two problems for nD open combinatorial maps, we give polynomial time algorithms for solving them, and we illustrate their interest and feasibility for searching patterns in 2D and 3D images, as any child would aim to do when he searches Wally in Martin Handford’s books.","Open combinatorial maps, Isomorphism and subisomorphism, Pattern detection, 2D and 3D images",Special issue on Graph-Based Representations in Computer Vision,,,,,,,,,,,,,,,,,,,,
Journal Article,Papadopoulos I,,Using mobile puzzles to exhibit certain algebraic habits of mind and demonstrate symbol-sense in primary school students,The Journal of Mathematical Behavior,2019,53,,210-227,,,,,2019,,0732-3123,https://www.sciencedirect.com/science/article/pii/S073231231730189X;http://dx.doi.org/10.1016/j.jmathb.2018.07.001,10.1016/j.jmathb.2018.07.001,"Given the growing concern for developing students’ algebraic ideas and thinking in earlier grades (NCTM, 2000) it is important for students to have experiences that better prepare them for their formal introduction to algebra. Mobile puzzles seem to be an opportunity for exhibiting certain algebraic habits of mind as well as for demonstrating symbol-sense which might support students in their transition from arithmetic to algebra. These puzzles include multiple balanced collections of objects whose weights must be determined by the solver. The arms/beams must be perfectly balanced for it to hang properly. Therefore, they represent, in a pictorial way, systems of equations. Each arm/beam that balances two sets of objects (representing variables as unknown “weights”) represents an equation. The data derived from Grade-6 students who were asked to solve a collection of tasks reflect the presence of the “Puzzling and Persevering” and “Seeking and Using Structure” habits of mind. At the same time these data incorporate instances of some main components of symbol-sense such as “friendliness with symbols”, “manipulating and ‘reading through’ symbolic expressions”, and “choice of symbols”. Also discussed is the way this experience contributes to an intuitive application of the conventional rules for solving equations that will be later introduced to the students as the standard algebraic “moves”.","Algebraic habits of mind, mobile puzzles, Symbol sense",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shyng JY,Shieh HM,Tzeng GH",,An integration method combining Rough Set Theory with formal concept analysis for personal investment portfolios,Knowledge-Based Systems,2010,23,6,586-597,,,,,2010,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705110000626;http://dx.doi.org/10.1016/j.knosys.2010.04.003,10.1016/j.knosys.2010.04.003,"The classical Rough Set Theory (RST) always generates too many rules, making it difficult for decision makers to choose a suitable rule. In this study, we use two processes (pre process and post process) to select suitable rules and to explore the relationship among attributes. In pre process, we propose a pruning process to select suitable rules by setting up a threshold on the support object of decision rules, to thereby solve the problem of too many rules. The post process used the formal concept analysis from these suitable rules to explore the attribute relationship and the most important factors affecting decision making for choosing behaviours of personal investment portfolios. In this study, we explored the main concepts (characteristics) for the conservative portfolio: the stable job, less than 4 working years, and the gender is male; the moderate portfolio: high school education, the monthly salary between NT$30,001 (US$1000) and NT$80,000 (US$2667), the gender is male; and the aggressive portfolio: the monthly salary between NT$30,001 (US$1000) and NT$80,000 (US$2667), less than 4 working years, and a stable job. The study result successfully explored the most important factors affecting the personal investment portfolios and the suitable rules that can help decision makers.","Rough Set Theory (RST), Formal concept analysis (FCA), Data mining, Choosing behaviours, Personal investment portfolios",,,,,,,,,,,,,,,,,,,,,
Journal Article,Vickers S,,Entailment systems for stably locally compact locales,Theoretical Computer Science,2004,316,1,259-296,,,,,2004,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397504000866;http://dx.doi.org/10.1016/j.tcs.2004.01.033,10.1016/j.tcs.2004.01.033,"The category SCFrU of stably continuous frames and preframe homomorphisms (preserving finite meets and directed joins) is dual to the Karoubi envelope of a category Ent whose objects are sets and whose morphisms X→Y are upper closed relations between the finite powersets FX and FY. Composition of these morphisms is the “cut composition” of Jung et al. that interfaces disjunction in the codomains with conjunctions in the domains, and thereby relates to their multi-lingual sequent calculus. Thus stably locally compact locales are represented by “entailment systems” (X,⊢) in which ⊢, a generalization of entailment relations, is idempotent for cut composition. Some constructions on stably locally compact locales are represented in terms of entailment systems: products, duality and powerlocales. Relational converse provides Ent with an involution, and this gives a simple treatment of the duality of stably locally compact locales. If A and B are stably continuous frames, then the internal preframe homA⋔B is isomorphic to Ã⊗B where Ã is the Hofmann–Lawson dual. For a stably locally compact locale X, the lower powerlocale of X is shown to be the dual of the upper powerlocale of the dual of X.","Locale, Stably compact, Stably locally compact, Information system, Multilingual sequent calculus, Constructivism",Recent Developments in Domain Theory: A collection of papers in honour of Dana S. Scott,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Jacobs B,Chapter 2 Simple type theory,,1998,141,,119-168,,Elsevier,,Categorical logic and type theory,1998,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X98800323;http://dx.doi.org/10.1016/S0049-237X(98)80032-3,10.1016/S0049-237X(98)80032-3,"Publisher Summary This chapter discusses the simple-type theory (STT). It also discusses the categorical semantics of STT, both in (traditional) terms of ordinary categories, and in terms of fibred categories. STT can be studied with various constructors for the formation of new types. These constructors include: exponents (or function spaces) (→), finite products (1, *), and finite coproducts (or disjoint unions) (0, +). In a fibred description of a type theory (or of a logic), contexts form objects of a base category. For simple-type theory, it suffices to consider simple fibrations because types do not contain any (term or type) variables and hence do not depend on a context. The finite product and exponent types in the calculus can be interpreted simply as finite product and exponent objects in a Cartesian-closed category. The chapter concludes by reviewinghow simple fibrations may also be used to give a suitable description of the data types with (simple) parameters.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,Dahn BI,,Boolean valued models and incomplete specifications,The Journal of Logic Programming,1992,12,3,225-236,,,,,1992,,0743-1066,https://www.sciencedirect.com/science/article/pii/074310669290025X;http://dx.doi.org/10.1016/0743-1066(92)90025-X,10.1016/0743-1066(92)90025-X,For each consistent universal first order theory T a Boolean valued model of T is constructed that satisfies an existential sentence if and only if it is provable from T. The resolution calculus is extended so that proofs from T yield representations of objects incompletely specified by T in a Boolean valued model.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,Kim JH,,Distributed inference for plausible classification,Pattern Recognition Letters,1987,5,3,195-201,,,,,1987,,0167-8655,https://www.sciencedirect.com/science/article/pii/0167865587900638;http://dx.doi.org/10.1016/0167-8655(87)90063-8,10.1016/0167-8655(87)90063-8,"A distributed inference technique for classifying observed patterns in terms of hierarchically organized object classes is described. Utilizing a hierarchical object class representation and the certainty factor calculus, an observed pattern is labeled at different levels of the class hierarchy in such a way that the confidence of a generic class is always higher than those of its more specific classes. By a group of processors structured isomorphic to the object class hierarchy, the rules associated with each object class are evaluated to compute local measures of belief and disbelief. Each processor, then, propagates the local measures to its neighbors and computes the global confidence by combining the neighbors' messages. This computational scheme was successfully employed for a vision expert system designed for man-made object recognition in natural scenes.","Classification, distributed processing, certainty factor, object hierarchy",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Grabowski J,Urbański P",,Algebroids — general differential calculi on vector bundles,Journal of Geometry and Physics,1999,31,2,111-141,,,,,1999,,0393-0440,https://www.sciencedirect.com/science/article/pii/S0393044099000078;http://dx.doi.org/10.1016/S0393-0440(99)00007-8,10.1016/S0393-0440(99)00007-8,"A notion of an algebroid— a generalized of a Lie algebroid structure on a vector bundle is introduced. We show that many objects of the differential calculus on a manifold M associated with the canonical Lie algebroid structure on TM can be obtained in the framework of a general algebroid. Also a compatibility condition which leads, in general, to a concept of a bialgebroid.","Lie algebroid, Exterior derivative, Poisson structure, Tangent lift, Vector bundle, Lie bialgebra",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Denker G,Meseguer J,Talcott C",,"Rewriting Semantics of Meta-Objects and Composable Distributed Services1 1Supported by DARPA through Rome Laboratories Contract F30602-97-C-0312, by DARPA and NASA through Contract NAS2-98073, by Office of Naval Research Contract N00014-99-C-0198, and by National Science Foundation Grants CCR-9505960 and CCR-9633363, and CCR-9900334",Electronic Notes in Theoretical Computer Science,2000,36,,405-425,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580132X;http://dx.doi.org/10.1016/S1571-0661(05)80132-X,10.1016/S1571-0661(05)80132-X,"Communication between distributed objects may have to be protected against random failures and malicious attacks; also, communication timeliness may be essential or highly desired. Therefore, a distributed application often has to be extended with communication services providing some kind of fault-tolerance, secrecy, or quality-of-service guarantees. Ideally, such services should be defined in a highly modular and dynamically composable way, so that the combined assurance of several services can be achieved by composition in certain cases, and so that services can be added or removed from applications at runtime in response to changes in the environment. To reason about the formal properties of such composable communication services one first needs to give them a precise semantics. This paper proposes a rewriting logic semantics for the so-called “onion skin” model of distributed object reflection, in which different meta-objects, providing different communication services, can be stacked on top of a basic application object. Since the correct behavior of a service depends on the type of hostile environment, against which the service must protect the application, rewriting logic should also be used to specify such hostile environments. The service guarantees are then guarantees about the behavior specified by the union of the rewrite theories specifying the basic application, the services, and the hostile environment.",,The 3rd International Workshop on Rewriting Logic and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fang SK,Shyng JY,Lee WS,Tzeng GH",,Exploring the preference of customers between financial companies and agents based on TCA,Knowledge-Based Systems,2012,27,,137-151,,,,,2012,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705111002048;http://dx.doi.org/10.1016/j.knosys.2011.09.003,10.1016/j.knosys.2011.09.003,"Based on transaction cost analysis (TCA), this research explores the customers’ loyalty to either the financial companies or the company financial agents with whom they have established relationship. In the past, consumers were divided into those who rely on agents and those who do not. In this study, we use two processes (pre-process and post-process) to select suitable rules, and to explore into the relationship among attributes. In the pre-process, we utilized factor analysis (FA) to choose the variable and rough set theory (RST) that found decision table to construct the decision rules, and approach to data mining and knowledge discovery based on information flow distribution in a flow graph. The post-process applies the formal concept analysis (FCA) from these suitable rules to explore the attribute relationship and the most important factors affecting the preference of customers for deciding whether to choose companies or agents. The degree of the customers’ dependence on agents was affected by the TCA, customer satisfaction and loyalty. The principal findings were that the different degrees of dependence of customers have various characteristics. The RST and FCA were two complementary mathematical tools for data analysis. Following an empirical analysis, we use two hit testes that incorporate 30 and 36 validated sample object into the decision rule. The hitting rate of two testes, were reached 90%. The results of the empirical study indicate that the generated decision rules can cover most new objects. Consequently, we believe that the result can be fully applied in financial research.","Transaction cost analysis (TCA), Rough set theory (RST), Formal concept analysis (FCA), Data mining, Flow graph, Customer relationship management (CRM)",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Härtig F,Stein M",,3D involute gear evaluation – Part I: Workpiece coordinates,Measurement,2019,134,,569-573,,,,,2019,,0263-2241,https://www.sciencedirect.com/science/article/pii/S0263224118310315;http://dx.doi.org/10.1016/j.measurement.2018.10.088,10.1016/j.measurement.2018.10.088,"The definition of 3D workpiece coordinates for cylindrical involute gears, together with their formal relation to conventional cross sections, are prerequisites for an unambiguous and thus reliable evaluation of 3D measurement data. Both will be described in this article, as no corresponding information is currently available in national or international standards and guidelines. The definitions and calculation methods presented here are part of reference algorithms used by the Physikalisch-Technische Bundesanstalt (PTB), the national metrology institute of Germany, to certify gear evaluation software.","Coordinate metrology, Involute gear metrology, 3D involute gear coordinates, Certification for involute gear evaluation, Software test",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Weintraub SH,Weintraub SH,"Chapter 1 - Differential Forms in Rn, I",,2014,,,1-50,Second Edition,Academic Press,Boston,Differential Forms (Second Edition),2014,9780123944030,,https://www.sciencedirect.com/science/article/pii/B9780123944030000013;http://dx.doi.org/10.1016/B978-0-12-394403-0.00001-3,10.1016/B978-0-12-394403-0.00001-3,"In this chapter we consider differential forms as formal objects in Rn. We show how to do algebra with differential forms, this algebra being known as exterior algebra, and we introduce the operation of exterior differentiation. We state and prove Poincaré’s Lemma. Focusing on R3, we show how, in R3, differential forms “correspond” to functions and vector fields and how, under this correspondence, the classical operations of gradient, curl, and divergence on vector fields are all special cases of exterior differentiation. We prove the converse of Poincaré’s Lemma in the case of forms defined on all of Rn.","Differential form, Exterior multiplication, Exterior differentiation, Poincaré’s Lemma, Fundamental correspondence",,,,,,,,,,,,,,,,,,,,,
Journal Article,Haugen Ø,,MSC-2000 interaction diagrams for the new millennium,Computer Networks,2001,35,6,721-732,,,,,2001,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128600002012;http://dx.doi.org/10.1016/S1389-1286(00)00201-2,10.1016/S1389-1286(00)00201-2,"MSC-2000 is the latest version of the language to describe message sequence charts (MSCs) recommended by ITU-T in Z.120. It has introduced advanced structuring mechanisms, data concepts and time descriptions.","Sequence diagrams, Formal language, MSC: Message Sequence Charts, Object orientation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Stelldinger P,Tcherniavski L",,Provably correct reconstruction of surfaces from sparse noisy samples,Pattern Recognition,2009,42,8,1650-1659,,,,,2009,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320308005086;http://dx.doi.org/10.1016/j.patcog.2008.11.031,10.1016/j.patcog.2008.11.031,"Automated three-dimensional surface reconstruction is a very large and still fast growing area of applied computer vision and there exists a huge number of heuristic algorithms. Nevertheless, the number of algorithms which give formal guarantees about the correctness of the reconstructed surface is quite limited. Moreover such theoretical approaches are proven to be correct only for objects with smooth surfaces and extremely dense samplings with no or very few noise. We define an alternative surface reconstruction method and prove that it preserves the topological structure of multi-region objects under much weaker constraints and thus under much more realistic conditions. We derive the necessary error bounds for some digitization methods often used in discrete geometry, i.e. supercover and m-cell intersection sampling. We also give a detailed analysis of the behavior of our algorithm and compare it with other approaches.","Surface reconstruction, Topology preservation, Alpha-shapes, Delaunay triangulation",Advances in combinatorial image analysis,,,,,,,,,,,,,,,,,,,,
Journal Article,Mach P,,On the stability of steady general-relativistic accretion and analogue black holes,Reports on Mathematical Physics,2009,64,1,257-269,,,,,2009,,0034-4877,https://www.sciencedirect.com/science/article/pii/S0034487709900313;http://dx.doi.org/10.1016/S0034-4877(09)90031-3,10.1016/S0034-4877(09)90031-3,"Investigation of general-relativistic spherically symmetric steady accretion of self-gravitating perfect fluid onto compact objects reveals the existence of two weakly accreting regimes. In the first (corresponding to the test fluid approximation), the mass of the central object is much larger than the mass of the accreting fluid; in the second, the mass of the fluid dominates. The stability of the solutions belonging to the first regime has been proved by Moncrief. In this work we report the results of a series of numerical studies demonstrating stability of massive solutions, i.e. belonging to the second of the aforementioned regimes. It is also shown that a formal analogy between “sonic horizons” in the accretion picture and event horizons in general relativity is rather limited. The notion of a “sonic horizon” is only valid in a linear regime of small hydrodynamical perturbations. Strong perturbations can still escape from beneath the ”sonic horizon.“","general-relativistic hydrodynamics, accretion",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Verlan S,Bernardini F,Gheorghe M,Margenstern M",,Generalized communicating P systems,Theoretical Computer Science,2008,404,1,170-184,,,,,2008,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397508002582;http://dx.doi.org/10.1016/j.tcs.2008.04.008,10.1016/j.tcs.2008.04.008,"This paper considers a generalization of various communication models based on the P system paradigm where two objects synchronously move across components. More precisely, the model uses blocks of four cells such that pairs of objects from two input cells travel together to target output cells. It is shown that the model introduced, based on interactions between blocks, is complete, being able to generate all recursively enumerable sets of natural numbers. It is also proven that completeness is achievable by using a minimal interaction between blocks, i.e. every pair of cells is the input or output for at most one block. It is also shown that the concepts introduced in this paper to define the model may be simulated by more particular communication primitives, including symport, antiport and uniport rules. This enables us to automatically translate a system using interaction rules in any of minimal symport, minimal antiport or conditional uniport P systems.","P systems, Symport, Antiport, Minimal interactions, Formal languages, Universal computations",Membrane Computing and Biologically Inspired Process Calculi,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhou X,Shao Z,Zeng W,Liu J",,Semantic graph construction for 3D geospatial data of multi-versions,Optik,2014,125,6,1730-1734,,,,,2014,,0030-4026,https://www.sciencedirect.com/science/article/pii/S0030402613013351;http://dx.doi.org/10.1016/j.ijleo.2013.09.057,10.1016/j.ijleo.2013.09.057,"3D geospatial data holds rich information that causing significant tough workload in 3D geospatial semantic building. In order to avoid those difficulties in building high precise semantic, this paper focuses on creating a semantic graph for 3D geospatial data via the novel approach called semantic graph. Firstly, all data related to geo-spatial are organized through semantic conceptualization processing. Its result is divided into conceptual description and formal pattern involving all features belong to certain 3D object or scene. Then from perspective of spatial, thematic and temporal domains, multi-versions semantic relations are created depend on relational rules and semantic mapping mechanism. On the basic of semantic conceptualization processing, all conceptual and formal patterns are controlled as semantic integrated result. Since the result covers spatial, thematic and temporal semantic information of 3D geospatial field, approach proposed by this paper can generate 3D geospatial data semantic graph based on semantic conceptualization and accomplish the transform from 3D geospatial data to 3D geospatial semantic effectively.","Semantic conceptualization, Multi-versions data, 3D geospatial data, Semantic graph",,,,,,,,,,,,,,,,,,,,,
Journal Article,Chandler JL,,An introduction to the perplex number system,Discrete Applied Mathematics,2009,157,10,2296-2309,,,,,2009,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X08005106;http://dx.doi.org/10.1016/j.dam.2008.06.054,10.1016/j.dam.2008.06.054,"The perplex number system is a generalization of the abstract logical relationships among electrical particles. The inferential logic of the new number system is homologous to the inferential logic of the progression of the atomic numbers. An electrical progression is defined categorically as a sequence of objects with teridentities. Each identity infers corresponding values of an integer, units and a correspondence relation between each unit and its integer. Thus, in this logical system, each perplex numeral contains an exact internal representational structure; it carries an internal message. This structure is a labeled bipartite graph that is homologous to the internal electrical structure of a chemical atom. The formal logical operations are conjunctions and disjunctions. Combinations of conjunctions and disjunctions compose the spatiality of objects. Conjunctions may include the middle term of pairs of propositions with a common term, thereby creating new information. The perplex numerals are used as a universal source of diagrams. The perplex number system, as an abstract generalization of concrete objects and processes, constitutes a new exact notation for chemistry without invoking alchemical symbols. Practical applications of the number system to concrete objects (chemical elements, simple ions and molecules, and the perplex isomers, ethanol and dimethyl ether) are given. In conjunction with the real number system, the relationships between the perplex number system and scientific theories of concrete systems (thermodynamics, intra-molecular dynamics, molecular biology and individual medicine) are described.","Chemical mathematics, Perplex logic, Synductive logic, Meso-syllogisms, Labeled bipartite graphs",Networks in Computational Biology,,,,,,,,,,,,,,,,,,,,
Journal Article,"Djedjig N,Tandjaoui D,Medjek F,Romdhani I",,Trust-aware and cooperative routing protocol for IoT security,Journal of Information Security and Applications,2020,52,,102467,,,,,2020,,2214-2126,https://www.sciencedirect.com/science/article/pii/S2214212619306751;http://dx.doi.org/10.1016/j.jisa.2020.102467,10.1016/j.jisa.2020.102467,"The resource-constrained nature of IoT objects makes the Routing Protocol for Low-power and Lossy Networks (RPL) vulnerable to several attacks. Although RPL specification provides encryption protection to control messages, RPL is still vulnerable to internal attackers and selfish behaviours. To address the lack of robust security mechanisms in RPL, we design a new Metric-based RPL Trustworthiness Scheme (MRTS) that introduces trust evaluation for secure routing topology construction. Extensive simulations show that MRTS is efficient in terms of packet delivery ratio, energy consumption, nodes’ rank changes, and throughput. In addition, a mathematical modelling analysis shows that MRTS meets the requirements of consistency, optimality, and loop-freeness and that the proposed trust-based routing metric has the isotonicity and monotonicity properties required for a routing protocol. By using game theory concepts, we formally describe MRTS as a strategy for the iterated Prisoner’s Dilemma and demonstrate its cooperation enforcement characteristic. Both mathematical analysis and evolutionary simulation results show clearly that MRTS, as a strategy, is an efficient approach in promoting the stability and the evolution of the Internet of Things network.","RPL, Secure routing, Internet of things, Trust management, Game theory, Cooperation enforcement",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mattar L,Higgins SS,Neves JA",,Diversity and autonomy in the structuration of a multilevel organizational social network in a technology park,Social Networks,2022,68,,346-355,,,,,2022,,0378-8733,https://www.sciencedirect.com/science/article/pii/S037887332100071X;http://dx.doi.org/10.1016/j.socnet.2021.08.009,10.1016/j.socnet.2021.08.009,"In organizational settings, along with their formal rules, informal norms and social preferences drive the formation of interpersonal networks. Empirical evidence and theoretical claims maintain that individual epistemic status influences the choice of an adviser in interpersonal advice networks within an organizational environment. In the context of an industrial cluster, the interpersonal networks are affiliated with the interorganizational network of the companies. Therefore, another source of influence to be considered is the interdependency of the interorganizational level relations among the companies in which the individuals are nested. Thus, beyond the one-level perspective, which is the usual approach in organizational network studies, this article explores how the interdependency of the interorganizational level can influence the dynamic of endogenous structuration of interpersonal relations. The object of this study is a collaboration network among companies and an advice network among directors from a Brazilian knowledge-intensive technological cluster. Through the use of the multilevel exponential random graph model (MERGM), statistical interdependent dynamics were identified between the two levels guided by the social processes of tie creation that result in similarities and distinctions between both levels of analysis. The centralization based on the activity of seeking advice guides the directors' network, and among companies there are multiple transitive and hierarchical closures with some intermediation between them. However, activity-based centralization also guides companies. From a multilevel perspective, the diversity of network processes that guide each level indicates that the cross-level interdependency between the two levels does not prevent some autonomy of the individual level from the organizational one.","Advice social network, Embeddedness, Intensive-knowledge cluster, Organizational social network, Multilevel exponential random graph model, Multilevel social network",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Nave O,Neuman Y,Perlovsky L,Howard N",,How much information should we drop to become intelligent?,Applied Mathematics and Computation,2014,245,,261-264,,,,,2014,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300314009862;http://dx.doi.org/10.1016/j.amc.2014.07.029,10.1016/j.amc.2014.07.029,"Cognitive processing by intelligent systems involves the deletion of information in favor of higher level abstractions. This process can be addressed through the physics of computation but a formal model that explains this process has not been proposed yet. In this short paper, we propose a model that through physical constraints only generates optimal solution to the collapse of n objects into n sets. A numerical simulation of the model results in a logarithmic function of information loss and condensation that perfectly fits our knowledge of cognitive processes.","Cognition and physics, Set partition, Entropy, Interdisciplinary research",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Poupyrev I,Ichikawa T",,Manipulating Objects in Virtual Worlds: Categorization and Empirical Evaluation of Interaction Techniques,Journal of Visual Languages & Computing,1999,10,1,19-35,,,,,1999,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X98901124;http://dx.doi.org/10.1006/jvlc.1998.0112,10.1006/jvlc.1998.0112,"The acceptance of virtual environment (VE) technology requires scrupulous optimization of the most basic interactions to maximize user performance and provide efficient and enjoyable virtual interfaces. Motivated by insufficient understanding of human factors implications in the design of interaction techniques for object manipulation in virtual worlds, this paper presents results of a formal study that evaluated two basic interaction metaphors for virtual manipulation—virtual pointer and virtual hand—in object selection and positioning tasks. In this work, we survey and categorize current virtual manipulation techniques according to their basic design metaphors, conduct experimental studies of the most basic techniques, and derive guidelines to aid designers in the practical development of VE applications.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sheard T,Stemple D",,Inheritance of theory in the ADABTPL language,Computer Languages,1992,17,3,157-167,,,,,1992,,0096-0551,https://www.sciencedirect.com/science/article/pii/009605519290026J;http://dx.doi.org/10.1016/0096-0551(92)90026-J,10.1016/0096-0551(92)90026-J,"The ADABTPL language is a functional specification language which attempts to support a programming paradigm that is natural and flexible, which supports concise programs, and which also promotes proofs of system properties. ADABTPL supports this paradigm by tying the compiler to a powerful induction based theorem prover in the style of Boyer and Moore. The theorem prover uses a tailored theory about particular programs that captures more of the application semantics than is usual in programming verification. Such theory is generated during compilation by instantiating selected parts of generic theorems about second order functions. The instantiated theory is more particular to the program in which it will be used and thus decreases the amount of search that is needed to prove program specific properties. This approach constitutes an instance of theory inheritance, and can also be used to make sound program transformations. Our work indicates, against intuition, that the introduction of higher order mechanisms does not necessarily complicate formal reasoning about programs, but instead provides a powerful abstraction mechanism for simplifying mechanical reasoning.","Higher order logic, Proof of program properties, Meta-theorem, Theory inheritance, Predicate-based types, Type-safe programs, Program transformation",ICCL'88-Part III,,,,,,,,,,,,,,,,,,,,
Journal Article,Wołczowski A,,Formal model of movable object control with application of parametric automaton,Annual Review in Automatic Programming,1985,12,,398-403,,,,,1985,,0066-4138,https://www.sciencedirect.com/science/article/pii/0066413885900710;http://dx.doi.org/10.1016/0066-4138(85)90071-0,10.1016/0066-4138(85)90071-0,"The paper discusses the problems related to the synthesis of an element controlling a movable object and able to plan the path along which such object will travel. It was assumed that the function of such a control element is performed by a parametric automaton able to adjust its performance to the type of control algorithm being realized. A formal model of the area across which an object is displacing was developed taking into account spatial relations observed between the distinquished elements of the area as well as all dependences characteristic for these relations. On the basis of the above model, the way in which the control algorithm can be realized was determined by way of arithmetical and logical operations performed by the automaton.","Movement control, game-playing automaton, self-moving object",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shirazi A,Amir E",,First-order logical filtering,Artificial Intelligence,2011,175,1,193-219,,,,,2011,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370210000512;http://dx.doi.org/10.1016/j.artint.2010.04.015,10.1016/j.artint.2010.04.015,"Logical filtering is the process of updating a belief state (set of possible world states) after a sequence of executed actions and perceived observations. In general, it is intractable in dynamic domains that include many objects and relationships. Still, potential applications for such domains (e.g., semantic web, autonomous agents, and partial-knowledge games) encourage research beyond intractability results. In this paper we present polynomial-time algorithms for filtering belief states that are encoded as First-Order Logic (FOL) formulas. Our algorithms are exact in many cases of interest. They accept belief states in FOL without functions, permitting arbitrary arity for predicates, infinite universes of elements, and equality. They enable natural representation with explicit references to unidentified objects and partially known relationships, still maintaining tractable computation. Previous results focus on more general cases that are intractable or permit only imprecise filtering. Our algorithms guarantee that belief-state representation remains compact for STRIPS actions (among others) with unbounded-size domains. This guarantees tractable exact filtering indefinitely for those domains. The rest of our results apply to expressive modeling languages, such as partial databases and belief revision in FOL.","Filtering, First-order logic, Belief update, Situation calculus",John McCarthy's Legacy,,,,,,,,,,,,,,,,,,,,
Book Chapter,Bench-Capon TJ,Bench-Capon TJ,7 - Logic and Predicate Calculus,,1990,,,103-121,,Academic Press,London,Knowledge Representation,1990,9780120864409,,https://www.sciencedirect.com/science/article/pii/B9780120864409500117;http://dx.doi.org/10.1016/B978-0-12-086440-9.50011-7,10.1016/B978-0-12-086440-9.50011-7,"Publisher Summary This chapter discusses the third of the major knowledge representation paradigms, logic, and in particular, the first-order predicate calculus. A number of logics have been developed in philosophy and mathematics to represent arguments and to assess their soundness or unsoundness. This, in turn, has meant that they have developed as a means of representing the premises of arguments and their conclusions, and this is sufficiently close to the idea of a knowledge base and the inferences that can be drawn from it to give hopes of transferring the representational ideas developed in logic in a relatively straightforward manner. The simplest form of logic is the propositional calculus, but this represents only the logical relations between whole statements and therefore, its expressive power is somewhat limited. More expressive is the first order-predicate calculus, which expresses relations between objects, asserting and denying these relationships, and stating the logical relations between these statements.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Reisig W,,Petri nets with individual tokens,Theoretical Computer Science,1985,41,,185-213,,,,,1985,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397585900702;http://dx.doi.org/10.1016/0304-3975(85)90070-2,10.1016/0304-3975(85)90070-2,"In the well-known model of Petri nets (place/transition nets), actual system states are represented as distributions of ‘black’ tokens on the places of the nets. Such tokens cannot be identified as individual objects. The introduction of individual objects as tokens considerably increases the descriptive power of nets and allows for small but efficient models of real systems. This paper presents such nets and illuminates their mathematical background. Our central concern is an intuitively and mathematically simple and transparent calculus of invariants, i.e., a powerful analysis technique. Other models of nets with individual tokens, viz. Predicate/Transition nets and coloured nets, will be translated to our calculus. In this way our invariant techniques become applicable to those models.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Goto S,,Proof normalization with nonstandard objects,Theoretical Computer Science,1991,85,2,333-351,,,,,1991,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397591901866;http://dx.doi.org/10.1016/0304-3975(91)90186-6,10.1016/0304-3975(91)90186-6,"It is well known that formal proof systems can serve as programming languages. A proof that describes an algorithm can be executed by Prawitz's normalization procedure. This paper extends the computational use of proofs to realize a lazy computation formally. It enables computation of a proof over stream objects (infinitely long lists) as in concurrent Prolog. In this paper we follow the natural deduction formalism. Our presentation of natural deduction differs from Gentzen's system in the existential elimination rule. We apply the Borkowski-Słupecki's device. There is no difference between Gentzen's rule and Borkowski-Słupecki's rule as far as formula provability is concerned. However, the new rule is essential to proof normalization. A new concept, the pseudonormal proof, is introduced to formalize our normalization method. To deal with infinitely long objects we extend the number theory to incorporate infinite numbers. This is an application of nonstandard analysis to computer programs. We show that the rule of mathematical induction can be extended to cover infinite numbers with appropriate computational meaning.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Galvão FL,Guimarães SJ,Falcão AX",,Image segmentation using dense and sparse hierarchies of superpixels,Pattern Recognition,2020,108,,107532,,,,,2020,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320320303356;http://dx.doi.org/10.1016/j.patcog.2020.107532,10.1016/j.patcog.2020.107532,"We investigate the intersection between hierarchical and superpixel image segmentation. Two strategies are considered: (i) the classical region merging, that creates a dense hierarchy with a higher number of levels, and (ii) the recursive execution of some superpixel algorithm, which generates a sparse hierarchy with fewer levels. We show that, while dense methods can capture more intermediate or higher-level object information, sparse methods are considerably faster and usually with higher boundary adherence at finer levels. We first formalize the two strategies and present a sparse method, which is faster than its superpixel algorithm and with similar boundary adherence. We then propose a new dense method to be used as post-processing from the intermediate level, as obtained by our sparse method, upwards. This combination results in a unique strategy and the most effective hierarchical segmentation method among the compared state-of-the-art approaches, with efficiency comparable to the fastest superpixel algorithms.","Superpixel segmentation, Hierarchical image segmentation, Image foresting transform, Iterative spanning forest, Graph-based image segmentation, Irregular image pyramid",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li WS,Selçuk Candan K,Hirata K,Hara Y",,Hierarchical image modeling for object-based media retrieval,Data & Knowledge Engineering,1998,27,2,139-176,,,,,1998,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X9700058X;http://dx.doi.org/10.1016/S0169-023X(97)00058-X,10.1016/S0169-023X(97)00058-X,"Images are more structurally complex than the data stored in the traditional DBMSs. Many systems perform media retrieval based on image feature matching; the fact that images have structures is ignored. On the other hand, we view images as compound objects containing many component objects. Each component object corresponds to a region(s) that is a visually and semantically meaningful entity (e.g. car, man, etc.). As images/objects truly have hierarchical structures and have both visual and semantics properties, we argue that image retrieval using either semantics and image matching alone is insufficient. In this paper, we introduce a hierarchical structure for image modeling to support image retrieval using combinations of semantic expressions and visual examples at both the whole image and object levels. We give formal definitions of a multimedia query language and a system implementation based on this image modeling. We also address associated query processing issues and discuss the portability and extendibility of our approach.","Object-based image retrieval, image modeling, hierarchical structure, image databases, multimedia query language, SQL3",,,,,,,,,,,,,,,,,,,,,
Journal Article,Lamandé P,,Sur la conception des objets et des méthodes mathématiques dans les textes philosophiques de d'Alembert,Historia Mathematica,2019,49,,20-59,,,,,2019,,0315-0860,https://www.sciencedirect.com/science/article/pii/S0315086018300600;http://dx.doi.org/10.1016/j.hm.2019.02.001,10.1016/j.hm.2019.02.001,"Résumé Ce texte est consacré à la conception des objets et des méthodes mathématiques selon d'Alembert. On rappelle d'abord sa vision de la place des mathématiques dans la connaissance de la nature, puis la hiérarchie interne des divers domaines de cette science fondée sur leur degré d'abstraction à partir des sensations (§1 et 2). On aborde ensuite l'idée que d'Alembert se fait des définitions, des idées premières, des idées simples et de leur génération comme de leur généralisation (§3 et 4). Puis, après avoir regardé ce qu'il entend par grandeurs, nombres, quantités, ainsi que sa conception des objets et des règles de l'algèbre comme idées simples abstraites par généralisation (§5), on aborde la question de la réalité des objets mathématiques sur l'exemple des irrationnels (§6). La suite est consacrée aux difficultés rencontrées dans divers domaines et la manière dont d'Alembert essaie de les résoudre : algèbre et quantités négatives (§7) ; principes de la géométrie (§8) ; la notion de limite comme fondement du calcul infinitésimal (§9). Ses réflexions, même inachevées, ne furent pas sans postérité (§10). This paper is devoted to the conception of mathematical objects and methods according to d'Alembert. We first recall his vision of the place of mathematics in the knowledge of nature, then the internal hierarchy of the various fields of this science, based on their degree of abstraction from sensations (§1 and 2). Then we come to the ideas of definitions, primitive ideas, simple ideas, and their generation as well as their generalization (§3 and 4). Then, having looked at what he means by quantities, numbers, quantities, as well as his conception of the objects and rules of algebra as abstract ideas by generalization (§5), we approach the question of the reality of mathematical objects with the example of the irrational (§6). The following paragraphs of the text are devoted to the difficulties encountered in various fields and the way d'Alembert tries to solve them: algebra and negative quantities (§7); principles of geometry (§8); the notion of limit as the basis of infinitesimal calculus (§9). His reflections, even if unfinished, were not without posterity (§10).","d'Alembert, Mathematical philosophy, Mathematical epistemology, 18th century mathematics, Foundations of mathematics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liu X,Shapiro V",,Multiscale shape–material modeling by composition,Computer-Aided Design,2018,102,,194-203,,,,,2018,,0010-4485,https://www.sciencedirect.com/science/article/pii/S0010448518302446;http://dx.doi.org/10.1016/j.cad.2018.04.024,10.1016/j.cad.2018.04.024,"We propose a formal framework for modeling multiscale material structures by recursive composition of two-scale material structures. The framework comprises three components: (1) single scale shape–material models, supported by single scale queries, to represent the geometry and spatial distribution of material property on each coarse and fine scales, (2) mechanisms to link the scales by establishing an explicit relationship between shape–material properties at fine scale and material properties at the coarse scale, and (3) multiscale queries abstracting fundamental multiscale operations by recursive composition. While the first component is consistent with classical solid heterogeneous material modeling, the second component manifests itself as a pair of conceptually new upscaling and downscaling functions. We show that classical solid modeling queries, exemplified by point membership testing, distance computation, and material evaluation, generalize to the corresponding multiscale queries that support implicit representations of multiscale structures as a composition of distinct single scale solid material models. The concept of neighborhood is indispensable in all three components. The framework provides a formal and consistent extension of solid modeling framework that underlies most commercial systems in use today, encompasses the variety of different approaches to multiscale modeling, identifies open issues and research problems with existing two-scale modeling methods, and provides foundations for next-generation systems by identifying key objects, classes, representation schemes, and API queries.","Multiscale modeling, Material structure, Homogenization, Multiscale query, Interoperability",Proceeding of SPM 2018 Symposium,,,,,,,,,,,,,,,,,,,,
Journal Article,"Srinivasan A,Sundaram D",,An object relational approach for the design of decision support systems,European Journal of Operational Research,2000,127,3,594-610,,,,,2000,,0377-2217,https://www.sciencedirect.com/science/article/pii/S0377221799003434;http://dx.doi.org/10.1016/S0377-2217(99)00343-4,10.1016/S0377-2217(99)00343-4,"We present an approach to implementing model based decision support systems. Our method integrates the power of management science modelling with the versatility of extensible data management technologies. Common criticisms of attempts to implement this class of systems have been that they are too domain specific, or that they focus on selected parts of the design life cycle at the expense of others. We deal with these criticisms by (1) rooting our implementation in a formal and generalisable conceptual basis: Structured Modelling and (2) developing applications in a software environment that handles constructs with varying degrees of complexity: an object relational database system. The choice of the object relational platform offers the (a) flexibility in the choice of a user interface, (b) ability to deal with scalable implementations, and (c) ability to support key aspects of the modelling life cycle via built-in components of the platform.","Decision support systems, Modelling, Object relational database systems, Structured modelling, Systems design principles",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mashal I,Alsaryrah O,Chung TY",,Performance evaluation of recommendation algorithms on Internet of Things services,Physica A: Statistical Mechanics and its Applications,2016,451,,646-656,,,,,2016,,0378-4371,https://www.sciencedirect.com/science/article/pii/S0378437116000935;http://dx.doi.org/10.1016/j.physa.2016.01.051,10.1016/j.physa.2016.01.051,"Internet of Things (IoT) is the next wave of industry revolution that will initiate many services, such as personal health care and green energy monitoring, which people may subscribe for their convenience. Recommending IoT services to the users based on objects they own will become very crucial for the success of IoT. In this work, we introduce the concept of service recommender systems in IoT by a formal model. As a first attempt in this direction, we have proposed a hyper-graph model for IoT recommender system in which each hyper-edge connects users, objects, and services. Next, we studied the usefulness of traditional recommendation schemes and their hybrid approaches on IoT service recommendation (IoTSRS) based on existing well known metrics. The preliminary results show that existing approaches perform reasonably well but further extension is required for IoTSRS. Several challenges were discussed to point out the direction of future development in IoTSR.","Internet of Things, Service recommendation, Tripartite graph, Collaborative filtering, Hyper-edge",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bernstam EV,Smith JW,Johnson TR",,What is biomedical informatics?,Journal of Biomedical Informatics,2010,43,1,104-110,,,,,2010,,1532-0464,https://www.sciencedirect.com/science/article/pii/S1532046409001075;http://dx.doi.org/10.1016/j.jbi.2009.08.006,10.1016/j.jbi.2009.08.006,"Biomedical informatics lacks a clear and theoretically-grounded definition. Many proposed definitions focus on data, information, and knowledge, but do not provide an adequate definition of these terms. Leveraging insights from the philosophy of information, we define informatics as the science of information, where information is data plus meaning. Biomedical informatics is the science of information as applied to or studied in the context of biomedicine. Defining the object of study of informatics as data plus meaning clearly distinguishes the field from related fields, such as computer science, statistics and biomedicine, which have different objects of study. The emphasis on data plus meaning also suggests that biomedical informatics problems tend to be difficult when they deal with concepts that are hard to capture using formal, computational definitions. In other words, problems where meaning must be considered are more difficult than problems where manipulating data without regard for meaning is sufficient. Furthermore, the definition implies that informatics research, teaching, and service should focus on biomedical information as data plus meaning rather than only computer applications in biomedicine.","Biomedical informatics, Scientific discipline, Data, Information, Knowledge, Definition, Philosophy of information",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Silva FB,de O. Werneck R,Goldenstein S,Tabbone S,da S. Torres R",,Graph-based bag-of-words for classification,Pattern Recognition,2018,74,,266-285,,,,,2018,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320317303680;http://dx.doi.org/10.1016/j.patcog.2017.09.018,10.1016/j.patcog.2017.09.018,"This paper introduces the Bag of Graphs (BoG), a Bag-of-Words model that encodes in graphs the local structures of a digital object. We present a formal definition, introducing concepts and rules that make this model flexible and adaptable for different applications. We define two BoG-based methods – Bag of Singleton Graphs (BoSG) and Bag of Visual Graphs (BoVG), which create vector representations for graphs and images, respectively. We evaluate the Bag of Singleton Graphs (BoSG) for graph classification on four datasets of the IAM repository, obtaining significant results in accuracy and execution time. The method Bag of Visual Graphs (BoVG) is evaluated for image classification on Caltech and ALOI datasets, and for remote sensing image classification on images of Monte Santo and Campinas datasets. This framework opens possibilities for retrieval, classification, and clustering tasks on large datasets that use graph-based representations impractical before due to the complexity of inexact graph matching.","Bag models, Graph matching, Graph-based retrieval, Graph-based classification",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Harbi Y,Aliouat Z,Refoufi A,Harous S,Bentaleb A",,Enhanced authentication and key management scheme for securing data transmission in the internet of things,Ad Hoc Networks,2019,94,,101948,,,,,2019,,1570-8705,https://www.sciencedirect.com/science/article/pii/S1570870519302689;http://dx.doi.org/10.1016/j.adhoc.2019.101948,10.1016/j.adhoc.2019.101948,"The Internet of Things (IoT), with its smartness and intelligence, is gradually changing human life by allowing everyday objects to be connected to the Internet. With the prevalence of the IoT, wireless sensor networks (WSNs) are attracting worldwide attention, because they cover a wide range of IoT applications. The sensors collect data from the physical world and communicate with each other through wireless links. Ensuring the security and privacy of WSNs’ communication is challenging. Recently, a secure authentication and key management scheme was proposed to secure data transmission in WSNs. In this paper, we show that this scheme has various security flaws, such as replay attack, denial of service attack, impersonation attack, and lack of mutual authentication and session key agreement. Then, we propose an enhanced scheme to overcome the identified security weaknesses. The security of the enhanced scheme is formally verified using the Burrows–Abadi–Needham logic and the Automated Validation of Internet Security Protocols and Applications tool. Our proposed scheme is more secure, efficient, and suitable for WSN-based IoT applications than recent related methods.","Privacy, Mutual authentication, Key agreement, Elliptic curve cryptography, BAN logic, AVISPA",,,,,,,,,,,,,,,,,,,,,
Book Chapter,O'Neill B,O'Neill B,Chapter 1 - Calculus on Euclidean Space,,2006,,,3-42,Second Edition,Academic Press,Boston,Elementary Differential Geometry (Second Edition),2006,9780120887354,,https://www.sciencedirect.com/science/article/pii/B9780120887354500055;http://dx.doi.org/10.1016/B978-0-12-088735-4.50005-5,10.1016/B978-0-12-088735-4.50005-5,"Publisher Summary This chapter focuses on the part of elementary calculus that deals with differentiation of functions of three variables and with curves in space, more specifically in Euclidean space. Euclidean 3-space, instead of saying that three numbers describe the position of a point, defines them to be a point. Elementary calculus does not always make a sharp distinction between the numbers and the functions. Indeed the analogous distinction on the real line may seem pedantic, but for higher-dimensional spaces such as R3, its absence leads to serious ambiguities. Here R3, or Euclidean 3-space, is the set of all ordered triples of real numbers. Such a triple is called a point of R3. In linear algebra, it is shown that R3 is, in a natural way, a vector space over the real numbers. Using R3, the chapter highlights various definitions relating to tangents, curves, and vector fields, which is dualized to 1-forms and that, in turn, lead to arbitrary differential forms. The notions of curve and differentiable function is generalized to that of a mapping function F: Rn → Rm. Starting from the usual notion of the derivative of a real-valued function, the chapter constructed appropriate differentiation operations for objects such as the directional derivative of a function, the exterior derivative of a form, the velocity of a curve, and the tangent map of a mapping. These differentiation operations all exhibited in one form or another, the characteristic linear and Leibnizian properties of ordinary differentiation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhao Y,Li Z,Deng W,Xie R,Li Q",,Learning entity type structured embeddings with trustworthiness on noisy knowledge graphs,Knowledge-Based Systems,2021,215,,106630,,,,,2021,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705120307590;http://dx.doi.org/10.1016/j.knosys.2020.106630,10.1016/j.knosys.2020.106630,"Knowledge graphs (KGs) automatic construction generally involves fine-grained entity typing, i.e., assigning the types to given entities as (entity, entity type). Since the non-negligible inaccuracy of entity typing systems and lack of sufficient human supervision, KGs inevitably face entity type noises. However, most conventional entity type embedding models unreasonably assume that all entity type instances in existing KGs are completely correct, which ignore noises and could lead to potential errors for down-stream tasks. To address this issue, we propose TrustE to build trustworthiness-aware entity type structured embeddings, which takes possible entity type noises into consideration for learning better representations. Specifically, since entities and entity types are completely distinct objects, we encode them in separate entity space and entity type space with a structural projecting matrix, and learn entity type embeddings with tuple trustworthiness. To make the trustworthiness more universal, we only utilize the internal structural knowledge in existing KGs and build two tuple trustworthiness considering the local tuple and global triple information respectively, which correspondingly makes it more challenging due to the limited knowledge. We evaluate our models on three tasks: entity type noise detection, entity type prediction and classification. Experimental results on real-world datasets (FB15kET and YAGO43kET) show that our models outperform all baselines on all tasks, which verify the capability of TrustE in learning better entity type structural embeddings on noisy KGs. The source code and data of this paper can be obtained from https://github.com/Quan-SWUFE/TrustE","Knowledge graph, Entity type, Noise detection, Trustworthiness",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cappelli A,Mazzeranghi D",,An intensional semantics for a hybrid language,Data & Knowledge Engineering,1994,12,1,31-62,,,,,1994,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X94900213;http://dx.doi.org/10.1016/0169-023X(94)90021-3,10.1016/0169-023X(94)90021-3,"One of the major assumptions in designing knowledge representation formalisms in the KL-One family, was the so-called ‘intensional representation’. An intensional representation is required when two descriptions have to be compared, or when they are interpreted by qualitative processes; in other words, many processes can be activated by using the global structure of a concept, and by interpreting its properties and the relationships between these properties. In this perspective, an intensional semantics for a typical terminological language has been designed, which is quite different from the extensional models proposed so far. The semantics of the language is similar to that of data types in programming languages. Primitive concepts are denoted by a set of values. Defined concepts are denoted by their properties. A denotation thus contains the minimum number of properties which are required for an individual to be an instance of a generic concept. More precisely, the denotation is the Cartesian product of the sets denoting the properties of the genetic concept (deduced from its syntax). A role is denoted by a function which, given a tuple, returns the values of the property which individuates the role. An individual is created by instantiating the properties of the relative generic concept, used as a guide. As a result, this process creates a tuple whose elements are the instantiating properties. The instantiation chain terminates by instantiating primitive concepts on the basis of their denotation. A deeper integration between the entire system and any programming language can be reached, which implicitly gives rise to an object-oriented system. In other words, it is possible to introduce an individual concept into a programming language, like any other data type. For instance, an individual concept is passed to a function as a parameter; once it has been verified that this individual is an instance of a generic concept, or of one of its subconcepts, the function will be executed. Furthermore, an increase in the expressive power is obtained, since it makes it possible to give a formal meaning to all kinds of recursive definitions of individual and generic concepts.","Artificial Intelligence, knowledge representation, hybrid systems, intensional semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,Etherington DW,,Formalizing nonmonotonic reasoning systems,Artificial Intelligence,1987,31,1,41-85,,,,,1987,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370287900816;http://dx.doi.org/10.1016/0004-3702(87)90081-6,10.1016/0004-3702(87)90081-6,"In recent years, there has been considerable interest in nonmonotonic reasoning systems. Unfortunately, formal rigor has not always kept pace with the enthusiastic propagation of new systems. The argument has long been made that, because of the general intractability of formal systems, it is unreasonable to consider them for practical applications. This is taken as support for the use of systems such as semantic networks which, although not completely understood, can compute quickly. We suggest that this argument is not entirely convincing, and that formalizing such systems may yield dividends in terms of both clarity and correctness. We argue that formal systems, such as Reiter's default logic, provide useful tools for the specification and description of nonmonotonic systems. We present new results which enhance this usefulness. To illustrate the benefits of this approach, a theory of inheritance networks is developed. This yields a notion of correct inference, and sufficient conditions for the coherence of network inference representations.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang J,Kuffer M,Pfeffer K",,The role of spatial heterogeneity in detecting urban slums,"Computers, Environment and Urban Systems",2019,73,,95-107,,,,,2019,,0198-9715,https://www.sciencedirect.com/science/article/pii/S0198971518301947;http://dx.doi.org/10.1016/j.compenvurbsys.2018.08.007,10.1016/j.compenvurbsys.2018.08.007,"Satellite images allow characterizing and monitoring urban slums. Yet the urban landscape as a complex geographic system is composed of hierarchical patterns and discrete objects in a spatial and temporal continuum with different scales and anisotropy which can only be estimated from image snapshots. Understanding the spatial heterogeneity of slums in terms of scale and anisotropy from discrete image pixels is nontrivial and has not been explicitly addressed by image-based studies detecting slums, where scale and direction in characterizing slum features are commonly done by trial and error. This study addresses this gap by analyzing the impact of scales and anisotropy detected in the scale space and frequency domain for the calculation of texture indices that ultimately govern the detection of slums. Employing case studies of three cities with a large portion of slum population and for which we have very high resolution satellite imagery, we identify the characteristic scales of slum and formal built-up areas. Results show that the characteristic scales correspond with the optimal grain size to obtain image texture features for detecting slums, while the directional spectral energy at the pixel level identifies characteristic directions. Thus texture indices calculated at the characteristic scale and along the characteristic directions of slum patterns improve the efficiency in feature extraction and classification of slums, where optimizing the scale has a higher impact on the detection of slums than choosing the optimal directions. This study provides a framework for scientifically selecting optimal scales and directions for slum mapping studies. The framework is recommended to be tested for more general applications in land surface characterization and classification especially by using high order texture indices.","Scaling law, Anisotropy, Scales, Grain size, Direction, Separability, Slum, Informal area, Texture",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wachs JP,Frenkel B,Dori D",,Operation room tool handling and miscommunication scenarios: An object-process methodology conceptual model,Artificial Intelligence in Medicine,2014,62,3,153-163,,,,,2014,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365714001092;http://dx.doi.org/10.1016/j.artmed.2014.10.006,10.1016/j.artmed.2014.10.006,"Objective Errors in the delivery of medical care are the principal cause of inpatient mortality and morbidity, accounting for around 98,000 deaths in the United States of America (USA) annually. Ineffective team communication, especially in the operation room (OR), is a major root of these errors. This miscommunication can be reduced by analyzing and constructing a conceptual model of communication and miscommunication in the OR. We introduce the principles underlying Object-Process Methodology (OPM)-based modeling of the intricate interactions between the surgeon and the surgical technician while handling surgical instruments in the OR. This model is a software- and hardware-independent description of the agents engaged in communication events, their physical activities, and their interactions. The model enables assessing whether the task-related objectives of the surgical procedure were achieved and completed successfully and what errors can occur during the communication. Methods and material The facts used to construct the model were gathered from observations of various types of operations miscommunications in the operating room and its outcomes. The model takes advantage of the compact ontology of OPM, which is comprised of stateful objects – things that exist physically or informatically, and processes – things that transform objects by creating them, consuming them or changing their state. The modeled communication modalities are verbal and non-verbal, and errors are modeled as processes that deviate from the “sunny day” scenario. Using OPM refinement mechanism of in-zooming, key processes are drilled into and elaborated, along with the objects that are required as agents or instruments, or objects that these processes transform. The model was developed through an iterative process of observation, modeling, group discussions, and simplification. Results The model faithfully represents the processes related to tool handling that take place in an OR during an operation. The specification is at various levels of detail, each level is depicted in a separate diagram, and all the diagrams are “aware” of each other as part of the whole model. Providing ontology of verbal and non-verbal modalities of communication in the OR, the resulting conceptual model is a solid basis for analyzing and understanding the source of the large variety of errors occurring in the course of an operation, providing an opportunity to decrease the quantity and severity of mistakes related to the use and misuse of surgical instrumentations. Since the model is event driven, rather than person driven, the focus is on the factors causing the errors, rather than the specific person. This approach advocates searching for technological solutions to alleviate tool-related errors rather than finger-pointing. Concretely, the model was validated through a structured questionnaire and it was found that surgeons agreed that the conceptual model was flexible (3.8 of 5, std=0.69), accurate, and it generalizable (3.7 of 5, std=0.37 and 3.7 of 5, std=0.85, respectively). Conclusion The detailed conceptual model of the tools handling subsystem of the operation performed in an OR focuses on the details of the communication and the interactions taking place between the surgeon and the surgical technician during an operation, with the objective of pinpointing the exact circumstances in which errors can happen. Exact and concise specification of the communication events in general and the surgical instrument requests in particular is a prerequisite for a methodical analysis of the various modes of errors and the circumstances under which they occur. This has significant potential value in both reduction in tool-handling-related errors during an operation and providing a solid formal basis for designing a cybernetic agent which can replace a surgical technician in routine tool handling activities during an operation, freeing the technician to focus on quality assurance, monitoring and control of the cybernetic agent activities. This is a critical step in designing the next generation of cybernetic OR assistants.","Surgical robots, Concept formation, Conceptual modeling, Operative surgical procedures, Process model",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Harpaz Y,Prasma M",,The Grothendieck construction for model categories,Advances in Mathematics,2015,281,,1306-1363,,,,,2015,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870815002030;http://dx.doi.org/10.1016/j.aim.2015.03.031,10.1016/j.aim.2015.03.031,"The Grothendieck construction is a classical correspondence between diagrams of categories and coCartesian fibrations over the indexing category. In this paper we consider the analogous correspondence in the setting of model categories. As a main result, we establish an equivalence between suitable diagrams of model categories indexed by M and a new notion of model fibrations over M. When M is a model category, our construction endows the Grothendieck construction with a model structure which gives a presentation of Lurie's ∞-categorical Grothendieck construction and enjoys several good formal properties. We apply our construction to various examples, yielding model structures on strict and weak group actions and on modules over algebra objects in suitable monoidal model categories.","Grothendieck construction, Model category, Infinity-category",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Kikuchi Y,Kishinami T",Usui E,Hierarchical Process Model and Description Architecture of Concurrent Design and Engineering Process,,1994,,,27-32,,Elsevier,Amsterdam,Advancement of Intelligent Production,1994,9780444819017,,https://www.sciencedirect.com/science/article/pii/B9780444819017500190;http://dx.doi.org/10.1016/B978-0-444-81901-7.50019-0,10.1016/B978-0-444-81901-7.50019-0,"A subject is to represent a concurrent design and manufacturing activity among several groups using a formal description technique. We propose a hierarchical design and manufacturing model that is consist of three parts. The first part is a design group mode for a static design group organization. The second is a design information model for a design process information. The third is a dynamic design process model. To describe the static design group model, we newly propose an inheritance modeling architecture in the formal description technique and describe a hierarchical design and manufacturing model.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Srivastava HM,Owa S",,Some applications of fractional calculus operators to certain classes of analytic and multivalent functions,Journal of Mathematical Analysis and Applications,1987,122,1,187-196,,,,,1987,,0022-247X,https://www.sciencedirect.com/science/article/pii/0022247X87903532;http://dx.doi.org/10.1016/0022-247X(87)90353-2,10.1016/0022-247X(87)90353-2,"Let T(p) be the class of analytic and p-valent functions with negative coefficients. Also let T∗(p,α) and C(p,α) denote the subclasses of T(p) consisting of p-valent starlike functions of order α and p-valent convex functions of order α, respectively. The object of the present paper is to prove various distortion theorems for the fractional calculus of functions in the classes T∗(p,α) and C(p,α). By specializing the parameters involved, the corresponding results for several interesting subclasses of analytic functions can easily be deduced.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Kung DC,,The behavior network model for conceptual information modeling,Information Systems,1993,18,1,1-21,,,,,1993,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437993900394;http://dx.doi.org/10.1016/0306-4379(93)90039-4,10.1016/0306-4379(93)90039-4,The Behavior Network Model (BNM) for conceptual information modeling is described. A BNM description specifies both the static and dynamic aspects of an application. Static aspect modeling describes the structural properties of real world objects and their structural relationships. The dynamic aspect is modeled by processes and their interfaces. BNM allows formal analysis of model descriptions and facilitates rapid prototyping. A methodology for conceptual modeling using BNM is also described.,"Information systems, conceptual modeling, methodology, formal method",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chroust S,Vincze M",,Comparison of Prediction Methods for Vision-Based Control of Motion,IFAC Proceedings Volumes,2000,33,27,207-212,,,,,2000,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017379302;http://dx.doi.org/10.1016/S1474-6670(17)37930-2,10.1016/S1474-6670(17)37930-2,"Vision-based control of motion has the main problem of handling the latency produced by acquiring and processing the CCD image. This paper evaluates different image processing architectures (on-the-fly, serial, parallel, pipeline) and control laws (PID, FF, GPC). A formal maximum is derived for the dynamic performance, that is, the highest average velocity the object can move without being lost. Since on-the-fly processing is unobtainable for most applications, a parallel processing architecture gives best results independent of the control law and computing power. Tracking a colored object with a pan/tilt unit tests the performance of the three control laws. The results show the good behavior of the FF-controller and GPC.","Predictive control, Visual motion, Control laws, Optimal Control","6th IFAC Symposium on Robot Control (SYROCO 2000), Vienna, Austria, 21-23 September 2000",,,,,,,,,,,,,,,,,,,,
Journal Article,"Fabricio DA,da Silva Hack P,ten Caten CS",,Estimation of the measurement uncertainty in the anisotropy test,Measurement,2016,93,,303-309,,,,,2016,,0263-2241,https://www.sciencedirect.com/science/article/pii/S0263224116303864;http://dx.doi.org/10.1016/j.measurement.2016.07.027,10.1016/j.measurement.2016.07.027,"The evaluation of the sheet metal drawability in mechanical shaping processes depends on a large number of analysis, among which the anisotropy evaluation. Nowadays, there is no Brazilian test laboratory accredited by the Metrology, Quality and Technology National Institute (INMETRO) to perform this analysis. So, the object of the present work is to establish a procedure for the estimation of the measurement uncertainty in the plastic anisotropy ratio of sheet metals, in accordance to the Guide to the Expression of Uncertainty in Measurement (GUM), aiming at the accreditation of this test in the Physical Metallurgy Laboratory. As results, we present the calculations performed and the uncertainty form proposed, and an analysis of which sources contributed the most for the uncertainty in the execution of a test. Finally, we propose improvement actions aiming at the reduction of the calculated uncertainty and the adequacy of the Measurement System for the desired application.","Measurement uncertainty, GUM, Anisotropy, Plastic strain ratio",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gutirrez de Mesa JA,Fernández-del-Castillo JR,Rodrigo JA,Hilera JR,Lucas Carreras F,Abanades C,Baldominos G",,A tool to reveal information on dependencies and relationships among the elements of successive document versions,Advances in Engineering Software,2001,32,4,279-283,,,,,2001,,0965-9978,https://www.sciencedirect.com/science/article/pii/S0965997800000971;http://dx.doi.org/10.1016/S0965-9978(00)00097-1,10.1016/S0965-9978(00)00097-1,"The algebraic theory of formal concept analysis can be quite helpful in recovering information concerning semantic structures from unordered information sets. In the case of binary object relationships, it is possible to associate them to a network tree. Such a process reveals the structure of the information. In the present paper, we apply the concept analysis to the identification of the conflicts resulting from effects due to changes in the information configuration brought forth along the successive document versions.","Management, Configuration, Network diagram, Binary relationships",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cruzeiro AB,Malliavin P",,"Renormalized Differential Geometry on Path Space: Structural Equation, Curvature",Journal of Functional Analysis,1996,139,1,119-181,,,,,1996,,0022-1236,https://www.sciencedirect.com/science/article/pii/S0022123696900816;http://dx.doi.org/10.1006/jfan.1996.0081,10.1006/jfan.1996.0081,"The theory of integration in infinite dimensions is in some sense the backbone of probability theory. On this backbone the stochastic calculus of variations has given rise to the flesh of differential calculus. Its first step is the construction at each point of the probability space of a Cameron–Martin-like tangent space in which the desired differential calculus can be developed. This construction proceeds along the lines of first-order differential geometry. In this paper we address the following questions: what could be the meaning of “curvature of the probability space”—how and why? How can curvatures be defined and computed? Why could a second-order differential geometry be relevant to stochastic analysis? We try to answer these questions for the probability space associated to the Brownian motion of a compact Riemannian manifold. Why? A basicenergy identity for anticipative stochastic integralswill be obtained as a byproduct of our computation of curvature. How? There are essentially four bottlenecks in the development of differential geometry on Wiener–Riemann manifolds: (i) the difficulty of finding an atlas of local charts such that the changes of charts preserve the class of the Wiener-like measures together with their associated Cameron–Martin-like tangent spaces; (ii) the difficulty of finding cylindrical approximations preserving the natural geometrical objects; (iii) the difficulty of renormalizing the divergent series to which the summation operations of finite dimensional differential geometry give rise in the non intrinsic context of local charts; (iv) the nonavailability of the computational procedures analogous to the local coordinates systems of the classical differential geometry. In the context of path space, the Itô filtration provides a much richer structure than that available in the framework of an abstract Wiener–Riemann manifold. Our work is a systematic attempt to replace the machinery of local charts with amethodology of moving frames. In our context, stochastic parallel transport provides a canonical moving frame on the path space. The concept of a cylindrical approximation has to be reshaped in our new situation into some geometric limit theorems, establishing that the Riemannian geometric objects of the cylindrical approximations induce by a limiting procedure geometric objects on the path space. Those limit theorems are reminiscent of the classical theorems which say that a Stratonovich SDE is the limit of an appropriate sequence of ODE. The canonical coordinate system provided by the moving frame will make it possible to proceed to the needed renormalizations byintrinsicstochastic integrals; in this context the anticipative stochastic integral theory of Nualart and Pardoux will play a decisive role. Finally, the moving frame will provide aneffective algorithm of computation for this differential geometry in infinite dimensions. In our study we encounter a new type of renormalization, thehypoelliptic renormalization, which corresponds to the fact that the bracket of smooth vector fields taking their values in the Cameron–Martin space can get out of this Cameron–Martin space. This hypoelliptic problem induces the nonrenormalizability of some geometrical objects. It leads also to a concept oftangent processesto probability spaces extending that based on the Cameron–Martin Theorem. For tangent processes a formula of integration by parts still holds; furthermore the tangent processes form a Lie algebra under the bracket. On the other hand, tangent processes cannot be stochastically integrated: this operation is well defined only for Cameron–Martin-type vector fields.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Muskens R,"Blackburn P,Van Benthem J,Wolter F",10 Higher order modal logic,,2007,3,,621-653,,Elsevier,,Handbook of Modal Logic,2007,,1570-2464,https://www.sciencedirect.com/science/article/pii/S1570246407800139;http://dx.doi.org/10.1016/S1570-2464(07)80013-9,10.1016/S1570-2464(07)80013-9,"Publisher Summary This chapter focuses at some of the motivations for combining modality with quantification and abstraction over objects of higher order. The basic ideas of modal logic are extended to higher-order settings and extended in a number of different ways. The chapter discusses Richard Montague's system of “Intensional Logic,” which is by far the most influential of higher order modal logics to date. The logic is not fully intensional, as it validates the axiom of extensionality. This leads to a series of well-known problems centering on “logical omniscience” and the logic is not Church-Rosser. An exposition of a modal type theory is intensional in two ways: in the sense of being a modal logic and in the sense that extensionality does not hold. The chapter explains the basic syntax and semantics of this logic, discusses a tableau calculus, and outlines the elementary model theory in the form of a model existence theorem and its usual corollaries, such as generalized completeness.",,,Studies in Logic and Practical Reasoning,,,,,,,,,,,,,,,,,,,
Journal Article,"Combi C,Oliboni B,Rossato R",,Merging multimedia presentations and semistructured temporal data: a graph-based model and its application to clinical information,Artificial Intelligence in Medicine,2005,34,2,89-112,,,,,2005,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365704001642;http://dx.doi.org/10.1016/j.artmed.2004.11.003,10.1016/j.artmed.2004.11.003,"Summary Objective: In this paper, we focus on the issue of providing physicians with the capability of representing in a seamless way both temporal aspects of multimedia semistructured data and their temporal presentation requirements. Background: Semistructured data are data having some structure, that may be irregular or incomplete and does not necessarily conform to a fixed schema. Semistructured data often contain the description of histories of the considered real world. The eXtensible Markup Language (XML) is becoming a cross compatible and standardized means for representing semistructured clinical data. In the field of medical informatics, there are many ongoing activities concerning XML. In the field of multimedia database systems, the topic related to the integration of several media objects (with their temporal aspects) have been considered both for data modeling and querying issues and for modeling multimedia presentations. Methodology: We first propose the Multimedia Temporal Graphical Model (MTGM), by representing a clinical database for cardiology patients undergoing cardiac angiographies and then describe it in a formal way. We deal with the problem of expressing MTGM data by XML and of managing MTGM clinical data through an XML-based system. We provide both a technique for translating (a part of) an MTGM database into an XML document and some techniques allowing us to obtain presentations defined by means of the Synchronized Multimedia Integration Language (SMIL) from MTGM presentations. Results: MTGM allows one to represent and store clinical information in a semistructured, temporal, and multimedia database. The physician can define multimedia presentations based on the stored data. Multimedia presentations are then stored in the same MTGM database together with temporal clinical information and are thus represented according to the same data model. A prototype based on an XML native database system has been designed and implemented. Discussion and conclusions: In this work we have considered the theoretical and methodological issues concerning the definition of a general data model for describing temporal and multimedia features of semistructured clinical information. Other research and application oriented features, which have not been considered in MTGM, could be investigated for completing MTGM with regard to its applicability to clinical domains: MTGM does not allow one to express times at different levels of granularities, i.e. with different time units, or with indeterminacy; besides the considered valid time, it could be interesting to manage also other temporal dimensions such as the transaction and availability times. Besides being useful for managing multimedia data stored according to widely accepted standards as MPEG and DICOM, nowadays semistructured data, and XML in particular, are becoming the most important way for expressing and exchanging medical knowledge and data: MTGM can be considered as a data model allowing the seamless representation of both (multimedia and temporal) clinical data and knowledge.","Temporal clinical data, Semistructured data, Multimedia, Multimedia presentations, Data model, Cardiology data",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Qian Z,Tudor J",,Differential structure and flow equations on rough path space,Bulletin des Sciences Mathématiques,2011,135,6,695-732,,,,,2011,,0007-4497,https://www.sciencedirect.com/science/article/pii/S0007449711000807;http://dx.doi.org/10.1016/j.bulsci.2011.07.011,10.1016/j.bulsci.2011.07.011,"We introduce a differential structure for the space of weakly geometric p rough paths over a Banach space V for 2<p<3. We begin by considering a certain natural family of smooth rough paths and differentiating in the truncated tensor series. The resulting object has a clear interpretation, even for non-smooth rough paths, which we take to be an element of the tangent space. We can associate it uniquely to an equivalence class of curves, with equivalence defined by our differential structure. Thus, for a functional on rough path space, we can define the derivative in a tangent direction analogous to defining the derivative in a Cameron–Martin direction of a functional on Wiener space. Our tangent space contains many more directions than the Cameron–Martin space and we do not require quasi-invariance of Wiener measure. In addition we also locally (globally) solve the associated flow equation for a class of vector fields satisfying a local (global) Lipshitz type condition.","Malliavin calculus, Rough paths, Tangent spaces",Special issue in memory of Paul Malliavin,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shankar NG,Zhong ZW",,A rule-based computing approach for the segmentation of semiconductor defects,Microelectronics Journal,2006,37,6,500-509,,,,,2006,,0026-2692,https://www.sciencedirect.com/science/article/pii/S002626920500296X;http://dx.doi.org/10.1016/j.mejo.2005.07.018,10.1016/j.mejo.2005.07.018,"This paper presents a rule-based approach to detect defect patterns and to classify the defect patterns that appear on the semiconductor wafer surfaces. To obtain a general and modular defect pattern detection technique, the proposed approach adopts a hierarchical perspective. A formal analogy has been drawn between the structure of defect patterns and the symptom of disease in clinical practice. The defect patterns to be recognized are viewed as decision made to a particular disease. Design goals include detection of flaws and correlation of defect features based on co-occurrence matrix. The system is capable of identifying the defects on the wafers after die sawing. Each unique defect structure is defined as an object. Objects are grouped into user-defined categories such as chipping, metallization peel off, silicon dust contamination, etc. after die sawing and micro-crack, scratch, ink dot being washed off, bridging, etc. from the wafer.","Machine vision, Clinical rule, Defect type, Referential inspection, Rule-based",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Jurasky W,Moder P,Milde M,Ehm H,Reinhart G",,Transformation of semantic knowledge into simulation-based decision support,Robotics and Computer-Integrated Manufacturing,2021,71,,102174,,,,,2021,,0736-5845,https://www.sciencedirect.com/science/article/pii/S0736584521000569;http://dx.doi.org/10.1016/j.rcim.2021.102174,10.1016/j.rcim.2021.102174,"Simulation is capable to cope with the uncertain and dynamic nature of industrial value chains. However, in-depth system expertise is inevitable for mapping objects and constraints from the real world to a virtual model. This knowledge-intensity leads to long development times of respective projects, which contradicts the need for timely decision support. Since more and more companies use industrial knowledge graphs and ontologies to foster their knowledge management, this paper proposes a framework on how to efficiently derive a simulation model from such semantic knowledge bases. As part of the approach, a novel Simulation Ontology provides a standardized meta-model for hybrid simulations. Its instantiation enables the user to come up with a fully parameterized formal simulation model. Newly developed Mapping Rules facilitate this process by providing guidance on how to turn knowledge from existing ontologies, which describe the system to be simulated, into instances of the Simulation Ontology. The framework is completed by a parsing procedure for an automated transformation of this conceptual model into an executable one. This novel modeling approach makes model development more efficient by reducing its complexity. It is validated in a use case implementation from semiconductor manufacturing, where cross-domain knowledge was required in order to model and simulate the impacts of the COVID-19 pandemic on a global supply chain network.","Knowledge transformation, Decision support, Ontologies, Hybrid modeling, Pandemic simulation, Supply chain simulation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ciesielski KC,Udupa JK",,Affinity functions in fuzzy connectedness based image segmentation II: Defining and recognizing truly novel affinities,Computer Vision and Image Understanding,2010,114,1,155-166,,,,,2010,,1077-3142,https://www.sciencedirect.com/science/article/pii/S107731420900143X;http://dx.doi.org/10.1016/j.cviu.2009.09.005,10.1016/j.cviu.2009.09.005,"Affinity functions — the measure of how strongly pairs of adjacent spels in the image hang together — represent the core aspect (main variability parameter) of the fuzzy connectedness (FC) algorithms, an important class of image segmentation schemas. In this paper, we present the first ever theoretical analysis of the two standard affinities, homogeneity and object-feature, the way they can be combined, and which combined versions are truly distinct from each other. The analysis is based on the notion of equivalent affinities, the theory of which comes from a companion Part I of this paper (Ciesielski and Udupa, in this issue) [11]. We demonstrate that the homogeneity based and object feature based affinities are equivalent, respectively, to the difference quotient of the intensity function and Rosenfeld’s degree of connectivity. We also show that many parameters used in the definitions of these two affinities are redundant in the sense that changing their values lead to equivalent affinities. We finish with an analysis of possible ways of combining different component affinities that result in non-equivalent affinities. In particular, we investigate which of these methods, when applied to homogeneity based and object-feature based components lead to truly novel (non-equivalent) affinities, and how this is affected by different choices of parameters. Since the main goal of the paper is to identify, by formal mathematical arguments, the affinity functions that are equivalent, extensive experimental confirmations are not needed — they show completely identical FC segmentations — and as such, only relevant examples of the theoretical results are provided. Instead, we focus mainly on theoretical results within a perspective of the fuzzy connectedness segmentation literature.","Affinity, Fuzzy connectedness, Image segmentation, Equivalence of algorithms",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aceto L,Victor B",,"Preface: Volume 39, Issue 1",Electronic Notes in Theoretical Computer Science,2003,39,1,1-2,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105825009;http://dx.doi.org/10.1016/S1571-0661(05)82500-9,10.1016/S1571-0661(05)82500-9,"The EXPRESS workshops aim at bringing together researchers interested in the relations between various formal systems, particularly in the field of Concurrency. More specifically, they focus on the comparison between programming concepts (such as concurrent, functional, imperative, logic and object-oriented programming) and between mathematical models of computation (such as process algebras, Petri nets, event structures, modal logics, rewrite systems etc.) on the basis of their relative expressive power. The EXPRESS workshops were originally held as meetings of the HCM project EXPRESS, which was active with the same focus from January 1994 till December 1997. The first three workshops were held respectively in Amsterdam (1994, chaired by Frits Vaandrager), Tarquinia (1995, chaired by Rocco De Nicola), and Dagstuhl (1996, co-chaired by Ursula Goltz and Rocco De Nicola). The workshop in 1997, which took place in Santa Margherita Ligure and was co-chaired by Catuscia Palamidessi and Joachim Parrow, was organized as a conference with a call for papers and a significant attendance from outside the project. The 1998 workshop was held as a satellite workshop of the CONCUR'98 conference in Nice, co-chaired by Ilaria Castellani and Catuscia Palamidessi, and like on that occasion EXPRESS'99 was hosted by the CONCUR'99 conference in Eindhoven, co-chaired by Ilaria Castellani and Björn Victor. This volume contains the Proceedings of EXPRESS'00, which was held in State College (Pennsylvania, USA) on 21 August 2000. It includes the six papers that were selected for presentation by the program committee, together with the contribution by the invited speaker, Neil D. Jones (DIKU, Denmark). We would like to thank the authors of the submitted papers, the invited speakers, and the members of the program committee for their contribution to both the meeting and this volume. Many thanks to Catuscia Palamidessi and Dale Miller (CONCUR 2000 Conference Chairs), and Uwe Nestmann (Satellite Workshops Chair), for the opportunity they gave us to organize EXPRESS'00, and for their continuous support. We would also like to thank Michael Mislove and Uffe Engberg for their help with the editing of the proceedings. Finally, we gratefully acknowledge the support of BRICS (Basic Research in Computer Science), Centre of the Danish National Research Foundation. EXPRESS'00 Programme Committe Luca Aceto(DK)Karen Bernstein Jeffrey(USA)Rance Cleaveland(USA)Wan Fokkink(NL)Rob van Glabbeek(NL)Ursula Goltz(DE)Rosario Pugliese(IT)Julian Rathke(UK)Davide Sangiorgi(FR)Björn Victor(SE)Igor Walukiewicz(PL) Luca Aceto and Björn Victor, Guest Editors",,"EXPRESS'00, 7th International Workshop on Expressiveness in Concurrency (Satellite Workshop from CONCUR 2000)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Imine A,Rusinowitch M,Oster G,Molli P",,Formal design and verification of operational transformation algorithms for copies convergence,Theoretical Computer Science,2006,351,2,167-183,,,,,2006,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439750500616X;http://dx.doi.org/10.1016/j.tcs.2005.09.066,10.1016/j.tcs.2005.09.066,"Distributed groupware systems provide computer support for manipulating objects such as a text document or a filesystem, shared by two or more geographically separated users. Data replication is a technology to improve performance and availability of data in distributed groupware systems. Indeed, each user has a local copy of the shared objects, upon which he may perform updates. Locally executed updates are then transmitted to the other users. This replication potentially leads, however, to divergent (i.e. different) copies. In this respect, Operational Transformation (OT) algorithms are applied for achieving convergence of all copies, i.e. all users view the same objects. Using these algorithms users can exchange their updates in any order since the convergence should be ensured in all cases. However, the design of such algorithms is a difficult and error-prone activity since building the correct updates for maintaining good convergence properties of the local copies requires examining a large number of situations. In this paper, we present the modelling and deductive verification of OT algorithms with algebraic specifications. We show in particular that many OT algorithms in the literature do not satisfy convergence properties unlike what was stated by their authors.","Distributed groupware systems, Replication, Operational transformation, Algebraic specification, Automated verification",Algebraic Methodology and Software Technology,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hamaker Z,Marberg E,Pawlowski B",,Involution words: Counting problems and connections to Schubert calculus for symmetric orbit closures,"Journal of Combinatorial Theory, Series A",2018,160,,217-260,,,,,2018,,0097-3165,https://www.sciencedirect.com/science/article/pii/S009731651830092X;http://dx.doi.org/10.1016/j.jcta.2018.06.012,10.1016/j.jcta.2018.06.012,"Involution words are variations of reduced words for involutions in Coxeter groups, first studied under the name of “admissible sequences” by Richardson and Springer. They are maximal chains in Richardson and Springer's weak order on involutions. This article is the first in a series of papers on involution words, and focuses on their enumerative properties. We define involution analogues of several objects associated to permutations, including Rothe diagrams, the essential set, Schubert polynomials, and Stanley symmetric functions. These definitions have geometric interpretations for certain intervals in the weak order on involutions. In particular, our definition of “involution Schubert polynomials” can be viewed as a Billey–Jockusch–Stanley type formula for cohomology class representatives of On- and Sp2n-orbit closures in the flag variety, defined inductively in recent work of Wyser and Yong. As a special case of a more general theorem, we show that the involution Stanley symmetric function for the longest element of a finite symmetric group is a product of staircase-shaped Schur functions. This implies that the number of involution words for the longest element of a finite symmetric group is equal to the dimension of a certain irreducible representation of a Weyl group of type B.","Permutations, Involutions, Reduced words, Schubert polynomials, Stanley symmetric functions, Bruhat order, Spherical varieties, Coxeter groups",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kirby JM,,System development — the challenges of re-useability,Microprocessors and Microsystems,1995,19,9,503-510,,,,,1995,,0141-9331,https://www.sciencedirect.com/science/article/pii/0141933196892775;http://dx.doi.org/10.1016/0141-9331(96)89277-5,10.1016/0141-9331(96)89277-5,"This paper describes the challenges faced by aerospace avionic systems developers in the 1990s, as they use ‘in anger’ both best-practice processes and state-of-the-art tools to try and achieve that most elusive goal in a large system development: Re-useable designs, meeting all customer needs, on-time, and within budget. The Boeing 777 electrical load management system (ELMS) developed by Smiths Industries Civil Systems, Cheltenham, has involved up to 250 engineers since 1991. It is an example of military technology being applied in the civil sector, and integrates over 50 aircraft utility systems as well as managing the supply of electrical power. The author has been Engineering Manager for this system since its inception, and takes this project as an example of large system development. He shares the advantages of those process approaches and types of tool which worked, and the disadvantages of those approaches which were less successful. The objectives of this paper are: •⊗ To share practical experience of current methods and types of tool for requirements capture, structured analysis, object-oriented design (which is very different to methodologies used only a decade ago), verification/validation and certification.•⊗ To discuss where these modern methods and tools assist reuseability, and where they impede it.•⊗ To describe the fresh management challenges they present, such as lack of visibility (-it's all in the system, if you know how to access it!).•⊗ To examine the design review strategies which and most value with these methods. (More peer-level reviews; less large formal meetings.)•⊗ To review how well these modern methods cope when faced with customer specification changes — both small changes and large-scale changes. (Is there much value in huge volumes of traceability information if it is all to be scrapped by a large change?) The paper also emphasizes the human elements in a successful development. Examples are the value of co-locating good engineers with customers (and good customer engineers within the developer's teams) and how this compares with technology such as datalinks, conference calls and videoconferencing; the values of concurrent engineering within the project; and good communication at all levels (technical and managerial). The author believes that even with best-class processes and tools, you still need good engineers to have a successful outcome!","system development, re-useability",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Huang J,Zhu Q,Yang L,Feng J",,A non-parameter outlier detection algorithm based on Natural Neighbor,Knowledge-Based Systems,2016,92,,71-77,,,,,2016,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705115004013;http://dx.doi.org/10.1016/j.knosys.2015.10.014,10.1016/j.knosys.2015.10.014,"Outlier detection is an important task in data mining with numerous applications, including credit card fraud detection, video surveillance, etc. Although many Outlier detection algorithm have been proposed. However, for most of these algorithms faced a serious problem that it is very difficult to select an appropriate parameter when they run on a dataset. In this paper we use the method of Natural Neighbor to adaptively obtain the parameter, named Natural Value. We also propose a novel notion that Natural Outlier Factor (NOF) to measure the outliers and provide the algorithm based on Natural Neighbor (NaN) that does not require any parameters to compute the NOF of the objects in the database. The formal analysis and experiments show that this method can achieve good performance in outlier detection.","Outlier detection, Natural Neighbor, Natural Outlier Factor",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Egli H,Constable RL",,Computability concepts for programming language semantics,Theoretical Computer Science,1976,2,2,133-145,,,,,1976,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397576900293;http://dx.doi.org/10.1016/0304-3975(76)90029-3,10.1016/0304-3975(76)90029-3,"This paper is about mathematical problems in programming language semantics and their influence on recursive function theory. We define a notion of computability on continuous higher types (for all types) and show its equivalence to effective operators. This resuit shows that our computable operators can model mathematically (i.e. extensionally) everything that can be done in an operational semantics. These new recursion theoretic concepts which are appropriate to semantics also allow us to construct Scott models for the λ-calculus which contain all and only computably elements. Depending on the choice of the initial cpo, our general theory yields a theory for either strictly determinate or else arbitrary non-deterministic objects (parallelism). The formal theory is developed in Part II of this paper. Part I gives motivation and comparison with related work.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Artemov S,"Blackburn P,Van Benthem J,Wolter F",16 Modal logic in mathematics,,2007,3,,927-969,,Elsevier,,Handbook of Modal Logic,2007,,1570-2464,https://www.sciencedirect.com/science/article/pii/S157024640780019X;http://dx.doi.org/10.1016/S1570-2464(07)80019-X,10.1016/S1570-2464(07)80019-X,"Publisher Summary Formal modal logic is mostly mathematical in its methods, regardless of area of application. This chapter presents a wide variety of mathematical techniques developed over decades of studying the intricate details of modal logic. Mathematics normally finds a proper language and level of abstraction for the study of its objects. Propositional modal logic offers a new paradigm of applying logical methods: instead of using the traditional languages with quantification to describe a structure, an appropriate quantifier-free language with additional logic operators that represent the phenomenon at hand, is used. Mathematics is one of modal logic's oldest application areas. There are two major ideas that dominate the landscape of modal logic application in mathematics: Gödel's provability semantics and Tarski's topological semantics. Gödel's use of modal logic to describe provability, gave the first exact semantics of modality. This approach led to comprehensive provability semantics for a broad class of modal logics. It also proved vital for applications such as the Brouwer–Heyting–Kolmogorov provability semantics for intuitionistic logic, for introducing justification into formal epistemology and tackling its logical omniscience problem, and for introducing self reference into combinatory logic and lambda-calculi.",,,Studies in Logic and Practical Reasoning,,,,,,,,,,,,,,,,,,,
Journal Article,"Fenton NE,Mole PDA",,A note on the use of Z to specify flowgraph decomposition,Information and Software Technology,1988,30,7,432-437,,,,,1988,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584988900407;http://dx.doi.org/10.1016/0950-5849(88)90040-7,10.1016/0950-5849(88)90040-7,"During the course of research into software metrication a formal specification was required for a system to process program flowgraphs. This note gives specifications for some of the objects in the system. The Z notation was used to write the specifications, it has proved apt for the purpose, enabling one to write succinct specifications in terms of a basic definition of a flowgraph.","program flowgraph, software metrics, formal specification, Z notation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Reed J,,Redundancy Elimination for LF,Electronic Notes in Theoretical Computer Science,2008,199,,89-106,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108000807;http://dx.doi.org/10.1016/j.entcs.2007.11.014,10.1016/j.entcs.2007.11.014,"We present a type system extending the dependent type theory LF, whose terms are more amenable to compact representation. This is achieved by carefully omitting certain subterms which are redundant in the sense that they can be recovered from the types of other subterms. This system is capable of omitting more redundant information than previous work in the same vein, because of its uniform treatment of higher-order and first-order terms. Moreover the ‘recipe’ for reconstruction of omitted information is encoded directly into annotations on the types in a signature. This brings to light connections between bidirectional (synthesis vs. checking) typing algorithms of the object language on the one hand, and the bidirectional flow of information in the ambient encoding language. The resulting system is a compromise seeking to retain both the effectiveness of full unification-based term reconstruction such as is found in implementation practice, and the logical simplicity of pure LF.","Proof Compression, Dependent Type Theory, Bidirectional Type Checking",Proceedings of the Fourth International Workshop on Logical Frameworks and Meta-Languages (LFM 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Meng S,Aichernig BK,Barbosa LS,Naixiao Z",,A Coalgebraic Semantic Framework for Component-based Development in UML,Electronic Notes in Theoretical Computer Science,2005,122,,229-245,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105000411;http://dx.doi.org/10.1016/j.entcs.2004.06.051,10.1016/j.entcs.2004.06.051,"This paper introduces a generic semantic framework for component-based development, expressed in the unified modelling language UML. The principles of a coalgebraic semantics for class, object and statechart diagrams as well as for use cases, are developed. It is also discussed how to formalize the refinement steps in the development process based upon a suitable notion of behavior refinement. In this way, a formal basis for component-based development in UML is studied, which allows the construction of more complex and specific systems from independent components.","Unified modeling language, refinement, UML, coalgebras",Proceedings of the 10th Conference on Category Theory in Computer Science (CTCS 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Meyer P,Olteanu AL",,Formalizing and solving the problem of clustering in MCDA,European Journal of Operational Research,2013,227,3,494-502,,,,,2013,,0377-2217,https://www.sciencedirect.com/science/article/pii/S037722171300043X;http://dx.doi.org/10.1016/j.ejor.2013.01.016,10.1016/j.ejor.2013.01.016,"The topic of clustering has been widely studied in the field of Data Analysis, where it is defined as an unsupervised process of grouping objects together based on notions of similarity. Clustering in the field of Multi-Criteria Decision Aid (MCDA) has seen a few adaptations of methods from Data Analysis, most of them however using concepts native to that field, such as the notions of similarity and distance measures. As in MCDA we model the preferences of a decision maker over a set of decision alternatives, we can find more diverse ways of comparing them than in Data Analysis. As a result, these alternatives may also be arranged into different potential structures. In this paper we wish to formally define the problem of clustering in MCDA using notions that are native to this field alone, and highlight the different structures which we may try to uncover through this process. Following this we propose a method for finding these structures. As in any clustering problem, finding the optimal result in an exact manner is impractical, and so we propose a stochastic heuristic approach, which we validate through tests on a large set of artificially generated benchmarks.","Clustering, Decision analysis, Metaheuristics, Combinatorial optimization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Alcalde C,Burusco A,Fuentes-González R,Zubia I",,The use of linguistic variables and fuzzy propositions in the L-Fuzzy concept theory,Computers & Mathematics with Applications,2011,62,8,3111-3122,,,,,2011,,0898-1221,https://www.sciencedirect.com/science/article/pii/S0898122111006870;http://dx.doi.org/10.1016/j.camwa.2011.08.024,10.1016/j.camwa.2011.08.024,"The use of linguistic variables and fuzzy propositions in the interval-valued L-Fuzzy contexts can be an interesting tool to extract a more complete information from them. In this paper, we analyze three different situations. First, we obtain significant relations in order to study all the objects and attributes of the interval-valued L-Fuzzy context by means of the interval-valued L-Fuzzy concepts. After that, we show how to replace the erroneous values to be able to study in a suitable way the context. Finally, we use the linguistic labels to obtain a subcontext that represents our interest of study. We also show an experimental evaluation in the paper.","Formal concept analysis, Interval-valued linguistic variables, Interval-valued fuzzy propositions, Interval-valued -Fuzzy contexts and subcontexts",,,,,,,,,,,,,,,,,,,,,
Journal Article,Rago F,,A Smart Adaptable Architecture Based on Contexts for Cyber Physical Systems,Procedia Computer Science,2015,61,,301-306,,,,,2015,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050915029713;http://dx.doi.org/10.1016/j.procs.2015.09.141,10.1016/j.procs.2015.09.141,"The key challenge today isn’t in manufacturing circuits but in programming the massively distributed system that will result from putting all the units together to manage daily huge amount of data with dimensionality factors depending on contexts. The use of the resulting information is even more critical. In the model for describing a particular context property, the domain of interpretation for the property represents the values that it may assume. Hierarchical Formal Concept Analysis (HFCA) models the world of data through the use of contextual objects and attributes (tags) structured in contexts. To evaluate the significance of a concept in a context we compute the significance score and we learn high-dimensional binary feature vectors through the Neural Modeling Fields (NMF) algorithm. The adaptive evolution of context models describes dynamics with different complexity. Each dynamic mode is associated with a mode behavior, the set of trajectories that satisfies the dynamical laws of that mode in a context. A switching signal (an event) determines when a transition occurs between dynamic modes. Symbolic control of nonlinear systems is based on an approximate notion of simulation relation, a way of obtaining feedback control laws.","Machine Learning, Big Data Analytics, Smart Systems Architecting, Cyber Physical Systems, Contexts, Formal Concept Analysis, Adaptive evolution, Mode behavior","Complex Adaptive Systems San Jose, CA November 2-4, 2015",,,,,,,,,,,,,,,,,,,,
Journal Article,"Buneman P,Naqvi S,Tannen V,Wong L",,Principles of programming with complex objects and collection types,Theoretical Computer Science,1995,149,1,3-48,,,,,1995,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759500024Q;http://dx.doi.org/10.1016/0304-3975(95)00024-Q,10.1016/0304-3975(95)00024-Q,"We present a new principle for the development of database query languages that the primitive operations should be organized around types. Viewing a relational database as consisting of sets of records, this principle dectates that we should investigate separately operations for records and sets. There are two immediate advantages of this approach, which is partly inspired by basic ideas from category theoryl. First, it provides a language for structures in which record and set types may be freely combined: nested relations or complex objects. Second, the fundamental operations for sets are closely related to those for other “collection types” such as bags or lists, and this suggests how database languages may be uniformly extended to these new types. the most general operation on sets, that of structural recursion, is one in which not all programs are well-defined. In looking for limited forms of this operation that always give rise to well-defined operations, we find a number of close connection with exiting database languages, notably those developed for complex objects. Moreover, even though the general paradigm of structural recursion is shown to be no more expressive than one of the existing languages for complex objects, it possesses certain properties of uniformity that make it a better candidate for an efficient, practical language. Thus rather than developing query languages by extending, for example, relational calculus, we advocate a very powerful paradigm in which a number of well-known languages are to be found as natural sublanguages.",,Fourth International Conference on Database Theory (ICDT '92),,,,,,,,,,,,,,,,,,,,
Journal Article,"Sadeghi Esfahlani S,Muresan B,Sanaei A,Wilson G",,Validity of the Kinect and Myo armband in a serious game for assessing upper limb movement,Entertainment Computing,2018,27,,150-156,,,,,2018,,1875-9521,https://www.sciencedirect.com/science/article/pii/S1875952117300952;http://dx.doi.org/10.1016/j.entcom.2018.05.003,10.1016/j.entcom.2018.05.003,"A cost-effective, easily-accessible neuro-motor rehabilitation solution is proposed that can determine the range of motion and the kinematic ability of participants. A serious game comprising four-scenarios are developed in which the players control an avatar that mirrors the rotations of the upper-limb joints through multi-channel-input devices (Kinect, Myo, FootPedal). Administered functional reach tests (FRT) challenge the player to interact with a 3D-environment while standing or sitting and using the FootPedal which simulates the action of walking whilst body movement is measured concurrently. The FRT’s complexity level is adapted using a Monte Carlo Tree Search algorithm which determines a virtual object’s position based on the proved ability of the user. Twenty-three volunteers were recruited to play the game in 45-min sessions. The data show that the system has a more positive impact on players performance and is more motivating than formal therapy. The visual representation of the trajectory of the objects is shown to increase the perception of the participants voluntary/involuntary upper extremity movement, and the results show a comparable inter-session reliability (acceptable-good) over two repeated sessions. A high Pearson correlation demonstrates the validity of using Kinect and Myo devices in assessing upper-limb rehabilitation, and the timing and the clinically relevant movement data have a higher accuracy when the devices are paired.","Kinect v2, Monte Carlo Tree Search (MCTS), Myo armband, FootPedal",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Csuhaj-Varjú E,Verlan S",,On generalized communicating P systems with minimal interaction rules,Theoretical Computer Science,2011,412,1,124-135,,,,,2011,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439751000455X;http://dx.doi.org/10.1016/j.tcs.2010.08.020,10.1016/j.tcs.2010.08.020,"Generalized communicating P systems are purely communicating tissue-like membrane systems with communication rules which allow the movement of only pairs of objects. In this paper, we study the power of these systems in the case of eight restricted variants of communication rules. We show that seven of these restrictions lead to computational completeness, while using the remaining one the systems are able to compute only finite singletons of non-negative integers. The obtained results complete the investigations of the computational power of generalized communicating P systems and provide further examples for simple architectures with simple functioning rules which are as powerful as Turing machines.","P systems, Symport, Antiport, Minimal interactions, Formal languages, Computational completeness",Complexity of Simple Programs,,,,,,,,,,,,,,,,,,,,
Journal Article,"Francaviglia M,Palese M,Vitolo R",,The Hessian and Jacobi morphisms for higher order calculus of variations,Differential Geometry and its Applications,2005,22,1,105-120,,,,,2005,,0926-2245,https://www.sciencedirect.com/science/article/pii/S0926224504000555;http://dx.doi.org/10.1016/j.difgeo.2004.07.008,10.1016/j.difgeo.2004.07.008,"We formulate higher order variations of a Lagrangian in the geometric framework of jet prolongations of fibered manifolds. Our formalism applies to Lagrangians which depend on an arbitrary number of independent and dependent variables, together with higher order derivatives. In particular, we show that the second variation is equal (up to horizontal differentials) to the vertical differential of the Euler–Lagrange morphism which turns out to be self-adjoint along solutions of the Euler–Lagrange equations. These two objects, respectively, generalize in an invariant way the Hessian morphism and the Jacobi morphism (which is then self-adjoint along critical sections) of a given Lagrangian to the case of higher order Lagrangians. Some examples of classical Lagrangians are provided to illustrate our method.","Fibered manifold, Jet space, Variational sequence, Second variation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Brinksma E,"Parker KR,Rose GA","What is the Method in Formal Methods?**This work has been supported in part by the CEC research programmes ESPRIT (LOTOSPHERE, ref: 2303) and RACE (SPECS, ref: 1046)",,1992,,,33-50,,Elsevier,Amsterdam,"Formal Description Techniques, IV",1992,9780444894021,,https://www.sciencedirect.com/science/article/pii/B9780444894021500126;http://dx.doi.org/10.1016/B978-0-444-89402-1.50012-6,10.1016/B978-0-444-89402-1.50012-6,"Many of the formal methods that abound in computer science are in fact just formal languages or calculi. They can be used to describe and analyse models of information systems of different complexities and application domains. Only to a much lesser extent are we also provided with methods that tell exactly how these models may be used to obtain working products. In this paper we attempt to analyse the difficulties of obtaining such methods by taking a look at the tension between the two fundamental approaches that underly the engineering of information systems: the formal approach, i.e. the internally consistent description of virtual objects, based on the principle of analysis by logical deduction, and the scientific approach, i.e. the externally consistent description of physical objects, based on the principle of validation (or refutation) by experimentation. One of our conclusions is that there is a need to be able to combine formal validation of designs, i.e. by mathematical means, with experimental validation of designs, i.e. by testing, within a single methodological framework. Some first ideas of what such a framework could look like are given.",,,IFIP Transactions C: Communication Systems,,,,,,,,,,,,,,,,,,,
Journal Article,"Heulluy B,Vernadat FB",,The CIMOSA Enterprise Modelling Ontology,IFAC Proceedings Volumes,1997,30,1,279-284,,,,,1997,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017446453;http://dx.doi.org/10.1016/S1474-6670(17)44645-3,10.1016/S1474-6670(17)44645-3,"To model and evaluate business processes, enterprise modelling tools and techniques are required. It is therefore necessary that all concepts and relationships underlying enterprise modelling languages be precisely defined. This is the role of ontologies. In this paper, we present an ontology for enterprise modelling based on constructs identified in the CEN ENV 12 204 (Constructs for Enterprise Modelling) and the CIMOSA modelling language. The language addresses functional, information, resource and organisational aspects of an enterprise and includes the time dimension. The ontology formally defines such concepts as activity, process, event, resource, resource capabilities, enterprise object, object view (or object state), organisation unit and organisation cell. A notion of cost can also be defined in relation to the concepts of activity and resource.","Enterprise Integration, Enterprise modelling, CIMOSA, Enterprise ontology","IFAC Workshop on Manufacturing Systems: Modelling, Management and Control, Vienna, Austria, 3-5 February",,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang KH,Chen CM,Fang W,Wu TY",,A secure authentication scheme for Internet of Things,Pervasive and Mobile Computing,2017,42,,15-26,,,,,2017,,1574-1192,https://www.sciencedirect.com/science/article/pii/S1574119216304369;http://dx.doi.org/10.1016/j.pmcj.2017.09.004,10.1016/j.pmcj.2017.09.004,"Security is one of the major issues in Internet of Things (IoT) research. The rapid growth in the number of IoT devices, the heterogeneity and complexity of these objects and their networks have made authentication a challenging task. Other constraints such as limited computational ability and power, and small storage of some embedded devices make implementation of complex cryptographic algorithms difficult. So far there has been no established industrial standard to address this problem. Recently, Kalra and Sood, and subsequently Chang et al. attempted to solve the authentication problem by proposing key agreement schemes for IoT devices. However, the security of their schemes were unproven. In this paper we demonstrate that these schemes are insecure. We extend upon their work to present a scheme that enables embedded devices to communicate securely with a server on an IoT network. We prove the security of this scheme using formal methods and demonstrate this under the intractability of some well-defined hard problems. We also discuss some practical aspects related to the implementation of the scheme.","IoT security, Authentication, Elliptic curve cryptography, Cryptanalysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,Curien PL,,Categorical combinators,Information and Control,1986,69,1,188-254,,,,,1986,,0019-9958,https://www.sciencedirect.com/science/article/pii/S001999588680047X;http://dx.doi.org/10.1016/S0019-9958(86)80047-X,10.1016/S0019-9958(86)80047-X,"Our main aim is to present the connection between λ-calculus and Cartesian closed categories both in an untyped and purely syntactic setting. More specifically we establish a syntactic equivalence theorem between what we call categorical combinatory logic and λ-calculus with explicit products and projections, with β and η-rules as well as with surjective pairing. “Combinatory logic” is of course inspired by Curry's combinatory logic, based on the well-known S, K, I. Our combinatory logic is “categorical” because its combinators and rules are obtained by extracting untyped information from Cartesian closed categories (looking at arrows only, thus forgetting about objects). Compiling λ-calculus into these combinators happens to be natural and provokes only n log n code expansion. Moreover categorical combinatory logic is entirely faithful to β-reduction where combinatory logic needs additional rather complex and unnatural axioms to be. The connection easily extends to the corresponding typed calculi, where typed categorical combinatory logic is a free Cartesian closed category where the notion of terminal object is replaced by the explicit manipulation of applying (a function to its argument) and coupling (arguments to build datas in products). Our syntactic equivalences induce equivalences at the model level. The paper is intended as a mathematical foundation for developing implementations of functional programming languages based on a “categorical abstract machine,” as developed in a companion paper (Cousineau, Curien, and Mauny, in “Proceedings, ACM Conf. on Functional Programming Languages and Computer Architecture,” Nancy, 1985).",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Santini S,Santini S,2 - The Mysterious Case of the Disappearing Semantics,,2001,,,25-53,,Academic Press,San Diego,Exploratory Image Databases,2001,9780126192612,,https://www.sciencedirect.com/science/article/pii/B9780126192612500039;http://dx.doi.org/10.1016/B978-012619261-2/50003-9,10.1016/B978-012619261-2/50003-9,"Publisher Summary This chapter considers the problem of image meaning from the point of view of image databases. It analyzes the proposition that the meaning of the image is a compositional function of the objects contained in the image. This hypothesis helps in extraction of objects from the images using some suitable computer vision algorithm, resulting in a symbolic description of the objects in the image and their relationship supplemented by whatever ancillary information about the objects one considers necessary. This symbolic description is then manipulated compositionally to obtain a formal description of the meaning of the image, which is stored in a database and used for the subsequent query process. This scheme, if implemented, would culturally make content-based image retrieval a special case of traditional databases, in which the data are obtained automatically from the images, rather than entered manually. The chapter focuses on semiotics—a discipline that studies signs, that is, things that stand for something else, and the general process of signification, that is, the process by which things stand for something else.",,,"Communications, Networking and Multimedia",,,,,,,,,,,,,,,,,,,
Journal Article,"Caprotti O,Cohen AM",,On the Role of OpenMath in Interactive Mathematical Documents,Journal of Symbolic Computation,2001,32,4,351-364,,,,,2001,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717100904668;http://dx.doi.org/10.1006/jsco.2000.0466,10.1006/jsco.2000.0466,"The standard OpenMath is an enabling technology for creating an integrated computer environment in which software packages for computer algebra and for proof checking can be combined. Here we demonstrate how OpenMath can be employed for generating interactive mathematical documents containing primality proofs. Our case study takes place within a browser; once a prime number is specified, a document appears summarizing the proof in a number of assertions. By clicking an assertion regarding the truth of an arithmetic equality, a computer algebra calculation is invoked verifying the equality. By clicking an assertion regarding a specific mathematical lemma called Pocklington’s Criterion, a verification of the corresponding formal proof is carried out by a proof checker. Moreover, the whole document is structured in such a way that it can be easily translated to a formal proof object. OpenMath supports the interaction between the document as it appears in the browser and the mathematical software packages. This paper begins with an introduction to OpenMath and a brief comparison with MathML.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Walther C,Walther C,1 - Introduction,,1987,,,1-10,,Morgan Kaufmann,,A Many-Sorted Calculus Based on Resolution and Paramodulation,1987,,0268-7526,https://www.sciencedirect.com/science/article/pii/B9780273087182500067;http://dx.doi.org/10.1016/B978-0-273-08718-2.50006-7,10.1016/B978-0-273-08718-2.50006-7,"Publisher Summary This chapter discusses many-sorted calculi and many-sorted language. The development of a many-sorted version of some given first-order one-sorted or unsorted calculus is well known in the area of formal logic. The first-order language has to be extended to a many-sorted language, the semantics for this language have to be defined, and the rules of inference have to be modified accordingly. Variable and function symbols are associated with a sort symbol, called the rangesort. The sort of a term is determined by the rangesort of its outermost symbol. This is a syntactic formulation of the fact that the object represented by a given term is a member of the subuniverse represented by the sort of that term. The syntactic requirement expresses the fact that not each term is meaningful as an argument to each function or predicate symbol. The definitions of the range and domain-sorts for the entire variable function and predicate symbols under consideration are collected in a so-called signature.",,,Research Notes in Artificial Intelligence,,,,,,,,,,,,,,,,,,,
Book Chapter,Uhl A,"Bernstein PA,Ioannidis YE,Ramakrishnan R,Papadias D",Chapter 47 - A Bandwidth Model for Internet Search,,2002,,,538-549,,Morgan Kaufmann,San Francisco,VLDB '02: Proceedings of the 28th International Conference on Very Large Databases,2002,9781558608696,,https://www.sciencedirect.com/science/article/pii/B9781558608696500548;http://dx.doi.org/10.1016/B978-155860869-6/50054-8,10.1016/B978-155860869-6/50054-8,"Publisher Summary A formal model for quantitatively analyzing the domain of search from a bandwidth perspective in distributed information sources has been presented in this chapter. The model assumes a possibly multi-rooted hierarchy of trader nodes with searchable information sources at the leaves of the tree. The provided formalism applies to a broad range of constellations and helps in finding the right number of subtraders in the trader tree and the maximum tree depth, making the indexing vs. query forwarding decision, and computing the tradeoff between buying more bandwidth and splitting a trader. Furthermore, the overhead of using polling instead of using a change-based notification mechanism has been quantified. The model uses a multidimensional parameter space including the query frequency, query and result object sizes, network bandwidth and latency, change rate of the searchable information, and the requested currency of search results. The model formally confirms that a centralized approach does not scale. Deeper hierarchies do not significantly increase the bandwidth required per covered object, but they allow numbers of objects that are several orders of magnitude larger than those that are reachable with a centralized approach. The tradeoff is a slightly increased query execution time. It has to be emphasized that the key result is the formalism, not necessarily some of the obvious statements that can be retrieved when applying the formalism to a typical set of parameters.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Arcos JL,Plaza E",,Inference and reflection in the object-centered representation language NOOS,Future Generation Computer Systems,1996,12,2,173-188,,,,,1996,,0167-739X,https://www.sciencedirect.com/science/article/pii/0167739X96000039;http://dx.doi.org/10.1016/0167-739X(96)00003-9,10.1016/0167-739X(96)00003-9,"This paper explains the inference and reflection capabilities of NOOS, an object-centered representation language designed to integrate problem solving and learning. Problem solving and learning in NOOS are modelled by means of concepts, tasks, methods and metalevels. Metalevels allow NOOS to reason about own problem solving. Using metalevels, NOOS can reason about preferences in order to make decisions about sets of alternatives present in domain knowledge and problem solving knowledge. Reflection in NOOS is provided by inference processes that involve metalevels. Basic reflective capabilities include reasoning about alternative methods to solve a task, reasoning about what is known by the system itself, and reasoning about the existence of solutions. A formal model of NOOS inference using Descriptive Dynamic Logic is also presented.","Reflection, Object-centered representation language, Knowledge representation, Machine learning, Case-based reasoning",Reflection and Meta-level AI Architectures,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li M,Wang G",,Approximate concept construction with three-way decisions and attribute reduction in incomplete contexts,Knowledge-Based Systems,2016,91,,165-178,,,,,2016,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705115003858;http://dx.doi.org/10.1016/j.knosys.2015.10.010,10.1016/j.knosys.2015.10.010,"Incomplete contexts are a kind of formal contexts in which the relationship between some objects and some attributes is unavailable or lost. Knowledge discovery in incomplete contexts is of interest because such databases are frequently encountered in the real world. This paper mainly focuses on two issues: approximate concept construction with three-way decisions and attribute reduction in incomplete contexts. The theory of three-way decisions is formulated based on the notions of acceptance, rejection and non-commitment. It is an extension of the commonly used binary-decision model with an added third option. Based on three-way decisions, we propose two models to construct approximate concepts in incomplete contexts, and the equivalence of the two is revealed. To simplify the representation of the approximate concept lattices, we further present the attribute reduction approaches.","Concept lattice, Approximate concept construction, Three-way decisions, Attribute reduction, Attribute characteristic",Three-way Decisions and Granular Computing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hadzilacos T,Hadzilacos V",,Transaction synchronisation in object bases,Journal of Computer and System Sciences,1991,43,1,2-24,,,,,1991,,0022-0000,https://www.sciencedirect.com/science/article/pii/0022000091900309;http://dx.doi.org/10.1016/0022-0000(91)90030-9,10.1016/0022-0000(91)90030-9,"We propose a formal model of concurrency control in object bases. An object base is like a database except that information is represented in terms of “objects” that encapsulate both data and the procedures through which the data can be manipulated. The model generalises the classical model of database concurrency control: it allows for nested transactions (as opposed to flat transactions) which may issue arbitrary operations (as opposed to just read and write operations). We establish an analogue to the classical serialisability theorem and use it to derive simple proofs of correctness of two concurrency control algorithms for object bases, namely nested two-phase locking (Moss' algorithm) and nested timestamp ordering (Reed's algorithm). Concurrency control in object bases can be viewed as a combination of intea-object and inter-object synchronisation. The former ensures that each object's own methods are executed in serialisable fashion; the latter ensures the compatibility of transaction serialisation orders in different objects. This separation allows for the possibility that each object chooses the most suitable concurrency control algorithm for synchronising its own procedures, independently of the algorithms used by other objects, thus enhancing concurrency.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Byott NP,,Monogenic Hopf orders and associated orders of valuation rings,Journal of Algebra,2004,275,2,575-599,,,,,2004,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869303005672;http://dx.doi.org/10.1016/j.jalgebra.2003.07.003,10.1016/j.jalgebra.2003.07.003,"Let R be a complete discrete valuation ring of mixed characteristic with perfect residue field, and let H be a finite local commutative R-Hopf algebra. We consider when there exists a finite extension of the field of fractions of R, whose valuation ring is a Galois H-object. If this occurs then H is monogenic. Conversely, if H is also cocommutative and H is monogenic, then there exists a valuation ring which is a Galois H-object. To prove this result, we represent H as the kernel of an isogeny of a special type between formal groups over R. We deduce that if A is a finite abelian R-Hopf algebra, such that both A and its dual are local, then A is the associated order of a valuation ring if and only if the dual of A is monogenic.","Galois module structure, Hopf order, Field extension, Local field",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kim JY,,Extinction and propagation of elastic waves in inhomogeneous materials,Mechanics of Materials,2003,35,9,877-884,,,,,2003,,0167-6636,https://www.sciencedirect.com/science/article/pii/S0167663602003241;http://dx.doi.org/10.1016/S0167-6636(02)00324-1,10.1016/S0167-6636(02)00324-1,Forward scattering theorems for elastic longitudinal and shear wave scatterings by an arbitrary-shaped cylindrical object embedded in an energy-absorbing medium are derived. The obtained expressions for extinction cross-sections are formally the same with those for non-absorbing medium. Examples of applications to the calculation of the total attenuation and the dynamic homogenization of inhomogeneous materials are given. Numerical results for fiber-reinforced composites are compared with those from existing approximate theories.,"Forward scattering theorem, Extinction cross-section, Attenuation, Composite materials, Homogenization",,,,,,,,,,,,,,,,,,,,,
Journal Article,Taylor P,,Local Compactness and the Baire Category Theorem in Abstract Stone Duality,Electronic Notes in Theoretical Computer Science,2003,69,,323-345,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104805723;http://dx.doi.org/10.1016/S1571-0661(04)80572-3,10.1016/S1571-0661(04)80572-3,"Abstract Stone Duality is a re-axiomatisation of general topology intended to make it recursive. By turning the idea of the Scott topology on its head, notions that involve directed (infinitary) joins are reformulated using functions of higher type instead. Here we consider compactness and the way below relation ≪ used for continuous lattices. A new characterisation of local compactness is formulated in terms of an effective basis, i.e. one that comes with a dual basis. Any object that is definable in the monadic λ-calculus for Abstract Stone Duality (including the lattice structure and Scott principle) has such a basis. This is used to prove a form of Baire's category theorem, that, for any countable family of open dense subsets, the intersection is also dense.",,"CTCS'02, Category Theory and Computer Science",,,,,,,,,,,,,,,,,,,,
Journal Article,"Ziemann P,Hölscher K,Gogolla M",,Coherently Explaining UML Statechart and Collaboration Diagrams by Graph Transformations,Electronic Notes in Theoretical Computer Science,2005,130,,263-280,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105002252;http://dx.doi.org/10.1016/j.entcs.2005.03.014,10.1016/j.entcs.2005.03.014,"In this paper we continue our work on the formalization and validation of UML models by means of graph transformation systems. We here concentrate on statechart and collaboration diagrams albeit our approach covers use case, class, object, and sequence diagrams as well. The statechart and collaboration diagrams describe the operations of the underlying class diagram and include OCL expressions as guards and parts of message expressions. We illustrate in detail the generation of graph transformation rules for the statechart and collaboration diagrams.","UML, graph transformation, integrated formal semantics, OCL",Proceedings of the Brazilian Symposium on Formal Methods (SBMF 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Alós-Ferrer C,Kern J",,Repeated games in continuous time as extensive form games,Journal of Mathematical Economics,2015,61,,34-57,,,,,2015,,0304-4068,https://www.sciencedirect.com/science/article/pii/S0304406815000907;http://dx.doi.org/10.1016/j.jmateco.2015.07.006,10.1016/j.jmateco.2015.07.006,"Extensive form games modeling continuous-time decisions are plagued with problems of nonexistence and nonuniqueness of outcomes. As a “second-best”, the literature has imposed extraneous restrictions on the strategy sets, raising questions on the nature and interpretation of the resulting formal object, and on which restrictions are appropriate. We provide a “first-best” framework, formalizing continuous-time repeated games as extensive form games incorporating natural conditions from the onset. Every strategy profile induces a unique outcome, without any restrictions on the strategy sets. Further, the unrestricted strategy sets are equivalent to a specific class of strategies in a more naïvely specified continuous-time game.","Extensive forms, Continuous time, Repeated games",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Wickerhauser MV,Wickerhauser MV,Chapter 2 - Space and Linearity,,2004,,,23-68,,Academic Press,San Diego,Mathematics for Multimedia,2004,9780127484518,,https://www.sciencedirect.com/science/article/pii/B9780127484518500021;http://dx.doi.org/10.1016/B978-012748451-8/50002-1,10.1016/B978-012748451-8/50002-1,"Publisher Summary The chapter presents the analysis of signals and their transformations with an overview of the applicable linear algebra followed by the results from advanced calculus needed to understand infinite dimensional spaces. The ability to see geometric properties of objects in space helps to visualize important properties of digital signals. However, it is necessary to find correspondence between the signal property and the geometric object. A starting point is the analytic geometry of the line, the plane, and the space. Digital signals representing sounds and images are modeled by points in some of these generalized spaces, and many common transformations of such signals are easily described as geometric operations on those points. For example, points in space may be added together or multiplied by real numbers that correspond respectively to mixing signals or amplify them. The results are variously called linear combinations, superpositions, or linear transformations. Linear transformations of linear spaces preserve linear combinations. Even rather complicated transformations satisfy this linearity assumption, which in many cases reduces their analysis to linear algebra.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bergel A,,Reconciling method overloading and dynamically typed scripting languages,"Computer Languages, Systems & Structures",2011,37,3,132-150,,,,,2011,,1477-8424,https://www.sciencedirect.com/science/article/pii/S1477842411000030;http://dx.doi.org/10.1016/j.cl.2011.03.002,10.1016/j.cl.2011.03.002,"The Java virtual machine (JVM) has been adopted as the executing platform by a large number of dynamically typed programming languages. For example, Scheme, Ruby, Javascript, Lisp, and Basic have been successfully implemented on the JVM and each is supported by a large community. Interoperability with Java is one important requirement shared by all these languages. We claim that the lack of type annotation in interpreted dynamic languages makes this interoperability either flawed or incomplete in the presence of method overloading. We studied 17 popular dynamically typed languages for JVM and .Net, none of them were able to properly handle the complexity of method overloading. We present dynamic type tag, an elegant solution for dynamic language interpreters to properly interact with Java objects in the presence of overloaded methods. The idea is to embody a type annotation in a Java object reference. Java references may be annotated in order to properly determine the signature of methods to invoke. We demonstrate its applicability in the JSmall language and provide the pellucid embedding, a formalization of our approach.","Multi-language system, Interoperability, SmalltalkLite, JavaLite, Dynamic languages",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Itoh K,Muramatsu K,Matsui M,Suzuki S",,Graphical editing and analysis system for network system (Geans),Computers & Graphics,1982,6,2,47-61,,,,,1982,,0097-8493,https://www.sciencedirect.com/science/article/pii/0097849382900176;http://dx.doi.org/10.1016/0097-8493(82)90017-6,10.1016/0097-8493(82)90017-6,"Network analysis is powerful in building formal network models of various computational systems or social systems and obtaining their functions and performance exactly because of simplicity of binary relations in networks. Traditionally, it takes lots of effort in network analysis because network analysis was performed by the use of lots of numerical data in batch processing form. Effective network analysis activity, satisfying the system requirements based on consideration for such traditional manner with high cost, requires semiautomatic or computer aided man-machine facilities with interactive editing, analysis, and result viewing functions. We have developed Graphical Editing and Analysis system for Network System (Geans) on DEC PDP-11/34 minicomputer with a graphic display which enables us to edit or modify various network representations and analyze their qualitative and quantitative property, smoothly and interactively with the use of graphics and data abstraction. Geans is composed of a network editing system with effective use of a graphic display, a network data management system with systematic use of network data abstraction, a network analysis system with construction of shared library routines and specific object problem oriented routines, and a node/arc shape definition system. Geans has been applied to various network models such as a transportation analysis problem, PERT/CPM planning, Petri Net analysis and a guidance system for an urban railway network, and moreover it is being applied to other analysis areas as evolving itself.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Venugopal M,Eastman CM,Teizer J",,An ontology-based analysis of the industry foundation class schema for building information model exchanges,Advanced Engineering Informatics,2015,29,4,940-957,,,,,2015,,1474-0346,https://www.sciencedirect.com/science/article/pii/S1474034615001019;http://dx.doi.org/10.1016/j.aei.2015.09.006,10.1016/j.aei.2015.09.006,"Robust knowledge sharing frameworks between different stakeholders in a building project is of high priority. Industry Foundation Classes (IFC) provides a rich schema for interoperability through object-based transactions. However, IFC lacks semantic clarity in mapping entities and relationships, resulting in multiple definitions to map the same information between different federated models. The objective of this research is to examine IFC from a perspective of an ontological framework, which can make the IFC definitions more formal, consistent and unambiguous. Different methods of ontological approaches to engineering knowledge are reviewed. Various issues such as the need for a logical framework, the current semantic approaches in the AEC/FM industry, and advantages of building an ontology structure are addressed. A comparative study of the ontology and segments of the existing IFC schema definition are performed. This exercise reveals the ambiguous nature of current IFC definitions and proposes reforms such that data exchanges would be more semantically robust. An ontology would structure the overall interoperability of BIM tools by providing a formal and consistent taxonomy and classification structure for extending IFC and for defining subsets as model view definitions (MVD).","Building Information Modeling (BIM), Product or process modeling, Model view definitions (MVD), Industry Foundation Class (IFC), Ontology, Semantic Exchange Modules (SEM)","Collective Intelligence Modeling, Analysis, and Synthesis for Innovative Engineering Decision Making Special Issue of the 1st International Conference on Civil and Building Engineering Informatics",,,,,,,,,,,,,,,,,,,,
Journal Article,"Griffiths T,Fernandes AA,Paton NW,Barr R",,The Tripod spatio-historical data model,Data & Knowledge Engineering,2004,49,1,23-65,,,,,2004,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X0300137X;http://dx.doi.org/10.1016/j.datak.2003.08.003,10.1016/j.datak.2003.08.003,"The storage and analysis of large amounts of time-varying spatial and aspatial data is becoming an important feature of many application domains. This has fuelled the need for spatio-temporal extensions to data models and their associated querying facilities. To date, much of this work has focused on the relational data model, with object data models receiving far less consideration. Where descriptions of such object models do exist, these models fail to fully integrate their spatial, aspatial and temporal dimensions into a uniform and coherent model. In addition, there is currently a lack of systems which build upon these models to produce database architectures that address the broad spectrum of issues related to the delivery of a fully functional spatio-temporal DBMS. This paper presents a foundation for the development of such a system, called Tripod, by describing a spatio-historical object model based on a specialized mechanism, called a history, for maintaining knowledge about entities that change over time. Key features of the resulting model include: (i) consistent representations of primitive spatial and timestamp types; (ii) a component-based design in which spatial, timestamp and historical extensions are formalized incrementally, for subsequent use together or separately; (iii) compatibility with mainstream query processing frameworks for object databases; and (iv) the integration of the spatio-temporal proposal with the ODMG object database standard. The paper presents a comprehensive formal characterization of the model and illustrates its capabilities in a crime data management application. It is also shown how the model can be programmed using an extension to the ODMG language bindings. The model and language bindings have been fully implemented.","Spatial databases, Temporal databases, Spatio-historical object databases, Data modelling",,,,,,,,,,,,,,,,,,,,,
Journal Article,Reichel H,,Preface: Volume 33,Electronic Notes in Theoretical Computer Science,2000,33,,1-2,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105803408;http://dx.doi.org/10.1016/S1571-0661(05)80340-8,10.1016/S1571-0661(05)80340-8,"This volume contains the Proceedings of the Third Workshop on Coalgebraic Methods in Computer Science (CMCS'2000). The Workshop was held in Berlin, Germany on March 25 and 26, 2000, as satellite event to ETAPS'2000. During the last few years it is becoming increasingly clear that a great variety of state-based dynamical systems, like transition systems, automata, process calculi and class-based systems can be captured uniformly as coalgebras. The aim of the workshops is to bring together researchers with a common interest in the theory of coalgebras and its applications. The first two volumes together with the current volume demonstrate that coalgebra is developing into a field of its own interest presenting a deep mathematical foundation, a growing field of applications and interactions with various other fields, such as modal logic, category theory, dynamical systems, control systems, object-oriented and concurrent programming, formal systems specifications, algebra, analysis, etc. The papers in this volume were reviewed by the program committee consisting, besides editor, of H. Peter Gumm(Department of Mathematics and Computer Science, University of Marburg)Bart Jacobs(Department of Computer Science, University of Nijmegen)Ugo Montanari(Department of Computer Science, University of Pisa)Larry Moss(Department of Mathematics, Indiana University)Ataru T. Nakagawa(Software Research Association)John Power(Department of Computer Science, The University of Edinburgh)Jan Rutten(Department of Software Technology, CWI) This volume will be published as volume 33 in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs The proceedings of the preceding two workshops are available as volume eleven and nineteen. A printed version of the current volume is distributed to the participants at the workshop in Berlin. We are very grateful to the following persons, whose help has been crucial for the success of CMCS'2000: Hartmut Ehrig and Uwe Wolter for their help with the organization of the Workshop as satellite event of ETAPS'2000; Mike Mislove, one of the Managing Editors of the ENTCS series, for his assistance with the use of the ENTCS style files; Dmitri Schamschurko for his great help in printing these Proceedings. Thanks are also due to the Institute for Theoretical Computer Science of the Dresden University of Technology, which has supplied financial support to cover the printing costs. March 14, 2000 Horst Reichel",,"CMCS'2000, Coalgebraic Methods in Computer Science",,,,,,,,,,,,,,,,,,,,
Journal Article,"De Maio C,Fenza G,Gaeta M,Loia V,Orciuoli F,Senatore S",,RSS-based e-learning recommendations exploiting fuzzy FCA for Knowledge Modeling,Applied Soft Computing,2012,12,1,113-124,,,,,2012,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494611003826;http://dx.doi.org/10.1016/j.asoc.2011.09.004,10.1016/j.asoc.2011.09.004,"Nowadays, Web 2.0 focuses on user generated content, data sharing and collaboration activities. Formats like Really Simple Syndication (RSS) provide structured Web information, display changes in summary form and stay updated about news headlines of interest. This trend has also affected the e-learning domain, where RSS feeds demand for dynamic learning activities, enabling learners and teachers to access to new blog posts, to keep track of new shared media, to consult Learning Objects which meet their needs. This paper presents an approach to enrich personalized e-learning experiences with user-generated content, through a contextualized RSS-feeds fruition. The synergic exploitation of Knowledge Modeling and Formal Concept Analysis techniques enables the design and development of a system that supports learners in their learning activities by collecting, conceptualizing, classifying and providing updated information on specific topics coming from relevant information sources. An agent-based layer supervises the extraction and filtering of RSS feeds whose topics cover a specific educational domain.","Knowledge Modeling, e-Learning, Web 2.0, Fuzzy logic, Formal Concept Analysis, Agent-based system",,,,,,,,,,,,,,,,,,,,,
Journal Article,Dufourd JF,,Formal specification of topological subdivisions using hypermaps,Computer-Aided Design,1991,23,2,99-116,,,,,1991,,0010-4485,https://www.sciencedirect.com/science/article/pii/001044859190001D;http://dx.doi.org/10.1016/0010-4485(91)90001-D,10.1016/0010-4485(91)90001-D,"In a way, the ideas of Lienhardt about boundary-representation models are extended, interpreted and rewritten. He has shown that the topology of graphical objects can easily be described by mathematical concepts of map and generalized map. The map specification problems are emphasized, to take into account topology and, to some extent, geometry. Indications are also given about implementation. A technique of algebraic specification is used to define a universe of graphical objects and operations based on the maps and their extensions. First, a unifying concept of hypermap is specified, for which different levels of operations are given. In the next step, this notion is specialized to retrieve the maps and the generalized maps with their own operations. The fundamental properties of the model of boundary representation are defined, and then obtained from the formal specification. It is shown that the notion of hypermap helps to precisely define the morphology of the objects, i.e. geometrical embedding and photometry, which can be attached to elements of hypermaps. The case of surfaces is specially considered. The question of implementation is also considered. From an algebraic specificatio, numerous concrete representations can be developed. Two different representations are demonstrated: a rapid prototyping in OBJ3 and an efficient pointer realization in C.","algebraic specification, N-dimensional space subdivision, maps, generalized maps, hypermaps, boundary representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bosch JB,Ehlers EM",,Remote sensing of characters on 3D objects,Computers & Industrial Engineering,1997,33,1,429-432,,,,,1997,,0360-8352,https://www.sciencedirect.com/science/article/pii/S0360835297001290;http://dx.doi.org/10.1016/S0360-8352(97)00129-0,10.1016/S0360-8352(97)00129-0,"This paper introduces a formal approach to the recognition of characters (OCR) on remote objects. Currently most applications using this technique are ad hoc. Lack of formalism creates the risk of fragmented adhocracy. This theoretical basis explores the potential of character recognition for automated reading using video and digital cameras. In order to do successful recognition the typical problems experienced in these applications should be well understood. The approach also suggests the use of commercial OCR software developed for scanners to be used in the recognition process. Finally, some experimental results of practical applications are given. This approach is pragmatic and can be used in many fields.","Computer Vision, OCR, Information Systems, Communications and Human Factors",Proceedings of the 21st International Conference on Computers and Industrial Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Alpatov A,Khoroshylov S,Bombardelli C",,Relative control of an ion beam shepherd satellite using the impulse compensation thruster,Acta Astronautica,2018,151,,543-554,,,,,2018,,0094-5765,https://www.sciencedirect.com/science/article/pii/S0094576518300146;http://dx.doi.org/10.1016/j.actaastro.2018.06.056,10.1016/j.actaastro.2018.06.056,"The “ion beam shepherd” is a recently proposed concept for removing space debris in a contactless manner. A shepherd satellite must be controlled to move at a certain small distance in front of a space debris object during the de-orbiting phase. Because of the considerable duration of this phase, the propellant consumption is a key requirement for the control design. In this paper, the in-plane relative position of the shepherd is maintained using a small thrust variation of the compensation thruster. The controller is designed and analyzed considering the time-varying and parametric uncertain plant in the presence of the ion beam and orbital perturbations, sensor noise, actuation errors, taking into account limitations on the controller output. The system robustness and specified requirements are confirmed both by a formal criteria and numerical simulations. The estimations show that this control strategy is more efficient in terms of propellant consumption than the conventional approach with chemical thrusters.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bae M,Kang S,Oh S",,Semantic similarity method for keyword query system on RDF,Neurocomputing,2014,146,,264-275,,,,,2014,,0925-2312,https://www.sciencedirect.com/science/article/pii/S0925231214008005;http://dx.doi.org/10.1016/j.neucom.2014.04.062,10.1016/j.neucom.2014.04.062,"Keyword query on RDF data is an effective option because it is lightweight and it is not necessary to have prior knowledge on the data schema or a formal query language such as SPARQL. However, optimizing the query processing to produce the most relevant results with only minimum computations is a challenging research issue. Current proposals suffer from several drawbacks, e.g., limited scalability, tight coupling with the existing ontology, and too many computations. To address these problems, we propose a novel approach to keyword search with automatic depth decisions using the relational and semantic similarities. Our approach uses a predicate that represents the semantic relationship between the subject and object. We take advantage of this to narrow down the target RDF data. The semantic similarity score is then calculated for objects with the same predicate. We make a linear combination of two scores to get the similarity score that is used to determine the depth of given keyword query results. We evaluate our algorithm with other approaches in terms of accuracy and query processing performance. The results of our empirical experiments show that our approach outperforms other existing approaches in terms of efficiency and query processing performance.","Keyword query, RDF, Semantic similarity, WordNet",Bridging Machine learning and Evolutionary Computation (BMLEC) Computational Collective Intelligence,,,,,,,,,,,,,,,,,,,,
Journal Article,Carey VJ,,Ontology concepts and tools for statistical genomics,Journal of Multivariate Analysis,2004,90,1,213-228,,,,,2004,,0047-259X,https://www.sciencedirect.com/science/article/pii/S0047259X04000223;http://dx.doi.org/10.1016/j.jmva.2004.02.001,10.1016/j.jmva.2004.02.001,"In computer science, an ontology is any formally structured vocabulary covering a conceptual domain. Gene Ontology (GO) is a structured collection of terms defining biological processes, cellular components, or molecular functions for the purpose of characterizing gene products and functions. The structure of GO is a directed acyclic graph (DAG) with typed edges. We describe a simple formalism for working with ontologies for statistical purposes, and define object-ontology complexes, which encode the usage of the vocabulary to label objects under analysis. Recently developed concepts of information content and semantic similarity are evaluated and used to explore the association between LocusLink loci and GO. We investigate relations between GO DAG structure, association evidence codes and term information content, illustrate computation of semantic similarities of genes within and between clusters discovered in a microarray, and describe a more general ontology and its use in inference on genetic network structure.","Ontology, Semantics, Sparse matrices, Bioinformatics",Special Issue on Multivariate Methods in Genomic Data Analysis,,,,,,,,,,,,,,,,,,,,
Journal Article,"Caccamo M,Winskel G",,Limit Preservation from Naturality,Electronic Notes in Theoretical Computer Science,2005,122,,3-22,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105000319;http://dx.doi.org/10.1016/j.entcs.2004.06.048,10.1016/j.entcs.2004.06.048,"A functor G:C→D is said to preserve limits of a diagram D:I→C if it sends any limiting cone from x to D to a limiting cone from G(x) to G∘D. When G preserves limits of a diagram D this entails directly that there is an isomorphism G(lim←ID)≅lim←I(G∘D) between objects. In general, such an isomorphism alone is not sufficient to ensure that G preserves limits. This paper shows how, with minor side conditions, the existence of an isomorphism natural in the diagram D does ensure that limits are preserved. In particular, naturality in the diagram alone is sufficient to yield the preservation of connected limits. At the other extreme, once terminal objects are preserved, naturality in the diagram is sufficient to give the preservation of products. General limits, which factor into a product of connected limits, are treated by combining these results. In particular, it is shown that a functor G:C→D between complete categories is continuous if there is an isomorphism G(lim←ID)≅lim←I(G∘D) natural in D∈[I,C], for any small category I. It is indicated how a little calculus of ends, in which the judgements are natural isomorphisms between functors, is useful in establishing continuity properties of functors.","category, functor, limit, preservation, naturality, end",Proceedings of the 10th Conference on Category Theory in Computer Science (CTCS 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Harris AW,Barucci MA,Cano JL,Fitzsimmons A,Fulchignoni M,Green SF,Hestroffer D,Lappas V,Lork W,Michel P,Morrison D,Payson D,Schäfer F",,The European Union funded NEOShield project: A global approach to near-Earth object impact threat mitigation,Acta Astronautica,2013,90,1,80-84,,,,,2013,,0094-5765,https://www.sciencedirect.com/science/article/pii/S0094576512003360;http://dx.doi.org/10.1016/j.actaastro.2012.08.026,10.1016/j.actaastro.2012.08.026,"Although discussions are underway within the Action Team 14 of the United Nations COPUOS, there is currently no concerted international plan addressing the impact threat from near-Earth objects (NEOs) and how to organize, prepare and implement mitigation measures. We report on a new international project to address impact hazard mitigation issues, being the subject of a proposal submitted to the European Commission in response to the 2011 FP7 Call “Prevention of impacts from near-Earth objects on our planet”. Our consortium consists of 13 research institutes, universities, and industrial partners from 6 countries and includes leading US and Russian space organizations. The primary aim of the project, NEOShield, is to investigate in detail the three most promising mitigation techniques: the kinetic impactor, blast deflection, and the gravity tractor, and devise feasible demonstration missions. Furthermore, we will investigate options for an international strategy for implementation when an actual impact threat arises. The NEOShield project was formally accepted by the European Commission on 17 November 2011 and funded with a total of 5.8 million Euros for a period of 3.5 years. The kick-off meeting took place at the DLR Institute of Planetary Research, Berlin, in January 2012. In this paper we present a brief overview of the planned scope of the project.","Asteroid, Near-Earth object, Impact hazard, Impact mitigation",NEO Planetary Defense: From Threat to Action - Selected Papers from the 2011 IAA Planetary Defense Conference,,,,,,,,,,,,,,,,,,,,
Journal Article,"Brzeziński T,Vercruysse J",,Bimodule herds,Journal of Algebra,2009,321,9,2670-2704,,,,,2009,,0021-8693,https://www.sciencedirect.com/science/article/pii/S002186930900057X;http://dx.doi.org/10.1016/j.jalgebra.2009.01.020,10.1016/j.jalgebra.2009.01.020,"The notion of a bimodule herd is introduced and studied. A bimodule herd consists of a B-A bimodule, its formal dual, called a pen, and a map, called a shepherd, which satisfies unitality and coassociativity conditions. It is shown that every bimodule herd gives rise to a pair of corings and coactions. If, in addition, a bimodule herd is tame i.e. it is faithfully flat and a progenerator, or if it is a progenerator and the underlying ring extensions are split, then these corings are associated to entwining structures; the bimodule herd is a Galois comodule of these corings. The notion of a bicomodule coherd is introduced as a formal dualisation of the definition of a bimodule herd. Every bicomodule coherd defines a pair of (non-unital) rings. It is shown that a tame B-A bimodule herd defines a bicomodule coherd, and sufficient conditions for the derived rings to be isomorphic to A and B are discussed. The composition of bimodule herds via the tensor product is outlined. The notion of a bimodule herd is illustrated by the example of Galois co-objects of a commutative, faithfully flat Hopf algebra.","Bimodule herd, Torsor, Coring, Galois comodule, Entwining structure",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Markl M,Merkulov S,Shadrin S",,"Wheeled PROPs, graph complexes and the master equation",Journal of Pure and Applied Algebra,2009,213,4,496-535,,,,,2009,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404908001667;http://dx.doi.org/10.1016/j.jpaa.2008.08.007,10.1016/j.jpaa.2008.08.007,"We introduce and study wheeled PROPs, an extension of the theory of PROPs which can treat traces and, in particular, solutions to the master equations which involve divergence operators. We construct a dg free wheeled PROP whose representations are in one-to-one correspondence with formal germs of SP-manifolds, key geometric objects in the theory of Batalin–Vilkovisky quantization. We also construct minimal wheeled resolutions of classical operads Com and Ass as non-trivial extensions of the well-known dg operads Com∞ and Ass∞. Finally, we apply the above results to a computation of cohomology of a directed version of Kontsevich’s complex of ribbon graphs.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Carboni A,,"Matrices, relations, and group representations",Journal of Algebra,1991,136,2,497-529,,,,,1991,,0021-8693,https://www.sciencedirect.com/science/article/pii/002186939190057F;http://dx.doi.org/10.1016/0021-8693(91)90057-F,10.1016/0021-8693(91)90057-F,"Motivated by the search for a good notion of a “selfdual” object in a symmetric monoidal category, we give an abstract notion of commutative separable algebra in a symmetric monoidal category V, such that when V is the category of modules over a commutative ring k we obtain the usual commutative separable algebras. Developing the calculus based on such an abstract notion we are able to prove that the dual category of separable algebras in any compact closed, additive category with coequalizers is in fact a boolean pretopos. We apply this result to give a simple characterization of the categories of continuous representations of profinite groups in discrete finite dimensional k-vector spaces. Finally we show that the same calculus can be applied to symmetric monoidal categories of relations to give an essentially algebraic characterization of such categories.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Bourlès H,Bourlès H,3 - Fiber Bundles,,2019,,,93-129,,Elsevier,,Fundamentals of Advanced Mathematics V3,2019,9781785482502,,https://www.sciencedirect.com/science/article/pii/B9781785482502500035;http://dx.doi.org/10.1016/B978-1-78548-250-2.50003-5,10.1016/B978-1-78548-250-2.50003-5,"Abstract: In the previous chapter, we assigned a tangent space Tb (B) to each point b of a manifold B. This idea is effective for first order differential calculus, allowing us to define the tangent linear mapping Tbf∈ℒTbBTfbB′ of a morphism f : B → B′ at every point b ∈ B. Our next task is to define the mapping T (f): b ↦ Tb (f). To do this, we need to assemble the various tangent spaces Tb (B) of B (b ∈ B) into a single object, written as T (B).If B is a surface in everyday space, the set of its tangent planes still belongs to this space. However, it is useful to reference points in the tangent plane Tb (B) by four coordinates: two for the point b =(b1, b2) on the surface (e.g. longitude and latitude for the Earth) and two determining the tangent vector hb in Tb (B) (its components with respect to a basis of Tb (B)). The set T (B) of planes tangent to a surface B is therefore the union of b × Tb (B), i.e. a disjoint union of all Tb (B). After establishing these definitions, in order to perform more advanced differential calculus, we still need to equip T (B) with a manifold structure. We can then define the tangent linear mapping Tx2 (f):= Tx (T (f)) of T (f): T (B) → T (B′) at a point x ∈ T (B). The set T (B) has a fiber bundle structure ([P2], section 5.2.3(I)) with base B and projection π : T (B) → B : (b, hb) ↦ b (here, the canonical surjection). In Tb (B), each tangent vector hb is referenced by its coordinates (t1, t2) = t, and any point x ∈ T (B) is a pair (b, t), where b = π (x). The fiber bundle M is characterized by its projection π : M ↠ B. Once the manifold T (B) has been constructed, we can iterate the process and define the fiber bundle T (T (B)) = T2 (B), etc., ad lib., which allows us to perform differential calculus of arbitrary order within the framework of manifolds. However, we need to expand this framework slightly further still by making the fibers themselves manifolds rather than vector spaces, leading to the notion of fibration. The details of this construction are somewhat tedious but are given in sections 3.2, 3.3 and 3.4. Most of the proofs are omitted to lighten the presentation. The majority of these proofs are entirely trivial; they are listed in full detail in [LAN 99b], Chapter 3, and [DIE 93], Volume 3, Chapter 16, for the finite-dimensional case.","Cocycles, Cotangent bundle, Fiber bundle, Fiber product, Fibrations, Principal bundles, Trivial principal bundles, Vector bundles, Vertical tangent vectors, Whitney sum and tensor product",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Asiala M,Cottrill J,Dubinsky E,Schwingendorf KE",,The development of students' graphical understanding of the derivative,The Journal of Mathematical Behavior,1997,16,4,399-431,,,,,1997,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312397900158;http://dx.doi.org/10.1016/S0732-3123(97)90015-8,10.1016/S0732-3123(97)90015-8,"This paper is part of a series of studies by the Research in Undergraduate Mathematics Education Community (RUMEC), concerning the nature and development of college students' mathematical knowledge. The present study explores calculus students' graphical understanding of a function and its derivative. An initial theoretical analysis of the cognitive constructions necessary for this understanding is given. An instructional treatment designed to help foster the formation of these mental constructions is described, and results of interviews, conducted after the implementation of the instructional treatment, are discussed. The understanding demonstrated by these students is analyzed according to the Action-Process-Object-Schema (APOS) theoretical framework. Based on the data collected as part of this study, a revised epistemological analysis for the graphical understanding of the derivative is proposed. Moreover, a comparative analysis is made of performance of students using the instructional treatment we designed with students taking a traditional calculus course. Although this analysis is flawed in many ways, it does suggest that the students whose course was based on the theoretical analysis of learning that we give here may have had more success in developing a graphical understanding of a function and its derivative, than students from traditional courses.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Angreani LS,Vijaya A",,Designing an Effective Collaboration using Information Technology Towards World Class University,Procedia Computer Science,2017,124,,577-584,,,,,2017,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050917329605;http://dx.doi.org/10.1016/j.procs.2017.12.192,10.1016/j.procs.2017.12.192,"One of the challenges in achieving success in the global competition for the government is to set up higher education institutions to be able to become a World Class University (WCU). It is believed that to address this challenge they need effective collaboration for both internally and externally where information technology (IT) is set as an enabler. However, in fact, this research has found that it is still not utilized effectively although the need for the collaboration has clearly stated in the organization’s strategic direction. This paper aims to increase such an effective collaboration model for higher education in Indonesia towards WCU. By using one of reputable state Islamic universities in Indonesia as research object, UIN Maliki Malang, which consist of more than 17,000 students and staffs, this paper proposing a collaboration architecture model equipped with suitable supporting tools. As approaching methods, we use business model design and transformation by mapping study object’s business strategic programs into proven collaborative model and their strategic planning of IS/IT. The result of the analysis conducted in the research shows that the majority of the strategic direction of UIN Maliki Malang requires collaboration using information technology both internally and externally. Additionally, UIN Maliki Malang also has facilitated by several collaborations tools within the organization. However, they still need a formal collaboration architecture model to achieve their strategic direction goals effectively. Thus, through the achievement of collaboration effectiveness using information technology, the achievement of a world class university can be realized.","Collaboration, Information Technology, World Class University","4th Information Systems International Conference 2017, ISICO 2017, 6-8 November 2017, Bali, Indonesia",,,,,,,,,,,,,,,,,,,,
Journal Article,"Schulz S,Hahn U",,Towards the ontological foundations of symbolic biological theories,Artificial Intelligence in Medicine,2007,39,3,237-250,,,,,2007,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365706001886;http://dx.doi.org/10.1016/j.artmed.2006.12.001,10.1016/j.artmed.2006.12.001,"Summary Objective Support for the symbolic representation of the physical structure of living organisms by an ontologically solid and logically sound foundation as a basis for formal reasoning. Methods A set of canonical relations and attributes necessary for empirically adequate descriptions of biological entities is proposed. Results It is shown how a broad range of biological organisms and their parts can be represented by cascading theories which are ordered by the dimensions of granularity, development, species, and canonicity. Conclusion The proposed representation of biological objects is non-redundant and compatible with inter- and intra-species similarities, developmental stages and pathological deviations.","Biomedical ontologies, Biomedical knowledge representation",Ontological Foundations for Biomedical Sciences,,,,,,,,,,,,,,,,,,,,
Journal Article,"Baroni P,Cerutti F,Dunne PE,Giacomin M",,Automata for infinite argumentation structures,Artificial Intelligence,2013,203,,104-150,,,,,2013,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370213000428;http://dx.doi.org/10.1016/j.artint.2013.05.002,10.1016/j.artint.2013.05.002,"The theory of abstract argumentation frameworks (afs) has, in the main, focused on finite structures, though there are many significant contexts where argumentation can be regarded as a process involving infinite objects. To address this limitation, in this paper we propose a novel approach for describing infinite afs using tools from formal language theory. In particular, the possibly infinite set of arguments is specified through the language recognized by a deterministic finite automaton while a suitable formalism, called attack expression, is introduced to describe the relation of attack between arguments. The proposed approach is shown to satisfy some desirable properties which cannot be achieved through other “naive” uses of formal languages. In particular, the approach is shown to be expressive enough to capture (besides any arbitrary finite structure) a large variety of infinite afs including two major examples from previous literature and two sample cases from the domains of multi-agent negotiation and ambient intelligence. On the computational side, we show that several decision and construction problems which are known to be polynomial time solvable in finite afs are decidable in the context of the proposed formalism and we provide the relevant algorithms. Moreover we obtain additional results concerning the case of finitary afs.","Infinite argumentation frameworks, Automata-based representation, Argumentation semantics computation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Pantazis A,Priavolou C",,3D printing as a means of learning and communication: The 3Ducation project revisited,Telematics and Informatics,2017,34,8,1465-1476,,,,,2017,,0736-5853,https://www.sciencedirect.com/science/article/pii/S0736585317302939;http://dx.doi.org/10.1016/j.tele.2017.06.010,10.1016/j.tele.2017.06.010,"This research project explores to what extent the utilization of open-source 3D printers and 3D design software could serve as means of learning and communication. The principles of non-formal education aligned with the concept of constructionism are used to create an experimental educational scenario focused on geocultural tourism for persons with visual impairments. This paper documents our experience and presents our findings from a 25-day long project, which took place in Zagori, northwestern Greece. 11 high school students from Portugal designed and manufactured natural and cultural heritage artifacts carrying messages in the Braille language. The objects were then handed to people with visual impairments with a twofold aim. First, to enable the communication among persons with and without visual impairments; and, second, to empower students to participate in training projects through open educational procedures. We conclude that open educational practices can boost students’ active engagement in educational processes. Finally, 3D printing encourages a meaningful communication among people with and without visual impairments via the tangible exploration of geocultural components.","3D printing, Open-source, Collaboration, Non-formal education, Constructionism, Participatory action research",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bose P,Toussaint G",,Geometric and computational aspects of gravity casting,Computer-Aided Design,1995,27,6,455-464,,,,,1995,,0010-4485,https://www.sciencedirect.com/science/article/pii/001044859500018M;http://dx.doi.org/10.1016/0010-4485(95)00018-M,10.1016/0010-4485(95)00018-M,"In the manufacturing industry, finding an orientation for a mould that eliminates surface defects and ensures a complete fill after the termination of the gravity casting process is an important and difficult problem which has not previously been investigated formally. The paper initiates the study of the gravity casting process from a geometric perspective and presents an optimal θ(n log n) time algorithm that solves this problem in 2D given an object of size n. The paper also characterizes the object shapes (modelled as simple polygons) that can be 1-filled and relate fillability to well known classes of polygons. For certain classes of objects, an optimal direction of fillability can be determined in linear time.","gravity casting, computational geometry, algorithms",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Greenhill S,Venkatesh S",,Semantic data modelling and visualisation using Noetica,Data & Knowledge Engineering,2000,33,3,241-276,,,,,2000,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X00000033;http://dx.doi.org/10.1016/S0169-023X(00)00003-3,10.1016/S0169-023X(00)00003-3,"Noetica is a tool for structuring knowledge about concepts and the relationships between them. It differs from typical information systems in that the knowledge it represents is abstract, highly connected, and includes meta-knowledge (knowledge about knowledge). Noetica represents knowledge using a strongly typed graph data model. By providing a rich type system it is possible to represent conceptual information using formalised structures. A class hierarchy provides a basic classification for all objects. This allows for a consistency of representation that is not often found in “free” semantic networks, and gives the ability to easily extend a knowledge model while retaining its semantics. Visualisation and query tools are provided for this data model. Visualisation can be used to explore complete sets of link-classes, show paths while navigating through the database, or visualise the results of queries. Noetica supports goal-directed queries (a series of user-supplied goals that the system attempts to satisfy in sequence) and pathfinding queries (where the system finds relationships between objects in the database by following links).","Knowledge representation, Graph traversal, Data visualisation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Suppes P,Meijers A,Measurement Theory and Engineering,,2009,,,825-860,,North-Holland,Amsterdam,Philosophy of Technology and Engineering Sciences,2009,,1878-9846,https://www.sciencedirect.com/science/article/pii/B9780444516671500343;http://dx.doi.org/10.1016/B978-0-444-51667-1.50034-3,10.1016/B978-0-444-51667-1.50034-3,"Publisher Summary The formal or mathematical theory of representation has as its primary goal such an enrichment of the understanding, although there are other goals of representation of nearly as great importance—for instance, the use of numerical representations of measurement procedures to make computations more efficient. A conceptual analysis of measurement can properly begin by formulating the two fundamental problems of any measurement procedure. The first problem is that of representation, justifying the assignment of numbers to objects or phenomena. What one must show is that the structure of a set of phenomena under certain empirical operations and relations is the same as the structure of some set of numbers under corresponding arithmetical operations and relations. Solution of the representation problem for a theory of measurement does not completely lay bare the structure of the theory, for there is often a formal difference between the kind of assignment of numbers arising from different procedures of measurement. This is the second fundamental problem, determining the scale type of a given procedure. The scale type is based on the proof of an invariance theorem for the representation. This is another way of stating the second fundamental problem.",,,Handbook of the Philosophy of Science,,,,,,,,,,,,,,,,,,,
Journal Article,"Arrighi P,Dowek G",,Causal graph dynamics,Information and Computation,2013,223,,78-93,,,,,2013,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540112001642;http://dx.doi.org/10.1016/j.ic.2012.10.019,10.1016/j.ic.2012.10.019,"We extend the theory of cellular automata to arbitrary, time-varying graphs. In other words we formalise, and prove theorems about, the intuitive idea of a labelled graph which evolves in time — but under the natural constraint that information can only ever be transmitted at a bounded speed, with respect to the distance given by the graph. The notion of translation-invariance is also generalised. The definition we provide for these ‘causal graph dynamics’ is simple and axiomatic. The theorems we provide also show that it is robust. For instance, causal graph dynamics are stable under composition and under restriction to radius one. In the finite case some fundamental facts of cellular automata theory carry through: causal graph dynamics admit a characterisation as continuous functions, and they are stable under inversion. The provided examples suggest a wide range of applications of this mathematical object, from complex systems science to theoretical physics.","Dynamical networks, Boolean networks, Generative networks automata, Cayley cellular automata, Graph automata, Graph rewriting automata, Parallel graph transformations, Amalgamated graph transformations, Time-varying graphs, Regge calculus, Local, No-signalling",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Car A,Frank AU",,Formalization of conceptual models for GIS using Gofer,"Computers, Environment and Urban Systems",1995,19,2,89-98,,,,,1995,,0198-9715,https://www.sciencedirect.com/science/article/pii/019897159500013X;http://dx.doi.org/10.1016/0198-9715(95)00013-X,10.1016/0198-9715(95)00013-X,"Formalization of spatial concepts is an important task for GIS. This paper focuses on a formalization of the conceptual model of hierarchy of space; wayfinding in a hierarchically structured road network is studied as a particular case. The formalization method introduced here uses algebraic specifications. We have found tools which allow us to execute algebraic specification. The functional programing language Gofer is suitable for writing formal specifications and their execution. It allows formal checks of the specifications on consistency, and supports rapid prototyping. This helps to control that the specification captures the intended semantics. Examples show the formalization of the objects defined in the ontology of the proposed conceptual model for a graph structure.",,1GIS/LIS '95 \bb Central Europe,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zandieh MJ,Knapp J",,Exploring the role of metonymy in mathematical understanding and reasoning: The concept of derivative as an example,The Journal of Mathematical Behavior,2006,25,1,1-17,,,,,2006,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312305000556;http://dx.doi.org/10.1016/j.jmathb.2005.11.002,10.1016/j.jmathb.2005.11.002,"In this paper we examine the roles that metonymy may play in student reasoning. To organize this discussion we use the lens of a structured derivative framework. The derivative framework consists of three layers of process–object pairs, one each for ratio, limit, and function. Each of the layers can then be illustrated in any appropriate context, for example graphically as slope, verbally as rate of change, or kinesthetically as velocity. We will illustrate three main cases of metonymy using data from student reasoning with derivative–paradigmatic metonymy, individual metonymy and part–part metonymy. Metonymies may function both in powerful and problematic ways for students as they come to understand and work with a complicated concept such as the derivative. It is the goal of this paper to illuminate and clarify how metonymy may function in student reasoning in the hopes of providing insights to teachers and researchers.","Metonymy, Calculus, Derivative, Metaphor, Rate, Slope",,,,,,,,,,,,,,,,,,,,,
Journal Article,Hadingham PT,,Modeling of edge based visual objects,Mathematical and Computer Modelling,1990,14,,435-439,,,,,1990,,0895-7177,https://www.sciencedirect.com/science/article/pii/0895717790902229;http://dx.doi.org/10.1016/0895-7177(90)90222-9,10.1016/0895-7177(90)90222-9,"Motivation for the ideas developed in this contribution arise from the perception that the important tasks of object representation, classification and recognition in machine vision need to be released from the strictures inherent in a discrete modeling domain. To this end, a formal language for describing object represented as edges in terms of arcs, parametrized by knot angle, curvature and length, developed earlier (Hadingham, 1988a, 1988b), is now expressed in the context of a novel structure referred to as the arc space. This topological space is shown to have properties important in supporting the above-mentioned machine vision tasks efficiently with respect to both time and space factors. As an example, object generalization/specialization as well as multiscaling operations, which are generally regarded as being crucial to machine vision tasks, are supported in a natural way.","Machine vision, object representation, object classification, object recognition, arc space",,,,,,,,,,,,,,,,,,,,,
Journal Article,Jakubczyk B,,Remarks on Equivalence and Linearization of Nonlinear Systems,IFAC Proceedings Volumes,1992,25,13,143-147,,,,,1992,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017522727;http://dx.doi.org/10.1016/S1474-6670(17)52272-7,10.1016/S1474-6670(17)52272-7,"In this note we consider a problem of equivalence of nonlinear systems described by a finite set of real variables satisfying a system of ordinary differential equations of finite order. Two systems are called equivalent (resp. weakly equivalent) if there exist nonlinear transformations so that the variables of one system are functions of the variables (resp. the variables and their derivatives) of the second system and vice versa, so that the sets of formal trajectories are maped onto the sets of formal trajectories. To each system we associate an algebraic object which is a D-algebra (a differential algebra). We show that our systems are weakly equivalent if and only if the corresponding D-algebras are isomorphic. The same result holds with weak equivalence replaced bv equivalence if the corresponding algebraic object is a D-algebra with filtration. As corollaries we obtain algebraic criteria for equivalence (weak equivalence) of a system to a linear controllable system.","Equivalence, nonlinear systems, trajectories, D-algebras, linearization","2nd IFAC Symposium on Nonlinear Control Systems Design 1992, Bordeaux, France, 24-26 June",,,,,,,,,,,,,,,,,,,,
Book Chapter,Ashenden PJ,Ashenden PJ,7 - Subprograms,,2002,,,195-230,Second Edition,Morgan Kaufmann,San Francisco,The Designer's Guide to VHDL (Second Edition),2002,,1875-9661,https://www.sciencedirect.com/science/article/pii/B9781558606746500095;http://dx.doi.org/10.1016/B978-155860674-6/50009-5,10.1016/B978-155860674-6/50009-5,"Publisher Summary When one writes complex behavioral models, it is useful to divide the code into sections with each section dealing with a relatively self-contained part of the behavior. VHDL provides a subprogram facility to do this. This chapter focuses on two kinds of subprograms: procedures and functions. A procedure can declare items in its declarative part for use in the statements in the procedure body. The declarations can include types, subtypes, constants, variables, and nested subprogram declarations. A parameterized procedure performs its algorithm using different data objects or values each time it is called. A function is a way of defining a new operation that can be used in expressions. One can use functions in VHDL to help write functional models more expressively. Unlike a procedure subprogram, a function calculates and returns a result that can be used in an expression. The difference between the two is that a procedure encapsulates a collection of sequential statements that are executed for their effect, whereas a function encapsulates a collection of statements that compute a result. Thus, a procedure is a generalization of a statement, whereas a function is a generalization of an expression. VHDL allows defining subprograms using a technique called overloading of subprogram names, where one can define two distinct subprograms with the same name but with different numbers or types of formal parameters.",,,Systems on Silicon,,,,,,,,,,,,,,,,,,,
Journal Article,"Zemskov KA,Pashkow AG",,Construction of optimal position strategies in a differential pursuit-evasion game with one pursuer and two evaders,Journal of Applied Mathematics and Mechanics,1997,61,3,391-399,,,,,1997,,0021-8928,https://www.sciencedirect.com/science/article/pii/S0021892897000506;http://dx.doi.org/10.1016/S0021-8928(97)00050-6,10.1016/S0021-8928(97)00050-6,"The game-theoretic pursuit-evasion problem of one pursuer and two evaders is considered. It is assumed that one of the evaders must leave the game (disappear) at some time; however, neither this time nor the leaving evader is known in advance. The dynamics of all the objects can be described by the equations of the well-known Isaacs problem of the “game of two cars” [1] subject to conditions of restricted manoeuvrabikity of the objects. The minimum time difference between the pursuer and the evader remaining in the game is the payoff of the game. Under certain assumptions, relating the parameters of the objects and their initial positions, the optimal position strategies for the pursuer and two evaders are constructed. The formal description of the problem follows that considered in [2]. The approach proposed in [3] is developed. Similar problems were considered in [10–16].",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Moss LS,,"Preface: Volume 65, Issue 1",Electronic Notes in Theoretical Computer Science,2002,65,1,365-366,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105803743;http://dx.doi.org/10.1016/S1571-0661(05)80374-3,10.1016/S1571-0661(05)80374-3,"This volume contains the Proceedings of the Fifth Workshop on Coalgebraic Methods in Computer Science (CMCS'2002). The Workshop was held in Grenoble, France on April 6--7 2002, as satellite event to ETAPS'2002. Over the last few years it has become clear that a great variety of state-based dynamical systems, like transition systems, automata, process calculi and class-based systems can be captured uniformly as coalgebras. The aim of the CMCS workshops is to bring together researchers with a common interest in the theory and application of coalgebras. The five CMCS volumes demonstrate that coalgebra is developing into a field of its own, presenting a deep mathematical foundation and a growing field of applications and interactions with various other fields, such as modal logic, category theory, dynamical systems, control systems, object-oriented and concurrent programming, formal systems specifications, algebra, analysis, combinatorics, and set theory. The papers in this volume were reviewed by the program committee: Jiri Adamek(Department of Computer Science, Technical University of Braunschweig)Alexandru Baltag(Department of Computer Science, Oxford University)H. Peter Gumm(Department of Mathematics and Computer Science, University of Marburg)Jesse Hughes(Department of Computer Science, University of Nijmegen)Bart Jacobs(Department of Computer Science, University of Nijmegen)Alexander Kurz(Department of Software Technology, CWI)Marina Lenisa(Department of Mathematics and Computer Science, University of Udine)Ugo Montanari(Department of Computer Science, University of Pisa)Larry Moss(Department of Mathematics, Indiana University)Ataru T. Nakagawa(SRA Key Technology Laboratory, Tokyo)John Power(Department of Computer Science, The University of Edinburgh)Horst Reichel(Institute of Theoretical Computer Science, Dresden University of Technology)Jan Rutten(Department of Software Technology, CWI) Several outside reviewers also assisted. CMCS received 20 submissions and accepted 15 of them. In addition, there were two invited speakers: Jose Meseguer and Luigi Santocanale. Their papers appear in this volume along with the 15 submitted contributions. We are grateful to everyone who sent us papers, and we regret that the length of the conference did not allow more papers to be presented. We thank the organizers of ETAPS'2002 for their help and encouragement. Special thanks to Rachid Echahed for his constant help with the organization of the workshop, and also to Mike Mislove for his work as a Managing Editor of the ENTCS series. Their efforts have been crucial for the success of CMCS'2002. September 1, 2002 Lawrence S. Moss",,"CMCS'2002, Coalgebraic Methods in Computer Science (Satellite Event of ETAPS 2002)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Bajwa IS,Lee M,Bordbar B",,Translating natural language constraints to OCL,Journal of King Saud University - Computer and Information Sciences,2012,24,2,117-128,,,,,2012,,1319-1578,https://www.sciencedirect.com/science/article/pii/S131915781200002X;http://dx.doi.org/10.1016/j.jksuci.2011.12.003,10.1016/j.jksuci.2011.12.003,"Object Constraint Language (OCL) is the only available language to annotate the Unified Modeling Language (UML) based conceptual schema (CS) of a software application. In practice, the constraints are captured in a natural language (NL) such as English and then an OCL expert manually transforms the NL expressions to OCL syntax. However, it is a common knowledge that OCL is difficult to write specifically for the novel users with little or no prior knowledge of OCL. In recent times, model transformation technology has made transformation of one language to another simpler and easier. In this paper we present a novel approach to automatically transform NL specification of software constraints to OCL constraints. In NL to OCL transformation, Semantics of Business Vocabulary and Rules (SBVR) standard is used as an intermediate representation due to a couple of reasons: first of all, SBVR is based on higher order logic that simplifies the transformation of SBVR to other formal languages such as OCL. Moreover, SBVR used syntax of natural language and thus is close to human beings. The presented NL to OCL transformation via SBVR will not only simplify the process of generating OCL constraints but also generate accurate models in less time.","Natural language processing, English constraints, Formal constraints",,,,,,,,,,,,,,,,,,,,,
Journal Article,Singh AK,,Specification of concurrent objects using auxiliary variables,Science of Computer Programming,1991,16,1,49-88,,,,,1991,,0167-6423,https://www.sciencedirect.com/science/article/pii/016764239190023Q;http://dx.doi.org/10.1016/0167-6423(91)90023-Q,10.1016/0167-6423(91)90023-Q,"The role of auxiliary variables in the specification of concurrent objects with multiple inputs and outputs is examined. Auxiliary variables needed in a specification are defined through logical assertions on the interface variables. Necessary conditions and generic rules for the definition of such auxiliary variables are presented. The method is illustrated by specifying a concurrent buffer. Based on this specification, a number of useful properties of concurrent buffers and systems composed of them are derived through formal manipulation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Milun EH,Walters DK,Li Y",,General Ribbon-Based Thinning Algorithms for Stylus-Generated Images,Computer Vision and Image Understanding,1999,76,3,267-277,,,,,1999,,1077-3142,https://www.sciencedirect.com/science/article/pii/S107731429990807X;http://dx.doi.org/10.1006/cviu.1999.0807,10.1006/cviu.1999.0807,"Thinning algorithms for stylus-generated images are presented which are based on the general ribbon model of stylus-generated images. These algorithms have several advantages over existing thinning algorithms, including the existence of a formal specification of the desired output of a thinning algorithm; the preservation of image features which have been shown to be the most perceptually significant for the human perception of stylus-generated images; and the ability to deal easily with images which contain both stroke and blob objects.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Middleditch AE,Reade CM,Gomes AJ",,Set-combinations of the mixed-dimension cellular objects of the Djinn API,Computer-Aided Design,1999,31,11,683-694,,,,,1999,,0010-4485,https://www.sciencedirect.com/science/article/pii/S0010448599000652;http://dx.doi.org/10.1016/S0010-4485(99)00065-2,10.1016/S0010-4485(99)00065-2,"This paper is concerned with the mathematics and formal specification of “set-like” operations for the mixed dimension cellular geometric objects of the Djinn Application Programming Interface. The relationships between these operations and stratifications of dimensionally heterogeneous semianalytic point-sets are uncovered and formalised. Semianalytic geometry is central to the algebraic model discussed in this paper, but multi-disciplinary concepts from topology, differential geometry and computer-aided geometric design have been used also. In particular, the use of strong relative topological stratifications enables Djinn to satisfy significant industrial requirements.","Solid modelling, Application programming interfaces, Semianalytic point-sets, Stratification, Point-set orientation, Set-operations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Pripužić K,Podnar Žarko I,Aberer K",,Top-k/w publish/subscribe: A publish/subscribe model for continuous top-k processing over data streams,Information Systems,2014,39,,256-276,,,,,2014,,0306-4379,https://www.sciencedirect.com/science/article/pii/S030643791200049X;http://dx.doi.org/10.1016/j.is.2012.03.003,10.1016/j.is.2012.03.003,"Continuous processing of top-k queries over data streams is a promising technique for alleviating the information overload problem as it distinguishes relevant from irrelevant data stream objects with respect to a given scoring function over time. Thus it enables filtering of irrelevant data objects and delivery of top-k objects relevant to user interests in real-time. We propose a solution for distributed continuous top-k processing based on the publish/subscribe communication paradigm—top-k publish/subscribe over sliding windows (top-k/w publish/subscribe). It identifies k best-ranked objects with respect to a given scoring function over a sliding window of size w, and extends the publish/subscribe communication paradigm by continuous top-k processing algorithms coming from the field of data stream processing. In this paper, we introduce, analyze and evaluate the essential building blocks of distributed top-k/w publish/subscribe systems: first, we present a formal top-k/w publish/subscribe model and compare it to the prevailing Boolean publish/subscribe model. Next, we outline the top-k/w processing tasks performed by publish/subscribe nodes and investigate the properties of supported scoring functions. Furthermore, we explore potential routing strategies for distributed top-k/w publish/subscribe systems. Finally, we experimentally evaluate model properties and provide a comparative study investigating traffic requirements of potential routing strategies.","Event-based systems, Data stream, Sliding-window queries",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mackay DS,Robinson VB,Band LE",,Classification of higher order topographic objects on digital terrain data,"Computers, Environment and Urban Systems",1992,16,6,473-496,,,,,1992,,0198-9715,https://www.sciencedirect.com/science/article/pii/019897159290040X;http://dx.doi.org/10.1016/0198-9715(92)90040-X,10.1016/0198-9715(92)90040-X,"The development of land information systems for organizing terrain information for use in classification and simulation modelling is becoming an important concern of environment and resource management. We present a methodology for handling terrain as complex entities which are higher order geographic objects. This paper focuses on the conceptual design of a system for organizing the terrain into higher order objects using a logic-based approach augmented with inexact reasoning. System development progresses from the conceptualization of a set of geomorphic objects in the real-world, to the formal representation of this world-view in a knowledge-based system. We adopt a logic programming approach to knowledge representation of terrain objects. Incompleteness and ambiguity are handled using inexact reasoning.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Warke PA,Curran JM,Turkington AV,Smith BJ",,Condition assessment for building stone conservation: a staging system approach,Building and Environment,2003,38,9,1113-1123,,,,,2003,,0360-1323,https://www.sciencedirect.com/science/article/pii/S0360132303000854;http://dx.doi.org/10.1016/S0360-1323(03)00085-4,10.1016/S0360-1323(03)00085-4,"Trofimov and Phillips (Geomorphology 5 (1992) 203) suggest that the ultimate goal of any science is to predict the behaviour of entire systems. With regard to the decay of building stone, making accurate predictions of stone behaviour remains an elusive goal but given our improved understanding of decay dynamics it should be possible to provide a forecast of likely system behaviour. However, forecasting system behaviour requires classification of the system state with the classification, whether formal or informal, founded on knowledge of the factors that control response. In the context of building stone decay these controlling factors include, structural properties, mineralogical properties, inheritance effects, contaminant loading and natural change. In trying to formalise building stone condition assessment and incorporate a forecast component, an analogy can be made between the requirements for classification and treatment determination of cancer patients and the approach to condition assessment and conservation of stone structures. In medicine, one of the most widely used and refined patient assessment schemes is the TNM Staging System. The rationale underpinning the TNM Staging System has many similarities with approaches to building stone assessment in that it seeks to impose a more formal structure on condition assessment that provides a commonality of approach, language and meaning and a procedure for forecasting the extent of remedial intervention required and outcome in terms of ‘life expectancy’.","Building stone, Decay, Sandstone, Staging system, Condition assessment","Building Stone Decay: Observations, Experiments and Modeling",,,,,,,,,,,,,,,,,,,,
Journal Article,"Kuhlmann S,Marshall M,Osiak K",,Cyclic 2-structures and spaces of orderings of power series fields in two variables,Journal of Algebra,2011,335,1,36-48,,,,,2011,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869311001074;http://dx.doi.org/10.1016/j.jalgebra.2011.02.026,10.1016/j.jalgebra.2011.02.026,"We consider the space of orderings of the field R((x,y)) and the space of orderings of the field R((x))(y), where R is a real closed field. We examine the structure of these objects and their relationship to each other. We define a cyclic 2-structure to be a pair (S,Φ) where S is a cyclically ordered set and Φ is an equivalence relation on S such that each equivalence class has exactly two elements. We show that each of these spaces of orderings is described by a cyclic 2-structure, in a natural way. We also show that if the real closed field R is archimedean then the space of R-places of these fields is describable in terms of the cyclic 2-structure.","Orderings, Real places, Formal power series",,,,,,,,,,,,,,,,,,,,,
Journal Article,Cohen G,,Intelligent vision system to control flexible assembly cell feeding processes,Engineering Applications of Artificial Intelligence,1994,7,1,67-76,,,,,1994,,0952-1976,https://www.sciencedirect.com/science/article/pii/0952197694900442;http://dx.doi.org/10.1016/0952-1976(94)90044-2,10.1016/0952-1976(94)90044-2,"A vision system which is installed at an assembly cell to detect its feeding system must analyze objects for inspection and assembly operations. This means that a description of the objects must be generated. A particular analytic technique may be characterized by the nature of the formal description generated, by the computation techniques employed and by the degree to which the formal description accurately reflects pertinent information about the object. To execute assembly tasks, the part identification, orientation, spatial position and geometric features were calculated. For inspection tasks, a list of deviations between the observed object and a reference object was generated to determine whether a part could proceed into the assembly cell. Since the vision system is associated with real-time assembly cell operations, its vision data processing time must be minimized. Therefore, intelligent processing techniques must be developed. Such techniques are provided by the developed knowledge-base and inference engine. The described vision system which is incorporated with the knowledge base and the inference engine is referred to as an “intelligent vision system”. The developed intelligent vision system was implemented in a simulation program to inspect the feeding systems of pneumatic motor assembly cells. The results support known interrelationships between parameters associated with detected assembly processes, and verify the reliability of the developed inference engine reasoning algorithms. Since the simulation was programmed in generic terms, it is not limited to a specific product but can be applied to a large variety of products.","Intelligent vision system, recognition processes, flexible assembly cell, feeding processes, expert systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kim H,Oh H,Bellavista P,Ben-Othman J",,Constructing event-driven partial barriers with resilience in wireless mobile sensor networks,Journal of Network and Computer Applications,2017,82,,77-92,,,,,2017,,1084-8045,https://www.sciencedirect.com/science/article/pii/S1084804517300152;http://dx.doi.org/10.1016/j.jnca.2017.01.010,10.1016/j.jnca.2017.01.010,"A barrier-coverage in wireless mobile sensor networks (WMSN) has attracted lots of interests recently. It is highly desirable to consider a barrier-coverage that can detect any moving objects between multiple sides in an event-driven environment. In this paper, we introduce a new architecture of barrier, event-driven partial barrier, which is able to monitor any movements of objects in the event-driven environment. Also, resilient event-driven partial barrier is introduced to consider the case that the constructed barriers collapsed due to failures of some sensors consisting of those barriers. Then, we define two different problems formally. One is to minimize the number of sensors to generate complete event-driven partial barrier. Another is to minimize a total movement distance of sensors such that resilient event-driven partial barrier is formed to recover from sensor failures without any new addition of sensors. To solve the first problem, we propose two approaches, Greedy-Shared-Barrier and Greedy-Shared-Sensor, which create the complete event-driven partial barrier with possible minimum number of sensors. For the second problem, the proposed schemes, Uncovered-Sensor-Movement and Verified-Sensor-Movement guarantee a recovery of defective barriers with possible minimum total movement distance of sensors. Then, we analyze their relative performances through extensive simulations with various scenarios and also provide the complexity analysis of the proposed schemes.","Sensor, Mobile, Event-driven, Barrier, Resilient",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gorraiz J,Melero-Fuentes D,Gumpenberger C,Valderrama-Zurián JC",,Availability of digital object identifiers (DOIs) in Web of Science and Scopus,Journal of Informetrics,2016,10,1,98-109,,,,,2016,,1751-1577,https://www.sciencedirect.com/science/article/pii/S1751157715301176;http://dx.doi.org/10.1016/j.joi.2015.11.008,10.1016/j.joi.2015.11.008,"This study aims to shed light on the implementation of the digital object identifier (DOI) in the two most important multidisciplinary databases, namely Web of Science Core Collection and Scopus, within the last decade (2005–2014). The results show a generally increased percentage of items with DOI in all the disciplines in both databases, which provide very similar numbers and trends. While the percentage of citable items with a DOI has already reached 90% in the Sciences and the Social Sciences in 2014, it has remained much lower in the Arts & Humanities, exceeding 50% only since 2013. The observed values for Books and Proceedings are even lower despite the importance of these document types, particularly for the Social Sciences and the Arts & Humanities. The fact that there are still journals with a large number of items still lacking DOIs in 2014 should be alarming for the corresponding editors and should give them reason to enhance the formal quality and visibility of their journals. Finally, scientists are also encouraged to review their publication strategies and to favour publication channels with established DOI assignments.","DOI, Web of Science Core Collection, Scopus, Citation databases, Visibility, Altmetrics",,,,,,,,,,,,,,,,,,,,,
Journal Article,von Plato J,,Combinatorial analysis of proofs in projective and affine geometry,Annals of Pure and Applied Logic,2010,162,2,144-161,,,,,2010,,0168-0072,https://www.sciencedirect.com/science/article/pii/S016800721000103X;http://dx.doi.org/10.1016/j.apal.2010.08.005,10.1016/j.apal.2010.08.005,"The axioms of projective and affine plane geometry are turned into rules of proof by which formal derivations are constructed. The rules act only on atomic formulas. It is shown that proof search for the derivability of atomic cases from atomic assumptions by these rules terminates (i.e., solves the word problem). This decision method is based on the central result of the combinatorial analysis of derivations by the geometric rules: The geometric objects that occur in derivations by the rules can be restricted to those known from the assumptions and cases. This “subterm property” is proved by permuting suitably the order of application of the geometric rules. As an example of the decision method, it is shown that there cannot exist a derivation of Euclid’s fifth postulate if the rule that corresponds to the uniqueness of the parallel line construction is taken away from the system of plane affine geometry.","Proof analysis, Projective geometry, Affine geometry, Word problem",,,,,,,,,,,,,,,,,,,,,
Journal Article,Shanahan M,,An attempt to formalise a non-trivial benchmark problem in common sense reasoning,Artificial Intelligence,2004,153,1,141-165,,,,,2004,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370203001917;http://dx.doi.org/10.1016/j.artint.2003.05.001,10.1016/j.artint.2003.05.001,"Most logic-based AI research works at a meta-theoretical level, producing new logics and studying their properties. Little effort is made to show how these logics can be used to formalise object-level theories of common sense. In the spirit of Pat Hayes's Naive Physics Manifesto, the present paper supplies a formalisation of a non-trivial benchmark problem in common sense physical reasoning, namely how to crack an egg. The formalisation is based on the event calculus, a well-known formalism for reasoning about action. Along the way, a number of methodological issues are raised, such as the question of how the symbols deployed in the formalisation might be grounded through a robot's interaction with the world.","Common sense reasoning, Naive physics, Cognitive robotics",Logical Formalizations and Commonsense Reasoning,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ziemann P,Hölscher K,Gogolla M",,From UML Models to Graph Transformation Systems,Electronic Notes in Theoretical Computer Science,2005,127,4,17-33,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105001763;http://dx.doi.org/10.1016/j.entcs.2004.10.025,10.1016/j.entcs.2004.10.025,"In this paper we present an approach that allows to validate properties of UML models. The approach is based on an integrated semantics for central parts of the UML. We formally cover UML use case, class, object, statechart, collaboration, and sequence diagrams. Additionally full OCL is supported in the common UML fashion. Our semantics is based on the translation of a UML model into a graph transformation system consisting of graph transformation rules and a working graph that represents the system state. By applying the rules on the working graph, the evolution of the modeled system is simulated.","Graph transformation, UML semantics, validation, CASE tool",Proceedings of the Workshop on Visual Languages and Formal Methods (VLFM 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Sanin C,Haoxi Z,Shafiq I,Waris MM,Silva de Oliveira C,Szczerbicki E",,Experience based knowledge representation for Internet of Things and Cyber Physical Systems with case studies,Future Generation Computer Systems,2019,92,,604-616,,,,,2019,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X17316965;http://dx.doi.org/10.1016/j.future.2018.01.062,10.1016/j.future.2018.01.062,"Cyber Physical Systems and Internet of Things have grown significant attention from industry and academia during the past decade. The main reason behind this interest is the capabilities of such technologies to revolutionize human life since they appear as seamlessly integrating classical networks, networked objects and people to create more efficient environments. However, enhancing these technologies with intelligent skills becomes an even more interesting and enticing scenario. In this paper, we propose and illustrate through a number of case studies how Decisional DNA, a multi-domain knowledge structure based on experience, can be implemented as a comprehensive embedded knowledge representation for Internet of Things and Cyber Physical Systems. Decisional DNA gathers explicit experiential knowledge based on formal decision events and uses this knowledge to support decision-making processes. The main advantages of using Decisional DNA are as follows: (i) offers a standardized form of the collected knowledge and experience, (ii) provides versatility and dynamicity of the knowledge structure, (iii) stipulates storage of day-to-day explicit experience in a single configuration, (iv) delivers transportability and shareability of the knowledge, and (v) provides predicting capabilities based on the collected experience. Consequently, test and results of the presented implementation of Decisional DNA case studies support it as a technology that can improve and be applied to the aforementioned technologies enhancing them with intelligence by predicting capabilities and facilitating knowledge engineering processes.","Decisional DNA, Set of experience knowledge structure, Cyber Physical Systems, Internet of Things, Factory 4.0, Knowledge representation, Knowledge engineering, Decision making, Artificial intelligence, Virtual engineering object, Virtual engineering process, Virtual engineering factory",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Deebak BD,AL-Turjman F",,Lightweight authentication for IoT/Cloud-based forensics in intelligent data computing,Future Generation Computer Systems,2021,116,,406-425,,,,,2021,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X2033034X;http://dx.doi.org/10.1016/j.future.2020.11.010,10.1016/j.future.2020.11.010,"Numerous application domains in practice related to target- tracking, monitoring, and transportation have utilized the wide usage of Wireless Sensor Networks (WSN’s) technology. These domains use physical networking objects connecting over the Internet to collect and exchange the data. Using the advancement of cloud computing technologies and aggravation of big-data growth caused by the incorporation of the Internet of Things (IoT), secure user authentication for remote access is playing a crucial role. Since it has limited authorization and authentication privileges for mobility users, an approach of mobile-sink has been instigated for the improvisation of remote user authentication i.e. cloud-based IoT applications. As a result, this article proposes a lightweight smartcard based secure authentication (LS-BSA) approach using the mathematical assumption of bilinear-pairing/mapping, elliptic-curve cryptosystems, and fuzzy verifier. An extensive security investigation demonstrates that the proposed LS-BSA not only guarantees the AKA security properties but also prevents significant vulnerabilities. Furthermore, the proposed LS-BSA uses lightweight operations to establish a seamless data connectivity over a secure network. It maintains the compatibility standards including low-cost and low-power to mitigate the computation and communication cost of cloud-based intelligent data computing. Formal security verification of BAN-logic is introduced to show that LS-BSA offers proper mutual user authentication and secret secure-session key agreement between the real-time entities. In addition, a network scenario has been set up using the NS-3 simulator to prove that the proposed LS-BSA is more efficient than other existing schemes in terms of packet delivery ratio, end-to-end delay, and throughput rate.","Intelligent data computing, Wireless sensor networks, Internet of Things, Cloud computing, Authentication and key agreement, Session-key agreement",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Leopold JL,Sabharwal CL,Ward KJ",,"Spatial relations between 3D objects: The association between natural language, topology, and metrics",Journal of Visual Languages & Computing,2015,27,,29-37,,,,,2015,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X14001347;http://dx.doi.org/10.1016/j.jvlc.2014.11.008,10.1016/j.jvlc.2014.11.008,"With the proliferation of 3D image data comes the need for advances in automated spatial reasoning. One specific challenge is the need for a practical mapping between spatial reasoning and human cognition, where human cognition is expressed through natural-language terminology. With respect to human understanding, researchers have found that errors about spatial relations typically tend to be metric rather than topological; that is, errors tend to be made with respect to quantitative differences in spatial features. However, topology alone has been found to be insufficient for conveying spatial knowledge in natural-language communication. Based on previous work that has been done to define metrics for two lines and a line and a 2D region in order to facilitate a mapping to natural-language terminology, herein we define metrics appropriate for 3D regions. These metrics extend the notions of previously defined terms such as splitting, closeness, and approximate alongness. The association between this collection of metrics, 3D connectivity relations, and several English-language spatial terms was tested in a human subject study. As spatial queries tend to be in natural language, this study provides preliminary insight into how 3D topological relations and metrics correlate in distinguishing natural-language terms.","Spatial reasoning, Natural-language processing, Region connection calculus, 3D images",Distributed Multimedia Systems DMS2014 Part II,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chen X,Rosen J",,Large deviations and renormalization for Riesz potentials of stable intersection measures,Stochastic Processes and their Applications,2010,120,9,1837-1878,,,,,2010,,0304-4149,https://www.sciencedirect.com/science/article/pii/S0304414910001298;http://dx.doi.org/10.1016/j.spa.2010.05.006,10.1016/j.spa.2010.05.006,"We study the object formally defined as (0.1)γ([0,t]2)=∬[0,t]2|Xs−Xr|−σdrds−E∬[0,t]2|Xs−Xr|−σdrds, where Xt denotes the symmetric stable processes of index 0<β≤2 in Rd. When β≤σ<min32β,d, this has to be defined as a limit, in the spirit of renormalized self-intersection local time. We obtain results about the large deviations and laws of the iterated logarithm for γ. This is applied to obtain results about stable processes in random potentials.","Large deviations, Renormalization, Riesz potentials, Stable intersection measure",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhou L,Li X,Yeh KH,Su C,Chiu W",,Lightweight IoT-based authentication scheme in cloud computing circumstance,Future Generation Computer Systems,2019,91,,244-251,,,,,2019,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X18307878;http://dx.doi.org/10.1016/j.future.2018.08.038,10.1016/j.future.2018.08.038,"Recently, authentication technologies integrated with the Internet of Things (IoT) and cloud computing have been promptly investigated for secure data retrieval and robust access control on large-scale IoT networks. However, it does not have a best practice for simultaneously deploying IoT and cloud computing with robust security. In this study, we present a novel authentication scheme for IoT-based architectures combined with cloud servers. To pursue the best efficiency, lightweight crypto-modules, such as one-way hash function and exclusive-or operation, are adopted in our authentication scheme. It not only removes the computation burden but also makes our proposed scheme suitable for resource-limited objects, such as sensors or IoT devices. Through the formal verification delivered by Proverif, the security robustness of the proposed authentication scheme is guaranteed. Furthermore, the performance evaluation presents the practicability of our proposed scheme in which a user-acceptable computation cost is achieved.","Internet-of-things (IoT), Cloud computing, Authentication, Proverif, User tracking",,,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Rabinowitz H,Vogel S",Chapter 8 - Style and Usage for Astronomy,,2009,,,351-374,,Academic Press,San Diego,The Manual of Scientific Style,2009,9780123739803,,https://www.sciencedirect.com/science/article/pii/B9780123739803500125;http://dx.doi.org/10.1016/B978-012373980-3.50012-5,10.1016/B978-012373980-3.50012-5,"Publisher Summary This chapter is about style and usage for astronomical notions such as formal astronomical name, standard capitalization rules, and celestial coordinate notions. There are more than a billion identified astronomical objects, and all of them need unique, systematic designations. The authority on astronomical nomenclature is the International Astronomical Union (IAU) located in Paris, France. Some objects have proper names, especially planets and naked-eye visible stars, but most are more reliably given a catalog name. This chapter also explains the use of acronym for the new designation and minor planets (asteroids) and minor comets. The acronym is a code that indicates the catalogue or collection of sources. It can be created out of catalogue names (e.g. NGC, BD), instruments or observatories used for large surveys (VLA, IRAS, 3C, 51W), or the names of authors (RCW). In recent years, however, the discovery of asteroids has accelerated due to the application of computer-assisted techniques (LINEAR and LONEOS, among others), which has resulted in the confirmed discovery of many thousands of asteroids. The CSBN has therefore placed a limitation on the naming process: a maximum of two names may be designated per discoverer per month.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Konvalina J,,Generalized Binomial Coefficients and the Subset–Subspace Problem,Advances in Applied Mathematics,1998,21,2,228-240,,,,,1998,,0196-8858,https://www.sciencedirect.com/science/article/pii/S019688589890598X;http://dx.doi.org/10.1006/aama.1998.0598,10.1006/aama.1998.0598,"Generalized binomial coefficients of the first and second kind are defined in terms of object selection with and without repetition from weighted boxes. The combinatorial definition unifies the binomial coefficients, the Gaussian coefficients, and the Stirling numbers and their recurrence relations under a common interpretation. Combinatorial proofs for some Gaussian coefficient identities are derived and shown to reduce to the ordinary binomial coefficients whenq=1. This approach provides a different perspective on the subset–subspace analogy problem. Generating function relations for the generalized binomial coefficients are derived by formal methods.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bozzato L,Eiter T,Serafini L",,Enhancing context knowledge repositories with justifiable exceptions,Artificial Intelligence,2018,257,,72-126,,,,,2018,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370218300018;http://dx.doi.org/10.1016/j.artint.2017.12.005,10.1016/j.artint.2017.12.005,"Dealing with context dependent knowledge is a well-known area of study that roots in John McCarthy's seminal work. More recently, the Contextualized Knowledge Repository (CKR) framework has been conceived as a logic-based approach in which knowledge bases have a two layered structure, modeled by a global context and a set of local contexts. The global context not only contains the meta-knowledge defining the properties of local contexts, but also holds the global (context independent) object knowledge that is shared by all of the local contexts. In many practical cases, however, it is desirable to leave the possibility to “override” the global object knowledge at the local level: in other words, it is interesting to recognize the pieces of knowledge that can admit exceptional instances in the local contexts that do not need to satisfy the general axiom. To address this need, we present in this paper an extension of CKR in which defeasible axioms can be included in the global context. The latter are verified in the local contexts only for the instances for which no exception to overriding exists, where exceptions require a justification in terms of facts that are provable from the knowledge base. We formally define this semantics and study some semantic and computational properties, where we characterize the complexity of the major reasoning tasks, among them satisfiability testing, instance checking, and conjunctive query answering. Furthermore, we present a translation of extended CKRs with knowledge bases in the Description Logic SROIQ-RL under the novel semantics to datalog programs under the stable model (answer set) semantics. We also present an implementation prototype and examine its scalability with respect to the size of the input CKR and the amount (level) of defeasibility in experiments. Finally, we compare our representation approach with some major formalisms for expressing defeasible knowledge in Description Logics and contextual knowledge representation. Our work adds to the body of results on using deductive database technology such as SQL and datalog in these areas, and provides an expressive formalism (in terms of intrinsic complexity) for exception handling by overriding.","Knowledge representation, Contextual reasoning, Description logics, Datalog, Defeasible knowledge",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Edwards DJ,Holt GD",,Case study analysis of risk from using excavators as ‘cranes’,Automation in Construction,2010,19,2,127-133,,,,,2010,,0926-5805,https://www.sciencedirect.com/science/article/pii/S0926580509002027;http://dx.doi.org/10.1016/j.autcon.2009.12.013,10.1016/j.autcon.2009.12.013,"Excavators are frequently used as ‘cranes’ for object handling on construction sites, but this situation brings with it significant health and safety hazards that often, are not fully appreciated by stakeholders. These hazards are identified; their risks explained and studied; and appropriate advice for stakeholders explicated. A developmental approach is employed that embraces accrual of evidence; case studies; theoretical examination; and derivation of guidance. It is found that excavators are often used as cranes employing both ‘formal’ or less satisfactory ‘informal’ methods of load connection. Hazards from using excavators as cranes (found principally among load connection points and associated lifting accessories), are often ‘hidden’ and can lead to catastrophic failure during lifting operations. Stakeholders need to be aware of the hazards and implement suggested risk controls to remove or mitigate them.","Excavators, Plant and equipment, Cranes, Lifting operations, Health and safety",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dufourd JF,Mathis P,Schreck P",,Geometric construction by assembling solved subfigures,Artificial Intelligence,1998,99,1,73-119,,,,,1998,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370297000702;http://dx.doi.org/10.1016/S0004-3702(97)00070-2,10.1016/S0004-3702(97)00070-2,"Among the expected contributions of Artificial Intelligence to Computer-Aided Design is the possibility of constructing a geometric object, the description of which is given by a system of topological and dimensional constraints. This paper presents the theoretical foundations of an original approach to formal geometric construction of rigid bodies in the Euclidian plane, based on invariance under displacements and relaxation of positional constraints. This general idea allows to explain in greater detail several methods proposed in the literature. One of the advantages of this approach is its ability to efficiently generalize and join together different methods for local solving. The paper also describes the main features of a powerful and extensible operational prototype based on these ideas, which can be viewed as a simple multi-agent system with a blackboard. Finally, some significant examples solved by this prototype are presented.","Geometric formal construction, System of geometric constraints, Computer-aided design, Local solving, Assembling of figures, Multi-agent system, Blackboard",,,,,,,,,,,,,,,,,,,,,
Journal Article,"van den Brand M,Parigot D",,"Preface: Volume 44, Issue 2",Electronic Notes in Theoretical Computer Science,2001,44,2,232-233,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105809302;http://dx.doi.org/10.1016/S1571-0661(05)80930-2,10.1016/S1571-0661(05)80930-2,"Foreword This volume contains the Proceedings of the First Workshop on Language Descriptions, Tools and Applications (LDTA'01). The Workshop was held in Genova, Italy on April 7, 2001, as satellite event to ETAPS'2001. This is the first edition of the Workshop on Language Descriptions, Tools and Applications. It is a combination of the “Workshop on Attribute Grammars and their Applications” and the former ASF+SDF workshops. Both workshop series had as theme the description of (programming) languages and the development and/or generation of tools for these languages based on formal descriptions. With this new workshop we hope to achieve a cross-fertilization of research in this area by bringing together researchers from various schools (attribute grammars, algebraic approaches, action semantics, operational semantics, and denotational semantics) working on language descriptions. The workshop also aims at bringing together people from the theoretical side as well as people who develop tools and work on applications. The LDTA'2001 program consists of 9 papers, which were selected from 18 submissions, one invited talk by Paul Klint on “Collaborative Development of Interactive Language Processing Tools”, and 4 tool demonstrations. The selected papers cover a broad range of themes like: object oriented tree traversal and attribute grammars, action semantics, rewriting engines, document transformation, and the use of XML and JAVA in combination with attribute grammars. The tool demonstrations include presentations of the ASF+SDF Meta-Environment, SmartTools, Stratego, and an action semantics environment. The papers in this volume were reviewed by the program committee consisting of Isabelle Attali(INRIA Sophia Antipolis)Mark van den Brand(CWI Amsterdam)Görel Hedin(Lund University)Jan Heering(CWI Amsterdam)Pierre-Etienne Moreau(LORIA Nancy)Marjan Mernik(University of Maribor)Peter D. Mosses(BRICS Aarhus)Didier Parigot(INRIA Sophia Antipolis)Günter Riedewald(University of Rostock)Eelco Visser(Utrecht University)David Watt(University of Glasgow) This volume will be published as volume 44-2 in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs We would like to thank the program committee members for their help in evaluating the papers and making a scientifically interesting selection. Furthermore, we would like to thank the ETAPS organizing committee for taking care of the local organization of our workshop. We thank Elsevier for publishing these proceedings in the Electronic Notes in Theoretical Computer Science (ENTCS). Finally, we thank Professor Michael Mislove for providing and adapting the style files for ENTCS. Mark van den Brand and Didier Parigot June, 2001",,"LDTA'01, First Workshop on Language Descriptions, Tools and Applications (a Satellite Event of ETAPS 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Malik A,Park H,Nadeem M,Salcic Z",,Memory management of safety-critical hard real-time systems designed in SystemJ,Microprocessors and Microsystems,2019,64,,101-119,,,,,2019,,0141-9331,https://www.sciencedirect.com/science/article/pii/S014193311830348X;http://dx.doi.org/10.1016/j.micpro.2018.10.007,10.1016/j.micpro.2018.10.007,"SystemJ is a programming language based on the Globally Asynchronous Locally Synchronous (GALS) Model of Computation (MoC) used to design safety critical hard real-time systems. SystemJ uses the Java programming language as the “host” language, for carrying out data computations, because Java provides clearly defined operational semantics, type and memory safety in the form of the Garbage Collector(GC), which help with formal functional verification. The same GC, which helps in functional verification, makes Worst Case Reaction Time (WCRT)11Similar to Worst Case Execution Time. analysis challenging. Any WCRT analysis framework for GALS programs needs to consider the operations performed by the host language. It has been shown that the worst case time estimates for garbage collection cycles are in seconds, whereas the program’s WCRT itself is in micro-seconds. These pessimistic estimates render the WCRT analysis framework ineffective. In order to overcome this problem, we develop a compiler assisted memory management technique for applications written in SystemJ. The SystemJ MoC plays the central role in the proposed technique. The SystemJ MoC allows clearly demarcating the state boundaries of the program, which in turn allows us to partition the heap, at compile time, into two distinct areas: (1) the memory area called the permanent heap, which holds objects that are alive throughout the life time of the application, and (2) the memory area used to hold all other objects, called the transient heap. The size of these memory areas are bounded statically. Furthermore, the memory allocation and reclaim procedures are simple load and pointer reset operations, respectively, which are guaranteed to complete within a bounded number of clock-cycles, thereby alleviating the need for large pessimistic WCRT bounds obtained due to the GC. Experimental results also show that the proposed approach is approximately three times faster, in terms of memory allocation times as compared to standard real-time GC approaches.","Compiler, Static analysis, WCET, SystemJ, Garbage collection",,,,,,,,,,,,,,,,,,,,,
Journal Article,López Franco IL,,"Formal Hopf algebra theory, II: Lax centres",Journal of Pure and Applied Algebra,2009,213,11,2038-2054,,,,,2009,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404909000589;http://dx.doi.org/10.1016/j.jpaa.2009.03.011,10.1016/j.jpaa.2009.03.011,"This paper is the second in a series started by [Ignacio L. López Franco, Formal Hopf algebra theory I: Hopf modules for pseudomonoids, J. Pure Appl. Algebra 213 (2009) 1046–1063], aiming to extend the basic theory of Hopf algebras to the context of pseudomonoids in monoidal bicategories. This article concentrates on the notion of lax centre of a pseudomonoid and its relationship with the Drinfel’d or quantum double of a finite Hopf algebra and the centre of a monoidal category. We can distinguish two parts in the present paper. In the first, for a pseudomonoid A with lax centre ZℓA in a Gray monoid ℳ with certain extra properties, we exhibit an equivalence ℳ(I,ZℓA)≃Zℓ(ℳ(I,A)) of categories enriched in ℳ(I,I). In the second, we construct the lax centre of a left autonomous map pseudomonoid A as an Eilenberg–Moore object for a certain opmonoidal monad on A. Moreover, if A is also right autonomous, the lax centre coincides with the centre. As an application, we show that a (left) autonomous monoidal V-category has a (lax) centre in V-Mod, of which we give an explicit description. In another application, we prove that a finite-dimensional coquasi-Hopf algebra H has a centre in the monoidal bicategory Comod(Vect) and it is equivalent to the Drinfel’d double D(H).",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Elloumi S,Boulifa B,Jaoua A,Saleh M,Al Otaibi J,Frias MF",,Inference engine based on closure and join operators over Truth Table Binary Relations,Journal of Logical and Algebraic Methods in Programming,2014,83,2,180-193,,,,,2014,,2352-2208,https://www.sciencedirect.com/science/article/pii/S1567832614000083;http://dx.doi.org/10.1016/j.jlap.2014.02.007,10.1016/j.jlap.2014.02.007,"We propose a conceptual reasoning method for an inference engine. Starting from a knowledge base made of decision rules, we first map each rule to its corresponding Truth Table Binary Relation (TTBR), considered as a formal context. Objects in the domain of TTBR correspond to all possible rule interpretations (in terms of their truth value assignments), and elements in the range of TTBR correspond to the attributes. By using the ‘natural join’ operator in the ‘ContextCombine’ Algorithm, we combine all truth tables into a global relation which has the advantage of containing the complete knowledge of all deducible rules. By conceptual reasoning using closure operators, from the initial rules we obtain all possible conclusions with respect to the global relation. We may then check if expected goals are among these possible conclusions. We also provide an approximate solution for the exponential growth of the global relation, by proposing modular and cooperative conceptual reasoning. We finally present experimental results for two case studies and discuss the effectiveness of our approach.","Truth Table Binary Relation, Relation combining, Closure operators, Formal concept analysis, Inference engine, Cooperative conceptual reasoning",Festschrift in Honour of Gunther Schmidt on the Occasion of his 75th Birthday,,,,,,,,,,,,,,,,,,,,
Journal Article,"Corteel S,Savage CD",,"Lecture hall theorems, q-series and truncated objects","Journal of Combinatorial Theory, Series A",2004,108,2,217-245,,,,,2004,,0097-3165,https://www.sciencedirect.com/science/article/pii/S0097316504000962;http://dx.doi.org/10.1016/j.jcta.2004.05.006,10.1016/j.jcta.2004.05.006,"We show here that the refined theorems for both lecture hall partitions and anti-lecture hall compositions can be obtained as straightforward consequences of two q-Chu Vandermonde identities, once an appropriate recurrence is derived. We use this approach to get new lecture hall-type theorems for truncated objects. The truncated lecture hall partitions are sequences (λ1,…,λk) such that λ1n⩾λ2n-1⩾⋯⩾λkn-k+1⩾0and we show that their generating function is ∑m=0knmqqm+12(-qn-m+1;q)m(q2n-m+1;q)m.From this, we are able to give a combinatorial characterization of truncated lecture hall partitions and new finite versions of refinements of Euler's theorem. The truncated anti-lecture hall compositions are sequences (λ1,…,λk) such that λ1n-k+1⩾λ2n-k+2⩾⋯⩾λkn⩾0.We show that their generating function is nkq(-qn-k+1;q)k(q2(n-k+1);q)k,giving a finite version of a well-known partition identity. We give two different multivariate refinements of these new results: the q-calculus approach gives (u,v,q)-refinements, while a completely different approach gives odd/even (x,y)-refinements.","Integer partitions, Integer compositions, Enumeration",,,,,,,,,,,,,,,,,,,,,
Journal Article,Siau K,,A visual object-relationship query language for user–database interaction,Telematics and Informatics,1998,15,1,103-119,,,,,1998,,0736-5853,https://www.sciencedirect.com/science/article/pii/S0736585398000070;http://dx.doi.org/10.1016/S0736-5853(98)00007-0,10.1016/S0736-5853(98)00007-0,"User–database interaction has a direct and immediate effect on the effectiveness and efficiency of database end users. Traditional query languages like SQL and QBE require end users to understand the underlying data structure in the database. This is a burden on end users, especially novice end users who have little technical knowledge or understanding of database. To alleviate the need for end users to know the logical database organization, this paper proposes the use of an object–relationship (OR) model and a formal high-level visual query language as the interface. Using this interface, end users communicate only domain knowledge with the system without the need to specify the storage structure or search strategies. The end users deal only with the conceptual model of the database and not the actual physical implementation of the database. To demonstrate the expressive power of the visual query language, this paper also provides a proof to show that it is relationally complete and hence is as powerful as traditional languages such as SQL.","User–database interaction, Iconic interface, Visual query language, Object–relationship model",,,,,,,,,,,,,,,,,,,,,
Journal Article,Sobolewski MW,,Structured Object Representations in Many-Sorted Attribute Systems,IFAC Proceedings Volumes,1983,16,20,105-112,,,,,1983,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017615908;http://dx.doi.org/10.1016/S1474-6670(17)61590-8,10.1016/S1474-6670(17)61590-8,"Units (frames) and semantic networks are the most popular schemes for representation of structured objects. Both schemes can be formaly interpreted in a predicate calculus. In the paper a new representational scheme, based on so-called many-sorted attribute systems, is proposed. We define elementary attributes and four types of structured attributes (corresponding to four types of structuring: union - subclasses of a class of objects, meet - properties of objects of the same class, product - subobjects of an object, set - a collection of elements of an ob ject). With this attributes we can describe a structured object, consisting of some simpler objects. A description of an object is given directly in a structured attribute defined by its component attributes. For this purpose, we associate a formalized language with a collection of attributes, defining syntax, semantics of this language. By analogy to semantic networks we propose so-called attribute networks and inversely to units so-called reversed units. Interpretation of this new structured object representations follows from the many-sorted attribute systems presented in the paper.","Artificial intelligence, data processing, hierarchical systems, knowledge representation, structured objects","IFAC Symposium on Artificial Intelligence, Leningrad, USSR, 4-6 October",,,,,,,,,,,,,,,,,,,,
Journal Article,Matthes R,,A general approach to connections: algebra and geometry,Reports on Mathematical Physics,1991,29,2,141-175,,,,,1991,,0034-4877,https://www.sciencedirect.com/science/article/pii/0034487791900025;http://dx.doi.org/10.1016/0034-4877(91)90002-5,10.1016/0034-4877(91)90002-5,"General algebraic notions of covariant derivative and connection are introduced and a related algebraic formalism, including a calculus of forms, is developed. Using the notion “space of an algebra”, i.e. the set of maximal, finitely generated ideals, generalized locality conditions for the considered objects are formulated. Then it is shown that the general algebraic scheme leads to generalized notions of connection and covariant derivative (so-called r-connections and r-localized covariant derivatives) in the usual differential geometric framework, and a considerable part of the usual theory can be extended to the generalized situation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shahriari HR,Makarem MS,Sirjani M,Jalili R,Movaghar A",,Vulnerability analysis of networks to detect multiphase attacks using the actor-based language Rebeca,Computers & Electrical Engineering,2010,36,5,874-885,,,,,2010,,0045-7906,https://www.sciencedirect.com/science/article/pii/S0045790608000451;http://dx.doi.org/10.1016/j.compeleceng.2008.04.009,10.1016/j.compeleceng.2008.04.009,"Increasing use of networks and their complexity make the task of security analysis more and more complicated. Accordingly, automatic verification approaches have received more attention recently. In this paper, we investigate applying of an actor-based language based on reactive objects for analyzing a network environment communicating via Transport Protocol Layer (TCP). The formal foundation of the language and available tools for model checking provide us with formal verification support. Having the model of a typical network including client and server, we show how an attacker may combine simple attacks to construct a complex multiphase attack. We use Rebeca language to model the network of hosts and its model checker to find counter-examples as violations of security of the system. Some simple attacks have been modeled in previous works in this area, here we detect these simple attacks in our model and then verify the model to find more complex attacks which may include simpler attacks as their steps. We choose Rebeca because of its powerful yet simple actor-based paradigm in modeling concurrent and distributed systems. As the real network environment is asynchronous and event-based, Rebeca can be utilized to specify and verify the asynchronous systems, including network protocols.","Security analysis, Vulnerability analysis, Actor, Model checking, Rebeca language",Advances in Computing Systems Science and Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gedela RK,Shatz SM,Xu H",,Compositional Petri net models of advanced tasking in Ada-95,Computer Languages,1999,25,2,55-87,,,,,1999,,0096-0551,https://www.sciencedirect.com/science/article/pii/S0096055199000144;http://dx.doi.org/10.1016/S0096-0551(99)00014-4,10.1016/S0096-0551(99)00014-4,"The Ada language has been designed to support development of concurrent and distributed software. While the Ada-83 standard defined the basic mechanisms of rendezvous-based tasking, the Ada-95 standard significantly extended this capability with the introduction of several advanced tasking constructs. We present and discuss formal models of these key tasking constructs using the Petri net model. We also provide some formal evaluation of the models using one particular net-based method, invariant analysis. The constructs considered are the asynchronous transfer of control, the protected object, and the requeue statement. By modeling these advanced Ada tasking constructs with Petri nets, we obtain compositional models of the constructs that are complementary to earlier work in net-based modeling of Ada tasking, both in terms of defining precise behavior for tasking semantics, and also in terms of providing support for automated analysis of concurrent software.","Ada-95, Compositional models, Concurrency, Petri nets, Tasking",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Castellani I,Victor B",,Preface: Volume 27,Electronic Notes in Theoretical Computer Science,1999,27,,1-2,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105802907;http://dx.doi.org/10.1016/S1571-0661(05)80290-7,10.1016/S1571-0661(05)80290-7,"This volume contains the Proceedings of EXPRESS'99, the sixth International Workshop on Expressiveness in Concurrency. The workshop was held in Eindhoven, The Netherlands, on 23 August 1999, as a satellite event to the CONCUR '99 conference. The EXPRESS workshops aim at bringing together researchers interested in the relations between various formal systems, particularly in the field of Concurrency. More specifically, they focus on the comparison between programming concepts (such as concurrent, functional, imperative, logic and object-oriented programming) and between mathematical models of computation (such as process algebras, Petri nets, event structures, modal logics, rewrite systems etc.) on the basis of their relative expressive power. The EXPRESS workshops were originally held as meetings of the HCM project EXPress which was active with the same focus from January 1994 till December 1997. The first three workshops were held respectively in Amsterdam (1994, chaired by Frits Vaandrager), Tarquinia (1995, chaired by Rocco De Nicola), and Dagstuhl (1996, co-chaired by Ursula Goltz and Rocco De Nicola). The workshop in 1997, which took place in Santa Margherita Ligure and was co-chaired by Catuscia Palamidessi and Joachim Parrow, was organized as a conference with a call for papers and a significant attendance from outside the project. The 1998 workshop, co-chaired by Ilaria Castellani and Catuscia Palamidessi, was held as a satellite workshop of the CONCUR'98 conference in Nice. Like last year, EXPRESS'99 was hosted by the CONCUR conference, this year in Eindhoven. We had 16 submissions, out of which we selected 9 for inclusion in these proceedings. Two of the selected contributions are abstracts. We also had two invited talks, by Prakash Panangaden (McGill University, CA) and Roberto Amadio (Universitacute de Provence, FR). We would like to thank the authors of the submitted papers, the invited speakers, the members of the program committee and their sub-referees for their contribution to both the meeting and this volume. We also would like to thank Eindhoven Technical University for their excellent help with the local organization, and Michael Mislove for his help with the editing of the proceedings. EXPRESS'99 Programme Committe Ilaria Castellani (co-chair, INRIA Sophia-Antipolis, FR) Björn Victor (Uppsala University, SE) Luca Aceto (BRICS, DK) Eric Badouel (INRIA Rennes, FR) Steve Brookes (Carnegie Mellon University, US) Rob van Glabbeek (Stanford University, US) Astrid Kiehn (TU München, DE) Marta Kwiatkowska (University of Birmingham, UK) Ugo Montanari (Università di Pisa, IT) Uwe Nestmann (BRICS, DK) Catuscia Palamidessi (Penn State University, US) Ilaria Castellani and Björn Victor, Guest Editors",,"EXPRESS'99, the 6th International Workshop on Expressiveness in Concurrency",,,,,,,,,,,,,,,,,,,,
Journal Article,"Jordan KE,Miller LE,Moore EL,Peters TJ,Russell A",,Modeling time and topology for animation and visualization with examples on parametric geometry,Theoretical Computer Science,2008,405,1,41-49,,,,,2008,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397508004441;http://dx.doi.org/10.1016/j.tcs.2008.06.023,10.1016/j.tcs.2008.06.023,"The art of animation relies upon modeling objects that change over time. A sequence of static images is displayed to produce an illusion of motion. Even for simple cases, a careful analysis exposes that formal topological guarantees are often lacking. This absence of rigor can result in subtle, but significant, topological flaws. A new modeling approach is proposed to integrate topological rigor with a continuous model of time. Examples will be given for Bézier curves, while indicating extensions to a richer class of parametric curves and surfaces. Applications to scientific visualization for molecular modeling are discussed. Prototype animations are available for viewing over the web.","Ambient isotopy, Computational topology, Temporal aliasing, Animation, Visualization, Curve approximation","Computational Structures for Modelling Space, Time and Causality",,,,,,,,,,,,,,,,,,,,
Journal Article,Panangaden P,,The Category of Markov Kernels,Electronic Notes in Theoretical Computer Science,1999,22,,171-187,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105806024;http://dx.doi.org/10.1016/S1571-0661(05)80602-4,10.1016/S1571-0661(05)80602-4,"Markov kernels are fundamental objects in probability theory. One can define a category based on Markov kernels which has many of the formal properties of the ordinary category of relations. In the present paper we will examine the categorical properties of Markov kernels and stress the analogies and differences with the category of relations. We will show that this category has partially-additive structure and, as such, supports basic constructs like iteration. This allows one to give a probabilistic semantics for a language with while loops in the manner of Kozen. The category in question was originally defined by Giry following suggestions of Lawvere.",,"PROBMIV'98, First International Workshop on Probabilistic Methods in Verification",,,,,,,,,,,,,,,,,,,,
Journal Article,"Pyatibratov GY,Kravchenko OA,Sukhenko NA",,Synthesis of Optimal Efforts Control in Electromechanical Systems with Elastic Mechanical Links,Procedia Engineering,2017,206,,319-325,,,,,2017,,1877-7058,https://www.sciencedirect.com/science/article/pii/S1877705817351639;http://dx.doi.org/10.1016/j.proeng.2017.10.480,10.1016/j.proeng.2017.10.480,"The article presents a solution, in optimal statement, of a problem of efforts control synthesis in elastic mechanisms which comprises significant forces of friction and inertia. Different methods of optimum control of electromechanical systems were compared, and the applicability of the methods based on variations calculus was proved. The application of the integral control quality criterion allowed determining the rational structure and parameters of a force regulator in elastic elements of mechanisms, during the operation in the conditions of uncertain perturbation actions. During the synthesis of the optimum effort regulator, real limitations were considered which are attached to the control impact and the conditions assuring stability of a control system with the synthesized regulator to possible changes of parameters of a controlled object are defined. The performed studies demonstrated the effectiveness of the synthesized force regulator in electromechanical systems with elastic gears in the case of changes in perturbation actions. The proposed method for the synthesis of the optimal effort regulator in elastic mechanisms was applied during the creation of the training simulator “Exit 2”, which was designed to train astronauts to work in zero gravity conditions, and during the modification of MP100 balanced type manipulators with 100 kg load-carrying capability.","electric drive, efforts control, speed restriction","International Conference on Industrial Engineering, ICIE 2017",,,,,,,,,,,,,,,,,,,,
Journal Article,Eloff JH,,The development of a specification language for a computer security system,Computers & Security,1985,4,2,143-147,,,,,1985,,0167-4048,https://www.sciencedirect.com/science/article/pii/0167404885900197;http://dx.doi.org/10.1016/0167-4048(85)90019-7,10.1016/0167-4048(85)90019-7,"The primary goal of this paper is to define an initial step towards the definition of ‘systems grammar’ based on the notion of formal languages which can be used as a ‘tool’ in the formal representation of computer security systems. Currently all modelling done on computer security systems is written up as mathematical models. These mathematical models are usually based on the mathematics of relations amongst objects, as opposed to the model described in this paper which is based on the theory of formal languages. This paper is aimed at people who are doing research on the logical aspects of computer security. It is the first of a series of two papers. This paper will give interim results and make more specific the definition of a ‘formal language’ which suits the computer security environment. The second paper will illustrate the actual use of the defined ‘formal language’ and show how to represent the characteristics of a computer security environment by using this ‘formal language’.","Logical security, Mathematical models, Computer security, Specification languages, Formal languages",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bai S,Sun S,Bai X,Zhang Z,Tian Q",,Improving context-sensitive similarity via smooth neighborhood for object retrieval,Pattern Recognition,2018,83,,353-364,,,,,2018,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320318302115;http://dx.doi.org/10.1016/j.patcog.2018.06.001,10.1016/j.patcog.2018.06.001,"Due to the ability of capturing the geometry structure of data manifold, context-sensitive similarity has demonstrated impressive performances in the retrieval task. The key idea of context-sensitive similarity is that the similarity between two data points can be more reliably estimated with the local context of other points in the affinity graph. Therefore, neighborhood selection is a crucial factor for those algorithms, which affects the performance dramatically. In this paper, we propose a new algorithm called Smooth Neighborhood (SN) that mines the neighborhood structure to satisfy the manifold assumption. By doing so, nearby points on the underlying manifold are guaranteed to yield similar neighbors as much as possible. Moreover, SN is adjusted to tackle multiple affinity graphs by imposing a weight learning paradigm, and this is the primary difference compared with related works which are only applicable with one affinity graph. Finally, we integrate SN with Sparse Contextual Activation (SCA), a representative context-sensitive similarity proposed recently. Extensive experimental results and comparisons manifest that with the neighborhood structure generated by SN, the proposed framework can yield state-of-the-art performances on shape retrieval, image retrieval and 3D model retrieval.","Object retrieval, Context-sensitive similarity, 3D shape, Re-ranking, Rank aggregation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Foley JD,Kim WC,Gibbs CA","Bullinger HJ,Shackel B",ALGORITHMS TO TRANSFORM THE FORMAL SPECIFICATION OF A USER-COMPUTER INTERFACE,,1987,,,1001-1006,,North-Holland,Amsterdam,Human–Computer Interaction–INTERACT '87,1987,9780444703040,,https://www.sciencedirect.com/science/article/pii/B9780444703040501576;http://dx.doi.org/10.1016/B978-0-444-70304-0.50157-6,10.1016/B978-0-444-70304-0.50157-6,"Publisher Summary This chapter describes a system that allows a user interface designer to formally specify key elements of the conceptual and semantic designs of a user-computer interface. The specification uses the Interface Definition Language (IDL) to describe the interface in terms of types of objects, properties of objects, class relationships among types of objects, and actions on the objects and properties. The color of created shapes is a static attribute and hence cannot be changed after the shape has been created. There is a general object class, called shape, with two subclasses, called square and triangle. The preconditions, which are conditions that must be true before a command can be made available to the user, concern the existence of objects on which to operate. Three separate transformation sexist for factoring; the commonality is that each factored parameter generally is set by an automatically added selection action, like set-color, set-shape, or set-action. To each action with the implicit parameter in its list is added a precondition that the parameter must have a value.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Spreitzer M,Janssen B",,HTTP `Next Generation',Computer Networks,2000,33,1,593-607,,,,,2000,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128600000827;http://dx.doi.org/10.1016/S1389-1286(00)00082-7,10.1016/S1389-1286(00)00082-7,"We report on the results of the Protocol Design Group of the W3C's HTTP `Next Generation' Activity. The group produced and measured a prototype that shows that it is possible, largely using familiar engineering principles, to make simultaneous improvements in the following problem areas of HTTP/1.1: (1) the layering of other application protocols over HTTP; (2) modularity and extensibility; (3) networking performance and fairness; (4) the rigid binding between identifiers and protocol stacks; and (5) the opacity of layered traffic to firewalls. The prototype also suggests that these can be done in a way that may lead to unifying the Web with related middleware systems such as COM, CORBA, and Java RMI.","HTTP-NG, Type system, Web applications, Distributed objects, RPC",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Veres SM,Veres AG",,Learning and Adaptation of Skills in Autonomous Physical Agents,IFAC Proceedings Volumes,2008,41,2,15457-15462,,,,,2008,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667016414795;http://dx.doi.org/10.3182/20080706-5-KR-1001.02614,10.3182/20080706-5-KR-1001.02614,"A skills learning methodology is presented for autonomous physical agents. Adaptation of skills and learning is a fundamental part of the simple agent behaviours outlined. A general framework of skills learning is described that uses skill macros to define simple behaviours by agents that communicate, sense and act in the physical world. Programmed playfulness can be easily implemented in this framework that plays an important part in acquiring sophisticated skills. Reusability of results in learning algorithms is supported by ontology based classification of learning in skills. Ontologies provide references to object instances that enable modularization of software and easy interfacing of skills with learning algorithms.","Intelligent physical agents, formal methods, learning, adaptive control modelling for control",17th IFAC World Congress,,,,,,,,,,,,,,,,,,,,
Book Chapter,Fourman MP,"Lolli G,Longo G,Marcja A",Continuous Truth I Non-constructive Objects,,1984,112,,161-180,,Elsevier,,Logic Colloquium '82,1984,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08718160;http://dx.doi.org/10.1016/S0049-237X(08)71816-0,10.1016/S0049-237X(08)71816-0,"We give a general theory of the logic of potentially infinite objects, derived from a theory of meaning for statements concerning these objects. The paper has two main parts which may be read independently but are intended to complement each other. The first part is essentially philosophical. In it, we discuss the theory of meaning. We believe that even the staunchest realist must view potential infinities operationally. The second part is formal. In it, we consider the interpretation of logic in the gros topos of sheaves over the category of separable locales equipped with the open cover topology. We show that general principles of continuity, local choice and local compactness hold for these models. We conclude with a brief discussion of the philosophical significance of our formal results. They allow us to reconcile our explanation of meaning with the \equivalence thesis\""","that rsnow is white is true\""1 iff snow is white.""",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,
Journal Article,"Zuck L,Pnueli A,Fang Y,Goldberg B",,"VOC: A Translation Validator for Optimizing Compilers1 1This research was supported in part by NSF grant CCR-0098299, ONR grant N00014-99-1-0131, and the Minerva Center for Verification of Reactive Systems, a gift from Intel, a grant from the German - Israel Foundation for Scientific Research and Development",Electronic Notes in Theoretical Computer Science,2002,65,2,2-18,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104803931;http://dx.doi.org/10.1016/S1571-0661(04)80393-1,10.1016/S1571-0661(04)80393-1,"There is a growing awareness, both in industry and academia, of the crucial role of formally proving the correctness of safety-critical components of systems. Most formal verification methods verify the correctness of a high-level representation of the system against a given specification. However, if one wishes to infer from such a verification the correctness of the code which runs on the actual target architecture, it is essential to prove that the high-level representation is correctly implemented at the lower level. That is, it is essential to verify the the correctness of the translation from the high-level source-code representation to the object code, a translation which is typically performed by a compiler (or a code generator in case the source is a specification rather than a programming language). Formally verifying a full-fledged optimizing compiler, as one would verify any other large program, is not feasible due to its size, ongoing evolution and modification, and, possibly, proprietary considerations. The translation validation method used in this paper is a novel approach that offers an alternative to the verification of translators in general and compilers in particular. According to the translation validation approach, rather than verifying the compiler itself, one constructs a validation tool which, after every run of the compiler, formally confirms that the target code produced on that run is a correct translation of the source program The paper presents VOC–a methodology for translation validation of optimizing compilers. We distinguish between structure preserving optimizations, for which we establish a simulation relation between the source and target code based on computational induction, and structure modifying optimizations, for which we develop specialized “meta-rules”. The paper also describes VOC64—a prototype translation validator that automatically produces verification conditions for the global optimizations of the SGI Pro-64 compiler.",,"COCV'02, Compiler Optimization Meets Compiler Verification (Satellite Event of ETAPS 2002)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Bertrand Y,Dufourd JF",,Algebraic Specification of a 3D-Modeler Based on Hypermaps,CVGIP: Graphical Models and Image Processing,1994,56,1,29-60,,,,,1994,,1049-9652,https://www.sciencedirect.com/science/article/pii/S1049965284710054;http://dx.doi.org/10.1006/cgip.1994.1005,10.1006/cgip.1994.1005,"We present the algebraic specification of a prototype interactive geometric modeler for 3D objects, whose topologies are represented by 3-dimensional generalized maps. After a reminder of some topological models, particularly maps and extensions, we begin with the more general frame of n-dimensional hypermaps. We specify algebraically a hierarchy of operations on hypermaps and generalized maps, which are embedded in a 3-dimensional Euclidean space. We make precise the modeling area and give the main functionalities of the modeler. We detail high-level operations on 3D objects, and some technical features of this software. Some constructions are explained using pictures. We show that hypermaps and algebraic specification constitute an efficient formal frame for developing large pieces of software in the area of boundary representation.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Stroyan KD,Stroyan KD,CHAPTER 14 - Geometric Optimization Projects,,1993,,,307-310,,Academic Press,,Calculus Using Mathematica,1993,9780126729757,,https://www.sciencedirect.com/science/article/pii/B978012672975750031X;http://dx.doi.org/10.1016/B978-0-12-672975-7.50031-X,10.1016/B978-0-12-672975-7.50031-X,"Publisher Summary This chapter discusses geometric optimization projects. The distance between lines, between curves, between a curve and a surface, etc., is a multidimensional minimization problem. The distance means the shortest distance as the points vary over both objects. Most calculus books do not treat this topic because the solution of the equations resulting in the critical point step is too hard to do by hand. Mathematica can help solve these deep geometrical problems.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bourne RA,,Explaining default intuitions using maximum entropy,Journal of Applied Logic,2003,1,3,255-271,,,,,2003,,1570-8683,https://www.sciencedirect.com/science/article/pii/S1570868303000156;http://dx.doi.org/10.1016/S1570-8683(03)00015-6,10.1016/S1570-8683(03)00015-6,"While research into default reasoning is extensive and many default intuitions are commonly held, no one system has yet captured all these intuitions nor given a formal account to motivate them. This paper argues that the extended maximum entropy approach which incorporates variable strength defaults provides a benchmark for default reasoning that is not only objectively motivated but also satisfies all the accepted default intuitions. It is shown that the behaviour of the approach coincides with a wide range of default intuitions taken from examples in the literature, and can be used to explain why some examples have led to confusion. Moreover, analysing the solutions produced by the maximum entropy approach enables clearer differentiation between the default knowledge they contain and the default inferences required of the reasoning system. This suggests that the maximum entropy approach can be used as a benchmark both for eliciting default knowledge when building a knowledge base and, by comparison, for clarifying the underlying biases of other default reasoning systems.","Maximum entropy, Default reasoning, Conflict resolution, Exceptional inheritance",Combining Probability and Logic,,,,,,,,,,,,,,,,,,,,
Journal Article,Lalanne JC,,Polyominos parallélogrammes á franges et fonctions de Bessel,Discrete Mathematics,1993,115,1,217-230,,,,,1993,,0012-365X,https://www.sciencedirect.com/science/article/pii/0012365X9390491B;http://dx.doi.org/10.1016/0012-365X(93)90491-B,10.1016/0012-365X(93)90491-B,"The object of this paper is to generalize some recent results about enumeration of parallelogram polyominos using Bessel functions. We first define the concept of parallelogram polyomino with border. Then we prove that the generating function for these objects, by area and number of columns, has a simple expression in terms of q-Bessel functions. Using q-calculus, we give some properties of these q-analogs. Résumé L'object de cet article est une généralisation de résultats récents sur l'énumération des polyominos parallélogrammes, utilisant les fonctions de Bessel. Pour cela, nous définissons d'abord la notion de polyomino parallélogramme à franges. Puis nous montrons que la fonction génératrice de ces objets selon l'aire et le nombre de colonnes s'exprime à l'aide de q-analogues de fonctions de Bessel. Nous établissons d'autre part quelques propriétés de ces q-analogues liés au q-calcul.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gutierrez A,Jimenez MJ,Monaghan D,O’Connor NE",,Topological evaluation of volume reconstructions by voxel carving,Computer Vision and Image Understanding,2014,121,,27-35,,,,,2014,,1077-3142,https://www.sciencedirect.com/science/article/pii/S1077314213002233;http://dx.doi.org/10.1016/j.cviu.2013.11.005,10.1016/j.cviu.2013.11.005,"Space or voxel carving (Broadhurst et al., 2001; Culbertson et al., 1999; Kutulakos and Seitz, 2000; Seitz et al., 2006) is a technique for creating a three-dimensional reconstruction of an object from a series of two-dimensional images captured from cameras placed around the object at different viewing angles. However, little work has been done to date on evaluating the quality of space carving results. This paper extends the work reported in (Gutierrez et al., 2012), where application of persistent homology was initially proposed as a tool for providing a topological analysis of the carving process along the sequence of 3D reconstructions with increasing number of cameras. We give now a more extensive treatment by: (1) developing the formal framework by which persistent homology can be applied in this context; (2) computing persistent homology of the 3D reconstructions of 66 new frames, including different poses, resolutions and camera orders; (3) studying what information about stability, topological correctness and influence of the camera orders in the carving performance can be drawn from the computed barcodes.","Voxel carving, Volume reconstruction, Persistent homology, Barcodes, Evaluation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cho S,Kang JY,Yasar AU,Knapen L,Bellemans T,Janssens D,Wets G,Hwang CS",,An Activity-based Carpooling Microsimulation Using Ontology,Procedia Computer Science,2013,19,,48-55,,,,,2013,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050913006200;http://dx.doi.org/10.1016/j.procs.2013.06.012,10.1016/j.procs.2013.06.012,"This study aims to show an ability of Ontology, which is a formal explicit description of concepts in a domain of interest, in an activity-based microsimulation. Thus, an agent-based carpooling application using ontology techniques is presented as a case study with a focus on three functions of the Ontology. First, Ontology facilitates integrating between heterogeneous databases by defining the relationship between their concepts. Second, Ontology verifies the compatibility and consistency between the different angles to combine varied models in a common structure by providing shared knowledge between different domains modelling with the definition of objects and concepts. Lastly, Ontology is useful for modelling agent communication by means of making explicit the parsed message between agents with the shared knowledge. This paper introduces related studies and basic knowledge about using methodologies, and supports an example of using Ontology in an agent-based carpooling simulation.","Ontology, Activity-based approach, Transportation, Agent-based model, Carpooling","The 4th International Conference on Ambient Systems, Networks and Technologies (ANT 2013), the 3rd International Conference on Sustainable Energy Information Technology (SEIT-2013)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Fan M,Han Q,Liu S,Ren S,Quan G,Ren S",,Enhanced fixed-priority real-time scheduling on multi-core platforms by exploiting task period relationship,Journal of Systems and Software,2015,99,,85-96,,,,,2015,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121214001976;http://dx.doi.org/10.1016/j.jss.2014.09.010,10.1016/j.jss.2014.09.010,"One common approach for multi-core partitioned scheduling problem is to transform this problem into a traditional bin-packing problem, with the utilization of a task being the “size” of the object and the utilization bound of a processing core being the “capacity” of the bin. However, this approach ignores the fact that some implicit relations among tasks may significantly affect the feasibility of the tasks allocated to each local core. In this paper, we study the problem of partitioned scheduling of periodic real-time tasks on multi-core platforms under the Rate Monotonic Scheduling (RMS) policy. We present two effective and efficient partitioned scheduling algorithms, i.e. PSER and HAPS, by exploiting the fact that the utilization bound of a task set increases as task periods are closer to harmonic on a single-core platform. We formally prove the schedulability of our partitioned scheduling algorithms. Our extensive experimental results demonstrate that the proposed algorithms can significantly improve the scheduling performance compared with the existing work.","Partitioned scheduling, RMS, Harmonic",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Arbab F,Wexler J,RSC: A CALCULUS OF SHAPES,,1984,,,244-251,,Butterworth-Heinemann,,CAD84,1984,9780408014403,,https://www.sciencedirect.com/science/article/pii/B9780408014403500331;http://dx.doi.org/10.1016/B978-0-408-01440-3.50033-1,10.1016/B978-0-408-01440-3.50033-1,"Constructive Solid Geometry (CSG) is a mathematical modeling scheme for representation of physical objects [12]. In recent years, CSG has become popular as an underlying logical model in Computer Aided Design/Computer Aided Manufacturing (CAD/CAM) systems for definition of mechanical parts [3, 4, 6, 7, 8, 10, 11]. Fundamental simplicity of CSG together with its sound mathematical basis are reasons for this popularity. This paper discusses a number of problems in CSG's modeling of solid objects. In particular, treatment of assemblies in CSG is shown to be inconsistent. As an alternative, a new coherent mathematical scheme, called Realizable Shape Calculus (RSC), is presented. RSC is a modeling formalism in the same spirit as CSG, for consistent representation of physical objects — assemblies as well as connected pieces.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Skuce D,Sowa JF,19 - A FRAME-LIKE KNOWLEDGE REPRESENTATION INTEGRATING ABSTRACT DATA TYPES AND LOGIC,,1991,,,543-563,,Morgan Kaufmann,,Principles of Semantic Networks,1991,,1046-9567,https://www.sciencedirect.com/science/article/pii/B9781483207711500278;http://dx.doi.org/10.1016/B978-1-4832-0771-1.50027-8,10.1016/B978-1-4832-0771-1.50027-8,"This paper describes a very general, formal knowledge representation based on algebraic ideas from abstract data types, i.e., on ideas originating outside the AI literature in research on foundations for programming and specification languages. Nevertheless, the representation incorporates practically necessary features found in inheritance systems such as AI frame systems used for natural language understanding, while offering a precise algebraic semantics. We term the approach conceptually oriented description. The contribution of this chapter is (1) to reformulate and simplify these ideas for AI applications, incorporating the useful features found in many practical AI inheritance systems, while retaining the theoretical foundation, and (2) to show how the approach is valuable in natural language semantics applications. This chapter will use some difficult examples motivated by natural language applications, but the formalism is very general and could be used for other applications, such as software requirements specification. The approach is based mainly on ideas from the language LOTOS, intended for the formal specification of concurrent systems, and also on similar work by Goguen and Meseguer [1987] on algebraically based functional specification. LOTOS adds to basic ADT concepts additional concepts for defining the notions like state, event, and temporal relationships including causality and synchronization. The main components of a software system for creating and debugging conceptual definitions using the formalism have been implemented and are briefly mentioned.",,,The Morgan Kaufmann Series in Representation and Reasoning,,,,,,,,,,,,,,,,,,,
Book Chapter,Gradshtein IS,Gradshtein IS,CHAPTER II - THE ELEMENTS OF MATHEMATICAL LOGIC,,1963,,,79-140,,Pergamon,,Direct and Converse Theorems,1963,9780080098326,,https://www.sciencedirect.com/science/article/pii/B9780080098326500105;http://dx.doi.org/10.1016/B978-0-08-009832-6.50010-5,10.1016/B978-0-08-009832-6.50010-5,"Publisher Summary This chapter discusses the elements of mathematical logic. Mathematical logic developed as a result of the application of mathematical methods to the problems of formal logic and as a discipline serving the ends of the foundations of mathematics. Mathematical logic has received diverse technical applications. Contemporary mathematical logic is connected with automation, with machine mathematics and problems of automatic translation from one language to another, with information theory, and with cybernetics. The methods of mathematical logic find wide applications in the theory of electrical networks with switching action. In algebra, numbers—the objects of the study of arithmetic—are denoted by letters. The object of that part of mathematical logic that is known as the propositional calculus is the study of propositions. The propositional calculus is the most elementary part of mathematical logic. Mathematical logic distinguishes carefully between the different ways of using variables and fixes them with the aid of a special symbolism.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Clark JM,Cordero F,Cottrill J,Czarnocha B,DeVries DJ,St. John D,Tolias G,Vidakovic D",,Constructing a schema: The case of the chain rule?,The Journal of Mathematical Behavior,1997,16,4,345-364,,,,,1997,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312397900122;http://dx.doi.org/10.1016/S0732-3123(97)90012-2,10.1016/S0732-3123(97)90012-2,"This paper is part of a series of studies by the Research in Undergraduate Mathematics Education Community (RUMEC), concerning the nature and development of college students' mathematical knowledge. This project began as an attempt to explore calculus students' understanding of the chain rule and its applications. Based on the initial description of how the chain rule concept may be learned (genetic decomposition) an attempt to interpret the data using the Action-Process-Object theoretical framework is made. The insufficiency of this alone led to an extension of the Action-Process-Object-Schema epistemological framework (APOS) which includes a theory of schema development based on ideas of Piaget and Garcia. The Piagetian Triad is suggested as a mechanism for describing schema development in general, and the chain rule is used as an example. The Triad of the Intra, Inter and Trans stages of schema development provides the structure for interpreting the students' understanding of the chain rule and classifying their responses to interview questions about the chain rule. The results of this data analysis allowed for a proposed revised epistemological analysis of the chain rule. Finally, several suggestions and questions for future study are presented.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Barendregt HP,Chapter 5 - Models,,1984,103,,86-128,,Elsevier,,The Lambda Calculus,1984,,0049-237X,https://www.sciencedirect.com/science/article/pii/B9780444875082500137;http://dx.doi.org/10.1016/B978-0-444-87508-2.50013-7,10.1016/B978-0-444-87508-2.50013-7,"Publisher Summary This chapter describes the models and combinatorial algebra. In the type free λ-calculus, the objects serve both as arguments and as functions to be applied to these arguments. One would like that semantics for the λ-calculus consists of a domain D such that its function space DD is isomorphic to D. Besides the first-order definition of λ-algebras and λ-models, there is a syntactical and also a categorical description of these classes. The syntactical description is convenient when calculating the interpretation of terms in a model. The categorical description of λ-algebras is rather natural and unifies the two concepts. It consists of a Cartesian closed category C together with a so-called reflexive object. The typed λ-calculus can represent only a proper subset of the recursive functions, whereas the type free theory represents them all. An applicative structure is combinatory complete if it can be expanded to combinatory algebra.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Lennon JA,Maurer H",,"MUSLI: A hypermedia interface for dynamic, interactive, and symbolic communication",Journal of Network and Computer Applications,2001,24,4,273-291,,,,,2001,,1084-8045,https://www.sciencedirect.com/science/article/pii/S1084804501901377;http://dx.doi.org/10.1006/jnca.2001.0137,10.1006/jnca.2001.0137,"This article proposes a hypermedia interface for writing and reading documents that include dynamic, interactive, abstract objects. Highly active and interactive documents supersede the passive ones we usually find in hypermedia systems. Although the work has its background in visual communication and story telling, it lends itself to any kind of domain modelling, shorthand systems, process descriptions, or formal representations of multimedia aspects of knowledge. It is a framework for dynamic abstract languages, rather than a single language as such. We present one specific example of such an interface: MUSLI (MUlti-Sensory Language Interface) and show how it may be used for interactive story telling.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Lehmann F,,Semantic networks,Computers & Mathematics with Applications,1992,23,2,1-50,,,,,1992,,0898-1221,https://www.sciencedirect.com/science/article/pii/0898122192901355;http://dx.doi.org/10.1016/0898-1221(92)90135-5,10.1016/0898-1221(92)90135-5,"A semantic network is a graph of the structure of meaning. This article introduces semantic network systems and their importance in Artificial Intelligence, followed by I. the early background; II. a summary of the basic ideas and issues including link types, frame systems, case relations, link valence, abstraction, inheritance hierarchies and logic extensions; and III. a survey of ‘world-structuring’ systems including ontologies, causal link models, continuous models, relevance, formal dictionaries, semantic primitives and intersecting inference hierarchies. Speed and practical implementation are briefly discussed. The conclusion argues for a synthesis of relational graph theory, graph-grammar theory and order theory based on semantic primitives and multiple intersecting inference hierarchies.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"van Bommel P,ter Hofstede AH,van der Weide TP",,Semantics and verification of object-role models,Information Systems,1991,16,5,471-495,,,,,1991,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799190037A;http://dx.doi.org/10.1016/0306-4379(91)90037-A,10.1016/0306-4379(91)90037-A,"In this paper we formalize data models that are based on the concept of predicator, the combination of an object type and a role. A very simple model, the Predicator Model, is introduced in a rigid formal way. We introduce the concept of population as an instantiation of an information structure. A primitive manipulation language is defined in the style of relational algebra. Well-known types of constraints are defined in terms of the algebra introduced, as restrictions on populations. They are given more expressive power than is usually the case. Constraints are of central importance for identification purposes. Weak identification ensures identifiability of objects within a specific population, while structural identification ensures identifiability of objects within every population. Different levels of constraint inconsistency are defined and it is shown that the verification of two important levels is NP-complete.","Information systems, data modelling, relational algebra, constraints, identification, verification, NIAM",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kim DH,Ryu KH,Kim HS",,A spatiotemporal database model and query language,Journal of Systems and Software,2000,55,2,129-149,,,,,2000,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121200000662;http://dx.doi.org/10.1016/S0164-1212(00)00066-2,10.1016/S0164-1212(00)00066-2,"Conventional spatial databases support efficiently a spatial management for objects. However, they manage only those that are valid at current time. Owing to this property, whenever a new value is inserted into databases, the old one should be deleted. So, it is very difficult for time varying spatial information to manage efficient historical information. To solve this problem, there is a rapid increase of interest for spatiotemporal databases. Spatiotemporal databases support historical information as well as spatial management at the same time, so that they can be used in various application areas such as geographic information system, urban plan system, and car navigation system, and so on. In this paper, we suggest a spatiotemporal data model that supports a bitemporal concept for spatial objects, and design a spatiotemporal database query language, entitled as STQL as well. When it is compared with the results of previous researches, it is the first spatiotemporal query language that supports temporal concept and spatial expression as well.","Spatiotemporal databases, Data model, Query language, Formal semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li X,Tang Z,Sun J",,The implementation of set operation for regularized geometric object,Computers & Graphics,1988,12,3,309-318,,,,,1988,,0097-8493,https://www.sciencedirect.com/science/article/pii/0097849388900507;http://dx.doi.org/10.1016/0097-8493(88)90050-7,10.1016/0097-8493(88)90050-7,"Geometric modelling, as a fundamental new branch of computer-aided design technology, has received much attention. The basic problem in geometric modelling—the regularized set operation of regularized geometric objects—is discussed in this paper. On the basis of the definition of a regularized geometric object, it is shown that a regularized geometric object may be represented by its boundary. A hierarchic boundary representation scheme and a formal description of regularized set operators are then given. Emphasis is placed on the implementation of regularized set operators, including intersection of bounded surfaces, formation and classification of loops, formation and classification of bounded surfaces, and formation of new object boundaries.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Watanabe H,,The object-predicate reciprocity and weak classification,Measurement,1997,21,1,35-45,,,,,1997,,0263-2241,https://www.sciencedirect.com/science/article/pii/S0263224197000420;http://dx.doi.org/10.1016/S0263-2241(97)00042-0,10.1016/S0263-2241(97)00042-0,"Measurement scales are for physical, non-human objects by nature, while there are increasingly many occasions where we need more than numbers to express what we want, feel and judge. One possible way to meet this new situation is to recapitulate the role of the nominal scale and to take advantage of classification of the objects by some predicates, or attributes, as an additional, more basic approach to the numerical scaling practice. Within a formal framework we examine the basic nature of classification procedure. Starting from the notion of indiscernibility, we modify it so that it satisfies a reciprocal relationship between the objects and the predicates, and introduce a new concept called weak indiscernibility, which defines a weak classification. The basic properties of this new classification are carefully analyzed in comparison with those of ordinary classification. A brief discussion is undertaken on the application of the theory to the evaluation problem, and a procedure for determining whether a set of criteria is reducible or not is proposed. Such a recapitulation of the classification procedure will help us to look at the scaling practice more carefully so that human judgement and human feeling may be given a more reasonable mathematical structure for measurement and evaluation.","Classification, Nominal scale, Measurement theory, Pattern recognition, Information theory, Knowledge representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gaba GS,Kumar G,Kim TH,Monga H,Kumar P",,Secure Device-to-Device communications for 5G enabled Internet of Things applications,Computer Communications,2021,169,,114-128,,,,,2021,,0140-3664,https://www.sciencedirect.com/science/article/pii/S0140366421000311;http://dx.doi.org/10.1016/j.comcom.2021.01.010,10.1016/j.comcom.2021.01.010,"Smart cities are developed to optimize operations across the city such as waste and traffic management, water supply management, criminal tracking, and pollution monitoring, etc. Smart cities are formed by the interconnection of various Internet of Things (IoT) devices for collecting the data from objects and humans to perform necessary actions. But the challenge lies in the exchange of enormous information in real-time to drive smart city applications. Therefore, smart city applications make use of Device-to-Device (D2D) communications which provides higher bandwidth and lower latency in message exchanges. D2D communications do not need any infrastructure for communication and hence are cost and time effective. However, this advantage becomes a threat as no third party is involved to verify the authenticity of the devices before exchange of real information. Consequently, a reliable authentication mechanism is required to address the security issues in WiFi (wireless fidelity) Direct communication. In this paper, we propose a secure and lightweight mutual authentication and key agreement protocol for WiFi Direct. The principle of the protocol is based upon a commit/open pair and Diffie Hellman key exchange algorithm. It is observed from the simulations that the proposed protocol successfully authenticates the D2D devices in the WiFi Direct environment. Investigation through formal security analysis revealed the strong resistivity of the proposed protocol against the prominent attacks in the WiFi Direct environment. The comparative analysis demonstrates the reliability of the suggested protocol over the traditional one. The proposed protocol eliminates the occurrence of the denial of service (DoS) and man-in-the-middle (MITM) attacks in the discovery and key agreement phase, respectively. The proposed protocol can be easily integrated into the devices enabled with WiFi Direct and can offer a wide security package.","Wi-Fi Direct, Device-to-Device communications, 5G, Internet of Things, Smart cities",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sabri KE,Hiary H",,Algebraic Model for Handling Access Control Policies,Procedia Computer Science,2016,83,,653-657,,,,,2016,,1877-0509,https://www.sciencedirect.com/science/article/pii/S1877050916301764;http://dx.doi.org/10.1016/j.procs.2016.04.146,10.1016/j.procs.2016.04.146,"Confidentiality of information is an important aspect that developers should take into consideration when building systems. One way to achieve confidentiality is to define access control policies that give authorization rules for allowing users to access resources. In large organizations, managing policies becomes a complex task. Usually, based on the defined policies, developers would need to manipulate policies such as composing them and enforcing predefined security constraints. In this paper, we present an algebraic model for specifying access control policies. It consists of a few number of operators which gives simplicity in specifying policies. The proposed model enables us to specify policies and enforce predefined security constraints. Furthermore, the model allows us to combine policies and analyze their effect on predefined constraints. Furthermore, it enables comparing the sensitivity of objects (e.g. files) and authority of subjects (e.g. users).","Information Security, Access Control Policies, Formal Specification, Algebraic Analysis","The 7th International Conference on Ambient Systems, Networks and Technologies (ANT 2016) / The 6th International Conference on Sustainable Energy Information Technology (SEIT-2016) / Affiliated Workshops",,,,,,,,,,,,,,,,,,,,
Journal Article,Hardin T,,Confluence results for the pure strong categorical logic CCL. λ-calculi as subsystems of CCL,Theoretical Computer Science,1989,65,3,291-342,,,,,1989,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397589901059;http://dx.doi.org/10.1016/0304-3975(89)90105-9,10.1016/0304-3975(89)90105-9,"The Strong Categorical Combinatory Logic (CCL, CCLβηSP), developed by Curien (1986) is, when typed and augmented with a rule defining a terminal object, a presentation of Cartesian Closed Categories. Furthermore, it is equationally equivalent to the Lambda-calculus with explicit couples and Surjective Pairing. Here we study the confluence propertied of (CCL, CCLβηSP) and of several of its subsystems, and the relationship between untyped Lambda-calculi and (CCL, CCLβηSP) as rewriting systems. We prove that there exists a subset D of CCL, and a subsystem SLβ of CCLβηSP confluent on D, a very simple isomorphism between Λ, the classical Lambda-calculus, and a subset SDλ of D, which is extended between β-derivations of Λ and a class of derivations of SLβ. Substitution, which is a one-step operation belonging to the metalanguage of Λ, is now described by rewritings with SLβ and calculations between several substitutions launched at the same time may be performed by SLβ. This point is a real increase in the calculation capacities of Lambda-calculus (same results for D). The same result holds for the Lambda-calculus with couples and projection rules (without Surjective Pairing). The locally confluent subsystem CCLβSP (that is SLβ + (SP)) is not confluent. This result is obtained by firstly designing a new counter-example (different from J.W. Klop's one) for confluence of the Lambda-calculus with couples and Surjective Pairing and then translating it into CCL. However, CCLβSP is shown to be confluent on the set derived from SDλ. These results cannot be obtained with classical methods of confluence and we designed a new method called Interpretation Method based on this trick: a given relation R is confluent on a set X if and only if a relation E(R) induced by R on a set of regularized terms E(X) is confluent.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Gumm HP,,"Preface: Volume 82, Issue 1",Electronic Notes in Theoretical Computer Science,2003,82,1,341-342,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105806486;http://dx.doi.org/10.1016/S1571-0661(05)80648-6,10.1016/S1571-0661(05)80648-6,"This volume contains the Proceedings of the Sixth Workshop on Coalgebraic Methods in Computer Science (CMCS'03). The workshop was held in Warsaw, Poland on April 5 and 6, 2003, as a satellite event to the European Joint Conference on Theory and Practice of Software (ETAPS'03). The aim of the CMCS workshop series is to bring together researchers with a common interest in the theory of coalgebras and its applications. Previous workshops have been organized in Lisbon (1998), Amsterdam (1999), Berlin (2000), Genoa (2001), and Grenoble (2002). Coalgebras have been found extremely useful for capturing state-based dynamical systems, such as transition systems, automata, process calculi, and class-based systems. The theory of coalgebras has developed into a field of its own interest, presenting a deep mathematical foundation, a growing domain of applications and interactions with various other fields, such as reactive and interactive systems theory, object oriented and concurrent programming, formal system specification, modal logic, dynamical systems, control systems, category theory, algebra, analysis, etc. The program committee of CMCS'03 consisted of Jiri AdámekTechnical University of Braunschweig, GermanyCorina CîrsteaOxford University, UKH. Peter GummUniversity of Marburg, Germany, (chair)Bart JacobsUniversity of Nijmwegen, The NetherlandsAlexander KurzUniversity of Leicester, UKMarina LenisaUniversity of Udine, ItalyUgo MontanariUniversity of Pisa, ItalyLarry MossIndiana University, Bloomington, USAAtaru T. NakagawaSoftware Research Associates, Tokyo, JapanHorst ReichelTechnical University Dresden, GermanyGrigore RosuUniversity of Illinois, Urbana, USAJan RuttenCWI, Amsterdam, The NetherlandsJames WorrellTulane University, New Orleans, USA The papers were refereed by the program committee and by several outside referees, whose help is gratefully acknowledged. The invited speakers at the conference were Zoltán ÉsikUniversity of Szeged, HungaryVaughan PrattStanford University, USA These proceedings are being published as volume 82.1 in the series Electronic Notes in Theoretical Computer Science (ENTCS). Printed copies, containing preliminary versions of the articles in these proceedings were distributed to the participants of the conference. The proceedings of the previous CMCS workshops appeared as ENTCS Volumes 11, 19, 33, 44.1, and 65.1. We are grateful to ENTCS for their continuing support, in particular to Mike Mislove, Managing Editor of the ENTCS series. For the sixth time, CMCS has been organized as satellite event to ETAPS. We are very grateful to the ETAPS organizers, especially to Damian Niwinski, for taking care of all the local organization and for accommodating all our special requests. Marburg, May 27, 2003H. Peter Gumm",,"CMCS'03, Coalgebraic Methods in Computer Science (Satellite Event for ETAPS 2003)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Agha G,Meseguer J,Sen K",,PMaude: Rewrite-based Specification Language for Probabilistic Object Systems,Electronic Notes in Theoretical Computer Science,2006,153,2,213-239,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106002672;http://dx.doi.org/10.1016/j.entcs.2005.10.040,10.1016/j.entcs.2005.10.040,"We introduce a rewrite-based specification language for modelling probabilistic concurrent and distributed systems. The language, based on PMaude, has both a rigorous formal basis and the characteristics of a high-level rule-based programming language. Furthermore, we provide tool support for performing discrete-event simulations of models written in PMaude, and for statistically analyzing various quantitative aspects of such models based on the samples that are generated through discrete-event simulation. Because distributed and concurrent communication protocols can be modelled using actors (concurrent objects with asynchronous message passing), we provide an actor PMaude module. The module aids writing specifications in a probabilistic actor formalism. This allows us to easily write specifications that are purely probabilistic – and not just non-deterministic. The absence of such (un-quantified) non-determinism in a probabilistic system is necessary for a form of statistical analysis that we also discuss. Specifically, we introduce a query language called Quantitative Temporal Expressions (or QuaTEx in short), to query various quantitative aspects of a probabilistic model. We also describe a statistical technique to evaluate QuaTEx expressions for a probabilistic model.","Specification language, , actors, probabilistic specification, non-deterministic specification, query language,",Proceedings of the Third Workshop on Quantitative Aspects of Programming Languages (QAPL 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Guo Y,Şengür A,Ye J",,A novel image thresholding algorithm based on neutrosophic similarity score,Measurement,2014,58,,175-186,,,,,2014,,0263-2241,https://www.sciencedirect.com/science/article/pii/S0263224114003583;http://dx.doi.org/10.1016/j.measurement.2014.08.039,10.1016/j.measurement.2014.08.039,"Image thresholding is an important field in image processing. It has been employed to segment the images and extract objects. A variety of algorithms have been proposed in this field. However, these methods perform well on the images without noise, and their results on the noisy images are not good. Neutrosophic set (NS) is a new general formal framework to study the neutralities’ origin, nature, and scope. It has an inherent ability to handle the indeterminant information. Noise is one kind of indeterminant information on images. Therefore, NS has been successfully applied into image processing and computer vision research fields. This paper proposed a novel algorithm based on neutrosophic similarity score to perform thresholding on image. We utilize the neutrosophic set in image processing field and define a new concept for image thresholding. At first, an image is represented in the neutrosophic set domain via three membership subsets T, I and F. Then, a neutrosophic similarity score (NSS) is defined and employed to measure the degree to the ideal object. Finally, an optimized value is selected on the NSS to complete the image thresholding task. Experiments have been conducted on a variety of artificial and real images. Several measurements are used to evaluate the proposed method’s performance. The experimental results demonstrate that the proposed method selects the threshold values effectively and properly. It can process both images without noise and noisy images having different levels of noises well. It will be helpful to applications in image processing and computer vision.","Image thresholding, Image segmentation, Fuzzy set, Neutrosophic set, Similarity score",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dai HK,Whang KY,Su HC",,Locality of Corner Transformation for Multidimensional Spatial Access Methods,Electronic Notes in Theoretical Computer Science,2008,212,,133-148,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108002739;http://dx.doi.org/10.1016/j.entcs.2008.04.058,10.1016/j.entcs.2008.04.058,"The geometric structural complexity of spatial objects does not render an intuitive distance metric on the data space that measures spatial proximity. However, such a metric provides a formal basis for analytical work in transformation-based multidimensional spatial access methods, including locality preservation of the underlying transformation and distance-based spatial queries. We study the Hausdorff distance metric on the space of multidimensional polytopes, and prove a tight relationship between the metric on the original space of k-dimensional hyperrectangles and the standard p-normed metric on the transform space of 2k-dimensional points under the corner transformation, which justifies the effectiveness of the transformation-based technique in preserving spatial locality.","databases, multidimensional spatial access methods, corner transformation, locality","Proceedings of the First International Conference on Foundations of Informatics, Computing and Software (FICS 2008)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Fileto R,May C,Renso C,Pelekis N,Klein D,Theodoridis Y",,The Baquara2 knowledge-based framework for semantic enrichment and analysis of movement data,Data & Knowledge Engineering,2015,98,,104-122,,,,,2015,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X15000555;http://dx.doi.org/10.1016/j.datak.2015.07.010,10.1016/j.datak.2015.07.010,"The analysis of movements frequently requires more than just spatio-temporal data. Thus, despite recent progresses in trajectory handling, there is still a gap between movement data and formal semantics. This gap hinders movement analyses benefiting from available knowledge, with well-defined and widely agreed semantics. This article describes the Baquara2 framework to help narrow this gap by exploiting knowledge bases to semantically enrich and analyze movement data. It provides an ontological model for structuring and abstracting movement data in a multilevel hierarchy of progressively detailed movement segments that generalize concepts such as trajectories, stops, and moves. Baquara2 also includes a general customizable process to annotate movement data with concepts and objects described in ontologies and Linked Open Data (LOD) collections. The resulting semantic annotations enable queries for movement analyses based on application and domain specific knowledge. The proposed framework has been used in experiments to semantically enrich movement data collected from social media with geo-referenced LOD. The obtained results enable powerful queries that illustrate Baquara2 capabilities.","Trajectories of moving objects, Social media, Ontologies, Linked open data, Semantic enrichment, Movement data analysis",Research on conceptual modeling,,,,,,,,,,,,,,,,,,,,
Journal Article,Kumpera A,,Automorphisms of flag systems,Journal of Differential Equations,2019,266,2,911-935,,,,,2019,,0022-0396,https://www.sciencedirect.com/science/article/pii/S0022039618304212;http://dx.doi.org/10.1016/j.jde.2018.07.057,10.1016/j.jde.2018.07.057,"We first discuss the problems in the theory of ordinary differential equations that gave rise to the concept of a flag system and illustrate these with the Cartan criterion for Monge equations (1st order) as well as the Cartan statement concerning the local equivalence of Monge–Ampère type equations (2nd order). Next, we describe a prolongation functor operating on the infinitesimal symmetries (automorphisms) of the Darboux flag and extending these, isomorphically, to all the symmetries of any other flag. Hence, flag systems cannot be distinguished by their symmetry algebras and the local classification of these objects is approached by considering higher order isotropies of these algebras as well as the groupoids of k-th order formal equivalences since the differential equations defining the latter provide precious information for the application of flag systems to differential equations (e.g., Cartan's criterion for non-linear Monge equations). In examining the behavior of the isotropy algebras, that can either diminish or remain the same, when passing from a derived system Sν to the consecutive system Sν+1, we obtain a full set of numerical invariants for the elementary flag systems that moreover specifies the local models.","Flag systems, Models, Infinitesimal automorphisms, Isotropy, Darboux prolongations, order equivalence groupoids",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bandelt HJ,Chepoi V,Dress A,Koolen J",,Combinatorics of lopsided sets,European Journal of Combinatorics,2006,27,5,669-689,,,,,2006,,0195-6698,https://www.sciencedirect.com/science/article/pii/S0195669805000491;http://dx.doi.org/10.1016/j.ejc.2005.03.001,10.1016/j.ejc.2005.03.001,"We develop a theory of isometric subgraphs of hypercubes for which a certain inheritance of isometry plays a crucial role. It is well known that median graphs and closely related graphs embedded in hypercubes bear geometric features that involve realizations by solid cubical complexes or are expressed by Euler-type counting formulae for cubical faces. Such properties can also be established for antimatroids, and in fact, a straightforward generalization (“conditional antimatroid”) captures this concept as well as median convexity. The key ingredient for the cube counting formulae that work in conditional antimatroids is a simple cube projection property, which, when letting sets be encoded by sign vectors, is seen to be invariant under sign switches and guarantees linear independence of the corresponding sign vectors. It then turns out that a surprisingly elementary calculus of projection and lifting gives rise to a plethora of equivalent characterizations of set systems bearing these properties, which are not necessarily closed under intersections (and thus are more general than conditional antimatroids). One of these descriptions identifies these particular set systems alias sets of sign vectors as the lopsided sets originally introduced by Lawrence in order to investigate the subgraphs of the n-cube that encode the intersection pattern of a given convex set K with the closed orthants of the n-dimensional Euclidean space. This demonstrates that the concept of lopsidedness in its various disguises is most natural and versatile in combinatorics.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Jiang Y,,The Thom–Sebastiani theorem for the Euler characteristic of cyclic L∞-algebras,Journal of Algebra,2018,498,,362-397,,,,,2018,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869317306208;http://dx.doi.org/10.1016/j.jalgebra.2017.11.032,10.1016/j.jalgebra.2017.11.032,Let L be a cyclic L∞-algebra of dimension 3 with finite dimensional cohomology only in dimension one and two. By transfer theorem there exists a cyclic L∞-algebra structure on the cohomology H⁎(L). The inner product plus the higher products of the cyclic L∞-algebra defines a superpotential function f on H1(L). We associate with an analytic Milnor fiber for the formal function f and define the Euler characteristic of L is to be the Euler characteristic of the étale cohomology of the analytic Milnor fiber. In this paper we prove a Thom–Sebastiani type formula for the Euler characteristic of cyclic L∞-algebras. As applications we prove the Joyce–Song formulas about the Behrend function identities for semi-Schur objects in the derived category of coherent sheaves over Calabi–Yau threefolds. A motivic Thom–Sebastiani type formula and a conjectural motivic Joyce–Song formula for the motivic Milnor fiber of cyclic L∞-algebras are also discussed.,"Thom–Sebastiani formula, Cyclic -algebras, Donaldson–Thomas invariants",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Martínez-Planell R,Trigueros M",,Using cycles of research in APOS: The case of functions of two variables,The Journal of Mathematical Behavior,2019,55,,100687,,,,,2019,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312318300543;http://dx.doi.org/10.1016/j.jmathb.2019.01.003,10.1016/j.jmathb.2019.01.003,"This article reports on an Action-Process-Object-Schema Theory (APOS) based study consisting of three research cycles on student learning of the basic idea of a two-variable functions and its graphical representation. Each of the three research cycles used semi-structured interviews with students to test a conjecture about mental constructions (genetic decomposition) students may use to understand functions of two variables, develop supporting classroom activities based on interview results, and successively improve the conjecture. The article brings together for the first time findings already reported in the literature from the first two research cycles, and the results of the third and final cycle. The final results show that students who were assigned special activities based on the research findings of the first two cycles were more likely to exhibit behavior consistent with a Process conception of function of two variables. An important contribution of the article is that it shows how different APOS research cycles may be used to successively improve students’ understanding of a mathematical notion. Also, the description of findings from the three research cycles, provides a potentially useful guide to improve student learning of function of two variables.","Functions of two variables, APOS theory, Semiotic representation theory, Genetic decomposition, Cycles of research, Networking of theories",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cole JB,Murase H,Naito S",,A lie group theoretic approach to the invariance problem in feature extraction and object recognition,Pattern Recognition Letters,1991,12,9,519-523,,,,,1991,,0167-8655,https://www.sciencedirect.com/science/article/pii/016786559190091Y;http://dx.doi.org/10.1016/0167-8655(91)90091-Y,10.1016/0167-8655(91)90091-Y,We derive a formal solution to the invariance problem and construct it using Lie group generators. Representations of these generators with respect to image data are discussed. Group theoretical obstacles to three-dimensional invariant recognition and possible solutions are considered.,"Invariance problem, Lie group generators",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Herbort S,Gerken B,Schugk D,Wöhler C",,3D range scan enhancement using image-based methods,ISPRS Journal of Photogrammetry and Remote Sensing,2013,84,,69-84,,,,,2013,,0924-2716,https://www.sciencedirect.com/science/article/pii/S0924271613001615;http://dx.doi.org/10.1016/j.isprsjprs.2013.07.004,10.1016/j.isprsjprs.2013.07.004,"This paper addresses the problem of 3D surface scan refinement, which is desirable due to noise, outliers, and missing measurements being present in the 3D surfaces obtained with a laser scanner. We present a novel algorithm for the fusion of absolute laser scanner depth profiles and photometrically estimated surface normal data, which yields a noise-reduced and highly detailed depth profile with large scale shape robustness. In contrast to other approaches published in the literature, the presented algorithm (1) regards non-Lambertian surfaces, (2) simultaneously computes surface reflectance (i.e. BRDF) parameters required for 3D reconstruction, (3) models pixelwise incident light and viewing directions, and (4) accounts for interreflections. The algorithm as such relies on the minimization of a three-component error term, which penalizes intensity deviations, integrability deviations, and deviations from the known large-scale surface shape. The solution of the error minimization is obtained iteratively based on a calculus of variations. BRDF parameters are estimated by initially reducing and then iteratively refining the optical resolution, which provides the required robust data basis. The 3D reconstruction of concave surface regions affected by interreflections is improved by compensating global illumination in the image data. The algorithm is evaluated based on eight objects with varying albedos and reflectance behaviors (diffuse, specular, metallic). The qualitative evaluation shows a removal of outliers and a strong reduction of noise, while the large scale shape is preserved. Fine surface details Which are previously not contained in the surface scans, are incorporated through using image data. The algorithm is evaluated with respect to its absolute accuracy using two caliper objects of known shape, and based on synthetically generated data. The beneficial effect of interreflection compensation on the reconstruction accuracy is evaluated quantitatively in a Photometric Stereo framework.","Photometry, Surface reconstruction, Laser scanning, Data fusion, BRDF, Interreflections",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Burgess JP,"Prawitz D,Skyrms B,Westerståhl D","Non-classical logic and ontological non-commitment, avoiding abstract objects through modal operators",,1995,134,,287-305,,Elsevier,,"Logic, Methodology and Philosophy of Science IX",1995,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X06800492;http://dx.doi.org/10.1016/S0049-237X(06)80049-2,10.1016/S0049-237X(06)80049-2,"Publisher Summary This chapter describes the nonclassical logic and ontological noncommitment, avoiding abstract objects through modal operators. Mathematical objects and facts are not concrete, but rather abstract, immutable, and impassive, unchanging with times and independent of contingencies. Correspondingly, mathematical language makes no use of temporal and modal distinctions. Consequently, mathematical logic includes among its operators none expressing such distinctions. To apply mathematical logic, with just its classical operators of negation, conjunction, disjunction, and existential and universal quantification, to non-mathematical language, one must resort to regimentation. A series of completeness theorems for temporal and modal logic establishes that the same arguments are validated by the regimented and the autonomous approaches whenever both are applicable. The regimented approach is, however, applicable to more arguments than the autonomous approach. In connection with each, divergences between natural language and the formal languages of mainstream systems of modal logic are encountered in the chapter.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhang Y,Li Z,Gao J,Hong J",,New reasoning algorithm for assembly tolerance specifications and corresponding tolerance zone types,Computer-Aided Design,2011,43,12,1606-1628,,,,,2011,,0010-4485,https://www.sciencedirect.com/science/article/pii/S0010448511001503;http://dx.doi.org/10.1016/j.cad.2011.06.008,10.1016/j.cad.2011.06.008,"When designing a mechanical product, how to determine its assembly tolerance specifications (ATS) and tolerance zone types (TZT) is a complex design problem, in which designers need to consider comprehensively the functional requirement, geometric feature, tolerance principle, and so on. Therefore, it has high requirements for designers. Meanwhile, the design and development of a complex assembly need to be done jointly by designers. This will cause difficulties for the overall coordination of tolerance design, which affects the quality and efficiency of product development. In order to reduce the uncertainty of ATS and TZT design, and to adapt to the requirements of digital design, a new reasoning algorithm for the automatic generation of ATS and TZT is presented. Polychromatic sets theory (PST) can provide a more formal approach to describe research objects and the relationships among them. Based on PST, this method establishes reasoning relation matrices to represent the relations among research objects, such as assembly feature, assembly constraint type, datum reference frame and tolerance zone type. Therefore, it can use a unified formal mathematical model to describe the whole reasoning process from assembly to ATS and TZT. This method realizes the systematization and computerization of ATS and TZT design, which can help designers to achieve the coordination and coherence of tolerance design. This method facilitates knowledge management and improves reasoning quality and efficiency. ATSs and TZTs generated by this method meet the functional requirements of product and are in accord with the tolerance standards in ISO/ASME. Furthermore, the method only requires a little geometric information and is consistent with the designers’ way of thinking, which shows good applicability for the practical design of ATS and TZT. Finally, the reasoning steps of ATSs and TZTs are demonstrated by means of an example.","Assembly tolerance specification, Tolerance zone type, Assembly constraint type, Datum reference frame, Polychromatic sets",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Suppes P,Krantz DM,Luce RD,Tversky A","Suppes P,Krantz DM,Luce RD,Tversky A",Chapter 14 - Proximity Measurement,,1989,,,159-225,,Academic Press,San Diego,Foundations of Measurement,1989,9780124254022,,https://www.sciencedirect.com/science/article/pii/B9780124254022500107;http://dx.doi.org/10.1016/B978-0-12-425402-2.50010-7,10.1016/B978-0-12-425402-2.50010-7,"Publisher Summary This chapter discusses the measurement of proximity. Proximity relations can be inferred from various types of observations, such as rating of similarity or dissimilarity, classification of objects, correlation among variables, frequency of co-occurrences, and errors of substitution. Proximity data are commonly used to infer the structure of the entities under study and to embed them in a suitable formal structure. Formal representations serve two related functions: (1) they provide convenient methods for describing, summarizing, and displaying proximity data; and (2) they are also treated as theories about the data-generating process. Representations of proximity relations can be divided into two general classes: (1) geometrical or spatial, models; and (2) set-theoretical or feature, models. Geometrical models represent the objects under study as points in a space so that the proximity ordering of the objects is represented by the ordering of the metric distances among the respective points. Set-theoretical models of proximity represent each object as a collection of features and express the proximity between objects in terms of the measures of their common and their distinctive features.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wan T,Cao J,Chen J,Qin Z",,Automated grading of breast cancer histopathology using cascaded ensemble with combination of multi-level image features,Neurocomputing,2017,229,,34-44,,,,,2017,,0925-2312,https://www.sciencedirect.com/science/article/pii/S0925231216305471;http://dx.doi.org/10.1016/j.neucom.2016.05.084,10.1016/j.neucom.2016.05.084,"We present a novel image-analysis based method for automatically distinguishing low, intermediate, and high grades of breast cancer in digitized histopathology. A multiple level feature set, including pixel-, object-, and semantic-level features derived from convolutional neural networks (CNN), is extracted from 106 hematoxylin and eosin stained breast biopsy tissue studies from 106 women patients. These multi-level features allow not only characterization of cancer morphology, but also extraction of structural and interpretable information within the histopathological images. In this study, an improved hybrid active contour model based segmentation method was used to segment nuclei from the images. The semantic-level features were extracted by a CNN approach, which described the proportions of nuclei belonging to the different grades, in conjunction with pixel-level (texture) and object-level (architecture) features, to create an integrated set of image attributes that can potentially outperform either subtype of features individually. We utilized a cascaded approach to train multiple support vector machine (SVM) classifiers using combinations of feature subtypes to enable the possibility of maximizing the performance by leveraging different feature sets extracted from multiple levels. Final class (cancer grade) was determined by combining the scores produced by the individual SVM classifiers. By employing a light (three-layer) CNN model and parallel computing, the presented approach is computationally efficient and applicable to large-scale datasets. The method achieved an accuracy of 0.92 for low versus high, 0.77 for low versus intermediate, and 0.76 for intermediate versus high, and an overall accuracy of 0.69 when discriminating low, intermediate, and high grades of histopathological breast cancer images. This suggested that our grading method could be useful in developing a computational diagnostic tool for differentiating breast cancer grades, which might enable objective and reproducible alternative for diagnosis.","Breast cancer grading, Histopathology, Multi-level features, Convolutional neural networks, Cascaded ensemble",Advances in computing techniques for big medical image data,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rusanov VA,Daneev AV,Dmitriev AV",,The spectral analysis of I-processes in the class of mixed problems for linear models of normal-hyperbolic type*,IFAC Proceedings Volumes,1999,32,2,4177-4182,,,,,1999,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017567129;http://dx.doi.org/10.1016/S1474-6670(17)56712-9,10.1016/S1474-6670(17)56712-9,"In this note it continue a developing of the axiomatic approach to the problems of the general theory of dynamic systems identification with equations of states in a linear non-normed topological space. The main aim of this note is a constructing in terms of the formal identificational process a decision of the determining problem of finite number of elements of operator spectrum of control object, the dynamics of which is determined by the linear model of normal hyperbolic type.","identification, mathematical models, spectral analysis, distributed models","14th IFAC World Congress 1999, Beijing, Chia, 5-9 July",,,,,,,,,,,,,,,,,,,,
Journal Article,"Tamani K,Boukezzoula R,Habchi G",,HIGH LEVEL PETRI NETS BASED APPROACH FOR ANALYSING CONCEPTUAL OBJECTS FOR PRODUCTION SYSTEMS SIMULATION,IFAC Proceedings Volumes,2006,39,3,361-366,,,,,2006,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667015359140;http://dx.doi.org/10.3182/20060517-3-FR-2903.00194,10.3182/20060517-3-FR-2903.00194,"In the field of design and analysis of manufacturing systems, models are sometimes built with the help of analytical methods. However, the verification of these models is often addressed by simulation. To check the performance of a manufacturing system, formal methods of design are needed. In this work, the selected modelling and verification tool is a high level Petri net. Based on properties of the generic concept called the Production Processing System (PPS) and developed for modelling and simulation of production resources, this article deals with analysing the PPS by high-level Petri nets (HLPN) formalisms.","High level Petri nets, Coloured Petri nets, Production Processing System, Simulation, Performance analysis",12th IFAC Symposium on Information Control Problems in Manufacturing,,,,,,,,,,,,,,,,,,,,
Journal Article,Lundberg BG,,Const—A constructive approach to information modelling,Information Systems,1987,12,2,157-165,,,,,1987,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437987900391;http://dx.doi.org/10.1016/0306-4379(87)90039-1,10.1016/0306-4379(87)90039-1,"An approach to information modelling is presented which is based on the principles of a constructive theory and employs the formalism of production rules. In the paper a constructive approach is taken concerning the nature and representation of abstract objects (here referred to as quasi objects). The cognitive, formal and metaphysical advantages are presented and discussed, and examples employing the constructive approach are presented with comments.","Information modelling, production rules, construction rules",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Thomas A,Mastrogiovanni F,Baglietto M",,MPTP: Motion-planning-aware task planning for navigation in belief space,Robotics and Autonomous Systems,2021,141,,103786,,,,,2021,,0921-8890,https://www.sciencedirect.com/science/article/pii/S0921889021000713;http://dx.doi.org/10.1016/j.robot.2021.103786,10.1016/j.robot.2021.103786,"We present an integrated Task-Motion Planning (TMP) framework for navigation in large-scale environments. Of late, TMP for manipulation has attracted significant interest resulting in a proliferation of different approaches. In contrast, TMP for navigation has received considerably less attention. Autonomous robots operating in real-world complex scenarios require planning in the discrete (task) space and the continuous (motion) space. In knowledge-intensive domains, on the one hand, a robot has to reason at the highest-level, for example, the objects to procure, the regions to navigate to in order to acquire them; on the other hand, the feasibility of the respective navigation tasks have to be checked at the execution level. This presents a need for motion-planning-aware task planners. In this paper, we discuss a probabilistically complete approach that leverages this task-motion interaction for navigating in large knowledge-intensive domains, returning a plan that is optimal at the task-level. The framework is intended for motion planning under motion and sensing uncertainty, which is formally known as belief space planning. The underlying methodology is validated in simulation, in an office environment and its scalability is tested in the larger Willow Garage world. A reasonable comparison with a work that is closest to our approach is also provided. We also demonstrate the adaptability of our approach by considering a building floor navigation domain. Finally, we also discuss the limitations of our approach and put forward suggestions for improvements and future work.","Task-motion planning, Belief space planning, Autonomous navigation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Niemi T,Järvelin K",,The processing strategy for the NF2 relational frc-interface,Information and Software Technology,1996,38,1,11-24,,,,,1996,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584995010416;http://dx.doi.org/10.1016/0950-5849(95)01041-6,10.1016/0950-5849(95)01041-6,"The idea of the frc- (form-relations-conditions) interface is to reduce the user effort in the NF2 (Non-First-Normal-Form) relational query formulation considerably. In the frc-interface the user only describes the structure of the result NF2 relation in a straightforward and intuitive way without specifying how the result NF2 relation is derived from the source NF2 relations. The lack of explicit restructuring expressions from the frc-interface means that query processing must be based on a different approach than that used in query languages (e.g. the SQL extensions made for the NF2 relational model) in which the user specifies the needed restructuring among data explicitly. In this paper we introduce our query processing strategy of the frc-interface which has been implemented in Prolog. Its kernel is a calculus consisting of two constructors (for concatenation and relation construction of NF2 objects). By applying these constructors recursively to atomic-valued attribute representations, any NF2 relation can be constructed. Our calculus-based approach affords the possibility of performing several operations at the same time, which gives a good starting point for efficient implementation. In the paper the optimization process used to manipulate several NF2 relations is described.","NF relational model, User interface, Query processing, Logic programming, Prolog-based knowledge representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Veres SM,Veres AG",,ADAPTATION AND LEARNING IN AN AUTONOMOUS PHYSICAL AGENT ARCHITECTURE,IFAC Proceedings Volumes,2007,40,13,256-262,,,,,2007,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667015320267;http://dx.doi.org/10.3182/20070829-3-RU-4911.00042,10.3182/20070829-3-RU-4911.00042,"Learning and adaptation is presented for a specific but generally applicable autonomous physical agent (APA) architecture. The paper is providing a general framework of skills learning within behaviour logic framework of agents that communicate, sense and act in the physical world. It is shown how programmed playfulness can be easily implemented that results in learning and ultimately better skills of agents. Reusability of results in learning algorithms is supported by ontology based classification of learning in operational modes. Ontology based classification provides object instances that enable modularization of software and easy interfacing of operational modes with learning algorithms.","Intelligent physical agents, formal methods, learning, adaptive control modelling for control",9th IFAC Workshop on Adaptation and Learning in Control and Signal Processing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Falkenberg ED,Van Der Pols R,Van Der Weide TP",,Understanding process structure diagrams,Information Systems,1991,16,4,417-428,,,,,1991,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437991900325;http://dx.doi.org/10.1016/0306-4379(91)90032-5,10.1016/0306-4379(91)90032-5,"This paper is an attempt to sketch a framework for understanding process structure diagrams, as used for business process analysis, being one phase of information system design. Proper understanding of any description method can only be achieved by specifying all the concepts (objects, predicates) and axioms of this method in a precise, formal way. On this basis, different description methods can be properly compared, translated, and thus their similarities and/or differences better understood. In our paper, this approach is applied to two description methods for process structuring, dataflow diagrams and activity graphs.","Process structure diagrams, dataflow diagrams, activity graphs, transformation, formal semantics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ballester-Bolinches A,Cosme-Llópez E,Esteban-Romero R",,A description based on languages of the final non-deterministic automaton,Theoretical Computer Science,2014,536,,1-20,,,,,2014,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397514000358;http://dx.doi.org/10.1016/j.tcs.2014.01.018,10.1016/j.tcs.2014.01.018,"The study of the behaviour of non-deterministic automata has traditionally focused on the languages which can be associated to the different states. Under this interpretation, the different branches that can be taken at every step are ignored. However, we can also take into account the different decisions which can be made at every state, that is, the branches that can be taken, and these decisions might change the possible future behaviour. In this case, the behaviour of the automata can be described with the help of the concept of bisimilarity. This is the kind of description that is usually obtained when the automata are regarded as labelled transition systems or coalgebras. Contrarily to what happens with deterministic automata, it is not possible to describe the behaviour up to bisimilarity of states of a non-deterministic automaton by considering just the languages associated to them. In this paper we present a description of a final object for the category of non-deterministic automata, regarded as labelled transition systems, with the help of some structures defined in terms of languages. As a consequence, we obtain a characterisation of bisimilarity of states of automata in terms of languages and a method to minimise non-deterministic automata with respect to bisimilarity of states. This confirms that languages can be considered as the natural objects to describe the behaviour of automata.","Non-deterministic automaton, Formal language, Coalgebra, Bisimilarity, Final automaton",,,,,,,,,,,,,,,,,,,,,
Journal Article,"ter Hofstede AH,Proper HA,van der Weide TP",,Formal definition of a conceptual language for the description and manipulation of information models,Information Systems,1993,18,7,489-523,,,,,1993,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799390004K;http://dx.doi.org/10.1016/0306-4379(93)90004-K,10.1016/0306-4379(93)90004-K,"Conceptual data modelling techniques aim at the representation of data at a high level of abstraction. This implies that conceptual data modelling techniques should not only be capable of naturally representing complex structures, but also the rules (constraints) that must hold for these structures. Contemporary data modelling techniques, however, do not provide a language, which on the one hand has a formal semantics and on the other hand leads to natural looking expressions, for formulating these constraints. In this paper such a language is defined for an existing data modelling technique (PSM), which is a generalisation of object-role models (such as ER or NIAM). In this language not only constraints, but also queries and updates can be expressed on a conceptual level.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gibert K,Rodríguez-Silva G,Annicchiarico R",,Post-processing: Bridging the gap between modelling and effective decision-support. The profile assessment grid in human behaviour,Mathematical and Computer Modelling,2013,57,7,1633-1639,,,,,2013,,0895-7177,https://www.sciencedirect.com/science/article/pii/S0895717711006510;http://dx.doi.org/10.1016/j.mcm.2011.10.046,10.1016/j.mcm.2011.10.046,"The importance of post-processing the results of clustering when using data mining to support subsequent decision-making is discussed. Both the formal embedded binary logistic regression (EBLR) and the visual profile’s assessment grid (PAG) methods are presented as bridging tools for the real use of clustering results. EBLR is a sequence of logistic regressions that helps to predict the class of a new object; while PAG is a graphical tool that visualises the results of an EBLR. PAG interactively determines the most suitable class for a new object and enables subsequent follow-ups. PAG makes the underlying mathematical model (EBLR) more understandable, improves usability and contributes to bridging the gap between modelling and decision-support. When applied to medical problems, these tools can perform as diagnostic-support tools, provided that the predefined set of profiles refer to different stages of a certain disease or different types of patients with a same medical problem, etc. Being a graphical tool, PAG enables doctors to quickly and friendly determine the profile of a patient in the everyday activity, without necessarily understanding the statistical models involved in the process, which used to be a serious limitation for wider application of these methods in clinical praxis. In this work, an application is presented with 4 functional disability profiles.","Data mining, Knowledge discovery from databases, Clustering, Logistic regression, Profiles assessment grid, Post-processing, Decision-support, Human behaviour",Public Key Services and Infrastructures EUROPKI-2010-Mathematical Modelling in Engineering & Human Behaviour 2011,,,,,,,,,,,,,,,,,,,,
Journal Article,"Catenacci R,Debernardi M,Grassi PA,Matessi D",,Čech and de Rham cohomology of integral forms,Journal of Geometry and Physics,2012,62,4,890-902,,,,,2012,,0393-0440,https://www.sciencedirect.com/science/article/pii/S0393044011002853;http://dx.doi.org/10.1016/j.geomphys.2011.12.011,10.1016/j.geomphys.2011.12.011,"We present a study on the integral forms and their Čech and de Rham cohomology. We analyze the problem from a general perspective of sheaf theory and we explore examples in superprojective manifolds. Integral forms are fundamental in the theory of integration in a supermanifold. One can define the integral forms introducing a new sheaf containing, among other objects, the new basic forms δ(dθ) where the symbol δ has the usual formal properties of Dirac’s delta distribution and acts on functions and forms as a Dirac measure. They satisfy in addition some new relations on the sheaf. It turns out that the enlarged sheaf of integral and “ordinary” superforms contains also forms of “negative degree” and, moreover, due to the additional relations introduced it is, in a non trivial way, different from the usual superform cohomology.","Supermanifold, Čech/de Rahm cohomology, Superforms",,,,,,,,,,,,,,,,,,,,,
Journal Article,Goldblatt R,,Final coalgebras and the Hennessy–Milner property,Annals of Pure and Applied Logic,2006,138,1,77-93,,,,,2006,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007205000886;http://dx.doi.org/10.1016/j.apal.2005.06.006,10.1016/j.apal.2005.06.006,"The existence of a final coalgebra is equivalent to the existence of a formal logic with a set (small class) of formulas that has the Hennessy–Milner property of distinguishing coalgebraic states up to bisimilarity. This applies to coalgebras of any functor on the category of sets for which the bisimilarity relation is transitive. There are cases of functors that do have logics with the Hennessy–Milner property, but the only such logics have a proper class of formulas. The main theorem gives a representation of states of the final coalgebra as certain satisfiable sets of formulas. The key technical fact used is that any function between coalgebras that is truth-preserving and has a simple codomain must be a coalgebraic morphism.","Coalgebra, Final object, Bisimulation, Bisimilarity, Congruence, Coinductive, Abstract logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,Parmar RK,,Extended τ-hypergeometric functions and associated properties,Comptes Rendus Mathematique,2015,353,5,421-426,,,,,2015,,1631-073X,https://www.sciencedirect.com/science/article/pii/S1631073X15000424;http://dx.doi.org/10.1016/j.crma.2015.01.016,10.1016/j.crma.2015.01.016,"Recently, an extension of the Pochhammer symbol was used in order to introduce and investigate a family of generalized hypergeometric functions [Srivastava et al. (2014) [11]]. The main object of this paper is to present an extension of the τ-Gauss hypergeometric functions R1τ2(z) and investigate its several properties, including, for example, its integral representations, derivative formulas, Mellin transforms and fractional calculus operators. Some interesting special cases of our main results are also pointed out. Résumé Récemment, une extension du symbole de Pochhammer a été utilisée pour introduire et étudier une famille de fonctions hypergéométriques généralisées [Srivastava et al. (2014) [11]]. L'objet de cette Note est de présenter une extension des fonctions τ-hypergéométriques de Gauss R1τ2(z) et d'étudier plusieurs de leurs propriétés, incluant, par exemple, leurs représentations intégrales, les formules de dérivées, les transformées de Mellin et les opérateurs de calcul fractionnaire. Quelques cas particuliers intéressants de nos résultats principaux sont également signalés.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chakhar S,Mousseau V",,An algebra for multicriteria spatial modeling,"Computers, Environment and Urban Systems",2007,31,5,572-596,,,,,2007,,0198-9715,https://www.sciencedirect.com/science/article/pii/S0198971507000580;http://dx.doi.org/10.1016/j.compenvurbsys.2007.08.007,10.1016/j.compenvurbsys.2007.08.007,"The objective of this paper is to propose a new algebra, called decision map algebra (DMA), especially devoted to multicriteria spatial modeling. DMA is a generic and context-independent modeling language inspired from map algebra and other similar languages. It supports the conventional geometric objects and cartographic maps and adds a rich set of new operands representing different spatial multicriteria concepts. Moreover, DMA supports different conventional map algebra-like operations and adds several new ones corresponding to different spatial multicriteria evaluation functions. The proposed algebra is the first step towards the development of a generic spatial multicriteria modeling language.","GIS, Spatial multicriteria modeling, Map algebra, Formal specification",Geospatial Analysis and Modeling,,,,,,,,,,,,,,,,,,,,
Journal Article,"Abramsky S,McCusker G",,"Linearity, Sharing and State: a fully abstract game semantics for Idealized Algol with active expressions: Extended Abstract",Electronic Notes in Theoretical Computer Science,1996,3,,2-14,,,,,1996,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105803986;http://dx.doi.org/10.1016/S1571-0661(05)80398-6,10.1016/S1571-0661(05)80398-6,"The manipulation of objects with state which changes over time is all-pervasive in computing. Perhaps the simplest example of such objects are the program variables of classical imperative languages. An important strand of work within the study of such languages, pioneered by John Reynolds, focuses on “Idealized Algol”, an elegant synthesis of imperative and functional features. We present a novel semantics for Idealized Algol using games, which is quite unlike traditional denotational models of state. The model takes into account the irreversibility of changes in state, and makes explicit the difference between copying and sharing of entities. As a formal measure of the accuracy of our model, we obtain a full abstraction theorem for Idealized Algol with active expressions.",,Linear Logic 96 Tokyo Meeting,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lavazza L,Morasca S,Morzenti A",,A Dual Language Approach to the Development of Time-Critical Systems,Electronic Notes in Theoretical Computer Science,2005,116,,227-239,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104052892;http://dx.doi.org/10.1016/j.entcs.2004.02.079,10.1016/j.entcs.2004.02.079,"Developing time-critical systems requires expressive, rigorous, easy to use notations to describe the time-related features of the systems, in a way that is formal enough to support and automate activities like property verification and test case generation. We propose a dual-language approach provided with a descriptive formalism for specifying the properties of a system and its components in addition to the typical UML (and UML-RT) diagrams. This description consists of a formula of a new logic, called OTL (Object Temporal Logic), which is an extension of OCL. The approach is applied to a case study derived from the authors' industrial experiences.","time-critical system, verification, testing, UML, OTL, OCL",Proceedings of the International Workshop on Test and Analysis of Component Based Systems (TACoS 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Park Y,Goldberg B",,Static analysis for optimizing reference counting,Information Processing Letters,1995,55,4,229-234,,,,,1995,,0020-0190,https://www.sciencedirect.com/science/article/pii/002001909500096U;http://dx.doi.org/10.1016/0020-0190(95)00096-U,10.1016/0020-0190(95)00096-U,"In reference counting schemes for automatically reclaiming storage, each time a reference to a heap-allocated object is created or destroyed, the reference count of the object needs to be updated. This may involve expensive inter-processor message exchanges in distributed environments. This overhead can be reduced by analyzing the lifetimes of references to avoid unnecessary updatings. We present a compile-time analysis for higher-order functional languages that determines whether the lifetime of a reference exceeds the lifetime of the environment in which the reference was created. Using this statically inferred information, a method for optimizing reference counting schemes is described. Our method can be applied to reference counting schemes in both uniprocessor and multiprocessor environments.","Garbage collection, Reference count, Programming languages, Formal semantics, Language processors, Static analysis, Functional programming, Distributed systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,"de Barros Filho IE,Silva I,Costa DG,Viegas CM,Ferrari P",,A reliability and performance GSPN-Based model for anti-collision RFID algorithms under noisy channels in industrial internet of things,Computers in Industry,2021,125,,103381,,,,,2021,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361520306151;http://dx.doi.org/10.1016/j.compind.2020.103381,10.1016/j.compind.2020.103381,"The Industrial Internet of Things (IIoT) has the potential to deeply change the technological landscape in factories, transforming the way automation procedures are performed and relevant objects are identified. For that, however, reliability and performance issues have to be considered when providing the expected communication services. When employing Radio-Frequency Identification (RFID) in an IIoT context, previous works have struggled to improve the efficiency of RFID-complaint systems, usually defining mathematical models for planning and quality assessment. Nevertheless, such models are designed based on error-free communications, which are unreal when considering the error-prone nature of wireless communications in industrial plants. Therefore, this article defines a new formal model based on Generalized Stochastic Petri Nets (GSPN) for RFID communications, modelling different possibilities for errors between readers and RFID tags. Since this proposal employs the EPCglobal UHF Class 1 Gen2 parameters as reference, which are already adopted by the Dynamic Frame Slotted Aloha anti-collision protocol for passive RFID systems, this model can be exploited to assess the reliability and performance of different RFID medium access protocols when assuming noisy channels, supporting better comparisons among different algorithms and protocols. Simulation scenarios are defined to present reliability and performance results when assessing RFID tags reading, which are valuable when designing and maintaining IIoT applications.","Industrial IoT, Petri nets, RFID, Reliability, Performance, Error modelling",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kracht WA,,Relational Modelling of an Information System's Object Area,IFAC Proceedings Volumes,1983,16,20,147-152,,,,,1983,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017615969;http://dx.doi.org/10.1016/S1474-6670(17)61596-9,10.1016/S1474-6670(17)61596-9,The paper consideres the representation of the model for a conceptual structure of an information system object area which is built as a relational lattice.,"Formal model, conceptual model, set theory, binary relations, unary relations","IFAC Symposium on Artificial Intelligence, Leningrad, USSR, 4-6 October",,,,,,,,,,,,,,,,,,,,
Journal Article,"Landis R,Johnson L",,Advances in planetary defense in the United States,Acta Astronautica,2019,156,,394-408,,,,,2019,,0094-5765,https://www.sciencedirect.com/science/article/pii/S0094576517315217;http://dx.doi.org/10.1016/j.actaastro.2018.06.020,10.1016/j.actaastro.2018.06.020,"The National Aeronautics and Space Administration (NASA) recently established an office to manage the Agency's planetary defense-related projects and coordinate activities across multiple U.S. agencies as well as with international efforts to plan appropriate responses to the potential asteroid impact hazard. The creation of the Planetary Defense Coordination Office (PDCO) is a logical and formal step forward with NASA's NEO Observations program which began nearly two decades ago. Since the program's inception in 1998, NASA-funded efforts have discovered more than 98% of the more than 16,000 NEOs currently known. As important as it is to mitigate a potential impact event, the essential first step is to find these near-Earth objects as early as possible. To that end, NASA's PDCO leads national and international efforts to:•detect any potential for significant impact of the Earth by natural objects;•appraise the range of potential effects by any possible object; and•develop strategies to mitigate impact effects on human welfare. Since commencing the program in 1998, NASA has provided funding to upgrade and operate existing 1-m class telescopes to conduct the search for NEOs. Today, NASA funds three primary ground-based survey capabilities: the Lincoln Near-Earth Asteroid Research (LINEAR) project, the Catalina Sky Survey (CSS), and the Panoramic Survey Telescope and Rapid Reporting System (Pan-STARRS). Recent enhancements to NASA's Near-Earth Object (NEO) Observations Program have led to ∼83% increase in the discovery rate of near-Earth asteroids (NEAs) over the past three years. These survey efforts are increasingly detecting close encounter events (i.e., <0.001 AU; recent examples include 2012 DA14, 2017 EA, and 2017 GM) and have enabled the prediction of some small object impact events (e.g., 2008 TC3 and 2014 AA). Such encounters provide opportunities for NASA's Infrared Telescope Facility (IRTF) to make spectral measurements; or observation by planetary radars at Arecibo and Goldstone to refine the orbit of the object with great precision and even “image” the small primitive body. Of critical importance is the Minor Planet Center (MPC), where automated systems process observations made by the search teams to determine orbits and what are NEOs. The Center for NEO Studies at the Jet Propulsion Laboratory (JPL) determines more precise orbits for the objects. Both JPL and the MPC utilize processes and procedures for NEO orbit determination and prediction that are sanctioned and monitored by the International Astronomical Union (IAU) and produce data catalogues on small bodies in the Solar System that are utilized world-wide by the astronomical community. The Wide-field Infrared Survey Explorer (WISE) was reactivated for the purpose detecting NEOs and will continue to operate well into 2018. It is in Sun-synchronous, near-polar inclination (97.5°) orbit around the Earth. The NEOWISE project uses WISE in ‘warm mode’ (at 3.4 and 4.6 μm), and in conjunction with ground-based follow-up, this unique dataset has set limits on population statistics, orbital parameters, approximate sizes, and initial compositional knowledge of the asteroid population. Further follow-up observations with visible and infrared telescopes (e.g., NASA's Infrared Telescope Facility, Spitzer Space Telescope, other NASA-funded NEO observer teams) refine the astrometric positions of an NEO, photometric observations obtain detailed light curve information [thereby constraining NEO shapes and spin state], and collect albedo and spectral data on basic physical properties and mineralogy. Planetary defense demonstration missions also fall within the purview of the PDCO. The Double Asteroid Redirection Test (DART) mission is directed by NASA to the Johns Hopkins University Applied Physics Laboratory (JHU/APL). The target is the binary near-Earth asteroid (65803) Didymos, which consists of a primary body ∼800 m across, and a secondary body (or “moonlet”) whose 150-m size is more typical of the size of asteroids that could pose a more common hazard to Earth. However, the first step in planetary defense is the overarching goal to complete the NEO survey down to a 100 m-sized objects. The asteroid hunter mission – NEOCam – is a single scientific instrument: 0.5-m aperture infrared telescope that would survey the solar system for NEOs from Sun-Earth L1 Lagrange point (SEL1). NEOCam is also in an extended Phase A study under the auspices of NASA's PDCO.","Planetary defense, NEO, NASA",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Van den Berghe S,Van Heuven P,Coppens J,De Turck F,Demeester P",,Distributed policy-based management of measurement-based traffic engineering: design and implementation,Future Generation Computer Systems,2003,19,2,291-302,,,,,2003,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X02001541;http://dx.doi.org/10.1016/S0167-739X(02)00154-1,10.1016/S0167-739X(02)00154-1,"This article discusses an architecture using monitoring feedback as an assisting factor for delivering QoS on packet-based networks. The handling of this feedback is done in an automated way, through the use of a policy-based management architecture. For this, a formal model for describing data plane and measurement objects was translated into an XML-based configuration language. On top of this, a proof-of-concept management architecture was developed and evaluated, using both a modified network simulator and enhanced Linux prototype routers.","Traffic engineering, Monitoring, Policy-based management, Real-time management",Selected Papers from the TERENA Networking Conference 2002,,,,,,,,,,,,,,,,,,,,
Journal Article,"Peters JF,Baumela L,Maravall D,Ramanna S",,Logical design of neural controllers,Annual Review in Automatic Programming,1994,19,,179-184,,,,,1994,,0066-4138,https://www.sciencedirect.com/science/article/pii/0066413894900620;http://dx.doi.org/10.1016/0066-4138(94)90062-0,10.1016/0066-4138(94)90062-0,The logical design of a neural controller is achieved by representing a neural computation as a stochastic timed linear proof with a built-in system for rewards and punishments based on the timeliness of a computation performed by a neural controller. Logical designs are represented with stochastic forms of proofnets and proofboxes. Sample applications of the logical design methodology to the truck-backer upper and a Real-Time object recognition and tracking system (RTorts) are presented. Performance results of the implementation of the target dynamics identification module of the RTorts are given and compared to similar systems.,"Control, formal modeling, control system design, formal languages, stochastic systems, target tracking, neural nets",,,,,,,,,,,,,,,,,,,,,
Journal Article,Lehmann JP,,A universal machine without change of state,Theoretical Computer Science,1987,55,2,291-348,,,,,1987,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397587901058;http://dx.doi.org/10.1016/0304-3975(87)90105-8,10.1016/0304-3975(87)90105-8,"The work we present here, is mainly an endeavour to explicit and to clarify the notion of symbol: once their physical status has been admitted, such entities have inevitably some extension in space and time; thus the corresponding concept must be defined in connection with the machinery of which the function is to mark and to modify the signs which are the objects of calculus. We can express this point of view by saying that the notion of symbol derives from the duality composed one the one hand, by a physical disturbance, and on the other, by a machinery which treats it. In a first stage, this approach enabled us to create a model of calculus, inspired by Turing's, in which the classical notion of state becomes superfluous. We call this model α→β, x and it is characterized: firstly by an exclusively Boolean processing component, without feed-back, secondly by a special movement of this component of which the amplitude is defined as smaller than that of symbol examined. A distinct theory can then be developed on this foundation, without recourse to other definitions of calculability; the detailed construction of a universal machine of the model ensures its autonomy.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Krämer B,Luqi",,Toward formal models of software engineering processes,Journal of Systems and Software,1991,15,1,63-74,,,,,1991,,0164-1212,https://www.sciencedirect.com/science/article/pii/016412129190077J;http://dx.doi.org/10.1016/0164-1212(91)90077-J,10.1016/0164-1212(91)90077-J,"In this paper, a Petri net-based formal specification method for distributed systems is applied to the domain of software process modeling. We introduce domain-specific concepts stressing the distributed and dynamic nature of software processes. Development states are viewed as distributed entities. Development activities are characterized by their effects on software objects, pertinent information exchange with human or technical participants involved, and local changes to development states. These dynamic aspects of software processes are represented as labeled Petri nets. Structuring mechanisms are sketched which support hierarchical decomposition and systematic combinations of separate views of a software engineering process.",,GRASPIN Software,,,,,,,,,,,,,,,,,,,,
Journal Article,"Scherl RB,Levesque HJ",,"Knowledge, action, and the frame problem",Artificial Intelligence,2003,144,1,1-39,,,,,2003,,0004-3702,https://www.sciencedirect.com/science/article/pii/S000437020200365X;http://dx.doi.org/10.1016/S0004-3702(02)00365-X,10.1016/S0004-3702(02)00365-X,"This paper proposes a method for handling the frame problem for knowledge-producing actions. An example of a knowledge-producing action is a sensing operation performed by a robot to determine whether or not there is an object of a particular shape within its grasp. The work is an extension of Reiter's approach to the frame problem for ordinary actions and Moore's work on knowledge and action. The properties of our specification are that knowledge-producing actions do not affect fluents other than the knowledge fluent, and actions that are not knowledge-producing only affect the knowledge fluent as appropriate. In addition, memory emerges as a side-effect: if something is known in a certain situation, it remains known at successor situations, unless something relevant has changed. Also, it will be shown that a form of regression examined by Reiter for reducing reasoning about future situations to reasoning about the initial situation now also applies to knowledge-producing actions.","Knowledge, Action, Situation calculus, Frame problem",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Heiler S,Zdonik SB","Beeri C,Schmidt JW,Dayal U",FUGUE: a Model for Engineering Information Systems and Other Baroque Applications,,1988,,,195-210,,Morgan Kaufmann,,Proceedings of the Third International Conference on Data and Knowledge Bases,1988,9781483213132,,https://www.sciencedirect.com/science/article/pii/B9781483213132500226;http://dx.doi.org/10.1016/B978-1-4832-1313-2.50022-6,10.1016/B978-1-4832-1313-2.50022-6,"This paper describes the FUGUE1 data model, an extension of DAPLEX that was developed to support engineering information systems. It begins by discussing the application requirements that must be met by such a model. They include the accurate representation of engineering data and processes; mechanisms to integrate heterogeneous hardware and software components and to tailor each instance of an EIS to local requirements and policies; and a type system that is powerful enough to support production systems, yet flexible enought to support design environments. The primitive notions of object and function are described. Then, a type system that combines the discipline of conventional types and instances with the flexibility of prototypes is presented. Finally, we show various ways of creating new objects and deriving new functions.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Glickman ME,Jensen ST",,Adaptive paired comparison design,Journal of Statistical Planning and Inference,2005,127,1,279-293,,,,,2005,,0378-3758,https://www.sciencedirect.com/science/article/pii/S0378375803003215;http://dx.doi.org/10.1016/j.jspi.2003.09.022,10.1016/j.jspi.2003.09.022,"An important aspect of paired comparison experiments is the decision of how to form pairs in advance of collecting data. A weakness of typical paired comparison experimental designs is the difficulty in incorporating prior information, which can be particularly relevant for the design of tournament schedules for players of games and sports. Pairing methods that make use of prior information are often ad hoc algorithms with little or no formal basis. The problem of pairing objects can be formalized as a Bayesian optimal design. Assuming a linear paired comparison model for outcomes, we develop a pairing method that maximizes the expected gain in Kullback–Leibler information from the prior to the posterior distribution. The optimal pairing is determined using a combinatorial optimization method commonly used in graph-theoretic contexts. We discuss the properties of our optimal pairing criterion, and demonstrate our method as an adaptive procedure for pairing objects multiple times. We compare the performance of our method on simulated data against random pairings, and against a system that is currently in use in tournament chess.","Bayesian optimal design, Bradley–Terry model, Competition, Swiss system, Tournament schedule",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Jakubczyk B,Fliess M,REMARKS ON EQUIVALENCE AND LINEARIZATION OF NONLINEAR SYSTEMS,,1993,,,143-147,,Pergamon,Oxford,Nonlinear Control Systems Design 1992,1993,9780080419015,,https://www.sciencedirect.com/science/article/pii/B9780080419015500282;http://dx.doi.org/10.1016/B978-0-08-041901-5.50028-2,10.1016/B978-0-08-041901-5.50028-2,"In this note we consider a problem of equivalence of nonlinear systems described by a finite set of real variables satisfying a system of ordinary differential equations of finite order. Two systems are called equivalent (resp. weakly equivalent) if there exist nonlinear transformations so that the variables of one system are functions of the variables (resp. the variables and their derivatives) of the second system and vice versa, so that the sets of formal trajectories are maped onto the sets of formal trajectories. To each system we associate an algebraic object which is a D-algebra (a differential algebra). We show that our systems are weakly equivalent if and only if the corresponding D-algebras are isomorphic. The same result holds with weak equivalence replaced by equivalence if the corresponding algebraic object is a D-algebra with filtration. As corollaries we obtain algebraic criteria for equivalence (weak equivalence) of a system to a linear controllable system.",,,IFAC Symposia Series,,,,,,,,,,,,,,,,,,,
Journal Article,"Arasteh AR,Debbabi M",,Forensic memory analysis: From stack and code to execution history,Digital Investigation,2007,4,,114-125,,,,,2007,,1742-2876,https://www.sciencedirect.com/science/article/pii/S1742287607000485;http://dx.doi.org/10.1016/j.diin.2007.06.010,10.1016/j.diin.2007.06.010,"Forensics memory analysis has recently gained great attention in cyber forensics community. However, most of the proposals have focused on the extraction of important kernel data structures such as executive objects from the memory. In this paper, we propose a formal approach to analyze the stack memory of process threads to discover a partial execution history of the process. Our approach uses a process logic to model the extracted properties from the stack and then verify these properties against models generated from the program assembly code. The main focus of the paper is on Windows thread stack analysis though the same idea is applicable to other operating systems.","Cyber forensics, Physical memory, Stack, Thread, Process logic",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Greenhill S,Venkatesh S",,Noetica: a tool for semantic data modelling,Information Processing & Management,1998,34,6,739-760,,,,,1998,,0306-4573,https://www.sciencedirect.com/science/article/pii/S0306457398000211;http://dx.doi.org/10.1016/S0306-4573(98)00021-1,10.1016/S0306-4573(98)00021-1,"Noetica is a tool for structuring knowledge about concepts and the relationships between them. It differs from typical information systems in that the knowledge it represents is abstract, highly connected and includes meta-knowledge (knowledge about knowledge). Noetica represents knowledge using a strongly-typed semantic network. By providing a rich type system it is possible to represent conceptual information using formalised structures. A class hierarchy provides a basic classification for all objects. This allows for a consistency of representation that is not often found in “free” semantic networks and gives the ability to easily extend a knowledge model while retaining its semantics. We also provide visualisation and query tools for this data model. Visualisation can be used to explore complete sets of link-classes, show paths while navigating through the database, or visualise the results of queries. Noetica supports goal-directed queries (a series of user-supplied goals that the system attempts to satisfy in sequence) and path-finding queries (where the system find relationships between objects in the database by following links).",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Caprotti O,Cohen AM",,Integrating Computational and Deduction Systems Using OpenMath,Electronic Notes in Theoretical Computer Science,1999,23,3,469-480,,,,,1999,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105806164;http://dx.doi.org/10.1016/S1571-0661(05)80616-4,10.1016/S1571-0661(05)80616-4,"The standard OpenMath is a crucial ingredient for creating an integrated environment combining systems for computer algebra with proof checkers. OpenMath consists of a formal grammar of OpenMath objects, their encodings, Content Dictionaries, Phrasebooks and other tools. The OpenMath standard allows integration of computational systems of different kind. Here we demonstrate how OpenMath works by setting up an environment in which Maple expressions are type-checked by the proof checkers Lego and Coq.",,"CALCULEMUS 99, Systems for Integrated Computation and Deduction (associated to FLoC'99, the 1999 Federated Logic Conference)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Klapper R,Stump A",,Validated Proof-Producing Decision Procedures,Electronic Notes in Theoretical Computer Science,2005,125,3,53-68,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105050723;http://dx.doi.org/10.1016/j.entcs.2004.06.067,10.1016/j.entcs.2004.06.067,"A widely used technique to integrate decision procedures (DPs) with other systems is to have the DPs emit proofs of the formulas they report valid. One problem that arises is debugging the proof-producing code; it is very easy in standard programming languages to write code which produces an incorrect proof. This paper demonstrates how proof-producing DPs may be implemented in a programming language, called Rogue-Sigma-Pi (RSP), whose type system ensures that proofs are manipulated correctly. RSP combines the Rogue rewriting language and the Edinburgh Logical Framework (LF). Type-correct RSP programs are partially correct: essentially, any putative LF proof object produced by a type-correct RSP program is guaranteed to type check in LF. The paper describes a simple proof-producing combination of propositional satisfiability checking and congruence closure implemented in RSP.","Decision Procedure, Proof Production, Logical Framework, Congruence Closure",Selected Papers from the Workshops on Disproving and the Second International Workshop on Pragmatics of Decision Procedures (PDPAR 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Tschaikowski M,Tribastone M",,Tackling continuous state-space explosion in a Markovian process algebra,Theoretical Computer Science,2014,517,,1-33,,,,,2014,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397513006403;http://dx.doi.org/10.1016/j.tcs.2013.08.016,10.1016/j.tcs.2013.08.016,"Fluid or mean-field methods are approximate analytical techniques which have proven effective in tackling the infamous state-space explosion problem which typically arises when modelling large-scale concurrent systems based on interleaving semantics. These methods are particularly suitable in situations which present large populations of simple interacting objects characterised by small local state spaces, since they require the analysis of a problem which is insensitive to the population sizes but is dependent only on the size of the local state spaces. This paper studies the case when the replicated objects are best described as composites which consist of smaller simple objects. A congenial formal modelling framework for situations of this kind may be given by stochastic process algebra. Using PEPA as a representative case, we find that fluid models with replicated copies of composite processes do not scale well with increasing population sizes, thus rendering intractable the analysis of the underlying system of ordinary differential equations (ODEs). We call this problem continuous state-space explosion, by analogy with its counterpart phenomenon in discrete state spaces. The main contribution of this paper is a result of equivalence that simplifies, in an exact way, the potentially massive ODE system arising in those circumstances to one whose size is independent from all the multiplicities in the model. As a byproduct, we find that these simplified ODEs turn out to characterise the fluid behaviour of a family of PEPA models whose elements cannot be related to each other through any known equivalence relation. A substantial numerical assessment investigates the relationship between the different underlying Markov chains and their unique fluid limit, demonstrating its generally good accuracy for all practical purposes.","Ordinary differential equations, State-space explosion, Aggregation, PEPA",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Huiskonen J,Pirttilä T",,Lateral coordination in a logistics outsourcing relationship,International Journal of Production Economics,2002,78,2,177-185,,,,,2002,,0925-5273,https://www.sciencedirect.com/science/article/pii/S0925527301001141;http://dx.doi.org/10.1016/S0925-5273(01)00114-1,10.1016/S0925-5273(01)00114-1,"This paper studies the coordination of activities between two different organizations. The object of analysis is a logistics outsourcing relationship and its inter-organizational coordination requirements. The possibilities of using different forms of lateral coordination mechanisms – informal coordination, formal inter-organizational teams, and integrating roles – are discussed. The main conclusion is that developing of lateral organizational capability through practicing the presented lateral coordination mechanisms, and actively promoting it to customers, can become a potential source of competitive advantage for logistics service providers.","Logistics, Outsourcing, Lateral coordination, Inter-organizational relations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Priyadarshini P,Qin F,Lim EP,Ng WK",,Parameter driven synthetic web database generation,Journal of Systems and Software,2004,69,1,29-42,,,,,2004,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121203000025;http://dx.doi.org/10.1016/S0164-1212(03)00002-5,10.1016/S0164-1212(03)00002-5,"To support intelligent data analysis on the web information, a data warehousing system called WHOWEDA (WareHouse Of WEb DAta) has been proposed. Unlike other relational data warehouses, WHOWEDA incorporates a Web Data Model that describes the web objects and their relationships as they are maintained within a data warehouse. A set of web operations has also been developed to manipulate the warehoused web information. In order to measure the performance of WHOWEDA and other similar systems that store and manipulate web information, a synthetic web database generator called WEDAGEN (WEb DAtabase GENerator) has been developed. It has the capability of generating collections of web objects of different sizes and complexities determined by a set of user-specified parameters. This paper presents the issues in the design and implementation of WEDAGEN. It also gives a detailed description of its system components and the strategy to generate synthetic web databases. A formal analysis of the generated web database and an empirical assessment of WEDAGEN has been reported.","Synthetic web data generation, Web warehousing, Web database performance",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Huang J,Zhu Q,Yang L,Cheng D,Wu Q",,A novel outlier cluster detection algorithm without top-n parameter,Knowledge-Based Systems,2017,121,,32-40,,,,,2017,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705117300254;http://dx.doi.org/10.1016/j.knosys.2017.01.013,10.1016/j.knosys.2017.01.013,"Outlier detection is an important task in data mining with numerous applications, including credit card fraud detection, video surveillance, etc. Outlier detection has been widely focused and studied in recent years. The concept about outlier factor of object is extended to the case of cluster. Although many outlier detection algorithms have been proposed, most of them face the top-n problem, i.e., it is difficult to know how many points in a database are outliers. In this paper we propose a novel outlier cluster detection algorithm called ROCF based on the concept of mutual neighbor graph and on the idea that the size of outlier clusters is usually much smaller than the normal clusters. ROCF can automatically figure out the outlier rate of a database and effectively detect the outliers and outlier clusters without top-n parameter. The formal analysis and experiments show that this method can achieve good performance in outlier detection.","Outlier detection, Outlier clusters, Top-n problem, Mutual neighbor",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gao L,Ma M,Shu Y,Wei Y",,An ultralightweight RFID authentication protocol with CRC and permutation,Journal of Network and Computer Applications,2014,41,,37-46,,,,,2014,,1084-8045,https://www.sciencedirect.com/science/article/pii/S1084804513002269;http://dx.doi.org/10.1016/j.jnca.2013.10.014,10.1016/j.jnca.2013.10.014,"Radio Frequency Identification (RFID) technology will become one of the most popular technologies to identify objects in the near future. However, the major barrier that the RFID system is facing presently is the security and privacy issue. Recently, an ultralightweight RFID authentication protocol with permutation has been proposed to provide security and prevent all possible attacks. However, it is discovered that a type of desynchronization attack can successfully break the proposed scheme. To overcome the vulnerability under the desynchronization attacks, we propose an approximate ultralightweight RFID authentication protocol which integrates the operation of the XOR operator, build-in CRC-16 function, the permutation and secret key backup technology to improve the security functions without increasing any security cost. We formally verify the security functionality of the proposed scheme by using Simple Promela Interpreter (SPIN). Analysis shows that our proposal has a strong ability to prevent existing possible attacks.","RFID, Ultralightweight, Permutation, Desynchronization, SPIN",,,,,,,,,,,,,,,,,,,,,
Journal Article,Sawin SF,,Invariants of Spin Three-Manifolds From Chern–Simons Theory and Finite-Dimensional Hopf Algebras,Advances in Mathematics,2002,165,1,35-70,,,,,2002,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870800919352;http://dx.doi.org/10.1006/aima.2000.1935,10.1006/aima.2000.1935,"A version of Kirby calculus for spin and framed three-manifolds is given and is used to construct invariants of spin and framed three-manifolds in two situations. The first is ribbon *-categories which possess odd degenerate objects. This case includes the quantum group situations corresponding to the half-integer level Chern–Simons theories conjectured to give spin TQFTs by Dijkgraaf and Witten (1990, Commun. Math. Phys.129, 393–429). In particular, the spin invariants constructed by Kirby and Melvin (1991, Invent. Math.105, 473–545) are shown to be identical to the invariants associated to SO(3). Second, an invariant of spin manifolds analogous to the Hennings invariant is constructed beginning with an arbitrary factorizable, unimodular quasitriangular Hopf algebra. In particular a framed manifold invariant is associated to every finite-dimensional Hopf algebra via its quantum double, and is conjectured to be identical to Kuperberg's noninvolutory invariant of framed manifolds associated to that Hopf algebra.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Spencer M,Takahashi N,Chakraborty S,Miles J,Shyu CR",,Heritable genotype contrast mining reveals novel gene associations specific to autism subgroups,Journal of Biomedical Informatics,2018,77,,50-61,,,,,2018,,1532-0464,https://www.sciencedirect.com/science/article/pii/S1532046417302708;http://dx.doi.org/10.1016/j.jbi.2017.11.016,10.1016/j.jbi.2017.11.016,"Though the genetic etiology of autism is complex, our understanding can be improved by identifying genes and gene-gene interactions that contribute to the development of specific autism subtypes. Identifying such gene groupings will allow individuals to be diagnosed and treated according to their precise characteristics. To this end, we developed a method to associate gene combinations with groups with shared autism traits, targeting genetic elements that distinguish patient populations with opposing phenotypes. Our computational method prioritizes genetic variants for genome-wide association, then utilizes Frequent Pattern Mining to highlight potential interactions between variants. We introduce a novel genotype assessment metric, the Unique Inherited Combination support, which accounts for inheritance patterns observed in the nuclear family while estimating the impact of genetic variation on phenotype manifestation at the individual level. High-contrast variant combinations are tested for significant subgroup associations. We apply this method by contrasting autism subgroups defined by severe or mild manifestations of a phenotype. Significant associations connected 286 genes to the subgroups, including 193 novel autism candidates. 71 pairs of genes have joint associations with subgroups, presenting opportunities to investigate interacting functions. This study analyzed 12 autism subgroups, but our informatics method can explore other meaningful divisions of autism patients, and can further be applied to reveal precise genetic associations within other phenotypically heterogeneous disorders, such as Alzheimer’s disease.","Data mining, Autistic disorder, Genetics, Frequent pattern mining",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chockler G,Gilbert S,Gramoli V,Musial PM,Shvartsman AA",,Reconfigurable distributed storage for dynamic networks,Journal of Parallel and Distributed Computing,2009,69,1,100-116,,,,,2009,,0743-7315,https://www.sciencedirect.com/science/article/pii/S0743731508001317;http://dx.doi.org/10.1016/j.jpdc.2008.07.007,10.1016/j.jpdc.2008.07.007,"This paper presents a new algorithm for implementing a reconfigurable distributed shared memory in an asynchronous dynamic network. The algorithm guarantees atomic consistency (linearizability) in all executions in the presence of arbitrary crash failures of the processing nodes, message delays, and message loss. The algorithm incorporates a classic quorum-based algorithm for read/write operations, and an optimized consensus protocol, based on Fast Paxos for reconfiguration, and achieves the design goals of: (i) allowing read and write operations to complete rapidly and (ii) providing long-term fault-tolerance through reconfiguration, a process that evolves the quorum configurations used by the read and write operations. The resulting algorithm tolerates dynamism. We formally prove our algorithm to be correct, we present its performance and compare it to existing reconfigurable memories, and we evaluate experimentally the cost of its reconfiguration mechanism.","Distributed algorithms, Reconfiguration, Atomic objects, Performance",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Masmoudi N,Nakanishi K",,From the Klein–Gordon–Zakharov system to a singular nonlinear Schrödinger system,"Annales de l'Institut Henri Poincaré C, Analyse non linéaire",2010,27,4,1073-1096,,,,,2010,,0294-1449,https://www.sciencedirect.com/science/article/pii/S0294144910000211;http://dx.doi.org/10.1016/j.anihpc.2010.02.002,10.1016/j.anihpc.2010.02.002,"In this paper, we continue our investigation of the high-frequency and subsonic limits of the Klein–Gordon–Zakharov system. Formally, the limit system is the nonlinear Schrödinger equation. However, for some special case of the parameters going to the limits, some new models arise. The main object of this paper is the derivation of those new models, together with convergence of the solutions along the limits. Résumé Dans cet article, on continue l'investigation des limites haute fréquence et subsonique du système de Klein–Gordon–Zakharov. Formellement, le système limite est le système de Schrödinger nonlinéaire. Cependant, pour un cas particulier des paramètres, on trouve un nouveau modèle qui contient un terme singulier. L'objet de ce papier est de donner une dérivation rigoureuse de ce modèle et de montrer la convergence dans l'espace d'énergie.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ray N,Schmitt W",,Combinatorial Models for Coalgebraic Structures,Advances in Mathematics,1998,138,2,211-262,,,,,1998,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870898917236;http://dx.doi.org/10.1006/aima.1998.1723,10.1006/aima.1998.1723,"We introduce a convenient category of combinatorial objects, known as cell-sets, on which we study the properties of the appropriate free abelian group functor. We obtain a versatile generalization of the notion of incidence coalgebra, giving rise to an abundance of coalgebras, Hopf algebras, and comodules, all of whose structure constants are positive integers with respect to certain preferred bases. Our category unifies and extends existing constructions in algebraic combinatorics, providing proper functorial descriptions; it is inspired in part by the notion of CW-complex, and is also geared to future applications in algebraic topology and the theory of formal group laws.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ghani N,Hancock P,Pattinson D",,Continuous Functions on Final Coalgebras,Electronic Notes in Theoretical Computer Science,2009,249,,3-18,,,,,2009,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610900303X;http://dx.doi.org/10.1016/j.entcs.2009.07.081,10.1016/j.entcs.2009.07.081,"In a previous paper we gave a representation of, and simultaneously a way of programming with, continuous functions on streams, whether discrete-valued functions, or functions between streams. We also defined a combinator on the representations of such continuous functions that reflects composition. Streams are one of the simplest examples of non-trivial final coalgebras. Here we extend our previous results to cover the case of final coalgebras for a broader class of functors than that giving rise to streams. Among the functors we can deal with are those that arise from countable signatures of finite-place untyped operators. These have many applications. The topology we put on the final coalgebra for such a functor is that induced by taking for basic neighbourhoods the set of infinite objects which share a common ‘prefix’, a la Baire space. The datatype of prefixes is defined together with the set of ‘growth points’ in a prefix, simultaneously. This we call beheading. To program and reason about representations of continuous functions requires a language whose type system incorporates the dependent function and pair types, inductive definitions at types Set, I→Set and (ΣI:Set)SetI, coinductive definitions at types Set and I→Set, as well as universal arrows for such definitions.","Continuous functions, final coalgebras, containers",Proceedings of the 25th Conference on Mathematical Foundations of Programming Semantics (MFPS 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Bhandarkar SM,Suk M",,Sensitivity analysis for matching and pose computation using dihedral junctions,Pattern Recognition,1991,24,6,505-513,,,,,1991,,0031-3203,https://www.sciencedirect.com/science/article/pii/003132039190017Y;http://dx.doi.org/10.1016/0031-3203(91)90017-Y,10.1016/0031-3203(91)90017-Y,"Recognition-via-localization is a popular approach in 3-D object recognition. This approach relies on the propagation of constraints that arise from the matches of local geometric features and could therefore be treated as a constraint satisfaction problem. Hough clustering, which verifies the consistency of local geometric constraints by determining the pose of the object in parameter space, is a popular technique owing to its conceptual simplicity and potential ease of parallelization. Our previous work has shown the usefulness of dihedral junctions for the recognition and localization of polyhedral objects and dihedral feature junctions for the recognition and localization of curved objects made up of piecewise combinations of conical, cylindrical and spherical surfaces. Experimental results from our previous work showed that the computed pose parameters are sensitive to the difference in the included angle between the scene and model dihedral junctions or the scene and model dihedral feature junctions. A formal analysis of the sensitivity of the computed pose to the difference in the included angle between the scene and model dihedral junctions or the scene and model dihedral feature junctions is presented in this paper. The results of the formal sensitivity analysis were found to be in conformity with the experimental results from our previous work and so the work presented in this paper could be treated as a sequel to our previous work. Based on the results of the sensitivity analysis, the rotation parameters were found to be more sensitive than the translation parameters which, in comparison, were far more robust. It is also shown how the introduction of redundancy in parameter space results in greater robustness in the computed pose. Although the analysis in this paper is based on the matching of dihedral junctions or dihedral feature junctions, the approach taken in the sensitivity analysis is general and can be applied to the matching based on other feature types.","Model-based vision, Pose clustering, Pose computation, Sensitivity analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,Szymanek AH,,Vector model of danger,Reliability Engineering & System Safety,1992,37,1,65-71,,,,,1992,,0951-8320,https://www.sciencedirect.com/science/article/pii/095183209290060X;http://dx.doi.org/10.1016/0951-8320(92)90060-X,10.1016/0951-8320(92)90060-X,"In this paper a mathematical model is described in which the danger to any real object is interpreted as a vector in a given vector space. This model also provides mathematical interpretations of danger speed as well as danger field, notions which can broaden the range of safety science. The model presented is intended to give a solid base of formal language to system safety theory. This paper includes an example of the vector interpretation of danger, and the possibility of mathematical description of danger in various human activities and natural systems.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cremers AB,Hibbard TN",,On the formal definition of dependencies between the control and information structure of a data space,Theoretical Computer Science,1977,5,2,113-128,,,,,1977,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397577900020;http://dx.doi.org/10.1016/0304-3975(77)90002-0,10.1016/0304-3975(77)90002-0,"A data space is a general mathematical model for data types with a dynamic component (procedures). It consists of a set of objects (states), a set of functions for describing the information aspects of these objects, together with a control, i.e. a function mapping objects into objects. A set of properties is given which specify the formal relationship among the constituent components of a data space. The results of this paper especially concern the dependency between information structuring and control structuring. The mathematical analysis of this relationship is enhanced by focussing on the structure of so-called dependency sets, i.e. sets of objects which reflect the underlying control structure. The paper develops techniques for constructing meaningful dependency sets.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Blute R,Cockett R,Jacqmin PA,Scott P",,Finiteness Spaces and Generalized Power Series,Electronic Notes in Theoretical Computer Science,2018,341,,5-22,,,,,2018,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066118300823;http://dx.doi.org/10.1016/j.entcs.2018.11.002,10.1016/j.entcs.2018.11.002,"We consider Ribenboim's construction of rings of generalized power series. Ribenboim's construction makes use of a special class of partially ordered monoids and a special class of their subsets. While the restrictions he imposes might seem conceptually unclear, we demonstrate that they are precisely the appropriate conditions to represent such monoids as internal monoids in an appropriate category of Ehrhard's finiteness spaces. Ehrhard introduced finiteness spaces as the objects of a categorical model of classical linear logic, where a set is equipped with a class of subsets to be thought of as finitary. Morphisms are relations preserving the finitary structure. The notion of finitary subset allows for a sharper analysis of computational structure than is available in the relational model. For example, fixed point operators fail to be finitary. In the present work, we take morphisms to be partial functions preserving the finitary structure rather than relations. The resulting category is symmetric monoidal closed, complete and cocomplete. Any pair of an internal monoid in this category and a ring induces a ring of generalized power series by an extension of the Ribenboim construction based on Ehrhard's notion of linearization of a finiteness space. We thus further generalize Ribenboim's constructions. We give several examples of rings which arise from this construction, including the ring of Puiseux series and the ring of formal power series generated by a free monoid.","Power series, finiteness space, linearization, poset, artinian poset, narrow poset, partially ordered monoid, Puiseux series, partial function",Proceedings of the Thirty-Fourth Conference on the Mathematical Foundations of Programming Semantics (MFPS XXXIV),,,,,,,,,,,,,,,,,,,,
Journal Article,Knop F,,Tensor envelopes of regular categories,Advances in Mathematics,2007,214,2,571-617,,,,,2007,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870807000722;http://dx.doi.org/10.1016/j.aim.2007.03.001,10.1016/j.aim.2007.03.001,"We extend the calculus of relations to embed a regular category A into a family of pseudo-abelian tensor categories T(A,δ) depending on a degree function δ. Assume that all objects have only finitely many subobjects. Then our results are as follows:1.Let N be the maximal proper tensor ideal of T(A,δ). We show that T(A,δ)/N is semisimple provided that A is exact and Mal'cev. Thereby, we produce many new semisimple, hence abelian, tensor categories.2.Using lattice theory, we give a simple numerical criterion for the vanishing of N.3.We determine all degree functions for which T(A,δ)/N is Tannakian. As a result, we are able to interpolate the representation categories of many series of profinite groups such as the symmetric groups Sn, the hyperoctahedral groups Sn⋉Z2n, or the general linear groups GL(n,Fq) over a fixed finite field. This paper generalizes work of Deligne, who first constructed the interpolating category for the symmetric groups Sn.","Tensor categories, Semisimple categories, Regular categories, Mal'cev categories, Tannakian categories, Möbius function, Lattices, Profinite groups",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Wigdor D,Wixon D","Wigdor D,Wixon D",Chapter 19 - Properties of a Gesture Language,,2011,,,137-144,,Morgan Kaufmann,Boston,Brave NUI World,2011,9780123822314,,https://www.sciencedirect.com/science/article/pii/B9780123822314000198;http://dx.doi.org/10.1016/B978-0-12-382231-4.00019-8,10.1016/B978-0-12-382231-4.00019-8,"Publisher Summary This chapter deals with the gesture language and its properties. A gesture language is a communication system. Its language depends on its fundamental clarity and its overall coherence. One can apply genetic epistemology of cognition to any gestural system. The developmental stage of formal operations is characterized by the following four properties: Identity (I), Negation (N), Reciprocal (R), and Commutative (identity of groups) (C). The chapter applies some of the concepts from Piaget's concepts of genetic epistomology to the design of a touch-based system. It seems logical to apply some well-accepted concepts of developmental psychology to understand a system. In part, any NUI presents a new world for the user. It is natural, in the sense that it supports skilled and fluid practice and does not require that objects and operations be formalized into abstractions.","Identity, negation, reciprocal, commutative, mathematics, Piaget",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Sageng E,"Grattan-Guinness I,Cooke R,Corry L,Crépel P,Guicciardini N","Chapter 10 - Colin Maclaurin, A treatise of fluxions (1742)",,2005,,,143-158,,Elsevier Science,Amsterdam,Landmark Writings in Western Mathematics 1640-1940,2005,9780444508713,,https://www.sciencedirect.com/science/article/pii/B9780444508713500917;http://dx.doi.org/10.1016/B978-044450871-3/50091-7,10.1016/B978-044450871-3/50091-7,"Publisher Summary MacLaurin provided a rigorous foundation for the method of fluxions based on a limit concept drawn from Archimedian classical geometry. He went on to demonstrate that the method so founded would support the entire received structure of fluxions and the calculus, and to make advances that were taken up by continental analysts. In 1734 George Berkeley had published The Analyst. Besides objecting to particular demonstrations and procedures, Berkeley's criticism of the method of fluxions amounted to the well substantiated assertion that it was founded inescapably either on infinitesimals or on a shifting of hypotheses, both of which were logically indefensible. The Treatise was generally cited by British fluxionists as the definitive answer to Berkeley's criticism, but MacLaurin had accomplished much more than this. MacLaurin's work was cited with admiration by Lagrange, Euler, Clairaut, d’Alembert, Laplace, Legendre, Lacroix, and Gauss. The influence of MacLaurin's use of the algebra of inequalities as a basis for his limit arguments can be seen in d’Alembert, L’Huilier, Lacroix and Cauchy.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Comito C,,NexT: A framework for next-place prediction on location based social networks,Knowledge-Based Systems,2020,204,,106205,,,,,2020,,0950-7051,https://www.sciencedirect.com/science/article/pii/S095070512030424X;http://dx.doi.org/10.1016/j.knosys.2020.106205,10.1016/j.knosys.2020.106205,"The extensive use of location-based social networks (LBSNs) allows for the collection of huge amount of geo-tagged data about people activities and costumes within urban context, including human mobility regularities. In this context, predicting the future position of a mobile object is the key for the implementations of several applications aiming at improving mobility within urban areas (e.g., traffic congestion, location-based advertisements). The paper proposes NexT, a next-place prediction framework, which exploits LBSNs data to forecast the next location of an individual based on the observations of her mobility behavior over some period of time and the recent locations that she has visited (individuals typical mobility routines) and on global mobility in the considered geographic area (e.g., mobility routines of all the Twitter users). The approach integrates frequent pattern mining and feature-based supervised classification, exploiting a set of spatio-temporal features characterizing locations and movements among them. The features are combined into a decision tree prediction model. The experimental evaluation, performed on real-world tweets shows the effectiveness and efficiency of the approach in predicting users next places, achieving a remarkable accuracy and prediction rate, outperforming state-of-the art approaches.","Next-place prediction, Trajectory pattern mining, LBSN",,,,,,,,,,,,,,,,,,,,,
Journal Article,Gardiner P,,Power simulation and its relation to traces and failures refinement,Theoretical Computer Science,2003,309,1,157-176,,,,,2003,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397503002007;http://dx.doi.org/10.1016/S0304-3975(03)00200-7,10.1016/S0304-3975(03)00200-7,"There are two quite distinct approaches commonly used when giving meaning to process algebra expressions: an operational semantics, often associated with the CCS language, defines an equivalence between terms by considering whether each can simulate the other; a denotational semantics, often associated with CSP, provides a mapping, recursively defined over the structure of the language, taking each term into a carefully chosen collection of set-theoretic objects. (The traces and failures models are well-known examples of such semantic domains.) We present a formal link between the two approaches, consisting in defining a variant of the bisimulation equivalence that naturally gives rise to the traces and failures ordering. We have no way at present to extend this result to the failures/divergence model.","Program semantics, Bisimulation, Failures, Unification, Predicate transformer",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gogolla M,Ziemann P,Kuske S",,Towards an Integrated Graph Based Semantics for UML,Electronic Notes in Theoretical Computer Science,2003,72,3,160-175,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104806194;http://dx.doi.org/10.1016/S1571-0661(04)80619-4,10.1016/S1571-0661(04)80619-4,"Recently, we proposed an integrated formal semantics based on graph transformation for central aspects of UML class, object and state diagrams. In this paper, we explain the basic ideas of that approach and show how two more UML diagram types, sequence and collaboration diagrams, can be captured. For UML models consisting of a class diagram and particular state diagrams, a graph transformation system can be defined. Its graphs are associated with system states and its rules with operations in the class diagram and transitions in the state diagrams. Sequence and collaboration diagrams then characterize sequences of operation applications and therefore sequences of transformation rule applications. Thus valid sequence and collaboration diagrams correspond to derivations induced by the graph transformation system. Proceeding this way, it can be checked for example whether such an operation application sequence may be applied in a specific system state.",,"GT-VMT'2002, Graph Transformation and Visual Modeling Techniques (First International Conference on Graph Transformation)",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Dubes R,Jain AK",Yovits MC,Clustering Methodologies in Exploratory Data Analysis,,1980,19,,113-228,,Elsevier,,,1980,,0065-2458,https://www.sciencedirect.com/science/article/pii/S0065245808600340;http://dx.doi.org/10.1016/S0065-2458(08)60034-0,10.1016/S0065-2458(08)60034-0,"Publisher Summary This chapter reviews cluster analysis and related topics or the formal study of classification schemata, whereby objects are grouped, or clustered, according to measured or perceived intrinsic characteristics. The objective of a cluster analysis is to uncover natural groupings, or types, to prod one's creativity and ingenuity, and initiate hypotheses about the phenomenon being studied. Cluster analysis has a heuristic nature that encourages the exploration of data. Taxonomists, social scientists, psychologists, biologists, statisticians, mathematicians, engineers, computer scientists, medical researchers, and others who handle real data have all contributed to clustering methodology. The chapter presents cross-disciplinary communication so that one application area can profit from the experiences of others. The literature of cluster analysis straddles all quantitative, scientific disciplines, as demonstrated by the remarkable variety. Emphasis is on new developments, especially in the verification and validation of clustering results. The intent is to provide an applications-oriented treatment of cluster analysis in the spirit of exploratory data analysis. The chapter focuses on the four operations highlighted by reviewing techniques for assessing the tendency of the data to cluster, performing the clustering itself, and evaluating the validity of the results. Data representation includes recognition of data type and scale, measures of proximity and affinity, normalization, various two-dimensional projections of data, methods of visualizing multidimensional data, techniques for creating scales to describe data, and related matters. The chapter introduces the concept of intrinsic dimensionality that helps determine an appropriate number of factors for representing data. The chapter recommends that a serious data analyst be conversant with as broad a range of data analysis techniques and programs as possible and be aware of the assumptions on which the techniques are based.",,,Advances in Computers,,,,,,,,,,,,,,,,,,,
Journal Article,"Morris KC,Flater D",,"Design of a flexible, integrated testing system for STEP and OMG standards",Computer Standards & Interfaces,2000,22,5,297-305,,,,,2000,,0920-5489,https://www.sciencedirect.com/science/article/pii/S092054890000057X;http://dx.doi.org/10.1016/S0920-5489(00)00057-X,10.1016/S0920-5489(00)00057-X,"New software standards supporting integration of manufacturing and engineering systems are emerging at a rapid pace. Two groups, the Object Management Group (OMG) and the community producing the Standard for the Exchange of Product Model Data (STEP, formally known as ISO 10303), dominate in the production of standards for manufacturing and engineering industries. Their standards are based on common methods, which can be exploited in developing tests for systems supporting the standards. This paper describes the methods employed and a system that builds on those methods to support the automatic and rapid development of conformance tests for the emerging standards.","Conformance testing, Manufacturing, Software, Standards",,,,,,,,,,,,,,,,,,,,,
Journal Article,Coen G,,Database Lexicography,Data & Knowledge Engineering,2002,42,3,293-314,,,,,2002,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X02000526;http://dx.doi.org/10.1016/S0169-023X(02)00052-6,10.1016/S0169-023X(02)00052-6,"This paper introduces database lexicography, a metadata analysis discipline that applies lexical graph theory to data design. Database lexicography proposes a formal design criterion for data dependencies, and it provides metrics to evaluate the conformance of designs to this criterion. It treats the data dictionary as a first class object encoding design concepts, and its benefits include identification of database dependency architecture; quantification of interdependent data elements' sensitivity to change; categorization of core and peripheral data elements; model integration; and figures of merit by which to fortify data architectures to withstand design fossilization and guide their evolution amidst changing requirements.","Database lexicography, Lexical graph, Data dictionary, Model integration",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Feito FR,Rivero M",,Geometric modelling based on simplicial chains,Computers & Graphics,1998,22,5,611-619,,,,,1998,,0097-8493,https://www.sciencedirect.com/science/article/pii/S0097849398000673;http://dx.doi.org/10.1016/S0097-8493(98)00067-3,10.1016/S0097-8493(98)00067-3,"In this work we present a mathematical formulation for geometric modelling which may be applied in spaces of any dimension. The model can be seen as an example of a graphic object algebra [see Torres, J. C. and Clares, B., Graphics objects: a mathematical abstract model for computer graphics. Computer Graphics Forum, 1993, 12(5), 311–328 and Feito, F. R. and Torres, J. C., Boundary representation of polyhedral heterogenous solids in the context of a graphics objects algebra. The Visual Computer, 1997, 13(2), 64–77]. It is based on the concept of simplicial chain which is considered a particular case of the polyhedral chains presented by Whitney (Geometric Integration Theory, Princeton University Press, Princeton, NJ, 1957). From the algebraic operations with simplicial chains we can obtain any element of the general polyhedral solids (manifold and non-manifold). Similarly, from the defined operations with chains, we can obtain the usual operations of geometric modelling (union, intersection and difference). So, the model can be considered a new scheme of representation of solids based on simplician chains. One of its uses is to obtain the usual operations of geometric modelling by means of operations with simplices (triangles, tetrahedra, etc) which are simple elements.","mathematical modelling, geometric modelling, simplices, formal methods in computer graphics",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cox PT,Smedley TJ",,A Formal Model for Parameterized Solids in a Visual Design Language,Journal of Visual Languages & Computing,2000,11,6,687-710,,,,,2000,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X00901745;http://dx.doi.org/10.1006/jvlc.2000.0174,10.1006/jvlc.2000.0174,"Software for designing structured objects such as machinery and buildings originated from drawing or drafting, and has evolved into suites of applications for different aspects of design. Modern CAD software usually consists of sophisticated tools for graphically building multidimensional models, together with textual programming languages for dealing with tasks such as specifying parameterized constructs or complex relationships between components. This dichotomy between design with graphics and programming with text divides the users of such systems into two groups with quite different skills. Programming languages, on the other hand, have evolved in the opposite direction, from purely textual descriptions of algorithms and data, to formalisms that rely primarily on graphics. This has led to the conjecture that the usability of design software might be improved by replacing their textual programming facilities by visual programming. Previously, we presented a preliminary proposal for a design language LSD that uses a visual representation of logic programming to provide a homogeneous view of design objects and the operations that transform them. In the current work, we present a model that captures the essential features of solids and operations on solids in a design space, then generalize LSD based on this model.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Schamp M,Ginste L,Hoedt S,Claeys A,Aghezzaf EH,Cottyn J",,Virtual Commissioning of Industrial Control Systems - a 3D Digital Model Approach,Procedia Manufacturing,2019,39,,66-73,,,,,2019,,2351-9789,https://www.sciencedirect.com/science/article/pii/S2351978920302766;http://dx.doi.org/10.1016/j.promfg.2020.01.229,10.1016/j.promfg.2020.01.229,"With the growing presence of industry 4.0, flexible workstations and distributed control logic, software development has become an even more important part of the automation engineering process than before. In a traditional workflow, the main commissioning part of industrial control systems is performed on the real set-up and consequently during a time critical phase of the project. Virtual commissioning can be used to reduce the real commissioning time and can allow an earlier commissioning start, reducing the overall project lead time, risk of damaging parts, amount of rework and cost of error correction. Previous research showed already a reduction potential of the real commissioning time by 73%, when using a virtual commissioning strategy based on a 3D digital model. However, the robustness of that approach still highly depends on the human expertise to fully evaluate the correct behavior in all possible use scenarios. This paper describes an approach to further automate these virtual commissioning steps by embedding functional specifications and use scenarios through a formal notation inside the 3D digital model. Configuration steps inside the virtual environment describe the conditions, independent from the control logic but related to component states and transitions in the digital model (actuator and sensor values, time restrictions, counters, positions of objects, etc.). These conditions are continuously monitored during an extensive commissioning run of the digital model covering all possible component states and transitions. A small scale experiment will show the reduction of the virtual commissioning time and earlier detection of quality issues.","Virtual commissioning, 3D digital model, Industrial control system, Functional specification, Use scenarios","25th International Conference on Production Research Manufacturing Innovation: Cyber Physical Manufacturing August 9-14, 2019 | Chicago, Illinois (USA)",,,,,,,,,,,,,,,,,,,,
Journal Article,Worboys M,,Relational databases: a theoretical primer,Information and Software Technology,1989,31,3,115-122,,,,,1989,,0950-5849,https://www.sciencedirect.com/science/article/pii/095058498990102X;http://dx.doi.org/10.1016/0950-5849(89)90102-X,10.1016/0950-5849(89)90102-X,"As a result of their tight and simple formal underpinning, relational techniques are suitable for application to a wide range of systems. Within the database community, relational databases have become the dominant type. There are now several comprehensive products on the market that meet many of the requirements of a truly relational system, and relational methods appear to be ever more extensively used. Relational techniques also have the advantage that they interlock well with standard design methodologies and to newer ideas, such as object modelling approaches. The aim of the paper is to provide a concise and theoretically based introduction to relational databases, both in their design and in the manipulation of data that they contain. The formal development proceeds in parallel with the progression of an extended example.","relational databases, SQL, relational algebra, normalization",,,,,,,,,,,,,,,,,,,,,
Journal Article,Ng W,,Ordered functional dependencies in relational databases,Information Systems,1999,24,7,535-554,,,,,1999,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437999000319;http://dx.doi.org/10.1016/S0306-4379(99)00031-9,10.1016/S0306-4379(99)00031-9,"We extend the relational data model to incorporate linear orderings into data domains, which we call the ordered relational model. The conventional Functional Dependencies (FDs) are examined in the context of ordered relational databases by using the notion of System Ordering Independence (SOI), which refers to the desirable scenario that the ordering of tuples in a relation is independent of the implementation of the underlying DBMS. We also extend Armstrong's axiom system for FDs to object relations, which are a subclass of ordered relations that allow us to view tuples as objects. We formally define Ordered Functional Dependencies (OFDs) for the extended model by means of two possible extensions of domains, pointwise-orderings and lexicographical orderings. We first present a sound and complete axiom system for OFDs in the case of pointwise-orderings and then establish a sound and complete set of chase rules for OFDs in the case of lexicographical orderings. Our main result shows that the implication problems for both cases of OFDs are decidable, and that it is linear time for the case of pointwise-orderings.","Functional Dependencies, Relational Databases, Linear Ordering, Linearly Ordered Domains, Chase Procedure",,,,,,,,,,,,,,,,,,,,,
Journal Article,Zieliński C,,Description of semantics of robot programming languages,Mechatronics,1992,2,2,171-198,,,,,1992,,0957-4158,https://www.sciencedirect.com/science/article/pii/095741589290030R;http://dx.doi.org/10.1016/0957-4158(92)90030-R,10.1016/0957-4158(92)90030-R,"The paper presents a formal method of defining semantics of robot programming language (RPL) instructions. These languages are divided into three levels: joint, manipulator and object level. As a criterion of this division, the abstract notion, that the instructions of the language refer to, is used. Moreover, depending on the precision of semantics definition of a particular language, these languages are classified into three types (point-to-point, bonded-path and continuous-path). The described method is capable of defining semantics of instructions independently of the type or the level of the considered language. To achieve this a concept of virtual environment is introduced. The description of the state of the system, consisting of the virtual environment, data base, variables and program control flow subsystem, is considered on each level. The object level languages are dealt with in particular detail. The attributes of the objects as well as the relations occurring between them are taken into account. Furthermore the method does not depend on the type of the industrial robot used.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Krotov VF,Kurzhanski AB",,National achievements in control theory: The aerospace perspective,Annual Reviews in Control,2005,29,1,13-31,,,,,2005,,1367-5788,https://www.sciencedirect.com/science/article/pii/S1367578805000064;http://dx.doi.org/10.1016/j.arcontrol.2005.01.002,10.1016/j.arcontrol.2005.01.002,"It is well known that among the first motivations for modern control theory were dynamic optimization problems in rocket launching and navigation in aerospace. These problems had become especially important in the 1940s and 1950s due to requirement to minimize various costly resources and design parameters, such as flight time, amount (mass) of fuel, weight of the spacecraft, the drag forces and other items. This had to be done under various restrictions on control capacities and other complicating factors, such for example, as incomplete information on the system. Among the precious techniques of applied mathematics there had long been developed an adequate tool for such problems which is the Calculus of Variations. Problems in flight dynamics had become the earliest serious technical object for its application. A large number of new basic ideas for adapting Calculus of Variations to modern control problems and synthesizing them into modern control theory were elaborated in the course of investigations in flight dynamics. This presentation traces some seminal investigations, which were crucial for related theoretical developments in former Soviet Union and present Russia and had also influenced related research beyond national borders. Such investigations had good historical precursors in the earlier mathematical works of P.L. Chebyshev, A.M. Lyapunov, A.A. Markov, the works in mechanics by N.E. Zhukovski and S.A. Chaplygin and the activities in dynamic systems theory of the 1930s (A.A. Andronov, L.S. Pontryagin, et al.). The present paper is confined only to deterministic problems in trajectory analysis, control and optimization within the framework of mathematical theory of controlled processes. The national community of researchers involved in these topics was enormous, including those in the Academy of Sciences, the Universities and the numerous institutions and plants supervised by related industrial ministries. While giving tribute to all those involved, this paper does not claim to give a full review of available publications, concentrating on what the authors believe to be the seminal issues in the field. This publication will therefore inevitably have a subjective flavor. We sincerely apologize to all those whose contributions may have been missed.","Control theory, Aerospace, Flight dynamics, Trajectory analysis, Navigation, Research history, Control synthesis, Optimization, Optimality conditions, Singular solutions, Uncertain dynamics, Measurement feedback",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Banditwattanawong T,Masdisornchote M",,On formulation of online algorithm and framework of near-optimally tractable eviction for nonuniform caches,Computer Networks,2020,178,,107332,,,,,2020,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128620301870;http://dx.doi.org/10.1016/j.comnet.2020.107332,10.1016/j.comnet.2020.107332,"Distributed data sharing in Internet, social, and cloud computing paradigms incurs nonuniform costs such as consumed downstream bandwidth, downloading delays, and cloud-data-out monetary charges. To alleviate such costs, caches have been widely deployed and researched to find efficient online-cache-eviction algorithms. However, existing online algorithms have no offline foundation, thus they are far from a global optimum. This paper proposes a framework for developing an online cache eviction algorithm, which is grounded in a near-optimally and tractably offline algorithm namely Shortest Maximum Forward Distance (SMFD). On the formulation of the framework, the near-optimality and tractability properties of existing offline algorithms were evaluated through the formal evaluation of the optimality and computational tractability based upon variable object costs. Subsequently, the lowest-complexity suboptimal schemes were empirically investigated to seek a near-optimal offline one, which appears to be SMFD. Also, the results originally show that SMFD and its variant can practically achieve multiple conventionally upper bounds of limitless cache sizes in a stable and simultaneous manner. SMFD was then transformed into novel online SMFD by quantifying the offline property, maximum forward distance, of SMFD with cache-scope time-to-live approximation. To guarantee the effectiveness of online SMFD over evolving request streams, a safety bound guideline and a cache-scope time-to-live distribution model are also proposed. Finally, experience on the framework was gained via experiments based on deep-neural-network models.","Cost saving ratio, Nonuniformity, Offline cache eviction, Time-to-live, Deep neural network",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gonçalves MA,Moreira BL,Fox EA,Watson LT",,“What is a good digital library?” – A quality model for digital libraries,Information Processing & Management,2007,43,5,1416-1437,,,,,2007,,0306-4573,https://www.sciencedirect.com/science/article/pii/S030645730600197X;http://dx.doi.org/10.1016/j.ipm.2006.11.010,10.1016/j.ipm.2006.11.010,"In this article, we elaborate on the meaning of quality in digital libraries (DLs) by proposing a model that is deeply grounded in a formal framework for digital libraries: 5S (Streams, Structures, Spaces, Scenarios, and Societies). For each major DL concept in the framework we formally define a number of dimensions of quality and propose a set of numerical indicators for those quality dimensions. In particular, we consider key concepts of a minimal DL: catalog, collection, digital object, metadata specification, repository, and services. Regarding quality dimensions, we consider: accessibility, accuracy, completeness, composability, conformance, consistency, effectiveness, efficiency, extensibility, pertinence, preservability, relevance, reliability, reusability, significance, similarity, and timeliness. Regarding measurement, we consider characteristics like: response time (with regard to efficiency), cost of migration (with respect to preservability), and number of service failures (to assess reliability). For some key DL concepts, the (quality dimension, numerical indicator) pairs are illustrated through their application to a number of “real-world” digital libraries. We also discuss connections between the proposed dimensions of DL quality and an expanded version of a workshop’s consensus view of the life cycle of information in digital libraries. Such connections can be used to determine when and where quality issues can be measured, assessed, and improved – as well as how possible quality problems can be prevented, detected, and eliminated.","Quality, Evaluation, Digital libraries, Theory, Information life cycle",Patent Processing,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gómez-Romero J,Serrano MA,García J,Molina JM,Rogova G",,Context-based multi-level information fusion for harbor surveillance,Information Fusion,2015,21,,173-186,,,,,2015,,1566-2535,https://www.sciencedirect.com/science/article/pii/S1566253514000165;http://dx.doi.org/10.1016/j.inffus.2014.01.011,10.1016/j.inffus.2014.01.011,"Harbor surveillance is a critical and challenging part of maritime security procedures. Building a surveillance picture to support decision makers in detection of potential threats requires the integration of data and information coming from heterogeneous sources. Context plays a key role in achieving this task by providing expectations, constraints and additional information for inference about the items of interest. This paper proposes a fusion system for context-based situation and threat assessment with application to harbor surveillance. The architecture of the system is organized in two levels. The lowest level uses an ontological model to formally represent input data and to classify harbor objects and basic situations by deductive reasoning according to the harbor regulations. The higher level applies Belief-based Argumentation to evaluate the threat posed by suspicious vessels. The functioning of the system is illustrated with several examples that reproduce common harbor scenarios.","Context, Higher-level fusion, Ontologies, Belief argumentation system, Maritime surveillance",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Holt RC,Schürr A,Sim SE,Winter A",,GXL: A graph-based standard exchange format for reengineering,Science of Computer Programming,2006,60,2,149-170,,,,,2006,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642305001176;http://dx.doi.org/10.1016/j.scico.2005.10.003,10.1016/j.scico.2005.10.003,"GXL (Graph eXchange Language) is an XML-based standard exchange format for sharing data between tools. Formally, GXL represents typed, attributed, directed, ordered graphs which are extended to represent hypergraphs and hierarchical graphs. This flexible data model can be used for object-relational data and a wide variety of graphs. An advantage of GXL is that it can be used to exchange instance graphs together with their corresponding schema information in a uniform format, i.e. using a common document type specification. This paper describes GXL and shows how GXL is used to provide interoperability of graph-based tools. GXL has been ratified by reengineering and graph transformation research communities and is being considered for adoption by other communities.","Graph exchange language, Graph-based tools, Data interoperability, Reengineering, XML","Special Issue on Software Analysis, Evolution and, Re-engineering",,,,,,,,,,,,,,,,,,,,
Journal Article,Barba E,,Cognitive Point of View in Recursive Design,"She Ji: The Journal of Design, Economics, and Innovation",2019,5,2,147-162,,,,,2019,,2405-8726,https://www.sciencedirect.com/science/article/pii/S2405872618300212;http://dx.doi.org/10.1016/j.sheji.2019.04.003,10.1016/j.sheji.2019.04.003,"The concept of scale is shared between systems science and design and, as a foundational element for systemic design theory and practice, provides a way to connect and share units of analysis between disciplines. To better connect these disciplines and begin a more rigorous, shared investigation of scale and hierarchy, I will illuminate the need and potential of a more explicit use of scale in problem formulation, theory and methods discussion, and design education. By discussing one well-known case study of sustainable design, I demonstrate how the designers’ process can be deconstructed using scale as an organizing concept. I then apply this analytical technique to the mundane example of a cup of coffee, to demonstrate some of the important generalizable properties of multiscale thinking in design. The most notable of these is the notion of cognitive point of view, which is grounded in second-order cybernetics and operates as a construct useful for understanding the dynamics between designer, design process, and designed object. Finally, the article argues that the concepts and topics found here should be taught explicitly to design students in practical ways, and researched formally as a subfield within the systemic design community as a method for recursive design.","Systemic design, Design theory, Systems science, Scale",,,,,,,,,,,,,,,,,,,,,
Journal Article,Lucas PJ,,Analysis of notions of diagnosis,Artificial Intelligence,1998,105,1,295-343,,,,,1998,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370298000812;http://dx.doi.org/10.1016/S0004-3702(98)00081-2,10.1016/S0004-3702(98)00081-2,"Various formal theories have been proposed in the literature to capture the notions of diagnosis underlying diagnostic programs. Examples of such notions are: heuristic classification, which is used in systems incorporating empirical knowledge, and model-based diagnosis, which is used in diagnostic systems based on detailed domain models. Typically, such domain models include knowledge of causal, structural, and functional interactions among modelled objects. In this paper, a new set-theoretical framework for the analysis of diagnosis is presented. Basically, the framework distinguishes between ‘evidence functions’, which characterize the net impact of knowledge bases for purposes of diagnosis, and ‘notions of diagnosis’, which define how evidence functions are to be used to map findings observed for a problem case to diagnostic solutions. This set-theoretical framework offers a simple, yet powerful tool for comparing existing notions of diagnosis, as well as for proposing new notions of diagnosis. A theory of flexible notions of diagnosis, called refinement diagnosis, is proposed and defined in terms of this framework. Relationships with notions of diagnosis known from the literature are investigated.","Diagnostic systems, Semantics of diagnosis, Formal theory of diagnosis",,,,,,,,,,,,,,,,,,,,,
Journal Article,Atanassov K,,Intuitionistic fuzzy logics as tools for evaluation of Data Mining processes,Knowledge-Based Systems,2015,80,,122-130,,,,,2015,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705115000222;http://dx.doi.org/10.1016/j.knosys.2015.01.015,10.1016/j.knosys.2015.01.015,"The Intuitionistic Fuzzy Sets (IFSs), proposed in 1983, are extensions of fuzzy sets. Some years after their introduction, sequentially, intuitionistic fuzzy propositional logic, intuitionistic fuzzy predicate logic, intuitionistic fuzzy modal logic and intuitionistic fuzzy temporal logic have been introduced, presented here shortly. During the last 25years, different intuitionistic fuzzy tools have been used for evaluation of objects from the area of the Artificial Intelligence, as expert systems (having, e.g. facts and rules, with intuitionistic fuzzy degrees of validity and non-validity), decision making processes (having, e.g. intuitionistic fuzzy estimations of the criteria), neural networks, pattern recognitions, metaheuristic algorithms, etc. Short review of these legs of research is offered, with some concrete ideas of possible new directions of study. On this basis, a non-formal discussion is raised on the benefits of applying various elements of intuitionistic fuzzy logics as tools for evaluation of Data Mining processes.","Artificial intelligence, Data Mining, Intuitionistic fuzzy estimation, Intuitionistic fuzzy logics, Intuitionistic fuzzy set",25th anniversary of Knowledge-Based Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,Isbell J,,Some inequalities in hom sets,Journal of Pure and Applied Algebra,1991,76,1,87-110,,,,,1991,,0022-4049,https://www.sciencedirect.com/science/article/pii/002240499190099N;http://dx.doi.org/10.1016/0022-4049(91)90099-N,10.1016/0022-4049(91)90099-N,"Finite sets, finite abelian groups, and a few similar categories satisfy a formal Cauchy inequality: |Hom(X, Y)| · |Hom(Y, X)| ⩽ |Hom(X, X)| · |Hom(Y, Y)|, with equality only if X and Y are isomorphic. For the abelian groups there is a generalization to n objects. In any locally finite category with a factorization system, X is determined by the function |Hom( , X)|.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Combes P,Dubois F,Renard B",,An open animation tool: application to telecommunication systems,Computer Networks,2002,40,5,599-620,,,,,2002,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128602003547;http://dx.doi.org/10.1016/S1389-1286(02)00354-7,10.1016/S1389-1286(02)00354-7,"This paper presents an animation environment based on an open and flexible architecture. Its flexible architecture allows animating different animation sources (formal and executable language like SDL or scenario languages like MSC or UML sequence diagrams). The animation multimedia user interface allows integrating different multimedia objects and different types of representations. This animation environment has been intensively used for telecommunication applications at different levels of a service and network architecture: service animation from the user’s point of view or from the service logic point of view (service logic and service feature logics), protocols and application programming interface (such as OSA/PARLAY) animation, service interaction analysis. Animation helps obtaining a comprehensive and user-friendly interface for education, and investigation of system behaviour from different points of view, in particular from a client point of view. Specifically applied to formal executable models (using SDL, for example), the tool helps checking properties of the system behaviour, and showing whether it really fulfils user expectations.","Animation, Prototyping, Service validation, Protocols, System design, SDL, UML, MSC",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Iwasaki Y,Simon HA",,Causality and model abstraction,Artificial Intelligence,1994,67,1,143-194,,,,,1994,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370294900140;http://dx.doi.org/10.1016/0004-3702(94)90014-0,10.1016/0004-3702(94)90014-0,"Much of science and engineering is concerned with characterizing processes by equations describing the relations that hold among parameters of objects and govern their behavior over time. In formal descriptions of processes in terms of parameters and equations, the notion of causality is rarely made explicit. Formal treatments of the foundations of sciences have avoided discussions of causation and spoken only of functional relations among variables. Nevertheless, the notion of causality plays an important role in our understanding of phenomena. Even when we describe the behavior of a system formally in terms of acausal, mathematical relations, we often give an informal, intuitive explanation of why the system behaves the way it does in terms of cause-effect relations. In this paper, we will present an operational definition of causal ordering. The definition allows us to extract causal dependency relations among variables implicit in a model of a system, when a model is represented as a set of acausal, mathematical relations. Our approach is based on the theory of causal ordering first presented by Simon [22]. The paper shows how to use the theory and its extension in reasoning about physical systems. Further, the paper studies the relation of the theory to the problems of model aggregation.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Ingerman PZ,Ingerman PZ,CHAPTER 2 - A Simple Language for Some Simple Examples,,1966,,,21-27,,Academic Press,,A Syntax-Oriented Translator,1966,9781483231044,,https://www.sciencedirect.com/science/article/pii/B9781483231044500070;http://dx.doi.org/10.1016/B978-1-4832-3104-4.50007-0,10.1016/B978-1-4832-3104-4.50007-0,"Publisher Summary This chapter discusses the development of simple assignment statement as language. An assignment statement is a message whose meaning is that some variable is to assume a specified value; the specified value is usually the result of evaluating some arithmetic expression. A simple assignment statement is one in which the arithmetic expressions are restricted to extended additions and the number of different variables is small. A grammar of a language, written in formal metasyntactic language, constitutes the description of the source language syntax that is required as the first of the two additional inputs to the syntax-oriented translator and is used to control the parsing of the input accretion to determine whether it is grammatical. The purpose of the parsing processor is to provide to the second processor of the syntax-oriented translator a complete description of the interrelationships of all of the objects in the input accretion. If the source language input is ascertained to be grammatical, the parsing is completed and a description of the rules used in the parsing process, the place in the parsing where they have been used, and the constructs associated with them is made available to the unparsing processor. The unparsing process generates as output the assembly language and is then processed to produce machine coding.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Velleman DJ,,Variable declarations in natural deduction,Annals of Pure and Applied Logic,2006,144,1,133-146,,,,,2006,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007206000649;http://dx.doi.org/10.1016/j.apal.2006.05.009,10.1016/j.apal.2006.05.009,"We propose the use of variable declarations in natural deduction. A variable declaration is a line in a derivation that introduces a new variable into the derivation. Semantically, it can be regarded as declaring that the variable denotes an element of the universe of discourse. Undeclared variables, in contrast, do not denote anything, and may not occur free in any formula in the derivation. Although most natural deduction systems in use today do not have variable declarations, the idea can be traced back to one of the first papers on natural deduction. We show how the use of variable declarations in natural deduction leads to a formal system that has a number of desirable features: It is simple, easy to use and understand, and corresponds closely to ordinary informal reasoning. Soundness and completeness of the system are easily proven. Furthermore, the system clarifies the role of the existential instantiation rule in natural deduction.","Natural deduction, Variable declaration, Arbitrary object",,,,,,,,,,,,,,,,,,,,,
Journal Article,Camurri A,,Temporal logic issues in music knowledge representation,Microprocessing and Microprogramming,1989,27,1,541-546,,,,,1989,,0165-6074,https://www.sciencedirect.com/science/article/pii/0165607489901075;http://dx.doi.org/10.1016/0165-6074(89)90107-5,10.1016/0165-6074(89)90107-5,"This paper shows possible applications to music of some results deriving from Temporal Reasoning (TR), a particular subfield of Artificial Intelligence (AI). In particular, TR can be usefully applied in music theory, musicology, composition, and in any activity involving reasoning on music knowledge. The basic assumption is that a general music theory has to cope deeply with formal theories of time. In the paper are briefly introduced and discussed the most relevant formalisms on TR, to investigate their possible implications in the music domain. Successively, the paper shows the formalism for TR embedded in an approach we have recently developed, consisting of a hybrid model for music knowledge representation based on SI-Nets (Semantic Inheritance Networks).",,Fifteenth EUROMICRO Symposium on Microprocessing and Microprogramming,,,,,,,,,,,,,,,,,,,,
Journal Article,"Georgiou C,Musial PM,Shvartsman AA",,Long-lived Rambo: Trading knowledge for communication,Theoretical Computer Science,2007,383,1,59-85,,,,,2007,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397507002654;http://dx.doi.org/10.1016/j.tcs.2007.03.052,10.1016/j.tcs.2007.03.052,"Shareable data services providing consistency guarantees, such as atomicity (linearizability), make building distributed systems easier. However, combining linearizability with efficiency in practical algorithms is difficult. A reconfigurable linearizable data service, called Rambo, was developed by Lynch and Shvartsman. This service guarantees consistency under dynamic conditions involving asynchrony, message loss, node crashes, and new node arrivals. The specification of the original algorithm is given at an abstract level aimed at concise presentation and formal reasoning about correctness. The algorithm propagates information by means of gossip messages. If the service is in use for a long time, the size and the number of gossip messages may grow without bound. This paper presents a consistent data service for long-lived objects that improves on Rambo in two ways: it includes an incremental communication protocol and a leave service. The new protocol takes advantage of the local knowledge, and carefully manages the size of messages by removing redundant information, while the leave service allows the nodes to leave the system gracefully. The new algorithm is formally proved correct by forward simulation using levels of abstraction. An experimental implementation of the system was developed for networks-of-workstations. The paper also includes selected analytical and preliminary empirical results that illustrate the advantages of the new algorithm.","Distributed algorithms, Atomic memory service, Long-lived executions",Structural Information and Communication Complexity (SIROCCO 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Marin R,Trillo JL,Garrido J",,A CASE tool for modelling and simulating distributed control systems based on MMS,IFAC Proceedings Volumes,1994,27,15,171-175,,,,,1994,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017457697;http://dx.doi.org/10.1016/S1474-6670(17)45769-7,10.1016/S1474-6670(17)45769-7,"This paper deals with the modeling of control systems based on the standard for industrial communications MMS [ISO-9506]. This model captures the machine’s main struaural characteristics in industrial communications environments, but lacks formal semantics describing device programs. In order to define the device program semantics Colored Timed Petri Nels are used. In its interpretation we include MMS service calls referencing MMS model objects. The object model definitions are constructed in EXPRESS, [IOS-10303 part 11] language. Man-machine interfaces are built using an iconic paradigm and Motif widgets. The model is stored in standard format STEP[IOS-10303, Part 21]. This model is then specialized for industrial network design based on fieldbus PROFIBUS (DIN-19245].","Manufacturing processes, computer-aided design, modelling, simulation, rapid-prototyping","12th IFAC Workshop on Distributed Computer Control Systems (DCCS'94), Toledo, Spain, 28-30 September, 1994",,,,,,,,,,,,,,,,,,,,
Journal Article,"Selman B,Kautz HA",,Model-preference default theories,Artificial Intelligence,1990,45,3,287-322,,,,,1990,,0004-3702,https://www.sciencedirect.com/science/article/pii/000437029090010W;http://dx.doi.org/10.1016/0004-3702(90)90010-W,10.1016/0004-3702(90)90010-W,"Most formal theories of default inference have very poor computational properties, and are easily shown to be intractable, or worse, undecidable. We are therefore investigating limited but efficiently computable theories of default reasoning. This paper defines systems of propositional model-preference defaults, which provide a model-theoretic account of default inference with exceptions. The most general system of model-preference defaults is decidable but still intractable. Inspired by the very good (linear) complexity of propositional Horn theories, we consider systems of Horn defaults. Surprisingly, finding a most preferred model in even this very limited system is shown to be NP-hard. Tractability can be achieved in two ways: by eliminating the “specificity ordering” among default rules and by restricting our attention to systems of acyclic Horn defaults. These acyclic theories can encode acyclic defeasible inheritance hiearchies, but are more general.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Akhmet MU,Fen MO",,Replication of chaos,Communications in Nonlinear Science and Numerical Simulation,2013,18,10,2626-2666,,,,,2013,,1007-5704,https://www.sciencedirect.com/science/article/pii/S1007570413000634;http://dx.doi.org/10.1016/j.cnsns.2013.01.021,10.1016/j.cnsns.2013.01.021,"We propose a rigorous method for replication of chaos from a prior one to systems with large dimensions. Extension of the formal properties and features of a complex motion can be observed such that ingredients of chaos united as known types of chaos, Devaney’s, Li-Yorke and obtained through period-doubling cascade. This is true for other appearances of chaos: intermittency, structure of the chaotic attractor, its fractal dimension, form of the bifurcation diagram, the spectra of Lyapunov exponents, etc. That is why we identify the extension of chaos through the replication as morphogenesis. To provide rigorous study of the subject, we introduce new definitions such as chaotic sets of functions, the generator and replicator of chaos, and precise description of ingredients for Devaney and Li-Yorke chaos in continuous dynamics. Appropriate simulations which illustrate the chaos replication phenomenon are provided. Moreover, in discussion form we consider inheritance of intermittency, replication of Shil’nikov orbits and quasiperiodical motions as a possible skeleton of a chaotic attractor. Chaos extension in an open chain of Chua circuits is also demonstrated.","Replication of chaos, Hyperbolic set of functions, Chaotic set of functions, Period-doubling cascade, Devaney chaos, Li-Yorke chaos, Intermittency, Chaotic attractor, Chaos control, Shil’nikov orbits, The double-scroll Chua’s attractor, Quasiperiodicity, Morphogenesis of chaos",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Woodfll J,Segre AM,Labor Saving New Distinctions,,1989,,,430-433,,Morgan Kaufmann,San Francisco (CA),Proceedings of the Sixth International Workshop on Machine Learning,1989,9781558600362,,https://www.sciencedirect.com/science/article/pii/B9781558600362501089;http://dx.doi.org/10.1016/B978-1-55860-036-2.50108-9,10.1016/B978-1-55860-036-2.50108-9,"ABSTRACT It has often been argued that ontologies ought to be determined pragmatically. We study this claim formally by considering a framework in which choosing new objects and relations is a computational task. Using this framework we examine two sets of examples, one involving new relations, the other new objects. For these examples, we consider the runtime space and time savings that can be achieved. We see that in some cases arbitrary new relations can be beneficial. The task of choosing new relations in this framework is shown to be NP-hard. For the class of new object examples we consider, new objects can reduce the runtime computation from O(√n2n) to O(n3).",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Mařík V,,Linguistic Approach to the Object Recognition by Grasping,IFAC Proceedings Volumes,1981,14,2,1915-1920,,,,,1981,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017637522;http://dx.doi.org/10.1016/S1474-6670(17)63752-2,10.1016/S1474-6670(17)63752-2,"A method for recognizing both the three-dimensional object shapes and their sizes by grasping them with an antropomorfic five-finger artificial hand is described. The hand is equipped with the position sensing elements in the joints of the fingers and with the tactile transducer net on the palm surface. The linguistic method uses formal grammars and languages for the pattern description. The recognition is multilevelly hierarchically arranged, every level being different from the others by the formal language which has been used. On every level the pattern description is generated and verified from the syntactical and semantical points of view. The results of the implementation of the recognition of cones, pyramides, spheres, prisms and cylinders are presented and discussed.","Robots, pattern recognition, artificial intelligence, manipulation, hierarchical systems, grammars languages","8th IFAC World Congress on Control Science and Technology for the Progress of Society, Kyoto, Japan, 24-28 August 1981",,,,,,,,,,,,,,,,,,,,
Journal Article,Phillips C,,Lean Cuisine+: an executable graphical notation for describing direct manipulation interfaces,Interacting with Computers,1995,7,1,49-71,,,,,1995,,0953-5438,https://www.sciencedirect.com/science/article/pii/0953543895908197;http://dx.doi.org/10.1016/0953-5438(95)90819-7,10.1016/0953-5438(95)90819-7,"The paper describes an executable semi-formal graphical notation, Lean Cuisine+, for describing the underlying behaviour of event-based direct manipulation interfaces, and outlines a methodology for constructing Lean Cuisine+ specifications. Lean Cuisine+ is a multilayered notation, and is a development of the meneme model of Lean Cuisine. A motivation of the research stems from the need for tools and techniques to facilitate high-level interface design. The research supports and brings together a number of views concerning the requirements of notations at this level. These are that a notation should be semi-formal, graphical, executable, and object-based, and that to be most effective it should be targeted at a specific category of interaction. The Lean Cuisine+ notation meets all these criteria, the underlying meneme model matching closely with the selection-based nature of direct manipulation interfaces.","human-computer interaction, interface design, direct manipulation, graphical dialogue notations",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Apostolico A,Caianiello ER,Fischetti E,Vitulano S",,An application of C-calculus to texture analysis: C-transforms,Pattern Recognition,1978,10,5,389-396,,,,,1978,,0031-3203,https://www.sciencedirect.com/science/article/pii/0031320378900109;http://dx.doi.org/10.1016/0031-3203(78)90010-9,10.1016/0031-3203(78)90010-9,"A method for the analysis and discrimination of textures, based on C-calculus, is proposed. The concepts of C-space and C-transform of a digitized signal are introduced as simple tools, well suited to the visualization of the filtering properties of C-calculus: C-filters are thus also defined and the “natural” role they seem to play in problems concerning textures is investigated in some practical instances. In particular, C-transforms of some sample textures are provided and texture classification in C-space is performed. Discrimination of objects against textural background is obtained by C-filtering, in an inherently parallel fashion. The philosophy involved in this approach is finally briefly discussed in a comparison with some extant methods.","Texture analysis, Image processing, Feature extraction, Parallel processing, “Composite-sets”",,,,,,,,,,,,,,,,,,,,,
Journal Article,Constable RL,,A Note on Complexity Measures for Inductive Classes in Constructive Type Theory,Information and Computation,1998,143,2,137-153,,,,,1998,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540198999990;http://dx.doi.org/10.1006/inco.1998.9999,10.1006/inco.1998.9999,"It is notoriously hard to express computational complexity properties of programs in programming logics based on a semantics which respects extensional function equality. That is a serious impediment to applications of programming logics requiring reasoning about complexity. This paper shows how to use existing mechanisms to define internal computational complexity measures in logics that support inductively defined types, dependent products, and functions. The method exploits a feature of inductive definitions in constructive type theory, namely that implicit proof codes are kept with the objects showing how they are presented in the inductive class. The idea is illustrated by giving a formal inductive definition ofPTimebased on ideas from Leivant's work and on Bellantoni and Cook's approach. Then a complexity measure is defined on elements of this class. This paper discusses the limitations of this idea and the need forfaithfulnessguarantees that link internal complexity classes to the implementation of the logic. The paper concludes with a definition ofresource bounded logicsand a discussion of interesting lines of investigation of these logics which have the potential to make practical uses of results from computational complexity theory in formal reasoning about the efficiency of programs.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cerveró MÀ,Vinacua À,Brunet P",,3D Model deformations with arbitrary control points,Computers & Graphics,2016,57,,92-101,,,,,2016,,0097-8493,https://www.sciencedirect.com/science/article/pii/S0097849316300231;http://dx.doi.org/10.1016/j.cag.2016.03.010,10.1016/j.cag.2016.03.010,"Cage-based space deformations are often used to edit and animate images and geometric models. The deformations of the cage are easily transferred to the model by recomputing fixed convex combinations of the vertices of the cage, the control points. In current cage-based schemes the configuration of edges and facets between these control points affects the resulting deformations. In this paper we present a family of similar schemes that includes some of the current techniques, but also new schemes that depend only on the positions of the control points. We prove that these methods afford a solution under fairly general conditions and result in an easy and flexible way to deform objects using freely placed control points, with the necessary conditions of positivity and continuity.","Deformations, Cage-based, Interactive mesh deformation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Krämer B,,Introducing the GRASPIN specification language SEGRAS,Journal of Systems and Software,1991,15,1,17-31,,,,,1991,,0164-1212,https://www.sciencedirect.com/science/article/pii/016412129190074G;http://dx.doi.org/10.1016/0164-1212(91)90074-G,10.1016/0164-1212(91)90074-G,"SEGRAS is a novel language for writing formal specifications of concurrent and distributed systems. It integrates algebraic specifications of abstract data types, high-level Petri net specifications of concurrent behavior, and a sort of parametric polymorphism in a common syntactic and semantic framework. The language treats data abstractions with distributed states and state-dependent operations that can dynamically create new data objects and concurrently modify their properties according to a specified dynamic behavior. Interactive construction and formal analysis of SEGRAS specifications is supported by a collection of tools integrated in the GRASPIN environment. This article illustrates some salient features of the language through examples and discusses methodological issues concerned with constructing, analyzing, and executing SEGRAS specifications with the aid of the GRASPIN environment.",,GRASPIN Software,,,,,,,,,,,,,,,,,,,,
Book Chapter,Lancaster GT,Lancaster GT,CHAPTER 3 - Identification and Environment Divisions,,1972,,,17-22,,Pergamon,,Programming in COBOL,1972,9780080163840,,https://www.sciencedirect.com/science/article/pii/B9780080163840500080;http://dx.doi.org/10.1016/B978-0-08-016384-0.50008-0,10.1016/B978-0-08-016384-0.50008-0,"Publisher Summary This chapter discusses the identification and environment divisions. The first of the four divisions of common business oriented language (COBOL) is the identification division. This division merely informs the compiler of the name of the program that is to be translated. The formal structure for the identification division is as follows: the program name must be six characters in length, the first of which must be alphabetic. The next three characters might be either alphabetic or numeric. With some computers, where multi-programming facilities are available, the last two characters are the priority number assigned to that program and must be numeric. Memory size is an assessment of the amount of core store area that is required by the object program. This assessment should be reasonably accurate, especially when the installation is using multi-programming facilities, otherwise the operating program or executive program would not process the program if there is insufficient core store available.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Alexi W,,Extraction and verification of programs by analysis of formal proofs,Theoretical Computer Science,1988,61,2,225-258,,,,,1988,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397588901259;http://dx.doi.org/10.1016/0304-3975(88)90125-9,10.1016/0304-3975(88)90125-9,"Mathematical proofs often implicity contain constructions of objects with certain properties. Our new program synthesis algorithm starts with a formal proof of size n, and in time O(n3) explicitly gives those constructions as a computer program. Termination and correctness are proved metamathematically (“program verification”). Furthermore, the region of algorithmically relevant formulae of a proof is characterized. Proofs outside this region may be inconstructive. A mathematical tool for the proof of termination and correctness is the proof-theoretical strong normalization. Graphs of symbols belonging together are constructed. From these the elementary program statements are read off.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shankar P,Dasgupta A,Deshmukh K,Rajan BS",,On viewing block codes as finite automata,Theoretical Computer Science,2003,290,3,1775-1797,,,,,2003,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439750200083X;http://dx.doi.org/10.1016/S0304-3975(02)00083-X,10.1016/S0304-3975(02)00083-X,"Block codes are viewed from a formal language theoretic perspective. It is shown that properties of trellises for subclasses of block codes called rectangular codes follow naturally from the Myhill Nerode theorem. A technique termed subtrellis overlaying is introduced with the object of reducing decoder complexity. Necessary and sufficient conditions for trellis overlaying are derived from the representation of the block code as a group, partitioned into a subgroup and its cosets. The conditions turn out to be simple constraints on coset leaders. It is seen that overlayed trellises are tail-biting trellises for which decoding is generally more efficient than that for conventional trellises. Finally, a decoding algorithm for tail-biting trellises is described, and the results of some simulations are presented.","Block codes, Tail-biting trellis, Decoder complexity, Maximum likelihood decoding",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Sahu AK,Sharma S,Nanda A","Singh AK,Elhoseny M",Chapter 16 - A secure lightweight mutual authentication and key agreement protocol for healthcare systems,,2020,,,293-308,,Academic Press,,Intelligent Data Security Solutions for e-Health Applications,2020,9780128195116,,https://www.sciencedirect.com/science/article/pii/B9780128195116000169;http://dx.doi.org/10.1016/B978-0-12-819511-6.00016-9,10.1016/B978-0-12-819511-6.00016-9,"The current era of technology is flooded with hundreds of Internet of Things (IoT) applications with billions of IoT objects. One of the primary applications is healthcare systems, where body area network (BAN)-sensing healthcare devices (such as leg movement sensor, heart-rate sensing, etc.) collect the user's real-time data (such as heart rate, step counts, and many more). These real-time users’ data are vulnerable to various attacks related to authentication. It may also create scope for further attacks exploiting authentication. Therefore it requires a proper authentication mechanism and should be transmitted securely without compromising the privacy of the user's healthcare information. Moreover, these devices are very much computationally resource constrained. This chapter emphasizes the afore-mentioned threats and constraints, and proposes a secure, lightweight authentication protocol between a healthcare wearable device and its user. The scheme uses a cryptographic hash function and X-OR functionalities only. It is tested by a well-known formal security verification tool, AVISPA, to show its robustness against various attacks related to authentications. The secure establishment of a shared secret key is also shown by the well-known BAN authentication logic. Furthermore, the computational cost of the scheme is also computed and compared with other work to prove its efficiency.","Authentication, Internet of things, IoT, Security, Protocol, Lightweight, Key establishment, One-way hash function, X-OR, Function, Mutual authentication",,Intelligent Data-Centric Systems,,,,,,,,,,,,,,,,,,,
Journal Article,Smith S,,Specification Diagrams for Actor Systems,Electronic Notes in Theoretical Computer Science,1998,10,,197,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580698X;http://dx.doi.org/10.1016/S1571-0661(05)80698-X,10.1016/S1571-0661(05)80698-X,"Traditional approaches to specifying distributed systems include temporal logic specification (e.g. TLA), and process algebra specification (e.g. LOTOS). We propose here a new form of graphical notation for specifying open distributed object systems. The primary design goal is to make a form of notation for defining message-passing behavior that is expressive, intuitively understandable, and that has a formal underlying semantics. We describe the language and its use through presentation of a series of example specifications. We also give an operationally-based interaction path semantics for specification diagrams.",,"HOOTS II, Second Workshop on Higher-Order Operational Techniques in Semantics",,,,,,,,,,,,,,,,,,,,
Journal Article,"Pasini F,Dotti FL",,Code Generation for Parallel Applications Modelled with Object-Based Graph Grammars,Electronic Notes in Theoretical Computer Science,2007,184,,113-131,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107004380;http://dx.doi.org/10.1016/j.entcs.2007.03.018,10.1016/j.entcs.2007.03.018,"During the development of a parallel application, besides being able to analyze performance aspects, it is highly desirable to be able to assure functional properties as early as possible. Assuring functional properties about a model of the parallel applicationcan lead to important savings since it reduces the time spent in application development and debugging. In this direction, model-checking and automatic code generation can be used as complementary tools during the development, making possible to analyze the system behavior and allowing the fast generation of corresponding code. In this paper we propose the use of Object-Based Graph Grammars (OBGG) for the specification of parallel applications. OBGG is a formal, visual language suited for the description of concurrent systems based on asynchronous message passing. Models described using OBGG can be verified through model checking. Following this approach, a translation from OBGG models to C code using MPI (Message Passing Interface), which is suited for clusters, is presented. To illustrate the contribution, a sample parallel application is modelled in OBGG; functional properties of the model are proven by model-checking; the C/MPI corresponding model is presented and performance results of the translated model are discussed and compared with an analogous C/MPI application built by hand.","Graph Grammars, Parallel Programming, MPI, Model Checking",Proceedings of the Second Brazilian Symposium on Formal Methods (SBMF 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,"Bonet Avalos J,Rubí JM,Bedeaux D,van der Zwan G",,Friction coefficients of axisymmetric particles in suspension,Physica A: Statistical Mechanics and its Applications,1994,211,2,193-217,,,,,1994,,0378-4371,https://www.sciencedirect.com/science/article/pii/0378437194001766;http://dx.doi.org/10.1016/0378-4371(94)00176-6,10.1016/0378-4371(94)00176-6,"We study the dynamics of an axisymmetric particle suspended in a fluid. The approach we use is based on the induced forces method. We then obtain formal expressions for the friction tensors from which one derives explicit formulas for the friction coefficients depending on the shape of the particle, valid in the long-particle limit. Some particular examples are under scrutiny namely, the case of particles of regular form and the influence of end effects and the roughness of the particles in the dynamics. The first one serves to illustrate our method whereas the second to manifest its applicability to open problems in the dynamics of objects in suspension.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rawnsley J,Cahen M,Gutt S",,Quantization of Kähler manifolds I: geometric interpretation of Berezin's quantization,Journal of Geometry and Physics,1990,7,1,45-62,,,,,1990,,0393-0440,https://www.sciencedirect.com/science/article/pii/039304409090019Y;http://dx.doi.org/10.1016/0393-0440(90)90019-Y,10.1016/0393-0440(90)90019-Y,We give a geometric interpretation of Berezin's symbolic calculus on Kähler manifolds in the framework of geometric quantization. Berezin's covariant symbols are defined in terms of coherent states and we study a function ϴ on the manifold which is the central object of the theory. When this function is constant Berezin's quantization rule coincides with the prescription of geometric quantization for the quantizable functions. It is defined on a larger class of functions. We show in the compact homogeneous case how to extend Berezin's procedure to a dense subspace of the algebra of smooth functions.,"Quantization, Kähler manifolds, 53 C 55, 81 D 07",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bowen PL,Debreceny R,Rohde FH,Basford J",,Selecting optimal instantiations of data models—Theory and validation of an ex ante approach,Decision Support Systems,2006,42,2,1170-1186,,,,,2006,,0167-9236,https://www.sciencedirect.com/science/article/pii/S0167923605001521;http://dx.doi.org/10.1016/j.dss.2005.10.002,10.1016/j.dss.2005.10.002,"The schema of an information system can significantly impact the ability of end users to efficiently and effectively retrieve the information they need. Obtaining quickly the appropriate data increases the likelihood that an organization will make good decisions and respond adeptly to challenges. This research presents and validates a methodology for evaluating, ex ante, the relative desirability of alternative instantiations of a model of data. In contrast to prior research, each instantiation is based on a different formal theory. This research theorizes that the instantiation that yields the lowest weighted average query complexity for a representative sample of information requests is the most desirable instantiation for end-user queries. The theory was validated by an experiment that compared end-user performance using an instantiation of a data structure based on the relational model of data with performance using the corresponding instantiation of the data structure based on the object-relational model of data. Complexity was measured using three different Halstead metrics: program length, difficulty, and effort. For a representative sample of queries, the average complexity using each instantiation was calculated. As theorized, end users querying the instantiation with the lower average complexity made fewer semantic errors, i.e., were more effective at composing queries.","Models of data, Data representations, Object-relational databases, Relational databases, Query languages, Query complexity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Deng Y,Yang CR",,"Architecture-driven modeling of real-time concurrent systems with applications in FMS1This work was supported in part by the National Science Foundation under Grant No. CCR-9308473, by the Air Force Office of Scientific Research under Grant No. F49620-96-1-0221, and by NASA under Grant No. NAGW-4080. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied by the above named Agencies.1",Journal of Systems and Software,1999,45,1,61-78,,,,,1999,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121298100687;http://dx.doi.org/10.1016/S0164-1212(98)10068-7,10.1016/S0164-1212(98)10068-7,"Petri nets have become increasingly popular for flexible manufacturing systems (FMS) modeling and control because they accurately capture the concurrent, non-deterministic and time-dependent properties of the systems. While offering many advantages, conventional Petri net models suffer from some serious problems that limit their usability as design models for complex FMS. Central to these problems is the lack of an engineering support for incremental design, refinement, and analysis of large-scale systems. In this paper, we present an architecture-driven approach for the modeling and design of FMS that effectively addresses the problems while leveraging the strengths of Petri nets. The approach has two major aspects: The first is a Net-based and Object-based Architectural Model (NOAM) that introduces a well-founded architectural framework into the Petri nets notation and lays a foundation to support formal design. The second is a modeling method based on NOAM that uses architecture decomposition and refinement as the basis to reduce design complexity, to provide smooth transition from informal to formal design, and to support incremental refinement and analysis. A case study using NOAM for FMS modeling is provided to show the applicability of our approach.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Krotov VF,Kurzhanski AB",,National Achievements in Control Theory (The Aerospace Perspective),IFAC Proceedings Volumes,2004,37,6,37-48,,,,,2004,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017321481;http://dx.doi.org/10.1016/S1474-6670(17)32148-1,10.1016/S1474-6670(17)32148-1,"It is well known that among the first motivations for modern control theory were dynamic optimization problems in rocket launching and navigation in aerospace. These problems had become especially important in the forties and fifties due to requirement to minimize various costly resources and design parameters, such as flight time, amount (mass) of fuel, weight of the spacecraft, the drag forces and other items. This had to be done under various restrictions on control capacities and other complicating factors, such for example, as incomplete information on the system. In the precious funds of applied mathematical techniques there had long been stored an adequate tool for such problems: it is the Calculus of Variations. Problems in flight dynamics had become the earliest serious technical object for its application. A large number of new basic ideas for adapting Calculus of Variations to modern control problems and synthesizing them into modern control theory were elaborated in the course of investigations in flight dynamics. This presentation traces some seminal investigations, which were crucial for related theoretical developments in former Soviet Union and present Russia and had also influenced related research beyond national borders. Such investigations had good historical precursors in the earlier mathematical works of P.L.Chebyshev, A.M.Lyapunov, A.A.Markov, the works in mechanics by N.E.Zhukovski and S.A.Chaplygin and the activities in dynamic systems theory of the thirties (A.A.Andronov, L.S.Pontryagin et al.) The present paper is confined only to deterministic problems in trajectory analysis, control and optimization within the framework of mathematical theory of controlled processes. The national community of researchers involved in these topics was enormous, including those in the Academy of Sciences, the Universities and the numerous institutions and plants supervised by related industrial ministries. While giving tribute to all those involved, this paper does not claim to give a full review of available publications, concentrating on what the authors believe to be the seminal issues in the field and their role in future directions of research. This publication will therefore inevitably have a subjective flavour. We sincerely apologize to all those whose contributions may have been missed",,"16th IFAC Symposium on Automatic Control in Aerospace 2004, Saint-Petersburg, Russia, 14-18 June 2004",,,,,,,,,,,,,,,,,,,,
Journal Article,"Lavy I,Shriki A",,Engaging in problem posing activities in a dynamic geometry setting and the development of prospective teachers’ mathematical knowledge,The Journal of Mathematical Behavior,2010,29,1,11-24,,,,,2010,,0732-3123,https://www.sciencedirect.com/science/article/pii/S0732312309000571;http://dx.doi.org/10.1016/j.jmathb.2009.12.002,10.1016/j.jmathb.2009.12.002,"In the present study we explore changes in perceptions of our class of prospective mathematics teachers (PTs) regarding their mathematical knowledge. The PTs engaged in problem posing activities in geometry, using the “What If Not?” (WIN) strategy, as part of their work on computerized inquiry-based activities. Data received from the PTs’ portfolios reveals that they believe that engaging in the inquiry-based activity enhanced both their mathematical and meta-mathematical knowledge. As to the mathematical knowledge, they deepened their knowledge regarding the geometrical concepts and shapes involved, and during the process of creating the problem and checking its validity and its solution, they deepened their understanding of the interconnections among the concepts and shapes involved. As to meta-mathematical knowledge, the PTs refer to aspects such as the meaning of the givens and their relations, validity of an argument, the importance and usefulness of the definitions of concepts and objects, and the importance of providing a formal proof.","Problem posing, The “What If Not?” strategy, Dynamic geometry software, Prospective teachers’ education, Portfolio, Inquiry-based activity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Drmota M,Soria M",,Marking in combinatorial constructions: Generating functions and limiting distributions,Theoretical Computer Science,1995,144,1,67-99,,,,,1995,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759400294S;http://dx.doi.org/10.1016/0304-3975(94)00294-S,10.1016/0304-3975(94)00294-S,"There is a wide field of combinatorial constructions, especially in the combinatorial analysis of algorithms, where it is possible to find an explicit generating function y(x) = Σynxn for the numbers yn of objects of size n and the bivariate generating function y(x, u) = Σynkxnuk for the numbers ynk of objects of size n where another parameter has value k. Formally this additional parameter is marked in the above combinatorial construction. The aim of this paper is to provide general methods to obtain the asymptotic limiting distribution of this additional parameter in objects of size n. We are especially interested in local limit theorems, which involves estimating the coefficients of powers of generating functions. When y(x) is a function with a logarithmic singularity, we derive uniform approximations for [xn]y(x)k for k ⩽ εn; and as a byproduct, we obtain conditional limiting distributions for the number of trees in random mappings where the number of cycles is given. Production schemas y(x, u) = g(x)F(uw(x)) are also considered: we show how the limiting distribution may be dictated either by g(x), or by F(uw(x)) or should involve both g and F; and give many combinatorial applications.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Codish M,Lagoon V,Bueno F",,An algebraic approach to sharing analysis of logic programs,The Journal of Logic Programming,2000,42,2,111-149,,,,,2000,,0743-1066,https://www.sciencedirect.com/science/article/pii/S0743106699000072;http://dx.doi.org/10.1016/S0743-1066(99)00007-2,10.1016/S0743-1066(99)00007-2,"This paper describes an algebraic approach to the sharing analysis of logic programs based on an abstract domain of set logic programs. Set logic programs are logic programs in which the terms are sets of variables and unification is based on an associative, commutative, and idempotent equality theory. All of the basic operations required for sharing analyses, as well as their formal justification, are based on simple algebraic properties of set substitutions and set-based atoms. An ordering on set-based syntactic objects, similar to “less general” on concrete syntactic objects, is shown to reflect the notion of “less sharing” information. The (abstract) unification of a pair of set-based terms corresponds to finding their most general ACI1 unifier with respect to this ordering. The unification of a set of equations between set-based terms is defined exactly as in the concrete case, by solving the equations one by one and repeatedly applying their solutions to the remaining equations. We demonstrate that all of the operations in a sharing analysis have natural definitions which are both correct and optimal.","Program analysis, ACI unification, Variable sharing",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hofmann M,Pierce BC",,Type Destructors,Information and Computation,2002,172,1,29-62,,,,,2002,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540101929268;http://dx.doi.org/10.1006/inco.2001.2926,10.1006/inco.2001.2926,"We study a variant of System F≤ that integrates and generalizes several existing proposals for calculi with “structural typing rules.” To the usual type constructors (→, ×, All, Some, Rec) we add a number of type destructors, each internalizing a useful fact about the subtyping relation. For example, in F≤ with products every closed subtype of a product S×T must itself be a product S′×T′ with S′<:S and T′<:T. We internalise this observation by introducing type destructors .1 and .2 and postulating an equivalence T=ηT.1×T.2 whenever T<:U×V (including, for example, when T is a variable). In other words, every subtype of a product type literally is a product type, modulo η-conversion. Adding type destructors provides a clean solution to the problem of polymorphic update without introducing new term formers, new forms of polymorphism, or quantification over type operators. We illustrate this by giving elementary presentations of two well-known encodings of objects, one based on recursive record types and the other based on existential packages. The formulation of type destructors poses some tricky meta-theoretic problems. We discuss two different variants: an “ideal” system where both constructors and destructors appear in general forms, and a more modest system, F≤TD, which imposes some restrictions in order to achieve a tractable metatheory. The properties of the latter system are developed in detail.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Sander P,,Boolean lattices of nested relations as a foundation for rule-based database languages,Data & Knowledge Engineering,1992,8,2,93-130,,,,,1992,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X92900338;http://dx.doi.org/10.1016/0169-023X(92)90033-8,10.1016/0169-023X(92)90033-8,"In this paper rule-based languages over partially ordered nested relations are considered. Starting with ideas of Bancilhon's and Koshafian's Object Calculus we define a class of purely lattice-based languages each of them depending on a fixed partial order. We show that for each ordering the semantics of a program can be equivalently defined by a minimal model or by a least fixpoint. Thus, our approach is semantically first order. Two well-known orderings — inclusion order and object order — and the corresponding languages are compared in detail. In order to combine the advantages of these two orderings we present a formalism to express more general orderings over so-called Generalized Partitioned Normal Form instances. Then we define the meta-concept modularization that enables us to express operations being non-monotone with respect to each of these orderings. It is comparable to stratification in other approaches, but the basic idea is different. Finally, we show how the semantics of negation can be defined in a theoretically well-founded way for partial orders corresponding to a Boolean lattice.","Databases, knowledge bases, nested realtions, deductive database",,,,,,,,,,,,,,,,,,,,,
Journal Article,McIlraith SA,,Integrating actions and state constraints: A closed-form solution to the ramification problem (sometimes),Artificial Intelligence,2000,116,1,87-121,,,,,2000,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370299000879;http://dx.doi.org/10.1016/S0004-3702(99)00087-9,10.1016/S0004-3702(99)00087-9,"Integrating actions and state constraints is a central problem in knowledge representation. State constraints are commonly used to represent the relationship between objects in the world. When a representation of action is integrated, state constraints implicitly define indirect effects of actions and impose further preconditions on the performance of actions. Thus, a semantically correct integration of actions and state constraints must address the ramification and qualification problems, as well as the frame problem. In this paper we achieve such an integration for a syntactically restricted class of situation calculus theories. This paper presents two major technical contributions. The first contribution is an axiomatic closed-form solution to the frame, ramification and qualification problems for a common class of theories. The solution is presented in the form of an automatable procedure that compiles a syntactically restricted set of situation calculus ramification constraints and effect axioms into a set of successor state axioms. The second major contribution of this paper is an independent semantic justification for this closed-form solution. In particular, we present a semantic specification for a solution to the frame and ramification problems in terms of a prioritized minimization policy, and show that the successor state axioms of our closed-form solution adhere to this specification. Observing that our minimization policy is simply an instance of prioritized circumscription, we exploit results of Lifschitz (1985) on computing circumscription to show that computing the prioritized circumscription yields our successor state axioms. In the special case where there are no ramification constraints, computing the circumscription yields Reiter's (1991) earlier successor state axiom solution to the frame problem.","Ramification problem, Frame problem, Qualification problem, Reasoning about action, State constraints, Planning, Model-based reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Xiong R,Song Y,Li H,Wang Y",,Onsite video mining for construction hazards identification with visual relationships,Advanced Engineering Informatics,2019,42,,100966,,,,,2019,,1474-0346,https://www.sciencedirect.com/science/article/pii/S1474034619305397;http://dx.doi.org/10.1016/j.aei.2019.100966,10.1016/j.aei.2019.100966,"Widely-used video monitoring systems provide a large corpus of unstructured image data on construction sites. Although previous developed vision-based approaches can be used for hazards recognition in terms of detecting dangerous objects or unsafe operations, such detection capacity is often limited due to lack of semantic representation of visual relationships between/among the components or crews in the workplace. Accordingly, the formal representation of textural criteria for checking improper relationships should also be improved. In this regard, an Automated Hazards Identification System (AHIS) is developed to evaluate the operation descriptions generated from site videos against the safety guidelines extracted from the textual documents with the assistance of the ontology of construction safety. In particular, visual relationships are modeled as a connector between site components/operators. Moreover, both visual descriptions of site operations and semantic representations of safety guidelines are coded in the three-tuple format and then automatically converted into Horn clauses for reasoning out the potential risks. A preliminary implementation of the system was tested on two separate onsite video clips. The results showed that two types of crucial hazards, i.e., failure to wear a helmet and walking beneath the cane, were successfully identified with three rules from Safety Handbook for Construction Site Workers. In addition, the high-performance results of Recall@50 and Recall@100 demonstrated that the proposed visual relationship detection method is promising in enriching the semantic representation of operation facts extracted from site videos, which may lead to better automation in the detection of construction hazards.","Scene graph, Hazards identification, Safety regulations, Ontology, Video mining",,,,,,,,,,,,,,,,,,,,,
Journal Article,Watanabe H,,Theory of classification of objects by predicates,Measurement,1996,18,1,59-69,,,,,1996,,0263-2241,https://www.sciencedirect.com/science/article/pii/0263224196000450;http://dx.doi.org/10.1016/0263-2241(96)00045-0,10.1016/0263-2241(96)00045-0,"The forming of classes of similar objects is no trivial matter, and an operation for determining equality is obviously the first step in measurement. Furthermore, from the cognitive aspects of human information processing, it provides the basis of all our categorization and concept formation. The nature of this classification procedure, however, has not so far been examined fully in the context of measurement theory. The present paper picks up this important, though neglected, subject. Within a formal framework we examine the basic nature of classification procedure, regarding it as a form of measurement, introduce some new notions and principles to reveal its so far unknown essential features, and discuss the possibilities of reinterpretation of the nominal scale. Through such a recapitulation of the classification procedure, the scope of measurement theory will be enlarged so as to embrace, for instance, some fundamental problems of knowledge technology, cognitive aspects of human information processing, and a metrical approach to logical and philosophical topics, beyond mere ranking and numericalization.","Classification, Nominal scale, Measurement theory, Pattern recognition, Information theory, Knowledge representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Molina-Abril H,Real P,Nakamura A,Klette R",,Connectivity calculus of fractal polyhedrons,Pattern Recognition,2015,48,4,1150-1160,,,,,2015,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320314002167;http://dx.doi.org/10.1016/j.patcog.2014.05.016,10.1016/j.patcog.2014.05.016,"The paper analyzes the connectivity information (more precisely, numbers of tunnels and their homological (co)cycle classification) of fractal polyhedra. Homology chain contractions and its combinatorial counterparts, called homological spanning forest (HSF), are presented here as an useful topological tool, which codifies such information and provides an hierarchical directed graph-based representation of the initial polyhedra. The Menger sponge and the Sierpiński pyramid are presented as examples of these computational algebraic topological techniques and results focussing on the number of tunnels for any level of recursion are given. Experiments, performed on synthetic and real image data, demonstrate the applicability of the obtained results. The techniques introduced here are tailored to self-similar discrete sets and exploit homology notions from a representational point of view. Nevertheless, the underlying concepts apply to general cell complexes and digital images and are suitable for progressing in the computation of advanced algebraic topological information of 3-dimensional objects.","Connectivity, Cycles, Topological analysis, Tunnels, Directed graphs, Betti number, Fractal set, Menger sponge, Sierpiński pyramid",,,,,,,,,,,,,,,,,,,,,
Journal Article,"England D,Gray P",,Temporal aspects of interaction in shared virtual worlds,Interacting with Computers,1998,11,1,87-105,,,,,1998,,0953-5438,https://www.sciencedirect.com/science/article/pii/S0953543898000332;http://dx.doi.org/10.1016/S0953-5438(98)00033-2,10.1016/S0953-5438(98)00033-2,"In this paper we examine the problems of usability and related temporal issues in shared virtual environments. Shared virtual environments involve physically distributed users interacting with each other and with distributed objects via complex highly graphical user interfaces. These factors can result in interaction which suffers from serious and unpredictable delays in system response times. Careful interaction design can alleviate the problems resulting from such delays. We look at several areas of shared virtual world design, including object interaction, avatars and scene rendering, investigating ways of dealing with communicating information, preserving world coherence and providing users with effective real-time interaction. Our medium of analysis is the Extended User Action Notation (XUAN), a variant of the User Action Notation that enables us to express explicitly and clearly the temporal features of our examples. Finally, we discuss the implications of our temporal analysis for further research and development of shared virtual worlds, and the implications for the further development and use of XUAN.","Temporal aspects, Usability, Shared virtual worlds, Virtual reality, Formal specification, Temporal specification, UAN, XUAN",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Stepp RE,Langley P,Machine Learning from Structured Objects,,1987,,,353-363,,Morgan Kaufmann,,Proceedings of the Fourth International Workshop on MACHINE LEARNING,1987,9780934613415,,https://www.sciencedirect.com/science/article/pii/B9780934613415500386;http://dx.doi.org/10.1016/B978-0-934613-41-5.50038-6,10.1016/B978-0-934613-41-5.50038-6,"Machine learning techniques applied to structured objects frequently use a predicate calculus representation to model the world. Unless careful attention is given to the semantics of this model, the results of inductive inference over descriptions of structured objects have unanticipated interpretations. In this paper, a motivation is given for the importance of careful attention to the semantics that underly descriptions of structured examples and categories of such examples. Particular attention is given to the use of must not clauses and the ability to determine relevant attributes. An example from INDUCE/NE is used to illustrate must not clauses with the INDUCE algorithm. An example from CLUSTER/CA is used to illustrate the use of knowledge about relevant attributes in learning.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Grabmayer C,,A Duality in Proof Systems for Recursive Type Equality and for Bisimulation Equivalence on Cyclic Term Graphs,Electronic Notes in Theoretical Computer Science,2007,72,1,59-74,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107005518;http://dx.doi.org/10.1016/j.entcs.2002.09.007,10.1016/j.entcs.2002.09.007,This paper is concerned with a proof-theoretic observation about two kinds of proof systems for regular cyclic objects. It is presented for the case of two formal systems that are complete with respect to the notion of “recursive type equality” on a restricted class of recursive types in μ-term notation. Here we show the existence of an immediate duality with a geometrical visualization between proofs in a variant of the coinductive axiom system due to Brandt and Henglein and “consistency-unfoldings” in a variant of a 'syntactic-matching' proof system for testing equations between recursive types due to Ariola and Klop. Finally we sketch an analogous result of a duality between a similar pair of proof systems for bisimulation equivalence on equational specifications of cyclic term graphs.,"Recursive types, recursive type equality, bisimulation, cyclic term graph",Proceedings of the First International Workshop on Term Graph Rewriting (TERMGRAPH 2002),,,,,,,,,,,,,,,,,,,,
Journal Article,"Sequeira LM,Morgado L,Pires EJ",,Simplifying Crowd Automation in the Virtual Laboratory of Archaeology,Procedia Technology,2014,13,,56-65,,,,,2014,,2212-0173,https://www.sciencedirect.com/science/article/pii/S221201731400019X;http://dx.doi.org/10.1016/j.protcy.2014.02.009,10.1016/j.protcy.2014.02.009,"Virtual archaeology projects have been evolving to go beyond a mere reconstruction of architecture and artefacts of heritage sites: human interaction with the environment is also an object of research for historians and archaeologists. Methodologies like the London Charter propose that historians and archaeologists, in close collaboration with technical teams, lead virtual archaeology projects to guarantee the credibility and scientific validation of the result. The question is how to allow historians to model crowds on their own, if lacking the required skills to programme complex artificial intelligent-driven autonomous agents. In this article a method is proposed, currently under development, to allow non-programmers will be able to successfully model crowds using very simple tools that do not require formal programming knowledge but can still provide convincing results. The underlying idea is to employ concepts borrowed from computer games, whose interfaces are targeted to non-experts and adapt them to the specificities of virtual world platforms like Second Life® and OpenSimulator. Moreover, some limitations and ideas for further extension are discussed.","Second Life, OpenSimulator, Artifircial intelligence, Virtual archaeology, Genetic algorithms, Bots",SLACTIONS 2013: Research conference on virtual worlds – Learning with simulations,,,,,,,,,,,,,,,,,,,,
Journal Article,"Thomas JP,Nissanke N",,An algebra for modelling assembly tasks,Mathematics and Computers in Simulation,1996,41,5,639-659,,,,,1996,,0378-4754,https://www.sciencedirect.com/science/article/pii/0378475495001077;http://dx.doi.org/10.1016/0378-4754(95)00107-7,10.1016/0378-4754(95)00107-7,"In this paper we develop a systematic approach to mechanical assembly which allows rigorous reasoning and is sufficiently general so that it is applicable to different kinds of assemblies. The paper presents a representation scheme based on attribute graphs for describing assembly parts and an algebra to model assembly tasks. Any task is modelled as a merging of two attribute graphs to produce a single attribute graph which represents the merged or assembled object. The paper introduces a number of different types of merging operations and their mathematical properties are of particular interest in the assembly context. These two aspects of assembly, namely the representation scheme to describe assembly objects and the framework to model assembly tasks, form major components of an assembly planner. Due to its generic, formal and systematic nature, the framework is applicable to the assembly of different kinds of products, thus making the proposed scheme particularly attractive for flexible assembly systems.","Attribute graphs, Assembly tasks, Algebra",Robotics and intelligent systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mislove M,Pavlovic D,Worrell J",,Labelled Markov Processes as Generalised Stochastic Relations,Electronic Notes in Theoretical Computer Science,2007,172,,459-478,,,,,2007,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066107000886;http://dx.doi.org/10.1016/j.entcs.2007.02.015,10.1016/j.entcs.2007.02.015,"Labelled Markov processes (LMPs) are labelled transition systems in which each transition has an associated probability. In this paper we present a universal LMP as the spectrum of a commutative C*-algebra consisting of formal linear combinations of labelled trees. This yields a simple trace-tree semantics for LMPs that is fully abstract with respect to probabilistic bisimilarity. We also consider LMPs with distinguished entry and exit points as stateful stochastic relations. This allows us to define a category GSRel of generalized stochastic relations, which has measurable spaces as objects and LMPs as morphisms. Our main result in this context is to provide a predicate-transformer duality for GSRel that generalises Kozen's duality for the category SRel of stochastic relations.","Labelled Markov process, (Generalized) Stochastic relation, Probabilistic bisimulation, Stone duality, *-algebra, Comonad","Computation, Meaning, and Logic: Articles dedicated to Gordon Plotkin",,,,,,,,,,,,,,,,,,,,
Journal Article,"Canuto C,Moreno P,Samatelo J,Vassallo R,Santos-Victor J",,Action anticipation for collaborative environments: The impact of contextual information and uncertainty-based prediction,Neurocomputing,2021,444,,301-318,,,,,2021,,0925-2312,https://www.sciencedirect.com/science/article/pii/S0925231220317719;http://dx.doi.org/10.1016/j.neucom.2020.07.135,10.1016/j.neucom.2020.07.135,"To interact with humans in collaborative environments, machines need to be able to predict (i.e., anticipate) future events, and execute actions in a timely manner. However, the observation of the human limb movements may not be sufficient to anticipate their actions unambiguously. In this work, we consider two additional sources of information (i.e., context) over time, gaze, movement and object information, and study how these additional contextual cues improve the action anticipation performance. We address action anticipation as a classification task, where the model takes the available information as the input and predicts the most likely action. We propose to use the uncertainty about each prediction as an online decision-making criterion for action anticipation. Uncertainty is modeled as a stochastic process applied to a time-based neural network architecture, which improves the conventional class-likelihood (i.e., deterministic) criterion. The main contributions of this paper are fourfold: (i) We propose a novel and effective decision-making criterion that can be used to anticipate actions even in situations of high ambiguity; (ii) we propose a deep architecture that outperforms previous results in the action anticipation task when using the Acticipate collaborative dataset; (iii) we show that contextual information is important to disambiguate the interpretation of similar actions; and (iv) we also provide a formal description of three existing performance metrics that can be easily used to evaluate action anticipation models. Our results on the Acticipate dataset showed the importance of contextual information and the uncertainty criterion for action anticipation. We achieve an average accuracy of 98.75% in the anticipation task using only an average of 25% of observations. Also, considering that a good anticipation model should perform well in the action recognition task, we achieve an average accuracy of 100% in action recognition on the Acticipate dataset, when the entire observation set is used.","Action anticipation, Early action prediction, Context information, Bayesian deep learning, Uncertainty",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shafiq SI,Sanin C,Szczerbicki E,Toro C",,Towards an experience based collective computational intelligence for manufacturing,Future Generation Computer Systems,2017,66,,89-99,,,,,2017,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X16301091;http://dx.doi.org/10.1016/j.future.2016.04.022,10.1016/j.future.2016.04.022,"Knowledge based support can play a vital role not only in the new fast emerging information and communication technology based industry, but also in traditional manufacturing. In this regard, several domain specific research endeavours have taken place in the past with limited success. Thus, there is a need to develop a flexible domain independent mechanism to capture, store, reuse, and share manufacturing knowledge. Consequently, innovative research to develop knowledge representation models of an engineering object and engineering process called Virtual engineering object (VEO) and Virtual engineering process (VEP) has been carried out and extensively reported. This paper proposes Virtual engineering factory (VEF), the final phase to create complete virtual manufacturing environment which would make use of the experience and knowledge involved in the factory at all levels. VEF is an experience based knowledge representation for a factory encompassing VEP and VEO within it. The novelty of this approach is that it uses manufacturer’s own previous experience and formal decisions to collect and expand intelligence for future production. The experience based collective computational techniques of Set of Experience Knowledge Structure (SOEKS) and Decisional DNA (DDNA) are used to develop aforesaid models. In this article the concept and architecture of VEF is explained as well as the integration of all three levels of virtual manufacturing i.e. VEO, VEP and VEF is presented. Furthermore, a case-study is presented to validate the practical implementation of the proposed concept. The benefits of this approach are manifold as it creates the environment for collective intelligence of a factory and enhances effective decision making. The models and research presented here embody the important first step into developing the future computational setting as required by the emerging next generation of cyber-physical systems.","Set of Experience Knowledge Structure, Decisional DNA, Virtual engineering object (VEO), Virtual engineering process (VEP), Virtual engineering factory (VEF)",,,,,,,,,,,,,,,,,,,,,
Journal Article,Gardiner P,,Power Simulation and its Relation to Traces and Failures Refinement,Electronic Notes in Theoretical Computer Science,2000,32,,78-100,,,,,2000,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104000969;http://dx.doi.org/10.1016/S1571-0661(04)00096-9,10.1016/S1571-0661(04)00096-9,"There are two quite distinct approaches commonly used when giving meaning to process algebra expressions: operational semantics, often associated with the CCS language, define equivalences between terms by considering whether each can simulate the other; denotational semantics, often associated with CSP, provide a mapping, recursively defined over the structure of the language, taking each term into a carefully chosen collection of set-theoretic objects. (The traces and failures models are well known examples of such semantic domains.) We present a formal link between the two approaches, consisting in defining a variant of the bisimulation equivalence that naturally gives rise to the traces and failures ordering.",,Workshop on secure architectures and information flow,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Moss LS,Tiede HJ","Blackburn P,Van Benthem J,Wolter F",19 Applications of modal logic in linguistics,,2007,3,,1031-1076,,Elsevier,,Handbook of Modal Logic,2007,,1570-2464,https://www.sciencedirect.com/science/article/pii/S157024640780022X;http://dx.doi.org/10.1016/S1570-2464(07)80022-X,10.1016/S1570-2464(07)80022-X,"Publisher Summary This chapter discusses the applications of modal logic in linguistics and provides a sophisticated view of modern interfaces between logic and natural language. Modal logic is known in linguistics for the light it throws on semantics; Richard Montague's use of higher-order modal logic for this purpose is widely considered to be the starting point of modern natural language semantics. Modal logic is also used to analyze syntactic structure and interesting links with formal language theory have emerged. In linguistic semantics, logic is used to formalize, or interpret, an object language. The main uses of modal logic in semantics are independent from the main concerns of modal logicians: completeness and correspondence. The two applications of modal logic to the syntax and semantics of natural languages because of the historical importance of modal logic in the development of natural language semantics and because of the significance of model theoretic syntax in current research in mathematical linguistics.",,,Studies in Logic and Practical Reasoning,,,,,,,,,,,,,,,,,,,
Journal Article,"Morrisett G,Harper R",,Typed Closure Conversion for Recursively-Defined Functions: Extended Abstract,Electronic Notes in Theoretical Computer Science,1998,10,,230-241,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105807029;http://dx.doi.org/10.1016/S1571-0661(05)80702-9,10.1016/S1571-0661(05)80702-9,"Much recent work on the compilation of statically typed languages such as ML relies on the propagation of type information from source to object code in order to increase the reliability and maintainabilty of the compiler itself and to improve the efficiency and verifiability of generated code. To achieve this the program transformations performed by a compiler must be cast as type-preserving translations between typed intermediate languages. In earlier work with Minamide we studied one important compiler transformation, closure conversion, for the case of pure simply-typed and polymorphic λ-calculus. Here we extend the treatment of simply-typed closure conversion to account for recursively-defined functions such as are found in ML. We consider three main approaches, one based on a recursive code construct, one based on a self-referential data structure, and one based on recursive types. We discuss their relative advantages and disadvantages, and sketch correctness proofs for these transformations based on the method of logical relations.",,"HOOTS II, Second Workshop on Higher-Order Operational Techniques in Semantics",,,,,,,,,,,,,,,,,,,,
Journal Article,"Siadat A,Dantan JY,Mauchand M,Martin P",,A COST ESTIMATION SYSTEM FOR MANUFACTURING PRODUCT USING ONTOLOGY AND EXEPERT SYSTEM,IFAC Proceedings Volumes,2007,40,18,37-42,,,,,2007,,1474-6670,https://www.sciencedirect.com/science/article/pii/S147466701532139X;http://dx.doi.org/10.3182/20070927-4-RO-3905.00008,10.3182/20070927-4-RO-3905.00008,"The capability to estimate accurately the internal costs of a product in the different stages of the development as well as external cost at the quote step is of a strategic importance to a company. The traditional accounting methods as well as the estimation tools have shown their limits to provide a stringent unified tool in both the accounting and the technical sides. A Method of estimation based on the Cost Entity was born recently in order to overcome the loopholes of the usual methods. This method allows from a more or less complete description of the product to link the manufacturing processes (Manufacturing Entities) with the consumption of the associated resources (Cost Entities). The highly cognitive character of such an approach suits the use of a knowledge formalization tool, like ontology. In fact, besides being a simple referencing tool for objects and concepts, the ontologies will allow to capitalize, formalize and structure the concrete knowledge (product description, process…) as well as the abstract one (calculus process, expert rules…) which are both required for cost estimations. The treatment of this knowledge to obtain cost estimation will be done by an independent expert system.","Cost estimation, ontology, cost entity, expert system, Intelligent manufacturing",4th IFAC Conference on Management and Control of Production and Logistics,,,,,,,,,,,,,,,,,,,,
Journal Article,"de Meer J,Roth R,Vuong S",,Introduction to algebraic specifications based on the language ACT ONE,Computer Networks and ISDN Systems,1992,23,5,363-392,,,,,1992,,0169-7552,https://www.sciencedirect.com/science/article/pii/016975529290013G;http://dx.doi.org/10.1016/0169-7552(92)90013-G,10.1016/0169-7552(92)90013-G,The tutorial will give an introduction to algebraic methods for system specifications. It will explain the basic mathematical theory. But the main emphasis will remain on the exposition of the methodological principles by which specifications are constructed. The concepts will be introduced on the basis of the specification language ACT ONE. We will demonstate the use of ACT ONE with an example from the OSI area.,"algebraic specification techniques, abstract data types, formal modelling, OSI, object based systems, glasnost and perestroica",,,,,,,,,,,,,,,,,,,,,
Journal Article,Cervesato I,,Typed Multiset Rewriting Specifications of Security Protocols,Electronic Notes in Theoretical Computer Science,2001,40,,8-51,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105800350;http://dx.doi.org/10.1016/S1571-0661(05)80035-0,10.1016/S1571-0661(05)80035-0,"The language MSR has successfully been used in the past to prove undecidability results about security protocols modeled according to the Dolev-Yao abstraction. In this paper, we revise this formalism into a flexible specification framework for complex crypto-protocols. More specifically, we equip it with an extensible typing-infrastructure based on dependent types with subsorting, which elegantly captures and enforces basic relations among objects, such as between a public key and its inverse. We also introduce the notion of memory predicate, where principals can store information that survives role termination. These predicates allow specifying complex protocols structured into a coordinated collection of subprotocols. Moreover, they permit describing different attacker models using the same syntax as any other role. We demonstrate this possibility and the precision of our type system by presenting two formalizations of the Dolev-Yao intruder. We discuss two execution models for this revised version of MSR, one sequential and one parallel, and prove that the latter can be simulated by the former.",,"MFCSIT2000, The First Irish Conference on the Mathematical Foundations of Computer Science and Information Technology",,,,,,,,,,,,,,,,,,,,
Journal Article,"Pinoli P,Ceri S,Martinenghi D,Nanni L",,Metadata management for scientific databases,Information Systems,2019,81,,1-20,,,,,2019,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437917306385;http://dx.doi.org/10.1016/j.is.2018.10.002,10.1016/j.is.2018.10.002,"Most scientific databases consist of datasets (or sources) which in turn include samples (or files) with an identical structure (or schema). In many cases, samples are associated with rich metadata, describing the process that leads to building them (e.g.: the experimental conditions used during sample generation). Metadata are typically used in scientific computations just for the initial data selection; at most, metadata about query results is recovered after executing the query, and associated with its results by post-processing. In this way, a large body of information that could be relevant for interpreting query results goes unused during query processing. In this paper, we present ScQL, a new algebraic relational language, whose operations apply to objects consisting of data–metadatapairs, by preserving such one-to-one correspondence throughout the computation. We formally define each operation and we describe an optimization, called meta-first, that may significantly reduce the query processing overhead by anticipating the use of metadata for selectively loading into the execution environment only those input samples that contribute to the result samples. In ScQL, metadata have the same relevance as data, and contribute to building query results; in this way, the resulting samples are systematically associated with metadata about either the specific input samples involved or about query processing, thereby yielding a new form of metadata provenance. We present many examples of use of ScQL, relative to several application domains, and we demonstrate the effectiveness of the meta-first optimization.","Metadata management, Scientific databases, Query optimization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mladenov M,Penchev S,Dejanov M",,"Complex assessment of the quality of foodstuffs through the analysis of visual images, spectrophotometric and hyperspectral characteristics",IFAC-PapersOnLine,2015,48,24,60-65,,,,,2015,,2405-8963,https://www.sciencedirect.com/science/article/pii/S2405896315026816;http://dx.doi.org/10.1016/j.ifacol.2015.12.057,10.1016/j.ifacol.2015.12.057,"This paper presents a new approach and a platform for complex, nondestructive, express evaluation of quality and safety of food products based on analysis of visual images, spectrophotometric characteristics and hyperspectral images, followed by fusion the results of these analyzes with the aim of categorization of the investigated products in quality groups. Within the context of the problem, the complex evaluation includes an assessment of the appearance and visual characteristics of the investigated product, evaluation of features associated with the composition of the product and the distribution of the features on its surface. The problem of the complex evaluation of the investigated products is represented by two main tasks: 1) The formal description of the investigated objects by fusion the data from color images, spectral and hyperspectral characteristics and 2) Evaluation of data separability in the following two aspects: separability of individual areas (e.g. areas with meat, fat and bone tissues) on a certain day of product storage and separability of data for the same area on different days of storage.","food products, quality, safety assessment, image, spectra, hyperspectral analyses","16th IFAC Conference on Technology, Culture and International Stability TECIS 2015",,,,,,,,,,,,,,,,,,,,
Journal Article,"Olarte C,Pimentel E,Xavier B",,A Fresh View of Linear Logic as a Logical Framework,Electronic Notes in Theoretical Computer Science,2020,351,,143-165,,,,,2020,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106612030044X;http://dx.doi.org/10.1016/j.entcs.2020.08.008,10.1016/j.entcs.2020.08.008,"One of the most fundamental properties of a proof system is analyticity, expressing the fact that a proof of a given formula F only uses subformulas of F. In sequent calculus, this property is usually proved by showing that the cut rule is admissible, i.e., the introduction of the auxiliary lemma A in the reasoning “if A follows from B and C follows from A, then C follows from B” can be eliminated. Mathematically, this means that we can inline the intermediate step A to have a direct proof of C from the hypothesis B. More importantly, the proof of cut-elimination shows that the proof of C follows directly from the axiomatic theory and B (and no external lemmas are needed). The proof of cut-elimination is usually a tedious process through several proof transformations, thus requiring the assistance of (semi-)automatic procedures to avoid mistakes. In a previous work by Miller and Pimentel, linear logic (LL) was used as a logical framework for establishing sufficient conditions for cut-elimination of object logics (OL). The OL's inference rules were encoded as an LL theory and an easy-to-verify criterion sufficed to establish the cut-elimination theorem for the OL at hand. Using such procedure, analyticity of logical systems such as LK (classical logic), LJ (intuitionistic logic) and substructural logics such as MALL (multiplicative additive LL) was proved within the framework. However, there are many logical systems that cannot be adequately encoded in LL, the most symptomatic cases being sequent systems for modal logics. In this paper we use a linear-nested sequent (LNS) presentation of SLL (a variant of linear logic with subexponentials) and show that it is possible to establish a cut-elimination criterion for a larger class of logical systems, including LNS proof systems for K, 4, KT, KD, S4 and the multi-conclusion LNS system for intuitionistic logic (mLJ). Impressively enough, the sufficient conditions for cut-elimination presented here remain as simple as the one proposed by Miller and Pimentel. The key ingredient in our developments is the use of the right formalism: we adopt LNS based OL systems, instead of sequent ones. This not only provides a neat encoding procedure of OLs into SLL, but it also allows for the use of the meta-theory of SLL to establish fundamental meta-properties of the encoded OLs. We thus contribute with procedures for checking cut-elimination of several logical systems that are widely used in philosophy, mathematics and computer science.","linear logic, cut elimination","Proceedings of LSFA 2020, the 15th International Workshop on Logical and Semantic Frameworks, with Applications (LSFA 2020)",,,,,,,,,,,,,,,,,,,,
Journal Article,Bettini C,,Time-dependent concepts: representation and reasoning using temporal description logics,Data & Knowledge Engineering,1997,22,1,1-38,,,,,1997,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X96000365;http://dx.doi.org/10.1016/S0169-023X(96)00036-5,10.1016/S0169-023X(96)00036-5,"A time-dependent concept is a conceptual entity that is defined in terms of temporal relationships with other entities. For example, the concept of an action is defined in terms of a set of temporal relationships among states of a system. The concept of “widow”, in natural language, is defined in terms of events that have occurred in the past. Time-dependent concepts appear in several application areas, from natural language to diagnosis, from planning to data mining. An interesting issue in knowledge representation is how to formally represent and reason with these concepts. In this paper, we represent a family of formal representation languages obtained as an interval-based temporal extension of description logics. We illustrate the expressiveness of these formalisms in representing time-dependent concepts with respect to standard description logics and other extensions. We give some complexity results for reasoning problems and we propose approximate algorithms to compute subsumption among time-dependent concepts.","Temporal knowledge, Temporal reasoning, Description logics, Taxonomies, Subsumption algorithms, Temporal objects",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ding L,Li K,Zhou Y,Love PE",,An IFC-inspection process model for infrastructure projects: Enabling real-time quality monitoring and control,Automation in Construction,2017,84,,96-110,,,,,2017,,0926-5805,https://www.sciencedirect.com/science/article/pii/S0926580517303783;http://dx.doi.org/10.1016/j.autcon.2017.08.029,10.1016/j.autcon.2017.08.029,"Comprehensive and timely inspection of quality issues is critical for reducing rework and delays in infrastructure projects. Enabling a real-time quality checking guidance system to be used in practice requires formal data exchange methods and inspection process control. This, however, remains an on-going challenge, as information is often expressed in different data representations and stored in disparate locations and formats. There have been a limited number of studies that have examined the relationship among physical objects, schedule, and quality management information related to the process of inspection as well as the difficulties associated with enabling real-time monitoring and control of quality. In addressing this issue, a design science research approach is used to develop and apply an Industrial Foundation Classes-based Inspection Process Model (IFC-IPM) to enable information exchange requirements for quality-related information to occur in real-time during construction. Within the IFC-IPM schema and extension that is developed, a physical, schedule, and quality management model exist. The IFC-IPM extension defines the dynamic property sets that form part of quality management system. The dynamic property set of the schedule can identify inspection codes, time, and its content. This provides inspectors with the ability to undertake real-time quality monitoring and control. The IFC-IPM that is developed is applied to a real-life subway infrastructure project. It is demonstrated that the developed IFC-IPM provides an effective platform for data sharing and exchange of quality related information and other IFC-compliant applications. The model can be used to streamline the quality management process as it reduces the time to attend to undertake rework and increases the accuracy and timeliness of inspections and the acceptance of activities and products.","BIM, Design science, Infrastructure, IFC, Quality detection, Real-time monitoring",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lesser VR,Nawab SH,Klassner FI",,IPUS: an architecture for the integrated processing and understanding of signals,Artificial Intelligence,1995,77,1,129-171,,,,,1995,,0004-3702,https://www.sciencedirect.com/science/article/pii/000437029400033W;http://dx.doi.org/10.1016/0004-3702(94)00033-W,10.1016/0004-3702(94)00033-W,"The Integrated Processing and Understanding of Signals (IPUS) architecture is presented as a framework that exploits formal signal processing models to structure the bidirectional interaction between front-end signal processing and signal understanding processes. This architecture is appropriate for complex environments, which are characterized by variable signal-to-noise ratios, unpredictable source behaviors, and the simultaneous occurrence of objects whose signal signatures can distort each other. A key aspect of this architecture is that front-end signal processing is dynamically modifiable in response to scenario changes and to the need to reanalyze ambiguous or distorted data. The architecture tightly integrates the search for the appropriate front-end signal processing configuration with the search for plausible interpretations. In our opinion, this dual search, informed by formal signal processing theory, is a necessary component of perceptual systems that must interact with complex environments. To explain this architecture in detail, we discuss examples of its use in an implemented system for acoustic signal interpretation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ibrahim RW,Hasan AM,Jalab HA",,A new deformable model based on fractional Wright energy function for tumor segmentation of volumetric brain MRI scans,Computer Methods and Programs in Biomedicine,2018,163,,21-28,,,,,2018,,0169-2607,https://www.sciencedirect.com/science/article/pii/S0169260718301974;http://dx.doi.org/10.1016/j.cmpb.2018.05.031,10.1016/j.cmpb.2018.05.031,"Background and objectives The MRI brain tumors segmentation is challenging due to variations in terms of size, shape, location and features’ intensity of the tumor. Active contour has been applied in MRI scan image segmentation due to its ability to produce regions with boundaries. The main difficulty that encounters the active contour segmentation is the boundary tracking which is controlled by minimization of energy function for segmentation. Hence, this study proposes a novel fractional Wright function (FWF) as a minimization of energy technique to improve the performance of active contour without edge method. Method In this study, we implement FWF as an energy minimization function to replace the standard gradient-descent method as minimization function in Chan–Vese segmentation technique. The proposed FWF is used to find the boundaries of an object by controlling the inside and outside values of the contour. In this study, the objective evaluation is used to distinguish the differences between the processed segmented images and ground truth using a set of statistical parameters; true positive, true negative, false positive, and false negative. Results The FWF as a minimization of energy was successfully implemented on BRATS 2013 image dataset. The achieved overall average sensitivity score of the brain tumors segmentation was 94.8 ± 4.7%. Conclusions The results demonstrate that the proposed FWF method minimized the energy function more than the gradient-decent method that was used in the original three-dimensional active contour without edge (3DACWE) method.","Fractional calculus, Wright function, Segmentation, Active contour, MRI scan",,,,,,,,,,,,,,,,,,,,,
Journal Article,Roitman M,,On twisted representations of vertex algebras,Advances in Mathematics,2003,176,1,53-88,,,,,2003,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870802000567;http://dx.doi.org/10.1016/S0001-8708(02)00056-7,10.1016/S0001-8708(02)00056-7,"In this paper, we develop a formalism for working with representations of vertex and conformal algebras by generalized fields—formal power series involving non-integer powers of the variable. The main application of our technique is the construction of a large family of representations for the vertex superalgebra VΛ corresponding to an integer lattice Λ. For an automorphism σ̂:VΛ→VΛ coming from a finite-order automorphism σ:Λ→Λ we find the conditions for existence of twisted modules of VΛ. We show that the category of twisted representations of VΛ is semisimple with finitely many isomorphism classes of simple objects.","Vertex algebras, Conformal algebras, Lattice vertex algebras, Twisted modules, Semisimple categories",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Radke H,Arendt T,Becker JS,Habel A,Taentzer G",,Translating essential OCL invariants to nested graph constraints for generating instances of meta-models,Science of Computer Programming,2018,152,,38-62,,,,,2018,,0167-6423,https://www.sciencedirect.com/science/article/pii/S016764231730165X;http://dx.doi.org/10.1016/j.scico.2017.08.006,10.1016/j.scico.2017.08.006,"Domain-specific modeling languages (DSMLs) are usually defined by meta-modeling using the Object Constraint Language (OCL) for specifying invariants. This approach is purely declarative in the sense that instance construction is not supported. In contrast, grammar-based language definition incorporates the stepwise construction of instances by applying production rules. Since the underlying structure of models are generally graphs, graph grammars are well suited to define modeling languages. Establishing a formal relation between meta-modeling and graph grammars opens up the possibility to integrate techniques of both fields. This integration can be advantageously used for optimizing DSML definition. We follow an approach where a meta-model is translated to a type graph with a set of nested graph constraints. While previous meta-model translations neglected OCL constraints, we focus on the translation of Essential OCL invariants to nested graph constraints in this paper. We show that a model satisfies an Essential OCL invariant iff its corresponding instance graph satisfies the corresponding nested graph constraint. In addition, nested graph constraints can be translated to application conditions of graph transformation rules. Composing both translations, an instance-generating graph grammar can be equipped with application conditions such that it generates instances of the original meta-model only.","Meta modeling, Essential OCL, Graph constraints, Instance generation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Yagiu T,,A predicate-logical method for modelling design objects,Artificial Intelligence in Engineering,1989,4,1,41-53,,,,,1989,,0954-1810,https://www.sciencedirect.com/science/article/pii/0954181089900241;http://dx.doi.org/10.1016/0954-1810(89)90024-1,10.1016/0954-1810(89)90024-1,"The subject of this paper is to formulate a modeller to descibe and manipulate models of design objects primarily in discrete manufacturing in terms of whatever attributes, functions of or relations among them are desired. Critical analysis is made on samples from typical past and current methods to reveal that none of them meets the requirements proper to CAD/CAM. These requirements derive from the more fundamental characteristics of our universe of discourse, the core fact being that the target of modelling is the ‘real’ world of physical and sensible entities and phenomena. This fact together with the desired formalness of the modeller makes us turn to the theories of natural-scientific structures, particularly those of logical-positivistic tradition and choose D. Hilbert's formal-axiomatic method of constructing mathematical disciplines as our paradigm. A sketch of a modeller in accordance with this paradigm is given.A model to be constructed contains a set of first order predicate-logical formulae as axioms that represent design requirements and a fact database that is an interpretation. The language of a partial implementation of the said modeller which has been in practical use for several years is presented in more details.","intelligent CAD, product model, engineering database, deductive database, design theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang Y,Chiew V",,On the cognitive process of human problem solving,Cognitive Systems Research,2010,11,1,81-92,,,,,2010,,1389-0417,https://www.sciencedirect.com/science/article/pii/S1389041708000417;http://dx.doi.org/10.1016/j.cogsys.2008.08.003,10.1016/j.cogsys.2008.08.003,"One of the fundamental human cognitive processes is problem solving. As a higher-layer cognitive process, problem solving interacts with many other cognitive processes such as abstraction, searching, learning, decision making, inference, analysis, and synthesis on the basis of internal knowledge representation by the object–attribute-relation (OAR) model. Problem solving is a cognitive process of the brain that searches a solution for a given problem or finds a path to reach a given goal. When a problem object is identified, problem solving can be perceived as a search process in the memory space for finding a relationship between a set of solution goals and a set of alternative paths. This paper presents both a cognitive model and a mathematical model of the problem solving process. The cognitive structures of the brain and the mechanisms of internal knowledge representation behind the cognitive process of problem solving are explained. The cognitive process is formally described using real-time process algebra (RTPA) and concept algebra. This work is a part of the cognitive computing project that designed to reveal and simulate the fundamental mechanisms and processes of the brain according to Wang’s layered reference model of the brain (LRMB), which is expected to lead to the development of future generation methodologies for cognitive computing and novel cognitive computers that are capable of think, learn, and perceive.","Cognitive informatics, Cognitive computing, Brain informatics, Computational intelligence, Reference model of the brain, Cognitive processes, Problem solving, Mathematical model, Concept algebra, RTPA",Brain Informatics,,,,,,,,,,,,,,,,,,,,
Journal Article,Schwer SR,,S-arrangements avec répétitions,Comptes Rendus Mathematique,2002,334,4,261-266,,,,,2002,,1631-073X,https://www.sciencedirect.com/science/article/pii/S1631073X02022586;http://dx.doi.org/10.1016/S1631-073X(02)02258-6,10.1016/S1631-073X(02)02258-6,"Résumé Nous étudions les correspondances naturelles entre l'ensemble des arrangements de parties d'un ensemble avec répétitions et des ensembles d'objets rencontrés dans des domaines variés des mathématiques (chemins dans des treillis de dimension n, pré-ordres) et de l'informatique (langages formels, réseaux de Petri, intelligence artificielle), en utilisant le cadre des langages formels. En dimension 2, ces objets sont énumérés par les nombres de Delannoy. Pour citer cet article : S.R. Schwer, C. R. Acad. Sci. Paris, Ser. I 334 (2002) 261–266. We study natural correspondances between the set of arrangements of subsets with repetitions and families of objects met in various areas of mathematics (walks in lattices, pre-order) and computer science (formal languages, Petri nets, Artificial Intelligence), using the framework of formal languages. For n=2, they are enumerated by Delannoy numbers. To cite this article: S.R. Schwer, C. R. Acad. Sci. Paris, Ser. I 334 (2002) 261–266.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferrucci L,Ricci L,Albano M,Baraglia R,Mordacchini M",,Multidimensional range queries on hierarchical Voronoi overlays,Journal of Computer and System Sciences,2016,82,7,1161-1179,,,,,2016,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000016300204;http://dx.doi.org/10.1016/j.jcss.2016.04.008,10.1016/j.jcss.2016.04.008,"The definition of a support for multi-attribute range queries is mandatory for highly distributed systems. Even if several solutions have been proposed in the last decade, most of them do not meet the requirements of recent platforms, like IoT or smart cities. The paper presents an approach that builds a multidimensional Voronoi graph by exploiting the attributes of the objects published by a node. Our solution overcomes the curse of dimensionality issue affecting Voronoi Tessellations in high dimensional spaces by defining a Voronoi hierarchy. The paper formally defines the structure, analysis the complexity of the operations and presents experimental results.","Distributed systems, Range queries, Voronoi",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhang J,He L,Karkee M,Zhang Q,Zhang X,Gao Z",,Branch detection for apple trees trained in fruiting wall architecture using depth features and Regions-Convolutional Neural Network (R-CNN),Computers and Electronics in Agriculture,2018,155,,386-393,,,,,2018,,0168-1699,https://www.sciencedirect.com/science/article/pii/S0168169918304162;http://dx.doi.org/10.1016/j.compag.2018.10.029,10.1016/j.compag.2018.10.029,"Due to the rising cost and decreasing availability of labor, manual picking is becoming an increasing challenge for apple growers. A targeted shake-and-catch apple harvesting technique is being developed at Washington State University to address this challenge. The performance and productivity of such a harvesting technique can be increased greatly if the shaking process is automated. The first step toward automated shaking is the detection and localization of branches in apple tree canopies. A branch detection method was developed in this work for apple trees trained in a formal, fruiting wall architecture using depth features and a Regions-Convolutional Neural Network (R-CNN). Microsoft Kinect v2 was used to acquire RGB images and pseudo-color images, as well as depth images in natural orchard environment. The R-CNN was composed of an improved AlexNet network and was trained to detect apple tree branches using integrated pseudo-color and depth images for improved detection accuracy. The average recall and accuracy from the Pseudo-Color Image and Depth (PCI-D) method were 92% and 86% respectively when the R-CNN confidence level of the pseudo-color image was 50%. For comparison, when using the Pseudo-Color Image (PCI) method (without depth images), these averages were only 86% and 81%, respectively. Furthermore, the average correlation coefficient (r) between the fitting curves for branch skeletons using the PCI-D method and the fitting curves for ground-truth images was 0.91—another indicator that the PCI-D method performs better than the PCI method. In addition, the average accuracy of branch detection increased with both the PCI method and PCI-D method, since the sensor was closer to the canopy. This study demonstrates the great potential for using depth features in branch detection and skeleton estimation to develop effective shake-and-catch apple harvesting machines for use in formally trained apple orchards.","Branch detection, Branch skeleton fitting, Shake-and-catch apple harvesting, R-CNN, Depth features",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gançarski S,Jomier G",,A framework for programming multiversion databases,Data & Knowledge Engineering,2001,36,1,29-53,,,,,2001,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X00000331;http://dx.doi.org/10.1016/S0169-023X(00)00033-1,10.1016/S0169-023X(00)00033-1,"Multiversion databases allow to represent in a database several states, or versions, of the real world entities. To take into account the new dimension introduced by versioning, new operations must be added to conventional database programming languages. In this paper, we describe such operations according to the DataBase Version (DBV) model, which allows an efficient management of as many versions as needed. Operations are first presented intuitively, then formal definitions of their syntax and their semantics is given. The work presented is considered as a syntactical framework for the development of sophisticated tools for design applications and configuration management. Special attention is paid to operations on complex object versions.","Database, Version, Context of versions, Programming language",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lämmel R,Thompson S,Kaiser M",,Programming errors in traversal programs over structured data,Science of Computer Programming,2013,78,10,1770-1808,,,,,2013,,0167-6423,https://www.sciencedirect.com/science/article/pii/S0167642311002061;http://dx.doi.org/10.1016/j.scico.2011.11.006,10.1016/j.scico.2011.11.006,"Traversal strategies à la Stratego (also à la Strafunski and ‘Scrap Your Boilerplate’) provide an exceptionally versatile and uniform means of querying and transforming deeply nested and heterogeneously structured data including terms in functional programming and rewriting, objects in OO programming, and XML documents in XML programming. However, the resulting traversal programs are prone to programming errors. We are specifically concerned with errors that go beyond conservative type errors; examples we examine include divergent traversals, prematurely terminated traversals, and traversals with dead code. Based on an inventory of possible programming errors we explore options of static typing and static analysis so that some categories of errors can be avoided. This exploration generates suggestions for improvements to strategy libraries as well as their underlying programming languages. Haskell is used for illustrations and specifications with sufficient explanations to make the presentation comprehensible to the non-specialist. The overall ideas are language-agnostic and they are summarized accordingly.","Traversal strategies, Traversal programming, Term rewriting, Stratego, Strafunski, Generic programming, Scrap your boilerplate, Type systems, Static program analysis, Functional programming, XSLT, Haskell",Special section on Language Descriptions Tools and Applications (LDTA’08 & ’09) & Special section on Software Engineering Aspects of Ubiquitous Computing and Ambient Intelligence (UCAmI 2011),,,,,,,,,,,,,,,,,,,,
Journal Article,Cheung TY,,Petri nets for protocol engineering,Computer Communications,1996,19,14,1250-1257,,,,,1996,,0140-3664,https://www.sciencedirect.com/science/article/pii/S0140366496011589;http://dx.doi.org/10.1016/S0140-3664(96)01158-9,10.1016/S0140-3664(96)01158-9,"This paper presents a review of the role Petri nets play in protocol engineering. This methodology provides various models for specification and many methods for verification and other software engineering tasks concerning protocols. In particular, many property-preserving transformations and compositional methods are available for reducing the impact of state explosion on the two well-known verification approaches — reachability analysis and invariant analysis. By conversion, Petri nets can be used for studying systems specified by many of the formal description techniques frequently used for protocol investigation such as MSC, SDL, ESTELLE, LOTOS, CCS, CSP and CCSP. For example, Petri nets can be used for deriving test sequences and cyclomatic complexity measure for LOTOS. Also, many equivalence relations concerning the theoretical foundation of protocol engineering have been formulated on the basis of Petri nets. Other developments of Petri nets related to protocols include: Petri nets with temporal logic, feature interaction, synthesis, complexity measure, timed or object-related Petri nets, etc.","Formal description technique, Invariant, Petri net, Protocol, Reachability, Specification, Synthesis, Testing, Verification",Protocol Engineering,,,,,,,,,,,,,,,,,,,,
Journal Article,"Holzhey CF,Wilczek F",,Black holes as elementary particles,Nuclear Physics B,1992,380,3,447-477,,,,,1992,,0550-3213,https://www.sciencedirect.com/science/article/pii/0550321392902549;http://dx.doi.org/10.1016/0550-3213(92)90254-9,10.1016/0550-3213(92)90254-9,"It is argued that the qualitative features of black holes, regarded as quantum-mechanical objects, depend both on the parameters of the hole and on the microscopic theory in which it is embedded. A thermal description is inadequate for external holes. In particular, extreme holes of the charged dilaton family can have entropy but nonzero, and even (for a > 1) formally infinite, temperature. The existence of a tendency to radiate at the extreme, which threatens to overthrow any attempt to identify the entropy as available internal states and also to expose a naked singularity, is at first quite disturbing. However, by analyzing the perturbations around the extreme holes we show that these holes are protected by mass gaps, or, alternatively, potential barriers, which removes them from thermal contact with the external world. We suggest that the behavior of these extreme-dilation black holes, which from the point of view of traditional black-hole theory seems quite bizarre, can reasonably be interpreted as the holes doing their best to behave like normal elementary particles. The a < 1 holes behave qualitatively as extended objects.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Cioni G,Kreczmar A","Cioni G,Salwicki A",Modules in high level programming languages,,1989,,,247-340,,Academic Press,,Advanced Programming Methodologies,1989,9780121746902,,https://www.sciencedirect.com/science/article/pii/B9780121746902500149;http://dx.doi.org/10.1016/B978-0-12-174690-2.50014-9,10.1016/B978-0-12-174690-2.50014-9,"Publisher Summary An average user appreciates a programming language looking at the easiness of programming, which depends mainly on its expressive power and its security. Generally, it is not necessary to understand even what the implementation of a programming language is. However, experienced programmers know quite well that without a deeper knowledge of some implementation aspects, the real software would never exist. This chapter discusses the kinds of programming languages; the module structure of a program; the blocks, procedures, and functions of a program; the cooperation of coroutines, coroutine sequencing, and the different passing modes of parameters. Some high level programming languages, like ALGOL 60, PL/1 and Pascal, allow procedures and functions as parameters, that is, they admit formal procedure construct. This important construct is easy in use; however, the precise semantics needs some deeper insight. One of the most important characteristics of classes is the possibility of defining abstract data types. An important feature that extends the power and the flexibility of classes is inheritance rule [CURR], [ING], [MEY], sometimes called prefixing [SIM]. Inheritance is a method for module extending by some new specifications and actions that are added to the previous ones. It can be said that such a module inherits all the properties of its parent module.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tsoukiàs A,Mousseau V",,Ordinal Measurement in Decision Aid,Electronic Notes in Discrete Mathematics,1999,2,,186-187,,,,,1999,,1571-0653,https://www.sciencedirect.com/science/article/pii/S1571065304000459;http://dx.doi.org/10.1016/S1571-0653(04)00045-9,10.1016/S1571-0653(04)00045-9,"The paper presents an ongoing research project concerning the use of ordinal measurement in situations of decision aiding. It is more and more often necessary to handle ordinal information and qualitative data in decision situations and our project aims to provide flexible and reliable tools in such cases. Our paper is organized in three main subject areas. In the first part we define the problem of ordinal measurement aggregation (for instance: a three dimension object which is “high”, “large” and “short” is a “big” object?). We also introduce the problem of hierarchical aggregation when the dimensions under which a set of objects has to be analyzed form a hierarchy. From a formal point of view the problem consists in defining a comprehensive ordinal measurement of each object taking in account a subset of evaluation dimensions. We demonstrate that a meaningful ordinal measure can be obtained using aggregation procedures based on majority rules, voting schemes and the concordance/discordance principle. Such procedures are then compared to methods based on valued similarity, fuzzy classification and rule based classification. In the second part we try to stress the specificity of decision aiding situations where ordinal measurement is required. The problem mainly arises when the evaluation model is constructed from a set of examples through a learning process. Besides the use of conventional “machine learning” techniques we claim the necessity of ad-hoc procedures enabling the client of the decision aid to understand the use of the examples and the definition of the evaluation model. In this part we present some learning techniques based on a measurement “disaggregation” principle. In the third part we try to demonstrate the usefulness of our approach in decision aiding situations. Besides some empirical validation in real life decision problems we discuss both the meaningfulness of aggregated measures and the efficiency of learning procedures. A distinction between descriptive and constructive learning is introduced and discussed. Open research directions and the further steps of our project conclude our paper.","ordinal scales, aggregation, decision aid, learning","OSDA98, Ordinal and Symbolic Data Analysis",,,,,,,,,,,,,,,,,,,,
Journal Article,"Catarci T,D'Angiolini G,Lenzerini M",,Conceptual language for statistical data modeling,Data & Knowledge Engineering,1995,17,2,93-125,,,,,1995,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X95984355;http://dx.doi.org/10.1016/0169-023X(95)98435-5,10.1016/0169-023X(95)98435-5,"We describe a new language for statistical data modeling. The language offers a general framework for the representation of elementary and summary data, and has three main characteristics: (i) the types of modeling primitives it provides are particularly suited for representing objects from a statistical point of view; (ii) it includes a rich set of structuring mechanisms for both elementary and summary data, which are given a formal semantics by means of logic; (iii) it is equipped with specialized inference procedures, allowing to perform different kinds of checks on the representation. The language is intended to be used during the specification phase of a statistical database, which we consider a knowledge-driven activity, where the availability of both powerful structuring mechanisms and suitable reasoning techniques constitute a valuable tool to the designer. The main focus of this paper is on the formal foundation of our approach. We describe the syntax and the semantics of the language, and we discuss its use in statistical data modeling. Also, we describe the basis for devising inference techniques for our language. Such techniques are based on an interesting correspondence between the language and propositional dynamic logic.","Statistical data modeling, Knowledge representation, Logic, Reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Moran T,Naor M",,Basing cryptographic protocols on tamper-evident seals,Theoretical Computer Science,2010,411,10,1283-1310,,,,,2010,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397509007750;http://dx.doi.org/10.1016/j.tcs.2009.10.023,10.1016/j.tcs.2009.10.023,"In this article, we attempt to formally study two very intuitive physical models: sealed envelopes and locked boxes, often used as illustrations for common cryptographic operations. We relax the security properties usually required from locked boxes [such as in bit-commitment (BC) protocols] and require only that a broken lock or torn envelope be identifiable to the original sender. Unlike the completely impregnable locked box, this functionality may be achievable in real life, where containers having this property are called “tamper-evident seals”. Another physical object with this property is the “scratch-off card”, often used in lottery tickets. We consider three variations of tamper-evident seals, and show that under some conditions they can be used to implement oblivious transfer, BC and coin flipping (CF). We also show a separation between the three models. One of our results is a strongly fair CF protocol with bias bounded by O(1/r) (where r is the number of rounds); this was a stepping stone towards achieving such a protocol in the standard model (in subsequent work).","Tamper-evident seals, Human, Protocol, Universally composable, Coin flipping",ICALP 2005 - Track C: Security and Cryptography Foundations,,,,,,,,,,,,,,,,,,,,
Journal Article,"Haynes LS,Morris GH",,A formal approach to specifying assembly operations,International Journal of Machine Tools and Manufacture,1988,28,3,281-298,,,,,1988,,0890-6955,https://www.sciencedirect.com/science/article/pii/0890695588900193;http://dx.doi.org/10.1016/0890-6955(88)90019-3,10.1016/0890-6955(88)90019-3,"Experience has proved that exploiting robots for assembly tasks is much more difficult than manufacturing engineers had expected and many attempts at implementing robotic assembly have failed. Our research has led us to believe that a formal approach to specifying the steps required for assembly would be of great benefit in developing the required software for a specific task, and in adaptively controlling and monitoring the execution of robotic assembly steps. The US National Bureau of Standards has developed a formal system, called ABC (for Assembly By Constraints) for specifying the steps required for assembly. The system is based on the reduction in the degrees of freedom of objects as they are assembled. Using this basic concept, we have developed 14 primitive operations which can be used to completely specify assembly steps for a large class of problems. This paper initially outlines the historical development of the system, then describes two pieces of software developed to allow easy definition of assembly tasks using the ABC system, and finally presents two practical examples.",,"ROBOTICS and AI: Sensing, Reasoning, Planning, Manipulation and Mobility",,,,,,,,,,,,,,,,,,,,
Journal Article,"Denzler J,Niemann H",,Active Rays: Polar-transformed Active Contours for Real-Time Contour Tracking,Real-Time Imaging,1999,5,3,203-213,,,,,1999,,1077-2014,https://www.sciencedirect.com/science/article/pii/S1077201497901169;http://dx.doi.org/10.1006/rtim.1997.0116,10.1006/rtim.1997.0116,"In this paper we describe a new approach to contour extraction and tracking, which is based on the principles of active contour models and overcomes its shortcomings. We formally introduce active rays, describe the contour extraction as an energy minimization problem and discuss what active contours and active rays have in common. The main difference is that for active rays a unique ordering of the contour elements in the 2D image plane is given, which cannot be found for active contours. This is advantageous for predicting the contour elements' position and prevents crossings in the contour. Further, another advantage is that instead of an energy minimization in the 2D image plane the minimization is reduced to a 1D search problem. The approach also shows any-time behavior, which is important with respect to real-time applications. Finally, the method allows for the management of multiple hypotheses of the object's boundary. This is an important aspect if concave contours are to be tracked. Results on real image sequences (tracking a toy train in a laboratory scene, tracking pedestrians in an outdoor scene) show the suitability of this approach for real-time object tracking in a closed loop between image acquisition and camera movement. The contour tracking can be done within the image frame rate (25 fps) on standard Unix workstations (HP 735) without any specialized hardware.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Daum S,Borrmann A",,Processing of Topological BIM Queries using Boundary Representation Based Methods,Advanced Engineering Informatics,2014,28,4,272-286,,,,,2014,,1474-0346,https://www.sciencedirect.com/science/article/pii/S1474034614000391;http://dx.doi.org/10.1016/j.aei.2014.06.001,10.1016/j.aei.2014.06.001,"Building Information Models (BIM) are comprehensive digital representations of buildings, which provide a large set of information originating from the different disciplines involved in the design, construction and operation processes. Moreover, accessing the data needed for a specific downstream application scenario is a challenging task in large-scale BIM projects. Several researchers recently proposed using formal query languages for specifying the desired information in a concise, well-defined manner. One of the main limitations of the languages introduced so far, however, is the inadequate treatment of geometric information. This is a significant drawback, as buildings are inherently spatial objects and qualitative spatial relationships accordingly play an important role in the analysis and verification of building models. In addition, the filters needed in specific data exchange scenarios for selecting the information required can be built by spatial objects and their relations. The lack of spatial functionality in BIM query languages is filled by the Query Language for Building Information Models (QL4BIM) which provides metric, directional and topological operators for defining filter expressions with qualitative spatial semantics. This paper focuses on the topological operators provided by the language. In particular, it presents a new implementation method based on the boundary representation of the operands which outperforms the previously presented octree-based approaches. The paper discusses the developed algorithms in detail and presents extensive performance tests.","Building information modeling, 3D spatial query language, Topology, Boundary representation, QL4BIM",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mi P,Scacchi W",,A meta-model for formulating knowledge-based models of software development,Decision Support Systems,1996,17,4,313-330,,,,,1996,,0167-9236,https://www.sciencedirect.com/science/article/pii/0167923696000073;http://dx.doi.org/10.1016/0167-9236(96)00007-3,10.1016/0167-9236(96)00007-3,"In this paper, we introduce a knowledge-based meta-model which serves as a unified resource model for integrating characteristics of major types of objects appearing in software development models (SDMs). The URM consists of resource classes and a web of relations that link different types of resources found in different kinds of models of software development. The URM includes specialized models for software models for software systems, documents, agents, tools, and development processes. The URM has served as the basis for integrating and interoperating a number of process-centered CASE environments. The major benefit of the URM is twofold: First, it forms a higher level of abstraction supporting SDM formulation that subsumes many typical models of software development objects. Hence, it enables a higher level of reusability for existing support mechanisms of these models. Second, it provides a basis to support complex reasoning mechanisms that address issues across different types of software objects. To explore these features, we describe the URM both formally and with a detailed example, followed by a characterization of the process of SDM composition, and then by a characterization of the life cycle of activities involved in an overall model formulation process.","Meta-modeling model composition, Software process modeling, Knowledge-based modelling, Knowledge-based models of software development",DSS on Model Formulation,,,,,,,,,,,,,,,,,,,,
Journal Article,"Wang Z,Qu H,Wu Z,Wang X",,Geo3DML: A standard-based exchange format for 3D geological models,Computers & Geosciences,2018,110,,54-64,,,,,2018,,0098-3004,https://www.sciencedirect.com/science/article/pii/S0098300417302716;http://dx.doi.org/10.1016/j.cageo.2017.09.008,10.1016/j.cageo.2017.09.008,"A geological model (geomodel) in three-dimensional (3D) space is a digital representation of the Earth's subsurface, recognized by geologists and stored in resultant geological data (geodata). The increasing demand for data management and interoperable applications of geomodelscan be addressed by developing standard-based exchange formats for the representation of not only a single geological object, but also holistic geomodels. However, current standards such as GeoSciML cannot incorporate all the geomodel-related information. This paper presents Geo3DML for the exchange of 3D geomodels based on the existing Open Geospatial Consortium (OGC) standards. Geo3DML is based on a unified and formal representation of structural models, attribute models and hierarchical structures of interpreted resultant geodata in different dimensional views, including drills, cross-sections/geomaps and 3D models, which is compatible with the conceptual model of GeoSciML. Geo3DML aims to encode all geomodel-related information integrally in one framework, including the semantic and geometric information of geoobjects and their relationships, as well as visual information. At present, Geo3DML and some supporting tools have been released as a data-exchange standard by the China Geological Survey (CGS).","Geo3DML, Geological model, Standard, Data exchange",,,,,,,,,,,,,,,,,,,,,
Journal Article,Yoshida T,,Categorical Aspects of Generating Functions (I): Exponential Formulas and Krull–Schmidt Categories,Journal of Algebra,2001,240,1,40-82,,,,,2001,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869300986022;http://dx.doi.org/10.1006/jabr.2000.8602,10.1006/jabr.2000.8602,"In this paper, we study formal power series with exponents in a category. For example, the generating function of a category E with finite hom sets is defined by E(t)=∑tX/|Aut(X)|, where the summation is taken over all isomorphism classes of objects of E. We can use such power series to enumerate the number of E-structures along a faithful functor (Theorem 4.6). Our theory is closely related to the theory of species (Joyal, 1981). A species can be identified with a faithful functor from a groupoid to the category of finite sets (Theorem 3.6). We use mainly the concept of faithful functors with finite fibers instead of species, so that we can separate the roles categories and functors play. For example, the exponential formula E(t)=exp(Con(E)(t)) means the unique coproduct decomposition property (Theorem 5.8). In the final section, we give some applications of our theory to rather classical enumerations.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li N,Hao H,Gu Q,Wang D,Hu X",,A transfer learning method for automatic identification of sandstone microscopic images,Computers & Geosciences,2017,103,,111-121,,,,,2017,,0098-3004,https://www.sciencedirect.com/science/article/pii/S0098300416303557;http://dx.doi.org/10.1016/j.cageo.2017.03.007,10.1016/j.cageo.2017.03.007,"Classification of sandstone microscopic images is an essential task in geology, and the classical method is either subjective or time-consuming. Computer aided automatic classification has been proved useful, but it seldom considers the situation where sandstone images are collected from separated regions. In this paper, we provide a method called Festra, which uses transfer learning to handle the problem of interregional sandstone microscopic image classification. The method contains two parts: one is feature selection, which aims to screen out features having great difference between the regions, the other is instance transfer using an enhanced TrAdaBoost, whose object is to mitigate the difference among thin section images collected from the regions. Experiments are conducted based on the sandstone images taken from four regions in Tibet to study the performance of Festra. The experimental results have proved both effectiveness and validity of Festra, which provides competitive prediction performance on all the four regions, with few target instances labeled suitable for the field use.","Transfer learningSandstone microscopic image, Automatic classification, Feature selection, Classification model",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Baltaci Akhuseyinoglu N,Joshi J",,A constraint and risk-aware approach to attribute-based access control for cyber-physical systems,Computers & Security,2020,96,,101802,,,,,2020,,0167-4048,https://www.sciencedirect.com/science/article/pii/S0167404820300869;http://dx.doi.org/10.1016/j.cose.2020.101802,10.1016/j.cose.2020.101802,"Cyber-physical systems (CPSs) integrate cyber components and physical processes. This integration enhances the capabilities of physical systems by incorporating intelligence into objects and services. On the other hand, the integration of cyber and physical components and the interaction between them introduce new security threats. Since CPSs are mostly safety-critical systems, data stored and communicated in them are highly critical. Hence, there is a crucial need for protecting the data and resources in CPSs against unauthorized accesses. In this paper, we propose an access control (AC) framework to address CPS related security issues. The proposed framework consists of two parts: a Cyber-Physical Access Control model (CPAC) and a Generalized Action Generation Model (GAGM). CPAC utilizes an attribute-based approach and extends it with cyber-physical components and cyber-physical interactions. In addition, we incorporate Separation of Duty (SoD) constraints into the CPAC model. GAGM is used to augment the enforcement of access policies. We present formal representations of CPAC and GAGM and demonstrate their use in a sample scenario for a medical CPS. We propose an algorithm for enforcing authorization policies. We implement the CPAC model and compare its performance against the core attribute-based access control model. We present an authorization enforcement approach and show through our experimental results its feasibility.","Attribute-based access control, Cyber-physical systems, Action generation, Risk, Separation of duties",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ambroziak JR,Kleiber M",,Blackboard consultation in solid mechanics,Engineering Applications of Artificial Intelligence,1991,4,2,85-95,,,,,1991,,0952-1976,https://www.sciencedirect.com/science/article/pii/095219769190048B;http://dx.doi.org/10.1016/0952-1976(91)90048-B,10.1016/0952-1976(91)90048-B,"The paper describes a consultation system for constitutive modelling of materials in solid mechanics. The reasons for applying the blackboard framework in a mechanics consultation system are briefly explained. The functioning of an example blackboard implementation is concisely described. It is shown that due to the generality and flexibility of the blackboard architecture an effective deduction scheme can be naturally implemented by introducing a special notation to represent clauses in a structured-object form. The form is demonstrated to be a computationally convenient means of expressing predicate calculus formulae. Finally, the inference procedure with reason maintenance is described as a cooperation between several knowledge sources. It is claimed that the blackboard architecture provides an accurate and explicit means of controlling deduction, as well as the overall consultation.","Expert systems, blackboard architecture, LISP-like symbolic language, constitutive material modelling",,,,,,,,,,,,,,,,,,,,,
Journal Article,Jürgensen H,,Higher-level constructs for families and multisets,Theoretical Computer Science,2017,682,,138-148,,,,,2017,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397517301366;http://dx.doi.org/10.1016/j.tcs.2017.01.034,10.1016/j.tcs.2017.01.034,"In an earlier paper we argued that the concept of multisets should be based on families, that is, on sets and functions between sets, rather than, as usual, on sets and cardinal numbers. We showed how certain fundamental problems regarding the distinguishablity of objects as well as unexpected anomalies of the basic operations of union, intersection, and complement can be avoided elegantly using families rather than multisets. On the other hand, there is a trivial mapping of families to multisets. Hence, using families does not introduce any significant formal complications. The difficulties with the usual definition of multisets by multiplicities reach beyond the philosophical or metamathematical foundations. For the basic operations one can find acceptable compromises. For higher-level set constructs like Cartesian products, projections, relations, functions, or the power set the multiset counterparts are rather contrived, and many of the constructions leave the strict definition of multisets, actually introducing family-like constructs through a back door. In the earlier paper we proposed to use families instead of multisets to resolve the basic problems. In this paper we show that families instead of multisets support the higher-level constructions even, when no appropriate multiset-based constructions exist. We also show that multisets form a category and that the natural mapping from families to multisets is a functor. This emphasizes our claim that, for a definition of multisets, one should start with families and only introduce multiplicities as a secondary concept.","Multiset, Bag, Family, Set",Special Issue on Languages and Combinatorics in Theory and Nature,,,,,,,,,,,,,,,,,,,,
Journal Article,"Díaz M,Garrido D,Llopis L,Troya JM",,Designing distributed software with RT-CORBA and SDL,Computer Standards & Interfaces,2009,31,6,1073-1091,,,,,2009,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548908001578;http://dx.doi.org/10.1016/j.csi.2008.09.033,10.1016/j.csi.2008.09.033,"The use of formal description techniques (FDTs), and specifically SDL, has emerged as an interesting way of designing embedded real time distributed systems (ERTDSs) taking into account the increasing complexity of this kind of system. The communication platform for these ERTDSs should be included at the design stage in order to consider the behaviour of the communications. RT-CORBA is an interesting alternative as a middleware for real-time distributed applications because, unlike standard CORBA, it guarantees predictable temporal response to invocations to remote objects. We propose a set of design patterns in SDL for the RT-CORBA middleware so that users can integrate the communication behavior into their designs. This approach provides three important results: firstly, it is possible to carry out the simulation and validation of the whole system including communications; secondly, the implementation stage is simplified because the integration of RT-CORBA allows code to be generated from the design. Finally, different analysis techniques at design level for ERTDS including the temporal behavior of RT-CORBA middleware can be carried out. To apply our proposals we have integrated the design of RT-CORBA with the SDL specification of a distributed control application called Siroco.","RT-CORBA, SDL, Software engineering, Distributed, Design",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Nilsson NJ,Nilsson NJ,CHAPTER 9 - STRUCTURED OBJECT REPRESENTATIONS,,1980,,,361-415,,Morgan Kaufmann,San Francisco (CA),Principles of Artificial Intelligence,1980,9780934613101,,https://www.sciencedirect.com/science/article/pii/B9780934613101500165;http://dx.doi.org/10.1016/B978-0-934613-10-1.50016-5,10.1016/B978-0-934613-10-1.50016-5,"Publisher Summary The representations aggregates several related predicate calculus expressions into larger structures (sometimes called units) that are identified with important objects in the subject domain of the system. When information about one of these objects is needed by the system, the appropriate unit is accessed and all of the relevant facts about the object are retrieved at once. It uses the phrase structured objects to describe these representational schemes because of the heavy emphasis on the structure of the representation. Indeed the structure carries some of the representational and computational burden. Certain operations that might otherwise have been performed by explicit rule applications can be performed in a more automatic way by mechanisms that depend on the structure of the representation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Huang CM,Chang YI,Lin CH,Chen JS",,Distributed multimedia synchronization specifications using M2EST,Information and Software Technology,1997,39,8,561-578,,,,,1997,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584997000128;http://dx.doi.org/10.1016/S0950-5849(97)00012-8,10.1016/S0950-5849(97)00012-8,"In order to properly schedule related multimedia objects, synchronization relationships of multimedia objects should be precisely specified and dispatched. Each multimedia presentation schedule contains two parts: (1) the state-transition control part, which specifies intra-medium and inter-media synchronization information, and (2) the data variables part, which specifies the dynamic aspects of the state-transition control for dealing with jitter and skew. In this paper, we propose a specification language for specifying multimedia synchronization. The language is called M2EST, which represents the MultiMedia Extended State Transition. M2EST can handle both the state-transition control part and the data variables part in multimedia presentation scheduling. Using M2EST, the temporal behavior of each medium stream is handled by an actor extended finite state machine (EFSM). The temporal relationships among media streams are handled by a synchronizer EFSM. Synchronizer and actors perform multimedia presentations cooperatively. The corresponding synchronization schemes, including both intra-stream and inter-stream synchronization schemes, which rectify the random networks delays caused on distributed presentation environment, can also be specified using M2EST.","Multimedia systems, Distributed multimedia synchronization, Formal specification languages",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aceto L,Panangaden P",,"Preface: Volume 52, Issue 1",Electronic Notes in Theoretical Computer Science,2002,52,1,137-138,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805730;http://dx.doi.org/10.1016/S1571-0661(05)80573-0,10.1016/S1571-0661(05)80573-0,"This volume contains the Proceedings of the Eighth International Workshop on Expressiveness in Concurrency (EXPRESS'01). The Workshop was held in Aalborg, Denmark on August 20, 2001, as satellite event to CONCUR 2001. The EXPRESS workshops aim at bringing together researchers interested in the relations between various formal systems, particularly in the field of Concurrency. More specifically, they focus on the comparison between programming concepts (such as concurrent, functional, imperative, logic and object-oriented programming) and between mathematical models of computation (such as process algebras, Petri nets, event structures, modal logics, rewrite systems etc.) on the basis of their relative expressive power. The EXPRESS workshops were originally held as meetings of the HCM project EXPRESS, which was active with the same focus from January 1994 till December 1997. The first three workshops were held respectively in Amsterdam (1994, chaired by Frits Vaandrager), Tarquinia (1995, chaired by Rocco De Nicola), and Dagstuhl (1996, co-chaired by Ursula Goltz and Rocco De Nicola). The workshop in 1997, which took place in Santa Margherita Ligure and was co-chaired by Catuscia Palamidessi and Joachim Parrow, was organized as a conference with a call for papers and a significant attendance from outside the project. The 1998 workshop was held as a satellite workshop of the CONCUR'98 conference in Nice, co-chaired by Ilaria Castellani and Catuscia Palamidessi, and like on that occasion EXPRESS'99 was hosted by the CONCUR'99 conference in Eindhoven, co-chaired by Ilaria Castellani and Björn Victor. The EXPRESS'00 workshop was again held as a satellite workshop of CONCUR 2000, Pennsylvania State University, USA, co-chaired by Luca Aceto and Björn Victor. The papers in this volume were reviewed by the program committee consisting, besides the editors, of Franck van Breugel(Department of Computer Science, York University)Ilaria Castellani(INRIA, Sophia-Antipolis)Rance Cleaveland(Department of Computer Science, SUNY at Stony Brook)Philippa Gardner(Department of Computing, Imperial College)Jan Friso Groote(Department of Computer Science, Eindhoven University of Technology)Faron Moller(Department of Computer Science, University of Wales Swansea)Joachim Parrow(KTH Teleinformatik, Royal Institute of Technology)Julian Rathke(School of Cognitive and Computing Sciences, University of Sussex)Roberto Segala(Dipartimento di Informatica, Università di Verona) This volume will be published as volume 52 in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs We are very grateful to the following persons, whose help has been crucial for the success of EXPRESS'01: Hans Hüttel and Anna Ingólfsdóttir for their help with the organization of the Workshop as satellite event of CONCUR 2001; Mike Mislove, one of the Managing Editors of the ENTCS series, for his assistance with the use of the ENTCS style files; Uffe Engberg for his great help in the production of the preliminary version of these Proceedings for distribution at the Workshop. Thanks are also due to BRICS (Basic Research in Computer Science), a centre of the Danish National Research Foundation, which has supplied financial support to cover the printing costs. December 20, 2001 Luca Aceto and Prakash Panangaden",,"EXPRESS'01, 8th International Workshop on Expressiveness in Concurrency (Satellite Event of CONCUR 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Stanley HE,Afanasyev V,Amaral LA,Buldyrev SV,Goldberger AL,Havlin S,Leschhorn H,Maass P,Mantegna RN,Peng CK,Prince PA,Salinger MA,Stanley MH,Viswanathan GM",,Anomalous fluctuations in the dynamics of complex systems: from DNA and physiology to econophysics,Physica A: Statistical Mechanics and its Applications,1996,224,1,302-321,,,,,1996,,0378-4371,https://www.sciencedirect.com/science/article/pii/0378437195004092;http://dx.doi.org/10.1016/0378-4371(95)00409-2,10.1016/0378-4371(95)00409-2,"We discuss examples of complex systems composed of many interacting subsystems. We focus on those systems displaying nontrivial long-range correlations. These include the one-dimensional sequence of base pairs in DNA, the sequence of flight times of the large seabird Wandering Albatross, and the annual fluctuations in the growth rate of business firms. We review formal analogies in the models that describe the observed long-range correlations, and conclude by discussing the possibility that behavior of large numbers of humans (as measured, e.g., by economic indices) might conform to analogs of the scaling laws that have proved useful in describing systems composed of large numbers of inanimate objects.",,Dynamics of Complex Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Redondi A,Cesana M,Tagliasacchi M,Filippini I,Dán G,Fodor V",,Cooperative image analysis in visual sensor networks,Ad Hoc Networks,2015,28,,38-51,,,,,2015,,1570-8705,https://www.sciencedirect.com/science/article/pii/S1570870515000165;http://dx.doi.org/10.1016/j.adhoc.2015.01.008,10.1016/j.adhoc.2015.01.008,"This work addresses the problem of enabling resource-constrained sensor nodes to perform visual analysis tasks. The focus is on visual analysis tasks that require the extraction of local visual features, which form a succinct and distinctive representation of the visual content of still images or videos. The extracted features are then matched against a feature data set to support applications such as object recognition, face recognition and image retrieval. Motivated by the fact that the processing burden imposed by common algorithms for feature extraction may be prohibitive for a single, resource-constrained sensor node, this paper proposes cooperative schemes to minimize the processing time of the feature extraction algorithms by offloading the visual processing task to neighboring sensor nodes. The optimal offloading strategy is formally characterized under different networking and communication paradigms. The performance of the proposed offloading schemes is evaluated using simulations and is validated through experiments carried out on a real wireless sensor network testbed. The results show that the proposed offloading schemes allow to reduce the feature extraction time up to a factor of 3 in the reference scenario.","Visual sensor network, Distributed processing, Divisible load theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,Pahl C,,A Superposition Operator for the Refinement of Algebraic Models,Electronic Notes in Theoretical Computer Science,2001,40,,269-287,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105800556;http://dx.doi.org/10.1016/S1571-0661(05)80055-6,10.1016/S1571-0661(05)80055-6,The development of computer languages or software artefacts from basic concepts to the final product is usually a process starting with an abstract model of a key concept and extending this by adding more detailed functionality for extended structural definitions. We will present a refinement approach for the stepwise development of algebraic models. In each step we either add new elements to a model or refine the properties of existing ones. The process of refining elements such that properties of the original element are preserved is called superposition. We will present a categorical framework for refining algebraic structures. Algebras can be used to model a variety of concepts and objects. Language semantics and formal methods are two application areas which use models represented in terms of algebras. We are grateful to the anonymous reviewers who have helped to improve the paper considerably.,,"MFCSIT2000, The First Irish Conference on the Mathematical Foundations of Computer Science and Information Technology",,,,,,,,,,,,,,,,,,,,
Journal Article,"Cross AD,Hancock ER",,Scale space vector fields for symmetry detection,Image and Vision Computing,1999,17,5,337-345,,,,,1999,,0262-8856,https://www.sciencedirect.com/science/article/pii/S0262885698001334;http://dx.doi.org/10.1016/S0262-8856(98)00133-4,10.1016/S0262-8856(98)00133-4,"This paper describes a vectorial representation that can be used to assess the symmetry of objects in 2D images. The method exploits the calculus of vector fields. Commencing from the gradient field extracted from filtered grey-scale images we construct a vector potential. Our image representation is based on the distribution of tangential gradient vectors residing on the image plane. By embedding the image plane in an augmented 3-dimensional space, we compute the vector potential by performing volume integration over the distribution of edge tangents. The associated vector field is computed by taking the curl of the vector potential. The auxiliary spatial dimension provides a natural scale-space sampling of the generating edge-tangent distribution; as the height above the image plane is increased, so the volume over which averaging is effected also increases. We extract edge and symmetry lines through a topographic analysis of the vector-field at various heights above the image plane. Symmetry axes are lines of where the curl of the vector potential vanishes; at edges the divergence of the vector potential vanishes.","Vector fields, Symmetry detection, Continuous symmetry, Canny edge-map",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhong Y,Qin Y,Huang M,Lu W,Chang L",,Constructing a meta-model for assembly tolerance types with a description logic based approach,Computer-Aided Design,2014,48,,1-16,,,,,2014,,0010-4485,https://www.sciencedirect.com/science/article/pii/S0010448513002078;http://dx.doi.org/10.1016/j.cad.2013.10.009,10.1016/j.cad.2013.10.009,"There is a critical requirement for semantic interoperability among heterogeneous computer-aided tolerancing (CAT) systems with the sustainable growing demand of collaborative product design. But current data exchange standard for exchanging tolerance information among these systems can only exchange syntaxes and cannot exchange semantics. Semantic interoperability among heterogeneous CAT systems is difficult to be implemented only with this standard. To address this problem, some meta-models of tolerance information supporting semantic interoperability and an interoperability platform based on these meta-models should be constructed and developed, respectively. This paper mainly focuses on the construction of a meta-model for assembly tolerance types with a description logic ALC(D) based approach. Description logics, a family of knowledge representation languages for authoring ontologies, are well-known for having rigorous logic-based semantics which supports semantic interoperability. ALC(D) can provide a formal method to describe the research objects and the relations among them. In this formal method, constraint relations among parts, assembly feature surfaces and geometrical features are defined with some ALC(D) assertional axioms, and the meta-model of assembly tolerance types is constructed through describing the spatial relations between geometrical features with some ALC(D) terminological axioms. Besides, ALC(D) can also provide a highly efficient reasoning algorithm to automatically detect the inconsistency of the knowledge base, a finite set of assertional and terminological axioms. With this reasoning algorithm, assembly tolerance types for each pair of geometrical features are generated automatically through detecting the inconsistencies of the knowledge base. An application example is provided to illustrate the process of generating assembly tolerance types.","Meta-model, Assembly tolerance types, Semantic interoperability, Description logics",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Teorey T,Lightstone S,Nadeau T,Jagadish HV","Teorey T,Lightstone S,Nadeau T,Jagadish HV",5 - Transforming the Conceptual Data Model to SQL,,2011,,,85-108,Fifth Edition,Morgan Kaufmann,Boston,Database Modeling and Design (Fifth Edition),2011,9780123820204,,https://www.sciencedirect.com/science/article/pii/B9780123820204000057;http://dx.doi.org/10.1016/B978-0-12-382020-4.00005-7,10.1016/B978-0-12-382020-4.00005-7,"Publisher Summary This chapter discusses the database life cycle step that is of particular interest when designing relational databases: transformation of the conceptual data model to candidate tables and their definition in SQL. Entities, attributes, and relationships in the ER model and classes, attributes, and associations in UML can be transformed directly into SQL table definitions with some simple rules. Entities are transformed into tables, with all attributes mapped one-to-one to table attributes. Tables representing entities that are the child (“many” side) of a parent–child (one-to-many or one-to-one) relationship must also include, as a foreign key, the primary key of the parent entity. A many-to-many relationship is transformed into a table that contains the primary keys of the associated entities as its composite primary key; the components of that key are also designated as foreign keys in SQL. A ternary or higher-level n-ary relationship is transformed into a table that contains the primary keys of the associated entities; these keys are designated as foreign keys in SQL. A subset of those keys can be designated as the primary key, depending on the functional dependencies associated with the relationship. Rules for generalization require the inheritance of the primary key from the supertype to the subtype entities when transformed into SQL tables. Optionality constraints in the ER or UML diagrams translate into nulls allowed in the relational model when applied to the “one” side of a relationship. In SQL, the lack of an optionality constraint determines the not null designation in the create table definition.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,Florio LA,,Direct particle motion and interaction modeling method applied to simulate propellant burn,Applied Mathematical Modelling,2013,37,8,5606-5626,,,,,2013,,0307-904X,https://www.sciencedirect.com/science/article/pii/S0307904X1200635X;http://dx.doi.org/10.1016/j.apm.2012.10.030,10.1016/j.apm.2012.10.030,"A direct particle motion and particle interaction modeling method was developed to provide an alternative means of capturing the fundamental phenomena occurring during the burning of propellant grains. Individual propellant grains and other moving components are directly incorporated into the computational domain, removing the need for correlations for particle drag and interaction effects. The motion of the individual particles is calculated from the locally acting fluid induced and collision effect forces and moments. Particle/object interactions are handled through a soft particle collision algorithm. Localized mass and energy sources, accompanied by a shrinking particle size, simulate the effects of the combustion process. The method is applied to the burning of propellant in a two-dimensional planar gun type system. Parametric studies were performed varying the parameters related to the propellant and projectile to explore the capabilities of the current modeling method and to determine the sensitivity of the gas, propellant, and projectile conditions. The model captured the local pressure waves moving between the breech and the bullet base not observed using a bulk effect model. The results also indicated that the conditions in the system that are most sensitive to the burn rate exponent where a 24% increase in the exponent produced a 200% increase in the peak pressure at the breech. The study demonstrated the utility of this new model in exploring in particular the localized phenomena and conditions that develop during the burning of propellant.","Computational, Fluid, Particle, Propellant burn",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Marin R,Trillo JL,Garrido J","de La Puente JA,Rodd MG",A CASE TOOL FOR MODELING AND SIMULATING DISTRIBUTED CONTROL SYSTEMS BASED ON MMS,,1995,,,177-181,,Pergamon,Oxford,Distributed Computer Control Systems 1994,1995,9780080422374,,https://www.sciencedirect.com/science/article/pii/B9780080422374500342;http://dx.doi.org/10.1016/B978-0-08-042237-4.50034-2,10.1016/B978-0-08-042237-4.50034-2,"This paper deals with the modeling of control systems based on the standard for industrial communications MMS [ISO-9506]. This model captures the machine's main structural characteristics in industrial communications environments, but lacks formal semantics describing device programs. In order to define the device programs' semantics Colored Timed Petri Nets are used. In its interpretation we include MMS service calls referencing MMS model objects. The object model definitions are constructed in EXPRESS, [ISO-10303 Part 11] language. Man-machine interfaces are built using an iconic paradigm and Motif widgets. The model is stored in standard format STEP[ISO-10303, Part 21]. This model is then specialized for industrial network design based on fieldbus PROFIBUS [DIN-19245].",,,IFAC Postprint Volume,,,,,,,,,,,,,,,,,,,
Journal Article,"Mousavi M,Reniers MA,Groote JF",,SOS formats and meta-theory: 20 years after,Theoretical Computer Science,2007,373,3,238-272,,,,,2007,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397506009054;http://dx.doi.org/10.1016/j.tcs.2006.12.019,10.1016/j.tcs.2006.12.019,"In 1981 Structural Operational Semantics (SOS) was introduced as a systematic way to define operational semantics of programming languages by a set of rules of a certain shape [G.D. Plotkin, A structural approach to operational semantics, Technical Report DAIMI FN-19, Computer Science Department, Aarhus University, Aarhus, Denmark, September 1981]. Subsequently, the format of SOS rules became the object of study. Using so-called Transition System Specifications (TSS’s) several authors syntactically restricted the format of rules and showed several useful properties about the semantics induced by any TSS adhering to the format. This has resulted in a line of research proposing several syntactical rule formats and associated meta-theorems. Properties that are guaranteed by such rule formats range from well-definedness of the operational semantics and compositionality of behavioral equivalences to security-, time- and probability-related issues. In this paper, we provide an overview of SOS rule formats and meta-theorems formulated around them.","Formal semantics, Structural operational semantics, Rule formats, Framework",Structural Operational Semantics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Barrena M,Jurado E,Márquez-Neila P,Pachón C",,A flexible framework to ease nearest neighbor search in multidimensional data spaces,Data & Knowledge Engineering,2010,69,1,116-136,,,,,2010,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X0900130X;http://dx.doi.org/10.1016/j.datak.2009.09.001,10.1016/j.datak.2009.09.001,"Similarity search is a very active area of research because of its usefulness in a set of modern applications, such as content-based image retrieval (CBIR), time series, spatial databases, data mining and multimedia databases in general. The usual way to do a similarity search is to map the objects to feature vectors and to model the search as a nearest neighbor query in the multidimensional space where vectors reside. The main critical issues to this process are: the distance function used to measure the proximity between vectors and the index method to accelerate the search. In this paper we propose a formal framework to perform similarity search that provides the user with a high degree of freedom in the choice of both the distance and the index structure used to organize the feature space. More specifically, we introduce a function to approximate eventually any distance function that can be used in conjunction with index structures that divide the feature space in multidimensional rectangular regions. Cases of use and experimental work are presented to demonstrate the applicability and the overhead of the framework.","Nearest neighbor search, Similarity measures, Query processing, Multimedia databases, Indexing methods",Including Special Section: 11th ACM International Workshop on Data Warehousing and OLAP (DOLAP’08) - Five selected and extended papers,,,,,,,,,,,,,,,,,,,,
Book Chapter,West M,West M,9 - General Principles for Entity Types,,2011,,,95-104,,Morgan Kaufmann,Boston,Developing High Quality Data Models,2011,9780123751065,,https://www.sciencedirect.com/science/article/pii/B9780123751065000099;http://dx.doi.org/10.1016/B978-0-12-375106-5.00009-9,10.1016/B978-0-12-375106-5.00009-9,"Publisher Summary One of the biggest problems in managing data is identifying what is being talked about. That is, recognizing what is a sound basis for identifying and naming entity types. In order to be able to hold data about something, one needs to identify what sort of thing it is. In order to be able to share and integrate data about something from different sources, it is a must to have a consistent view of what it is about, independent of the context for a particular use. When data is context dependent, this means that the data could mean something else in another context, or data that is part of the context is missing. In order to make such data independent of its context, the context must be made an explicit part of the data, rather than something assumed. Two principles that help to achieve this are—entity types should represent, and be named after, the underlying nature of an object, and entity types should be part of a subtype/supertype hierarchy in order to define a universal context for the model.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lifshits M,Setterqvist E",,Energy of taut strings accompanying Wiener process,Stochastic Processes and their Applications,2015,125,2,401-427,,,,,2015,,0304-4149,https://www.sciencedirect.com/science/article/pii/S030441491400235X;http://dx.doi.org/10.1016/j.spa.2014.09.020,10.1016/j.spa.2014.09.020,"Let W be a Wiener process. For r>0 and T>0 let IW(T,r)2 denote the minimal value of the energy ∫0Th′(t)2dt taken among all absolutely continuous functions h(⋅) defined on [0,T], starting at zero and satisfying W(t)−r≤h(t)≤W(t)+r,0≤t≤T. The function minimizing energy is a taut string, a classical object well known in Variational Calculus, in Mathematical Statistics, and in a broad range of applications. We show that there exists a constant C∈(0,∞) such that for any q>0rT1/2IW(T,r)⟶LqC,as rT1/2→0, and for any fixed r>0, rT1/2IW(T,r)⟶a.s.C,as T→∞. Although precise value of C remains unknown, we give various theoretical bounds for it, as well as rather precise results of computer simulation. While the taut string clearly depends on entire trajectory of W, we also consider an adaptive version of the problem by giving a construction (called Markovian pursuit) of a random function h(t) based only on the values W(s),s≤t, and having minimal asymptotic energy. The solution, i.e. an optimal pursuit strategy, turns out to be related with a classical minimization problem for Fisher information on the bounded interval.","Gaussian processes, Markovian pursuit, Taut string, Wiener process",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tamiz M,Mardle SJ",,"An interactive graphics-based linear, integer and goal programme modelling environment",Decision Support Systems,1998,23,3,285-296,,,,,1998,,0167-9236,https://www.sciencedirect.com/science/article/pii/S0167923698000451;http://dx.doi.org/10.1016/S0167-9236(98)00045-1,10.1016/S0167-9236(98)00045-1,"Model development packages have, in recent years, become a standard tool for the development of linear and integer programmes. This can be seen by the popularity of such algebraic modelling languages as GAMS, AMPL etc. Traditionally, they have been designed around text based systems, and therefore offer a formal and structured declarative language for model definition. However, with the onset of graphics-based operating systems, standard graphical screen objects can be utilised to offer a fully interactive and guided model development package. It is noted by Greenberg that providing analysis tools to the modeller offers a form of intelligent computer assistance. Therefore, it is a natural extension to the modelling package to provide an encapsulated environment for the investigation and development of linear, integer and goal programmes. A complete interactive graphics-based environment for the process of developing, solving and analysing linear, integer and goal programmes (named MoGLI) is presented. The specifications of the package are discussed for such an environment. User-interface screens for model definition are introduced and described, together with a formal algebraic modelling language developed primarily for model processing, although model definition can be performed in either mode. The integration of analysis tools such as preprocessing routines and infeasibility analysis routines are also described, together with standard model information screens.","Linear programming, Goal programming, Modelling",,,,,,,,,,,,,,,,,,,,,
Journal Article,Conrad M,,Rapprochement of artificial intelligence and dynamics,European Journal of Operational Research,1987,30,3,280-290,,,,,1987,,0377-2217,https://www.sciencedirect.com/science/article/pii/0377221787900725;http://dx.doi.org/10.1016/0377-2217(87)90072-5,10.1016/0377-2217(87)90072-5,It is proposed that continuous time is in effect discretized in the brain by dynamic pattern recognition mechanisms in neurons. Time discretization is required to support formal computations in continuous time systems consisting of a large number of components. The ability to perform formal computations is necessary if the system is to execute high level algorithms of the type used in present day artificial intelligence. The weakness of such algorithms is that they work efficiently only when the forms of patterns and objects presented to them are highly constrained. The dynamic mechanisms which discretize the brain's time line also serve to code patterns into constrained forms suitable for high level processing.,"Computers, brain, adaptive processes, learning, artificial intelligence, time",Modelling Complex Systems II,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li J,Chen X,Huang Q,Wong DS",,Digital provenance: Enabling secure data forensics in cloud computing,Future Generation Computer Systems,2014,37,,259-266,,,,,2014,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X13002161;http://dx.doi.org/10.1016/j.future.2013.10.006,10.1016/j.future.2013.10.006,"Secure provenance that records the ownership and process history of data objects is vital to the success of data forensics in cloud computing. In this paper, we propose a new secure provenance scheme based on group signature and attribute-based signature techniques. The proposed provenance scheme provides confidentiality on sensitive documents stored in a cloud, unforgeability of the provenance record, anonymous authentication to cloud servers, fine-grained access control on documents, and provenance tracking on disputed documents. Furthermore, it is assumed that the cloud server has huge computation capacity, while users are regarded as devices with low computation capability. Aiming at this, we show how to utilize the cloud server to outsource and decrease the user’s computational overhead during the process of provenance. With provable security techniques, we formally demonstrate the security of the proposed scheme under standard assumptions.","Provenance, Cloud computing, Privacy, Attribute-based signature","Special Section: Innovative Methods and Algorithms for Advanced Data-Intensive Computing Special Section: Semantics, Intelligent processing and services for big data Special Section: Advances in Data-Intensive Modelling and Simulation Special Section: Hybrid Intelligence for Growing Internet and its Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"Berenguer-Vidal R,Verdú-Monedero R,Morales-Sánchez J",,Convergence analysis of multidimensional parametric deformable models,Computer Vision and Image Understanding,2015,135,,157-177,,,,,2015,,1077-3142,https://www.sciencedirect.com/science/article/pii/S1077314215000247;http://dx.doi.org/10.1016/j.cviu.2015.01.009,10.1016/j.cviu.2015.01.009,"Deformable models are mathematical tools, used in image processing to analyze the shape and movement of real objects due to their ability to emulate physical features such as elasticity, stiffness, mass and damping. In the original approach, parametric models are obtained from the minimization of an energy functional by means of the Euler–Lagrange equation. Finite element method is used for spatial discretization. The shape and position of the model is governed by a second-order partial differential equation system, which is obtained by applying the calculus of variations. Subsequent work propose a model formulation defined completely in the frequency domain, by translating the PDE system into the Fourier domain. This new approach offers important computational efficiency and an easier generalization to multidimensional models, since each spectral component of the model is ruled by an independent PDE. This paper reviews the frequency based formulation and analyzes the convergence and stability of these multidimensional parametric deformable models. Results show that the accuracy and speed of convergence depend on the dynamic parameters of the system and the spectrum of the data to be characterized, providing a procedure to speed-up the convergence by an appropriate choice of these parameters.","Multidimensional deformable model, Euler–Lagrange equation, Convergence analysis, Finite elements discretization, Non-rigid deformation, Frequency domain, Partial differential equations",,,,,,,,,,,,,,,,,,,,,
Journal Article,Horváth I,,"The analysis of space–time structure in QCD vacuum, I: localization vs global behavior in local observables and Dirac eigenmodes",Nuclear Physics B,2005,710,1,464-484,,,,,2005,,0550-3213,https://www.sciencedirect.com/science/article/pii/S0550321304010454;http://dx.doi.org/10.1016/j.nuclphysb.2004.12.038,10.1016/j.nuclphysb.2004.12.038,"The structure of QCD vacuum can be studied from first principles using lattice-regularized theory. This line of research entered a qualitatively new phase recently, wherein the space–time structure (at least for some quantities) can be directly observed in configurations dominating the QCD path integral, i.e., without any subjective processing of typical configurations. This approach to QCD vacuum structure does not rely on any proposed picture of QCD vacuum but rather attempts to characterize this structure in a model-independent manner, so that a coherent physical picture of the vacuum can emerge when such unbiased numerical information accumulates to a sufficient degree. An important part of this program is to develop a set of suitable quantitative characteristics describing the space–time structure in a meaningful and physically relevant manner. One of the basic pertinent issues here is whether QCD vacuum dynamics can be understood in terms of localized vacuum objects, or whether such objects behave as inherently global entities. The first direct studies of vacuum structure strongly support the latter. In this paper, we develop a formal framework which allows to answer this question in a quantitative manner. We discuss in detail how to apply this approach to Dirac eigenmodes and to basic scalar and pseudoscalar composites of gauge fields (action density and topological charge density). The approach is illustrated numerically on overlap Dirac zero modes and near-zero modes. This illustrative data provides direct quantitative evidence supporting our earlier arguments for the global nature of QCD Dirac eigenmodes.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Greco S,Palopoli L,Rullo P",,Netlog: a logic query language for network model databases,Data & Knowledge Engineering,1991,6,3,183-203,,,,,1991,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9190004H;http://dx.doi.org/10.1016/0169-023X(91)90004-H,10.1016/0169-023X(91)90004-H,"A logic-based language for network model databases is presented. The language, called Netlog, provides support for navigating through objects while preserving the declarativity of logic programming. A formal definition of the network data model is presented along with a syntax and a declarative sematics of Netlog. The suitability of Netlog as a query language for CODASYL databases is then shown and an operational semantics, in terms of ordinary logic programs, is provided.","Logic programming, Navigational data models, Query languages, CODASYL databases",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Niblack CW,Gibbons PB,Capson DW",,Generating skeletons and centerlines from the distance transform,CVGIP: Graphical Models and Image Processing,1992,54,5,420-437,,,,,1992,,1049-9652,https://www.sciencedirect.com/science/article/pii/104996529290026T;http://dx.doi.org/10.1016/1049-9652(92)90026-T,10.1016/1049-9652(92)90026-T,"We describe an algorithm for generating connected skeletons of objects in a binary image. The algorithm combines essentially all desirable properties of a skeletonization method: (1) the skeletons it produces have the same simple connectivity as the objects; it is based on a distance transform and can use any “natural” distance metric (in particular those giving a good approximation to the Euclidean distance), resulting in skeletons that are both (2) well-centered and (3) robust with respect to rotation; the skeletons allow the objects to be reconstructed either (4) exactly or (5) approximately to within a specified error; (6) for approximate reconstruction, the skeletons are insensitive to “border noise” without image prefiltering or skeleton postpruning; (7) the skeletons can be thin; (8) the algorithm is fast, taking a fixed number of passes through the image regardless of the width of the objects; and (9) the skeletons have a pleasing visual appearance. Several of these properties may conflict. For example, skeletons cannot always be both thin and allow exact reconstruction and our algorithm can be run to give priority to either property. This paper describes the skeletonization algorithm, discusses the tradeoffs involved and summarizes the formal proofs of its connectivity and reconstructability properties. Because the algorithm is fast, robust, flexible, and provably correct, it is ideally suited for many of the applications of skeletonization—data compression, OCR, shape representation and binary image analysis. The quality of the skeletons produced is demonstrated with numerous examples.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bryant RM,,Free Lie algebras and formal power series,Journal of Algebra,2002,253,1,167-188,,,,,2002,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869302000686;http://dx.doi.org/10.1016/S0021-8693(02)00068-6,10.1016/S0021-8693(02)00068-6,"Let G be a group and K a field. If V is a graded KG-module of the form V=V1⊕V2⊕⋯, where each Vn is finite dimensional, then the free Lie algebra L(V) acquires the structure of a graded KG-module, L(V)=L1(V)⊕L2(V)⊕⋯. The isomorphism types of V and L(V) may be described by the power series ∑n⩾1[Vn]tn and ∑n⩾1[Ln(V)]tn with coefficients from the Green ring. The main object of study is the function on power series which maps ∑[Vn]tn to ∑[Ln(V)]tn for every graded KG-module V. Closed formulae are given in certain cases, and these are closely related to character formulae of Brandt and others.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Niggl KH,,Mω considered as a programming language,Annals of Pure and Applied Logic,1999,99,1,73-92,,,,,1999,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007299800025;http://dx.doi.org/10.1016/S0168-0072(99)80002-5,10.1016/S0168-0072(99)80002-5,"The paper studies a simply typed term system Mω providing a primitive recursive concept of parallelism in the sense of Plotkin. The system aims at defining and computing partial continuous functionals. Some connections between denotational and operational semantics → for Mω are investigated. It is shown that → is correct with respect to the denotational semantics. Conversely, → is complete in the sense that if a program denotes some number k, then it is reducible to the numeral nk. Restricting to the primitive recursive kernel ℘Rω of Mω, it is shown that → is strongly normalising with uniquely determined normal forms. The twist is the design of fixed point style conversion rules for constants μl accounting for parallelly bounded parallel search such that correctness and strong normalisation hold. Thereupon, minor alternations to → bring about that every reduction sequence for a program of ℘Rω terminates either in a numeral nk if the program denotes k, or in the term (⊂-1)0 if the program denotes the “undefined” object. Thus, ℘Rω can be considered a primitive recursive version of Plotkin's LPA+∃·.","λ-calculus with sequential search, Operational and denotational semantics, Scott domains, Parallelism, Weak and strong normalisation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Halpin T,Halpin T,3 - Conceptual Modeling: First Steps,,2001,,,55-107,,Academic Press,San Diego,Information Modeling and Relational Databases,2001,9781558606722,,https://www.sciencedirect.com/science/article/pii/B9781558606722500063;http://dx.doi.org/10.1016/B978-155860672-2/50006-3,10.1016/B978-155860672-2/50006-3,"Publisher Summary Conceptual modeling portrays the application domain at a high level, using terms and concepts familiar to the application users, ignoring logical- and physical-level aspects (that is, the underlying database or programming structures used for implementation) and external-level aspects (that is, the screen forms used for data entry). This chapter discusses the desirable characteristics for any language to be used for conceptual modeling: expressibility, clarity, simplicity and orthogonality, semantic stability, semantic relevance, validation mechanisms, abstraction mechanisms, and formal foundation. With large-scale applications, the UoD can be divided into convenient modules. The conceptual schema design procedure (CSDP) is applied to each, and the resulting subschemas can be integrated into the global conceptual schema. This chapter explores three steps of CSDP: verbalizing familiar information examples as facts; refining these into formal, elementary facts, and applying quality checks; drawing the fact types, and applying a population check; and checking for entity types that should be combined. This object-role modeling approach has been used productively in industry for over 25 years.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Book Chapter,"Kolman B,Shapiro A","Kolman B,Shapiro A",CHAPTER FIFTEEN - TOPICS IN ALGEBRA,,1982,,,441-472,,Academic Press,,Algebra for College Students,1982,9780124178755,,https://www.sciencedirect.com/science/article/pii/B9780124178755500202;http://dx.doi.org/10.1016/B978-0-12-417875-5.50020-2,10.1016/B978-0-12-417875-5.50020-2,"This chapter presents several topics in algebra that are somewhat independent of the flow of ideas in the earlier chapters of this book. Some of these topics, such as sequences, deal with functions whose domain is the set of natural numbers. An important reason for studying sequences and series is that the underlying concepts can be used as an introduction to calculus. The binomial theorem gives us a way to expand the expression (a + b)n. Those students who proceed to a study of calculus will find this theorem used when they begin to study the derivative. The theory of permutations and combinations enables us to count the ways in which we can arrange or select a subset of a set of objects and is necessary background to a study of probability theory.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Antal G,Szirmay-Kalos L,Csonka F,Kelemen C",,Multiple strategy stochastic iteration for architectural walkthroughs,Computers & Graphics,2003,27,2,285-292,,,,,2003,,0097-8493,https://www.sciencedirect.com/science/article/pii/S0097849302002844;http://dx.doi.org/10.1016/S0097-8493(02)00284-4,10.1016/S0097-8493(02)00284-4,"Architectural walkthroughs require fast rendering algorithms and also physically accurate results. This paper introduces a global illumination method that combines several strategies to meet these contradicting criteria. The methods include parallel and perspective ray-bundle shooting and ray shooting. Each method is designed to randomly approximate the effect of the light transport operator. Parallel ray-bundle tracing transfers the radiance of all points parallel to a randomly selected global direction, with perspective ray-bundles we can shoot the radiance of a single patch in all directions, and ray shooting transfers the radiance of a randomly selected point at a randomly selected direction. These strategies have complementary features since each of them is effective in different illumination conditions. In each step of the proposed iterative algorithm the applied strategy is selected randomly according to the properties of the current radiance distribution. The formal framework of the combination is the stochastic iteration. Although the algorithm is view dependent, a rough approximation of the radiance function is stored in object-space, which allows fast animations at reasonable storage requirements and also speeds up Monte-Carlo simulations. The method is also suited for interactive walkthrough animation in glossy scenes since when the viewpoint changes, the object-space radiance values remain valid and the image quickly adapts to the new situation.","Global illumination, Stochastic iteration, Finite-element techniques, Monte-Carlo methods",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Barshevsky GA,Borduzhe VV,Suzdaltsev VB",,Some Points of Building the Control System for One Class of FMS Assembly,IFAC Proceedings Volumes,1986,19,2,317-321,,,,,1986,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017641430;http://dx.doi.org/10.1016/S1474-6670(17)64143-0,10.1016/S1474-6670(17)64143-0,"Mathematical description of FMS structure is given, it allows a designers to classify FMS on the principle of uniformity of decision-making tasks in the FMS control system; to refer a concrete FMS to this or that class; to define a list of control actions upon the control object; to evaluate algorithmically concrete FMS scheme. Formal description examples of one class of FMS assembly are given. The control system synthesis for the given class of objects is discussed. Scheduling functions are formulated. Some problems of dispatching control are also formulated and methods of their solving are discussed.","Flexible manufacturing system (FMS), control system synthesis, transportation control, vectors, concrete, Boolean variable","5th IFAC/IFIP/IMACS/IFORS Conference on Information Control Problems in Manufacturing, Suzdal, USSR, 22-25 April 1986",,,,,,,,,,,,,,,,,,,,
Journal Article,"Groote JF,Mousavi MR,Reniers MA",,A Hierarchy of SOS Rule Formats,Electronic Notes in Theoretical Computer Science,2006,156,1,3-25,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066106002155;http://dx.doi.org/10.1016/j.entcs.2005.11.077,10.1016/j.entcs.2005.11.077,"In 1981 Structural Operational Semantics (SOS) was introduced as a systematic way to define operational semantics of programming languages by a set of rules of a certain shape [G.D. Plotkin. A structural approach to operational semantics. Technical Report DAIMI FN-19, Computer Science Department, Aarhus University, Aarhus, Denmark, September 1981. Also published in: Journal of Logic and Algebraic Programming 60–61 (2004) 17–140]. Subsequently, the format of SOS rules became the object of study. Using so-called Transition System Specifications (TSS's) several authors syntactically restricted the format of rules and showed several useful properties about the semantics induced by any TSS adhering to the format. This has resulted in a line of research proposing several syntactical rule formats and associated meta-theorems. Properties that are guaranteed by such rule formats range from well-definedness of the operational semantics and compositionality of behavioral equivalences to security- and probability-related issues. In this paper, we provide an initial hierarchy of SOS rules formats and meta-theorems formulated around them.","Formal Semantics, Structural Operational Semantics, Rule Formats, Framework",Proceedings of the Second Workshop on Structural Operational Semantics (SOS 2005),,,,,,,,,,,,,,,,,,,,
Journal Article,D. Dixon J,,On duality theorems,Linear Algebra and its Applications,1981,39,,223-227,,,,,1981,,0024-3795,https://www.sciencedirect.com/science/article/pii/0024379581903050;http://dx.doi.org/10.1016/0024-3795(81)90305-0,10.1016/0024-3795(81)90305-0,There are several examples in linear algebra and number theory of theorems which are formally similar to the well-known duality theorem of linear programming. The object of this paper is to present a general setting in which we can state and prove a simple criterion for such duality theorems to hold.,,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Lyons WC,Plisga GJ,Lorenz MD",Chapter 1 - Mathematics,,2016,,,1-1-1-62,Third Edition,Gulf Professional Publishing,Boston,Standard Handbook of Petroleum and Natural Gas Engineering (Third Edition),2016,9780123838469,,https://www.sciencedirect.com/science/article/pii/B9780123838469000011;http://dx.doi.org/10.1016/B978-0-12-383846-9.00001-1,10.1016/B978-0-12-383846-9.00001-1,"This chapter provides basic ideas and guidelines on mathematical functions of various branches of mathematics such as geometry, algebra, trigonometry, differential and integral calculus, analytical geometry, numerical methods, applied statistics, and computer applications. The first section of the chapter discusses sets and functions. A set is a collection of distinct objects or elements. A function can be defined as a set of ordered pairs, denoted as (x, y) such that no two such pairs have the same first element. The chapter also discusses geometry that deals with angles, polygons, triangles, quadrilaterals, circles and spheres, arcs of circles, concurrencies, similarities, prisms and pyramids, coordinate systems, graphs, vectors, and lengths and areas of plane figures. The chapter describes operator precedence and notation, fractions, rules of addition, rules of multiplication and simple factoring, exponents, logarithms, binomial theorems, progressions, sums of the first “n” natural numbers, solution of different equations, and determinants. The chapter also describes basic trigonometric functions, graphs of trigonometric functions, inverse trigonometric functions, trigonometric properties, solution of plane triangles, hyperbolic functions, and polar coordinate system. The chapter further discusses different orders of derivatives, maxima and minima, different types of differentials and integrals, differential equations, methods of solving ordinary differential equations, and the Laplace transformation. It discusses analytical geometry—both 2D and 3D—and provides information on symmetry, intercepts, asymptotes, and different forms of equations of straight line, plane, curves, and solids.","Mathematical functions, Sets, Geometry, Trigonometric functions, Maxima and minima, Analytical geometry",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Guttman M,Parodi J","Guttman M,Parodi J",Chapter one - Introduction,,2007,,,3-11,,Morgan Kaufmann,San Francisco,Real-Life MDA,2007,9780123705921,,https://www.sciencedirect.com/science/article/pii/B9780123705921500040;http://dx.doi.org/10.1016/B978-012370592-1/50004-0,10.1016/B978-012370592-1/50004-0,"Publisher Summary This chapter gives an introduction to various case studies in which each study is an example of how some form of Model Driven Architecture (MDA) has been introduced into an organization to help solve a real-life business problem. At the conceptual level, MDA is a holistic approach for improving the entire Information Technology (IT) life cycle–specification, architecture, design, development, deployment, maintenance, and integration–based on formal modeling. More specifically, MDA is a framework of technical standards progressively being developed by the members of the Object Management Group (OMG)–an open industry consortium supporting this approach–along with a set of usage guidelines for enabling the application of those standards with appropriate tools and processes. MDA is less about generating code per se and much more about precisely capturing requirements, enforcing architectural standards, maintaining traceability, and facilitating effective communication between the business and IT.",,,The MK/OMG Press,,,,,,,,,,,,,,,,,,,
Journal Article,"Lathrop JI,Lutz JH",,Recursive Computational Depth,Information and Computation,1999,153,2,139-172,,,,,1999,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540199927943;http://dx.doi.org/10.1006/inco.1999.2794,10.1006/inco.1999.2794,"In the 1980s, Bennett introduced computational depth as a formal measure of the amount of computational history that is evident in an object's structure. In particular, Bennett identified the classes of weakly deep and strongly deep sequences and showed that the halting problem is strongly deep. Juedes, Lathrop, and Lutz subsequently extended this result by defining the class of weakly useful sequences and proving that every weakly useful sequence is strongly deep. The present paper investigates refinements of Bennett's notions of weak and strong depth, called recursively weak depth (introduced by Fenner, Lutz, and Mayordomo) and recursively strong depth (introduced here). It is argued that these refinements naturally capture Bennett's idea that deep objects are those which “contain internal evidence of a nontrivial causal history.” The fundamental properties of recursive computational depth are developed, and it is shown that the recursively weakly (respectively, strongly) deep sequences form a proper subclass of the class of weakly (respectively, strongly) deep sequences. The above-mentioned theorem of Juedes, Lathrop, and Lutz is then strengthened by proving that every weakly useful sequence is recursively strongly deep. It follows from these results that not every strongly deep sequence is weakly useful, thereby answering a question posed by Juedes.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,de Bruijn NG,"Nederpelt RP,Geuvers JH,de Vrijer RC",Set Theory with Type Restrictions,,1994,133,,841-847,,Elsevier,,Selected Papers on Automath,1994,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08702295;http://dx.doi.org/10.1016/S0049-237X(08)70229-5,10.1016/S0049-237X(08)70229-5,"Publisher Summary This chapter discusses a kind of type theory where the use of types is very similar to the role of types in cases where the objects to be discussed are not sets. Sets are a very important part of the language. Set theory is the basis of all mathematics. Many rigorous texts on mathematical analysis were written with little or no use of the language and notation of sets. It is superficial as long as it is nothing but a translation from predicates to sets. The Cantor–Zermelo–Fraenkel theory is interesting, correct, rich and deep, and does not imply that it is necessarily the tool that should be available for every mathematician's use. It has some disadvantages too. The natural, intuitive way to think of a set is to collect things that belong to a class or type given beforehand. There are various ways to do set theory in such a system. There are two different ways to talk about sets by means of typing. The orientation on geometrical constructions and the basis of formal geometry is also discussed. The chapter also provides a naïve approach to observability and arbitrary objects are also taken in account.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Rieger K,Schlacher K",,Implicit discrete-time systems and accessibility,Automatica,2011,47,9,1849-1859,,,,,2011,,0005-1098,https://www.sciencedirect.com/science/article/pii/S0005109811002615;http://dx.doi.org/10.1016/j.automatica.2011.05.006,10.1016/j.automatica.2011.05.006,"An intrinsic description for dynamic systems, whose evolution along discrete time is governed by (nonlinear) implicit difference equations in one independent variable and zero-order (algebraic) equations, is presented by means of differential geometrical methods, where systems are associated with appropriate geometric objects reflecting their dynamics. Dynamic systems given in implicit form have the peculiarity that they may contain so-called hidden restrictions. A normal form is presented which is characterized by the circumstances that there are no further restrictions. In addition, it is illustrated that such a normal form allows for an equivalent system representation in explicit form. Based on the geometric picture of (implicit) discrete-time systems the qualitative property of accessibility along a fixed trajectory is discussed. By applying symmetry groups of discrete-time systems and studying invariants of these groups a formal approach is provided that allows us to gather local accessibility criteria successively, which can be tested by computer algebra. Several examples illustrate the results.","Discrete-time systems, Implicit systems, Accessibility, Control system analysis, Differential geometry",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li YF,Kennedy G,Ngoran F,Wu P,Hunter J",,An ontology-centric architecture for extensible scientific data management systems,Future Generation Computer Systems,2013,29,2,641-653,,,,,2013,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X1100118X;http://dx.doi.org/10.1016/j.future.2011.06.007,10.1016/j.future.2011.06.007,"Data management has become a critical challenge faced by a wide array of scientific disciplines in which the provision of sound data management is pivotal to the achievements and impact of research projects. Massive and rapidly expanding amounts of data combined with data models that evolve over time contribute to making data management an increasingly challenging task that warrants a new approach. In this paper we present an ontology-centric architecture for data management systems that is extensible and domain independent. In this architecture, the behaviors of domain concepts and objects are captured entirely by ontological entities, around which all data management tasks are carried out. The open and semantic nature of ontology languages also makes this architecture amenable to greater data reuse and interoperability. To evaluate the proposed architecture, we have applied it to the challenge of managing phenomics data.","PODD, Data management systems, OWL, Ontology-centric architecture, Phenomics, Bioinformatics",Special section: Recent advances in e-Science,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ludwig T,Walter B",,EFTA: a database retrieval algebra for feature-terms,Data & Knowledge Engineering,1991,6,2,125-149,,,,,1991,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9190019T;http://dx.doi.org/10.1016/0169-023X(91)90019-T,10.1016/0169-023X(91)90019-T,"We define a data-model based on the notation of a feature-term. A Feature-Term Algebra (FTA) for database-retrieval of feature-terms is presented. FTA is comparable to other attempts to extend or modify Relational Algebra to cope with complex objects and set-valued attributes etc., but extends these proposals to an open-world-assumption for the processing of incomplete knowledge. Since we want to define the algebra as an intermediate language for the compilation of feature-logic database-queries, we augment it by a closure-operator to be able to compile recursive queries. Formal semantics of this Extended Feature-Term Algebra (EFTA) are given, its expressive power is investigated, and the algebra is discussed in the context of related work.","Deductive database, Complex object algebra, Open world assumption, Recursive queries",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Sterrett SG,Meijers A,Similarity and Dimensional Analysis,,2009,,,799-823,,North-Holland,Amsterdam,Philosophy of Technology and Engineering Sciences,2009,,1878-9846,https://www.sciencedirect.com/science/article/pii/B9780444516671500331;http://dx.doi.org/10.1016/B978-0-444-51667-1.50033-1,10.1016/B978-0-444-51667-1.50033-1,"Publisher Summary This article illustrates dimensionless parameters and dimensional analysis insofar as they bear on identifying and reasoning about physically similar systems. Authors of works in philosophy and philosophy of science in the twentienth century who wrote about similarity often did so without mentioning the theory of dimensions or dimensionless ratios. Some formal investigations into the topics of dimensional analysis and physical similarity in philosophy of science were carried out, but the work was not very well assimilated into philosophy. Often, what philosophers mean by similarity is simply sharing a property, such as red; or that the shade of red of one object is very close to the shade of red of another. Much of the practical import of dimensional analysis arises from the powerful and simple logical (or, perhaps, grammatical) principle regarding the requirement of dimensional homogeneity, which is applied to dimensional equations. The principle is known as the principle of dimensional homogeneity. Thus, even if the solution to the associated physical equation is not known, the principle can be employed to obtain information by applying it to dimensional equations.",,,Handbook of the Philosophy of Science,,,,,,,,,,,,,,,,,,,
Journal Article,"Guo Y,Şengür A",,A novel image segmentation algorithm based on neutrosophic similarity clustering,Applied Soft Computing,2014,25,,391-398,,,,,2014,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494614004347;http://dx.doi.org/10.1016/j.asoc.2014.08.066,10.1016/j.asoc.2014.08.066,"Segmentation is an important research area in image processing, which has been used to extract objects in images. A variety of algorithms have been proposed in this area. However, these methods perform well on the images without noise, and their results on the noisy images are not good. Neutrosophic set (NS) is a general formal framework to study the neutralities’ origin, nature, and scope. It has an inherent ability to handle the indeterminant information. Noise is one kind of indeterminant information on images. Therefore, NS has been successfully applied into image processing algorithms. This paper proposed a novel algorithm based on neutrosophic similarity clustering (NSC) to segment gray level images. We utilize the neutrosophic set in image processing field and define a new similarity function for clustering. At first, an image is represented in the neutrosophic set domain via three membership sets: T, I and F. Then, a neutrosophic similarity function (NSF) is defined and employed in the objective function of the clustering analysis. Finally, the new defined clustering algorithm classifies the pixels on the image into different groups. Experiments have been conducted on a variety of artificial and real images. Several measurements are used to evaluate the proposed method's performance. The experimental results demonstrate that the NSC method segment the images effectively and accurately. It can process both images without noise and noisy images having different levels of noises well. It will be helpful to applications in image processing and computer vision.","Image segmentation, Clustering analysis, Neutrosophic set, Similarity function",,,,,,,,,,,,,,,,,,,,,
Journal Article,Rieger P,,"Problems of development control, Solutions and their applications in territorial health planning",IFAC Proceedings Volumes,1977,10,"15, Part 5",96-102,,,,,1977,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017663225;http://dx.doi.org/10.1016/S1474-6670(17)66322-5,10.1016/S1474-6670(17)66322-5,"Summary Developing objects are characterized by changing sets of states and accordingly by a changing law of motion. Thus a developing object must be described by transitioua from one system to another one: S=/M,R/ S′ =/M′, R′/ R describes formally a collection of relations, e.g.: the law of motion /behaviour/ performance. M describes formally a collection of sets; the latter art the domains and eodomains of the relations. S, the collection of M and R, describes formally the system; an object can be described by the formal system S and the signification of Its symbols. The controllability of system is defined according to M.D. Mesarovió and Y. Takahara. The rapid social developments make the preoise systems formulation uneffective. Only a rough final description gives the chance of more preoise oontrol by deciding than the empirical practice of control. Such a description is briefly presented here. It has three stages:1a precise expression for social satisfaction (or another oriterion function for lower ranks of tha social system) v = ln P - a °A and the criterion referring to this v → max l, P describes the product evaluation, A describes the evaluatlon of expenditure.2algorithms for the evaluation of statas (performances, products, work…), whereby the states are elenents of fuzzy sets.3a good system analysis concept. The system analysis delivers the states to evaluate. An application of this concept for the laboratory diagnostics of the GDR is being sketehed here.",,"IFAC Symposium on Control Mechanisms in Bio and Ecosystems. Volume 5 Biocommunication and Ecosystems, Leipzig, GDR, 11-16 September",,,,,,,,,,,,,,,,,,,,
Journal Article,"Zhenye W,Shiping L",,The generalized plane strain problem and its application in three-dimensional stress measurement,International Journal of Rock Mechanics and Mining Sciences & Geomechanics Abstracts,1990,27,1,43-49,,,,,1990,,0148-9062,https://www.sciencedirect.com/science/article/pii/014890629090007O;http://dx.doi.org/10.1016/0148-9062(90)90007-O,10.1016/0148-9062(90)90007-O,"This paper proposes a complete definition of the plane strain problem. It consists of five subtypes: the classical one and four subtypes of the generalized plane strain problem. Among them the axial strain is a compatible condition. Following that definition, for problems which are not more complex than that, the axial load as well as axial strain are linear functions of x, y, and the problems can be solved as a plane strain problem. Their solutions are found by simply superposing the solutions of three of the fundamental equations. According to the fourth subtype of the generalized plane strain problem mentioned, the solutions of a hollow inclusion adhered inside a round hole in an infinite object are given, by which the six stress components of virgin stresses in a rock mass stress measurement using CSIR or CSIRO triaxial probes can be fixed. Comparing the calculated results by the method proposed in this paper with the existing methods, utilizing the data of some authors, it is noticed that the axial stress component calculated by the former method is reduced and that the principal stresses and their directions are altered, which may directly explain the discovery by some authors that the axial stress analyzed by the existing methods tends to a higher value.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Javadi M,Asghari M,Sohrabpour S",,Material growth and remodeling formulation based on the finite couple stress theory,International Journal of Non-Linear Mechanics,2020,121,,103413,,,,,2020,,0020-7462,https://www.sciencedirect.com/science/article/pii/S002074621930246X;http://dx.doi.org/10.1016/j.ijnonlinmec.2020.103413,10.1016/j.ijnonlinmec.2020.103413,"The mathematical formulation for material growth and remodeling processes in finite deformation is developed based on the couple stress theory. The generalized continuum mechanics of couple stress theory is capable of capturing small-scale cellular effects and of modeling mass flux in these processes. The frame-indifferent balance equations of mass, linear and angular momentums, as well as internal energy together with the entropy inequality are first introduced in the presence of the mass flux based on the finite couple-stress theory. Then, within the framework of material uniformity the Eshelby and Mandel stress tensors as driving or configurational forces for local rearrangement of the first- and second-order material inhomogeneities are determined for the Cauchy stress tensor as well as the couple stress tensor. In the next step, the basic kinematic tensors are multiplicatively decomposed into elastic and anelastic parts, and by utilizing the derived entropy inequality, the hyper-elastic constitutive equations with respect to both reference and current configurations are obtained. Additionally, an admissible form for each of the two evolution laws of classical and higher-order material transplant tensors of material growth which satisfy the general formal restrictions are developed as a function of classical and hyper versions of the Mandel stress. Moreover, in a numerical study the effects of presented evolution laws on the growth of a cubic materially isotropic object under a specific oscillating external loading, corresponding to some diagonal classical stress and skew-symmetric couple stress tensors in the reference configuration, are investigated.","The finite couple stress theory, Length scale, Growth, Remodeling, The Mandel stress, The Eshelby stress",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shinwell MR,Pitts AM",,On a monadic semantics for freshness,Theoretical Computer Science,2005,342,1,28-55,,,,,2005,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397505003385;http://dx.doi.org/10.1016/j.tcs.2005.06.003,10.1016/j.tcs.2005.06.003,"A standard monad of continuations, when constructed with domains in the world of FM-sets [M.J. Gabbay, A.M. Pitts, A new approach to abstract syntax with variable binding, Formal Aspects Comput. 13 (2002) 341–363], is shown to provide a model of dynamic allocation of fresh names that is both simple and useful. In particular, it is used to prove that the powerful facilities for manipulating fresh names and binding operations provided by the “Fresh” series of metalanguages [M.R. Shinwell, Swapping the atom: Programming with binders in Fresh O’Caml, Proc. MERλIN, 2003; M.R. Shinwell, A.M. Pitts, Fresh O’Caml User Manual, Cambridge University Computer Laboratory, September 2003, available at 〈http://www.freshml.org/foc/〉; M.R. Shinwell, A.M. Pitts, M.J. Gabbay, FreshML: Programming with binders made simple, in: Proc. ICFP ’03, ACM Press, 2003, pp. 263–274] respect α-equivalence of object-level languages up to meta-level contextual equivalence.",,Applied Semantics: Selected Topics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tranoris C,Thramboulidis K",,A tool supported engineering process for developing control applications,Computers in Industry,2006,57,5,462-472,,,,,2006,,0166-3615,https://www.sciencedirect.com/science/article/pii/S0166361506000492;http://dx.doi.org/10.1016/j.compind.2006.02.006,10.1016/j.compind.2006.02.006,"Engineers in industrial and control sector continuously face problems on developing modern distributed industrial control applications. The latest standard in this domain, the IEC61499, defines a methodology to be used by system designers to construct distributed industrial control applications. New generation Engineering Support Systems (ESSs) are required to support the whole development process. In this paper, a process that introduces new and enhances already defined phases of the IEC61499 development process is presented. Model Driven Development has been adopted and two meta-models have been defined: a Unified Modelling Language (UML) based one that is used in the analysis phase and an IEC61499 based for the design phase. A set of transformation rules, formally defined by means of UML's Object Constraint Language, is defined to ameliorate the transformation process between the two metamodels. The proposed development process is supported by a prototype ESS, namely CORFU ESS, which is used to present a case study.","Distributed Control Applications, Function Block, IEC61499, Control Application development process, Model Driven Development",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Varela LM,Garcı́a M,Mosquera V",,Non-Debye screening in a formally consistent version of the modified mean spherical approximation,Physica A: Statistical Mechanics and its Applications,2002,311,1,35-49,,,,,2002,,0378-4371,https://www.sciencedirect.com/science/article/pii/S0378437102008233;http://dx.doi.org/10.1016/S0378-4371(02)00823-3,10.1016/S0378-4371(02)00823-3,"The non-Debye decay length of ionic solutions (κ) is analyzed combining the dressed ion theory route with a new version of the modified mean spherical approximation (MMSA) [Varela et al., J. Chem. Phys. 109, 1930 (1998)]. Seeking formal consistency, the MMSA short-range direct correlation function is naturally extended to include a linear term in radial distance whose effect on the screening predictions is analyzed. This behavior is derived from soft-core considerations and the concentration-dependent slope is related to the penetrability of the ions by means of a Tosi–Fumi-type potential. A limit is established for the slope of c(r) in order to predict the correct behavior of the decay constant in the low concentration regime (κ→kD+, kD being Debye's parameter). This limit is shown to be violated by the classical mean spherical approximation (MSA) for a one-component charged spheres fluid. Thus, it is confirmed that the MSA effective decay constant tends to Debye's one from below in the limit of vanishing concentration, in accordance with the recent hypernetted chain (HNC) calculations, a behavior which has been the object of some controversy in the literature. Finally, the HNC calculations of κ are analyzed for various ionic species and the behavior of the calculated slope of c(r) discussed in terms of ionic coupling.","Ionic solutions, Effective screening length",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Vandeginste BG,Massart DL,Buydens LM,De Jong S,Lewi PJ,Smeyers-Verbeke J","Vandeginste BG,Massart DL,Buydens LM,De Jong S,Lewi PJ,Smeyers-Verbeke J",Chapter 29 - Vectors Matrices Operations on Matrices,,1998,20,,7-56,,Elsevier,,Handbook of Chemometrics and Qualimetrics: Part B,1998,,0922-3487,https://www.sciencedirect.com/science/article/pii/S0922348798800397;http://dx.doi.org/10.1016/S0922-3487(98)80039-7,10.1016/S0922-3487(98)80039-7,"This chapter is an extension and generalization of the material presented in Chapter 9. Here we deal with the calculus of vectors and matrices from the point of view of the analysis of a two-way multivariate data table, as defined in Chapter 28. Such data arise when several measurements are made simultaneously on each object in a set [1]. Usually these raw data are collected in tables in which the rows refer to the objects and the columns to the measurements. For example, one may obtain physicochemical properties such as lipophilicity, electronegativity, molecular volume, etc., on a number of chemical compounds. The resulting table is called a measurement table. Note that the assignment of objects to rows and of measurements to columns is only conventional. It arises from the fact that often there are more objects than measurements, and that printing of such a table is more convenient with the smallest number of columns. In a cross-tabulation each element of the table represents a count, a mean value or some other summary statistic for the various combinations of the categories of the two selected measurements. In the above example, one may cross the categories of lipophilicity with the categories of electronegativity (using appropriate intervals of the measurement scales). When each cell of such a cross-tabulation contains the number of objects that belong to the combined categories, this results in a contingency table or frequency table which is discussed extensively in Chapter 32. In a more general cross-tabulation, each cell of the table may refer, for example, to the average molecular volume that has been observed for the combined categories of lipophilicity and electronegativity. One of the aims of multivariate analysis is to reveal patterns in the data, whether they are in the form of a measurement table or in that of a contingency table. In this chapter we will refer to both of them by the more algebraic term ‘matrix’. In what follows we describe the basic properties of matrices and of operations that can be applied to them. In many cases we will not provide proofs of the theorems that underlie these properties, as these proofs can be found in textbooks on matrix algebra (e.g. Gantmacher [2]). The algebraic part of this section is also treated more extensively in textbooks on multivariate analysis (e.g. Dillon and Goldstein [1], Giri [3], Cliff [4], Harris [5], Chatfield and Collins [6], Srivastana and Carter [7], Anderson [8]).",,,Data Handling in Science and Technology,,,,,,,,,,,,,,,,,,,
Journal Article,Mislove M,,Discrete random variables over domains,Theoretical Computer Science,2007,380,1,181-198,,,,,2007,,0304-3975,https://www.sciencedirect.com/science/article/pii/S030439750700165X;http://dx.doi.org/10.1016/j.tcs.2007.02.061,10.1016/j.tcs.2007.02.061,"In this paper we initiate the study of discrete random variables over domains. Our work is inspired by that of Daniele Varacca, who devised indexed valuations as models of probabilistic computation within domain theory. Our approach relies on new results about commutative monoids defined on domains that also allow actions of the non-negative reals. Using our approach, we define two such families of real domain monoids, one of which allows us to recapture Varacca’s construction of the Plotkin indexed valuations over a domain. Each of these families leads to the construction of a family of discrete random variables over domains, the second of which forms the object level of a continuous endofunctor on the categories RB (domains that are retracts of bifinite domains), and on FS (domains where the identity map is the directed supremum of deflations finitely separated from the identity). The significance of this last result lies in the fact that there is no known category of continuous domains that is closed under the probabilistic power domain, which forms the standard approach to modelling probabilistic choice over domains. The fact that RB and FS are Cartesian closed and also are closed under a power domain of discrete random variables means we can now model, e.g. the untyped lambda calculus extended with a probabilistic choice operator, implemented via random variables.",,"Automata, Languages and Programming",,,,,,,,,,,,,,,,,,,,
Journal Article,"Gerstl P,Pribbenow S",,A conceptual theory of part-whole relations and its applications,Data & Knowledge Engineering,1996,20,3,305-322,,,,,1996,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X96000146;http://dx.doi.org/10.1016/S0169-023X(96)00014-6,10.1016/S0169-023X(96)00014-6,"This paper shows two applications of a theory of part-whole relations that has been introduced in [1] in two different areas: natural language semantics and modelling parts of physical objects. A short overview of the theory will be given, followed by two sections which present results in the two application areas. In Section 2 we provide an analysis of the domain of solid objects like devices, buildings and other artifacts of our daily life. We first examine in more detail the relevant part-whole relations in that domain. The second part describes how these relations can be represented and manipulated in a hybrid system. In Section 3 it will be shown that there is a strong and immediate correspondence between classes of part-whole-relations and syntactically or lexically motivated classes of genitive constructions. The two applications illustrate the generality of the theory as well as its usefulness for representing and reasoning about part-whole information in totally different domains.","Commonsense knowledge, Compositional structure, Diagrammatic reasoning, Formal mereology, Knowledge representation, Natural language processing, Part-whole relations",Modeling Parts and Wholes,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rauber TW,Steiger-Garçao A",,Binary Pattern Description based on UNL-Fourier Features - A Neural Network Identifier with Learning Capability,IFAC Proceedings Volumes,1992,25,6,143-149,,,,,1992,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017508952;http://dx.doi.org/10.1016/S1474-6670(17)50895-2,10.1016/S1474-6670(17)50895-2,"The paper presents a general purpose method to describe the form of binary patterns. Features based on a Fourier analysis of transformed parametric curves are introduced which are insensitive to translation, rotation and scaling. If patterns are different they can be distinguished without explicitly specifying the differences due to the information preserving qualities of the transform. The calculus of the features is inexpensive compared to the potentiality to characterize a arbitrary formed pattern. An identifier using a backpropagation neural network simulator is constructed on top of the feature model. In order to prove the general purpose capability of the technique, we present results originating from three different pattern types: Object contours from vision system images, 2-D projections of CAD modelled solids and handwritten numerals.","Pattern recognition, shape features, Fourier analysis, computer vision, backpropagation neural network","IFAC Symposium on Intelligent Components and Instruments for Control Applications (SICICA'92), Malaga, Spain, 20-22 May 1992",,,,,,,,,,,,,,,,,,,,
Journal Article,"Fink T,Koch M,Pauls K",,An MDA approach to Access Control Specifications Using MOF and UML Profiles,Electronic Notes in Theoretical Computer Science,2006,142,,161-179,,,,,2006,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105052175;http://dx.doi.org/10.1016/j.entcs.2004.12.045,10.1016/j.entcs.2004.12.045,"We present a Model Driven Development (MDD) approach to the development of access control policies for distributed systems. The models are expressed as Meta-Object Facility (MOF) models enriched by Unified Modeling Language (UML) profiles. The view-based access control model is used as an example, for which we present a platform independent meta-model and platform specific meta-models for the Java 2 Platform, Enterprise Edition (J2EE). A management application is used to build instance models for the platform independent and platform specific meta-models, respectively. We present in this paper how the platform independent models can be used to generate the platform specific models, and how the meta-models can be used to generate the models for the specific application. Finally, the platform specific models are used to generate the security policy to be deployed in the security infrastructure. We show how consistence requirements can be verified formally by using category-based graph transformations.","MDA, MDD, UML, CORBA, J2EE, Security",Proceedings of the First International Workshop on Views on Designing Complex Architectures (VODCA 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,Torriani HH,,Constructive implicit function theorems,Discrete Mathematics,1989,76,3,247-269,,,,,1989,,0012-365X,https://www.sciencedirect.com/science/article/pii/0012365X89903233;http://dx.doi.org/10.1016/0012-365X(89)90323-3,10.1016/0012-365X(89)90323-3,"An algorithm that yields every coefficient of the reversed series of a formal power series in one variable is presented. Another algorithm solves implicit analytic functions on the plane for one of the variables. This constructive approach to the Lagrange inversion formula rests on factorization properties of partitions of integers and distributions of distinguishable objects. Several open problems related to this material and dealing with combinatorial analysis, determinantal hypersurfaces, invariant theory and characteristic classes are mentioned at the end.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Chen K,Owen CL",,Form language and style description,Design Studies,1997,18,3,249-274,,,,,1997,,0142-694X,https://www.sciencedirect.com/science/article/pii/S0142694X97000021;http://dx.doi.org/10.1016/S0142-694X(97)00002-1,10.1016/S0142-694X(97)00002-1,"This paper presents a ‘style description framework’ for the analysis of style as it is exhibited by objects, artifacts and, particularly, products. The framework equips a designer with both the ability to analyse existing styles and to describe new styles for target markets. A ‘style profile’ consists of a set of polar adjective scales and associated weighting mechanisms. Within the profile, stylistic attributes — in the form of values given on the scales — are grouped into six categories: form elements, joining relationships, detail treatments, materials, colour treatments and textures. Two weighting mechanisms, an importance index and confidence factor, fine-tune the description. The style profile can be used not only to communicate styles between designers and computers, but also to accumulate formal style knowledge.","aesthetics, product design, computer aided design, form language",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Di Manzo M,Giunchiglia F",,A first order theory of common sense object positioning,Computers in Industry,1986,7,3,257-262,,,,,1986,,0166-3615,https://www.sciencedirect.com/science/article/pii/0166361586900515;http://dx.doi.org/10.1016/0166-3615(86)90051-5,10.1016/0166-3615(86)90051-5,"The aim of this paper is to present a first order formalization of the cognitive mechanisms which allow a listener to form a “mental image” of a scene incompletely and ambiguously described (for instance by means of natural language sentences). In particular we are faced with the problem of imagining all the objects (probably) present in an inferred environment till a three-dimensional representation of the space enveloped by the current (inferred) environment. In this paper, for lack of space, the formal system is not entirely described (a technical report with the complete formalization is forthcoming), but we are more focused on those mechanisms of reasoning “by default” which allow humans to reach conclusions even if their knowledge is largely incomplete.","Natural language processing, Cognitive modelling",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Duchesneau F,"Fenstad JE,Frolov IT,Hilpinen R",Leibniz and the Philosophical Analysis of Science,,1989,126,,609-624,,Elsevier,,"Logic, Methodology and Philosophy of Science VIII",1989,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08700685;http://dx.doi.org/10.1016/S0049-237X(08)70068-5,10.1016/S0049-237X(08)70068-5,"Publisher Summary Leibniz developed a conception of philosophy of science that can be defined as architectonic rather than strictly foundational or critical. The chapter discusses the conception of the analytic method Leibniz developed and the ways in which Leibnizian analysis aims at dealing in a combinatory fashion with indefinite notions, thus allowing for the potential systematization of truths of fact. The Leibnizian doctrine on analysis purports to replace the intuitive progression by a process of unfolding of the formal structures involved in the concatenation of concepts and propositions. For Leibniz, the validity of mathematics would result from the correspondence one can set between stages of analytical decombination and a series of judgments whose formal validity can be identified for each element in the series. He focused on the combination and decombination of concepts that form sufficient marks for reckoning the object as real because of its essential possibility.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Horváth D,Pincak R",,From the currency rate quotations onto strings and brane world scenarios,Physica A: Statistical Mechanics and its Applications,2012,391,21,5172-5188,,,,,2012,,0378-4371,https://www.sciencedirect.com/science/article/pii/S0378437112004931;http://dx.doi.org/10.1016/j.physa.2012.06.006,10.1016/j.physa.2012.06.006,"In the paper, we study the projections of the real exchange rate dynamics onto the string-like topology. Our approach is inspired by the contemporary movements in the string theory. The string map of data is defined here by the boundary conditions, characteristic length, real valued and the method of redistribution of information. As a practical matter, this map represents the detrending and data standardization procedure. We introduced maps onto 1-end-point and 2-end-point open strings that satisfy the Dirichlet and Neumann boundary conditions. The questions of the choice of extra-dimensions, symmetries, duality and ways to the partial compactification are discussed. Subsequently, we pass to higher dimensional and more complex objects. The 2D-Brane was suggested which incorporated bid-ask spreads. Polarization by the spread was considered which admitted analyzing arbitrage opportunities on the market where transaction costs are taken into account. The model of the rotating string which naturally yields calculation of angular momentum is suitable for tracking of several currency pairs. The systematic way which allows one suggest more structured maps suitable for a simultaneous study of several currency pairs was analyzed by means of the Gâteaux generalized differential calculus. The effect of the string and brane maps on test data was studied by comparing their mean statistical characteristics. The study revealed notable differences between topologies. We review the dependence on the characteristic string length, mean fluctuations and properties of the intra-string statistics. The study explores the coupling of the string amplitude and volatility. The possible utilizations of the string theory approach in financial markets are slight.","Econophysics, Financial markets, String theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Landauer C,Bellman KL",,New architectures for constructed complex systems,Applied Mathematics and Computation,2001,120,1,149-163,,,,,2001,,0096-3003,https://www.sciencedirect.com/science/article/pii/S0096300399002404;http://dx.doi.org/10.1016/S0096-3003(99)00240-4,10.1016/S0096-3003(99)00240-4,"This paper is an overview of our research program in intelligent systems. Our object of study is constructed complex systems, which are software and hardware systems mediated or managed by computers. We describe how biological systems provide stiff competition for constructed complex systems in the areas of autonomy and intelligence, robustness, adaptability, and communication. We describe our computationally reflective integration infrastructure, called `wrappings', and show how it can provide many of the necessary flexibilities. We also describe two directions of research in computational semiotics, which for us means the study of the use of symbols by computing systems. We describe our `conceptual categories', which are a method of knowledge representation that supports these flexibilities, and some new results on symbol systems, which leads to some new mathematical questions about what can be represented in formal systems and how they can be extended automatically. These are then combined to describe our architecture, which we are currently in the process of implementing.","Constructed complex systems, Knowledge-based integration infrastructure, Conceptual categories, Reflective architectures",The Bellman Continuum,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gosliga J,Gardner PA,Bull LA,Dervilis N,Worden K",,"Foundations of Population-based SHM, Part II: Heterogeneous populations – Graphs, networks, and communities",Mechanical Systems and Signal Processing,2021,148,,107144,,,,,2021,,0888-3270,https://www.sciencedirect.com/science/article/pii/S0888327020305306;http://dx.doi.org/10.1016/j.ymssp.2020.107144,10.1016/j.ymssp.2020.107144,"This paper is the second in a series of three which aims to provide a basis for Population-Based Structural Health Monitoring (PBSHM); a new technology which will allow transfer of diagnostic information across a population of structures, augmenting SHM capability beyond that applicable to individual structures. The new PBSHM can potentially allow knowledge about normal operating conditions, damage states, and even physics-based models to be transferred between structures. The first part in this series considered homogeneous populations of nominally-identical structures. The theory is extended in this paper to heterogeneous populations of disparate structures. In order to achieve this aim, the paper introduces an abstract representation of structures based on Irreducible Element (IE) models, which capture essential structural characteristics, which are then converted into Attributed Graphs (AGs). The AGs form a complex network of structure models, on which a metric can be used to assess structural similarity; the similarity being a key measure of whether diagnostic information can be successfully transferred. Once a pairwise similarity metric has been established on the network of structures, similar structures are clustered to form communities. Within these communities, it is assumed that a certain level of knowledge transfer is possible. The transfer itself will be accomplished using machine learning methods which will be discussed in the third part of this series. The ideas introduced in this paper can be used to define precise terminology for PBSHM in both the homogeneous and heterogeneous population cases.","Population-based structural health monitoring (SHM), Irreducible Element (IE) model, Attributed Graph (AG), Complex networks of structures",,,,,,,,,,,,,,,,,,,,,
Journal Article,Yokouchi H,,Retraction map categories and their applications to the construction of lambda calculus models,Information and Control,1986,71,1,33-86,,,,,1986,,0019-9958,https://www.sciencedirect.com/science/article/pii/S0019995886800171;http://dx.doi.org/10.1016/S0019-9958(86)80017-1,10.1016/S0019-9958(86)80017-1,"This paper deals with categorical models of the λ-calculus. We generalize the inverse limit method Scott used for his construction of D∞, and introduce order-enriched ccc's, retraction map categories and ɛ-categories. An order-enriched ccc is a cartesian closed category C equipped with a partial order relation ⩽ on the set of the arrows. A retraction map category of C is R=(R, ⩽, i, j), where ⩽ is a partial order relation on the set |C| of all the objects of C, R is the category of the poset (|C|, ⩽), and i and j are functors from R to C and from Rop to C that satisfy the conditions: (1) j a, b ∘ i a, b ⩾ ida and (2) i a, b ∘ j a, b ⩽ idb for every arrow a, b: a → b in R (i.e., a⩽b). The ɛ-category E=E(C, R) of C w.r.t. R is the category whose objects are ideals of (|C|, ⩽) and whose arrows are ideals of (C, ⊑), where ⩽ is the partial order relation in R and ⊑ is the partial order relation defined by f ⊑ g iff dom(f)⩽dom(g), cod(f)⩽cod(g) in R and f⩽j a, b ∘ g ∘ i(a, b in C. We show that every ɛ-category E=E(C, R) is also an order-enriched ccc. Moreover when E and R satisfy a particular condition, E(C, R) has a reflexive object. For example, if there is an ideal U of (|C|, ⩽) satisfying the following conditions, then U is isomorphic to UU in E and a λ-algebra is constructed from E and U: (1) for every pair of a, b ∈ U, U contains ba, and (2) for every c ∈ U, there are a, b ∈ U such that c ∈ ba. We reconstruct Pω and D∞ using ɛ-categories.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fan CI,Wu CN,Sun WZ,Chen WK",,Multi-recastable e-bidding game with dual-blindness,Mathematical and Computer Modelling,2013,58,1,68-78,,,,,2013,,0895-7177,https://www.sciencedirect.com/science/article/pii/S0895717712001264;http://dx.doi.org/10.1016/j.mcm.2012.06.003,10.1016/j.mcm.2012.06.003,"Electronic auctions (e-auction) enable bidders to bid for diverse sold objects under an electronic platform via the Internet. Relevant literature has presented numerous online bidding auction schemes considering different security issues. However, none of them can satisfy all essential properties simultaneously and some of them possess security vulnerabilities. For example, the winner cannot hold the properties of anonymity and unlinkability without re-registration for the auction of another product. In order to cope with the above problems, this study presents an e-auction scheme which owns the following features: every bidder’s anonymity during the entire auction, unlinkability among plural auctions of different selling topics, unforgeability, no framing (tamper resistance of bidding tickets), non-repudiation, public verifiability of all bidding tickets, and easy revocation for illegal activities. In our e-bidding protocol, all participants can take part in a sequence of different auctions for various products unlimitedly after performing one time of registration, where the winner does not need to re-register again, either. We formally prove the security of the proposed scheme and also provide comparisons to show that it is the most efficient one as compared with previous works.","Electronic auction, e-commerce, Cryptography, Information security",Financial IT & Security and 2010 International Symposium on Computational Electronics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Le Guyader C,Vese LA",,A combined segmentation and registration framework with a nonlinear elasticity smoother,Computer Vision and Image Understanding,2011,115,12,1689-1709,,,,,2011,,1077-3142,https://www.sciencedirect.com/science/article/pii/S1077314211001573;http://dx.doi.org/10.1016/j.cviu.2011.05.009,10.1016/j.cviu.2011.05.009,"In this paper, we present a new non-parametric combined segmentation and registration method. The shapes to be registered are implicitly modeled with level set functions and the problem is cast as an optimization one, combining a matching criterion based on the active contours without edges for segmentation (Chan and Vese, 2001) [8] and a nonlinear-elasticity-based smoother on the displacement vector field. This modeling is twofold: first, registration is jointly performed with segmentation since guided by the segmentation process; it means that the algorithm produces both a smooth mapping between the two shapes and the segmentation of the object contained in the reference image. Secondly, the use of a nonlinear-elasticity-type regularizer allows large deformations to occur, which makes the model comparable in this point with the viscous fluid registration method. In the theoretical minimization problem we introduce, the shapes to be matched are viewed as Ciarlet–Geymonat materials. We prove the existence of minimizers of the introduced functional and derive an approximated problem based on the Saint Venant–Kirchhoff stored energy for the numerical implementation and solved by an augmented Lagrangian technique. Several applications are proposed to demonstrate the potential of this method to both segmentation of one single image and to registration between two images.","Image segmentation, Image registration, Nonlinear elasticity, Ogden materials, Saint Venant–Kirchhoff materials, Calculus of variations, Augmented Lagrangian","Special issue on Optimization for Vision, Graphics and Medical Imaging: Theory and Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferrucci F,Pacini G,Satta G,Sessa MI,Tortora G,Tucci M,Vitiello G",,Symbol–Relation Grammars: A Formalism for Graphical Languages,Information and Computation,1996,131,1,1-46,,,,,1996,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540196900905;http://dx.doi.org/10.1006/inco.1996.0090,10.1006/inco.1996.0090,"A common approach to the formal description of pictorial and visual languages makes use of formal grammars and rewriting mechanisms. The present paper is concerned with the formalism of Symbol–Relation Grammars (SR grammars, for short). Each sentence in an SR language is composed of a set of symbol occurrences representing visual elementary objects, which are related through a set of binary relational items. The main feature of SR grammars is the uniform way they use context-free productions to rewrite symbol occurrences as well as relation items. The clearness and uniformity of the derivation process for SR grammars allow the extension of well-established techniques of syntactic and semantic analysis to the case of SR grammars. The paper provides an accurate analysis of the derivation mechanism and the expressive power of the SR formalism. This is necessary to fully exploit the capabilities of the model. The most meaningful features of SR grammars as well as their generative power are compared with those of well-known graph grammar families. In spite of their structural simplicity, variations of SR grammars have a generative power comparable with that of expressive classes of graph grammars, such as the edNCE and the N-edNCE classes.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Basin D,Clavel M,Doser J,Egea M",,Automated analysis of security-design models,Information and Software Technology,2009,51,5,815-831,,,,,2009,,0950-5849,https://www.sciencedirect.com/science/article/pii/S095058490800075X;http://dx.doi.org/10.1016/j.infsof.2008.05.011,10.1016/j.infsof.2008.05.011,"We have previously proposed SecureUML, an expressive UML-based language for constructing security-design models, which are models that combine design specifications for distributed systems with specifications of their security policies. Here, we show how to automate the analysis of such models in a semantically precise and meaningful way. In our approach, models are formalized together with scenarios that represent possible run-time instances. Queries about properties of the security policy modeled are expressed as formulas in UML’s Object Constraint Language. The policy may include both declarative aspects, i.e., static access-control information such as the assignment of users and permissions to roles, and programmatic aspects, which depend on dynamic information, namely the satisfaction of authorization constraints in a given scenario. We show how such properties can be evaluated, completely automatically, in the context of the metamodel of the security-design language. We demonstrate, through examples, that this approach can be used to formalize and check non-trivial security properties. The approach has been implemented in the SecureMOVA tool and all of the examples presented have been checked using this tool.","UML, OCL, SecureUML, Security policies, Formal analysis, Metamodels",SPECIAL ISSUE: Model-Driven Development for Secure Information Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kozen D,Palsberg J,Schwartzbach MI",,Efficient inference of partial types,Journal of Computer and System Sciences,1994,49,2,306-324,,,,,1994,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000005800510;http://dx.doi.org/10.1016/S0022-0000(05)80051-0,10.1016/S0022-0000(05)80051-0,"Partial types for the λ-calculus were introduced by >Thatte in 1988 as a means of typing objects that are not typable with simple types, such as heterogeneous lists and persistent data. In that paper he showed that type inference for partial types was semidecidable. Decidability remained open until quite recently, when O'Keefe and Wand gave an exponential time algorithm for type inference. In this paper we given an O(n3) algorithm. Our algorithm constructs a certain finite automaton that represents a canonical solution to a given set of type constraints. Moreover, the construction works equally well for recursive types; this sovles an open problem stated by O'Keefe and Wand (in “Proceedings, European Symposium on Programming,” Lect. Notes in Comput. Sci., Vol. 582, pp. 408–417, Springer-Verlag, New York/Berlin, 1992).",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Brachman RJ,Findler NV,"ON THE EPISTEMOLOGICAL STATUS OF SEMANTIC NETWORKS**Prepared in part at Bolt Beranek and Newman Inc. under contracts sponsored by the Defense Advance Research Projects Agency and the Office of Naval Research. The views and conclusions stated are those of the author and should not be interpreted as necessarily representing the official policies, either express or implied, of the Defense Advanced Research Projects Agency or the U.S. Government",,1979,,,3-50,,Academic Press,,Associative Networks,1979,9780122563805,,https://www.sciencedirect.com/science/article/pii/B9780122563805500074;http://dx.doi.org/10.1016/B978-0-12-256380-5.50007-4,10.1016/B978-0-12-256380-5.50007-4,"ABSTRACT This chapter examines in detail the history of a set of network-structured formalisms for knowledge representation—the so-called “semantic networks.” Semantic nets were introduced around 1966 as a representation for the concepts underlying English words, and since then have become an increasingly popular type of language for representing concepts of a widely varying sort. While these nets have for the most part retained their basic associative nature, their primitive representational elements have differed significantly from one project to the next. These differences in underlying primitives are symptomatic of deeper philosophical disparities, and I discuss a set of five significantly different “levels” at which networks can be understood. One of these levels, the “epistemological,” or “knowledge-structuring,” level, has played an important implicit part in all previous notations, and is here made explicit in a way that allows a new type of network formalism to be specified. This new type of formalism accounts precisely for operations like individuation of description, internal concept structure in terms of roles and interrelations between them, and structured inheritance. In the final section, I present a brief sketch of an example of a particular type of formalism (“Structured Inheritance Networks”) that was designed expressly to treat concepts as formal representational objects. This language, currently under development, is called KLONE, and it allows the explicit expression of epistemological level relationships as network links.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Vickers S,,The connected Vietoris powerlocale,Topology and its Applications,2009,156,11,1886-1910,,,,,2009,,0166-8641,https://www.sciencedirect.com/science/article/pii/S0166864109000820;http://dx.doi.org/10.1016/j.topol.2009.03.043,10.1016/j.topol.2009.03.043,"The connected Vietoris powerlocale is defined as a strong monad Vc on the category of locales. VcX is a sublocale of Johnstone's Vietoris powerlocale VX, a localic analogue of the Vietoris hyperspace, and its points correspond to the weakly semifitted sublocales of X that are “strongly connected”. A product map ×:VcX×VcY→Vc(X×Y) shows that the product of two strongly connected sublocales is strongly connected. If X is locally connected then VcX is overt. For the localic completion Y¯ of a generalized metric space Y, the points of VcY¯ are certain Cauchy filters of formal balls for the finite power set FY with respect to a Vietoris metric. Application to the point-free real line R gives a choice-free constructive version of the Intermediate Value Theorem and Rolle's Theorem. The work is topos-valid (assuming natural numbers object). Vc is a geometric construction.","Locale, Hyperspace, Geometric logic, Intermediate Value Theorem, Rolle",A Conference in honour of Peter Collins and Mike Reed,,,,,,,,,,,,,,,,,,,,
Journal Article,"Corradini A,Lenisa M,Montanari U",,"Preface: Volume 44, Issue 1",Electronic Notes in Theoretical Computer Science,2001,44,1,308-309,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105809168;http://dx.doi.org/10.1016/S1571-0661(05)80916-8,10.1016/S1571-0661(05)80916-8,"This volume contains the Proceedings of the Fourth Workshop on Coalgebraic Methods in Computer Science (CMCS 2001). The Workshop was held in Genova, Italy on April 6 and 7, 2001, as a satellite event of ETAPS 2001. The aim of the CMCS workshop series is to bring together researchers with a common interest in theory of coalgebras and its applications. Previous workshops have been organized in Lisbon (1998), Amsterdam (1999) and Berlin (2000). The proceedings appeared as ENTCS Vols. 11,19 and 33. During the last few years it is becoming increasingly clear that a great variety of state-based dynamical systems, like transition systems, automata, process calculi and class-based systems can be captured uniformly as coalgebras. The first three volumes together with the current volume demonstrate that theory of coalgebras and its applications are developing into a field of its own interest presenting a deep mathematical foundation, a growing field of applications and interactions with various other fields, such as reactive and interactive system theory, object oriented and concurrent programming, formal system specification, modal logic, dynamical systems, control systems, category theory, algebra, analysis, etc. The Program Committee of CMCS 2001 consisted of Alexandru Baltag(Department of Software Technology, CWI)Andrea Corradini(Department of Computer Science, University of Pisa)Bart Jacobs(Department of Computer Science, University of Nijmegen)Marina Lenisa(Department of Mathematics and Computer Science, University of Udine)Ugo Montanari(Department of Computer Science, University of Pisa)Larry Moss(Department of Mathematics, Indiana University, Bloomington)Ataru T. Nakagawa(Software Research Associates, Tokyo)Dusko Pavlovic(Kestrel Institute, Palo Alto)John Power(Laboratory for Foundations of Computer Science, University of Edinburgh)Horst Reichel(Institute of Theoretical Computer Science, Dresden University of Technology)Jan Rutten(Department of Software Technology, CWI) The Invited Speakers of CMCS 2001 were Robin Cockett (University of Calgary) and Gordon Plotkin (University of Edinburgh). The papers in this volume were reviewed by the program committee members and by Falk Bartels, Anna Bucalo, Corina Cirstea, Pietro Di Gianantonio, Marcelo Fiore, Jesse Hughes, Alexander Kurz, Anna Labella, Lambert Meertens, Marino Miculan, Marco Pistore, Grigore Rosu, Doug Smith. This volume will be published in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs A printed version of the current volume is distributed to the participants at the workshop in Genova. We are very grateful to the following persons, whose help has been crucial for the success of CMCS 2001: Maura Cerioli and Gianna Reggio for their help with the organization of the Workshop as satellite event of ETAPS 2001; and Mike Mislove, Managing Editor of the ENTCS series, for his assistance with the use of the ENTCS style files. Thanks are also due to the Department of Computer Science of the University of Pisa, which has covered the printing cost of the copies distributed in Genova. Andrea Corradini, Marina Lenisa, Ugo Montanari March 13, 2000",,"CMCS 2001, Coalgebraic Methods in Computer Science (a Satellite Event of ETAPS 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Pauly A,Schneider M",,VASA: An algebra for vague spatial data in databases,Information Systems,2010,35,1,111-138,,,,,2010,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437909000519;http://dx.doi.org/10.1016/j.is.2009.05.003,10.1016/j.is.2009.05.003,"Many geographical applications deal with objects in space that cannot be adequately described by determinate, crisp spatial concepts because of their intrinsically indeterminate and vague nature. Geographical information systems and spatial database systems are currently unable to cope with this kind of data. To support the efficient representation, querying, and manipulation of vague spatial data in a database context, we present a formal data model called vague spatial algebra (VASA). This algebra comprises a set of vague spatial data types for vague points, vague lines, and vague regions together with a comprehensive collection of vague spatial operations and vague topological predicates. One of VASA's main benefits is that its formal framework is based on well known, general, and exact models of crisp spatial data types. This enables an exact definition of the vague spatial model since we can build upon an already existing theory of spatial data types. In particular, crisp spatial data types turn out to be a special case of their vague counterparts. In addition, our approach enables executable specifications for the operations, which can be immediately used as implementations. The article offers a precise and conceptually clean foundation for implementing a DBMS extension for vague spatial data and demonstrates the embedding of these new data types as attribute data types in a database schema as well as the incorporation of vague spatial operations and predicates into queries formulated in an SQL-like query language. All concepts have been verified in a prototype implementation.","Vague spatial data types, Vague topological predicates, Characterization predicates, Executable specifications, Binary constraint networks",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Barclay K,Savage J","Barclay K,Savage J",Chapter 5 - Simple input and output,,2007,,,39-45,,Morgan Kaufmann,San Francisco,Groovy Programming,2007,9780123725073,,https://www.sciencedirect.com/science/article/pii/B9780123725073500071;http://dx.doi.org/10.1016/B978-012372507-3/50007-1,10.1016/B978-012372507-3/50007-1,"Publisher Summary Strictly, input and output facilities are not part of the Groovy language. Nonetheless, real programs do communicate with their environment. To produce simple text output in Groovy, statements of the following form are used: print XXX print(xxx) println xxx println(xxx). The methods print and println are used to display the value concerned (denoted by xxx). The value may represent a String literal, a variable or expression, or an interpreted String. Method print outputs its value, and any further output appears on the same output line. Method println advances to the next output line after displaying its value. Formatted output is achieved with the printf method call. The formal description of printf is: printf(String format. List values). This method prints its values on the console. The values are any expressions representing what is to be printed. The presentation of these values is under control of the formatting string. This string contains two types of information: ordinary characters, which are simply copied to the output, and conversion specifications, which control conversion and printing of the values. The object is defined in the Java class System represents the standard input, and is an object of the class InputStream. This class includes the method readLine, which reads a single line of input as a String. Hence, the method call System.in.readLine0 can be used to obtain a line of input from the user.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Stern A,Stern A,CHAPTER 1 - ELEMENTS OF MATRIX CALCULUS,,1988,,,7-35,,North-Holland,Amsterdam,Matrix Logic,1988,9780444704320,,https://www.sciencedirect.com/science/article/pii/B9780444704320500059;http://dx.doi.org/10.1016/B978-0-444-70432-0.50005-9,10.1016/B978-0-444-70432-0.50005-9,"Publisher Summary This chapter discusses the elements of matrix calculus. In a bra or row-vector components are ordered vertically. The components of the row of the first vector, bra or ket, are multiplied by the corresponding components of the column of the second vector, ket or bra, and if there are several results they are added. The interaction of two vectors can, depending on the order of operations, generate two different mathematical objects, that is, either numbers or matrices. The inner and outer products bridge two important mathematical domains—the domain of numbers and the domain of matrices. The outer product serves to define the closure relation that can be employed to construct a vector space. The inner product offers a way of defining the orthogonality of vectors. The complete vector space can be generated from vectors called basis vectors and the key property of a basis set of vectors is linear independence.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tewari R,Adam NR",,Using semantic knowledge of transactions to improve recovery and availability of replicated data,Information Systems,1992,17,6,477-490,,,,,1992,,0306-4379,https://www.sciencedirect.com/science/article/pii/030643799290027K;http://dx.doi.org/10.1016/0306-4379(92)90027-K,10.1016/0306-4379(92)90027-K,"Replication in distributed computing systems provides improved availability and reliability in the event of site failure and network partitioning. However, if strict mutual consistency is required, transactions can be processed in at most one partition, thereby reducing availability. We present a consistency control algorithm that relaxes strict mutual consistency criteria, and allows concurrent processing in all partitions. Inconsistency of data objects in different partitions is resolved at the time of merging the partitions when recovery occurs. The basis of our algorithm is a new merge mechanism that utilizes available semantic information about the data objects and transaction types. We present a formal proof of correctness of the algorithm. Results from a simulation model show that our algorithm performs better than a previously proposed approach that uses compensating transactions to sacrifice serializability of replicated data.","Distributed databases, replicated data management, recovery, consistency control",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bartetzko D,Fischer C,Möller M,Wehrheim H",,Jass — Java with Assertions1 1This work was partially funded by the German Research Council (DFG) under grant OL 98/3-1,Electronic Notes in Theoretical Computer Science,2001,55,2,103-117,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104002476;http://dx.doi.org/10.1016/S1571-0661(04)00247-6,10.1016/S1571-0661(04)00247-6,"Design by Contract, proposed by Meyer for the programming language Eiffel, is a technique that allows run-time checks of specification violation and their treatment during program execution. Jass, Java with assertions, is a Design by Contract extension for Java allowing to annotate Java programs with specifications in the form of assertions. The Jass tool is a pre-compiler that translates annotated into pure Java programs in which compliance with the specification is dynamically tested. Besides the standard Design by Contract features known from classical program verification (e.g. pre- and postconditions, invariants), Jass additionally supports refinement, i.e. subtyping, checks and the novel concept of trace assertions. Trace assertions are used to monitor the dynamic behaviour of objects in time.",,"RV'2001, Runtime Verification (in connection with CAV '01)",,,,,,,,,,,,,,,,,,,,
Journal Article,Onwubolu GC,,Finite element mesh generation of arbitrary solid objects in cad,Computers & Structures,1991,41,5,1011-1018,,,,,1991,,0045-7949,https://www.sciencedirect.com/science/article/pii/004579499190294V;http://dx.doi.org/10.1016/0045-7949(91)90294-V,10.1016/0045-7949(91)90294-V,This paper discusses a three-dimensional solid modelling scheme developed with B-spline as a basis and the techniques for transforming the solid model geometric data into formal solid finite elements. A solid is represented by the scheme as a union of quasi-disjointed cells which are bounded by orthogonal B-spline curves. An algorithm developed converts the cells into solid finite elements. The modelling technique is a powerful tool in the CAD/CAM environment because it is particularly useful for the design and analysis of curved solid mechanical parts.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kahl W,Parnas DL,Schmidt G",,"Preface: Volume 44, Issue 3",Electronic Notes in Theoretical Computer Science,2003,44,3,221-223,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105800106;http://dx.doi.org/10.1016/S1571-0661(05)80010-6,10.1016/S1571-0661(05)80010-6,"RelMiS 2001 This issue contains the Proceedings of the First International Workshop on Relational Methods in Software (RelMiS 2001). The Workshop was held in Genova, Italy, on April 7 and 8, 2001, as a satellite event to ETAPS 2001. The rôle of the calculus of relations in algebra and logic is well understood and appreciated; relational methods should be part of the “toolbox” of everyone who uses mathematics, and relational methods can also be of great value to everyone who develops or specifies software. For example, much of the work on special logics or “laws” for programs can be simplified by applying relational algebra. Further, every relation on a state space can be used as a specification or description of a program. This is an advantage over some predicate-based formalisms in which one can write “specifications” that are impossible to satisfy. During the 1980's, the equational theory of relation algebras was applied to program semantics and program development. On the other hand, a topic such as relational databases was an essentially new development, but one that did not take full advantage of earlier mathematical work on relations. It has contributed new concepts. Computer science, as a new application field for relational methods, has both drawn from and contributed to previous work in logics and mathematics. Further integration of the mathematical work in relational methods with research in computer science can only benefit both. Although a series of international “RelMiCS” workshops on “Relational Methods in Computer Science” already has been established, and, more recently, the joint European COST Action 274 TARSKI (Theory and Application of Relational Methods as Knowledge Instruments) has gained considerable interest, we felt that more exposure of relational methods to software practitioners and computer scientists with interests in software development was needed. Consequently, we decided to initiate a satellite event for ETAPS 2001, and are grateful to the ETAPS organisers for including RelMiS among their satellite events. RelMiS 2001 consisted of two distinct parts: •a tutorial introduction to relational methods for computer scientists and software developers, and•a workshop to discuss new results and possible future work. For the tutorial part, four lectures were held: •Gunther Schmidt:Basics of Relational Methods This tutorial presented the foundations of relational methods, stressing the component-free compositional approach which allows more compact formalisations and concise, easily verified, proofs.•David L. Parnas:The Tabular Method for Relational Documentation The basic mathematical laws of relations can be presented and verified using compact abstract notation. However, descriptions of specific relations, such as those that arise in describing software, must be done in terms of a a state representation. When conventional notation is used, the expressions can be complex and hard to use. This tutorial presented and explained tabular notation that has been found useful in practical software development. It also described a set of prototype tools that make it easier to apply relational methods in software development.•Wolfram Kahl:Refinement and Development of Programs from Relational Specifications Starting from relational specifications, refinement steps may be used to obtain first more detailed specifications, and then programs. The foundations of relational refinement concepts were discussed and the “demonic calculus of relations” and other tools for calculational program development by relational refinement were presented.•Rudolf Berghammer (Christian-Albrechts-Universität zu Kiel):Prototyping and Programming with Relations This tutorial showed an approach to programming directly on the level of binary relations, and with strong visualisation support. This was then used for solving combinatorial problems and for prototyping complex algorithms on a high level of abstraction. For the open workshop, we called for contributions in a field centering around the following topics: •Relational Specifications and Modelling Methods and tools, tabular methods, abstract data types•Relational Software Design and Development Techniques Relational refinement, heuristic approaches for derivation, correctness considerations, dynamic programming, greedy algorithms, catamorphisms, paramorphisms, hylomorphisms and related topics•Programming with Relations Prototyping, testing, fault tolerance, information systems, information coding•Handling of Large Relations Problems of scale, innovative representations, distributed implementation, implementing relational algebra with mixed representation of relations This special issue begins with slides from the second tutorial and notes for the last two tutorials. The remainder is made up of the six accepted contributions presented on the second day of the RelMiS workshop, which saw much lifely discussion and which concluded with software demonstrations from the participants. The contribution by Del Gobbo and Mili employs relation-algebraic reasoning for composing the specification of a fault-tolerant flight control system, exploiting the flexibility of relational formalisations and the ease with which relational operations allow composition at a high level of abstraction to arrive at a logically structured specification that also addresses the non-functional requirement of fault-tolerance. Also in the realm of specification, Khédri considers relational formalisations of scenarios. He arrives at a characterisation of bisimulation via fixpoints involving residuals, and uses this to outline a technique that can be used for automated comparison of different formalisations of scenarios, yielding information not only about discrepancies, but also about different levels of formality and granularity. Omodeo and Doberkat propose a relation-algebraic semantics for the static aspects of entity-relationship models with the aim of enabling formal reasoning about ER-models. They use a formalisation of set theory inside relation algebra to enable a formal semantics of a restricted kind of ER-models (but including inheritance) close to the intuitive understanding of ER-modellers. A new kind of relational diagrams representing relation-algebraic formulae is introduced by Formisano, Omodeo and Simeoni, and implemented as an application of an existing graph rewriting tool. This provides a proof assistant for graphical reasoning in the calculus of binary relations, and includes mechanisms for the translation of predicate-logic specifications. Bruni and Gadduci investigate fundamental properties of category-theoretic spans and co-pans and show how closely these relate to algebras of relations and of multirelations. An intersting application shows how co-pans, used as semantic domain for Petri nets, suport reasoning about causality between different threads of a distributed computation. Building on a relation-algebraic model of CCS processes, Winter presents an implemented mechanism for generating process definitions from safety conditions expressed in a modal logic, and includes a sketch how this could be extended to also cover temporal logic lifeness conditions. We are very grateful to Jules Desharnais (Université Laval, Québec, Canada) and Rudolf Berghammer (Christian-Albrechts-Universität zu Kiel, Germany) for joining us on the program committee for the workshop, and also wish to express our sincere gratitude to Michael Mislove for making this special issue of ENTCS possible. Wolfram KahlDavid L. ParnasGunther SchmidtHamiltonLimerickMünchen",,"RelMiS 2001, Relational Methods in Software (a Satellite Event of ETAPS 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Getta J,Rybiński H",,HOLMES: A deduction augmented database management system,Information Systems,1984,9,2,167-179,,,,,1984,,0306-4379,https://www.sciencedirect.com/science/article/pii/0306437984900255;http://dx.doi.org/10.1016/0306-4379(84)90025-5,10.1016/0306-4379(84)90025-5,"HOLMES is a database system based on object-relationship concept. The idea of a generalized schema is introduced. A uniform language, based on first order predicate calculus, intended to express both formulas of a generalized schema and users' queries is presented. This high level database language enables one to define a database application as a “theory” expressed by a set of formulas. Possibilities of the presented approach are discussed. Implementation problems are sketched.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Thatte SR,,Type inference with partial types,Theoretical Computer Science,1994,124,1,127-148,,,,,1994,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397594900566;http://dx.doi.org/10.1016/0304-3975(94)90056-6,10.1016/0304-3975(94)90056-6,"As a partial solution to the problem of combining static and dynamic typing in a language with parametric polymorphism, this paper introduces a new form of type expressions which represent partial type information. These expressions are meant to capture the type information statically derivable from heterogeneous objects. The new ground types form a semilattice of subtypes and require type inference based on inclusion constraints. We discuss the existence and form of principal types under this extension and present a semi-decision procedure for the complete type inference problem.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cleaveland R,Garavel H",,"Preface: Volume 66, Issue 2",Electronic Notes in Theoretical Computer Science,2002,66,2,211-213,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580413X;http://dx.doi.org/10.1016/S1571-0661(05)80413-X,10.1016/S1571-0661(05)80413-X,"Foreword The aim of the FMICS workshops is to provide a forum for researchers who are interested in the development and application of formal methods in industry. In particular, these workshops are intended to bring together scientists who are active in the area of formal methods and interested in exchanging their experiences in the industrial usage of these methods. These workshops also strive to promote research and development for the improvement of formal methods and tools for industrial applications. Topics include, but are not restricted to: •Tools for the design and development of formal descriptions•Verification and validation of complex, distributed, real-time systems and embedded systems•Verification and validation methods that aim at circumventing shortcomings of existing methods in respect to their industrial applicability•Formal methods based conformance, interoperability and performance testing•Case studies and project reports on formal methods related projects with industrial participation (e.g. safety critical systems, mobile systems, object-based distributed systems)•Application of formal methods in standardization and industrial forums Previous workshops of the ERCIM working group on Formal Methods for Industrial Critical Systems were held in Oxford (March 1996), Cesena (July 1997), Amsterdam (May 1998), Trento (July 1999), Berlin (April 2000), and Paris (July 2001). This year's workshop is organized at the University of Málaga, immediately after the ICALP 2002 conference. It includes five sessions of regular contributions. We are also pleased to welcome three invited presentations: Andreas Podelski, who discusses abstraction for software model checking, Andrew D. Gordon, who investigates in authenticity types for cryptographic protocols and Wang Yi, who addresses the issue of synthetizing verified real time software. The proceedings of FMICS 02 are published both physically, as a technical report of the University of Málaga, and electronically, in the ENTCS series (Electronic Notes in Theoretical Computer Science). We wish to thank the members of the programme committee and the additional reviewers for their careful evaluation of the submitted papers (13 papers have been selected out of 22 submitted). We are very grateful to the local organizers at the University of Málaga, and especially Pedro Merino, for their excellent assistance during the workshop preparation. Finally, we would like to thank ERCIM and ICALP for their financial and organizational support of FMICS 02. Our reviewing process benefited from the METAFrame Online Conference Service (courtesy of METAFrame Technologies, which we would like to thank also for their technical support in setting and running the service). Rance Cleaveland, Hubert Garavel June 2002 Further information about the FMICS working group: http://www.inrialpes.fr/vasy/fmics Programme Committee •T. Arts (Ericsson, S)•M. Bernardo (Univ. of Urbino, I)•R. Cleaveland, co-chair (SUNY and Reactive Systems, USA)•W.J. Fokkink(CWI, NL)•H. Garavel, co-chair (INRIA Rhone-Alpes, F)•S. Gnesi (CNR/IEI Pisa, I)•P. Godefroid (Bell Labs, USA)•H. Hermanns (Univ. Twente, NL)•T. Margaria (METAFrame Technologies, D)•P. Merino Gómez, local organization chair (Univ. Málaga, E)•I. Schieferdecker (GMD Berlin, D)•S. Schneider (Royal Holloway, University of London, UK)•M. Sighireanu (University of Paris-7 Jussieu, F)•R. de Simone (INRIA Sophia Antipolis, F)•U. Ultes-Nitsche (University of Southampton, UK)•A. Valmari (Tampere University of Technology, Fi)•W. Visser (RIACS/NASA Ames, USA) Additional Reviewers •Bahareh Badban•Clara Benac Earle•Tommaso Bolognesi•Antonio Cerone•Kousha Etessami•Alessandro Fantechi•Natalia Ioustinova•Frederic Lang•Izak van Langevelde•Michael Leuschel•Pablo Lopez•Cecilia Mascolo•Mieke Massink•Radu Mateescu•Simona Orzan•Jun Pang•Laurence Pierre•Simon St James•Laurent Thery•Mikko Tiusanen Local Organizing Committee Software Engineering Group, University of Málaga •M. del Mar Gallardo•P. López•J. Martínez•P. Merino, local organization chair","Formal Methods, Formal Description Techniques, Modelling, Specification, Verification, Prototyping, Testing, Software Development, Protocols, Safety Critical Software, Abstractions, Model Checking, Real Time","FMICS'02, 7th International ERCIM Workshop in Formal Methods for Industrial Critical Systems (ICALP 2002 Satellite Workshop)",,,,,,,,,,,,,,,,,,,,
Journal Article,Currie JD,,Which graphs allow infinite nonrepetitive walks?,Discrete Mathematics,1991,87,3,249-260,,,,,1991,,0012-365X,https://www.sciencedirect.com/science/article/pii/0012365X9190134N;http://dx.doi.org/10.1016/0012-365X(91)90134-N,10.1016/0012-365X(91)90134-N,"A word is simply a finite string of letters. A word w is nonrepetitive if no two adjacent blocks in w are identical. Contrary to what one might expect, arbitrarily long nonrepetitive words exist on a three letter alphabet. The existence of arbitrarily long nonrepetitive words on finite alphabets has been used to create pathological objects in algebra, dynamics, formal language theory and other areas. The author explores the structure of nonrepetitive words by determining on which finite undirected graphs infinite nonrepetitive words can be walked.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Korff M,Ribeiro L",,Concurrent Derivations as Single Pushout Graph Grammar Processes,Electronic Notes in Theoretical Computer Science,1995,2,,177-186,,,,,1995,,1571-0661,https://www.sciencedirect.com/science/article/pii/S157106610580194X;http://dx.doi.org/10.1016/S1571-0661(05)80194-X,10.1016/S1571-0661(05)80194-X,"Algebraic graph transformations visually support intuition, have a strong theoretical basis, and provide a formal, implementation independent basis for the description of discretely evolving computational systems and their formal and tractable analysis. Graph grammar models of concurrent systems (petri nets, actor systems) have inspired corresponding semantics developments. Recently this led to the introduction of partial orders of concurrent derivations (concurrent computations). A concurrent derivation (CDer) abstracts from the (sequential) order of rule applications in the sequential derivation and thus can be considered as a concurrent process. Complementary, a morphism between two concurrent derivations expresses that the first is a computational approximation of the second. In this paper we newly introduce non-deterministic concurrent derivations (CTrees) as classes of concurrently equivalent sequential derivation trees. Due to the fact that also infinite computations are represented by CTrees, the category of all CTrees of a given graph grammar has a final object (the concurrent counterpart of the whole sequential tree of the given grammar) which is approximated by all other CTrees. We show that (syntactical) morphisms between two graph grammars induce corresponding adjunction between the corresponding (semantic) categories of CDers and CTrees respectively.",,"SEGRAGRA 1995, Joint COMPUGRAPH/SEMAGRAPH Workshop on Graph Rewriting and Computation",,,,,,,,,,,,,,,,,,,,
Journal Article,Störrle H,,VMQL: A visual language for ad-hoc model querying,Journal of Visual Languages & Computing,2011,22,1,3-29,,,,,2011,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X1000073X;http://dx.doi.org/10.1016/j.jvlc.2010.11.004,10.1016/j.jvlc.2010.11.004,"In large scale model based development, analysis level models are more like knowledge bases than engineering artifacts. Their effectiveness depends, to a large degree, on the ability of domain experts to retrieve information from them ad-hoc. For large scale models, however, existing query facilities are inadequate. The visual model query language (VMQL) is a novel approach that uses the respective modeling language of the source model as the query language, too. The semantics of VMQL is defined formally based on graphs, so that query execution can be defined as graph matching. VMQL has been applied to several visual modeling languages, implemented, and validated in small case studies, and several controlled experiments.","Model querying, Unified modeling language (UML), Object constraint language (OCL), Domain specific languages (DSL), End user modelers",Special Issue on Visual Languages and Logic,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liu H,Liu L,Zhang H",,A fast pruning redundant rule method using Galois connection,Applied Soft Computing,2011,11,1,130-137,,,,,2011,,1568-4946,https://www.sciencedirect.com/science/article/pii/S1568494609002178;http://dx.doi.org/10.1016/j.asoc.2009.11.004,10.1016/j.asoc.2009.11.004,"Besides preprocessing, post-analysis also plays an important role in knowledge discovery. It can effectively assist users to grasp the obtained knowledge. However, many of data mining algorithms merely take performance into consideration and put the post-analysis of results aside. They generate a modest number of rules for the purpose of improving accuracy. Unfortunately, most induced rules are redundant or insignificant. Their presence not only confuses end-users in post-analysis, but also degrades efficiency in future decision task. Thus, it is necessary to eliminate redundant or irrelevant rules as more as possible. In this paper, we present an efficient post-processing method to prune redundant rules by virtue of the property of Galois connection, which inherently constrains rules with respect to objects. Its advantage is that information will not be lost greatly during pruning step. The experimental evaluation shows that the proposed method is competent for discarding a large number of superfluous rules effectively and a high compression factor will be achieved. What’s more, the computational cost of our method is surprisingly lower than the Apriori method.","Data mining, Rule pruning, Galois connection, Formal concept analysis, Post-analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Derrick J,Boiten E,Woodcock J,von Wright J",,"Preface: Volume 70, Issue 3",Electronic Notes in Theoretical Computer Science,2002,70,3,1-2,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105804785;http://dx.doi.org/10.1016/S1571-0661(05)80478-5,10.1016/S1571-0661(05)80478-5,"This volume contains the Proceedings of the REFINE 2002 workshop. The Workshop was held in Copenhagen, Denmark on July 20 and 21, 2002, as a satellite event to FLoC'02 as an FME-affiliated workshop. Refinement is one of the cornerstones of a formal approach to software engineering. Refinement is the process of developing a more detailed design or implementation from an abstract specification through a sequence of mathematically-based steps that maintain correctness with respect to the original specification. The aim of this BCS FACS refinement workshop was to bring together people who are interested in the development of more concrete designs or executable programs from abstract specifications using formal notations, tool support for formal software development, and practical experience with formal refinement methodologies. The purpose of the workshop was to provide a forum for discussion of common ground and key differences. Topics of interest included: •Simulation techniques•Foundations and semantics•Case studies (specification and verification)•Compositional and modular reasoning•Object-orientation•Time•Specification notations•Programming models•Verification and tool support The workshop continued a long tradition of refinement workshops run under the auspices of the British Computer Society (BCS) FACS special interest group. Running since 1988, previous refinement workshops have been held at Cambridge, London, Bath etc. In 1998 the BCS refinement workshop was combined with the Australasian Refinement Workshop to form the International Refinement Workshop, hosted at alongside Formal Methods Pacific 1998 at The Australian National University. The papers in this volume were reviewed by a small program committee consisting of •John Derrick<jd1@ukc.ac.uk, University of Kent, UK.•Eerke Boiten<eab2@ukc.ac.uk, University of Kent, UK.•Jim Woodcock<jcpw@ukc.ac.uk, University of Kent, UK.•Joakim von Wright<jockum.wright@abo.fi, Åbo Akademi University, Finland Additional information about the Workshop can be found at: http://www.cs.ukc.ac.uk/people/staff/eab2/refine/floc.html This volume will be published as volume 70 issue 3 in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs A printed version of the current volume was distributed to the participants at the workshop in Denmark. We are very grateful to the following persons, whose help has been crucial for the success of REFINE 2002: Lars-Henrik Eriksson and Peter Lindsay of FME for their help with the organization of the Workshop as satellite event of FLoC'02 and an FME affiliated workshop; Mike Mislove, one of the Managing Editors of the ENTCS series, for his assistance with the use of the ENTCS style files. Thanks are also due to the Computing Laboratory of the University of Kent, which supplied financial support to cover the printing costs. July 24, 2002 John Derrick",,"REFINE 2002, The BCS FACS Refinement Workshop (Satellite Eventof FLoC 2002)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Eick CF,Raupp T",,Towards a formal semantics and inference rules for conceptual data models,Data & Knowledge Engineering,1991,6,4,297-317,,,,,1991,,0169-023X,https://www.sciencedirect.com/science/article/pii/0169023X9190036W;http://dx.doi.org/10.1016/0169-023X(91)90036-W,10.1016/0169-023X(91)90036-W,"A new-from a theoretical point of view-approach to expressing data- or knowledge base semantics is described: the universe of discourse is modeled by classes (unary relations), by attributes (binary relations), and by a set of general, possibly multityped functional and existence dependencies between these classes and attributes. In contrast to single-typed approaches, such as normalization, our approach has to cope with dependencies ranging over more than one type. The notation of a path and of confluent type hierarchies are introduced to cope with multityped dependencies. An axiomatization for general functional and existence dependencies is provided. Possibilities and limitations of our approach for automating reasoning involving conceptual schemas are discussed, and its relationship to relational database theory is outlined.","Logical database design, dealing with inheritance structures, dependencies involving paths, multityped functional dependencies, multityped existence dependencies, semantics of conceptual data models, inference rules for conceptual data models, -diagram",,,,,,,,,,,,,,,,,,,,,
Journal Article,Goguen JA,,Modular algebraic specification of some basic geometrical constructions,Artificial Intelligence,1988,37,1,123-153,,,,,1988,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370288900525;http://dx.doi.org/10.1016/0004-3702(88)90052-5,10.1016/0004-3702(88)90052-5,"This paper applies some recent advances in algebraic specification technology to plane geometry. The two most important specification techniques are parameterized modules and order-sorted algebra; the latter provides a systematic treatment of subtypes. This exercise also indicates how a rigorous semantic foundation in equational logic can be given for many techniques in knowledge representation, including is-a hierarchies (with multiple inheritance), multiple representations, implicit (one-way) coercion of representation and parameterized modular structuring. Degenerate cases (which can be a particular nuisance in computational geometry), exception handling, information hiding, block structure, and pattern-driven rules are also treated, and again have rigorous semantic foundations. The geometric constructions which illustrate all this are specified over any ordered field having square roots of nonnegative elements; thus, we also specify some algebra, including rings, fields, and determinants. All specifications are written in a variant of the OBJ language.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Defays D,,Tree representations of ternary relations,Journal of Mathematical Psychology,1979,19,2,208-218,,,,,1979,,0022-2496,https://www.sciencedirect.com/science/article/pii/002224967990018X;http://dx.doi.org/10.1016/0022-2496(79)90018-X,10.1016/0022-2496(79)90018-X,"In recent years there has been a growing interest in representing data by trees. Most of the literature has been concerned with inferring trees from pairwise data. In this paper, trees are constructed from ternary relations; the model represents each object of an empirical set by a node of a tree so that a betweenness relation among the nodes (the node b is on the path from the node a to the node c) in the graph reflects a ternary relation among the objects. Various systems of formal properties that lead to three different kinds of tree representation are investigated.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kang X,Li D,Wang S",,A multi-instance ensemble learning model based on concept lattice,Knowledge-Based Systems,2011,24,8,1203-1213,,,,,2011,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705111001043;http://dx.doi.org/10.1016/j.knosys.2011.05.010,10.1016/j.knosys.2011.05.010,"This paper introduces concept lattice and ensemble learning technique into multi-instance learning, and proposes the multi-instance ensemble learning model based on concept lattice which can be applied to content-based image retrieval, etc. In this model, a ♢-concept lattice is built based on training set firstly. Because bags rather than instances in bags will serve as objects of formal context in the process of building ♢-concept lattice, the corresponding time complexity and space complexity can be effectively descend to a certain extent; Secondly, the multi-instance learning problem is divided into multiple local multi-instance learning problems based on ♢-concept lattice, and local target feature sets are found further in each local multi-instance learning problem. Finally, the whole training set can be classified almost correctly by ensemble of multiple local target feature sets. Through precise theorization and extensive experimentation, it proves that the method is effective. Conclusions of this paper not only help to understand multi-instance learning better from the prospective of concept lattice, but also provide a new theoretical basis for data analysis and processing.","-Concept lattice, Multi-instance learning, Local target feature set, Ensemble learning, Content-based image retrieval",,,,,,,,,,,,,,,,,,,,,
Journal Article,Boute RT,,Syntactic and semantic aspects of formal system description,Microprocessing and Microprogramming,1989,27,1,155-161,,,,,1989,,0165-6074,https://www.sciencedirect.com/science/article/pii/0165607489900392;http://dx.doi.org/10.1016/0165-6074(89)90039-2,10.1016/0165-6074(89)90039-2,"A desirable characteristic of formal system description languages is notational convenience for symbolic manipulation. As most natural and man-made objects are essentially non-algorithmic, syntactic and semantic concepts from traditional programming languages are ill-suited for more general system description. Syntactically, the function notation commonly used in mathematics and engineering provides a better match with the system concepts to be expressed. Depending on whether or not one may discern a (directional) signal flow in the system, lambda terms or sigma terms are appropriate. Semantically, the variety of systems and models has resulted in a corresponding variety of semantic domains and mathematical formalisms. Again based on “standard” notations from applied mathematics, a unifying (but not yet fully formalized) set of language concepts is proposed called Funmath (Functional Mathematics). Two subsets of Funmath are intended to have, respectively, also an operational interpretation as a functional programming language and a structural interpretation as a system description language. Examples are given in various application areas.",,Fifteenth EUROMICRO Symposium on Microprocessing and Microprogramming,,,,,,,,,,,,,,,,,,,,
Journal Article,"Contento A,Di Egidio A",,On the use of base isolation for the protection of rigid bodies placed on a multi-storey frame under seismic excitation,Engineering Structures,2014,62-63,,1-10,,,,,2014,,0141-0296,https://www.sciencedirect.com/science/article/pii/S0141029614000224;http://dx.doi.org/10.1016/j.engstruct.2014.01.019,10.1016/j.engstruct.2014.01.019,"The use of base isolation applied to rigid bodies placed on a multi-storey frame is considered with the aim of understanding whether or not seismic isolation is beneficial in preventing their collapse during an earthquake. The rigid body is placed on either a fixed or an isolated oscillating base. It may be subjected to sliding, rocking and sliding–rocking motions. When base isolation is considered, security stops capable of preventing the isolation system from breaking are always assumed to be present. The frame, modelled as a four-storey, shear-type system, is always considered to work in the elastic regime. The geometrical characteristics of the body are chosen so that a collapse event, such as overturning or falling out from the support, is obtained for an excitation for which the behaviour of the frame remains in the elastic regime. Overturning and falling-out curves are plotted against PGA (Peak Ground Acceleration) to demonstrate the role of the geometrical parameters characterising the body, of the spectral characteristics of the earthquake and of the level of the frame at which the object is placed. The analyses performed reveal that base isolation applied to a rigid body placed on a frame is not always appropriate in cases where the same body is placed on a fixed base.","2D rigid block, Eccentricity, Multi-storey frame, Sliding, Rocking, Overturning",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Kerbrat A,Jéron T,Groz R","Dssouli R,v. Bochmann G,Lahav Y",Automated test generation from SDL specifications,,1999,,,135-151,,Elsevier Science B.V.,Amsterdam,SDL '99,1999,9780444502285,,https://www.sciencedirect.com/science/article/pii/B9780444502285500114;http://dx.doi.org/10.1016/B978-044450228-5/50011-4,10.1016/B978-044450228-5/50011-4,"Automated test generation from formal specifications presents a lot of promises, either in cost control or test suite correctness. Some interesting tools begin to emerge, either prototypes or industrial strength tools. We present the result of the integration in ObjectGEODE of an industrial test generation tool11This work has been initiated and funded by France-Telecom. This tool is based on two complementary test generation prototypes, TVEDA and TGV. TVEDA comes from the research laboratory France-Telecom-CNET, it provides for test purposes and test case generation, based on state space exploration combined with heuristics. TGV has been designed in the research laboratories Irisa and Verimag, it provides test case generation based on efficient, on-the-fly state space exploration techniques.","test generation, conformance testing, SDL, TTCN, verification, static analysis",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Normann D,"Ferro R,Bonotto C,Valentini S,Zanardo A",Kleene-spaces,,1989,127,,91-109,,Elsevier,,Logic Colloquium '88,1989,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08702647;http://dx.doi.org/10.1016/S0049-237X(08)70264-7,10.1016/S0049-237X(08)70264-7,"A Kleene space is an abstract version of Kleene's continuous functionals of some type. A Kleene space consists of a set of formal neighbourhoods with an ordering and a consistency relation, and a set of associates of total objects. The associates are total with respect to certain “questions” represented by chains of mutually incomparable neighbourhoods. Each neighbourhood is nonempty, which is demonstrated by the extension associate, considered as a part of the Kleene space. A transfinite hierarchy of Kleene spaces is constructed, the construction is based on the principal constructors: Function space; well founded tree space; iteration of a constructor over a well founded tree and product of thus parameterised families of spaces.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Kreisel G,Krivine JL",Chapter 2 Predicate Calculus,,1967,48,,15-33,,Elsevier,,Elements of Mathematical Logic,1967,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X0871721X;http://dx.doi.org/10.1016/S0049-237X(08)71721-X,10.1016/S0049-237X(08)71721-X,"Publisher Summary This chapter focuses on predicate calculus. The main notion emphasized in the chapter is those of formula and language of first order predicate logic, and that of a realization of a language, from which the notion of a model of a collection of formulas is defined. The chapter also describes the construction of canonical models in which each object (that is, element of the model) has a name in the language under consideration. The construction of canonical models is done with the help of function schemas. This method leads to several results such as (1) each model of a finite or countable set of formulas Ҝ has a countable subsystem which is also a model of Ҝ, (2) the finiteness theorem (This is proved by reduction to the case of propositional calculus), and (3) the uniformity theorem. The method described in the chapter permit an extension to predicate logic of the interpolation lemma.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Fu J,Tao J",,Robust multi-model adaptation regression with local feature space representation,Knowledge-Based Systems,2019,174,,160-176,,,,,2019,,0950-7051,https://www.sciencedirect.com/science/article/pii/S0950705119301078;http://dx.doi.org/10.1016/j.knosys.2019.03.004,10.1016/j.knosys.2019.03.004,"Learning visual models of object categories generally requires a large number of training examples. We show in this paper that it is possible to uncover much discriminative information about a visual category from a small number of examples with just fewlabeled data. The key insight is that, rather than learning from scratch with the original feature representation, we learn an optimal target model with the local feature space representations by leveraging some prior models pre-trained on other related datasets, no matter how different they might be. This target model can be obtained by learning a robust regression scheme with a multi-source adaptation regularization term, which is formally formulated as a Robust Multi-model Adaptation Regression (RMAR) framework with local feature space representations of the target data. This framework is composed of three core components: (1) local consistency Laplacian regularization by constructing a self-adaptive affinity graph based on local feature space representation (LFSR), which aims to augment the discriminative space of the target domain; (2) robust regression learning scheme with feature selection based on l2,1-norm minimization by explicitly considering the regression noise/outlier as well as the regression residual; and (3) scatter constrained multi-model adaptation regularization for generalizing the established robust regression framework to exploit the prior models, under the assumption that multiple auxiliary discriminative models can help the semi-supervised learning from few labeled samples. Lastly, we further propose an effective extension to RMAR, i.e., ensemble LFSR-graph Laplacians regularization framework. The optimization algorithms for RMAR and its extension can be efficiently solved by the alternating iterative strategy, and the iteration convergence can be theoretically guaranteed. Experiments over several real datasets show the promising performance of our methods compared with several representative state-of-the-art works.","Robust regression, Multi-model adaptation, Laplacian regularization, Feature space representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,Gips J,,A syntax-directed program that performs a three-dimensional perceptual task,Pattern Recognition,1974,6,3,189-199,,,,,1974,,0031-3203,https://www.sciencedirect.com/science/article/pii/0031320374900211;http://dx.doi.org/10.1016/0031-3203(74)90021-1,10.1016/0031-3203(74)90021-1,"A syntax-directed program that performs a three-dimensional perceptual task is described. The task, in a slightly simpler form, was used originally in a psychological study of mental rotation. (1) The task consists of determining whether two line drawings portray (different views of) identical objects, mirror image objects, or structurally different objects, where the objects are composed of linear strings of attached cubes. The program is syntax-directed in the sense that it uses a fixed set of syntactic rules to analyze the line drawings. This is the first use of formal syntactic techniques in the analysis of pictures (in this case, line drawings) of three-dimensional objects.","Syntactic pattern recognition, Shape grammars, Graph grammars, Picture grammars, Scene analysis, Perception, Mental rotation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tifferet S,Vilnai-Yavetz I",,Gender differences in Facebook self-presentation: An international randomized study,Computers in Human Behavior,2014,35,,388-399,,,,,2014,,0747-5632,https://www.sciencedirect.com/science/article/pii/S0747563214001381;http://dx.doi.org/10.1016/j.chb.2014.03.016,10.1016/j.chb.2014.03.016,"Facebook is a popular social network that can be used for self-presentation. In the current study we examined gender differences in Facebook self-presentation by evaluating components of profile and cover photos. We used evolutionary psychology—a theory which holds many assumptions regarding gender differences—to draw hypotheses. In order to eliminate the pitfalls of self-reported data, we analyzed public data presented in Facebook pages of a random representative international sample of 500 Facebook users. As hypothesized, profile photos on Facebook differed according to gender. Males’ photos accentuated status (using objects or formal clothing) and risk taking (outdoor settings), while females’ photos accentuated familial relations (family photos) and emotional expression (eye contact, smile intensity and lack of sunglasses). Cover photos, however, did not show most of these gender differences, perhaps since they serve only as a supplement to the self-presentation that appears in the profile photos. These findings demonstrate that evolutionary theory rooted in the past can help us understand new social tools of the future.","Facebook, Gender differences, Evolutionary psychology, Impression management, Images, Photo analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Maciá-Pérez F,Berna-Martinez JV,Fernández Oliva A,Abreu Ortega MA",,Algorithm for the detection of outliers based on the theory of rough sets,Decision Support Systems,2015,75,,63-75,,,,,2015,,0167-9236,https://www.sciencedirect.com/science/article/pii/S016792361500086X;http://dx.doi.org/10.1016/j.dss.2015.05.002,10.1016/j.dss.2015.05.002,"Outliers are objects that show abnormal behavior with respect to their context or that have unexpected values in some of their parameters. In decision-making processes, information quality is of the utmost importance. In specific applications, an outlying data element may represent an important deviation in a production process or a damaged sensor. Therefore, the ability to detect these elements could make the difference between making a correct and an incorrect decision. This task is complicated by the large sizes of typical databases. Due to their importance in search processes in large volumes of data, researchers pay special attention to the development of efficient outlier detection techniques. This article presents a computationally efficient algorithm for the detection of outliers in large volumes of information. This proposal is based on an extension of the mathematical framework upon which the basic theory of detection of outliers, founded on Rough Set Theory, has been constructed. From this starting point, current problems are analyzed; a detection method is proposed, along with a computational algorithm that allows the performance of outlier detection tasks with an almost-linear complexity. To illustrate its viability, the results of the application of the outlier-detection algorithm to the concrete example of a large database are presented.","Knowledge discovery, Detection of outliers, Rough set theory",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Schütt T,Schintke F,Reinefeld A",,Range queries on structured overlay networks,Computer Communications,2008,31,2,280-291,,,,,2008,,0140-3664,https://www.sciencedirect.com/science/article/pii/S0140366407003258;http://dx.doi.org/10.1016/j.comcom.2007.08.027,10.1016/j.comcom.2007.08.027,"The efficient handling of range queries in peer-to-peer systems is still an open issue. Several approaches exist, but their lookup schemes are either too expensive (space-filling curves) or their queries lack expressiveness (topology-driven data distribution). We present two structured overlay networks that support arbitrary range queries. The first one, named Chord#, has been derived from Chord by substituting Chord’s hashing function by a key-order preserving function. It has a logarithmic routing performance and it supports range queries, which is not possible with Chord. Its O(1) pointer update algorithm can be applied to any peer-to-peer routing protocol with exponentially increasing pointers. We present a formal proof of the logarithmic routing performance and show empirical results that demonstrate the superiority of Chord# over Chord in systems with high churn rates. We then extend our routing scheme to multiple dimensions, resulting in SONAR, a Structured Overlay Network with Arbitrary Range queries. SONAR covers multi-dimensional data spaces and, in contrast to other approaches, SONAR’s range queries are not restricted to rectangular shapes but may have arbitrary shapes. Empirical results with a data set of two million objects show the logarithmic routing performance in a geospatial domain.","Structured overlay networks, Routing in P2P networks, Consistent hashing, Multi-dimensional range queries",Special Issue: Foundation of Peer-to-Peer Computing,,,,,,,,,,,,,,,,,,,,
Book Chapter,Schubert LK,Sowa JF,2 - SEMANTIC NETS ARE IN THE EYE OF THE BEHOLDER,,1991,,,95-107,,Morgan Kaufmann,,Principles of Semantic Networks,1991,,1046-9567,https://www.sciencedirect.com/science/article/pii/B9781483207711500084;http://dx.doi.org/10.1016/B978-1-4832-0771-1.50008-4,10.1016/B978-1-4832-0771-1.50008-4,"The term “semantic nets,” in its broadest sense, has become virtually meaningless. It is applied to systems which, as a class, lack distinctive representational and computational properties vis à vis other knowledge representation (KR) schemes. This terminological problem is not due to lack of substance or coherence of work done under the semantic net banner. Rather, it is due to convergence of the major KR schemes: the representational and computational strategies employed in semantic net systems are abstractly equivalent to those employed in virtually all state-of-the-art systems incorporating a substantial propositional knowledge base, whether they are described as logic-based, frame-based, rule-based, or something else. In particular, I will argue that using a graph-theoretic propositional representation does not automatically distinguish it from others: even sets of predicate calculus (PC) formulas, abstractly viewed, are graphs. Nor is “proximity-based” inference (using graph-theoretic distance) automatically distinctive, since even resolution strategies (with reasonable indexing schemes) are proximity based in the abstract; nor is hierarchic property inheritance any longer distinctive, given its availability in state-of-the-art logic-based, frame-based, and rule-based systems. So I urge some more restrictive, and hence more meaningful use of the term “semantic nets” than is the current practice.",,,The Morgan Kaufmann Series in Representation and Reasoning,,,,,,,,,,,,,,,,,,,
Journal Article,"Clemotte A,Velasco MA,Raya R,Ceres R,de Córdoba R,Rocon E",,Metodología de Evaluación de Eye-trackers como Dispositivos de Acceso Alternativo para Personas con Parálisis Cerebral,Revista Iberoamericana de Automática e Informática Industrial RIAI,2017,14,4,384-393,,,,,2017,,1697-7912,https://www.sciencedirect.com/science/article/pii/S1697791217300456;http://dx.doi.org/10.1016/j.riai.2017.07.004,10.1016/j.riai.2017.07.004,"Resumen Los procedimientos de evaluación de los sistemas alternativos de acceso al ordenador son poco rigurosos, sistemáticos y formales. Este trabajo presenta una metodología para la valoración de la interacción usuario-ordenador, cuando los sistemas de eye-tracking son utilizados como herramienta de acceso alternativo al ordenador por personas con Parálisis Cerebral (PC). Para ello, proponemos tres métricas de evaluación: tasa de fallos de calibración, tasa de error en el clic y tiempo de clic. Validamos la metodología, comparando 3 (tres) eye- trackers, con 9 (nueve) participantes con PC con trastornos motores severos. Los resultados indican que la calibración es un proceso crítico en estos escenarios como refleja la alta tasa de fallos de calibración medida. Los participantes con PC también tienen una alta tasa de error del clic, lo que indica que el uso de eye-trackers para alcanzar un objeto en pantalla es un proceso complejo para estos niveles de discapacidad motriz. Los tiempos de clics son similares entre todos los eye-trackers y participantes. Este trabajo pretende establecer líneas metodológicas para la efectiva evaluación de estos dispositivos, que pueden llegar a ser una interesante alternativa de acceso al ordenador para esta población. The procedures for evaluating alternative computer access systems are neither rigorous, systematic nor formal. We present a methodology to evaluate the user-computer interaction, based on three metrics, when people with cerebral palsy (CP) use eye- trackers as an alternative access device. We validated the methodology by comparing three commercial eye-trackers with nine participants seriously affected by CP. The results indicate that the calibration is a very critical process in these scenarios because of the high rate of calibration failures measured. The participants with CP also have a high click error rate, indicating that using eye- trackers to reach an object on the screen is a complex process for these levels of disability. The click times are similar between all eye-trackers and participants. This study is not intended to discourage the use of eye-trackers in the population with CP, but to establish methodological guidelines for the effective evaluation of commercial devices, which can be an interesting alternative to computer access for this population.","Acceso alternativo, eye-trackers, metodología, evaluación, valoración, parálisis cerebral, ley de Fitts, Alternative access, Eye-trackers, Methodology, Evaluation, Assessment, Cerebral palsy, Fitts’ Law",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Robbins KA,Jeffery C,Robbins S",,Visualization of Splitting and Merging Processes,Journal of Visual Languages & Computing,2000,11,6,593-614,,,,,2000,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X00901630;http://dx.doi.org/10.1006/jvlc.2000.0163,10.1006/jvlc.2000.0163,Information about objects that split or merge is often generated dynamically as a by-product of computation or in the observation of real-world behavior. Visualization tools for such processes must not only reveal temporal patterns and spatial organization but should also accommodate on-the-fly generation of split–merge information. This paper develops a formal structure for split–merge processes that provides a suitable underpinning for dynamic visualization tools. The structure allows split–merge processes to be constructed dynamically and supports operations such as concatenation and partitioning while maintaining the underlying split–merge structure. The paper also proposes a method for abstracting split–merge substructure to assist in the visualization of large systems. The abstractions can be used to produce visual simplification and to guide layout heuristics in producing better visualizations. The implications of visualizing split–merge processes with time lines are explored. Auxiliary visualization strategies based on dynamic boxes and tree rings are introduced to enhance information content of focus areas in larger time-line visualizations. The concepts are illustrated using data from timings of a network protocol and from the detection of patterns in scientific video data.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Baruch O,Loew MH",,Segmentation of two-dimensional boundaries using the chain code,Pattern Recognition,1988,21,6,581-589,,,,,1988,,0031-3203,https://www.sciencedirect.com/science/article/pii/0031320388900313;http://dx.doi.org/10.1016/0031-3203(88)90031-3,10.1016/0031-3203(88)90031-3,"We divide the boundary of a two-dimensional object into segments, each of which is either straight or a circular arc; associated with the segment end-points are angle measures that can be used to match an object with a transformed (rotated, scaled) version of itself. The chain code, easily extracted from the boundary pixels, is the basis of this division. The approach avoids problems common to many of the existing methods for identification of curvature extrema: sensitivity to noise and dependence on parameters that are chosen empirically. To each section of the boundary we assign a code that represents the change in slope between it and the previous section. This set of codes is integrated and thus provides a measure of the total directional change relative to the first section. For a closed object, the sequence of these sums is periodic, and one cycle can be plotted as a function of arc length, s. Such a plot can be shown to contain only straight lines: those that are not parallel to the s-axis (representing circular arcs on the original boundary of the object) and those that are (representing straight sections on the boundary). This paper describes a recursive procedure for dividing the digital version of the curve described above into its linear segments. Each segment represents an arc that is the best fit to a portion of the original boundary; the angle which is defined by the arc is identical to the angle change of the edge in the same section, and the length of the arc is identical to that of the edge. The recursive procedure measures the error (for each value of arc length) between a proposed fitting line and the actual value of cumulative angle; where the error is maximum, and above a threshold, the line is segmented. The procedure is repeated until the error is sufficiently small. The breakpoints thus indicate the location and value of points of greatest curvature change. A formal definition of the procedure is given, and it is shown to perform well for rotated, scaled and noisy objects.","Chain code, Boundary segmentation, Shape description, Curvature, Extrema",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Varsamidis T,P. Jobling C,Hope S",,Towards a “Repository Service” for Computer-Aided Control Engineering,IFAC Proceedings Volumes,1997,30,4,73-78,,,,,1997,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017436159;http://dx.doi.org/10.1016/S1474-6670(17)43615-9,10.1016/S1474-6670(17)43615-9,"The integration of tools within a computer-aided control engineering environment has been the topic of research for many years. In much of this previous work, a database has been placed at the centre of the proposed designs. By examining the whole lifecycle of control systems design, a unified information model has been developed which allows tools to exchange information between any stage in the design process. The information model is used as the basis for a prototype information repository service for an integrated computer-aided control engineering environment. Use is made of the EXPRESS information modelling language to formally specify the data objects to be stored in the repository and in software wrappers that allow existing tools to make use of the information. Examples of use of the repository and directions for further work are given.","Computer-aided control systems design, computer-aided control engineering, databases, repository services, integration, STEP/EXPRESS","7th IFAC Symposium on Computer Aided Control Systems Design (CACSD '97), Gent, Belgium, 28-30 April",,,,,,,,,,,,,,,,,,,,
Journal Article,"Gray JO,Downes CG",,A Formal Computer Based Design Environment for Aircraft Engine Control Systems,IFAC Proceedings Volumes,1988,21,8,431-439,,,,,1988,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017549915;http://dx.doi.org/10.1016/S1474-6670(17)54991-5,10.1016/S1474-6670(17)54991-5,"Manufacturers of modern aerospace systems often use formalistic design methods, frequently of a modular and hierarchical nature to specify the model of the system in question. This often takes the form of a graphical representation, and hence the development of a graphical interface to the variety of software tools used would enhance the productivity and consistency of such work. In this paper a graphical operating system (ARGOS) is used as an interface for the time response package TSIM in the investigation of jet engine control system performance.","Human interface, graphical interpretation, dynamic systems simulation, hierarchial design, object orientation","4th IFAC Symposium on computer aided Design in Control Systems 1988, Beijing, PRC, 23-25 August",,,,,,,,,,,,,,,,,,,,
Journal Article,Anselmi D,,Anomalies in instanton calculus,Nuclear Physics B,1995,439,3,617-649,,,,,1995,,0550-3213,https://www.sciencedirect.com/science/article/pii/055032139500024M;http://dx.doi.org/10.1016/0550-3213(95)00024-M,10.1016/0550-3213(95)00024-M,"I develop a formalism for solving topological field theories explicitly, in the case when the explicit expression of the instantons is known. I solve topological Yang-Mills theory with the k = 1 instanton of Belavin et al. and topological gravity with the Eguchi-Hanson instanton. It turns out that naively empty theories are indeed nontrivial. Many unexpected interesting hidden quantities (punctures, contact terms, nonperturbative anomalies with or without gravity) are revealed. Topological Yang-Mills theory with G = SU(2) is not just Donaldson theory, but contains a certain link theory. Indeed, local and non-local observables have the property of marking cycles. Moreover, from topological gravity one learns that an object can be considered BRST exact only if it is so all over the moduli space M, boundary included. Being BRST exact in any interior point of M is not sufficient to make an amplitude vanish. Presumably, recursion relations and hierarchies can be found to solve topological field theories in four dimensions, in particular topological Yang-Mills theory with G = SU(2) on R4 and topological gravity with the full set of asymptotically locally Euclidean manifolds.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Klohs K,Kastens U",,Memory Requirements of Java Bytecode Verification on Limited Devices,Electronic Notes in Theoretical Computer Science,2005,132,1,95-111,,,,,2005,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105050073;http://dx.doi.org/10.1016/j.entcs.2005.01.031,10.1016/j.entcs.2005.01.031,"Bytecode verification forms the corner stone of the Java security model that ensures the integrity of the runtime environment even in the presence of untrusted code. Limited devices, like Java smart cards, lack the necessary amount of memory to verify the type-safety of Java bytecode on their own. Proof carrying code techniques compute, outside the device, tamper-proof certificates which simplify bytecode verification and pass them along with the code. Rose has developed such an approach for a small subset of the Java bytecode language. In this paper, we extend this approach to real world Java software and develop a precise model of the memory requirements on the device. We use a variant of interval graphs to model liveness of memory regions in the checking step. Based on this model, memory-optimal checking strategies are computed outside the device and attached to the certificate. The underlying type system of the bytecode verifier has been augmented with multi-dimensional arrays and recognizes references to uninitialized Java objects. Our detailed measurements, based on real world Java libraries, demonstrate that the approach offers a substantial improvement in size of certificate over the similar approach taken by the KVM verifier. Worst case memory consumption on the device is examined as well and it turns out that the refinements based on our model save a significant amount of memory.","Proof Carrying Code, Bytecode Verification, Limited Devices, Java Card",Proceedings of the 3rd International Workshop on Compiler Optimization Meets Compiler Verification (COCV 2004),,,,,,,,,,,,,,,,,,,,
Journal Article,"Leroux P,Viennot XG",,A combinatorial approach to nonlinear functional expansions: an introduction with an example,Theoretical Computer Science,1991,79,1,179-193,,,,,1991,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759190150Z;http://dx.doi.org/10.1016/0304-3975(91)90150-Z,10.1016/0304-3975(91)90150-Z,"In this paper we present a new approach to causal functionals. We introduce combinatorial interpretations of the solutions of nonlinear differential equations with forcing terms. This theory parallels the algebraic approach with formal power series in noncommutative variables developed by Fliess, Lamnabhi and Lamnabhi-Lagarrigue. This theory makes use of certain combinatorial objects called weighted increasing trees, weighted paths and histories. We can deduce very efficient algorithms for the computation of the corresponding Volterra kernels. We present an introduction to our combinatorial theory. An example with a nonlinear circuit gives the flavor of our approach. The complete proofs and general theory will be discussed in a further paper.",,2001,,,,,,,,,,,,,,,,,,,,
Journal Article,"Martinelli F,Mori P",,On usage control for GRID systems,Future Generation Computer Systems,2010,26,7,1032-1042,,,,,2010,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X09001848;http://dx.doi.org/10.1016/j.future.2009.12.005,10.1016/j.future.2009.12.005,"This paper introduces a formal model, an architecture and a prototype implementation for usage control on GRID systems. The usage control model (UCON) is a new access control paradigm proposed by Park and Sandhu that encompasses and extends several existing models (e.g. MAC, DAC, Bell-Lapadula, RBAC, etc.). Its main novelty is based on continuity of the access monitoring and mutability of attributes of subjects and objects. We identified this model as a perfect candidate for managing access/usage control in GRID systems due to their peculiarities, where continuity of control is a central issue. Here we adapt the original UCON model to develop a full model for usage control in GRID systems. We use as policy specification language a process description language and show how this is suitable to model the usage policy models of the original UCON model. We also describe a possible architecture to implement the usage control model. Moreover, we describe a prototype implementation for usage control of GRID computational services, and we show how our language can be used to define a security policy that regulates the usage of network communications to protect the local computational service from the applications that are executed on behalf of remote GRID users.","Access/usage control, Security policies, Grid security, Distributed systems security",,,,,,,,,,,,,,,,,,,,,
Journal Article,E. Altenkrüger D,,A mathematical data/knowledge model: The formal association inference model FAIM,Mathematical Modelling,1987,8,,98-101,,,,,1987,,0270-0255,https://www.sciencedirect.com/science/article/pii/0270025587905495;http://dx.doi.org/10.1016/0270-0255(87)90549-5,10.1016/0270-0255(87)90549-5,"Data base (DB) technology is a large field, comprising DB design methods, DB theory, DB models, DB management, and DB applications. In recent years, formally defined DB models have become an important topic. In knowledge representation, being the Artificial Intelligence area most closely related to DB research, the general trend moves towards the standard description of models by predicate logic. For DB design, an architecture on 3 abstraction levels is a widely accepted standard. It distinguishes between the conceptual level, the internal level, and the external level. On the conceptual level the problem relevant aspects are exclusively considered, whereas on the internal level the physical aspects (implementation details), and on the external level specific applications are treated. Each level has its respective schemas. In this paper we focus on already designed FAIM conceptual schemas (a design method is available): A mathematical model is developed for them. Each FAIM conceptual schema consists of association types (FAIM) with action types thereon (insert/retrieve/modify/delete) and inference typēs̄ (FAIM), all of which are formally defined (FAIM) by first order logic with equality. Associations, actions, and inferences are instances of association, action, and inference types. Associations are modelled relations among modelled living beings, things (so-called individuals), or abstract concepts (so-called designators). An object (individual or designator) must be modelled as an individual if either its name may be subject to change, or if its name is a compound name. Objects play so-called roles within associations. Actions are modelled events, inferences modelled rules. The use of predicate logic leads to particularly exact, unambiguous, and expressive definitions. Nevertheless only few models have been rigorously defined for conceptual schemas. Within the scope of further developments FAIM is going to be a model of knowledge representation schemas.","data base management systems, 3-level architecture, conceptual data models, knowledge representation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Liang GR,Hong HM",,"Hierarchy transformation method for repetitive manufacturing system specification, design, verification and implementation",Computer Integrated Manufacturing Systems,1994,7,3,191-205,,,,,1994,,0951-5240,https://www.sciencedirect.com/science/article/pii/0951524094900388;http://dx.doi.org/10.1016/0951-5240(94)90038-8,10.1016/0951-5240(94)90038-8,"The hierarchy transformation method consists of a series of transformations through functional, controllable, dynamic, commanding hierarchies for CIM implementation. Here a functional hierarchy is initially constructed from a manufacturing system specification. Then a controllable hierarchy at the design stage is constructed after the functional hierarchy. Subsequently, a dynamic hierarchy and a commanding hierarchy are constructed through transformations at the verification and implementation stages, respectively. After invariant analysis at the verification stage, the controlled objects at the implementation stage are generated by computation. After deadlock analysis, their behaviours are monitored and predicted by verified rules. This provides not only a systematic method, but also a formal approach for CIM implementation.","repetitive manufacturing system, hierarchy transformation method, rule-based expert system",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Machno A,Jannin P,Dameron O,Korb W,Scheuermann G,Meixensberger J",,Ontology for assessment studies of human–computer-interaction in surgery,Artificial Intelligence in Medicine,2015,63,2,73-84,,,,,2015,,0933-3657,https://www.sciencedirect.com/science/article/pii/S0933365714001493;http://dx.doi.org/10.1016/j.artmed.2014.12.011,10.1016/j.artmed.2014.12.011,"Objective New technologies improve modern medicine, but may result in unwanted consequences. Some occur due to inadequate human–computer-interactions (HCI). To assess these consequences, an investigation model was developed to facilitate the planning, implementation and documentation of studies for HCI in surgery. Methods and material The investigation model was formalized in Unified Modeling Language and implemented as an ontology. Four different top-level ontologies were compared: Object-Centered High-level Reference, Basic Formal Ontology, General Formal Ontology (GFO) and Descriptive Ontology for Linguistic and Cognitive Engineering, according to the three major requirements of the investigation model: the domain-specific view, the experimental scenario and the representation of fundamental relations. Furthermore, this article emphasizes the distinction of “information model” and “model of meaning” and shows the advantages of implementing the model in an ontology rather than in a database. Results The results of the comparison show that GFO fits the defined requirements adequately: the domain-specific view and the fundamental relations can be implemented directly, only the representation of the experimental scenario requires minor extensions. The other candidates require wide-ranging extensions, concerning at least one of the major implementation requirements. Therefore, the GFO was selected to realize an appropriate implementation of the developed investigation model. The ensuing development considered the concrete implementation of further model aspects and entities: sub-domains, space and time, processes, properties, relations and functions. Conclusions The investigation model and its ontological implementation provide a modular guideline for study planning, implementation and documentation within the area of HCI research in surgery. This guideline helps to navigate through the whole study process in the form of a kind of standard or good clinical practice, based on the involved foundational frameworks. Furthermore, it allows to acquire the structured description of the applied assessment methods within a certain surgical domain and to consider this information for own study design or to perform a comparison of different studies. The investigation model and the corresponding ontology can be used further to create new knowledge bases of HCI assessment in surgery.","Human–computer-interaction, Automation consequences, Ontology, Surgery",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Carpineto C,Romano G",,GALOIS : An order-theoretic approach to conceptual clustering,,1993,,,33-40,,Morgan Kaufmann,San Francisco (CA),Machine Learning Proceedings 1993,1993,9781558603073,,https://www.sciencedirect.com/science/article/pii/B9781558603073500113;http://dx.doi.org/10.1016/B978-1-55860-307-3.50011-3,10.1016/B978-1-55860-307-3.50011-3,"The theory of concept (or Galois) lattices provides a natural and formal setting in which to discover and represent concept hierarchies. In this paper we present a system, GALOIS, which is able to determine the concept lattice corresponding to a given set of objects. GALOIS is incremental and relatively efficient, the time complexity of each update ranging from O(n) to O(n2) where n is the number of concepts in the lattice. Unlike most approaches to conceptual clustering, GALOIS represents and updates all possible classes in a restricted concept space. Therefore the concept hierarchies it finds are always justified and are not sensitive to object ordering. We experimentally demonstrate, using several machine learning data sets, that GALOIS can be successfully used for class discovery and class prediction. We also point out applications of GALOIS in fields related to machine learning (i.e., information retrieval and databases).",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Cook MV,Cook MV,Chapter 10 - Flying and Handling Qualities,,2007,,,240-273,Second Edition,Butterworth-Heinemann,Oxford,Flight Dynamic Principles (Second Edition),2007,9780750669276,,https://www.sciencedirect.com/science/article/pii/B9780750669276500131;http://dx.doi.org/10.1016/B978-075066927-6/50013-1,10.1016/B978-075066927-6/50013-1,"Publisher Summary This chapter explores the flying and handling qualities of an aeroplane. These qualities are those properties that govern the ease and precision with which the aeroplane responds to pilot commands in the execution of the flight task. Although these rather intangible properties are described qualitatively and are formulated in terms of pilot opinion, it becomes necessary to find alternative quantitative descriptions for more formal analytical purposes. The flying and handling qualities of an aeroplane are, in part, intimately dependent on its stability and control characteristics. This includes the effects of a flight control system when one is installed. The stability and control parameters of an aeroplane are commonly used as indicators and measures of the flying and handling qualities. So, the object of the chapter is to introduce, at an introductory level, the way in which stability and control parameters are used to quantify the flying and handling qualities of an aeroplane. Various examples have been explained throughout the text for better illustration of the subject. The chapter classifies the aeroplane and defines its flight phase. It emphasizes on the importance of the design of an aeroplane and thus a designer designs to achieve the highest level of flying qualities whereas, an evaluator confirms that this gets accomplished.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Cooper MC,,Accelerated analysis of occlusion,Image and Vision Computing,1988,6,1,3-12,,,,,1988,,0262-8856,https://www.sciencedirect.com/science/article/pii/026288568890039X;http://dx.doi.org/10.1016/0262-8856(88)90039-X,10.1016/0262-8856(88)90039-X,"Instead of relying on heuristics for the automatic analysis of occlusion, this paper introduces provably correct algorithms for simple classes of synthetic pictures. This work is an initial part of research towards efficient picture analysing algorithms that have the same rigour as, for example, parsing algorithms for formal languages. Systematic analysis of a synthetic picture composed of known object images involves a search tree, pruning of which is shown to substantially accelerate the search for feasible interpretations. Quantitative experimental results are reported for noise-free and noisy synthetic pictures.","image analysis, occlusion, ambiguity, tree pruning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Patnaik S,Immerman N",,"Dyn-FO: A Parallel, Dynamic Complexity Class",Journal of Computer and System Sciences,1997,55,2,199-209,,,,,1997,,0022-0000,https://www.sciencedirect.com/science/article/pii/S0022000097915208;http://dx.doi.org/10.1006/jcss.1997.1520,10.1006/jcss.1997.1520,"Traditionally, computational complexity has considered only static problems. Classical complexity classes such as NC, P, and NP are defined in terms of the complexity of checking—upon presentation of an entire input—whether the input satisfies a certain property. For many applications of computers it is more appropriate to model the process as a dynamic one. There is a fairly large object being worked on over a period of time. The object is repeatedly modified by users and computations are performed. We develop a theory of dynamic complexity. We study the new complexity class, dynamic first-order logic (Dyn-FO). This is the set of properties that can be maintained and queried in first-order logic, i.e., relational calculus, on a relational database. We show that many interesting properties are in Dyn-FO, including multiplication, graph connectivity, bipartiteness, and the computation of minimum spanning trees. Note that none of these problems is in static FO, and this fact has been used to justify increasing the power of query languages beyond first-order. It is thus striking that these problems are indeed dynamic first-order and, thus, were computable in first-order database languages all along. We also define “bounded-expansion reductions” which honor dynamic complexity classes. We prove that certain standard complete problems for static complexity classes, such as REACHafor P, remain complete via these new reductions. On the other hand, we prove that other such problems, including REACH for NL and REACHdfor L, are no longer complete via bounded-expansion reductions. Furthermore, we show that a version of REACHa, called REACHa+, is not in Dyn-FO unless all of P is contained in parallel linear time.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Sills A,Ahmed M,Dotthatcom.com,Boumphrey F,Ortiz J","Sills A,Ahmed M,Dotthatcom.com,Boumphrey F,Ortiz J",Chapter 1 - Introducing the Microsoft .NET Framework,,2002,,,1-53,,Syngress,Rockland,XML .NET Developer's Guide,2002,9781928994473,,https://www.sciencedirect.com/science/article/pii/B9781928994473500044;http://dx.doi.org/10.1016/B978-192899447-3/50004-4,10.1016/B978-192899447-3/50004-4,"Publisher Summary This chapter explores how .NET works internally. With the introduction of the .NET architecture, Microsoft presents a solution that provides a solid base for distributed applications. Visual Studio .NET is the first real .NET application that will see daylight. To leverage the communication of distributed .NET applications, the .NET architecture makes heavy use of XML. The Framework includes abstract base classes to inherit from, as well as implementations of these classes to use. All the classes are derived from the system object that gives great power and flexibility. All applications will share a common runtime environment called the Common Language Runtime (CLR). The .NET Framework now includes a Common Type System (CTS) that allows all the languages to share data using the same types. These features facilitate cross-language interoperability. The .Net platform is a great leap forward in the evolution of computing from PCs connected to servers through networks such as the Internet, to one where all manner of smart devices, computers, and services work together to provide a richer user experience.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Krajewski S,,Gödel on Tarski,Annals of Pure and Applied Logic,2004,127,1,303-323,,,,,2004,,0168-0072,https://www.sciencedirect.com/science/article/pii/S0168007203001271;http://dx.doi.org/10.1016/j.apal.2003.11.019,10.1016/j.apal.2003.11.019,"Contacts of the two logicians are listed, and all Gödel's written mentions of Tarski's work are quoted. Why did Gödel almost never mention Tarski's definition of truth in his notes and papers? This puzzle of Gödel's silence, proposed by Feferman, is not merely biographical or psychological but has interesting connections to Gödel's philosophical views. No satisfactory answer is given by the three “standard” explanations: (i) no need to repeat the work already done; (ii) Tarski's achievement was obvious to Gödel; (iii) Gödel's exceptional caution. In fact, (i), Tarski had done the work, but Gödel almost never mentioned the achievement; (ii), the obviousness is no explanation for the omission of Tarski's work in contexts in which an application of the definition of satisfaction was useful, and even necessary; (iii), the point was not just caution: if Gödel had felt the need to mention the program of scientific semantics he could easily have done that in his manuscripts, or in conversations. Three ideas, detectable in Gödel's approach, can help us understand Gödel's silence: (A) the idea of truth as the intuitive provability in the most general sense; defining it set-theoretically would contribute nothing. (B) the idea of truth as an inexhaustible idea in the sense of Kant; “truth in general” is a category that must be applicable to all kinds of sentential expressions; also, while for Gödel language was secondary, Tarski's definition is focused on language. (C) the idea of logic as the universal language, in Hintikka's sense, as opposed to the perception of logic as a reinterpretable calculus; hence the thesis that semantics is inexpressible. Gödel always remains a Platonist who asks a natural question: what does really happen in the realm of abstract objects?","Gödel, Tarski, Truth, Truth definition, Logic, Semantics, Platonism","Provinces of logic determined. Essays in the memory of Alfred Tarski. Parts IV, V and VI",,,,,,,,,,,,,,,,,,,,
Journal Article,"Šaša A,Krisper M",,Enterprise architecture patterns for business process support analysis,Journal of Systems and Software,2011,84,9,1480-1506,,,,,2011,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121211000689;http://dx.doi.org/10.1016/j.jss.2011.02.043,10.1016/j.jss.2011.02.043,"The field of enterprise architectures lacks architecture patterns that would support analysis of a given enterprise architecture, comparison of different enterprise architecture solutions and provide guidelines for development of a target enterprise architecture based on the analysis of existing enterprise architecture. In this paper, we focus on business process support analysis using information derived from enterprise architecture description. We give a systematic overview of important aspects. We establish and formally define foundational enterprise architecture patterns for business process support analysis. They are implementation independent and enable more efficient qualitative architecture analysis of business process support, which is the basis for achieving more optimal business operation. We have defined the patterns using the standard enterprise architecture language – ArchiMate. They are formalized in a way that enables their implementation in enterprise architecture tools. This is an important characteristic that allows for efficient work by automatic detection of different, more or less suitable, architecture structures. We have derived the patterns based on real-world enterprise architecture descriptions and have used and verified them in enterprise architecture analysis and planning projects for four large organizations. The enterprise architecture analysis patterns address an important research issue in the field of enterprise architectures that has so far not been systematically researched.","Enterprise architecture, Enterprise architecture pattern, Business process support analysis, Business process, Business object",Selected papers from the 2009 Joint Working IEEE/IFIP Conference on Software Architecture & European Conference on Software Architecture (WICSA/ECSA 2009),,,,,,,,,,,,,,,,,,,,
Journal Article,"Wakeman I,Jeffrey A,Owen T,Pepper D",,SafetyNet: A language-based approach to programmable networks,Computer Networks,2001,36,1,101-114,,,,,2001,,1389-1286,https://www.sciencedirect.com/science/article/pii/S1389128601001542;http://dx.doi.org/10.1016/S1389-1286(01)00154-2,10.1016/S1389-1286(01)00154-2,"It appears that some degree of programmability is inevitable within the network, whether it be through active networks, active services, or programmable middleware. We argue that programming network elements with languages designed for use within a single machine is inappropriate, since the only defense for the shared resource of the network is through the use of sandboxes, which are prone to performance problems and are difficult to implement correctly. Instead, we believe that new languages should be designed for programmable networks, using type systems that ensure safe programs, and encourage correct programs. We have designed and provided the full semantics for such a language, SafetyNet. Building upon this, we have implemented a compiler, run time environment and a simulation environment for our language. In this paper we describe the major features of the language that protect the network: abstracted locations; located objects; volatile routing; thread and class loading; and enforced resource counting. We show how these features are used in a number of small case studies, and in implementing optimised communication libraries. We describe the implications of the language design for the implementation of the run time support environment. The ease with which these demonstrations have been built and debugged shows the potential for enforcing network programming models with well-typed languages.","Active networks, Strongly typed languages, Programming language design",Active Networks and Services,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Martyr AJ,Plint MA","Martyr AJ,Plint MA","15 - The test department organization, health and safety management, risk assessment correlation of results and design of experiments",,2007,,,308-323,Third Edition,Butterworth-Heinemann,Oxford,Engine Testing (Third Edition),2007,9780750684392,,https://www.sciencedirect.com/science/article/pii/B9780750684392500189;http://dx.doi.org/10.1016/B978-075068439-2/50018-9,10.1016/B978-075068439-2/50018-9,"Publisher Summary This chapter discusses the administrative and technical management tasks and organization of a medium-sized test department, suggesting how the constituent parts should fit together and interact. The chapter also describes the responsibilities imposed by health and safety (H&S) legislation and format for risk assessments is mentioned. Formal responsibility for H&S within a large organization is that of a manager trained to ensure that policies of the company and legal requirements are adhered to by the supervisory organization. Staff involved in carrying out risk assessments need to understand that the object of the exercise is less about describing the risk and more about putting in place realistic actions and procedures in order to eliminate or reduce the potential effects of the hazard. The prime task of technical management is to ensure that the test equipment is used to its optimum efficiency which in many cases is organizationally interpreted as ensuring plant achieves maximum “up-time.” The efficiency of many test facilities is judged by periodic cell up-time or “shaft rotation” figures.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Cheniti Belcadhi L,,Personalized feedback for self assessment in lifelong learning environments based on semantic web,Computers in Human Behavior,2016,55,,562-570,,,,,2016,,0747-5632,https://www.sciencedirect.com/science/article/pii/S0747563215300534;http://dx.doi.org/10.1016/j.chb.2015.07.042,10.1016/j.chb.2015.07.042,"Feedback constitutes an important component of assessment in learning environments, as it allows learners to evaluate their progress in the learning process and helps tutors to personalize learning content according to learners' needs and profiles. In this paper we propose an intelligent personalized feedback framework based on Semantic Web technologies, one that provides personalized feedback for self-assessment and that is appropriate for Lifelong Learning environment. The framework takes into consideration the level of complexity of each question in a self assessment test in order to decide on the type of individual feedback required. This process provides accurate information about the learner's level based on the result of their own participation in the assessment. The framework is based on semantic models for user information and feedback generation that ensure interoperability and reuse of Assessment and learning resources. In our approach, a personalized feedback framework based on web services uses the information contained in the learner's profile to proactively assist them by suggesting personalized feedback and helping them overcome their shortcomings in a particular field of knowledge.","Personalized feedback, Web services, Ontology, Web-based assessment, Lifelong learning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Astala K,Päivärinta L,Reyes JM,Siltanen S",,Nonlinear Fourier analysis for discontinuous conductivities: Computational results,Journal of Computational Physics,2014,276,,74-91,,,,,2014,,0021-9991,https://www.sciencedirect.com/science/article/pii/S0021999114005257;http://dx.doi.org/10.1016/j.jcp.2014.07.032,10.1016/j.jcp.2014.07.032,"Two reconstruction methods of Electrical Impedance Tomography (EIT) are numerically compared for nonsmooth conductivities in the plane based on the use of complex geometrical optics (CGO) solutions to D-bar equations involving the global uniqueness proofs for Calderón problem exposed in Nachman (1996) [43] and Astala and Päivärinta (2006) [6]: the Astala–Päivärinta theory-based low-pass transport matrix method implemented in Astala et al. (2011) [3] and the shortcut method which considers ingredients of both theories. The latter method is formally similar to the Nachman theory-based regularized EIT reconstruction algorithm studied in Knudsen et al. (2009) [34] and several references from there. New numerical results are presented using parallel computation with size parameters larger than ever, leading mainly to two conclusions as follows. First, both methods can approximate piecewise constant conductivities better and better as the cutoff frequency increases, and there seems to be a Gibbs-like phenomenon producing ringing artifacts. Second, the transport matrix method loses accuracy away from a (freely chosen) pivot point located outside of the object to be studied, whereas the shortcut method produces reconstructions with more uniform quality.","Inverse problem, Beltrami equation, Conductivity equation, Inverse conductivity problem, Complex geometrical optics solution, Nonlinear Fourier transform, Scattering transform, Electrical impedance tomography",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Scheirer WJ,Wilber MJ,Eckmann M,Boult TE",,Good recognition is non-metric,Pattern Recognition,2014,47,8,2721-2731,,,,,2014,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320314000703;http://dx.doi.org/10.1016/j.patcog.2014.02.018,10.1016/j.patcog.2014.02.018,"Recognition is the fundamental task of visual cognition, yet how to formalize the general recognition problem for computer vision remains an open issue. The problem is sometimes reduced to the simplest case of recognizing matching pairs, often structured to allow for metric constraints. However, visual recognition is broader than just pair-matching: what we learn and how we learn it has important implications for effective algorithms. In this review paper, we reconsider the assumption of recognition as a pair-matching test, and introduce a new formal definition that captures the broader context of the problem. Through a meta-analysis and an experimental assessment of the top algorithms on popular data sets, we gain a sense of how often metric properties are violated by recognition algorithms. By studying these violations, useful insights come to light: we make the case for local distances and systems that leverage outside information to solve the general recognition problem.","Machine learning, Metric learning, Recognition, Computer vision, Face recognition, Object recognition",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Boyer RS,Moore SJ","Rich C,Waters RC",PROOF CHECKING THE RSA PUBLIC KEY ENCRYPTION ALGORITHM11The research reported here was supported by National Science Foundation Grant MCS-8202943 and Office of Naval Research Contract N00014-81-K-0634,,1986,,,87-95,,Morgan Kaufmann,,Readings in Artificial Intelligence and Software Engineering,1986,9780934613125,,https://www.sciencedirect.com/science/article/pii/B9780934613125500100;http://dx.doi.org/10.1016/B978-0-934613-12-5.50010-0,10.1016/B978-0-934613-12-5.50010-0,"Publisher Summary This chapter highlights the concept of proof checking the RSA public key encryption algorithm. A formal mathematical proof is a finite sequence of formulas, each element of which is either an axiom or the result of applying one of a fixed set of mechanical rules to the previous formulas in the sequence. It is, thus, possible to write a computer program to check mechanically whether a given sequence is a formal proof. However, formal proofs are rarely used. The theorem-prover deals with a quantifier free first order logic providing equality, recursively defined functions, mathematical induction, and inductively constructed objects such as the natural numbers and finite sequences. The less ambitious motivation behind much automatic theorem-proving research is to mechanize the often mundane and tedious proofs arising in connection with computer programs. The chapter also presents the examples as evidence that proof checking mathematics is not only a theoretical but also a practical possibility.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Xu R,Luo J,Wang M",,Kinematic and dynamic manipulability analysis for free-floating space robots with closed chain constraints,Robotics and Autonomous Systems,2020,130,,103548,,,,,2020,,0921-8890,https://www.sciencedirect.com/science/article/pii/S0921889019309236;http://dx.doi.org/10.1016/j.robot.2020.103548,10.1016/j.robot.2020.103548,"This paper presents the manipulability analysis of free-floating multi-arm space robots. Evaluation of manipulator capability is useful both in the design and in the operation phase. After capturing a target, closed kinematic chains are formed with multi-arm cooperative manipulating a common object. Owing to the dynamic coupling effect, the manipulability analysis of free-floating systems is more complex than that of ground-fixed closed chain systems. To analyze the cooperative manipulability, kinematic and dynamic formulations for the free-floating closed chain systems are firstly derived. The formulations describe the mapping of joint velocities and torques, respectively, to task velocities and forces, as well as joint torques to task accelerations and forces, by using the generalized Jacobian matrices. Next, the well-known concepts of manipulability ellipsoid, manipulability measure and task compatibility of the free-floating closed chain system are formally extended. Besides, a new approach called scaling factor method is used in the analysis of the task compatibility, which is more accurate compared with the manipulability ellipsoid method. Three applications of the performance indices are considered: (1) the feasibility analysis for a given task, (2) the trajectory planing giving a desired task path, and (3) configuration optimization with different task requirements. The proposed index is proved a very efficient tool that can be utilized in the cooperative manipulation tasks for free-floating space robotic systems.","Cooperative manipulation, Free-floating, Multi-arm space robot, Closed chain system, Manipulability analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Stapleton G,Delaney A",,Evaluating and generalizing constraint diagrams,Journal of Visual Languages & Computing,2008,19,4,499-521,,,,,2008,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X08000177;http://dx.doi.org/10.1016/j.jvlc.2008.04.003,10.1016/j.jvlc.2008.04.003,"The constraint diagram language was designed to be used in conjunction with the unified modelling language (UML), primarily for placing formal constraints on software models. In particular, constraint diagrams play a similar role to the textual object constraint language (OCL) in that they can be used for specifying system invariants and operation contracts in the context of a UML model. Unlike the OCL, however, constraint diagrams can be used independently of the UML. In this paper, we illustrate a range of intuitive and counter-intuitive features of constraint diagrams and highlight some (potential) expressiveness limitations. The counter-intuitive features are related to how the individual pieces of syntax interact. A generalized version of the constraint diagram language that overcomes the illustrated counter-intuitive features and limitations is proposed. In order to discourage specification readers and writers from overlooking certain semantic information, the generalized notation allows this information to be expressed more explicitly than in the non-generalized case. The design of the generalized notation takes into account five language design principles which are discussed in the paper. We provide a formalization of the syntax and semantics for generalized constraint diagrams. Moreover, we establish a lower bound on the expressiveness of the generalized notation and show that they are at least as expressive as constraint diagrams.","Constraint diagrams, Precise software specification, Diagrammatic specification, Expressiveness",Selected Papers from IEEE Symposium on Visual Languages and Human Centric Computing 2007 (VL/HCC 2007),,,,,,,,,,,,,,,,,,,,
Journal Article,"Cho I,Lee K,Choi W,Song YA",,Development of a new sheet deposition type rapid prototyping system,International Journal of Machine Tools and Manufacture,2000,40,12,1813-1829,,,,,2000,,0890-6955,https://www.sciencedirect.com/science/article/pii/S0890695599000863;http://dx.doi.org/10.1016/S0890-6955(99)00086-3,10.1016/S0890-6955(99)00086-3,"Sheet deposition type rapid prototyping systems have many advantages: high build speed, low operating cost, large part size, no phase change, no need for support generation, etc. However, those sheet deposition type rapid prototyping systems generally require an additional post-processing step to remove excessive material. This post-processing step is generally time-consuming and labor-intensive as well. Especially, in case of parts with hollow cores and internal cavities, the removal of excessive materials can be an extremely demanding task. A new sheet deposition type rapid prototyping system that can minimize the post-processing is proposed. In the proposed system, the sheet is cut in two steps: the first before the shielding paper is peeled off and the second after peeling-off. The excessive area is removed during the peeling-off process after the first cutting. In this way, this system can reduce the post-processing time and cost as well as the limitation on the feasible geometric shapes compared to the conventional sheet deposition type systems.","Rapid prototyping, Sheet deposition, Decubing, Laminated object manufacturing (LOM)",,,,,,,,,,,,,,,,,,,,,
Journal Article,Stoughton A,,An Operational Semantics Framework Supporting the Incremental Construction of Derivation Trees,Electronic Notes in Theoretical Computer Science,1998,10,,122-133,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105806930;http://dx.doi.org/10.1016/S1571-0661(05)80693-0,10.1016/S1571-0661(05)80693-0,"We describe the current state of the design and implementation of Dops, a framework for Deterministic OPerational Semantics that will support the incremental construction of derivation trees, starting from term/input pairs. This process of derivation tree expansion may terminate with either a complete derivation tree, explaining why a term/input pair evaluates to a particular output, or with a blocked incomplete derivation tree, explaining why a term/input pair fails to evaluate to an output; or the process may go on forever, yielding, in the limit, an infinite incomplete derivation tree, explaining why a term/input pair fails to evaluate to an output. The Dops metalanguage is a typed lambda calculus in which all expressions converge. Semantic rules are specified by lambda terms involving resumptions, which are used by a rule to consume the outputs of sub-evaluations and then resume the rule's work. A rule's type describes the number and kinds of sub-evaluations that the rule can initiate, and indicates whether the rule can block. The semantics of Dops is defined in an object language-independent manner as a small-step semantics on concrete derivation trees: trees involving resumptions. These concrete derivation trees can then be abstracted into ordinary derivation trees by forgetting the resumptions.",,"HOOTS II, Second Workshop on Higher-Order Operational Techniques in Semantics",,,,,,,,,,,,,,,,,,,,
Journal Article,"Snášel V,Nowaková J,Xhafa F,Barolli L",,Geometrical and topological approaches to Big Data,Future Generation Computer Systems,2017,67,,286-296,,,,,2017,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X16301856;http://dx.doi.org/10.1016/j.future.2016.06.005,10.1016/j.future.2016.06.005,"Modern data science uses topological methods to find the structural features of data sets before further supervised or unsupervised analysis. Geometry and topology are very natural tools for analysing massive amounts of data since geometry can be regarded as the study of distance functions. Mathematical formalism, which has been developed for incorporating geometric and topological techniques, deals with point cloud data sets, i.e. finite sets of points. It then adapts tools from the various branches of geometry and topology for the study of point cloud data sets. The point clouds are finite samples taken from a geometric object, perhaps with noise. Topology provides a formal language for qualitative mathematics, whereas geometry is mainly quantitative. Thus, in topology, we study the relationships of proximity or nearness, without using distances. A map between topological spaces is called continuous if it preserves the nearness structures. Geometrical and topological methods are tools allowing us to analyse highly complex data. These methods create a summary or compressed representation of all of the data features to help to rapidly uncover particular patterns and relationships in data. The idea of constructing summaries of entire domains of attributes involves understanding the relationship between topological and geometric objects constructed from data using various features. A common thread in various approaches for noise removal, model reduction, feasibility reconstruction, and blind source separation, is to replace the original data with a lower dimensional approximate representation obtained via a matrix or multi-directional array factorization or decomposition. Besides those transformations, a significant challenge of feature summarization or subset selection methods for Big Data will be considered by focusing on scalable feature selection. Lower dimensional approximate representation is used for Big Data visualization. The cross-field between topology and Big Data will bring huge opportunities, as well as challenges, to Big Data communities. This survey aims at bringing together state-of-the-art research results on geometrical and topological methods for Big Data.","Big Data, Industry 4.0, Topological data analysis, Persistent homology, Dimensionality reduction, Big Data visualization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Adem A,Karagueuzian DB,Mináč J",,On the Cohomology of Galois Groups Determined by Witt Rings,Advances in Mathematics,1999,148,1,105-160,,,,,1999,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870899918479;http://dx.doi.org/10.1006/aima.1999.1847,10.1006/aima.1999.1847,"Let F denote a field of characteristic different from two. In this paper we describe the mod2 cohomology of a Galois group GF (called the W-group of F) which is known to essentially characterize the Witt ring WF of anisotropic quadratic modules over F. We show that H*(GF, F2) contains the mod2 Galois cohomology of F and that its structure will reflect important properties of the field. We construct a space XF endowed with an action of an elementary abelian group E such that the computation of the cohomology of GF reduces to calculating the equivariant cohomology H*E(XF, F2). For the case of a field which is not formally real this amounts to computing the cohomology of an explicit Euclidean space form, an object which is interesting in its own right. We provide a number of examples and a substantial combinatorial computation for the cohomology of the universal W-groups.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Joseph M,Goswami A",,Formal description of realtime systems: a review,Information and Software Technology,1989,31,2,67-76,,,,,1989,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584989900852;http://dx.doi.org/10.1016/0950-5849(89)90085-2,10.1016/0950-5849(89)90085-2,"Work on the formal description and analysis of realtime systems has followed two paths. On one side, it has considered the specification of realtime systems, the design of language constructs for realtime programming, and semantic models to describe the properties of realtime programs. On the other side, there has been a large body of work analysing the performance of realtime systems in terms of scheduling theory, relating program modules with their use of resources, and determining timing characteristics, especially in relation to hard realtime problems. The paper reviews some of this work and examines how realtime computations are modelled in a proof-theoretic framework and in scheduling analyses. The object of this review, and indeed of other contemporary work in the field, is to examine whether it is possible to relate issues of correctness and performance, e.g., interpreting the semantics of execution of realtime programs in terms of scheduling solutions to realtime problems.","realtime systems, realtime programs, specification, requirements, scheduling, semantics, correctness, performance",,,,,,,,,,,,,,,,,,,,,
Book Chapter,McCarthy JC,Halpern JY,MENTAL SITUATION CALCULUS,,1986,,,307,,Morgan Kaufmann,,Theoretical Aspects of Reasoning About Knowledge,1986,9780934613040,,https://www.sciencedirect.com/science/article/pii/B9780934613040500259;http://dx.doi.org/10.1016/B978-0-934613-04-0.50025-9,10.1016/B978-0-934613-04-0.50025-9,"ABSTRACT The situation calculus of (McCarthy and Hayes 1969)1 has mainly been used to reason about states of the physical world, taking into account the locations and physical properties of objects and admitting such events as moving them. Analogously we can consider a mental situation calculus (MSC) in which the situations include beliefs, goals, intentions and other mental qualities, and the events include inferring, observing, establishing goals and discharging them. MSC has several motivations:1.MSC involves reifying beliefs, and one of its basic forms will be believes (, ss) standing for the assertion that the proposition is believed in mental situation ss. The formalism allows for belief not to be closed under inference. In fact one of the possible mental actions is to make an inference. Therefore, we can describe in detail the circumstances under which we want our system to make inferences.2.Non-monotonic reasoning requires closer control over inference than deduction, because of its tentative character. Some problems that have recently arisen with blocks world axiomatizations may require that circumscription be controlled in accordance with the pedigree of the system's objective beliefs and not merely being determined by what the beliefs are.3.It looks like several useful methods of control of reasoning can be accomplished by hill-climbing in mental situation space.Besides reifying beliefs, MSC involves reifying goals and partial plans for achieving them. Depending on progress the paper to be presented will include both general discussion of MSC and specific formalizations.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Backes M,Pfitzmann B,Waidner M",,The reactive simulatability (RSIM) framework for asynchronous systems,Information and Computation,2007,205,12,1685-1720,,,,,2007,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540107000648;http://dx.doi.org/10.1016/j.ic.2007.05.002,10.1016/j.ic.2007.05.002,"We define reactive simulatability for general asynchronous systems. Roughly, simulatability means that a real system implements an ideal system (specification) in a way that preserves security in a general cryptographic sense. Reactive means that the system can interact with its users multiple times, e.g., in many concurrent protocol runs or a multi-round game. In terms of distributed systems, reactive simulatability is a type of refinement that preserves particularly strong properties, in particular confidentiality. A core feature of reactive simulatability is composability, i.e., the real system can be plugged in instead of the ideal system within arbitrary larger systems; this is shown in follow-up papers, and so is the preservation of many classes of individual security properties from the ideal to the real systems. A large part of this paper defines a suitable system model. It is based on probabilistic IO automata (PIOA) with two main new features: One is generic distributed scheduling. Important special cases are realistic adversarial scheduling, procedure-call-type scheduling among colocated system parts, and special schedulers such as for fairness, also in combinations. The other is the definition of the reactive runtime via a realization by Turing machines such that notions like polynomial-time are composable. The simple complexity of the transition functions of the automata is not composable. As specializations of this model we define security-specific concepts, in particular a separation between honest users and adversaries and several trust models. The benefit of IO automata as the main model, instead of only interactive Turing machines as usual in cryptographic multi-party computation, is that many cryptographic systems can be specified with an ideal system consisting of only one simple, deterministic IO automaton without any cryptographic objects, as many follow-up papers show. This enables the use of classic formal methods and automatic proof tools for proving larger distributed protocols and systems that use these cryptographic systems.","Security, Cryptography, Simulatability, Formal methods, Reactive systems, Composability, Probabilistic IO automata, Distributed polynomial time",,,,,,,,,,,,,,,,,,,,,
Journal Article,Harnad S,,The symbol grounding problem,Physica D: Nonlinear Phenomena,1990,42,1,335-346,,,,,1990,,0167-2789,https://www.sciencedirect.com/science/article/pii/0167278990900876;http://dx.doi.org/10.1016/0167-2789(90)90087-6,10.1016/0167-2789(90)90087-6,"There has been much discussion recently about the scope and limits of purely symbolic models of the mind and about the proper role of connectionism in cognitive modeling. This paper describes the “symbol grounding problem”: How can the semantic interpretation of a formal symbol system be made intrinsic to the system, rather than just parasitic on the meanings in our heads? How can the meanings of the meaningless symbol tokens, manipulated solely on the basis of their (arbitrary) shapes, be grounded in anything but other meaningless symbols? The problem is analogous to trying to learn Chinese from a Chinese/Chinese dictionary alone. A candidate solution is sketched: Symbolic representations must be grounded bottom-up in nonsymbolic representations of two kinds: (1) iconic representations, which are analogs of the proximal sensory projections of distal objects and events, and (2) categorical representations, which are learned and innate feature detectors that pick out the invariant features of object and event categories from their sensory projections. Elementary symbols are the names of these object and event categories, assigned on the basis of their (nonsymbolic) categorical representations. Higher-order (3) symbolic representations, grounded in these elementary symbols, consist of symbol strings describing category membership relations (e.g. “An X is a Y that is Z”). Connectionism is one natural candidate for the mechanism that learns the invariant features underlying categorical representations, thereby connecting names to the proximal projections of the distal objects they stand for. In this way connectionism can be seen as a complementary component in a hybrid nonsymbolic/symbolic model of the mind, rather than a rival to purely symbolic modeling. Such a hybrid model would not have an autonomous symbolic “module,” however; the symbolic functions would emerge as an intrinsically “dedicated” symbol system as a consequence of the bottom-up grounding of categories' names in their sensory representations. Symbol manipulation would be governed not just by the arbitrary shapes of the symbol tokens, but by the nonarbitrary shapes of the icons and category invariants in which they are grounded.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"La Torre S,Murano A,Napoli M",,Weak Muller acceptance conditions for tree automata,Theoretical Computer Science,2005,332,1,233-250,,,,,2005,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397504007194;http://dx.doi.org/10.1016/j.tcs.2004.10.027,10.1016/j.tcs.2004.10.027,"Over the last decades the theory of automata on infinite objects has been an important source of tools for the specification and the verification of computer programs. Trees are more suitable than words to model nondeterminism and concurrency. In the literature, there are several examples of acceptance conditions that have been proposed for automata on infinite words and then have been fruitfully extended to infinite trees. The type of acceptance condition can influence both the succinctness of the language acceptors and the computational complexity of the decision problems. Here we consider, relatively to automata on infinite trees, two acceptance conditions that are obtained by a relaxation of the Muller acceptance condition: the Landweber and the Muller-Superset conditions. We prove that Muller-Superset tree automata accept the same class of languages as Büchi tree automata. Also, we show that for such languages the minimal Muller-Superset acceptor is at least as succinct as the minimal Büchi acceptor and, in some cases, it can be exponentially more succinct. Landweber tree automata, instead, define a class of languages that is not comparable with that defined by Büchi tree automata. The main result we prove is that the emptiness problem for this class of automata is decidable in polynomial time, and thus we extend the class of automata with a tractable emptiness problem.","Tree automata, Formal languages",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kulpa Z,,"On the properties of discrete circles, rings, and disks",Computer Graphics and Image Processing,1979,10,4,348-365,,,,,1979,,0146-664X,https://www.sciencedirect.com/science/article/pii/S0146664X7980043X;http://dx.doi.org/10.1016/S0146-664X(79)80043-X,10.1016/S0146-664X(79)80043-X,"This paper is about formal properties of discrete circles (defined as Freeman digitizations of circles with integer radius and center coordinates), discrete disks (defined as discrete circles with filled-in interiors), and discrete rings (defined as differences between consecutive discrete disks). Such objects are important in applications involving distance transforms and propagation methods. Several properties of these objects are derived, namely, conditions for occurrence of certain point configurations, formulas for the number of raster points in these objects, and their perimeters and areas. These parameters are also related to corresponding properties of ideal (nondiscrete) circles, and some limit theorems (for radius approaching infinity) are stated.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hong ZW,Lin JM,Jiau HC,Fang GM,Chiou CW",,Encapsulating windows-based software applications into reusable components with design patterns,Information and Software Technology,2006,48,7,619-629,,,,,2006,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584905000996;http://dx.doi.org/10.1016/j.infsof.2005.06.005,10.1016/j.infsof.2005.06.005,"Reusing software by integrating Commercial Off-The-Shelf (COTS) applications into a software system is maturing in practice. Our previous work [1] presented a component wrapping approach to convert Windows-based COTS applications into CORBA objects. A formal and generalized representation of the conversion process for a Windows-based COTS application into a reusable software component would be useful and desirable for applying such software reuse to COTS-based system development. This study addresses a pattern-based representation of our experience. The patterns in this study offer clear documentation and sufficient information for a software developer to develop a COTS-based software system rapidly. An example system, Graphic Mechanical Part Management System (GMPMS) assembling two COTS applications under MS-DOS and MS-Windows 2000/XP, respectively, is also developed in this study to reveal how the patterns are utilized.","Software reuse, COTS-based system (CBS), Design patterns, Graphic mechanical part management system (GMPMS)",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Li K,D’Andrea R",,Motion design and learning of autonomous robots based on primitives and heuristic cost-to-go,Robotics and Autonomous Systems,2008,56,8,658-669,,,,,2008,,0921-8890,https://www.sciencedirect.com/science/article/pii/S092188900700173X;http://dx.doi.org/10.1016/j.robot.2007.11.006,10.1016/j.robot.2007.11.006,"The task of trajectory design of autonomous vehicles is typically two-fold. First, it needs to take into account the intrinsic dynamics of the vehicle, which are sometimes termed local constraints. Second, on a higher level, the designed trajectories must allow the vehicle to achieve some application-specific task. The specification of the task results in the so-called global constraints. Both of these two components of trajectory design are generally nontrivial problems, and very often, they are pursued as two parallel areas. When the results drawn from the two areas are applied in conjunction, the synthesis is usually somewhat arbitrary. In this paper, we assume that some optimal control laws are available as a set of motion primitives to address the vehicle dynamics. The trajectories that achieve the task are determined solely through the primitives and do not reference the vehicle dynamics directly. For the higher level, we translate the task into a very special type of cost-to-go function, which is partially specified artificially and partially determined by an admissibility condition imposed by the set of primitives. The optimality feature of the primitives is formally extended to the final trajectory design. We illustrate this result with the example of a mobile robot retrieving an object, which is an interesting problem of its own right. Both a direct design approach and a learning approach are presented.","Optimal control, Hierarchical design, Path planning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Martí-Oliet N,Meseguer J",,"Rewriting Logic as a Logical and Semantic Framework1 1This paper is a short version of [36], where the reader can find more examples and details not discussed here",Electronic Notes in Theoretical Computer Science,1996,4,,190-225,,,,,1996,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104000404;http://dx.doi.org/10.1016/S1571-0661(04)00040-4,10.1016/S1571-0661(04)00040-4,"Rewriting logic [40] is proposed as a logical framework in which other logics can be represented, and as a semantic framework for the specification of languages and systems. Using concepts from the theory of general logics [39], representations of an object logic L in a framework logic F are understood as mappings L → F that translate one logic into the other in a conservative way. The ease with which such maps can be defined is discussed in detail for the cases of linear logic, logics with quantifiers, and any sequent calculus presentation of a logic for a very general notion of “sequent.” Using the fact that rewriting logic is reflective, it is often possible to reify inside rewriting logic itself a representation map L → RWLogic for the finitely presentable theories of L . Such a reification takes the form of a map between the abstract data types representing the finitary theories of L and of RWLogic. Regarding the different but related use of rewriting logic as a semantic framework, the straightforward way in which very diverse models of concurrency can be expressed and unified within rewriting logic is illustrated with CCS. In addition, the way in which constraint solving fits within the rewriting logic framework is briefly explained.",,"RWLW96, First International Workshop on Rewriting Logic and its Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"Lysak DB,Devaux PM,Kasturi R",,View labeling for automated interpretation of engineering drawings,Pattern Recognition,1995,28,3,393-407,,,,,1995,,0031-3203,https://www.sciencedirect.com/science/article/pii/003132039400103S;http://dx.doi.org/10.1016/0031-3203(94)00103-S,10.1016/0031-3203(94)00103-S,"A method is presented for segmenting engineering drawings into views and identifying the corresponding view points. A set of 2.5D view-based coordinate systems is introduced as an intermediate between the 2D drawing-based system and the 3D object-based coordinates, and a formal technique is developed for constructing transformation matrices between coordinates. The method accommodates auxiliary views in addition to the standard orthogonal set, and the number of views and their positions need not be known a priori. Drawings with moderate errors in line placement and view alignment can also be handled. A rule based approach, using evidential reasoning, is applied for labeling the views.","Engineering drawing interpretation, Document analysis, Segmentation, Labeling 3D interpretation, Evidential reasoning, Rule-based methods",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Pooley R,Wilcox P","Pooley R,Wilcox P",Chapter 7 - Road junction,,2004,,,107-121,,Butterworth-Heinemann,Oxford,Applying UML,2004,9780750656832,,https://www.sciencedirect.com/science/article/pii/B9780750656832500073;http://dx.doi.org/10.1016/B978-075065683-2/50007-3,10.1016/B978-075065683-2/50007-3,"Publisher Summary This chapter presents a case study of a traffic light control system. The chapter addresses a real-time engineering level problem, where synchronization and timing are significant aspects of the requirements. The case study examines the details of states, interactions and system testing. In addition to the core unified modeling language (UML) features, concepts and elements introduced in the proposal for a “profile for schedulability, performance, and time” are used. The development of a set of components from which the traffic light system can be constructed with the help of a class diagram is described. The chapter provides a brief summary of the aspects of the profile used in the case study, especially RTtimer and RTtimeout. It shows how the formal definition of the key elements is built up using the UML extension mechanisms. The key features of Timer are its duration, which determines the period after which it sends a Timeout and the isPeriodic flag, which makes it send repeatedly each time the duration elapses. A sequence diagram shows how the objects and actors need to interact to allow the “junction” to function. A possible statechart for a TrafficLight is presented to show the internal behavior of a system's components. To see an overall view of this behavior, the collaboration diagram (external view) and the statechart (internal view) can be combined, which gives a full model. Combined statechart and collaboration diagrams generate the overall behavior generated by the logic of the statecharts of the individual objects in the system. Building on this the overall state transition diagrams of the system and the resulting event sequences can be derived to match against those required. Adding timings to the model allows checking the response times either deterministically or as bounds or averages.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Boyer RS,Moore JS","Boyer RS,Moore JS",II - A Sketch of the Theory and Two Simple Examples,,1979,,,8-27,,Academic Press,,A Computational Logic,1979,,0572-4252,https://www.sciencedirect.com/science/article/pii/B9780121229504500061;http://dx.doi.org/10.1016/B978-0-12-122950-4.50006-1,10.1016/B978-0-12-122950-4.50006-1,"Publisher Summary This chapter presents an introduction to function-based theory and to discusses the way by which theorems are proved. To prove theorems formally, proofs are to be constructed in a formal theory. Any theory concerned with the mathematics behind computing must provide inductively constructed objects. In formalizing properties of programs, it has been found that it is convenient to allow the introduction of new types of inductively constructed objects, of which the integers are just a single example. The principle can be called the shell principle. The name shell derives from imagining the new objects to be colored structures encapsulating a fixed number of components, possibly of certain colors. In proofs by induction, it is easier to prove strong theorems than weak ones, because strong theorems permit obtaining strong induction hypotheses with which to work.",,,ACM Monograph Series,,,,,,,,,,,,,,,,,,,
Journal Article,"Chandersekaran CS,Linger RC",,Software specification using the special language,Journal of Systems and Software,1981,2,1,31-38,,,,,1981,,0164-1212,https://www.sciencedirect.com/science/article/pii/0164121281900443;http://dx.doi.org/10.1016/0164-1212(81)90044-3,10.1016/0164-1212(81)90044-3,"This paper presents a tutorial overview of special, a formal specification and assertion language created by SRI International as part of their hierarchical design methodology. The language is based on a formal model of system behavior and is supported by language processors that assist in the interactive development of specifications. special is a strongly typed language that models data and programs as abstract resources known as objects. Collections of modules known as abstract machines are the major building blocks of a software specification in special. The technical foundations of special and the components of a special specification are described. A sample specification is detailed in an appendix.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Becker S,,Generation and application of rules for quality dependent façade reconstruction,ISPRS Journal of Photogrammetry and Remote Sensing,2009,64,6,640-653,,,,,2009,,0924-2716,https://www.sciencedirect.com/science/article/pii/S0924271609000689;http://dx.doi.org/10.1016/j.isprsjprs.2009.06.002,10.1016/j.isprsjprs.2009.06.002,"Frequently, terrestrial LiDAR and image data are used to extract high resolution building geometry like windows, doors and protrusions for three-dimensional (3D) façade reconstruction. However, such a purely data driven bottom-up modelling of façade structures is only feasible if the available observations meet considerable requirements on data quality. Errors in measurement, varying point densities, reduced accuracies, as well as incomplete coverage affect the achievable correctness and reliability of the reconstruction result. While dependence on data quality is a general disadvantage with data driven bottom-up approaches, model based top-down reconstructions are much more robust. Algorithms introduce knowledge about the appearance and arrangement of objects. Thus, they cope with data uncertainty and allow for a procedural modelling of building structures in a predefined architectural style, which is inherent in grammar or model descriptions. We aim at a quality sensitive façade reconstruction which is on the one hand robust against erroneous and incomplete data, but on the other hand not subject to prespecified rules or models. For this purpose, we combine bottom-up and top-down strategies by integrating automatically inferred rules into a data driven reconstruction process. Façade models reconstructed during a bottom-up method serve as a knowledge base for further processing. Dominant or repetitive features and regularities as well as their hierarchical relationship are detected from the modelled façade elements and automatically translated into rules. These rules together with the 3D representations of the modelled façade elements constitute a formal grammar. It holds all the information which is necessary to reconstruct façades in the style of the given building. The paper demonstrates that the proposed algorithm is very flexible towards different data quality and incomplete sensor data. The inferred grammar is used for the verification of the façade model produced during the data driven reconstruction process and the generation of synthetic façades for which only partial or no sensor data is available. Moreover, knowledge propagation is not restricted to façades of one single building. Based on a small set of formal grammars derived from just a few observed buildings, façade reconstruction is also possible for whole districts featuring uniform architectural styles.","Architecture, Modelling, Interpretation, Building, Three-dimensional",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Agustin RD,Suwardi IS,Purwarianti A,Surendro K",,Knowledge Representation and Inference Engine Model of SAPS Gaming Concept,Procedia Technology,2013,11,,696-703,,,,,2013,,2212-0173,https://www.sciencedirect.com/science/article/pii/S2212017313004015;http://dx.doi.org/10.1016/j.protcy.2013.12.247,10.1016/j.protcy.2013.12.247,"This paper propose a conceptual graph model to represent the concept of gaming, named SAPS (Status, Access, Power, Stuff) and propose a building block of the engine to run and control the game by rule of game design that be expressed in the SAPS. The advantage of this design is flexibility of the rule definition, supports many game mechanic and dynamic, as well as accommodates multirole playing and multiplayer games. The Excellence is achieved through representation of an access as actionID, Heuristic Value, Role name, Prerequisite, Impact. Prerequisite and impact are represented into a positive sentence of first order predicate calculus with the AND operator. The predicate in pre-requisite sentences express status and criteria. Predicate in impact have been identified 4 kinds, namely increment, decrement, add, and sets. Are those representative for update status, still need more research .Game mechanic was accommodated through status that be represented in (type of status; objects; attributes; criteria). Valid Type of status includes xpoint, redeemable Point, level/badge, progress, stuff, ownership, and time. Game Dynamic was accommodated through the discretion to perform user defined action. But the form of human computer interaction of such action has not been designed. Heuristic value on the model is filled by game designer and designed to support the delivery guidance to the player automatically, by suggesting optimal actions to achieve goals using Forward A* Search. Moreover three modules of Forward Intelligent Searching are designed, ie first to update the state of action based on current status. There are three kinds of state, namely the ‘lock’, ‘open’, ‘closed’. The second is to update the status automatically based on the selected action to be executed. The third is execute automatic action that be triggered by status or by time. They all refer to the rule of the game are defined in the ‘access’","Gaming Concepts, SAPS, Knowledge Representation, Inference Engine, A* Algorithm","4th International Conference on Electrical Engineering and Informatics, ICEEI 2013",,,,,,,,,,,,,,,,,,,,
Book Chapter,Wechsler H,Hawkes PW,Invariance in Pattern Recognition,,1987,69,,261-322,,Academic Press,,,1987,,0065-2539,https://www.sciencedirect.com/science/article/pii/S0065253908602036;http://dx.doi.org/10.1016/S0065-2539(08)60203-6,10.1016/S0065-2539(08)60203-6,"Publisher Summary This chapter reviews the problem of invariance in pattern recognition. It describes the computational techniques for recognizing patterns, invariant to the distortions they might have been subject to. The visual recognition problem stems from the fact that the interpretation of a three-dimensional (3-D) scene from a single two-dimensional (2-D) image is confounded by several dimensions of variability. Such dimensions include uncertain perspective, position, orientation, and size (pure geometric variability) along with sensor noise, object occlusion, and nonuniform illumination. There are several major ways for handling the issue of image variability. The approaches can be distinguished according to the type of (memory) prototype patterns that are matched with the computed image representations at the interface with visual memory. One of the ways of performing invariant pattern recognition is to look for some internal structure. To capture such (internal) relationships among object components tools, such as Markov chains and the minimum spanning tree (MST) or formal languages (grammars) can be used.",,,Advances in Electronics and Electron Physics,,,,,,,,,,,,,,,,,,,
Journal Article,"Maciel AA,Ford B,Lamberts R",,Main influences on the design philosophy and knowledge basis to bioclimatic integration into architectural design—The example of best practices,Building and Environment,2007,42,10,3762-3773,,,,,2007,,0360-1323,https://www.sciencedirect.com/science/article/pii/S0360132306003052;http://dx.doi.org/10.1016/j.buildenv.2006.07.041,10.1016/j.buildenv.2006.07.041,"This paper studies the influence of architectural education and early experience of the work of a group pf architects, whose work shows strong features of bioclimatic integration (such as Lele and Severiano Porto in Brazil and Spencer de Grey and Mario Cucinella in Europe). The first analysis of their individual experiences, through semi-structured interviews, indicates that the integration of bioclimatic concepts into design is beyond the development or improvement of tools. First of all, it is fundamental that these concepts are part of the design philosophy of the professional, which is determinant on the application of research and innovation in architectural practice. Therefore, before the tools, the formal education can be a tool to promote the inclusion of these principles as part of their design philosophy, influencing the approach to design. It happened in the cases in which there was a commitment of the school to develop a technical knowledge basis in building physics into studio activities, highlighting the aesthetic character of environmental integration. This basis was consolidated in the contact with the building site construction, which also strengthened their ethical commitment regarding the quality of the built object. It has the potential to generate confidence in the consideration of these issues, also making it easier to get the right information from available resources and tools, via a critical understanding of the different issues.","Energy efficiency, Bioclimatic design, Best practices",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ilies HT,Shapiro V",,The dual of sweep,Computer-Aided Design,1999,31,3,185-201,,,,,1999,,0010-4485,https://www.sciencedirect.com/science/article/pii/S0010448599000159;http://dx.doi.org/10.1016/S0010-4485(99)00015-9,10.1016/S0010-4485(99)00015-9,"As an infinite union operation, sweep of a moving object through space is a powerful and natural addition to the Boolean set operations that incorporates motion-related information for the purposes of shaping, collision detection, and simulation of moving objects. Use of sweep has been hindered by limited computational support and by the fact that it is a ‘material growing’ operation, whereas many applications, such as interference elimination and mechanism design, appear to be better modeled by a ‘material removal’ operation. This article formally defines a new geometric modeling operation of unsweep. Given an arbitrary subset E of Euclidean space and a general motion M, unsweep(E,M) returns the largest subset of E that remains inside the original E under M. When M is a translation, unsweep (E,M) naturally reduces to the standard Minkowski difference of E and the trajectory generated by the inverted motion M̂. In this sense, the operation of unsweep is a generalization of Minkowski difference that corresponds to a ‘material removal’ operation, it can be also defined as an infinite intersection operation, and is the dual of sweep in a precise set-theoretic sense. We show that unsweep has attractive theoretical and computational properties, including a practical point membership test for arbitrary general motions. Using duality, the established properties of unsweep is extended to the general sweep operation, and can be used to improve the computational support for general sweeps.","Unsweep, Sweep, Geometric and solid modeling, Motion, Point membership test, Set operators",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fua P,Leclerc YG",,Taking Advantage of Image-Based and Geometry-Based Constraints to Recover 3-D Surfaces,Computer Vision and Image Understanding,1996,64,1,111-127,,,,,1996,,1077-3142,https://www.sciencedirect.com/science/article/pii/S107731429690048X;http://dx.doi.org/10.1006/cviu.1996.0048,10.1006/cviu.1996.0048,"A unified framework for 3-D shape reconstruction allows us to combine image-based and geometry-based information sources. The image information is akin to stereo and shape-from-shading, while the geometric information may be provided in the form of 3-D points, 3-D features, or 2-D silhouettes. A formal integration framework is critical in recovering complicated surfaces because the information from a single source is often insufficient to provide a unique answer. Our approach to shape recovery is to deform a generic object-centered 3-D representation of the surface so as to minimize an objective function. This objective function is a weighted sum of the contributions of the various information sources. We describe these various terms individually, our weighting scheme, and our optimization method. Finally, we present results on a number of difficult images of real scenes for which a single source of information would have proved insufficient.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Vernadat F,,Towards a Manufacturing System Specification Language,IFAC Proceedings Volumes,1994,27,4,121-127,,,,,1994,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017460101;http://dx.doi.org/10.1016/S1474-6670(17)46010-1,10.1016/S1474-6670(17)46010-1,"A specification language called MSS based on the process model of CIMOSA is introduced for modelling and specification of manufacturing business processes. The language provides declarative aspects, procedural aspects and exception handling aspects. Declarative aspects concern the structural description of manufacturing system entities (functions, resources and object views) as basic constructs. Procedural aspects concern process behaviour (i.e. control flow) and activity behaviour (i.e. functionality). They allow for sequential, conditional, iterative and parallel control structures. Exception handling aspects concern procedures to be activated in the case of exceptional situations to face real-world non-determinism and system failures.","Manufacturing system specification, enterprise modelling, process models, formal description language, CIMOSA","IFAC Workshop on Intelligent Manufacturing Systems 1994 (IMS'94), Vienna, Austria, 13-15 June",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Popchev I,Zlatareva N,Mircheva M","Jorrand P,Sgurev V","A LOGIC FOR TRUTH MAINTENANCE REASONING**This research was partially supported by the Bulgarian Committee for Science under grant No.318, and by the National Program for Investigation of the Human Brain under grant No.23",,1990,,,71-80,,North-Holland,Amsterdam,Artificial Intelligence IV,1990,9780444887719,,https://www.sciencedirect.com/science/article/pii/B9780444887719500143;http://dx.doi.org/10.1016/B978-0-444-88771-9.50014-3,10.1016/B978-0-444-88771-9.50014-3,"This paper presents a logic for truth-maintenance reasoning. To take into account both the incompleteness and the uncertainty of a problem domain knowledge our logic works with different categories of objects. A special kind of belief revision is provided if the contradiction is detected. The purpose of this revision is to block the propagation of the contradiction during the inference process, rather than to try to get rid of it. This is achieved by modifying the set of inference rules in a special way, which in turn makes the inference process a nonmonotonic one. Some formal results about the non-monotonic inference relation are given.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Génova G,Llorens J,Fraga A",,Metamodeling generalization and other directed relationships in UML,Information and Software Technology,2014,56,7,718-726,,,,,2014,,0950-5849,https://www.sciencedirect.com/science/article/pii/S0950584914000214;http://dx.doi.org/10.1016/j.infsof.2014.01.010,10.1016/j.infsof.2014.01.010,"Context Generalization is a fundamental relationship in object orientation and in the UML (Unified Modeling Language). The generalization relationship is represented in the UML metamodel as a “directed relationship”. Objective Being a directed relationship corresponds to the nature of generalization in the semantic domain of object orientation: a relationship that is directed from the subclass to the superclass. However, we claim that the particular form this relationship adopts in the metamodel is erroneous, which entails a series of inconveniencies for model manipulation tools that try to adhere to the UML specification. Moreover, we think that this error could be due to a misinterpretation of the relationships between metamodeling levels in the UML: represented reality (M0), model (M1) and metamodel (M2). This problem also affects other directed relationships: Dependency and its various subtypes, Include and Extend between use cases, and others. Method We analyze the features of the generalization relationship in various domains and how it has been metamodeled in UML. We examine the problems, both theoretical and technological, posed by the UML metamodel of generalization. We then compare it with the metamodel of other directed relationships. Results We arrive at the conclusion that the metamodel of all directed relationships could be improved. Namely, we claim that, at level M2, the metamodel should not contain any one-way meta-associations: all meta-associations should be two-way, both for practical and theoretical reasons. Conclusions The rationale for our main claim can be summarized as follows: connected graphical symbols do know each other, and the goal of a metamodel is to specify the syntactic properties of a language, ergo meta-associations must be two-way. This, of course, does not preclude at all the use of one-way associations at the user model level (M1).","Unified Modeling Language, Model engineering, Metamodel, Generalization, Directed relationship",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Martínez E,Cariñena JF,Sarlet W",,Derivations of differential forms along the tangent bundle projection II,Differential Geometry and its Applications,1993,3,1,1-29,,,,,1993,,0926-2245,https://www.sciencedirect.com/science/article/pii/0926224593900202;http://dx.doi.org/10.1016/0926-2245(93)90020-2,10.1016/0926-2245(93)90020-2,"The study of the calculus of forms along the tangent bundle projection τ, initiated in a previous paper with the same title, is continued. The idea is to complete the basic ingredients of the theory up to a point where enough tools will be available for developing new applications in the study of second-order dynamical systems. A list of commutators of important derivations is worked out and special attention is paid to degree zero derivations having a Leibnitz-type duality property. Various ways of associating tensor fields along τ to corresponding objects on TM are investigated. When the connection coming from a given second-order system is used in this process, two important concepts present themselves: one is a degree zero derivation called the dynamical covariant derivative; the other one is a type (1, 1) tensor field along τ, called the Jacobi endomorphism. It is illustrated how these concepts play a crucial role in describing many of the interesting geometrical features of a given dynamical system, which have been dealt with in the literature.","Derivations, forms along a map, second-order equations, nonlinear connections",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Shipman DW,"Mylopolous J,Brodie M",The Functional Data Model and the Data Language DAPLEX,,1989,,,168-184,,Morgan Kaufmann,San Francisco (CA),Readings in Artificial Intelligence and Databases,1989,9780934613538,,https://www.sciencedirect.com/science/article/pii/B9780934613538500170;http://dx.doi.org/10.1016/B978-0-934613-53-8.50017-0,10.1016/B978-0-934613-53-8.50017-0,"Publisher Summary This chapter presents the DAPLEX language and the underlying data model on which it is based. DAPLEX is a data definition and manipulation language for database systems, grounded in a concept of data representation called the functional data model. DAPLEX may be considered to be a syntactic embodiment of the functional data model. A fundamental goal of DAPLEX is to provide a conceptually natural database interface language. That is, the DAPLEX constructs used to model real-world situations are intended to closely match the conceptual constructs a human being might employ when thinking about those situations. Such conceptual naturalness, to the extent it has been achieved, presumably simplifies the process of writing and understanding DAPLEX requests, as the translation between the user's mental representation and its formal expression in DAPLEX is more direct. The basic constructs of DAPLEX are the entity and the function. These are intended to model conceptual objects and their properties. DAPLEX is a database language which incorporates:(1)a formulation of data in terms of entities;(2)a functional representation for both actual and virtual data relationships;(3)a rich collection of language constructs for expressing entity selection criteria;(4)a notion of subtype/supertype relationships among entity types. This paper presents and motivates the DAPLEX language and the underlying data model on which it is based.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kamensky D,Hsu MC,Schillinger D,Evans JA,Aggarwal A,Bazilevs Y,Sacks MS,Hughes TJ",,An immersogeometric variational framework for fluid–structure interaction: Application to bioprosthetic heart valves,Computer Methods in Applied Mechanics and Engineering,2015,284,,1005-1053,,,,,2015,,0045-7825,https://www.sciencedirect.com/science/article/pii/S0045782514004101;http://dx.doi.org/10.1016/j.cma.2014.10.040,10.1016/j.cma.2014.10.040,"In this paper, we develop a geometrically flexible technique for computational fluid–structure interaction (FSI). The motivating application is the simulation of tri-leaflet bioprosthetic heart valve function over the complete cardiac cycle. Due to the complex motion of the heart valve leaflets, the fluid domain undergoes large deformations, including changes of topology. The proposed method directly analyzes a spline-based surface representation of the structure by immersing it into a non-boundary-fitted discretization of the surrounding fluid domain. This places our method within an emerging class of computational techniques that aim to capture geometry on non-boundary-fitted analysis meshes. We introduce the term “immersogeometric analysis” to identify this paradigm. The framework starts with an augmented Lagrangian formulation for FSI that enforces kinematic constraints with a combination of Lagrange multipliers and penalty forces. For immersed volumetric objects, we formally eliminate the multiplier field by substituting a fluid–structure interface traction, arriving at Nitsche’s method for enforcing Dirichlet boundary conditions on object surfaces. For immersed thin shell structures modeled geometrically as surfaces, the tractions from opposite sides cancel due to the continuity of the background fluid solution space, leaving a penalty method. Application to a bioprosthetic heart valve, where there is a large pressure jump across the leaflets, reveals shortcomings of the penalty approach. To counteract steep pressure gradients through the structure without the conditioning problems that accompany strong penalty forces, we resurrect the Lagrange multiplier field. Further, since the fluid discretization is not tailored to the structure geometry, there is a significant error in the approximation of pressure discontinuities across the shell. This error becomes especially troublesome in residual-based stabilized methods for incompressible flow, leading to problematic compressibility at practical levels of refinement. We modify existing stabilized methods to improve performance. To evaluate the accuracy of the proposed methods, we test them on benchmark problems and compare the results with those of established boundary-fitted techniques. Finally, we simulate the coupling of the bioprosthetic heart valve and the surrounding blood flow under physiological conditions, demonstrating the effectiveness of the proposed techniques in practical computations.","Fluid–structure interaction, Bioprosthetic heart valve, Immersogeometric analysis, Isogeometric analysis, Nitsche’s method, Weakly enforced boundary conditions",Isogeometric Analysis Special Issue,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ghallab M,Gonzalo EI",,A linear control algorithm for a class of rule-based systems,The Journal of Logic Programming,1991,11,2,117-132,,,,,1991,,0743-1066,https://www.sciencedirect.com/science/article/pii/074310669190015H;http://dx.doi.org/10.1016/0743-1066(91)90015-H,10.1016/0743-1066(91)90015-H,"This paper presents a new and efficient control algorithm for the class of rule-based systems that rely on monotonic inference and on the 〈object attribute value〉 or similar propositional formalisms. Production rules considered are of the Horn-clause type or of some extended non-Horn form. The proposed algorithm uses a top-down (backward chaining) strategy and is able to solve the indirect-recursivity problem. Its worst-case complexity is proved to be linearly bounded by the total number of propositions. In each case the algorithm uses a minimal number of propositions. The control algorithm is formally described, illustrated with examples, proved, and analysed. Extensions to rules in non-Horn form and to problems seeking “best” solutions are finally considered.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Knapp A,"Futatsugi K,Nakagawa AT,Tamai T",Chapter 5 - Generating Rewrite Theories from UML Collaborations,,2000,,,97-120,,Elsevier Science B.V.,Amsterdam,CAFE: An Industrial-Strength Algebraic Formal Method,2000,9780444505569,,https://www.sciencedirect.com/science/article/pii/B9780444505569500654;http://dx.doi.org/10.1016/B978-044450556-9/50065-4,10.1016/B978-044450556-9/50065-4,"Publisher Summary This chapter presents an executable model for collaborations and interactions of the Unified Modeling Language as a rewriting logic theory in CafeOBJ. The Unified Modeling Language comprises a notion of interaction modeling, called collaborations, and simultaneously features a sound abstract syntax and a rich and detailed, though informal, semantics for this concept. However, the transfer of known simulation results is limited by some semantical deviations and the integration of new characteristics. In an UML model, collaborations specify how an operation or a use case of the model is realized by a cooperation of several instances of model elements. Therefore this chapter proposes an executable formal model for UML collaborations that is directly based on UML's abstract syntax and provably correct with respect to the temporal logic semantics of interactions, thus yielding simulation capabilities for UML's specific notion of interaction modeling. The chapter uses rewriting logic dimension of the algebraic specification language CafeOBJ, as a semantic framework that allows for a unified treatment of object-orientation and concurrency. Moreover, it summarizes UML collaboration's concrete and abstract syntax and the formal semantics of UML interactions in temporal logic. This chapter also describes the generation of a CafeOBJ specification from UML collaboration along with the correctness proof for the generated rewrite theory with respect to the temporal logic specification of the collaboration's interaction. The chapter concludes conclude with an outlook to possible refinements and extensions.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cheng J,Lin F",,Approach of heterogeneous bio-modeling based on material features,Computer-Aided Design,2005,37,11,1115-1126,,,,,2005,,0010-4485,https://www.sciencedirect.com/science/article/pii/S0010448505000333;http://dx.doi.org/10.1016/j.cad.2005.02.003,10.1016/j.cad.2005.02.003,"To capture the heterogeneity of biomaterials, a material feature based approach of heterogeneous bio-modelling is presented in this paper. The concept of material feature is defined as the specified material distribution of a certain sub-region within a solid, which is a high level abstraction of design intent. These material features are finally laid down on the function representations, which consist of material composition functions. The definition, formation and domain of material composition functions are formally presented. In order to facilitate the evaluation of material distribution, these functions are classified into component function and constraint function. Meanwhile, to capture the distinct material composition partition existing in medical objects, the material interface is introduced. The problem of overlapping and/or ambiguous of the feature domains is addressed. Finally, the feature tree for storing, evaluating of material features and tracing of design intents is proposed and the feature solving algorithm is presented. A prototype heterogeneous bio-modeling system is implemented based on open source graphics kernel VTK, with the help of translation layer to improve the system's efficiency and compatibility.","Heterogeneous solid, Material feature, Material composition function, Feature tree",Bio-CAD,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kemp MC,Ng YK",,The incompatibility of individualism and ordinalism,Mathematical Social Sciences,1982,3,1,33-37,,,,,1982,,0165-4896,https://www.sciencedirect.com/science/article/pii/016548968290004X;http://dx.doi.org/10.1016/0165-4896(82)90004-X,10.1016/0165-4896(82)90004-X,A formal proof is offered of the fact that Individualism and Ordinalism imply the controversial condition A3 used by Kemp and Ng (1976) to show the non-existence of an individualistic social welfare function based only on ordinal preferences but objected to by Samuelson (1977) as unreasonable. Mayston's argument against our definition of ordinality is refuted; his notion of ‘true ordinality’ involves elements of cardinality and/or goes against individualism.,"Social welfare function, individualism, ordinalism",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Pan W,Chai C",,Structure-aware Mashup service Clustering for cloud-based Internet of Things using genetic algorithm based clustering algorithm,Future Generation Computer Systems,2018,87,,267-277,,,,,2018,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X18302097;http://dx.doi.org/10.1016/j.future.2018.04.052,10.1016/j.future.2018.04.052,"An increasing number of physical objects connected to the Internet makes it possible for smart things to access all kinds of cloud services. Mashup technology has been an effective way to the rapid IoT (Internet of Things) application development. However, the number of Mashup services (IoT applications) being so large makes how to discover the desired IoT applications accurately and efficiently become a problem. Service clustering technology can facilitate service discovery effectively, and many different approaches have been proposed. However, many of them only use semantic similarities to guide clustering operations and need the configuration of the number of clusters. Structural similarities are orthogonal to semantic similarities. But they have never been used in service clustering approaches. In this paper, we propose a novel Mashup service clustering approach based on a structural similarity and a genetic algorithm based clustering algorithm. First, it applies a two-mode graph to describe Mashups, Web APIs, and their relations formally. Second, it applies the SimRank algorithm to quantify the structural similarity between every pair of Mashup services. Finally, it introduces a genetic algorithm based clustering algorithm to organize Mashup services into clusters effectively and determines the number of clusters automatically. Empirical results on a real-world Mashup services data set collected from ProgrammableWeb demonstrate that our approach can cluster Mashup services efficiently without any constraints on the number of clusters, and its performance is better than other Mashup service clustering approaches based on semantic metrics.","Service clustering, Mashup, Genetic algorithm, Structural similarity, Semantic similarity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cimadamore M,Viroli M",,On the reification of Java wildcards,Science of Computer Programming,2008,73,2,59-75,,,,,2008,,0167-6423,https://www.sciencedirect.com/science/article/pii/S016764230800066X;http://dx.doi.org/10.1016/j.scico.2008.06.005,10.1016/j.scico.2008.06.005,"Providing runtime information about generic types–that is, reifying generics–is a challenging problem studied in several research papers in the last years. This problem is not tackled in current version of the Java programming language (Java 6), which consequently suffers from serious safety and coherence problems. The quest for finding effective and efficient solutions to this problem is still open, and is further made more complicated by the new mechanism of wildcards introduced in Java J2SE 5.0: its reification aspects are currently unexplored and pose serious semantics and implementation issues. In this paper, we discuss an implementation support for wildcard types in Java. We first analyse the problem from an abstract viewpoint, discussing the issues that have to be faced in order to extend an existing reification technique so as to support wildcards, namely, subtyping, capture conversion and wildcards capture in method calls. Secondly, we present an implementation in the context of the EGO compiler. EGO is an approach for efficiently supporting runtime generics at compile-time: synthetic code is automatically added to the source code by the extended compiler, so as to create generic runtime type information on a by need basis, store it into object instances, and retrieve it when necessary in type-dependent operations. The solution discussed in this paper makes the EGO compiler the first reification approach entirely dealing with the present version of the Java programming language.","Generic types, Wildcards, Java, Reification",,,,,,,,,,,,,,,,,,,,,
Journal Article,Radig B,,Image sequence analysis using relational structures,Pattern Recognition,1984,17,1,161-167,,,,,1984,,0031-3203,https://www.sciencedirect.com/science/article/pii/0031320384900438;http://dx.doi.org/10.1016/0031-3203(84)90043-8,10.1016/0031-3203(84)90043-8,"Time varying images are usually analyzed to obtain a description of the observed objects and of their actions. An abstraction process is necessary which converts the input images into symbolic descriptions. The attributes of image symbols and the relationship between symbols are computed from the sampled intensity or colour measurements. Relational structures are a formal tool to describe not only the symbolic image representation but, furthermore, stored models as prototypes of objects and objects as instantiations of such prototypes. Following this paradigm, an essential task of image sequence analysis is the generation of mappings between images to establish the correspondence relationship and between images and prototypes to identify objects. Different types of morphisms between relational structures (RS-morphisms) are proposed, together with an approach for computing them by searching for cliques in a compatibility graph of hypothetical assignments of elements from both structures. The common formalism, presented here, aims at a unification of methods for those steps necessary to instantiate objects and follow them through the sequence. One practical reason for this attempt is to make (relational) database systems available to store and retrieve the large amount of data whidch might be generated during the exploration of a real-world image sequence.","Image sequence analysis, Time varying images, Relational structures, Morphisms, Hierarchical synthesis, Correspondence, Inexact matching, Cliques",Knowledge Based Image Analysis,,,,,,,,,,,,,,,,,,,,
Journal Article,"Skersys T,Danenas P,Butleris R",,Extracting SBVR business vocabularies and business rules from UML use case diagrams,Journal of Systems and Software,2018,141,,111-130,,,,,2018,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412121830061X;http://dx.doi.org/10.1016/j.jss.2018.03.061,10.1016/j.jss.2018.03.061,"In model-driven information systems engineering, model transformations reside at the very core of this paradigm. Indeed, model transformations (in particular, model-to-model, or M2M) are a must-have feature of any modern model-driven approach supported by CASE technology. Model transformations are intended to raise quality of the models under development, and also speed-up the modeling itself by bringing in certain level of automation into the development process. Nevertheless, due to certain objective reasons, the level of such automation is spread unevenly throughout the development process – in this respect, Business Modeling and System Analysis are, arguably, the most underdeveloped phases of the model-driven information systems development life cycle. In this paper, we show how M2M transformation technology was used to extract well-structured business vocabularies and business rules from formal use case models represented through a set of use case diagrams; Object Management Group's (OMG) standards Semantics for Business Vocabulary and Rules (SBVR) and Unified Modeling Language (UML) were used for this purpose. The proposed solution consists of two concurrent approaches, namely, automatic and semi-automatic, which may be used selectively to achieve the best expected result. Basic implementation aspects of the solution integrating both approaches are also briefly presented in the paper. While UML use case models is the main subject in this research, the proposed solution may be adopted for other UML and MOF-based models as well.","SBVR business vocabulary, SBVR business rules, UML use case diagram, Model-to-model transformation",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Overbeek S,Janssen M,van Bommel P",,A standard language for service delivery: Enabling understanding among stakeholders,Computer Standards & Interfaces,2012,34,4,355-366,,,,,2012,,0920-5489,https://www.sciencedirect.com/science/article/pii/S0920548912000049;http://dx.doi.org/10.1016/j.csi.2011.12.006,10.1016/j.csi.2011.12.006,"In Integrated Service Delivery (ISD), multiple service providers have to collaborate in order to serve as a one-stop shop for their clients. Although technical standards have been met, collaboration is difficult. Service providers do not know what kind of information other providers need, are not aware of each other's processes or simply do not understand each other due to the use of ambiguous terms. In this paper, foundations for a language are developed to specify the requirements for ISD and enable the unambiguous understanding of these requirements. A combination of the standards Object-Role Modeling (ORM) and Semantics of Business Vocabulary and Business Rules (SBVR) is used to ensure human readability and to have the full expressive power of formal languages. Composed expressions are developed to express logical, temporal, and geographical requirements. This enables service providers to understand how, when, and where services need to be integrated. By utilizing these foundations to generate a standard language for ISD, service providers can collaborate and they can understand complex client requirements which lead to improved ISD.","Integrated service delivery, Ontology, Organizational networks, ORM, SBVR, Service composition",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lespérance Y,Levesque HJ",,Indexical knowledge and robot action—a logical account,Artificial Intelligence,1995,73,1,69-115,,,,,1995,,0004-3702,https://www.sciencedirect.com/science/article/pii/000437029400010X;http://dx.doi.org/10.1016/0004-3702(94)00010-X,10.1016/0004-3702(94)00010-X,"The knowledge required for action is generally indexical rather than objective. For example, a robot that knows the relative position of an object is generally able to go and pick it up; he need not know its absolute position. Agents may have very incomplete knowledge of their situation in terms of what objective facts hold and still be able to achieve their goals. This paper presents a formal theory of knowledge and action, embodied in a modal logic, that handles the distinction between indexical and objective knowledge and allows a proper specification of the knowledge prerequisites and effects of action. Several kinds of robotics situations involving indexical knowledge are formalized within the framework; these examples show how actions can be specified so as to avoid making excessive requirements upon the knowledge of agents.",,"Computational Research on Interaction and Agency, Part 2",,,,,,,,,,,,,,,,,,,,
Journal Article,Auinger K,,The Bifree Locally Inverse Semigroup on a Set,Journal of Algebra,1994,166,3,630-650,,,,,1994,,0021-8693,https://www.sciencedirect.com/science/article/pii/S0021869384711690;http://dx.doi.org/10.1006/jabr.1994.1169,10.1006/jabr.1994.1169,"A class of regular semigroups closed under taking direct products, regular subsemigroups and homomorphic images is an e(xistence) variety of regular semigroups. For an e-variety V of locally inverse or E-solid regular semigroups, the bifree object BFV(X) on a set X is the natural concept of a \free object\"" in V. Its existence has been proved by Y. T. Yeh. In this paper",the bifree locally inverse semigroup BFLJ(X) is described as a homomorphic image of the absolutely free algebra of type [2,2] generated by X and the set of formal inverses X′,and equivalently as subsemigroup of a semidirect product of a suitable free semilattice by the bifree completely simple semigroup on X. This latter realization is used to show that BFLJ(X) is combinatorial,completely semisimple and satisfies several finiteness conditions. Furthermore,the approach of biidentities is used to formulate a Birkhoff-type theorem for e-varieties of locally inverse semigroups and to establish a one-one correspondence between locally inverse e-varieties and fully invariant congruences on BFLJ(X) for countably infinite X. As an application,"it is shown that in each e-variety of locally inverse semigroups all free products exist.""",,,,,,,,,,,,,,,,
Book Chapter,"Medioni G,Lee MS,Tang CK","Medioni G,Lee MS,Tang CK",Chapter 1 - Introduction,,2000,,,1-20,,Elsevier Science B.V.,Amsterdam,A Computational Framework for Segmentation and Grouping,2000,9780444503534,,https://www.sciencedirect.com/science/article/pii/B9780444503534500032;http://dx.doi.org/10.1016/B978-044450353-4/50003-2,10.1016/B978-044450353-4/50003-2,"Publisher Summary A successful computer vision system must generate scene description in terms of geometry, motion, appearance, lighting, and object identity, from one or more two-dimensional arrays of pixels. It is required to formulate, implement, and test a computational methodology to achieve this goal. Mathematically, due to the projective nature of imaging, the problem is underconstrained, as many different scene configurations can produce the same image, even though, most of the time, only one of these is perceived by the human visual system. This chapter devises a robust methodology for applying the continuity constraint to solve a variety of early vision problems. The methodology is grounded in two elements, namely, tensor calculus for data representation and nonlinear voting for data communication that together provide a unified framework for the robust inference of multiple curves, surfaces, regions, and junctions from any combination of points, segments, and surface patch elements. In order to evaluate the efficiency and effectiveness of the method, algorithms have been developed to address a number of early vision problems, such as perceptual grouping in two-dimensional and three-dimensional, shape from stereo, shape from shading, and motion grouping and segmentation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"White DR,Jorion P",,Kinship networks and discrete structure theory: Applications and implications,Social Networks,1996,18,3,267-314,,,,,1996,,0378-8733,https://www.sciencedirect.com/science/article/pii/0378873395002774;http://dx.doi.org/10.1016/0378-8733(95)00277-4,10.1016/0378-8733(95)00277-4,"Confusions between substantive and relational concepts of kinship as a social network have led to a number of problems that are clarified by a temporally ordered relational theory of network structure. The ordered-network approach gives rise to a novel means of graphing the social field of kinship relations, while allowing kinship to be locally defined in culturally relative terms. Its utility is exemplified in applications to kinships among US Presidents, Old Testament Canaanites, and native Australians of Groote Eylandt. The formal concepts treated in the mapping of kinship networks are: kinship axioms, parental graph structure, core, circuits of consanguineally and affinally linked kin, sides and divides, homeomorphic mappings, homomorphisms as potentially simplifying mappings of kinship, elementary structure, and order-structure. Representational theorems are proven about homeomorphisms, cores and circuits, and the ambiguity of elementary structures. The last set of theorems leads to clarifying and redefining some of the basic concepts of elementary, semi-complex and complex structures of kinship in terms of properties of generationally ordered networks. The conclusions of the formal argument are ‘post-structural’ in the narrow sense of demonstrating the need for specifying contingent historical processes in the structural analysis of kinship as a social field. The open-ended approach to change, one that is implied by the study of ordered structures that unfold in a temporal succession, connects to issues of population variability, selection, and evolutionary processes. The kinship structures that are mapped in this approach are not intended as any sort of complete representations of kinship ‘systems’, but merely as scaffoldings that help to bring into view kinship as a social field, providing a baseline for other mappings (which may be superimposed) of social processes such as communicative fields, exchange processes, transmission of learned behaviors, social rights and inheritance, political and religious succession, and the like.",,Social Network and Discrete Structure Analysis,,,,,,,,,,,,,,,,,,,,
Journal Article,Casti JL,,The theory of metabolism-repair systems,Applied Mathematics and Computation,1988,28,2,113-154,,,,,1988,,0096-3003,https://www.sciencedirect.com/science/article/pii/0096300388900902;http://dx.doi.org/10.1016/0096-3003(88)90090-2,10.1016/0096-3003(88)90090-2,"Classical control systems based upon the Newtonian framework make the implicit assumption that there is a controller who injects regulating signals into the system from the outside. In biology as well as the social and behavioral sciences, there is usually no readily recognizable external controller, and the system somehow controls itself from the inside, so to speak. The theory of metabolism-repair (M,R) systems has been developed as a mathematical extension of the classical setup aimed directly at the formal characterization of such self-referential or “lifelike” systems. This paper outlines the way in which a controlled (M,R) systems can be naturally obtained from an uncontrolled classical system, as well as providing a fairly detailed mathematical consideration of the new system-theoretic questions arising when the processes of repair and replication are added to the classical “metabolism only” framework. In addition to giving a general framework suitable for the mathematical representation of living systems, the paper also considers a variety of questions arising out of the underlying biological motivation, including the problems of growth, differentiation, repair, replication, and Lamarckian inheritance. A number of possible applications from the areas of cellular biology, economics and manufacturing are also discussed, as are extensions to the basic framework.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,St-Denis R,,Designing reactive systems: integration of abstraction techniques into a synthesis procedure,Journal of Systems and Software,2002,60,2,103-112,,,,,2002,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121201000838;http://dx.doi.org/10.1016/S0164-1212(01)00083-8,10.1016/S0164-1212(01)00083-8,"This paper presents a new paradigm for designing reactive systems. It combines the use of formal methods widely recognized in software engineering and synthesis procedures developed within the framework of the Supervisory Control Theory for discrete event systems. It promotes design exploration by means of a synthesis approach with the sole aim of producing reliable reactive systems. The adoption of these particular synthesis procedures is, however, not sufficient to achieve this objective, because of scalability and computational complexity issues. To circumvent these difficulties, this paper suggests two extensions with respect to conventional synthesis procedures. The first one concerns the representation of reactive programs by attributed controllers. This requires that the process to be controlled must be described not only in terms of controllable active components but also in terms of uncontrollable passive components by using timed transition graphs and algebraic specifications, respectively. The second one involves abstraction and equational reasoning to take into account the use of strongly typed objects. This requires various kinds of transformation applied to the original problem specification as well as to intermediate solutions.","Reactive systems, Synthesis procedures, Algebraic specifications, Abstraction techniques","Artificial and Computational Intelligence for Decisions, Control, and Automation in Engineering and Industrial Applications",,,,,,,,,,,,,,,,,,,,
Journal Article,"Uwe N,Prakash P",,"Preface: Volume 68, Issue 2",Electronic Notes in Theoretical Computer Science,2002,68,2,1-2,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105803585;http://dx.doi.org/10.1016/S1571-0661(05)80358-5,10.1016/S1571-0661(05)80358-5,"The EXPRESS workshops aim at bringing together researchers interested in the relations between various formal systems, particularly in the field of Concurrency. More specifically, they focus on the comparison between programming concepts (such as concurrent, functional, imperative, logic and object-oriented programming) and between mathematical models of computation (such as process algebras, Petri nets, event structures, modal logics, rewrite systems etc.) on the basis of their relative expressive power. For online-information see http://express02.epfl.ch/. The EXPRESS workshops were originally held as meetings of the HCM project EXPRESS, which was active with the same focus from January 1994 till December 1997. The first three workshops were held respectively in Amsterdam (1994, chaired by Frits Vaandrager), Tarquinia (1995, chaired by Rocco De Nicola), and Dagstuhl (1996, co-chaired by Ursula Goltz and Rocco De Nicola). The workshop in 1997, which took place in Santa Margherita Ligure and was co-chaired by Catuscia Palamidessi and Joachim Parrow, was organized as a conference with a call for papers and a significant attendance from outside the project. The 1998 workshop was held as a satellite workshop of the CONCUR'98 conference in Nice, co-chaired by Ilaria Castellani and Catuscia Palamidessi, and like on that occasion EXPRESS'99 was hosted by the CONCUR'99 conference in Eindhoven, co-chaired by Ilaria Castellani and Björn Victor. The EXPRESS'00 workshop was held as a satellite workshop of CONCUR 2000, Pennsylvania State University, USA, co-chaired by Luca Aceto and Björn Victor. The EXPRESS'01 workshop was held at BRICS, Aalborg University as a satellite of CONCUR'01 and was co-chaired by Luca Aceto and Prakash Panangaden. In addition to the nine accepted (out of 30 submitted) papers presented at the workshop, this collection also contains the abstracts of the two invited talks by Catuscia Palamidessi and Igor Walukiewicz. We would like to thank the authors of the submitted papers, the invited speakers, and the members of the program committee for their contribution to both the meeting and this volume. We also would like to thank EPFL for the printing and Michael Mislove and Simon Kramer for his help with the editing of the preliminary proceedings, the CONCUR organizing committee at Brno University for hosting EXPRESS'02, especially the workshop coordinator Antonín Kucera for further local organization. EXPRESS'02 Programme Committee Martin Berger (U. London, UK), Alan Jeffrey (DePaul U., USA), Barbara König (TU München, DE), Francois Laroussinie (ENS Cachan, FR), James Leifer (INRIA Rocquencourt, FR), Massimo Merro (EPFL, CH), Faron Moller (U. Wales, Swansea, UK), Uwe Nestmann (EPFL, CH), Prakash Panangaden (McGill U., CA), Arend Rensink (U. Twente, NL), Peter Sewell (U. Cambridge, UK), Gianluigi Zavattaro (U. Bologna, IT), EXPRESS'02 Additional Referees Luca Aceto, Alessandro Aldini, Paolo Baldan, Paolo Ballarini, Béatrice Bérard, Henrik Bohnenkamp, Alexandre Boisseau, Mario Bravetti, Roberto Bruni, Marzia Buscemi, Nadia Busi, Didier Caucal, Vincent Cremet, Silvano Dal-Zilio, Vincent Danos, Stéphane Demri, Simon Gay, Daniel Hirschkoff, Michael Huth, Ole Høgh Jensen, Astrid Kiehn, Huimin Lin, Sergio Maffeis, Monika Maidl, Nicolas Markey, Fabio Martinelli, Robin Milner, Francesco Zappa Nardelli, Mikkel Nygaard, Martin Otto, Laure Petrucci, Carla Piazza, Jorge Sousa Pinto, Rosario Pugliese, Marina Ribaudo, Christine Röckl, Stefan Römer, Alan Schmitt, Philippe Schnoebelen, Stefan Schwoon, Martin Steffen, Simone Tini, Björn Victor, Walter Vogler, Heike Wehrheim, Lucian Wischik, Pascal Zimmer.",,"EXPRESS'02, 9th International Workshop on Expressiveness in Concurrency (Satellite Workshop of CONCUR 2002)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Giacobazzi R,Debray SK,Levi G",,Generalized semantics and abstract interpretation for constraint logic programs,The Journal of Logic Programming,1995,25,3,191-247,,,,,1995,,0743-1066,https://www.sciencedirect.com/science/article/pii/0743106695000380;http://dx.doi.org/10.1016/0743-1066(95)00038-0,10.1016/0743-1066(95)00038-0,"We present simple and powerful generalized algebraic semantics for constraint logic programs that are parameterized with respect to the underlying constraint system. The idea is to abstract away from standard semantic objects by focusing on the general properties of any—possibly nonstandard—semantic definition. In constraint logic programming, this corresponds to a suitable definition of the constraint system supporting the semantic definition. An algebraic structure is introduced to formalize the notion of a constraint system, thus making classical mathematical results applicable. Both top-down and bottom-up semantics are considered. Nonstandard semantics for constraint logic programs can then be formally specified using the same techniques used to define standard semantics. Different nonstandard semantics for constraint logic languages can be specified in this framework. In particular, abstract interpretation of constraint logic programs can be viewed as an instance of the constraint logic programming framework itself.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Calixto M,,Generalized W∞ higher-spin algebras and symbolic calculus on flag manifolds,Journal of Geometry and Physics,2006,56,2,143-174,,,,,2006,,0393-0440,https://www.sciencedirect.com/science/article/pii/S0393044005000045;http://dx.doi.org/10.1016/j.geomphys.2005.01.003,10.1016/j.geomphys.2005.01.003,"We study a new class of infinite-dimensional Lie algebras W∞(N+,N−) generalizing the standard W∞ algebra, viewed as a tensor operator algebra of SU(1,1) in a group-theoretic framework. Here we interpret W∞(N+,N−) either as an infinite continuation of the pseudo-unitary symmetry U(N+,N−), or as a “higher-U(N+,N−)-spin extension” of the diffeomorphism algebra diff(N+,N−) of the N=N++N− torus U(1)N. We highlight this higher-spin structure of W∞(N+,N−) by developing the representation theory of U(N+,N−) (discrete series), calculating higher-spin representations, coherent states and deriving Kähler structures on flag manifolds. They are essential ingredients to define operator symbols and to infer a geometric pathway between these generalized W∞ symmetries and algebras of symbols of U(N+,N−)-tensor operators. Classical limits (Poisson brackets on flag manifolds) and quantum (Moyal) deformations are also discussed. As potential applications, we comment on the formulation of diffeomorphism-invariant gauge field theories, like gauge theories of higher-extended objects, and non-linear sigma models on flag manifolds.","Infinite-dimensional Lie algebras, Virasoro and symmetries, Berezin and geometric quantization, Coherent states, Operator symbols, Classical limit, Poisson bracket, Coadjoint orbit, Quantum (Moyal) deformations, Diffeomorphism invariant QFT",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Myhill J,"Kino A,Myhill J,Vesley RE",Formal Systems of Intuitionistic Analysis II: The Theory of Species,,1970,60,,151-162,,Elsevier,,Intuitionism and Proof Theory: Proceedings of the Summer Conference at Buffalo N.Y. 1968,1970,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X0870747X;http://dx.doi.org/10.1016/S0049-237X(08)70747-X,10.1016/S0049-237X(08)70747-X,"Publisher Summary This chapter discusses the formal systems of intuitionistic analysis and presents a formal description of the system. An axiom system for the elementary part of intuitionistic analysis, that is, the theory of natural numbers, computable functions and free-choice sequences, has been proposed. It has been proved that the restriction on continuity is not an ad hoc one to avoid contradiction. The law-like objects of any type are a detachable subspecies of that type, and the mathematical objects are a detachable subspecies of the law-like one. A few other additions are made to the original system and there is also a problem about law-like. Certain primitive recursive functionals of specified type also appear in the axioms.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Chakravarty MM,Lock HC",,Towards the uniform implementation of declarative languages,Computer Languages,1997,23,2,121-160,,,,,1997,,0096-0551,https://www.sciencedirect.com/science/article/pii/S009605519700012X;http://dx.doi.org/10.1016/S0096-0551(97)00012-X,10.1016/S0096-0551(97)00012-X,"Current implementation techniques for functional languages differ considerably from those for logic languages. This complicates the development of flexible and efficient abstract machines that can be used for the compilation of declarative languages combining concepts of functional and logic programming. We propose an abstract machine, called the JUMP-machine, which systematically integrates the operational concepts needed to implement the functional and logic programming paradigm. The use of a tagless representation for heap objects, which originates from the Spineless Tagless G-machine, supports the integration of different concepts. In this paper, we provide a functional logic kernel language and show how to translate it into the abstract machine language of the JUMP-machine. Furthermore, we define the operational semantics of the machine language formally and discuss the mapping of the abstract machine to concrete machine architectures. We tested the approach by writing a compiler for the functional logic language GTML. The obtained performance results indicate that the proposed method allows to implement functional logic languages efficiently.","logic programming, functional programming, abstract machine",ICLP'94,,,,,,,,,,,,,,,,,,,,
Journal Article,Voevudsky VP,,Convergence of regularized spline approximants to solutions of initial and boundary value problems for ODE,Journal of Computational and Applied Mathematics,1995,58,1,55-66,,,,,1995,,0377-0427,https://www.sciencedirect.com/science/article/pii/0377042793E0267P;http://dx.doi.org/10.1016/0377-0427(93)E0267-P,10.1016/0377-0427(93)E0267-P,"Spline collocation has been known for some time as a very suitable numerical method in solving linear initial and boundary value problems for ODE (Voevudsky, 1989). In those cases, however, when the right-hand side of the equation, given on a discrete mesh, includes errors, the method for spline collocation becomes rather unstable with respect to the errors. The object of the present paper is to investigate the convergence of an approximate solution defined as a minimizer of Tikhonov-like regularizer. All results presented in this paper are valid both for initial value problems and, with slight modifications, for boundary value problems with zero boundary conditions; but we have chosen an initial value problem of the first order to simplify our considerations. It is shown that the spline approximant exists for any mesh and for any positive value of the regularization parameter and that it converges to the solution of the initial value problem if an appropriate regularization parameter is chosen. We have made use of some ideas of Ragozin (1983).","Noisy data, Smoothing, Regularization, Calculus of variations, Maximal defect spline, Band matrix",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee CK,Wong SP",,A fuzzy approach to determine morphological thinning algorithms for fast removal of unwanted skeletal legs,Engineering Applications of Artificial Intelligence,1995,8,3,281-298,,,,,1995,,0952-1976,https://www.sciencedirect.com/science/article/pii/095219769500008O;http://dx.doi.org/10.1016/0952-1976(95)00008-O,10.1016/0952-1976(95)00008-O,"Thinning algorithms based on morphological hit/miss transforms are good at extracting the skeletons of closed-loop objects in noisy images. However, many skeletal legs are generated usually with unnecessary lengths, and the removal requires much time. This paper investigates fast removal algorithms, and provides a formal performance analysis for algorithms with different arrangements of leg shortening (trimming) templates. First, the use of three algorithms is compared for different image conditions based on probability analysis. Second, to obtain prior information to determine the fastest algorithm, a reduced image is used. Finally, based on this information, a fuzzy-logic approach is used to determine the arrangement of templates. Also, procedures are proposed to form fuzzification functions for the leg properties. An illustration of applying this fuzzy inference mechanism to real-scene images is also included.","Thinning, skeletal legs, mathematical morphology, fuzzy logic, inference",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Kierstead DP,"Barwise J,Keisler HJ,Kunen K",A Semantics for Kleene's j-expressions,,1980,101,,353-366,,Elsevier,,The Kleene Symposium,1980,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08712680;http://dx.doi.org/10.1016/S0049-237X(08)71268-0,10.1016/S0049-237X(08)71268-0,"S. C. Kleene (Generalized Recursion Theory II, edited by J. E. Fenstad et al. (North-Holland, Amsterdam)) proposed a system for computation in higher types which was based on the syntactic manipulation of formal symbols, called j-expressions. No adequate semantics for these expressions could be based on the classical (total) type structure over N. In particular, not all j-expressions corresponded to objects of type j, and two j-expressions corresponding to the same object could not necessarily be substituted for each other in other j-expressions without altering their meaning. In this paper we provide a semantics which eliminates these problems. The type structure for this semantics is obtained by adding one extra object at type 0 and, at type (j + 1), allowing all monotone, partial functions from type j into N. The original type structure is embeddable into the extended type structure in a manner which preserves Kleene's computations.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Cirstea H,Kirchner C,Kopetz R,Moreau PE",,Anti-patterns for rule-based languages,Journal of Symbolic Computation,2010,45,5,523-550,,,,,2010,,0747-7171,https://www.sciencedirect.com/science/article/pii/S0747717110000155;http://dx.doi.org/10.1016/j.jsc.2010.01.007,10.1016/j.jsc.2010.01.007,"Negation is intrinsic to human thinking and most of the time when searching for something, we base our patterns on both positive and negative conditions. This should be naturally reflected in software that provide pattern-based searches. We would like for example to specify that we search for white cars that are not station wagons, or that we search for a list of objects that does not contain two identical elements. In this paper we extend the notion of pattern to the one of anti-pattern, i.e. patterns that may contain complement symbols. This concept is appropriate to design powerful extensions to pattern-based programming languages like Ml, Asf+Sdf, Stratego, Maude, Elan or Tom and we show how this is used to extend the expressiveness and usability of the Tom language. We further define formally the semantics of anti-patterns both in the syntactic case, i.e. when the symbols have no specific theory associated, and modulo an arbitrary equational theory E. We then extend the classical notion of matching between patterns and ground terms to matching between anti-patterns and ground terms. Solving such problems can be performed either using general techniques as disunification, which we exemplify in the syntactical case, or more tailored and efficient approaches, which we chose to illustrate on the specific and very useful case of associativity, possibly with a unity. This allows us to be generic enough to give in this framework a very simple and natural expression of, for instance, the AllDiff standard predicate of constraint programming.","Pattern matching, List matching, Complement problem, Equational problem, Anti-pattern, Disunification, Associativity, Equational theory, Rule-based language, Pattern-based language",Symbolic Computation in Software Science,,,,,,,,,,,,,,,,,,,,
Journal Article,"Caianiello ER,Gisolfi A,Vitulano S",,A technique for texture analysis using C-Calculus,Signal Processing,1979,1,2,159-173,,,,,1979,,0165-1684,https://www.sciencedirect.com/science/article/pii/0165168479900173;http://dx.doi.org/10.1016/0165-1684(79)90017-3,10.1016/0165-1684(79)90017-3,"Based on C-Calculus, a method for analysis and classification of textures is described. Concepts of C-Space and C-Transform are briefly discussed. Applications of C-Filter for filtering patterns with more than one texture, or with textured objects on a textured background are described. Some direct experimental results are also given. Zusammenfassung In diesem Artikel wird eine Methode zur Analyse und Classifizierung von Texturen, basiert auf “C-Calculus”, vorgestellt. Die Konzepte von “C-Space” und “C-Transform” eines diskretisierten Bildes werden, wenn auch in einfacher Art, erklärt. Eine Filtrierungsmethode, das “C-Filtering”, wird präsentiert. Anwendungen dieser Methode auf Bilder die mehr als eine Textur enthalten, oder einne Grudtextur und einige Gegenstände, die eigene Textur besitzen, werden beschrieben. Schliesslich werden verschiedene experimentale Ergebnisse vorgestellt. Résumé Cet article présente une méthode d'analyse et de classification des textures, basée sur le “C-Calculus”. Nous décrivons, d'une maniére simple, les notions de “C-Space” et de “C-Transform” d'une image numérisée. Nous présentons ensuite une méthode de filtrage appelée “C-Filtering”, appliquée à des images qui contiennent plus d'une texture ou des objets texturés sur un fond texturé. Finalement nous concluons avec divers résultats expérimentaux.","C-Calculus, C-Filter, C-Space, C-Transform",,,,,,,,,,,,,,,,,,,,,
Journal Article,Zarri GP,,The “descriptive” component of a hybrid knowledge representation language,Computers & Mathematics with Applications,1992,23,6,697-718,,,,,1992,,0898-1221,https://www.sciencedirect.com/science/article/pii/089812219290130A;http://dx.doi.org/10.1016/0898-1221(92)90130-A,10.1016/0898-1221(92)90130-A,"We describe one component of a “hybrid” Knowledge Representation Language (KRL) used for the development of Large Knowledge Bases (LKBs). This hybrid language involves two different aspects, the “descriptive” and the “definitional”. The representation of the elementary events occurring in the real world (descriptive data = “Snoopy is Charlie Brown's beagle”) is organized around “semantic predicates” (with “roles” and “arguments”); this gives rise to units called “predicative occurrences”. The single predicative occurrences can be combined using logical, causal etc., relationships, giving rise to complex conceptual constructions (“binding occurrences”). “Abstract” conceptual units (“templates”) which describe the expected properties of the “concrete” predicative and binding occurrences are placed in a specialization hierarchy (H_TEMP) characterized by the inheritance of properties and behaviours; the concrete “occurrences” constitute the “leaves” of this hierarchy. On the other hand, the “classes” representing the “general categories” of all the basic entities of the application domain which appear in the predicative occurrences are defined in terms of their own specialization hierarchy, H_CLASS (this is definitional data = “A beagle is a sort of hound / a hound is a dog … ”); the concrete “instances” of the defined classes are the “leaves” of this second hierarchy. The “definitional component” is not discussed in this article. The main difference between this KRL and other recent “hybrid” languages is that the “descriptive component” is not a first order predicate calculus language, but a highly structured semantic network.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Waelbroeck L,Barroso JA,The Category of Quotient Bornological Spaces,,1986,34,,873-894,,Elsevier,,Aspects of Mathematics and its Applications,1986,,0924-6509,https://www.sciencedirect.com/science/article/pii/S0924650909702971;http://dx.doi.org/10.1016/S0924-6509(09)70297-1,10.1016/S0924-6509(09)70297-1,"Publisher Summary This chapter discusses the category of quotient bornological spaces. The chapter consists of an abelian category. The objects are formal quotients of b-spaces. The chapter proves that the morphism has a kernel, a cokernel, and is such that the natural morphism of the cokernel of the kernel into the kernel of the cokernel is an isomorphism. The chapter also defines multilinear mappings in the category q by placing a q structure on the vector space. Every q-space is isomorphic to a standard one and every morphism can be replaced by a strict one. The chapter also proves that the category q is an abelian.",,,North-Holland Mathematical Library,,,,,,,,,,,,,,,,,,,
Journal Article,"Kent RE,Neuss C",,Creating a web analysis and visualization environment,Computer Networks and ISDN Systems,1995,28,1,109-117,,,,,1995,,0169-7552,https://www.sciencedirect.com/science/article/pii/016975529500095X;http://dx.doi.org/10.1016/0169-7552(95)00095-X,10.1016/0169-7552(95)00095-X,"Due to the rapid growth of the World-Wide Web, resource discovery has become an increasing problem. As an answer to the demand for information management, a third generation of World-Wide Web tools will evolve: Information gathering and processing agents. This paper describes WAVE (Web Analysis and Visualization Environment), a 3D interface for World-Wide Web information visualization and browsing. It uses the mathematical theory of concept analysis to conceptually cluster objects. So-called “conceptual scales” for attributes, such as location, title, keywords, topic, size, or modification time, provide a formal mechanism that automatically classifies and categorizes documents, creating a conceptual information space. A visualization shell serves as an ergonomically sound user interface for exploring this information space.","Indexing, Resource discovery, Concept analysis",Selected Papers from the Second World-Wide Web Conference,,,,,,,,,,,,,,,,,,,,
Journal Article,Freedman D,,From Association to Causation via Regression,Advances in Applied Mathematics,1997,18,1,59-110,,,,,1997,,0196-8858,https://www.sciencedirect.com/science/article/pii/S0196885896905011;http://dx.doi.org/10.1006/aama.1996.0501,10.1006/aama.1996.0501,"For nearly a century, investigators in the social sciences have used regression models to deduce cause-and-effect relationships from patterns of association. Path models and automated search procedures are more recent developments. In my view, this enterprise has not been successful. The models tend to neglect the difficulties in establishing causal relations, and the mathematical complexities tend to obscure rather than clarify the assumptions on which the analysis is based. Formal statistical inference is, by its nature, conditional. If maintained hypotheses A,B,C,… hold, then H can be tested against the data. However, if A,B,C,… remain in doubt, so must inferences about H. Careful scrutiny of maintained hypotheses should therefore be a critical part of empirical work—a principle honored more often in the breach than the observance. This paper focuses on modeling techniques that seem to convert association into causation. The object is to clarify the differences among the various uses of regression, as well as the source of the difficulty in making causal inferences by modeling. The discussion will proceed mainly by examples, ranging from71to63.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Nessel J,Lange S",,Learning erasing pattern languages with queries,Theoretical Computer Science,2005,348,1,41-57,,,,,2005,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397505005232;http://dx.doi.org/10.1016/j.tcs.2005.09.001,10.1016/j.tcs.2005.09.001,"A pattern is a finite string of constant and variable symbols. The non-erasing language generated by a pattern is the set of all strings of constant symbols that can be obtained by substituting non-empty strings for variables. In order to build the erasing language generated by a pattern, it is also admissible to substitute the empty string. The present paper deals with the problem of learning erasing pattern languages within Angluin's model of learning with queries. Moreover, the learnability of erasing pattern languages with queries is studied when additional information is available. The results obtained are compared with previously known results in case non-erasing pattern languages have to be learned. First, when regular pattern languages have to be learned, it is shown that the learnability results for the non-erasing case remain valid, if the proper superclass of all erasing regular pattern languages is the object of learning. Second, in the general case, serious differences have been observed. For instance, it turns out that arbitrary erasing pattern languages cannot be learned in settings in which, in the non-erasing case, even polynomially many queries will suffice.","Formal language theory, Algorithmic learning, Query inference",Algorithmic Learning Theory (ALT 2000),,,,,,,,,,,,,,,,,,,,
Journal Article,"Choppella V,Haynes CT",,Source-tracking unification,Information and Computation,2005,201,2,121-159,,,,,2005,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540105000878;http://dx.doi.org/10.1016/j.ic.2004.10.013,10.1016/j.ic.2004.10.013,"We propose a path-based framework for deriving and simplifying source-tracking information for first-order term unification in the empty theory. Such a framework is useful for diagnosing unification-based systems, including debugging of type errors in programs and the generation of success and failure proofs in logic programming. The objects of source-tracking are deductions in the logic of term unification. The semantics of deductions are paths over a unification graph whose labels form the suffix language of a semi-Dyck set. Based on this idea of unification paths, two algorithms for generating proofs are presented: the first uses context-free labeled shortest-path algorithms to generate optimal (shortest) proofs in time O(n3) for a fixed signature, where n is the number of vertices of the unification graph. The second algorithm integrates easily with standard unification algorithms, entailing an overhead of only a constant factor, but generates non-optimal proofs. These non-optimal proofs may be further simplified by group rewrite rules.","Algorithms, Debugging, Formal languages, Graph theory, Logic programming, Path problems, Term unification, Type inference",,,,,,,,,,,,,,,,,,,,,
Journal Article,McIntosh BS,,Qualitative modelling with imprecise ecological knowledge: a framework for simulation,Environmental Modelling & Software,2003,18,4,295-307,,,,,2003,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815203000021;http://dx.doi.org/10.1016/S1364-8152(03)00002-1,10.1016/S1364-8152(03)00002-1,"Ecological understanding is often imprecise and heterogeneous; relationships between different quantities and objects may only be expressed in roughly quantitative or even non-quantitative terms. We argue that there is a need for general time-driven simulation modelling systems capable of utilising these types of understanding, using vegetation dynamics as an example. Although work has gone into developing qualitative models in the past, it has not focussed on the needs of time-driven simulation and there is currently no off-the-shelf solution available. This paper presents a categorisation of the types of knowledge that comprise formal models, then uses the categorisation as the basis for exploring and developing a framework for time-driven simulation modelling with imprecise, heterogeneous knowledge. One of the key concepts presented is the explicit separation of all non-quantitative state variable values from their direction and rate of change. From this concept a general computational method is developed for updating non-quantitative state variables in time-driven simulation. First-order logic is advocated as a suitable representational vehicle and a modelling system that implements the proposed framework is briefly presented. We believe that the framework provides a useful step towards increasing the practical utility of available knowledge.","Functional attributes, Imprecise knowledge, Modelling systems, Qualitative modelling, Simulation, Support sets, Vegetation dynamics",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Zadeh LA,"Zadeh LA,Fu KS,Tanaka K,Shimura M",CALCULUS OF FUZZY RESTRICTIONS,,1975,,,1-39,,Academic Press,,Fuzzy Sets and their Applications to Cognitive and Decision Processes,1975,9780127752600,,https://www.sciencedirect.com/science/article/pii/B9780127752600500062;http://dx.doi.org/10.1016/B978-0-12-775260-0.50006-2,10.1016/B978-0-12-775260-0.50006-2,"ABSTRACT A fuzzy restriction may be visualized as an elastic constraint on the values that may be assigned to a variable. In terms of such restrictions, the meaning of a proposition of the form “x is P,” where x is the name of an object and P is a fuzzy set, may be expressed as a relational assignment equation of the form R(A(x)) = P, where A(x) is an implied attribute of x, R is a fuzzy restriction on x, and P is the unary fuzzy relation which is assigned to R. For example, “Stella is young,” where young is a fuzzy subset of the real line, translates into R(Age(Stella))= young. The calculus of fuzzy restrictions is concerned, in the main, with (a) translation of propositions of various types into relational assignment equations, and (b) the study of transformations of fuzzy restrictions which are induced by linguistic modifiers, truth-functional modifiers, compositions, projections and other operations. An important application of the calculus of fuzzy restrictions relates to what might be called approximate reasoning, that is, a type of reasoning which is neither very exact nor very inexact. The main ideas behind this application are outlined and illustrated by examples.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bernauer J,,Analysis of part-whole relation and subsumption in the medical domain,Data & Knowledge Engineering,1996,20,3,405-415,,,,,1996,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X9600016X;http://dx.doi.org/10.1016/S0169-023X(96)00016-X,10.1016/S0169-023X(96)00016-X,"The part-whole relation has significant effect on classification in the medical domain, since diagnoses, medical procedures and findings commonly relate to anatomical objects and their parts. The paper analyses conventional medical terminology and classification systems with respect to part-whole relations, it investigates how languages of the KL-ONE-family approach the complexity of part-whole relation and subsumption, and it outlines recent developments in medical concept representation. Conventional systems used for medical documentation, indexing of clinical data or bibliographical retrieval are weak for several reasons. Partitive and generic relations are often incompletely represented and both relations are often mixed. This is due to the common combination of a concept system with a coding schema, which often constrains the hierarchical organization of concepts. Terminological languages in the tradition of KL-ONE approach the part-whole relation by different ways: Partly, they use the transitivity of subsumption for representing the transitivity of part-whole. On the other hand, there are arguments for keeping the part-whole relation outside the classifier and for modelling the effect of part-whole on subsumption in the axiomatic component of a terminological reasoning system. GRAIL and BERNWARD are approaches which focus on formal concept representation in the medical domain. GRAIL considers part-whole relations by the classifier and allows for the specification of roles to be refinable along partitive criteria. BERNWARD is based on conceptual graphs and follows a different approach. The transitivity of part-whole is represented by explicit ordering of concepts through a partonomy and by transitive chaining of part-of roles in composite concept descriptions. Both approaches allow for partitive nesting in concept representation and consider the effect of partitive attributes on subsumption by the classifier, but lack a deeper theory of the part-whole relation.","Subsumption, Part-whole, Bodyparts, Formal concept representation, Medical terminology",Modeling Parts and Wholes,,,,,,,,,,,,,,,,,,,,
Journal Article,"Didier G,Remy E",,Relations between gene regulatory networks and cell dynamics in Boolean models,Discrete Applied Mathematics,2012,160,15,2147-2157,,,,,2012,,0166-218X,https://www.sciencedirect.com/science/article/pii/S0166218X12002168;http://dx.doi.org/10.1016/j.dam.2012.05.010,10.1016/j.dam.2012.05.010,"An asynchronous Boolean dynamics to some extent represents the joint evolution of a system of Boolean-discretized variables. In a biological context, these kinds of objects are used to model the evolution of the gene expression levels. With such a dynamics, one can associate a (genetic) regulatory graph summarizing the influence of each variable on the others. The first of Thomas’s rules, formally proved in particular in the asynchronous Boolean framework, states that the presence of several stationary states in a dynamics arises only if the corresponding regulatory graph contains a positive feedback loop. In the present work, we first give a necessary condition for the presence of a single stationary state in a dynamics and next derive a necessary condition for multistationarity which is slightly stronger than that required in the first of Thomas’s rules. Next, we reverse the approach and study the properties of dynamics corresponding to a particular class of regulatory graphs, that are made up of several circuits sharing a common component. We prove that the corresponding dynamics contains at most two stationary states and give more specific results for when the regulatory graphs contain less than two positive (resp. negative) circuits. Moreover, we show that the behavior of a dynamics cannot be predicted if its regulatory graph contains both at least two positive circuits and two negative circuits (all sharing a common component). In particular, it may contain zero, one or two stationary states.","Dynamical systems, Boolean networks, Gene regulatory graphs, Genetic regulation, Thomas’s rules",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bauer A,Birkedal L,Scott DS",,Equilogical spaces,Theoretical Computer Science,2004,315,1,35-59,,,,,2004,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397503006169;http://dx.doi.org/10.1016/j.tcs.2003.11.012,10.1016/j.tcs.2003.11.012,"It is well known that one can build models of full higher-order dependent-type theory (also called the calculus of constructions) using partial equivalence relations (PERs) and assemblies over a partial combinatory algebra. But the idea of categories of PERs and ERs (total equivalence relations) can be applied to other structures as well. In particular, we can easily define the category of ERs and equivalence-preserving continuous mappings over the standard category Top0 of topological T0-spaces; we call these spaces (a topological space together with an ER) equilogical spaces and the resulting category Equ. We show that this category—in contradistinction to Top0—is a cartesian closed category. The direct proof outlined here uses the equivalence of the category Equ to the category PEqu of PERs over algebraic lattices (a full subcategory of Top0 that is well known to be cartesian closed from domain theory). In another paper with Carboni and Rosolini (cited herein), a more abstract categorical generalization shows why many such categories are cartesian closed. The category Equ obviously contains Top0 as a full subcategory, and it naturally contains many other well known subcategories. In particular, we show why, as a consequence of work of Ershov, Berger, and others, the Kleene–Kreisel hierarchy of countable functionals of finite types can be naturally constructed in Equ from the natural numbers object N by repeated use in Equ of exponentiation and binary products. We also develop for Equ notions of modest sets (a category equivalent to Equ) and assemblies to explain why a model of dependent type theory is obtained. We make some comparisons of this model to other, known models.","Domain theory, Topology, Logic, Type theory, Realizability",Mathematical Foundations of Programming Semantics,,,,,,,,,,,,,,,,,,,,
Journal Article,"Briand LC,Labiche Y,O’Sullivan L,Sówka MM",,Automated impact analysis of UML models,Journal of Systems and Software,2006,79,3,339-352,,,,,2006,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412120500097X;http://dx.doi.org/10.1016/j.jss.2005.05.001,10.1016/j.jss.2005.05.001,"The use of Unified Modeling Language (UML) analysis/design models on large projects leads to a large number of interdependent UML diagrams. As software systems evolve, UML diagrams undergo changes that address error corrections and changed requirements. Those changes can in turn lead to subsequent changes to other elements in the UML diagrams. Impact analysis is defined as the process of identifying the potential consequences (side-effects) of a change, and estimating what needs to be modified to accomplish that change. In this article, we propose a UML model-based approach to impact analysis that can be applied before implementation of changes, thus allowing early decision-making and change planning. We first verify that the UML diagrams in a design model are consistent. Then the changes between two different versions of UML models are automatically identified according to a change taxonomy. Next, model elements which are directly or indirectly impacted by the changes (i.e., may undergo changes) are determined using formally defined impact analysis rules (defined with the Object Constraint Language). A measure of distance between a changed element and potentially impacted elements is also proposed to prioritize the results of impact analysis according to their likelihood of occurrence. We also present a prototype tool that provides automated support for our impact analysis strategy, and two case studies that validate both the methodology and the tool. Empirical results confirm that distance helps determine the likelihood of change in the code.","Impact analysis, UML, Design",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Albertos P,Morant F,la Puente JA,Crespo A",,COMO: A Modula-2 Program for Real-Time Control of a Raw Material Mill,IFAC Proceedings Volumes,1986,19,6,101-107,,,,,1986,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017597311;http://dx.doi.org/10.1016/S1474-6670(17)59731-1,10.1016/S1474-6670(17)59731-1,"A computer program for real-time computer control of a mill process in a cement plant is described. The purpose of the process is to blend and mill raw materials in adequate proportions so that slurry, the resulting product, has the required composition. The program has been developed from a formal specification, using an object-based methodology and the Modula-2 programming language. The complete system consists of a structured collection of tasks and monitors. Simulation and preliminary plant results are presented.","Computer control, cement industry, computer programming, programming languages, Modula-2, adaptive control","4th IFAC/IFIP Symposium on Software for Computer Control 1986, Graz, Austria, 20-23 May 1986",,,,,,,,,,,,,,,,,,,,
Journal Article,Dolby JL,,On the notions of ambiguity and information loss,Information Processing & Management,1977,13,1,69-77,,,,,1977,,0306-4573,https://www.sciencedirect.com/science/article/pii/0306457377900322;http://dx.doi.org/10.1016/0306-4573(77)90032-2,10.1016/0306-4573(77)90032-2,"One of the fundamental problems in information science is to distinguish various objects (such as books or journal articles) on the basis of associated values (such as authors and titles). Where the values fail to distinguish two distinct objects we say that the objects are ambigious under the given value assignment. To obtain a measure of ambiguity, it is only necessary to count the number of ways that the objects can be arranged for each set of ambiguous objects, multiply these counts and take logarithms. It is shown that such an approach leads to a measure in the formal sense and that the measure depends only on the definition of equality of values so that it can be simply extended to sets of values and ordered sets of values. It is also shown that it is possible to construct a function of ambiguity that one can call “information” and that the information loss that occurs when distinct values are grouped into equivalence classes (as in the use of search and sort keys) is also a measure. Finally, it is shown that ambiguity and information as here defined are directly related to Shannon's definition of “information” thus tieing this approach to that portion of information theory associated with the derivation of optimal distributions frequently used in information science models.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Günther H,,On the geometrical approach to the theory of structural defects,International Journal of Engineering Science,1981,19,12,1799-1807,,,,,1981,,0020-7225,https://www.sciencedirect.com/science/article/pii/0020722581901701;http://dx.doi.org/10.1016/0020-7225(81)90170-1,10.1016/0020-7225(81)90170-1,"Subject of consideration is the theory of structural defects for a general continuum. It is shown, that this theory, including time-depending processes, consequently has to be a 4-dimensional one. The origin for this 4-dimensionality is the underlying mechanically defined manifold, whereas for the 4-dimensional Minkowski metric, introduced later for the description of deformation, the distinguished signal velocity c is a redundant quantity. Though the geometrical equations for all continua, cristals, line structures or any others, formally are identically, their physical content may be very different, since the interpretation for all components of the mechanically defined geometrical objects essentially depends on the medium itself. However, only the spatial components of the 4-dimensional geometrical objects will be affected. That means, given a well defined static theory for a certain kind of material, kinematics and dynamics are coming out from geometrical theory. Three-dimensional points lattices as well as line structures are examples.",,Dedicated to Prof. K. Kondo on the occassion of his seventieth birthday,,,,,,,,,,,,,,,,,,,,
Book Chapter,Halpin T,Halpin T,8 - Entity-Relationship Modeling,,2001,,,313-348,,Academic Press,San Diego,Information Modeling and Relational Databases,2001,9781558606722,,https://www.sciencedirect.com/science/article/pii/B9781558606722500117;http://dx.doi.org/10.1016/B978-155860672-2/50011-7,10.1016/B978-155860672-2/50011-7,"Publisher Summary Entity-relationship (ER) modeling approach views an application domain in terms of entities that have attributes and participate in relationships. Of the dozens different ER versions in existence, the most widely used are the Barker notation and Information Engineering (IE). The popular IDEF1X approach is often referred to as a version of ER, but is actually a mixture of ER and relational approaches, with an emphasis on the relational approach. In the Information Engineering approach, entity types are displayed as named rectangles with a list of attributes. IDEF1X models may be viewed at three levels. An entity type may be classified into one or more clusters of mutually exclusive categories. Subtype links are depicted as categorization relationships with a circle at the supertype end. The cluster is incomplete or complete according to whether the circle has a single underline or double underlines, respectively. ER or IDEF1X models are best developed by mapping them from object-role modeling (ORM) models and noting any additional ORM constraints as comments.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,"Herlihy MP,Weihl WE",,Hybrid concurrency control for abstract data types,Journal of Computer and System Sciences,1991,43,1,25-61,,,,,1991,,0022-0000,https://www.sciencedirect.com/science/article/pii/002200009190031Y;http://dx.doi.org/10.1016/0022-0000(91)90031-Y,10.1016/0022-0000(91)90031-Y,"Databases and other transaction-processing systems use concurrency control and recovery algorithms to ensure that transactions are atomic (i.e., serializable and recoverable). We present a new algorithm based on locking that permits more concurrency than existing commutativity-based algorithms. The algorithm exploits type-specific properties of objects; necessary and sufficient constraints on lock conflicts are derived directly from a data type specification. In addition, the algorithm permits operations to be both partial and non-deterministic, and it permits the lock mode for an operation to be determined by its results as well as its name and arguments. We give a complete formal description of the algorithm, encompassing both concurrency control and recovery, and prove that the algorithm satisfies hybrid atomicity, a local atomicity property that combines aspects of static and dynamic atomic algorithms. We also show that the algorithm is optimal in the sense that no hybrid atomic locking scheme can permit more concurrency.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Knobloch E,,Beyond Cartesian limits: Leibniz's passage from algebraic to “transcendental” mathematics,Historia Mathematica,2006,33,1,113-131,,,,,2006,,0315-0860,https://www.sciencedirect.com/science/article/pii/S0315086004000199;http://dx.doi.org/10.1016/j.hm.2004.02.001,10.1016/j.hm.2004.02.001,"This article deals with Leibniz's reception of Descartes' “geometry.” Leibnizian mathematics was based on five fundamental notions: calculus, characteristic, art of invention, method, and freedom. On the basis of methodological considerations Leibniz criticized Descartes' restriction of geometry to objects that could be given in terms of algebraic (i.e., finite) equations: “Descartes's mind was the limit of science.” The failure of algebra to solve equations of higher degree led Leibniz to develop linear algebra, and the failure of algebra to deal with transcendental problems led him to conceive of a science of the infinite. Hence Leibniz reconstructed the mathematical corpus, created new (transcendental) notions, and redefined known notions (equality, exactness, construction), thus establishing “a veritable complement of algebra for the transcendentals”: infinite equations, i.e., infinite series, became inestimable tools of mathematical research. Zusammenfassung Der Aufsatz behandelt Leibniz' Aufnahme von Descartes' ,,Geometrie“. Die Leibnizsche Mathematik war auf fünf grundlegenden Begriffen aufgebaut: Kalkül, Charakteristik, Erfindungskunst, Methode, Freiheit. Leibniz' methodologische Betrachtungen zogen seine Kritik der cartesischen algebraischen Methoden nach sich, die das Gebiet der Geometrie definierten: ,,Descartes' Geist war die Grenze der Wissenschaft“. Die Unvollkommenheit der Algebra (Lösung algebraischer Gleichungen höheren Grades) ließ Leibniz lineare Algebra entwickeln und eine Wissenschaft des Unendlichen entwerfen. Leibniz baute also das Gebäude der Mathematik neu auf, schuf neue Begriffe (transzendent) und definierte bekannte Begriffe neu (Gleichheit, Genauigkeit, Konstruktion). Auf diese Weise begründete er eine ,,wahre Ergänzung der Algebra für transzendente Größen“: unendliche Gleichungen, das heißt unendliche Reihen, wurden unschätzbare Hilfsmittel der mathematischen Forschung.","Descartes, Leibniz, Linear algebra, Combinatorics, Geometry, Construction, Infinite series",The Origins of Algebra: From al-Khwarizmi to Descartes,,,,,,,,,,,,,,,,,,,,
Journal Article,"Granados A,Hogan SJ,Seara TM",,"The scattering map in two coupled piecewise-smooth systems, with numerical application to rocking blocks",Physica D: Nonlinear Phenomena,2014,269,,1-20,,,,,2014,,0167-2789,https://www.sciencedirect.com/science/article/pii/S0167278913003175;http://dx.doi.org/10.1016/j.physd.2013.11.008,10.1016/j.physd.2013.11.008,"We consider a non-autonomous dynamical system formed by coupling two piecewise-smooth systems in R2 through a non-autonomous periodic perturbation. We study the dynamics around one of the heteroclinic orbits of one of the piecewise-smooth systems. In the unperturbed case, the system possesses two C0 normally hyperbolic invariant manifolds of dimension two with a couple of three dimensional heteroclinic manifolds between them. These heteroclinic manifolds are foliated by heteroclinic connections between C0 tori located at the same energy levels. By means of the impact map we prove the persistence of these objects under perturbation. In addition, we provide sufficient conditions of the existence of transversal heteroclinic intersections through the existence of simple zeros of Melnikov-like functions. The heteroclinic manifolds allow us to define the scattering map, which links asymptotic dynamics in the invariant manifolds through heteroclinic connections. First order properties of this map provide sufficient conditions for the asymptotic dynamics to be located in different energy levels in the perturbed invariant manifolds. Hence we have an essential tool for the construction of a heteroclinic skeleton which, when followed, can lead to the existence of Arnold diffusion: trajectories that, on large time scales, destabilize the system by further accumulating energy. We validate all the theoretical results with detailed numerical computations of a mechanical system with impacts, formed by the linkage of two rocking blocks with a spring.","Arnold diffusion, Piecewise smooth systems, Rocking block",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Leone N,Palopoli L,Romeo M",,A language for updating logic programs and its implementation,The Journal of Logic Programming,1995,23,1,1-61,,,,,1995,,0743-1066,https://www.sciencedirect.com/science/article/pii/0743106694000252;http://dx.doi.org/10.1016/0743-1066(94)00025-2,10.1016/0743-1066(94)00025-2,"This paper proposes an update language, called ULL, for knowledge systems based on logic programming. This language is built upon two basic update operators, respectively denoting insertion and deletion of a positive literal (atom). Thus, simple control structures are defined for combining the basic updates into programs capable of expressing complex updates. The semantics of the update language is centered around the idea of executing a basic update by directly modifying the truth valuation of that (intensionally or extensionally defined) atom which is the object of the update. This modification propagates recursively to the truth valuations of those atoms dependent upon the updated one. The expressive power of this language is discussed, its implementation is studied, and an interpreter is given, which is proven correct w.r.t. the defined formal semantics. The computational complexity of the proposed implementation is also analyzed, showing that the update language interpreter runs efficiently. Finally, three extensions to ULL are discussed. The first allows the programmer to insert and delete rules, the second supports a form of hypothetical reasoning about updates, and the last introduces facilities in the language for the definition and the calling of update procedures.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Mosses PD,Van Leeuwen JAN,CHAPTER 11 - Denotational Semantics,,1990,,,575-631,,Elsevier,Amsterdam,Formal Models and Semantics,1990,9780444880741,,https://www.sciencedirect.com/science/article/pii/B9780444880741500160;http://dx.doi.org/10.1016/B978-0-444-88074-1.50016-0,10.1016/B978-0-444-88074-1.50016-0,"Publisher Summary This chapter focuses on denotational semantics, which is a framework for the formal description of programming language semantics. The main idea of denotational semantics is that each phrase of the language described is given a denotation, which is a mathematical object that represents the contribution of the phrase to the meaning of any complete program in which it occurs. The denotation of each phrase is determined just by the denotations of its subphrases. The chapter discusses the formalism used in denotational semantics: abstract syntax, semantic functions, and semantic domains. It also describes the nature of semantic functions and also describes the properties of compositionality and full abstractness. The chapter illustrates the major standard techniques that are used in denotational descriptions of programming languages, such as environments, stores, and continuations. The chapter explains the relation between these techniques and some fundamental concepts of programming languages.",,,Handbook of Theoretical Computer Science,,,,,,,,,,,,,,,,,,,
Journal Article,"Baguelin M,LeFèvre J,Richard JP",,How to deal with potentially huge dimensional state space: The meta-dynamics approach—application to a model of the co-evolution of bacterio-phage populations,Journal of Computational and Applied Mathematics,2007,205,2,687-695,,,,,2007,,0377-0427,https://www.sciencedirect.com/science/article/pii/S0377042706003931;http://dx.doi.org/10.1016/j.cam.2006.03.036,10.1016/j.cam.2006.03.036,"In many problems coming from the “complexity sciences”, the presence of high-dimensional state spaces and non-linear equations renders traditional mathematical objects useless. To deal with these issues, several approaches have recently been studied, most of them presenting the particularity of splitting the dynamical events in two categories; an upper level in which the events describe how the structure of the system changes (the meta-dynamics) and a lower level with the events describing the evolution of the elements in the structure (the dynamics). The state space is then not defined in extenso but unfolds or contracts during the evolution of the system. In term of simulation, this view allows us to deal with only a small part of the state space at each step avoiding the time and memory limitations. In this paper, we develop the implementation of an example of co-evolving population using a recently published unified mathematical formalism of the concept of meta-dynamics, based on an extension of Kalman's definition of dynamical systems. This general framework describes how to combine the two levels of dynamics, in order to allow the upper level (the meta-dynamics) to be able to modify the lower one (the dynamics). We explain here in detail how to use this formal approach in terms of simulation and algorithms. It allows us to present simulation results combining both changes of the structure of the system and changes at a lower population level.","Dynamical systems, Adaptive systems, Biological systems",Special issue on evolutionary problems,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Kolman B,Shapiro A","Kolman B,Shapiro A",12 - TOPICS IN ALGEBRA,,1986,,,503-557,Second Edition,Academic Press,,College Algebra and Trigonometry (Second Edition),1986,9780124179059,,https://www.sciencedirect.com/science/article/pii/B9780124179059500174;http://dx.doi.org/10.1016/B978-0-12-417905-9.50017-4,10.1016/B978-0-12-417905-9.50017-4,"Publisher Summary This chapter reviews a few topics in algebra. These topics are related in that they all involve the set of natural numbers. The chapter also discusses the concept of mathematical induction, which provides a means of proving certain theorems involving the natural numbers that appear to resist other means of proof. One of the earliest results obtained in a calculus course requires the binomial theorem in its derivation. The last topic discussed in the chapter, probability theory, which is a very useful topic in algebra, enables to state the likelihood of occurrence of a given event and has obvious applications to games of chance. The theory of permutations and combinations, which enables to count the ways in which we can arrange a set of objects or select a subset of the original set, is a necessary background to a study of probability theory.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Ivančević NS,,Stereometric pattern recognition by artificial touch,Pattern Recognition,1974,6,2,77-83,,,,,1974,,0031-3203,https://www.sciencedirect.com/science/article/pii/0031320374900107;http://dx.doi.org/10.1016/0031-3203(74)90010-7,10.1016/0031-3203(74)90010-7,"An artificial touch perception system has been created in order to study a method of processing information obtainable through tactile exploration of three-dimensional forms. The results can be useful for several purposes. The first part of the work concerns the project of the tactile explorator. For this purpose we used a kind of artificial limb like a finger with a certain number of touch sensitive transducers distributed along the surface of the finger tip. The information received by touching the object with the finger, is successively utilized as the input of the control servosystem which moves the finger point-by-point along the object surface in order to proceed with the exploration. It must be noticed that, from a philosophical point-of-view, the parallel approach with more fingers touching simultaneously the object in several points, is equal to sequential touching of these points by one moving finger. The second part describes the use of the propositional calculus in logical classification of the objects, as a method of three-dimensional pattern recognition. Elaboration of the input data obtained by tactile exploration, and computation of characteristic geometrical features of three-dimensional forms, has been performed on computer.","Artificial, Autonomy, Computer, Exploration, Pattern recognition, Space, Three-dimensional, Touch",,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Barendregt HP,Chapter 2 - Conversion,,1984,103,,22-49,,Elsevier,,The Lambda Calculus,1984,,0049-237X,https://www.sciencedirect.com/science/article/pii/B9780444875082500101;http://dx.doi.org/10.1016/B978-0-444-87508-2.50010-1,10.1016/B978-0-444-87508-2.50010-1,"Publisher Summary This chapter discusses the lambda terms and conversion. The principal object of study in the λ-calculus is the set of lambda terms modulo convertibility. The basic equivalence relation on λ-terms is that of convertibility. This relation is generated by axioms. As in the case of predicate logic, some care is needed in defining this operation to avoid confusion between free and bound variables. Using some conventions, one can work with λ-terms in the naive way. The concept of reduction provides an important proof theoretic tool for theory λ and some extensions. Standard translations can be defined from λ-terms to combinatorial logic (CL)-terms, and back. These translations do not yet constitute an isomorphism between the two theories. The λ-terms have a fine structure that is not visible from the corresponding CL-terms.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Lyons WC,Plisga GJ",1 - Mathematics,,2004,,,1-46,Second Edition,Gulf Professional Publishing,Burlington,Standard Handbook of Petroleum and Natural Gas Engineering (Second Edition),2004,9780750677851,,https://www.sciencedirect.com/science/article/pii/B9780750677851500130;http://dx.doi.org/10.1016/B978-075067785-1/50013-0,10.1016/B978-075067785-1/50013-0,"Publisher Summary This chapter provides basic ideas and guidelines on mathematical functions of various branches of mathematics such as geometry, algebra, trigonometry, differential and integral calculus, analytical geometry, numerical methods, applied statistics, and computer applications. The first section of the chapter discusses sets and functions. A set is a collection of distinct objects or elements. A function can be defined as a set of ordered pairs, denoted as (x, y) such that no two such pairs have the same first element. The chapter also discusses Geometry that deals with angles, polygons, triangles, quadrilaterals, circles and spheres, arcs of circles, concurrencies, similarities, prisms and pyramids, coordinate systems, graphs, vectors, and lengths and areas of plane figures. The chapter describes operator precedence and notation, fractions, rules of addition, rules of multiplication and simple factoring, exponents, logarithms, binomial theorems, progressions, sums of the first “n” natural numbers, solution of different equations, and determinants. The chapter also describes basic trigonometric functions, graphs of trigonometric functions, inverse trigonometric functions, trigonometric properties, solution of plane triangles, hyperbolic functions, and polar coordinate system. The chapter further discusses different orders of derivatives, maxima and minima, different types of differentials and integrals, differential equations, methods of solving ordinary differential equations, and the Laplace Transformation. It discusses analytical geometry—both 2D and 3D—and provides information on symmetry, intercepts, asymptotes, and different forms of equations of straight line, plane, curves, and solids.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Kosko B,,Optimal fuzzy hierarchical decisions,IFAC Proceedings Volumes,1986,19,17,51-56,,,,,1986,,1474-6670,https://www.sciencedirect.com/science/article/pii/S147466701769387X;http://dx.doi.org/10.1016/S1474-6670(17)69387-X,10.1016/S1474-6670(17)69387-X,"A general multiobjective decision algorithm is developed for evaluating objects in a criteria hierarchy given fuzzy decision input. The Al techniques used are knowledge representation theory (fuzzy sets, logic, and reasoning) and expert systems theory (forward chaining inference). A formal hierarchy theory is developed. Fuzzy theory is reviewed. The fuzzy hierarchical decision (FHD) algorithm is developed from the fuzzy decision work of Bellman, Zadeh, Yager, and Kosko, and stated in full generality. Candidate applications for the FHD algorithm include the salary review problem in a corporate hierarchy of vice-presidents, managers, supervisors, and technical staff. Other managerial and finance applications-as well as cognitive processing hierarchy applications-are under development at VERAC.",,"IFAC Workshop on Artificial Intelligence in Economics and Management, Zurich, Switzerland, 12-14 March, 1985",,,,,,,,,,,,,,,,,,,,
Journal Article,"Silva JM,Silva JR",,A new hierarchical approach to requirement analysis of problems in automated planning,Engineering Applications of Artificial Intelligence,2019,81,,373-386,,,,,2019,,0952-1976,https://www.sciencedirect.com/science/article/pii/S0952197619300430;http://dx.doi.org/10.1016/j.engappai.2019.02.019,10.1016/j.engappai.2019.02.019,"The use of Knowledge Engineering (KE) processes to analyze and configure domains in automated planning is becoming more appealing since it was noticed that this issue could make a difference to solve real problems. The contrast between a generic domain independent approach, taken as canonical in AI, and alternative processes that include knowledge engineering – eventually adding specific knowledge – has been discussed by Computer and Engineering communities. A big impact has been noticed mainly in the early phase of requirement analysis when KE approach is normally introduced. Requirement analysis is responsible for carrying out the Knowledge modeling of both problem and work domains, which is a key issue to guide different planner algorithms to come out with efficient solutions. Also, there is the scalability issue that appear in most real problems. To face that, hierarchical methods played an important hole in the history of planning and inspired several solutions since the proposal of NONLIN in the 70’s. Since then, the idea of associating hierarchical relational nets with partial ordered actions has prevailed when large systems were considered. However, there is still a gap between the hierarchical approach and the state of art of requirements analysis to allow features anticipated by KE approach to really appear in the requirements of a planning process. This paper proposes a pathway to solve this gap starting with requirements elicitation represented first in the conventional semi-formal (diagrammatic) language – UML – that is translated to Hierarchical Petri Nets (HPNs) by a new enhanced algorithm. The proposed process was installed in a software tool – developed by one of the authors – that analyzes the performance of the KE planning model: itSIMPLE (Integrated Tools Software Interface for Modeling Planning Environment). This tool was initially designed to use classic Place/Transition nets and an old version of UML (2.1). It is now enhanced to use UML 2.4 and a hierarchical Petri Net extension, also developed by the authors. Realistic examples illustrate the process which is now being applied to larger problems related to the manufacturing of car sequencing domain, one of challenge of ROADEF 2005 (French Operations Research & Decision Support Society). Finally, we consider the possibility to introduce another approach to the KE process by using KAOS (Keep All Object Satisfied) to make the planning design more accurate.","Knowledge engineering, Hierarchical automated planning, Planning domain analysis, Hierarchical petri nets, Requirements analysis",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Teorey T,Lightstone S,Nadeau T,Jagadish HV","Teorey T,Lightstone S,Nadeau T,Jagadish HV",2 - The Entity–Relationship Model,,2011,,,13-34,Fifth Edition,Morgan Kaufmann,Boston,Database Modeling and Design (Fifth Edition),2011,9780123820204,,https://www.sciencedirect.com/science/article/pii/B9780123820204000021;http://dx.doi.org/10.1016/B978-0-12-382020-4.00002-1,10.1016/B978-0-12-382020-4.00002-1,"Publisher Summary This chapter defines all the major entity–relationship (ER) concepts that can be applied to the conceptual data modeling phase of the database life cycle. An entity is a person, place, thing, or event of informational interest. Attributes are objects that provide descriptive information about entities. Attributes may be unique identifiers or non-unique descriptors. Relationships describe the connectivity between entity instances: one-to-one, one-to-many, or many-to-many. The degree of a relationship is the number of associated entities: two (binary), three (ternary), or any n (n-ary). The role (name), or relationship name, defines the function of an entity in a relationship. The concept of existence in a relationship determines whether an entity instance must exist (mandatory) or not (optional). The concept of generalization allows for the implementation of supertype and subtype abstractions. This simple form of ER models is used in most design tools and is easy to learn and apply to a variety of industrial and business applications. It is also a very useful tool for communicating with the end user about the conceptual model and for verifying the assumptions made in the modeling process. A more complex form, a superset of the simple form, is useful for the more experienced designer who wants to capture greater semantic detail in diagram form, while avoiding having to write long and tedious narrative to explain certain requirements and constraints.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,Jerrum MR,,The complexity of finding minimum-length generator sequences,Theoretical Computer Science,1985,36,,265-289,,,,,1985,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397585900477;http://dx.doi.org/10.1016/0304-3975(85)90047-7,10.1016/0304-3975(85)90047-7,"The computational complexity of the following problem is investigated: Given a permutation group specified as a set of generators, and a single target permutation which is a member of the group, what is the shortest expression for the target permutation in terms of the generators? The general problem is demonstrated to be PSppace-complete and, indeed,is shown to remain so even when the generator set is restricted to contain only two permutations. The restriction on generator set cardinality is the best possible, as the problem becomes soluble in polynomial time if the generator set cantains only one permutation. An interesting feature of this problem is that it does not fall under the headings of ‘two person games’ or ‘formal languages’ which cover the great majority of known PSpace-complete problems. Some restricted versions of the problem, in which the generator set is fixed rather than being part of the problem instance, are also investigated and shown to be computationally tractable. One result of this kind is that determining the most compact expression of a permutation in terms of ‘cyclicly adjacent transpositions’ can be achieved in polynomial time. Thus, from an initial arrangement of distinct objects on a circle, one can quickly compute the smallest number of interchanges of adjacent objects required to realise any other arrangement. Surprisingly, this problem appears substantially more difficult to solve than the related one (for which a solution has been known for some time) in which the objects are arranged on a line segment.","Computational complexity, permutation groups, polynomial-time algorithms, -completeness",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Goldin DQ,Smolka SA,Wegner P",,"Turing Machines, Transition Systems, and Interaction",Electronic Notes in Theoretical Computer Science,2002,52,1,120-136,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066104002208;http://dx.doi.org/10.1016/S1571-0661(04)00220-8,10.1016/S1571-0661(04)00220-8,"We present Persistent Turing Machines (PTMs), a new way of interpreting Turing-machine computation, one that is both interactive and persistent. We show that the class of PTMs is isomorphic to a very general class of effective transition systems. One may therefore conclude that the extensions to the Turing-machine model embodied in PTMs are sufficient to make Turing machines expressively equivalent to transition systems. We also define the persistent stream language (PSL) of a PTM and a corresponding notion of PSL-equivalence, and consider the infinite hierarchy of successively finer equivalences for PTMs over finite interaction-stream prefixes. We show that the limit of this hierarchy is strictly coarser than PSL-equivalence, a “gap” whose presence can be attributed to the fact that the transition systems corresponding to PTM computations naturally exhibit unbounded nondeterminism. We also consider amnesic PTMs and a corresponding notion of equivalence based on amnesic stream languages (ASLs). It can be argued that amnesic stream languages are representative of the classical view of Turing-machine computation. We show that the class of ASLs is strictly contained in the class of PSLs. Furthermore, the hierarchy of PTM equivalence relations collapses for the subclass of amnesic PTMs. These results indicate that, in a stream-based setting, the extension of the Turing-machine model with persistence is a nontrivial one, and provide a formal foundation for reasoning about programming concepts such as objects with static attributes.",,"EXPRESS'01, 8th International Workshop on Expressiveness in Concurrency (Satellite Event of CONCUR 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,Vein PR,,Identities among certain triangular matrices,Linear Algebra and its Applications,1986,82,,27-79,,,,,1986,,0024-3795,https://www.sciencedirect.com/science/article/pii/0024379586901424;http://dx.doi.org/10.1016/0024-3795(86)90142-4,10.1016/0024-3795(86)90142-4,"The object of this paper is to develop the ideas introduced in the author's paper [1] on matrices which generate families of polynomials and associated infinite series. A family of infinite one-subdiagonal non-commuting matrices Qm is defined, and a number of identities among its members are given. The matrix Q1 is applied to solve a problem concerning the derivative of a family of polynomials, and it is shown that the solution is remarkably similar to a conventional solution employing a scalar generating function. Two sets of infinite triangular matrices are then defined. The elements of one set are related to the terms of Laguerre, Hermite, Bernoulli, Euler, and Bessel polynomials, while the elements of the other set consist of Stirling numbers of both kinds, the two-parameter Eulerian numbers, and numbers introduced in a note on inverse scalar relations by Touchard. It is then shown that these matrices are related by a number of identities, several of which are in the form of similarity transformations. Some well-known and less well-known pairs of inverse scalar relations arising in combinatorial analysis are shown to be derivable from simple and obviously inverse pairs of matrix relations. This work is an explicit matrix version of the umbral calculus as presented by Rota et al. [24-26].",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Kang S,Iaccarino G,Ham F,Moin P",,Prediction of wall-pressure fluctuation in turbulent flows with an immersed boundary method,Journal of Computational Physics,2009,228,18,6753-6772,,,,,2009,,0021-9991,https://www.sciencedirect.com/science/article/pii/S0021999109002915;http://dx.doi.org/10.1016/j.jcp.2009.05.036,10.1016/j.jcp.2009.05.036,"The objective of this paper is to assess the accuracy and efficiency of the immersed boundary (IB) method to predict the wall pressure fluctuations in turbulent flows, where the flow dynamics in the near-wall region is fundamental to correctly predict the overall flow. The present approach achieves sufficient accuracy at the immersed boundary and overcomes deficiencies in previous IB methods by introducing additional constraints – a compatibility for the interpolated velocity boundary condition related to mass conservation and the formal decoupling of the pressure on this surfaces. The immersed boundary-approximated domain method (IB-ADM) developed in the present study satisfies these conditions with an inexpensive computational overhead. The IB-ADM correctly predicts the near-wall velocity, pressure and scalar fields in several example problems, including flows around a very thin solid object for which incorrect results were obtained with previous IB methods. In order to have sufficient near-wall mesh resolution for LES and DNS computations, the present approach uses local mesh refinement. The present method has been also successfully applied to computation of the wall-pressure space–time correlation in DNS of turbulent channel flow on grids not aligned with the boundaries. When applied to a turbulent flow around an airfoil, the computed flow statistics – the mean/RMS flow field and power spectra of the wall pressure – are in good agreement with experiment.","Immersed boundary, Turbulent flow, Wall-pressure fluctuation, Pressure decoupling constraint, LES, DNS, Space–time correlation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Allemang D,Hendler J","Allemang D,Hendler J",Chapter 12 - Good and Bad Modeling Practices,,2008,,,271-291,,Morgan Kaufmann,San Francisco,Semantic Web for the Working Ontologist,2008,9780123735560,,https://www.sciencedirect.com/science/article/pii/B9780123735560000125;http://dx.doi.org/10.1016/B978-0-12-373556-0.00012-5,10.1016/B978-0-12-373556-0.00012-5,"Publisher Summary The basic assumptions behind the Semantic Web—the AAA (Anyone can say Anything about Any topic), Open World, and Nonunique Naming assumptions—place very specific restrictions on the modeling language. The structure of RDF (Resource Description Framework) is in the form of statements with familiar grammatical constructs like subject, predicate, and object. The structure of OWL (Web Ontology Language) includes familiar concepts like class and property. But the meaning of a model is given by the inference rules of OWL, which incorporate the assumptions of the Semantic Web. All of these models are valid expressions in RDF/OWL, but they are erroneous in the sense that they do not accomplish what the modeler intended by creating them. In each case, the mismatch can be revealed through careful examination of the inferences that the model entails. In some cases (like the objectification error), the requirements themselves are inconsistent with the Semantic Web assumptions. In other cases (like the exclusivity error), the requirements are quite consistent with the Semantic Web assumptions and can be modeled easily with a simple pattern. The support that a model provides for question answering is given formally by the inferences that the model entails. As far as an inference engine is concerned, entities in the model could have any name at all, like G0001 or Node97. But names of this sort are of little help when perusing a model to determine whether it can satisfy one's own goals.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Reape M,"Rupp CJ,Rosner MA,Johnson RL","3 - A Feature Value Logic with Intensionality, Nonwellfoundedness and Functional and Relational Dependencies",,1994,,,77-110,,Academic Press,San Diego,"Constraints, Language and Computation",1994,9780080502960,,https://www.sciencedirect.com/science/article/pii/B9780080502960500103;http://dx.doi.org/10.1016/B978-0-08-050296-0.50010-3,10.1016/B978-0-08-050296-0.50010-3,"Publisher Summary This chapter discusses feature value logic with intensionality, nonwellfoundedness, and functional and relational dependencies. In a modal approach to feature logic, it is more appropriate to treat functions and relations as polyadic modalities than to adopt a predicate modal logic approach. The addition of functions and relations to the language not only permits the definition of functional and relational dependencies as used in HPSG, but also allows for the definition of structures other than feature structures. The formal semantics that are given to functional and relational dependencies is the one which most closely matches the informal, intuitive semantics or the use of such dependencies in actual grammatical practice. Formal semantics has some pleasant features. Among these features is the ability to reconstruct the type-token distinction, or to put it another way, the extensionality–intensionality distinction for arbitrary structures and the ability to describe cyclic or nonwellfounded structures of all types. The standard predicate modal logic approach to functions and relations is inadequate to capture the intuitive semantics of functional and relational dependencies as used in the literature. Subsequently, function and relation symbols are existential polyadic polymodal modalities. Thereafter, the interpretation of relation symbols is intensional, whereas the interpretation of function symbols is extensional allowing a type-token distinction for arbitrary objects, including sets.",,,Cognitive Science,,,,,,,,,,,,,,,,,,,
Journal Article,"Almendros-Jiménez JM,Iribarne L",,An extension of UML for the modeling of WIMP user interfaces,Journal of Visual Languages & Computing,2008,19,6,695-720,,,,,2008,,1045-926X,https://www.sciencedirect.com/science/article/pii/S1045926X07000870;http://dx.doi.org/10.1016/j.jvlc.2007.12.004,10.1016/j.jvlc.2007.12.004,"The Unified Modeling Language (UML) [OMG, Unified Modeling Language Specification, Version 2.0, Technical Report, Object Management Group 〈http://www.omg.org/technology/documents/formal/uml.htm〉, 2005] provides system architects working on analysis and design (A&D) with one consistent language for specifying, visualizing, constructing, and documenting the artifacts of software systems, as well as for the business modeling. The user interface (UI), as a significant part of most applications, should be modeled using UML, and automatic CASE tools may help to generate UIs from UML designs. In this paper, we describe how to use and specialize UML diagrams in order to describe the UIs of a software system based on WIMP (Windows, Icons, Menus and Pointers). Use case diagrams are used for extracting the main UIs. Use cases are described by means of user-interaction diagrams, a special kind of activity diagrams in which states represent data output actions and transitions represent data input events. Input and output interactions in the user-interaction diagrams help the designer to extract the UI components used in each UI. We obtain a new and specialized version of the use case diagram for the UI modeling (called UI diagram) and a class diagram for UI components—called UI-class diagram. The user-interaction, UI and UI-class diagrams, can be seen as the UML-based UI models of the system. Finally, UI prototypes can be generated from UI-class diagrams with CASE tool support. As case study of our technique, we will describe an Internet book shopping system.","UML 2.0, Use cases, Model-driven development, User interface modeling, Human–computer interaction",,,,,,,,,,,,,,,,,,,,,
Book Chapter,McCarthy J,Brown FM,The Frame Problem Today,,1987,,,3,,Morgan Kaufmann,,The Frame Problem in Artificial Intelligence,1987,9780934613323,,https://www.sciencedirect.com/science/article/pii/B9780934613323500046;http://dx.doi.org/10.1016/B978-0-934613-32-3.50004-6,10.1016/B978-0-934613-32-3.50004-6,"The frame problem is that of specifying what doesn't change when an event occurs. It is readily solved in systems that have fixed sets of actions and fixed sets of fluents built into the program. It is most acute when the system must be open-ended, i.e. must be ready to accept descriptions of new kinds of events and new kinds of fluents whose values are in general not affected by events whose descriptions don't mention them. Our formalisms are in languages of mathematical logic, mostly first order. We begin with a 1960s situation calculus description of the effects of moving and painting objects with explicit frame axioms. We go on to discuss frames as objects and introduce a formalism that describes change as making generalized assignment statements using my 1963 axiomatization of assignment. We discuss the length of proof that a fluent hasn't changed its value after a large number of events have occurred and discuss sufficient conditions under which this takes a constant number of proof steps independent of the number of events that are presumed to have occurred. Next we discuss non-monotonic formalizations of the effects of actions and their use in solving the frame and qualification problems. The relation between model-theoretic treatments and second order axiomatizations is discussed. There is some discussion of the relation between the frame problem and the heuristics of planning. This draft of FRAME.abs[w87, jmc] TEXed on 1987 February 2 at 4:39 p.m. Copyright © 1987 by John McCarthy",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Roman GC,Cox KC,Wilcox CD,Plun JY",,Pavane: a system for declarative visualization of concurrent computations,Journal of Visual Languages & Computing,1992,3,2,161-193,,,,,1992,,1045-926X,https://www.sciencedirect.com/science/article/pii/1045926X9290014D;http://dx.doi.org/10.1016/1045-926X(92)90014-D,10.1016/1045-926X(92)90014-D,"This paper describes the conceptual model, specification method and visualization methodology for Pavane—a visualization environment concerned with exploring, monitoring and presenting concurrent computations. The underlying visualization model is declarative in the sense that visualization is treated as a mapping from program states to a three-dimensional world of geometric objects. The latter is rendered in full color and may be examined freely by a viewer who is allowed to navigate through the geometric world. The state-to-geometry mapping is defined as a composition of several simpler mappings. The choice is determined by methodological and architectural considerations. This paper shows how this decomposition was molded by two methodological objectives: (1) the desire visually to capture abstract formal properties of programs (e.g. safety and progress) rather than operational details; and (2) the need to support complex animations of atomic computational events. All mappings are specified using a rule-based notation; rules may be added, deleted and modified at any time during the visualization. An algorithm for termination detection in diffusing computations is used to illustrate the specification method and to demonstrate its conceptual elegance and flexibility. A concurrent version of a popular artificial intelligence program provides a vehicle for demonstrating how we derive graphical representations and animation scenarios from key formal properties of the program, i.e. from those safety and progress assertions about the program which turn out to be important in verifying its correctness.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Strelnikov YN,Dmitrevich GD",,Formal description and comparison of interactive design strategies,Artificial Intelligence in Engineering,1991,6,4,186-195,,,,,1991,,0954-1810,https://www.sciencedirect.com/science/article/pii/095418109190023H;http://dx.doi.org/10.1016/0954-1810(91)90023-H,10.1016/0954-1810(91)90023-H,"This paper describes a method which provides unified descriptive facilities for specification, logic analysis, decomposition and comparison of operational CAD system components, planned for, or having, the possibility to be modified to suit a particular application. A formalization of the CAD process is discussed in order to present it in the form of a closed directed graph which, in practice, can be easily translated into conventional operational forms such as algorithms, syntactic structures,simulation nets and first order predicate languages. The general design process model appears as a kind of procedural engineering knowledge. The model deals with the two abstract concepts of object specification and design procedure. These components are formulated using the set-theory postulated concept of transitive mapping closure of procedures. It provides for systematization and structural, functional, and behavioural analysis of operational components which, when put together, will operate in a required manner.","computer aided design, interactive CAD systems, knowledge analysis, knowledge-based simulation, design modelling, expert systems",,,,,,,,,,,,,,,,,,,,,
Journal Article,Harrison PG,,Linearisation: An optimisation for nonlinear functional programs,Science of Computer Programming,1988,10,3,281-318,,,,,1988,,0167-6423,https://www.sciencedirect.com/science/article/pii/0167642388900524;http://dx.doi.org/10.1016/0167-6423(88)90052-4,10.1016/0167-6423(88)90052-4,"Functional programming languages have great appeal from the point of view of both software design and amenability to formal reasoning, but to date they have suffered from poor performance when run on conventional computers. A promising solution to this problem may be provided by program transformation and several schemes have been proposed which can give quite impressive optimisations. However, these are at best only semi-automatic, requiring reasoning on behalf of the programmer to assist the transformation process. Part of the problem is that these schemes must take into account not only functions but also the objects to which they are applied in the defining expressions. By reasoning at the function level, the auxiliary domain of objects need not be considered explicitly, and transformations can be derived in terms of identities between functional expressions, rather than via sets of equations satisfied by objects from a certain class. By expressing functional expressions in variable-free form, we use algebraic methods, based on the functional algebra of the language FP, to transform a certain class of nonlinear functions into linear form. A function in this class generates a reduction graph in the form of a balanced tree when applied to an argument, whereas a linear function generates a single-spine tree and so executes with a number of function calls which is linear in the size of its argument. Thus, for example, tail recursive functions form a small subset of the class of linear functions. Further optimisations include the tupling of functions which are defined by mutal recursion, and we identify conditions under which these are equivalent to a linear function. The compiler is able to detect if the conditions required by these transformation theorems are satisfied, and generate the appropriate optimised functions.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Hoskins EM,,Design development and description using 3D box geometries,Computer-Aided Design,1979,11,6,329-336,,,,,1979,,0010-4485,https://www.sciencedirect.com/science/article/pii/0010448579900332;http://dx.doi.org/10.1016/0010-4485(79)90033-2,10.1016/0010-4485(79)90033-2,"Computer-aided building often relates to complex designed objects such as hospital buildings. The design image comprises initially an overall formal description and later a unique assembly of many separate 3D elements. The 3D design description used here for buildings accommodates both forms of description simultaneously. The level of description required for each is, however, not necessarily fully detailed. This paper outlines the approach taken by ARC (Applied Research of Cambridge) to modelling large-scale, multiple-element assemblies that make up building designs. These techniques are employed in the BDS (Building Design Systems) supplied and supported by ARC.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"de Bonneval A,Courvoisier M,Combacau M",,Real Time Diagnosis and Recovery in Hierarchical FMS Control,IFAC Proceedings Volumes,1991,24,6,307-312,,,,,1991,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017511593;http://dx.doi.org/10.1016/S1474-6670(17)51159-3,10.1016/S1474-6670(17)51159-3,"This paper presents a hierarchical and modular structure for real-time control of Flexible Manufacturing Systems integrating monitoring of process failures. Modularity is obtained by using a basic component — the module — to build the control system. The structure of the module is given. Monitoring consists of the three following functions: detection, diagnosis and recovery. Distinction made within a module between control and monitoring allows us to take advantage of two formal techniques well suited in their own domains: Petri nets to specify the normal control sequences and A.I. techniques to deal with the essential monitoring problems (diagnosis and recovery decision). After describing the global operation of a module, particularities of the failure detection and diagnosis are exposed before focusing on recovery decision.","discrete event systems, multi-level architecture, Petri Nets with Objects, F.M.S. real-time control, real-time monitoring","IFAC/IMACS Symposium on Fault Detection, Supervision and Safety for Technical Processes (SAFEPROCESS'91), Baden-Baden, Germany, 10-13 September 1991",,,,,,,,,,,,,,,,,,,,
Journal Article,"Walinsky C,Banerjee D",,A Data-Parallel FP Compiler,Journal of Parallel and Distributed Computing,1994,22,2,138-153,,,,,1994,,0743-7315,https://www.sciencedirect.com/science/article/pii/S074373158471077X;http://dx.doi.org/10.1006/jpdc.1994.1077,10.1006/jpdc.1994.1077,"In data-parallel programming, operations are performed simultaneously on all elements of large data structures. Backus′s FP functional language promotes this view. FP provides a large set of data rearrangement primitives, and a useful set of functional combining forms that are applied to entire data structures. We describe an FP compiler that generates programs capable of exploiting data-parallelism. The FP compiler deduces the type and shape of objects through type inference, and generates efficient parallel implementations of combining forms. In addition, the compiler determines the effects of data rearrangement functions at compile-time, thereby avoiding creation of large intermediate data structures, and reducing interprocessor communication overhead. FP and its compiler are formally specified, reducing ambiguity concerning constructs of the language and results of the compiler. Performance and speed-ups achieved from our compilation and optimization techniques are demonstrated with timings from a prototype implementation on the Connection Machine CM-2.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cushing R,Belloum A,Bubak M,de Laat C",,Towards a data processing plane: An automata-based distributed dynamic data processing model,Future Generation Computer Systems,2016,59,,21-32,,,,,2016,,0167-739X,https://www.sciencedirect.com/science/article/pii/S0167739X15003647;http://dx.doi.org/10.1016/j.future.2015.11.016,10.1016/j.future.2015.11.016,"Data processing complexity, partitionability, locality and provenance play a crucial role in the effectiveness of distributed data processing. Dynamics in data processing necessitates effective modeling which allows the understanding and reasoning of the fluidity of data processing. Through virtualization, resources have become scattered, heterogeneous, and dynamic in performance and networking. In this paper, we propose a new distributed data processing model based on automata where data processing is modeled as state transformations. This approach falls within a category of declarative concurrent paradigms which are fundamentally different than imperative approaches in that communication and function order are not explicitly modeled. This allows an abstraction of concurrency and thus suited for distributed systems. Automata give us a way to formally describe data processing independent from underlying processes while also providing routing information to route data based on its current state in a P2P fashion around networks of distributed processing nodes. Through an implementation, named Pumpkin, of the model we capture the automata schema and routing table into a data processing protocol and show how globally distributed resources can be brought together in a collaborative way to form a processing plane where data objects are self-routable on the plane.","Data processing, Automata-based computing, Load predication, Backlog avoidance, Distributed computing, Content based routing",,,,,,,,,,,,,,,,,,,,,
Journal Article,Pietarinen AV,,What do epistemic logic and cognitive science have to do with each other?,Cognitive Systems Research,2003,4,3,169-190,,,,,2003,,1389-0417,https://www.sciencedirect.com/science/article/pii/S1389041703000032;http://dx.doi.org/10.1016/S1389-0417(03)00003-2,10.1016/S1389-0417(03)00003-2,"Epistemic logic is a multi-faceted theory aimed at targeting notions such as knowledge, belief, information, awareness, memory and other propositional attitudes, by means of logical and semantical tools. These concepts ought to be in the spotlight of cognitive science too, but the two have not yet seriously been explored in cooperation. In this paper, it is shown that a number of possibilities is opened up by attempting to answer the question of what epistemic logic and cognitive science have to do with each other. Among the proposed answers are: (i) new quantified versions of multi-agent epistemic logic capture locutions involving object identification, giving rise to applications in representing knowledge in multi-agent systems and parallel processing. (ii) The framework of game-theoretic semantics for the ensuing logics enjoys increased cognitive plausibility as the true semantics for epistemic notions. (iii) Several recent findings in cognitive neuroscience pertaining to the notions of awareness and explicit versus implicit processing contribute to logical studies. These three connections are explored here from both logical and cognitive perspectives. Reflecting neuroscientific research, new extensions of epistemic logic are defined, increasing formal understanding of unconscious and unaware information processing in the brain, and making the formalism thus amenable to knowledge representation in multi-agent configurations.","Epistemic logic, Knowledge, Multi-agent systems, Game-theoretic semantics, Cognitive neuroscience, Awareness",Cognitive Agents and Multiagent Interaction,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dolin RH,Alschuler L,Boyer S,Beebe C,Behlen FM,Biron PV,Shabo (Shvo) A",,"HL7 Clinical Document Architecture, Release 2",Journal of the American Medical Informatics Association,2006,13,1,30-39,,,,,2006,,1067-5027,https://www.sciencedirect.com/science/article/pii/S1067502705001878;http://dx.doi.org/10.1197/jamia.M1888,10.1197/jamia.M1888,"Clinical Document Architecture, Release One (CDA R1), became an American National Standards Institute (ANSI)–approved HL7 Standard in November 2000, representing the first specification derived from the Health Level 7 (HL7) Reference Information Model (RIM). CDA, Release Two (CDA R2), became an ANSI-approved HL7 Standard in May 2005 and is the subject of this article, where the focus is primarily on how the standard has evolved since CDA R1, particularly in the area of semantic representation of clinical events. CDA is a document markup standard that specifies the structure and semantics of a clinical document (such as a discharge summary or progress note) for the purpose of exchange. A CDA document is a defined and complete information object that can include text, images, sounds, and other multimedia content. It can be transferred within a message and can exist independently, outside the transferring message. CDA documents are encoded in Extensible Markup Language (XML), and they derive their machine processable meaning from the RIM, coupled with terminology. The CDA R2 model is richly expressive, enabling the formal representation of clinical statements (such as observations, medication administrations, and adverse events) such that they can be interpreted and acted upon by a computer. On the other hand, CDA R2 offers a low bar for adoption, providing a mechanism for simply wrapping a non-XML document with the CDA header or for creating a document with a structured header and sections containing only narrative content. The intent is to facilitate widespread adoption, while providing a mechanism for incremental semantic interoperability.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Heping H,Zedan H",,An executable specification language for fast prototyping parallel responsive systems,Computer Languages,1996,22,1,1-13,,,,,1996,,0096-0551,https://www.sciencedirect.com/science/article/pii/009605519600001X;http://dx.doi.org/10.1016/0096-0551(96)00001-X,10.1016/0096-0551(96)00001-X,"An executable specification language, known as PSP, for fast prototyping parallel responsive systems is introduced. The language is equipped with directly executable mathematical data objects, first order predicates, temporal operators, parallel assignment, state and state history, sets, maps and sequences, etc. An abstract system model of a parallel responsive systems may be constructed using PSP. Using this model, various dynamic behaviors of the system can be studied and analysed at an early design stage. These include detailed temporal relations between every component in the system. Temporal and functional properties of the system can also be expresse within PSP as (temporal) predicates. Global cause-effect relations and other temporal properties of the system can be tested by executing both the abstract system model and its associated functional/temporal asscertions. Inconsistency an incompleteness in the abstract design can then be discoverd against user's intention before real implemention, thus reducing design cost. PSP is illustrated using a lift system.","formal specification, prototype, reactive, parallel system",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Albertos P,Morant F,de la Puente JA,Crespo A","Florian D,Haase V",COMO: A MODULA-2 PROGRAM FOR REAL-TIME CONTROL OF A RAW MATERIAL MILL,,1987,,,101-107,,Pergamon,Amsterdam,Software for Computer Control 1986,1987,9780080340838,,https://www.sciencedirect.com/science/article/pii/B9780080340838500211;http://dx.doi.org/10.1016/B978-0-08-034083-8.50021-1,10.1016/B978-0-08-034083-8.50021-1,"A computer program for real-time computer control of a mill process in a cement plant is described. The purpose of the process is to blend and mill raw materials in adequate proportions so that slurry, the resulting product, has the required composition. The program has been developed from a formal specification, using an object-based methodology and the Modula-2 programming language. The complete system consists of a structured collection of tasks and monitors. Simulation and preliminary plant results are presented.",,,IFAC Symposia Series,,,,,,,,,,,,,,,,,,,
Journal Article,"Benveniste A,Caillaud B,Le Guernic P",,Compositionality in Dataflow Synchronous Languages: Specification and Distributed Code Generation,Information and Computation,2000,163,1,125-171,,,,,2000,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540100999991;http://dx.doi.org/10.1006/inco.2000.9999,10.1006/inco.2000.9999,"Modularity is advocated as a solution for the design of large systems; the mathematical translation of this concept is often that of compositionality. This paper is devoted to the issues of compositionality for modular code generation, in dataflow synchronous languages. As careless reuse of object code in new or evolving system designs fails to work, we first concentrate on what are the additional features needed to abstract programs for the purpose of code generation: we show that a central notion is that of scheduling specification as resulting from a causality analysis of the given program. Using this notion, we study separate compilation for synchronous programs. An entire section is devoted to the formal study of causality and scheduling specifications. Then we discuss the issue of distributed implementation using an asynchronous medium of communication. Our main results are that it is possible to characterize those synchronous programs which can be distributed on an asynchronous architecture without loosening semantic properties. Two new notions of endochrony and isochrony are introduced for this purpose. As a result, we derive a theory for synthesizing additional schedulers and protocols needed to guarantee the correctness of distributed code generation. Corresponding algorithms are implemented in the framework of the DC+ common format for synchronous languages, and the V4 release of the SIGNAL language.","synchronous languages, modularity, distributed code generation, separate compilation, desynchronization",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dong J,Alencar PS,Cowan DD,Yang S",,Composing pattern-based components and verifying correctness,Journal of Systems and Software,2007,80,11,1755-1769,,,,,2007,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121207000817;http://dx.doi.org/10.1016/j.jss.2007.03.005,10.1016/j.jss.2007.03.005,"Designing large software systems out of reusable components has become increasingly popular. Although liberal composition of reusable components saves time and expense, many experiments indicate that people will pay for this (liberal composition) sooner or later, sometimes paying even a higher price than the savings obtained from reusing components. Thus, we advocate that more rigorous analysis methods to check the correctness of component composition would allow combination problems to be detected early in the development process so that people can save the considerable effort of fixing errors downstream. In this paper we describe a rigorous method for component composition that can be used to solve combination and integration problems at the (architectural) design phase of the software development lifecycle. In addition, we introduce the notion of composition pattern in order to promote the reuse of composition solutions to solve routine component composition problems. Once a composition pattern is proven correct, its instances can be used in a particular application without further proof. In this way, our proposed method involves reusing compositions as well as reusing components. We illustrate our approach through an example related to the composition of design patterns as design components. Structural and behavioral correctness proofs about the composition of design patterns are provided. Case studies are also presented to show the applications of the composition patterns.","Design pattern, Formal specification and verification, Integration, Modeling, Design component, Composition pattern, Temporal logic, Object-Z",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ferro N,Silvello G",,"Descendants, ancestors, children and parent: A set-based approach to efficiently address XPath primitives",Information Processing & Management,2016,52,3,399-429,,,,,2016,,0306-4573,https://www.sciencedirect.com/science/article/pii/S0306457315001259;http://dx.doi.org/10.1016/j.ipm.2015.11.001,10.1016/j.ipm.2015.11.001,"XML is a pervasive technology for representing and accessing semi-structured data. XPath is the standard language for navigational queries on XML documents and there is a growing demand for its efficient processing. In order to increase the efficiency in executing four navigational XML query primitives, namely descendants, ancestors, children and parent, we introduce a new paradigm where traditional approaches based on the efficient traversing of nodes and edges to reconstruct the requested subtrees are replaced by a brand new one based on basic set operations which allow us to directly return the desired subtree, avoiding to create it passing through nodes and edges. Our solution stems from the NEsted SeTs for Object hieRarchies (NEASTOR) formal model, which makes use of set-inclusion relations for representing and providing access to hierarchical data. We define in-memory efficient data structures to implement NESTOR, we develop algorithms to perform the descendants, ancestors, children and parent query primitives and we study their computational complexity. We conduct an extensive experimental evaluation by using several datasets: digital archives (EAD collections), INEX 2009 Wikipedia collection, and two widely-used synthetic datasets (XMark and XGen). We show that NESTOR-based data structures and query primitives consistently outperform state-of-the-art solutions for XPath processing at execution time and they are competitive in terms of both memory occupation and pre-processing time.","In-memory XPath processing, NESTOR, Set-based data models, Data structures",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Fath BD,Borrett SR",,A MATLAB® function for Network Environ Analysis,Environmental Modelling & Software,2006,21,3,375-405,,,,,2006,,1364-8152,https://www.sciencedirect.com/science/article/pii/S1364815204003032;http://dx.doi.org/10.1016/j.envsoft.2004.11.007,10.1016/j.envsoft.2004.11.007,"Network Environ Analysis is a formal, quantitative methodology to describe an object's within system “environ”ment [Patten, B.C., 1978a. Systems approach to the concept of environment. Ohio Journal of Science 78, 206–222]. It provides a perspective of the environment, based on general system theory and input–output analysis. This approach is one type of a more general conceptual approach called ecological network analysis. Application of Network Environ Analysis on ecosystem models has revealed several important and unexpected results [see e.g., Patten, B.C., 1982. Environs: relativistic elementary particles or ecology. American Naturalist 119, 179–219; Patten, B.C., 1985. Energy cycling in the ecosystem. Ecological Modelling 28, 1–71; Fath, B.D., Patten, B.C., 1999a. Review of the foundations of network environ analysis. Ecosystems 2, 167–179], which have been identified and summarized in the literature as network environ properties. To conduct the analysis one needs ecosystem data including the intercompartmental flows, compartmental storages, and boundary input and output flows. The software presented herein uses these data to perform the main network environ analyses and environ properties including unit environs, indirect effects ratio, network homogenization, network synergism, network mutualism, mode partitioning, and environ control. The software is available from The MathWorks MATLAB® Central File Exchange website (http://www.mathworks.com/matlabcentral/fileexchange/loadCategory.do).","Ecological Modelling, Ecological Network Analysis, Network Environ Analysis",,,,,,,,,,,,,,,,,,,,,
Journal Article,Kandrup HE,,Particle creation and entropy generation in time-dependent quantum fields,Physica A: Statistical Mechanics and its Applications,1989,158,1,336-342,,,,,1989,,0378-4371,https://www.sciencedirect.com/science/article/pii/0378437189905335;http://dx.doi.org/10.1016/0378-4371(89)90533-5,10.1016/0378-4371(89)90533-5,"Recently, this author has proposed a measure of nonequilibrium entropySN for a quantum field in a dynamical spacetime which, motivated by the Uncertainty Principle, reflects in a natural way the average particle number〈N〉 and the dispersion ΔN. Superficially, this SN appears very different from the “correlational” entropy S1 introduced by Hu and Kandrup. However, it is shown here that both S1 and SN can be viewed in much the same sense as reflecting a “coarse-graining” of the full density matrix, so that they are in fact quite similar objects. This formal similarity sheds light on the special role of “random phase” initial data, which lead to subsequent increases in 〈N〉, ΔN, andSN.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Palm R,,Robot Control by External Sensors,IFAC Proceedings Volumes,1986,19,2,295-300,,,,,1986,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017641399;http://dx.doi.org/10.1016/S1474-6670(17)64139-9,10.1016/S1474-6670(17)64139-9,"The feedback of the interaction between the industrial robot and the object world by the help of external sensory control requires a special approach with regard to the formulation of the task. The formal statement of a robot action can be characterized by two types of tasks, the motion task and the reaction task. The result of the motion task is a trajectory planned, for example a straight line, an ore, and a parabola, respectively. On the other hond, the reaction task takes into consideration the interaction between the robot effector and the object, for example a force/torque vector acting upon a surface. The control method presented makes use of the base equation of the manipulation including this two tasks. To control a robot in relation to external certesian coordinates an appropriate description of tho dynamic behavior of the robot is required. Each joint of the robot is locally servocontrolled by a feedback - feedforward controller. Coming from the servocontrolled arm it can be shown that the dynamic behavior of the robot according to certesian coordinates and joint coordinates is approximately the same. In the robot system depicted hero basic functions and complex functions arc defined on a language level. By the help of them the user is able to configurate special sensory programs (skills) in detail. An example deals with a contouring algorithm by the help of a special control method for distance and orientation of the robot offoctor relative to the object surface. The contouring method makes use of the estimation of tho direction of the surface tangent by linear regression.","Robots, Manipulation, sensors, programming languages, trajectory generation, contouring control, skills","5th IFAC/IFIP/IMACS/IFORS Conference on Information Control Problems in Manufacturing, Suzdal, USSR, 22-25 April 1986",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Baldassarri F,Chiarellotto B","Cristante V,Messing W",Algebraic versis Rigid Cohomology with Logarithmic Coefficients,,1994,15,,11-50,,Academic Press,,Barsotti Symposium in Algebraic Geometry,1994,,1040-4368,https://www.sciencedirect.com/science/article/pii/B9780121972707500073;http://dx.doi.org/10.1016/B978-0-12-197270-7.50007-3,10.1016/B978-0-12-197270-7.50007-3,"Publisher Summary This chapter discusses algebraic versus rigid cohomology with logarithmic coefficients. If the field is assumed to be algebraically closed, so that Γ is a dense subgroup of the multiplicative group and a discretely valued complete subfield K of K, with valuation ring, uniformizing parameter, and residue field is fixed, the field K will play the role of field of definition for all the algebraic objects. Under the assumptions of the theorem, also if it is assumed that the eigenvalues are p-adically non-Liouville, the formally merornorphic solutions at 0 are merornorphic. The morphisms induce isomorphisms of hypercohomology groups. The chapter presents the classification of systems with logarithmic singularities along the coordinate divisor on an open polydisk, relative to a smooth affinoid base-space. The two notions of local overconvergence and of non-Liouvilleness of the exponents of monodromy, play a crucial role. The spectral sequence of relative cohomology is used to reduce to comparison of de Rham cohomology.",,,Perspectives in Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,Devienne P,,Weighted graphs: A tool for studying the halting problem and time complexity in term rewriting systems and logic programming,Theoretical Computer Science,1990,75,1,157-215,,,,,1990,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759090066Q;http://dx.doi.org/10.1016/0304-3975(90)90066-Q,10.1016/0304-3975(90)90066-Q,"This study is based on the halting and complexity problems for a simple class of logic programs in PROLOG-like languages. Any Prolog program can be expressed in the form of an overlap of some simpler programs whose structures are basic and can be studied formally. The simplest recursive rules are studied here and the weighted graph is introduced to characterise their behaviour. This new syntactic object, the weighted graph, generalises the directed graph. Unfoldings of directed graphs generate infinite regular trees that I generalise by weighting the arrows and putting periods on the variables. The weights along a branch are added during unfolding and the result (modulo of the period) indexes variables. Hence, their interpretations are non-regular trees because of the infinity of variables. This paper presents some of the formal properties of these graphs, finite and infinite interpretation and unification. Although they have a consistency apart from all possible applications, weighted graphs characterise the behaviour of recursive rules in the form L:-R. They express themost general fixpoint of these rules and range across a finite sequence of recursive rewritings. Within global rewriting systems and logic programming, the halting problem and the existence of solutions are proved to be decidable for this simple recursive rule with linear goals and facts, and the complexity is shown to be at most linear. Although these problems are undecidable for slightly more complex schemes, it is hoped that from the weighted graphs of each recursive sub-structure of a Prolog program, the whole behaviour of the program will be understandable. Then, the weighted graphs would be the nucleus of an efficient and methodological logic programming, which could be called Structured Logic Programming.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Moonen B,,Serre–Tate theory for moduli spaces of PEL type,Annales Scientifiques de l’École Normale Supérieure,2004,37,2,223-269,,,,,2004,,0012-9593,https://www.sciencedirect.com/science/article/pii/S001295930400014X;http://dx.doi.org/10.1016/j.ansens.2003.04.004,10.1016/j.ansens.2003.04.004,"We develop a Serre–Tate theory for moduli spaces of PEL type. This leads us to study Barsotti–Tate groups X equipped with an action ι of a Zp-algebra and possibly also a polarization λ. We define a notion of ordinariness for such triples X=(X,ι,λ). If we work over k=k̄ and fix suitable discrete invariants, such as the CM-type, we prove that there is a unique ordinary object, up to isomorphism. We introduce a new structure, called a cascade, that generalizes the notion of a biextension, and we show that the formal deformation space of an ordinary triple has a natural cascade structure. In particular, our theory gives rise to canonical liftings of ordinary objects. In the final section of the paper we apply our theory to the study of congruence relations. Résumé Nous développons une “théorie de Serre–Tate” pour les espaces de modules de type PEL. Ceci nous mène à étudier les groupes de Barsotti–Tate X munis d'une action ι d'une Zp-algèbre et éventuellement d'une polarisation λ. Nous définissons une notion d'ordinarité pour de tels systèmes X=(X,ι,λ). Nous démontrons que, sur k=k̄, en fixant certains invariants comme le “type CM”, il n'existe qu'un seul objet ordinaire, à isomorphisme près. Nous introduisons une nouvelle structure, appelée cascade, généralisation de la notion de biextension, et nous prouvons que l'espace de déformations formelles d'un objet ordinaire admet une structure naturelle de cascade. En particulier, notre théorie donne des relèvements canoniques des objets ordinaires. Dans la dernière section nous appliquons notre théorie à l'étude de relations de congruence.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Palmer RS,,Chain models and finite element analysis: An executable Chains formulation of plane stress,Computer Aided Geometric Design,1995,12,7,733-770,,,,,1995,,0167-8396,https://www.sciencedirect.com/science/article/pii/016783969500015X;http://dx.doi.org/10.1016/0167-8396(95)00015-X,10.1016/0167-8396(95)00015-X,"Algebraic-topological k-chains defined over finite cell complexes have been proposed as a uniform computational means of representing physical objects, systems and properties. This article introduces Chains, a computer language whose basic datatypes are cells, cell complexes, and k-chains. To illustrate how Chains may be used in numerical computing, we develop a two page Chains program that completely specifies a finite element solution to plane strain, including symbolic definition of quadratic shape functions, the related “element stiffness matrices”, and an algebraic-topological specification of the assembly process. In contrast to a textbook derivation of the finite element method (which it closely resembles), this program is a fully formal finite element computation, and hence is a step towards the goal of improving the process of creating software for scientific computing by raising the semantic level at which physical systems are specified.","Finite element analysis, CAD, Computational topology, Geometry","Grid Generation, Finite Elements, and Geometric Design",,,,,,,,,,,,,,,,,,,,
Book Chapter,Segen J,"Porter B,Mooney R",Graph Clustering and Model Learning by Data Compression,,1990,,,93-101,,Morgan Kaufmann,San Francisco (CA),Machine Learning Proceedings 1990,1990,9781558601413,,https://www.sciencedirect.com/science/article/pii/B9781558601413500158;http://dx.doi.org/10.1016/B978-1-55860-141-3.50015-8,10.1016/B978-1-55860-141-3.50015-8,"This paper uses a minimal representation criterion to formally define tasks of matching, classification, and interpretation of objects represented as graphs, as well as conceptual clustering of graphs, and supervised learning of structured concepts represented as probabilistic graphs. These definitions do not rely on acceptance thresholds, or other user selectable parameters. The resulting problems of combinatorial optimization are approximately solved by a fast graph matching heuristic, which is a key element of the described learning methods, that include forced learning of graph models, and two graph clustering methods: incremental, and agglomerative. These methods apply to usual directed graphs, and to recursively defined layered graphs. The presented methodology has been applied to real problems of concept learning, classification and interpretation of nonrigid shapes.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Cooke R,"Grattan-Guinness I,Cooke R,Corry L,Crépel P,Guicciardini N","Chapter 43 - Richard Dedekind, Stetigkeit und irrationale zahlen (1872)",,2005,,,553-563,,Elsevier Science,Amsterdam,Landmark Writings in Western Mathematics 1640-1940,2005,9780444508713,,https://www.sciencedirect.com/science/article/pii/B9780444508713501248;http://dx.doi.org/10.1016/B978-044450871-3/50124-8,10.1016/B978-044450871-3/50124-8,"Publisher Summary This chapter focuses on Richard Dedekind's work, Stetigkeit und Irrationale Zahlen. Dedekind wrote this essay to clarify a foundational problem that had lain beneath the surface of analysis since the time of Descartes. The roots of the problem go back to the earliest mathematics that is now recognized as formally deductive, to the problem of incommensurables, first raised in the fourth century BCE. The Pythagoreans had discovered that some ratios of lines, such as the diagonal and side of a square or regular pentagon, could not be expressed as ratios of integers. Dedekind had, in modern terms, provided a model of a structure that has the properties of a number system and at the same time those of a geometric line. Dedekind's clarity remained a model for other mathematicians to use when creating new objects. In the last analysis, the geometric intuition from which the idea of continuity and the idea of an infinitely precise real number arise, does not mesh well with the finite, verbal aspect of mathematics that is adapted for logical inference and computation. Yet it is reassuring to know that a precise verbal description of an intuitive geometric idea does exist, to which it is possible to have recourse when intuition becomes doubtful. To have provided that description is the lasting achievement of Dedekind's pamphlet.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Despland A,Mazaud M,Rakotozafy R",,Using rewriting techniques to produce code generators and proving them correct,Science of Computer Programming,1990,15,1,15-54,,,,,1990,,0167-6423,https://www.sciencedirect.com/science/article/pii/016764239090043D;http://dx.doi.org/10.1016/0167-6423(90)90043-D,10.1016/0167-6423(90)90043-D,"A major problem in deriving a compiler from a formal definition is the production of correct and efficient object code. In this context, we propose a solution to the problem of code-generator generation. Our approach is based on a target machine description where the basic concepts used (storage classes, access modes, access classes and instructions) are hierarchically described by tree patterns. These tree patterns are terms of an abstract data type. The program intermediate representation (input to the code generator) is a term of the same abstract data type. The code generation process is based on access modes and instruction template-driven rewritings. The result is that each program instruction is reduced to a sequence of elementary machine instructions, each of them representing an instance of an instruction template. The axioms of the abstract data type are used to prove that the rewritings preserve the semantics of the intermediate representation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Reiter R,Mackworth AK",,A logical framework for depiction and image interpretation,Artificial Intelligence,1989,41,2,125-155,,,,,1989,,0004-3702,https://www.sciencedirect.com/science/article/pii/0004370289900088;http://dx.doi.org/10.1016/0004-3702(89)90008-8,10.1016/0004-3702(89)90008-8,"We propose a logical framework for depiction and interpretation that formalizes image domain knowledge, scene domain knowledge and the depiction mapping between the image and scene domains. This framework requires three sets of axioms: image axioms, scene axioms and depiction axioms. An interpretation of an image is defined to be a logical model of these axioms. The approach is illustrated by a case study, a reconstruction in first-order logic of a simplified map-understanding program, Mapsee. The reconstruction starts with a description of the map and a specification of general knowledge of maps, geographic objects and their depiction relationships. For the simple map world we show how the task level specification may be refined to a provably correct implementation by applying model-preserving transformations to the initial logical representation to produce a set of propositional formulas. The implementation may use known constraint satisfaction techniques to find the set of models of these propositional formulas. In addition, we sketch preliminary logical treatments for image queries, contingent scene knowledge, ambiguity in image description, occlusion, complex objects, preferred interpretations and image synthesis. This approach provides a formal framework for analyzing and going beyond existing systems such as Mapsee, and for understanding the use of constraint satisfaction techniques. It can be used as a foundation for the specification, design and implementation of vision and graphics systems that are correct with respect to the task and algorithm levels.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ribaric S,Hrkac T",,A model of fuzzy spatio-temporal knowledge representation and reasoning based on high-level Petri nets,Information Systems,2012,37,3,238-256,,,,,2012,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437911001529;http://dx.doi.org/10.1016/j.is.2011.09.010,10.1016/j.is.2011.09.010,"In many application areas there is a need to represent human-like knowledge related to spatio-temporal relations among multiple moving objects. This type of knowledge is usually imprecise, vague and fuzzy, while the reasoning about spatio-temporal relations is intuitive. In this paper we present a model of fuzzy spatio-temporal knowledge representation and reasoning based on high-level Petri nets. The model should be suitable for the design of a knowledge base for real-time, multi-agent-based intelligent systems that include expert or user human-like knowledge. The central part of the model is the knowledge representation scheme called FuSpaT, which supports the representation and reasoning for domains that include imprecise and fuzzy spatial, temporal and spatio-temporal relationships. The scheme is based on the high-level Petri nets called Petri nets with fuzzy spatio-temporal tokens (PeNeFuST). The FuSpaT scheme integrates the theory of the PeNeFuST and 117 spatio-temporal relations. The reasoning in the proposed model is a spatio-temporal data-driven process based on the dynamical properties of the scheme, i.e., the execution of the Petri nets with fuzzy spatio-temporal tokens. An illustrative example of the spatio-temporal reasoning for two agents in a simplified robot-soccer scene is given.","Knowledge representation, Fuzziness, Spatio-temporal reasoning, Multi-agent systems, High-level Petri nets",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Wakefield C,Sonder HE,Lee WM","Wakefield C,Sonder HE,Lee WM",Chapter 2 - The Microsoft .NET Framework,,2001,,,33-89,,Syngress,Rockland,VB.net Developer's Guide,2001,9781928994480,,https://www.sciencedirect.com/science/article/pii/B9781928994480500070;http://dx.doi.org/10.1016/B978-192899448-0/50007-0,10.1016/B978-192899448-0/50007-0,"Publisher Summary Visual Basic .Net (VB .NET) is the first true version of VB released with a complete redesign after VB 4.0 came out. All the limitations that Visual Basic programmers have found in the past, such as being limited to windowed applications, are now completely gone. With the interoperability that .NET provides, programmers can use any language to overcome any of VB's language shortcomings. .NET provides developers with new possibilities for creating applications. The Common Language Runtime (CLR) changes the way that programs are written, in the sense that VB developers won't be limited to the Windows platform. The CLR is the heart of the .NET Framework. It provides a lot of the functionality that .NET uses. CLR provides the function of translating the application internally, code to code, within the native environment. Programming for .NET is not limited to the Microsoft standard languages. Any compiler that follows the Common Type System and other requirements for .NET can be created for any programming language. The new deployable unit for .NET is an assembly. It is more like a logical dynamic link library (DLL) file than a true executable file. Each assembly file consists of the internal code, the manifest area, and the metadata contained within the manifest area. Metadata contains the map that .NET uses to layout objects in memory and how they are used.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Iliffe JK,Goodman R,The Use of the Genie System in Numerical Calculation,,1961,2,,1-28,,Elsevier,,Annual Review in Automatic Programming,1961,,0074-9141,https://www.sciencedirect.com/science/article/pii/B9781483197791500057;http://dx.doi.org/10.1016/B978-1-4831-9779-1.50005-7,10.1016/B978-1-4831-9779-1.50005-7,"Publisher Summary This chapter describes the use of the Genie system in numerical calculation. The set of codes designed for interpreting formal expressions on the Rice University computer is termed the Genie system, or simply Genie. Genie is concerned in general with the definition of objects belonging to certain computable domains, and the execution of particular operations between or upon these objects. Formal calculation proceeds by naming objects of interest, and assigning values to such objects either by means of equations or, in the case of linguistic objects, by exhibiting specific examples of the objects. One of the objectives of Genie is to extend the basic forms of definition that can readily be understood, and simply and efficiently encoded. The chapter also discusses the static properties of algorithm descriptions with illustrative examples. At the highest organizational level, Genie is concerned with the interaction of two definition sets—one initially in the machine and one written by the coder. The result of the interaction is a new definition set in the machine and some printed output information of interest to the coder.",,,International Tracts in Computer Science and Technology and Their Application,,,,,,,,,,,,,,,,,,,
Journal Article,Grandis M,,Weak subobjects and the epi-monic completion of a category,Journal of Pure and Applied Algebra,2000,154,1,193-212,,,,,2000,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404999001917;http://dx.doi.org/10.1016/S0022-4049(99)00191-7,10.1016/S0022-4049(99)00191-7,"The notion of weak subobject, or variation, was introduced by Grandis (Cahiers Topologie Géom. Différentielle Catégoriques 38 (1997) 301–326) as an extension of the notion of subobject, adapted to homotopy categories or triangulated categories, and well linked with their weak limits. We study here some formal properties of this notion. Variations in the category X can be identified with (distinguished) subobjects in the Freyd completion FrX, the free category with epi-monic factorisation system over X, which extends the Freyd embedding of the stable homotopy category of spaces in an abelian category (Freyd, in: Proceedings of Conference on Categ. Algebra, La Jolla, 1965, Springer, Berlin, 1966, pp. 121–176). If X has products and weak equalisers, as HoTop and various other homotopy categories, FrX is complete; similarly, if X has zero-object, weak kernels and weak cokernels, as the homotopy category of pointed spaces, then FrX is a homological category (Grandis, Cahiers Topologie Géom. Différentielle Catégoriques 33 (1992) 135–175); finally, if X is triangulated, FrX is abelian and the embedding X→FrX is the universal homological functor on X, as in Freyd's original case. These facts have consequences on the ordered sets of variations.",,Category Theory and its Applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Luján-Mora S,Trujillo J,Song IY",,A UML profile for multidimensional modeling in data warehouses,Data & Knowledge Engineering,2006,59,3,725-769,,,,,2006,,0169-023X,https://www.sciencedirect.com/science/article/pii/S0169023X0500176X;http://dx.doi.org/10.1016/j.datak.2005.11.004,10.1016/j.datak.2005.11.004,"The multidimensional (MD) modeling, which is the foundation of data warehouses (DWs), MD databases, and On-Line Analytical Processing (OLAP) applications, is based on several properties different from those in traditional database modeling. In the past few years, there have been some proposals, providing their own formal and graphical notations, for representing the main MD properties at the conceptual level. However, unfortunately none of them has been accepted as a standard for conceptual MD modeling. In this paper, we present an extension of the Unified Modeling Language (UML) using a UML profile. This profile is defined by a set of stereotypes, constraints and tagged values to elegantly represent main MD properties at the conceptual level. We make use of the Object Constraint Language (OCL) to specify the constraints attached to the defined stereotypes, thereby avoiding an arbitrary use of these stereotypes. We have based our proposal in UML for two main reasons: (i) UML is a well known standard modeling language known by most database designers, thereby designers can avoid learning a new notation, and (ii) UML can be easily extended so that it can be tailored for a specific domain with concrete peculiarities such as the multidimensional modeling for data warehouses. Moreover, our proposal is Model Driven Architecture (MDA) compliant and we use the Query View Transformation (QVT) approach for an automatic generation of the implementation in a target platform. Throughout the paper, we will describe how to easily accomplish the MD modeling of DWs at the conceptual level. Finally, we show how to use our extension in Rational Rose for MD modeling.","UML, Multidimensional modeling, Data warehouses, UML extension, UML profile",Including: ER 2003,,,,,,,,,,,,,,,,,,,,
Journal Article,"Heping H,Zedan H",,A fast prototype tool for parallel reactive systems,Journal of Systems Architecture,1996,42,4,251-266,,,,,1996,,1383-7621,https://www.sciencedirect.com/science/article/pii/1383762196000240;http://dx.doi.org/10.1016/1383-7621(96)00024-0,10.1016/1383-7621(96)00024-0,"An executable specification language, known as PSP, for fast prototyping parallel reactive systems is introduced. The language is equipped with executable mathematical data objects, first order predicates, temporal operators, parallel assignment, state and state history, sets, maps and sequences. An abstract system model of a parallel reactive system may be constructed using PSP. Using this model, various dynamic behavior of the system can be studied and analyzed. These include detailed temporal relations between every component in the system at a very early design stage. Temporal and functional properties of the system can also be expressed within PSP as (temporal) predicates. Global cause-effect relations and other temporal properties of the system can be tested by executing both the abstract system model and its associated functional/temporal assertions. Inconsistency and incompleteness in the abstract design can then be discovered against user's intention at an early stage, reducing design cost. PSP is illustrated using a simple safe-pump system.","Formal specification, Prototype, Reactive, Parallel system",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Hyland JM,Ong CH",,"On Full Abstraction for PCF: I, II, and III",Information and Computation,2000,163,2,285-408,,,,,2000,,0890-5401,https://www.sciencedirect.com/science/article/pii/S0890540100929171;http://dx.doi.org/10.1006/inco.2000.2917,10.1006/inco.2000.2917,"We present an order-extensional, order (or inequationally) fully abstract model for Scott's language pcf. The approach we have taken is very concrete and in nature goes back to S. C Kleene (1978, in “General Recursion Theory II, Proceedings of the 1977 Oslo Symposium,” North-Holland, Amsterdam) and R. O. Gandy (1993, “Dialogues, Blass Games, Sequentiality for Objects of Finite Type,” unpublished manuscript) in one tradition, and to G. Kahn and G. D. Plotkin (1993, Theoret. Comput. Sci.121, 187–278) and G. Berry and P.-L. Curien (1982, Theoret. Comput. Sci.20, 265–321) in another. Our model of computation is based on a kind of game in which each play consists of a dialogue of questions and answers between two players who observe the following principles of civil conversation: 1.Justification. A question is asked only if the dialogue at that point warrants it. An answer is proffered only if a question expecting it has already been asked. 2.Priority. Questions pending in a dialogue are answered on a last-asked-first-answered basis. This is equivalent to Gandy's no-dangling-question-mark condition. We analyze pcf-style computations directly in terms of partial strategies based on the information available to each player when he or she is about to move. Our players are required to play an innocent strategy: they play on the basis of their view which is that part of the history that interests them currently. Views are continually updated as the play unfolds. Hence our games are neither history-sensitive nor history-free. Rather they are view-dependent. These considerations give expression to what seems to us to be the nub of pcf-style higher-type sequentiality in a (dialogue) game-semantical setting.","higher-type sequential computation, full abstraction, , -calculus, game semantics",,,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Kreisel G,Krivine JL",Part B Combinatorial Foundations,,1967,48,,195-221,,Elsevier,,Elements of Mathematical Logic,1967,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08717312;http://dx.doi.org/10.1016/S0049-237X(08)71731-2,10.1016/S0049-237X(08)71731-2,"Publisher Summary This chapter focuses on combinatorial foundations. The objects with which this kind of reasoning is concerned, and whence it takes its name, are finite combinations of concrete objects such as letters of an alphabet, numerals, symbols of a formal language, and such. A combinatorial function of n variables is a mechanical rule, together with a combinatorial proof of functionality—that is, a proof establishing that if the rule is applied to any n objects (chosen among the combinations of objects under consideration), it will determine a value after a finite number of steps; the rule is applied to a description (of an object) which, in general, is distinct from the object itself. The chapter also discusses the analysis of intuitive mathematics in terms of the basic combinatorial notions.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,Shoham Y,Brown FM,What is the frame problem?,,1987,,,5-21,,Morgan Kaufmann,,The Frame Problem in Artificial Intelligence,1987,9780934613323,,https://www.sciencedirect.com/science/article/pii/B9780934613323500058;http://dx.doi.org/10.1016/B978-0-934613-32-3.50005-8,10.1016/B978-0-934613-32-3.50005-8,"Ever since its introduction by McCarthy and Hayes in 1969, the so-called frame problem has been the object of much fascination and debate. Although it was defined in the narrow context of the situation calculus, a specific temporal formalism. it was clear from the start that it is in fact a manifestation of some fundamental problem in temporal reasoning. Despite its apparent universal nature, however, we know of no attempt to define the problem in its most general form. This is precisely our aim here. We argue that the frame problem arises from the conflicting desires to reason both rigorously and efficiently about the future. This conflict does not depend on the particular underlying temporal formalism. In particular, we identify two formalism-indepedent problems, called the qualification problem and the extended prediction problem, which subsume the frame problem. To illustrate the fact that these problems are indeed inherent to the prediction task and not to a particular formalism, we show that they arise in two distinct frameworks: classical mechanics, and Hayes' histories notation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Atherton TJ,Kerbyson DJ",,Size invariant circle detection,Image and Vision Computing,1999,17,11,795-803,,,,,1999,,0262-8856,https://www.sciencedirect.com/science/article/pii/S0262885698001607;http://dx.doi.org/10.1016/S0262-8856(98)00160-7,10.1016/S0262-8856(98)00160-7,"The Circle Hough Transform (CHT) has become a common method for circle detection in numerous image processing applications. Various modifications to the basic CHT operation have been suggested which include: the inclusion of edge orientation, simultaneous consideration of a range of circle radii, use of a complex accumulator array with the phase proportional to the log of radius, and the implementation of the CHT as filter operations. However, there has also been much work recently on the definition and use of invariance filters for object detection including circles. The contribution of the work presented here is to show that a specific combination of modifications to the CHT is formally equivalent to applying a scale invariant kernel operator. This work brings together these two themes in image processing which have herewith been quite separate. Performance results for applying various forms of CHT filters incorporating some or all of the available modifications, along with results from the invariance kernel, are included. These are in terms of an analysis of the peak width in the output detection array (with and without the presence of noise), and also an analysis of the peak position in terms of increasing noise levels. The results support the equivalence between the specific form of the CHT developed in this work and the invariance kernel.","Circle Hough Transform, Scale invariance, Circle detection in noise",,,,,,,,,,,,,,,,,,,,,
Journal Article,Lehmer DH,,Multisectioned moments of stirling numbers of the second kind,"Journal of Combinatorial Theory, Series A",1973,15,2,210-224,,,,,1973,,0097-3165,https://www.sciencedirect.com/science/article/pii/S0097316573800081;http://dx.doi.org/10.1016/S0097-3165(73)80008-1,10.1016/S0097-3165(73)80008-1,"The Stirling number of the second kind, S(n, k), enumerates the ways that n distinct objects can be stored in k non-empty indistinguishable boxes. When k is restricted to a given residue class modulo μ, the moments of the distribution S(n, k) have properties associated with the Olivier functions of order μ evaluated at 1 and −1. The simplest example is Dobinski's formula for the Bell numberBn=∑k−0nS(n,k)=e−1∑λ−0∞λn/λ!The treatment is based on combinatorial arguments and umbral calculus.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,St-Denis R,,LGV: A domain knowledge validation environment,Computers & Graphics,1990,14,2,311-320,,,,,1990,,0097-8493,https://www.sciencedirect.com/science/article/pii/009784939090043W;http://dx.doi.org/10.1016/0097-8493(90)90043-W,10.1016/0097-8493(90)90043-W,"This paper describes a software tool that executes logical and graphic requirements specifications for application domains. Entities, activities, and constraints of a real environment are specified and represented by icons, icon transformations, and production rules respectively. The behavior of the system is simulated by executing the production rules combined with an icon animation. The aspects chosen to be modeled are those about operational strategies encountered in distributed or real-time systems. This paper concentrates on design issues, generally leaving aside implementation problems. In particular, we show how to organize a knowledge base and build graphic objects from a formal description of an application domain. Because this tool has been designed within a software engineering context by adopting techniques from artificial intelligence, it can be used in the evolutionary process of knowledge system development for validating knowledge of expert systems.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,van Heijenoort J,"Gandy RO,Hyland JM",Set-Theoretic Semantics,,1977,87,,183-190,,Elsevier,,Logic Colloquium 76,1977,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X09704276;http://dx.doi.org/10.1016/S0049-237X(09)70427-6,10.1016/S0049-237X(09)70427-6,"Publisher Summary This chapter focuses on set-theoretic semantics. Two fundamental acquisitions of modern logic are the notion of formal system and that of interpretation. These two notions somehow complement each other; when a formal language is constructed, the meanings of the symbols, in order to deal with their syntactic relations, are abandoned. The two semantics may have to be used concurrently;first, because a sentence may contain both count terms and mass terms, and second, because the quasi-individual terms obtained from mass terms by a variety of linguistic means, require individuals for their interpretation. There is also, with mass terms, the problem of mixtures, both on the syntactic and on the semantic plane. Because quantifiers cannot be interpreted except in a discrete domain, the proper treatment of mass terms requires a variable-free system. The chapter introduces model theory that has bloomed into an extensive science. But this new discipline does not seem to care much about what was the original object of semantics.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,Ershov YL,"Gandy RO,Hyland JM",Model of Partial Continuous Functionals,,1977,87,,455-467,,Elsevier,,Logic Colloquium 76,1977,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X09704392;http://dx.doi.org/10.1016/S0049-237X(09)70439-2,10.1016/S0049-237X(09)70439-2,"In the last years (most fully in the thesis by M. Hyland [6]) the coincidence of a large number of models of everywhere defined functionals of the finite type has been proved. This coincidence demonstrates the definite significance of the model , which is the model of the bar-recursive functionals theory as well. However, I am convinced that the most natural way of this model determination is in determining it by the natural model of partial continuous functionals, and that it is model that is more fundamental than model , in the general mathematical sense. The most essential point is that partial objects may be built by the successive expansion of finite objects, which are the elements of model . The history of recursive functions theory, in particular, shows that only after the introduction of the notion “partially recursive function” into usage this theory acquired well-composed structure. Further account is divided into two parts. The first and larger part contains the definitions and the properties of some classes of topological spaces, the efficience of which, I presume, is not covered by the construction of model or the models of λ-calculus [2]. The second part contains the main results concerning model .",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,"Baldwin LL,Hoffman S,Miller DD","Baldwin LL,Hoffman S,Miller DD",20 - Installing OpenVMS Software,,2003,,,487-522,Second Edition,Digital Press,Burlington,OpenVMS System Management Guide (Second Edition),2003,9781555582432,,https://www.sciencedirect.com/science/article/pii/B9781555582432500219;http://dx.doi.org/10.1016/B978-155558243-2/50021-9,10.1016/B978-155558243-2/50021-9,"Publisher Summary This chapter discusses the steps for installing freeware and provides an overview of OpenVMS installation. OpenVMS installation uses PRODUCT that is the preferred tool used to install layered products. The VMSINSTAL script predated PRODUCT and was used for many years for layered product installation.. Most freeware packages are zipped, although some follow the UNIX convention of GZ and tar. There are freeware packages to deal with all of these formats available on the process.com site. ZIP compresses the package, which in turn reduces download time. A benefit of the ZIP format is that it effectively checksums the files and assures proper download delivery. Normally the compilation step is not necessary. Linking is normally necessary so the precompiled objects can be linked with the OpenVMS version-specific run-time libraries. Some packages require that a command be defined as a symbol, that is a foreign command, and some must be formally defined with a command definition. If the freeware package is a management tool only, one must take care to protect the .EXE file. To make it more secure, one should not start these tools to SYSTARTUP_VMS.COM. Instead, add the startup command to SYSTEM's LOGIN.COM script.",,,HP Technologies,,,,,,,,,,,,,,,,,,,
Journal Article,"Fiech A,Huth M",,Algebraic domains of natural transformations,Theoretical Computer Science,1994,136,1,57-78,,,,,1994,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759400122Y;http://dx.doi.org/10.1016/0304-3975(94)00122-Y,10.1016/0304-3975(94)00122-Y,"Motivated by the semantics of polymorphic programming languages and typed λ-calculi, by formal methods in functor category semantics, and by well-known categorical and domain-theoretical constructs, we study domains of natural transformations F→̇G of functors F, G:Ω→C with a small category Ω as source and a cartesian closed category of Scott-domains C as target. We put constraints on the image arrows of the functors to obtain that F→̇G is an object in C. Inf-faithful domains F→̇G allow that infima in F→̇G can be computed in each component [FA→GA] separately. If F, G:Ω→SCOTT are two functors such that for all f in mor(Ω) the maps F(f) preserve finite elements and G(f) preserve all nonempty infima, then F→̇G is inf-faithful, and all inf-faithful domains are Scott-domains. Familiar notions like “inverse limits”, “small products”, and “strict function spaces” are special instances of functors that meet the conditions above. We extend these results to retracts of Scott-domains.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Barker J,Hoogi A,Depeursinge A,Rubin DL",,Automated classification of brain tumor type in whole-slide digital pathology images using local representative tiles,Medical Image Analysis,2016,30,,60-71,,,,,2016,,1361-8415,https://www.sciencedirect.com/science/article/pii/S1361841515001838;http://dx.doi.org/10.1016/j.media.2015.12.002,10.1016/j.media.2015.12.002,"Computerized analysis of digital pathology images offers the potential of improving clinical care (e.g. automated diagnosis) and catalyzing research (e.g. discovering disease subtypes). There are two key challenges thwarting computerized analysis of digital pathology images: first, whole slide pathology images are massive, making computerized analysis inefficient, and second, diverse tissue regions in whole slide images that are not directly relevant to the disease may mislead computerized diagnosis algorithms. We propose a method to overcome both of these challenges that utilizes a coarse-to-fine analysis of the localized characteristics in pathology images. An initial surveying stage analyzes the diversity of coarse regions in the whole slide image. This includes extraction of spatially localized features of shape, color and texture from tiled regions covering the slide. Dimensionality reduction of the features assesses the image diversity in the tiled regions and clustering creates representative groups. A second stage provides a detailed analysis of a single representative tile from each group. An Elastic Net classifier produces a diagnostic decision value for each representative tile. A weighted voting scheme aggregates the decision values from these tiles to obtain a diagnosis at the whole slide level. We evaluated our method by automatically classifying 302 brain cancer cases into two possible diagnoses (glioblastoma multiforme (N = 182) versus lower grade glioma (N = 120)) with an accuracy of 93.1 % (p << 0.001). We also evaluated our method in the dataset provided for the 2014 MICCAI Pathology Classification Challenge, in which our method, trained and tested using 5-fold cross validation, produced a classification accuracy of 100% (p << 0.001). Our method showed high stability and robustness to parameter variation, with accuracy varying between 95.5% and 100% when evaluated for a wide range of parameters. Our approach may be useful to automatically differentiate between the two cancer subtypes.","Digital pathology, Computer aided diagnosis, Object classification",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Chen Q,Chu WW","Kim W,Nicolas JM,Nishio S",HILOG: A HIGH-ORDER LOGIC PROGRAMMING LANGUAGE FOR NON-1NF DEDUCTIVE DATABASES,,1990,,,431-452,,North-Holland,Amsterdam,Deductive and Object-Oriented Databases,1990,9780444884336,,https://www.sciencedirect.com/science/article/pii/B9780444884336500319;http://dx.doi.org/10.1016/B978-0-444-88433-6.50031-9,10.1016/B978-0-444-88433-6.50031-9,"A formal framework of a strongly typed logic programming language with high-order terms (HILOG) is developed which extends Logic Programming (LP) from First-Order Logic (FOL) and which generalizes deductive databases to handle non-normalized relations. To remedy the limitations of current approaches by treating complex objects as function terms of the FOL, we reformulate the key Logic Programming (LP) notions through the introduction of appropriate mathematical concepts such as partial containment, packing and unpacking. In this paper, we have developed the extended notion of the satisfaction, the existence of a minimal model closure, the uniqueness of a standard (packed) minimal model for a HILOG program, the model p-intersection theorem, and the extended least fixpoint characteristics of the HILOG minimal model. Therefore, HILOG provides a canonical framework for high-order LP in which semantics covers the key points of LP. HILOG Language has the capabilities of representing structured knowledge and type hierarchies which are important for integrating the LP notions to other programming systems for handling complex objects and for developing non-1NF deductive databases. An example is given to demonstrate the use of HILOG in representing structured knowledge and in deductive retrieval of complex objects.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Goldblatt R,Chapter 2 - What Categories are,,1984,98,,17-36,,Elsevier,,Topoi,1984,,0049-237X,https://www.sciencedirect.com/science/article/pii/B9780444867117500103;http://dx.doi.org/10.1016/B978-0-444-86711-7.50010-3,10.1016/B978-0-444-86711-7.50010-3,"Publisher Summary This chapter discusses that a category can initially be conceived as a universe of mathematical discourse, and that such a universe is determined by specifying a certain kind of object and a certain kind of function between objects. The chapter also discusses the pathology of abstraction. Identifying the notion of a category is one of the basic modi operandi of pure mathematics; it is called abstraction. It begins with the recognition, through experience and examination of a number of specific situations, that certain phenomena occur repeatedly, that there are a number of common features, that there are formal analogies in the behavior of different entities. Then comes the actual process of abstraction, wherein these common features are singled out and presented in isolation; an axiomatic description of an abstract concept.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Anders U,Mainka EU,Rabe G",,Tools and Methodologies for Quality Assurance,IFAC Proceedings Volumes,1990,23,6,113-118,,,,,1990,,1474-6670,https://www.sciencedirect.com/science/article/pii/S1474667017521874;http://dx.doi.org/10.1016/S1474-6670(17)52187-4,10.1016/S1474-6670(17)52187-4,"Nowadays the qualification and assessment of microprocessor based safety related systems cannot be done manually. Therefore a set of tools has been developed which consists of disassemblers for an important group of microprocessors, a control flow analyser and a data flow analyser. To do the analysis unaffected by errors in the documentation, compilers or linkers it starts from the object code. The disassemblers supply direct metric survey information about the programs. Further result files of the diassemblers are processed by the control flow analyser and data flow analyser. All tools give hints on formal errors on the one hand, on the other hand they deliver accounts that allow an efficient semantic analysis of the control and data flow. A large amount of safety relevant applications can be ascertained by this method.","Computer control, computer evaluation, programmable controllers, quality control, software tools, Computer evaluation","IFAC/EWICS/SARS Symposium on Safety of Computer Control Systems 1990 (SAFECOMP'90), Gatwick, UK, 30 October-November 2, 1990",,,,,,,,,,,,,,,,,,,,
Journal Article,"Kieburtz RB,Nordström B",,The design of Apple—A language for modular programs,Computer Languages,1985,10,1,1-22,,,,,1985,,0096-0551,https://www.sciencedirect.com/science/article/pii/0096055185900074;http://dx.doi.org/10.1016/0096-0551(85)90007-4,10.1016/0096-0551(85)90007-4,"Sometimes programming is difficult because of the amount of detail that is relevant to the problem being solved. A suitable language for these problems should aid the programmer in organizing a program as a synthesis of parts. Apple is a language designed for such applications. It is a typed language in which functions are objects, and it provides three complementary ways to modularize programs. These are the definition of environments, the use of functional abstraction, and the use of data abstraction or parameterized, abstract data types. In this paper we describe the main features of Apple, and explain the motivation for many of the design decisions. Another document furnishes a formal definition.","Functional programming, Abstract data types, Static environments, Type polymorphism",,,,,,,,,,,,,,,,,,,,,
Journal Article,Chaitin GJ,,Algorithmic entropy of sets,Computers & Mathematics with Applications,1976,2,3,233-245,,,,,1976,,0898-1221,https://www.sciencedirect.com/science/article/pii/089812217690016X;http://dx.doi.org/10.1016/0898-1221(76)90016-X,10.1016/0898-1221(76)90016-X,In a previous paper a theory of program size formally identical to information theory was developed. The entropy of an individual finite object was defined to be the size in bits of the smallest program for calculating it. It was shown that this is −log2 of the probability that the object is obtained by means of a program whose successive bits are chosen by flipping an unbiased coin. Here a theory of the entropy of recursively enumerable sets of objects is proposed which includes the previous theory as the special case of sets having a single element. The primary concept in the generalized theory is the probability that a computing machine enumerates a given set when its program is manufactured by coin flipping. The entropy of a set is defined to be −log2 of this probability.,,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Iosif-Lazăr AF,Wąsowski A",,Trustworthy variant derivation with translation validation for safety critical product lines,Journal of Logical and Algebraic Methods in Programming,2016,85,6,1154-1176,,,,,2016,,2352-2208,https://www.sciencedirect.com/science/article/pii/S2352220816000146;http://dx.doi.org/10.1016/j.jlamp.2016.02.001,10.1016/j.jlamp.2016.02.001,"Software product line (SPL) engineering facilitates development of entire families of software products with systematic reuse. Model driven SPLs use models in the design and development process. In the safety critical domain, validation of models and testing of code increases the quality of the products altogether. However, to maintain this trustworthiness it is necessary to know that the SPL tools, which manipulate models and code to derive concrete product variants, do not introduce errors in the process. We propose a general technique of checking correctness of product derivation tools through translation validation. We demonstrate it using Featherweight VML—a core language for separate variability modeling relying on a single kind of variation point to define transformations of artifacts seen as object models. We use Featherweight VML with its semantics as a correctness specification for validating outputs of a variant derivation tool. We embed this specification in the theorem proving system Coq and develop an automatic generator of correctness proofs for translation results within Coq. We show that the correctness checking procedure is decidable, which allows the trustworthy proof checker of Coq to automatically verify runs of a variant derivation tool for correctness. We demonstrate how such a simple validation system can be constructed, by using this to validate variant derivation of a simple variability model implementation based on the Eclipse Modeling Framework. We hope that this presentation will encourage other researchers to use translation validation to validate more complex correctness properties in handling variability, as well as demonstrate to commercial tool vendors that formal verification can be introduced into their tools in a very lightweight manner.",,NWPT 2013,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Colajinni B,de Grassi M,Naticchia B,di Manzo M",Gero JS,Can planning be a research paradigm in architectural design?,,1991,,,23-48,,Butterworth-Heinemann,,Artificial Intelligence in Design '91,1991,9780750611886,,https://www.sciencedirect.com/science/article/pii/B9780750611886500065;http://dx.doi.org/10.1016/B978-0-7506-1188-6.50006-5,10.1016/B978-0-7506-1188-6.50006-5,"In the present paper we discuss the possible use of ‘planning’°°A distinction should be drawn between the meanings attributed to the words planning and planner in the field of Artificial Intelligence on the one hand, and in city and land planning on the other. In this paper, the terms planning and planner are used in their accepted meanings in the field of Artificial Intelligence. to support architectural design. Architectural design is conceived as a process incorporating non-trivial subprocesses consisting of evolutionary sequences of drawings. The ‘planner’ can be viewed as a tool capable of managing the automatic development of formal descriptions of architectural objects, according to goals and constraints which are interactively assigned or removed by the designer. The main features of a ‘planner’ dedicated to architectural design are then put forward. The system has been implemented at the University of Ancona, Italy.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Halpin T,Halpin T,10 - Relational Mapping,,2001,,,403-456,,Academic Press,San Diego,Information Modeling and Relational Databases,2001,9781558606722,,https://www.sciencedirect.com/science/article/pii/B9781558606722500130;http://dx.doi.org/10.1016/B978-155860672-2/50013-0,10.1016/B978-155860672-2/50013-0,"Publisher Summary Most database modeling tools allow entering a data model in one or more high-level notations like Entity-Relationship (ER), IDEF1X, Object-Role Modeling (ORM), and Unified Modeling Language (UML), as well as in logical-level notations (like Relational). A high-level (conceptual or semiconceptual) schema must be mapped down to a logical and then physical schema in order for the database to be populated and queried. Because of the dominance of relational database systems, the relational model is used for the logical schema. The basic procedure is discussed for mapping an ORM conceptual schema onto a relational schema. This can be easily adapted to cover mapping from other notations such as entity-relationship or the UML. Furthermore, this chapter presents advanced aspects of relational mapping including the use of conceptual annotations to override default mapping choices (that is, to control how subtypes or 1:1 associations are mapped) and the fundamental constructs in relational database schemas using a genetic notation.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Journal Article,Milner R,,A theory of type polymorphism in programming,Journal of Computer and System Sciences,1978,17,3,348-375,,,,,1978,,0022-0000,https://www.sciencedirect.com/science/article/pii/0022000078900144;http://dx.doi.org/10.1016/0022-0000(78)90014-4,10.1016/0022-0000(78)90014-4,"The aim of this work is largely a practical one. A widely employed style of programming, particularly in structure-processing languages which impose no discipline of types, entails defining procedures which work well on objects of a wide variety. We present a formal type discipline for such polymorphic procedures in the context of a simple programming language, and a compile time type-checking algorithm W which enforces the discipline. A Semantic Soundness Theorem (based on a formal semantics for the language) states that well-type programs cannot “go wrong” and a Syntactic Soundness Theorem states that if W accepts a program then it is well typed. We also discuss extending these results to richer languages; a type-checking algorithm based on W is in fact already implemented and working, for the metalanguage ML in the Edinburgh LCF system.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dattasharma A,Keerthi SS",,An augmented Voronoi roadmap for 3D translational motion planning for a convex polyhedron moving amidst convex polyhedral obstacles,Theoretical Computer Science,1995,140,2,205-230,,,,,1995,,0304-3975,https://www.sciencedirect.com/science/article/pii/030439759400191K;http://dx.doi.org/10.1016/0304-3975(94)00191-K,10.1016/0304-3975(94)00191-K,"This paper concerns the development of a piecewise linear Voronoi roadmap for translating a convex polyhedron in a three-dimensional (3-D) polyhedral world. In general the Voronoi roadmap is incomplete for motion planning, i.e., it can have several disjoint components in one connected component of free space. An analysis of the roadmap shows that incompleteness is caused by the occurrence of the following simple geometric structure: a polygon in the Voronoi surface containing one or more polygons inside it. We formally bring out the details of this geometric structure and give an efficient augmentation of the roadmap that makes it complete. We show that the roadmap has size e = O(n2Q2l2), where n is the total number of faces on the obstacles, Q is the total number of obstacles and l is the number of faces on the moving object. We also present an algorithm to construct the roadmap in O((n + Ql)e + Q2log Q) time.",,Design and Analysis of Geometrical Algorithms for Robot Motion Planning and Vision,,,,,,,,,,,,,,,,,,,,
Journal Article,"Shock RC,Hartrum TC",,A classification scheme for software modules,Journal of Systems and Software,1998,42,1,29-44,,,,,1998,,0164-1212,https://www.sciencedirect.com/science/article/pii/S0164121298000053;http://dx.doi.org/10.1016/S0164-1212(98)00005-3,10.1016/S0164-1212(98)00005-3,"The current abstract view of the detailed architecture of a software program simply focuses on a set of modules that interact with each other. The pictorial view of the architecture of modules abstracts to a directed, connected, acyclic graph whose nodes are modules and whose arcs reveal the reference dependency relationship. No distinction exists among the modules. This paper provides a decided distinction. This paper introduces a new, formal, objective classification scheme of ten classes for modules. The process of fashioning the classification scheme applies the software principle of information hiding to three internal structural components of a module. These components are the variable, the data structure, and the subprogram. Two conceptual constructs enable information hiding. One is the encapsulation of a data structure (object). The other is the inaccessible section of a module which is the section that no external module can reference. Each module belongs to exactly one class. The assignment of a module to a class is objective, not subjective. The scheme opens up the opportunity for a deeper study into each class. The classes of the scheme are subjectively ranked into four categories, ranging from best to worst. The paper lists five benefits of this classification scheme, and relates these benefits to three application areas.","Module, Classification, Encapsulation, Information hiding",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sokolsky O,Viswanathan M",,"Preface: Volume 89, Issue 2",Electronic Notes in Theoretical Computer Science,2003,89,2,246-247,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105810527;http://dx.doi.org/10.1016/S1571-0661(05)81052-7,10.1016/S1571-0661(05)81052-7,"Foreword This volume contains the proceedings of the Third International Workshop on Run-time Verification (RV '03). RV '03 was held on July 13, 2003, as a satellite workshop of the International Conference of Computer-Aided Verification (CAV '03). The first two workshops in this series were also held as satellite workshops of CAV; RV '01 was held in Paris in July 2001, and RV '02 was held in Copenhagen in July 2002. The purpose of this series of workshops has been to bring together researchers and practitioners, interested in various aspects related to the dynamic analysis of software and systems, with respect to formally specified correctness requirements. Run-time verification aims to provide a “lightweight” complement to traditional verification methods like model checking and theorem proving, by analysing an actual implementation with respect to the reduced correctness obligations of certifying the correctness of a single execution. Despite the weaker guarantees, run-time verification improves upon other more ad-hoc approaches in monitoring, by providing formal proofs. The papers selected for this year's workshop cover a wide range of topics related to runtime verification, including designing efficient and optimal verification algorithms, techniques for instrumenting programs at the source or object code/byte code level to observe program execution, developing specification languages for monitors, dynamic program analysis, and formally proving the correctness of monitoring systems. This volume includes these papers and the abstract of the Invited Presentation by the Invited Presentation by Aloysius K. Mok (University of Texas at Austin). The volume will be published in the Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs. We would like to thank the Program Committee members and their reviewers, who did an excellent job evaluating the submissions and shaping the program of the workshop. We are grateful to the Steering Committee for helpful guidance and support. Special thanks go to Al Mok for agreeing to be the Invited Speaker. Thanks to the CAV '03 co-Chairs: Warren A. Hunt, Jr. (University of Texas at Austin) and Fabio Somenzi (University of Colorado at Boulder) for the opportunity to continue the tradition of having the RV workshops as CAV satellites. July 1, 2003Oleg SokolskyMahesh Viswanathan Program Committee Saddek BensalemVERIMAG LaboratoryRance CleavelandState University of New York at Stony BrookAnn GatesUniversity of Texas, El PasoPatrice GodefroidBell LaboratoriesGerard HolzmannNASA/JPL Laboratory for Reliable SoftwareSusan HorwitzUniversity of Wisconsin, MadisonMichael MoellerUniversity of OldenburgAloysius K. MokUniversity of Texas, AustinHenny SipmaStanford UniversityOleg SokolskyUniversity of PennsylvaniaScott StollerState University of New York at Stony BrookMahesh ViswanathanUniversity of Illinois at Urbana-ChampaignSergio YovineVERIMAG LaboratoryLenore ZuckNew York University Steering Committee Klaus HavelundNASA Ames Research Center - Kestrel TechnologyInsup LeeUniversity of PennsylvaniaGrigore RosuUniversity of Illinois at Urbana-Champaign",,"RV '2003, Run-time Verification (Satellite Workshop of CAV '03)",,,,,,,,,,,,,,,,,,,,
Book Chapter,"Anders U,Mainka EU,Rabe G",Daniels BK,TOOLS AND METHODOLOGIES FOR QUALITY ASSURANCE,,1990,,,113-118,,Pergamon,Amsterdam,Safety of Computer Control Systems 1990 (Safecomp '90),1990,9780080409535,,https://www.sciencedirect.com/science/article/pii/B9780080409535500258;http://dx.doi.org/10.1016/B978-0-08-040953-5.50025-8,10.1016/B978-0-08-040953-5.50025-8,"Abstract Nowadays the qualification and assessment of microprocessor based safety related systems cannot be done manually. Therefore a set of tools has been developed which consists of disassemblers for an important group of microprocessors, a control flow analyser and a data flow analyser. To do the analysis unaffected by errors in the documentation, compilers or linkers it starts from the object code. The disassemblers supply direct metric survey information about the programs. Further result files of the diassemblers are processed by the control flow analyser and data flow analyser. All tools give hints on formal errors on the one hand, on the other hand they deliver accounts that allow an efficient semantic analysis of the control and data flow. A large amount of safety relevant applications can be ascertained by this method.",,,IFAC Symposia Series,,,,,,,,,,,,,,,,,,,
Book Chapter,Mascré D,"Grattan-Guinness I,Cooke R,Corry L,Crépel P,Guicciardini N","Chapter 38 - Benhard Riemann, posthumous thesis on the representation of functions by trigonometric series (1867)",,2005,,,491-505,,Elsevier Science,Amsterdam,Landmark Writings in Western Mathematics 1640-1940,2005,9780444508713,,https://www.sciencedirect.com/science/article/pii/B9780444508713501194;http://dx.doi.org/10.1016/B978-044450871-3/50119-4,10.1016/B978-044450871-3/50119-4,"Publisher Summary In his thesis on the representation of functions by trigonometric series,, prepared for a doctoral defence in 1854 but published only after his death, Riemann refined the understanding of the integral and especially opened a new era in the handling of Fourier series. Riemann argued that “the Fourier series does not necessarily belong to the first class: it was therefore impossible, to deduce its convergence from the law according to which terms decrease.” A trigonometric series can represent every periodic function with the period 2π that is integrable throughout, does not have infinitely many maxima and minima, and takes on the mean value of its two limiting values wherever its value changes abruptly. It remains that its publication in 1867 gradually opened the way to an incredible number of new theories. The definition of the integral, characterization of integrable functions and introduction of sets of zero Lebesgue measure, study of general trigonometric series, formal integration, relations between real and complex methods in Fourier analysis, fractal objects, scale factors, pseudo-functions and smooth functions, oscillating integrals, and condensation of singularities—all these are concepts and techniques that directly issued from Riemann's idea.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Camurri A,Innocenti C,Massucco C",,"Multi-paradigm software environment for the real-time processing of sound, music and multimedia",Knowledge-Based Systems,1994,7,2,114-126,,,,,1994,,0950-7051,https://www.sciencedirect.com/science/article/pii/0950705194900248;http://dx.doi.org/10.1016/0950-7051(94)90024-8,10.1016/0950-7051(94)90024-8,"The paper introduces a system and a software architecture for the representation and real-time processing of sound, music, and multimedia based on artificial intelligence techniques. This system, called WinProcne/HARP, is able to represent objects in a two-fold formalism—symbolic and analogical—at different levels of abstraction, and to carry out plans according to the user's goals. It also provides both formal and informal analysis capabilities for extracting information. In WinProcne/HARP the user can build, update, browse, and merge various knowledge bases of sound, music, and multimedia material, as well as enter queries, start and manage real time performance, using a high-level graphical user interface. The system is currently used by researchers and composers in various experiments, including (a) advanced robotics projects, in which the system is used as a tool for interacting, cotrolling and simulating robot movements, and (b) theatrical automation, where the system is delegated to manage and integrate sound, music, and three-dimensional computer animations of humanoid figures. The paper explicitly refers to some applications in the music field.","AI and music, multimedia knowledge representation, hybrid systems, analogical reasoning",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aljadeff E,Kassel C",,Polynomial identities and noncommutative versal torsors,Advances in Mathematics,2008,218,5,1453-1495,,,,,2008,,0001-8708,https://www.sciencedirect.com/science/article/pii/S0001870808000856;http://dx.doi.org/10.1016/j.aim.2008.03.014,10.1016/j.aim.2008.03.014,"To any cleft Hopf Galois object, i.e., any algebra Hα obtained from a Hopf algebra H by twisting its multiplication with a two-cocycle α, we attach two “universal algebras”AHα and UHα. The algebra AHα is obtained by twisting the multiplication of H with the most general two-cocycle σ formally cohomologous to α. The cocycle σ takes values in the field of rational functions on H. By construction, AHα is a cleft H-Galois extension of a “big” commutative algebra BHα. Any “form” of Hα can be obtained from AHα by a specialization of BHα and vice versa. If the algebra Hα is simple, then AHα is an Azumaya algebra with center BHα. The algebra UHα is constructed using a general theory of polynomial identities that we set up for arbitrary comodule algebras; it is the universal comodule algebra in which all comodule algebra identities of Hα are satisfied. We construct an embedding of UHα into AHα; this embedding maps the center ZHα of UHα into BHα when the algebra Hα is simple. In this case, under an additional assumption, AHα≅BHα⊗ZHαUHα, thus turning AHα into a central localization of UHα. We completely work out these constructions in the case of the four-dimensional Sweedler algebra.","Hopf algebra, Comodule algebra, Galois extension, Cocycle, Polynomial identity",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Morik K,Kietz JU",Segre AM,A BOOTSTRAPPING APPROACH TO CONCEPTUAL CLUSTERING,,1989,,,503-504,,Morgan Kaufmann,San Francisco (CA),Proceedings of the Sixth International Workshop on Machine Learning,1989,9781558600362,,https://www.sciencedirect.com/science/article/pii/B9781558600362501326;http://dx.doi.org/10.1016/B978-1-55860-036-2.50132-6,10.1016/B978-1-55860-036-2.50132-6,"Publisher Summary This chapter reviews a bootstrapping approach to conceptual clustering. It is based on an inference engine with facts and rules represented in a restricted first order predicate logic. Facts and rules can be viewed as observations and the input to the learning procedure. Its output is a lattice of concept descriptions with inheritance represented in the KL-ONE knowledge representation language. This can be viewed as a domain theory or conceptual structure of the domain. The domains and types of descriptors need not be given to the system in advance as a part of the background knowledge but are learned in the course of concept formation using the same learning algorithm. This is a bootstrapping approach to conceptual clustering, because the concepts to be learned are described using concepts which in turn are learned—both by the same procedure. The notion of background knowledge covers many different things such as relations between concepts, inference rules, theorems, structured domains of variables, and applicability of attributes. Concepts and roles are organized in a lattice, the Tbox. Exploiting the formal properties of a lattice, a classifier puts a concept definition in its place in the concept taxonomy. The basis for the learning procedure is the basic taxonomy of primitive concepts that follows straightforward from the facts.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Kreisel G,Krivine JL",Appendix II Foundations of Mathematics,,1967,48,,160-164,,Elsevier,,Elements of Mathematical Logic,1967,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08717294;http://dx.doi.org/10.1016/S0049-237X(08)71729-4,10.1016/S0049-237X(08)71729-4,"Publisher Summary This chapter discusses the foundations of mathematics. Foundational studies are concerned with describing and analyzing intuitive or informal mathematics, that is, mathematics as understood by ordinary working mathematicians. Informal mathematics is reformulated in a formal language (for example, that of set theory). Compared with the language of informal mathematics such formal languages have a very restricted vocabulary and a perfectly exact grammar, with a consequent increase in precision and freedom from inessential features. If one holds the view that intuitive mathematics is essentially concerned with certain (abstract) objects, one will be led to a realist theory of these basic objects: in such a system of foundations, the meaning of intuitive statements is analyzed in terms of this theory and the rules of reasoning are deduced from the laws obeyed by the basic objects. However, if one holds the view that the essence of intuitive mathematics consists in proof or, more specifically, the various kinds of proof, one will be led to an idealist system of foundations, which refers to mathematical activity itself.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,Reutenauer C,,Séries formelles et algèbres syntactiques,Journal of Algebra,1980,66,2,448-483,,,,,1980,,0021-8693,https://www.sciencedirect.com/science/article/pii/0021869380900976;http://dx.doi.org/10.1016/0021-8693(80)90097-6,10.1016/0021-8693(80)90097-6,"The notion of the syntactic monoid is well known to be very important for formal languages, and in particular for rational languages; examples of that importance are Kleene's theorem, Schützenberger's theorem about aperiodic monoid and Eilenberg's theorem about varieties. We introduce here, for formal power series, a similar object: to each formal power series we associate its syntactic algebra. The Kleene-Schützenberger theorem can then be stated in the following way: a series is rational if and only if its syntactic algebra has finite dimension. A rational central series (this means that the coefficient of a word depends only on its conjugacy class) is a linear combination of characters if and only if its syntactic algebra is semisimple. Fatou properties of rational series in one variable are extended to series in several variables and a special case of the rationality of the Hadamard quotient of two series is positively answered. The correspondence between pseudovarieties of finite monoids and varieties of rational languages, as studied by Eilenberg, is extended between pseudovarieties of finite dimensional algebras and varieties of rational series. We study different kinds of varieties that are defined by closure properties and prove a theorem similar to Schützenberger's theorem on aperiodic monoids.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Olson JE,Olson JE,Chapter 5 - Data Quality Issues Management,,2003,,,80-102,,Morgan Kaufmann,San Francisco,Data Quality,2003,9781558608917,,https://www.sciencedirect.com/science/article/pii/B9781558608917500081;http://dx.doi.org/10.1016/B978-155860891-7/50008-1,10.1016/B978-155860891-7/50008-1,"Publisher Summary This chapter describes how issues are created and managed that originate from data inaccuracy discoveries. Data quality improvements are long-term and very public tasks. The data quality assurance group cannot function in isolation. The other departments engaged in the data acquisition, management, and use activities are very integral parts of the process and need to be included in the process at all steps. They also need to accept the goal of better-quality data and welcome efforts rather than resist them. Issues can have a very long life that leads to the need for formal treatment of them as business objects. Issue resolutions are often considered interruptive to the normal flow of work through departments that develop and deploy information technology. They will tend to get sidetracked easily if not monitored and placed in front of management on a regular basis. These activities need to become the normal flow of work. Monitoring data quality and making corrections to improve it should not be considered a nuisance, but should be considered a regular part of information systems operations. This chapter highlights the need to coordinate the activities of data quality assurance with the complete information systems agenda.",,,The Morgan Kaufmann Series in Data Management Systems,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Bultheel A,Van Barel M",Chapter 6 Linear systems and partial realization,,1997,6,,271-349,,Elsevier,,"Linear Algebra, Rational Approximation and Orthogonal Polynomials",1997,,1570-579X,https://www.sciencedirect.com/science/article/pii/S1570579X97800080;http://dx.doi.org/10.1016/S1570-579X(97)80008-0,10.1016/S1570-579X(97)80008-0,"This chapter will serve to introduce several concepts from linear system theory and to give an interpretation of the previously obtained results in this context. Since it is our experience that specialists in approximation theory are not always familiar with the notions and the terminology from linear systems, we think that it is worth introducing the basic concepts. Eventually we shall work with and apply our results to very specific systems that can be defined quickly. However, we think that then the meaning of certain assumptions will be lost and in that case one is playing with mathematical objects that haven't any physical interpretation. This is what we want to prevent and therefore we start with the most general situation and introduce several concepts at the lowest possible level. We hope that this will give the reader a grip on what all the terminology means. Of course we restrict ourselves to the bare minimum since we do not have the ambition to rewrite any of the excellent books on linear system theory that already exist. The reader is warmly recommended to consult the extensive literature [36, 101, 165, 169]. Linear system theory is a place where many mathematical disciplines meet. In harmony with the previous chapters of the book, we shall give a rather formal algebraic treatment. So most of the definitions will be given for a commutative field. However at a certain point this will not be possible anymore. We then switch from formal series and rational forms to functions of a complex variable. In contrast with this relatively extensive introduction, our interpretation of the results of previous chapters will be relatively short. Most of the theorems will be just reformulations of earlier ones in a different terminology without needing a new proof. Other results, like the theory of orthogonal polynomials with respect to a Toeplitz moment matrix, as we have discussed it, will be definitely too thin to serve system theoretic demands. In both cases, the discussion will be brief.",,,Studies in Computational Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,Cooper SB,"Prawitz D,Skyrms B,Westerståhl D",Rigidity and definability in the noncomputable universe,,1995,134,,209-235,,Elsevier,,"Logic, Methodology and Philosophy of Science IX",1995,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X06800467;http://dx.doi.org/10.1016/S0049-237X(06)80046-7,10.1016/S0049-237X(06)80046-7,"Publisher Summary This chapter discusses the rigidity and definability in the noncomputable universe. A noncomputable universe is intimately connected with the world of everyday mathematics. This noncomputability is of a fundamental nature, and does not arise from mere practical limitations such as those on capacity of memory or duration of computational processes. An important aim of recursion theory is to investigate the context of interesting mathematical objects within the noncomputable universe, and Kleene and Post proposed the degrees of unsolvability as an appropriate theoretical framework, or fine structure theory, within which to do this. The subsequent development of local degree theory is largely based on autonomy of interest and motivation through which evolved elegant techniques and striking results, while its general impact amongst mathematicians and computer scientists is limited by its seeming preoccupation with pathology and technique of evermore prohibitive complexity. There are of course a number of notions on which to base a useful fine structure theory, of which two are especially important—namely, many-one reducibility and Turing reducibility. Many-one reductions are historically significant as the recursion theoretic analogues of natural translations between formal theories, while Turing reducibility includes all possible notions of effective computability relative to oracles.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,Aczel P,"Barcan Marcus R,Dorn GJ,Weingartner P",The Type Theoretic Interpretation of Constructive Set Theory: Inductive Definitions,,1986,114,,17-49,,Elsevier,,"Logic, Methodology and Philosophy of Science VII",1986,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X09706834;http://dx.doi.org/10.1016/S0049-237X(09)70683-4,10.1016/S0049-237X(09)70683-4,"Publisher Summary Constructive set theory is a possible framework for the formalization of constructive mathematics. The chapter describes the formal system CZF+DC and its type theoretic interpretation. An inductive definition usually involves the characterization of a collection of objects as the smallest collection satisfying certain closure conditions. Such a characterization can be made explicit in one of at least two ways. The first way is to define the collection as the intersection of all collections that satisfies the closure conditions. Such an explicit definition is thoroughly impredicative in that the collection is defined using quantification over all collections. The second way is to build up the collection from below as the union of a hierarchy of stages. These stages of the inductive definition are indexed using some suitable notion of “ordinal.” The paradigm for a direct understanding of an inductive definition is that for the collection of natural numbers, which is characterized as the smallest collection containing zero and closed under the successor function.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Theodorakis M,Analyti A,Constantopoulos P,Spyratos N",,A theory of contexts in information bases,Information Systems,2002,27,3,151-191,,,,,2002,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437901000369;http://dx.doi.org/10.1016/S0306-4379(01)00036-9,10.1016/S0306-4379(01)00036-9,"Although semantic data models provide expressive conceptual modeling mechanisms, they do not support context, i.e. providing controlled partial information on conceptual entities by viewing them from different viewpoints or in different situations. In this paper, we present a model for representing contexts in information bases along with a set of operations for manipulating contexts. These operations support context creation, update, copy, union, intersection, and difference. In particular, our operations of context union, intersection, and difference are different from those of set theory as they take into account the notion of context. However, they also satisfy the important properties of commutativity, associativity, and distributivity. Our model contributes to the efficient handling of information, especially in distributed, cooperative environments, as it enables (i) representing (possibly overlapping) partitions of an information base; (ii) partial representations of objects, (iii) flexible naming (e.g. relative names, synonyms and homonyms), (iv) focusing attention, and (v) combining and comparing different partial representations. This work advances towards the development of a formal framework intended to clarify several theoretical and practical issues related to the notion of context. The use of context in a cooperative environment is illustrated through a detailed example.","Information modeling, Contexts, Abstractions, Cooperative environments, Views, Versions, Workspaces, Viewpoints",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Sahoo SS,Valdez J,Kim M,Rueschman M,Redline S",,ProvCaRe: Characterizing scientific reproducibility of biomedical research studies using semantic provenance metadata,International Journal of Medical Informatics,2019,121,,10-18,,,,,2019,,1386-5056,https://www.sciencedirect.com/science/article/pii/S1386505618302697;http://dx.doi.org/10.1016/j.ijmedinf.2018.10.009,10.1016/j.ijmedinf.2018.10.009,"Objective Reproducibility of research studies is key to advancing biomedical science by building on sound results and reducing inconsistencies between published results and study data. We propose that the available data from research studies combined with provenance metadata provide a framework for evaluating scientific reproducibility. We developed the ProvCaRe platform to model, extract, and query semantic provenance information from 435, 248 published articles. Methods The ProvCaRe platform consists of: (1) the S3 model and a formal ontology; (2) a provenance-focused text processing workflow to generate provenance triples consisting of subject, predicate, and object using metadata extracted from articles; and (3) the ProvCaRe knowledge repository that supports “provenance-aware” hypothesis-driven search queries. A new provenance-based ranking algorithm is used to rank the articles in the search query results. Results The ProvCaRe knowledge repository contains 48.9 million provenance triples. Seven research hypotheses were used as search queries for evaluation and the resulting provenance triples were analyzed using five categories of provenance terms. The highest number of terms (34%) described provenance related to population cohort followed by 29% of terms describing statistical data analysis methods, and only 5% of the terms described the measurement instruments used in a study. In addition, the analysis showed that some articles included a higher number of provenance terms across multiple provenance categories suggesting a higher potential for reproducibility of these research studies. Conclusion The ProvCaRe knowledge repository (https://provcare.case.edu/) is one of the largest provenance resources for biomedical research studies that combines intuitive search functionality with a new provenance-based ranking feature to list articles related to a search query.","Scientific reproducibility, Provenance metadata, W3C PROV specifications, ProvCaRe ontology, S3 model, Provenance-based ranking, ProvCaRe knowledge repository",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mouton F,Leenen L,Venter HS",,"Social engineering attack examples, templates and scenarios",Computers & Security,2016,59,,186-209,,,,,2016,,0167-4048,https://www.sciencedirect.com/science/article/pii/S0167404816300268;http://dx.doi.org/10.1016/j.cose.2016.03.004,10.1016/j.cose.2016.03.004,"The field of information security is a fast-growing discipline. Even though the effectiveness of security measures to protect sensitive information is increasing, people remain susceptible to manipulation and thus the human element remains a weak link. A social engineering attack targets this weakness by using various manipulation techniques to elicit sensitive information. The field of social engineering is still in its early stages with regard to formal definitions, attack frameworks and templates of attacks. This paper proposes detailed social engineering attack templates that are derived from real-world social engineering examples. Current documented examples of social engineering attacks do not include all the attack steps and phases. The proposed social engineering attack templates attempt to alleviate the problem of limited documented literature on social engineering attacks by mapping the real-world examples to the social engineering attack framework. Mapping several similar real-world examples to the social engineering attack framework allows one to establish a detailed flow of the attack whilst abstracting subjects and objects. This mapping is then utilised to propose the generalised social engineering attack templates that are representative of real-world examples, whilst still being general enough to encompass several different real-world examples. The proposed social engineering attack templates cover all three types of communication, namely bidirectional communication, unidirectional communication and indirect communication. In order to perform comparative studies of different social engineering models, processes and frameworks, it is necessary to have a formalised set of social engineering attack scenarios that are fully detailed in every phase and step of the process. The social engineering attack templates are converted to social engineering attack scenarios by populating the template with both subjects and objects from real-world examples whilst still maintaining the detailed flow of the attack as provided in the template. Furthermore, this paper illustrates how the social engineering attack scenarios are applied to verify a social engineering attack detection model. These templates and scenarios can be used by other researchers to either expand on, use for comparative measures, create additional examples or evaluate models for completeness. Additionally, the proposed social engineering attack templates can also be used to develop social engineering awareness material.","Bidirectional communication, Indirect communication, Mitnick's attack cycle, Social engineering, Social engineering attack detection model, Social engineering attack examples, Social engineering attack framework, Social engineering attack scenario, Social engineering attack templates, Unidirectional communication",,,,,,,,,,,,,,,,,,,,,
Journal Article,Arthur JD,,Toward a formal specification of menu-based systems,Journal of Systems and Software,1987,7,1,73-82,,,,,1987,,0164-1212,https://www.sciencedirect.com/science/article/pii/0164121287900094;http://dx.doi.org/10.1016/0164-1212(87)90009-4,10.1016/0164-1212(87)90009-4,"As software systems continue to increase in sophistication and complexity, so do the interface requirements that support the corresponding user interaction. To select the proper blend of ingredients that constitutes an adequate user interface, it is essential that the system designer have a firm understanding of the interaction process, i.e., how the selected dialogue format interacts with the user and with the underlying task software. To promote such an understanding, this paper presents a model that characterizes one particular dialogue format: menu-based interaction. This model is actually a sequence of models, hierarchically structured, in which each successive model builds on its predecessor by introducing additional characterization elements. The first model describes the minimal set of elements inherent to any menu-based interface; successive models extend this minimal set by introducing task actions, incremental history sequences, and frame-associated memory. These principal model elements enable the characterization of fundamental, menu-based operations like computational and decision processes, user response reversal, and user directed movement. Moreover, because the principal model elements correspond directly to “real world” objects, an intuitive as well as formal understanding of menu-based interaction can be achieved. Effectively, the model elements and the hierarchical structure imposed by these elements provide an ideal environment for characterizing and classifying menu-based systems at various levels of sophistication.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bellamy JA,Butters JN",,Experiments evaluating holograms in professional communication,Optics and Lasers in Engineering,1981,2,3,189-202,,,,,1981,,0143-8166,https://www.sciencedirect.com/science/article/pii/0143816681900191;http://dx.doi.org/10.1016/0143-8166(81)90019-1,10.1016/0143-8166(81)90019-1,"The potential of holograms to achieve improved communication in education and training tasks has been investigated. Experiments in education have been carried out at the secondary level and additionally observations of pupil reactions have been observed for younger children. The holograms were found to command attention which is an important aspect of teaching. Some typical examples of the use of holograms included communication of visual information recorded from rare museum exhibits and science examples in physics and biology. The holograms were capable of displaying images in true perspective, thus conveying the same information as a model or real object, but being conviniently reproduced and requiring a minimum of maintenance and storage space. The experiments were extended to training in two study areas where interest was expressed by tutors and there was a willingness to cooperate in the creation and use of training material in holographic form. The areas concerned were in foundry technology and textiles. The requirements in foundry technology were to assist students in the comprehension of the solid form from engineering drawings and the reverse requirement to produce adequate engineering drawings to define a cast form. In the textile case holograms were used to assist the comprehension of the relationship between stitch form and fabric properties and to identify machine faults from stitch irregularities. The number of students formally tested was small leaving statistical analysis inconclusive, but tutors using holograms found that students learned faster when holograms were made available. As a parallel investigation, three undergraduate engineering students used holographic communication as the subject of their project. Subjects included a tutorial display of a carburettor showing the outside form with air and fuel passages in correct perspective. Other examples showed the transmission arrangement in a Mercedes car and the arrangement of cams for a new ‘Locstitch’ textile machine. Holograms also found use in communication between a UK laboratory and overseas manufacturer to explain the effect of bearing lubricant cavitation. The work was carried out during a period of rapid development of the holographic process and the initial holograms were difficult to use since they required special monochromatic light sources. Later developments used white light reflection holograms which were much more convinient to use. The cost of producing holograms can also be expected to fall. All holograms used in the trials were individually made in the laboratory, but developments in ‘printed’ holograms promise reduced costs in the future. It is to be expected that holograms will in future be used in distance learning packages and possibly in textbooks.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Gómez L,Haesevoets S,Kuijpers B,Vaisman AA",,Spatial aggregation: Data model and implementation,Information Systems,2009,34,6,551-576,,,,,2009,,0306-4379,https://www.sciencedirect.com/science/article/pii/S0306437909000131;http://dx.doi.org/10.1016/j.is.2009.03.002,10.1016/j.is.2009.03.002,"Data aggregation in Geographic Information Systems (GIS) is a desirable feature, only marginally present in commercial systems nowadays, mostly through ad hoc solutions. We address this problem introducing a formal model that integrates, in a natural way, geographic data and non-spatial information contained in a data warehouse external to the GIS. This approach allows both aggregation of geometric components and aggregation of measures associated to those components, defined in GIS fact tables. We define the notion of geometric aggregation, a general framework for aggregate queries in a GIS setting. Although general enough to express a wide range of (aggregate) queries, some of these queries can be hard to compute in a real-world GIS environment because they involve computing an integral over a certain area. Thus, we identify the class of summable queries, which can be efficiently evaluated replacing this integral with a sum of functions of geometric objects. Integration of GIS and OLAP (On Line Analytical Processing) is supported also through a language, GISOLAP-QL. We present an implementation, denoted Piet, which supports four kinds of queries: standard GIS, standard OLAP, geometric aggregation (like “total population in states with more than three airports”), and integrated GIS-OLAP queries (“total sales by product in cities crossed by a river”, also allowing navigation of the results). Further, Piet implements a novel query processing technique: first, a process called subpolygonization decomposes each thematic layer in a GIS, into open convex polygons; then, another process (the overlay precomputation) computes and stores in a database the overlay of those layers for later use by a query processor. Experimental evaluation showed that for a wide class of geometric queries, overlay precomputation outperforms R-tree-based techniques, suggesting that it can be an alternative for GIS query processing.","Data warehousing, OLAP, GIS, Aggregation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Hummel RA,Zucker SW","Fischler MA,Firschein O",On the Foundations of Relaxation Labeling Processes,,1987,,,585-605,,Morgan Kaufmann,San Francisco (CA),Readings in Computer Vision,1987,9780080515816,,https://www.sciencedirect.com/science/article/pii/B9780080515816500581;http://dx.doi.org/10.1016/B978-0-08-051581-6.50058-1,10.1016/B978-0-08-051581-6.50058-1,"A large class of problems can be formulated in terms of the assignment of labels to objects. Frequently, processes are needed which reduce ambiguity and noise, and select the best label among several possible choices. Relaxation labeling processes are just such a class of algorithms. They are based on the parallel use of local constraints between labels. This paper develops a theory to characterize the goal of relaxation labeling. The theory is founded on a definition of consistency in labelings, extending the notion of constraint satisfaction. In certain restricted circumstances, an explicit functional exists that can be maximized to guide the search for consistent labelings. This functional is used to derive a new relaxation labeling operator. When the restrictions are not satisfied, the theory relies on variational calculus. It is shown that the problem of finding consistent labelings is equivalent to solving a variational inequality. A procedure nearly identical to the relaxation operator derived under restricted circumstances serves in the more general setting. Further, a local convergence result is established for this operator. The standard relaxation labeling formulas are shown to approximate our new operator, which leads us to conjecture that successful applications of the standard methods are explainable by the theory developed here. Observations about convergence and generalizations to higher order compatibility relations are described.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Dehbi Y,Plümer L",,Learning grammar rules of building parts from precise models and noisy observations,ISPRS Journal of Photogrammetry and Remote Sensing,2011,66,2,166-176,,,,,2011,,0924-2716,https://www.sciencedirect.com/science/article/pii/S0924271610000924;http://dx.doi.org/10.1016/j.isprsjprs.2010.10.001,10.1016/j.isprsjprs.2010.10.001,"The automatic interpretation of dense three-dimensional (3D) point clouds is still an open research problem. The quality and usability of the derived models depend to a large degree on the availability of highly structured models which represent semantics explicitly and provide a priori knowledge to the interpretation process. The usage of formal grammars for modelling man-made objects has gained increasing interest in the last few years. In order to cope with the variety and complexity of buildings, a large number of fairly sophisticated grammar rules are needed. As yet, such rules mostly have to be designed by human experts. This article describes a novel approach to machine learning of attribute grammar rules based on the Inductive Logic Programming paradigm. Apart from syntactic differences, logic programs and attribute grammars are basically the same language. Attribute grammars extend context-free grammars by attributes and semantic rules and provide a much larger expressive power. Our approach to derive attribute grammars is able to deal with two kinds of input data. On the one hand, we show how attribute grammars can be derived from precise descriptions in the form of examples provided by a human user as the teacher. On the other hand, we present the acquisition of models from noisy observations such as 3D point clouds. This includes the learning of geometric and topological constraints by taking measurement errors into account. The feasibility of our approach is proven exemplarily by stairs, and a generic framework for learning other building parts is discussed. Stairs aggregate an arbitrary number of steps in a manner which is specified by topological and geometric constraints and can be modelled in a recursive way. Due to this recursion, they pose a special challenge to machine learning. In order to learn the concept of stairs, only a small number of examples were required. Our approach represents and addresses the quality of the given observations and the derived constraints explicitly, using concepts from uncertain projective geometry for learning geometric relations and the Wakeby distribution together with decision trees for topological relations.","Inductive logic programming, Attribute grammar, 3D model, Uncertain projective geometry, Probability distributions","Quality, Scale and Analysis Aspects of Urban City Models",,,,,,,,,,,,,,,,,,,,
Book Chapter,Stegmüller W,"Suppes P,Henkin L,Joja A,Moisil GC",Carnap's Normative Theory of Inductive Probability,,1973,74,,501-513,,Elsevier,,"Proceedings of the Fourth International Congress for Logic, Methodology and Philosophy of Science, Bucharest, 1971",1973,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X09703829;http://dx.doi.org/10.1016/S0049-237X(09)70382-9,10.1016/S0049-237X(09)70382-9,"Publisher Summary This chapter discusses Carnap's normative theory of inductive probability. The problem of induction is to include all kinds of endeavor to formulate rules either for finding yet-undiscovered laws or for justifying proposed hypothetical laws. The objects Carnap's investigates are not any more formal object languages but conceptual systems consisting of individuals, families of attributes and functions. Systems of this kind usually contain much more than could be expressed within a language. With the help of two devices, Carnap succeeds in connecting Tarski semantics with mathematical measure theory. His first device consists in representing whole models by n-place functions Z based on an indexing of the various entities of his domain. Carnap's second device consists in identifying the model functions with the points of the possibility space and taking as the class of propositions the σ-field generated by the class of the atomic propositions.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Pudlák P,Springsteel FN",,Complexity in mechanized hypothesis formation,Theoretical Computer Science,1979,8,2,203-225,,,,,1979,,0304-3975,https://www.sciencedirect.com/science/article/pii/0304397579900458;http://dx.doi.org/10.1016/0304-3975(79)90045-8,10.1016/0304-3975(79)90045-8,"Practical questions of computability are studied for a special mechanized method designed to suggest scientific hypotheses on the basis of sampled data: the so-called GUHA method. In simplified terms our GUHA system accepts particular data as a binary (or, binary plus “x”: unknown) input matrix, which relates objects in the sample to a common set of yes-or-no properties. It seeks to output factual (non-tautologous) formal sentences, which are true in the data and so yield general hypotheses for the universe of all such objects. This paper is the first detailed analysis of the algorithmic complexity of this type of system, by considering the time (number of steps) needed to solve its basic decision problem: whether some factual sentence, of various pre-specified forms, will be so output. The resulting time bounds are functions of changeable input size and give minima for overall system complexity. In fact, when judged by the norm for efficient computability of polynomial-time, we present here both some positive and some closely related “negative” results: e.g. the distinction between P-time and NP-completeness (usually considered to be exponential time) often depends only on being given binary or ternary data, the basic question being existence of a true elementary disjunction. Quite similar results are true for sentences with either classical or non-classical (statistically motivated) quantifiers. Moreover, some closely related two-valued problems, involving input parameters to bound desired sentence length, resisted all our efforts to place them as P-time or NP-complete and have an apparently intermediate complexity. At least they are concrete candidates for the (theoretical) hierarchy of P-reducible degrees between P and NP (assuming P ≠ NP.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Rosenfeld A,Strong JP",Tou JT,A Grammar for Maps,,1971,2,,227-239,,Elsevier,,Computer and Information Sciences–1969,1971,,1386-369X,https://www.sciencedirect.com/science/article/pii/B9780126962024500206;http://dx.doi.org/10.1016/B978-0-12-696202-4.50020-6,10.1016/B978-0-12-696202-4.50020-6,"Publisher Summary This chapter describes a grammar for maps. Grammars whose sentences are not strings of symbols, but rather sets of symbols that can be interconnected in more general ways, are of importance in connection with the formal theory of picture processing and description. One of the most general formalisms of this kind deals with sentences, which are labeled directed graphs, that is, webs. Webs arise naturally in connection with descriptions of pictures; a description can present the relations among objects or regions in the given picture, so that it can be represented by a web whose vertices represent regions and whose edges indicate related pairs of regions. As pictures are planar, the webs that arise in this way can mostly be planar. When a graph is used to represent the adjacency relation between regions in the plane, not all of the topological information about the regions is preserved.",,,SEN Report Series Software Engineering,,,,,,,,,,,,,,,,,,,
Journal Article,Cronin T,,Automated reasoning with contour maps,Computers & Geosciences,1995,21,5,609-618,,,,,1995,,0098-3004,https://www.sciencedirect.com/science/article/pii/0098300494001009;http://dx.doi.org/10.1016/0098-3004(94)00100-9,10.1016/0098-3004(94)00100-9,"An extension of binary search into two dimensions is applied to the issue of automated interpretation of contour maps. A contour map, more formally known as a topographic line map, may be perceived as a hierarchy of nested contours. Once a map is organized into a sorted data structure termed a contour containment graph, the power of binary search may be invoked to achieve O(log n) time complexity during a topographical query, where n is the number of contours that comprise a specific map subdivision. A topographical query is a request by a user to interpret the position of an arbitrary coordinate, termed the query point, in the context of a contour map background. An “interpretation” is defined to be five pieces of information: the label of the map subdivision within which the query point resides; the topographical contour of the subdivision that encloses the query point; the local elevation at the point; and the two components of slope at the point—the gradient and aspect angle. An investigation of the tradeoff in precision and performance of the new algorithm is included, in the context of contoured versus gridded representations of terrain. It is suggested that the best features of the contour approach be integrated with the best features of algorithms which process gridded digital elevation models.","Contour map, Raster, Vector, Binary search, Object-orientation",,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Goldblatt R,Chapter 12 - Categorial Set Theory,,1984,98,,289-331,,Elsevier,,Topoi,1984,,0049-237X,https://www.sciencedirect.com/science/article/pii/B9780444867117500206;http://dx.doi.org/10.1016/B978-0-444-86711-7.50020-6,10.1016/B978-0-444-86711-7.50020-6,"Publisher Summary This chapter discusses the categorial set theory. A topos in general is understood as a generalized universe of sets. There are many topoi whose structure is markedly different from that of Set, the domain of classical set theory. Even within a topos that has classical logic, there may be an infinity of truth-values, noninitial objects that lack elements, and distinct arrows not distinguished by elements of their domain. To identify those topoi that look the same as Set one imposes conditions such as well-pointedness and bivalence. However, to say which topoi look like Set, one has to know what Set looks like. It has been talked blithely about the category of all sets without even acknowledging that there might be some doubt as to whether, or why, such a unique thing may exist at all. This matter is resolved by introducing a formal first-order language for set-theory, in which one writes down versions of set-theoretic principles.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Dix J,Leite JA,Satoh K",,Preface,Electronic Notes in Theoretical Computer Science,2002,70,5,204-206,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805985;http://dx.doi.org/10.1016/S1571-0661(05)80598-5,10.1016/S1571-0661(05)80598-5,"Over recent years, the notion of agency has claimed a major role in defining the trends of modern research. Influencing a broad spectrum of disciplines such as Sociology, Psychology, among others, the agent paradigm virtually invaded every sub-field of Computer Science, not least because of the Internet and Robotics. Multi-agent Systems (MAS) are communities of problem-solving entities that can perceive and act upon their environments to achieve their individual goals as well as joint goals. The work on such systems integrates many technologies and concepts in artificial intelligence and other areas of computing. There is a full spectrum of MAS applications that have been and are being developed; from search engines to educational aids to electronic commerce and trade. Although commonly implemented by means of imperative languages, mainly for reasons of efficiency, the agent concept has recently increased its influence in the research and development of computational logic based systems. Computational Logic, by virtue of its nature both in substance and method, provides a well-defined, general, and rigorous framework for systematically studying computation, be it syntax, semantics, procedures, or attending implementations, environments, tools, and standards. Computational Logic approaches problems, and provides solutions, at a sufficient level of abstraction so that they generalise from problem domain to problem domain, afforded by the nature of its very foundation in logic, both in substance and method, which constitutes one of its major assets. The purpose of this workshop is to discuss techniques, based on computational logic, for representing, programming and reasoning about multi-agent systems in a formal way. This is clearly a major challenge for computational logic, to deal with real world issues and applications. The first workshop in this series took place in Las Cruces, New Mexico, USA, in 1999, under the designation Multi-Agent Systems in Logic Programming (MASLP'99), and affiliated with ICLP'99. In the following year, the name of the workshop changed to Computational Logic in Multi-Agent Systems (CLIMA'00), taking place in London, UK, and affiliated with CL'2000. The subsequent edition, CLIMA'01, took place in Paphos, Cyprus, affiliated with ICLP'01. The present edition, CLIMA'02, takes place in Copenhagen, Denmark, on August the 1st of 2002, and is affiliated with ICLP'02 and part of FLOC'02. We would like to thank the authors of the submitted papers, the members of the program committee and the additional reviewers for their contribution to both the meeting and this volume. We would also like to thank Michael Mislove for his help with the editing of the proceedings. Programme Committee Jürgen Dix (The University of Manchester, UK)Thomas Eiter (Vienna University of Technology, Austria)Klaus Fischer (DFKI, Germany)Michael Fisher (University of Liverpool, UK)James Harland (Royal Melbourne Institute of Technology, Australia)Wiebe van der Hoek (Utrecht University, The Netherlands)Katsumi Inoue (Kobe University, Japan)João Alexandre Leite (New University of Lisbon, Portugal)Luís Moniz Pereira (New University of Lisbon, Portugal)Ken Satoh (National Institute of Informatics, Japan)V. S. Subrahmanian (University of Maryland, USA)Francesca Toni (Imperial College, UK)Paolo Torroni (University of Bologna, Italy) Additional Reviewers José AlferesKoji IwanumaAndrea SchalkTadashi AraragiGerhard LakemeyerMichael SchroederAlastair BurtWei LiuKenji TaguchiAnna CiampoliniSeng LokeHans TompitsPierangelo Dell'AcquaHidetomo NabeshimaMirosaw TruszczynskiUwe EglyNaoyuki NideMathijs de WeerdtMichael FinkInna PivkinnaMichael WinikoffChiara GhidiniFabrizio RiguzziCees WitteveenHisashi HayashiChiaki Sakama For this edition of CLIMA, we have received 25 submissions of which 12 were selected for presentation, after a careful review process where each paper was independently reviewed by three members of the Program Committee. The workshop consisted of five sessions: four devoted to the oral presentation of the selected papers and subsequent discussion; and one devoted to a panel discussion, Paolo Torroni being the invited moderator. There follows a brief overview of the workshop. Session 1 - Agents: Arguments and Updates Schroeder and Schweimeier present a framework based on logic programming with 3-valued multi-agent argumentation and fuzzy unification, for knowledge representation and reasoning in agents, to accommodate arguments for negotiating agents when agent communication is subject to uncertainty. Leite et al. extend the language LUPS introducing MLUPS, an update command language designed for specifying the flexible evolution of hierarchically related groups of agents, based on logic programming, thus assigning them declarative semantics. Kakas and Moraïtis present a modular argumentation framework for modelling agent deliberation, where object level arguments can be made conditional on agents' roles and the priority relation amongst such roles can, in turn, be made conditional on contents, on top of which a simple form of abduction allows dealing with incomplete knowledge. Session 2 - Logics for Agents Toyama et al. introduce a translation of multi-agent autoepistemic logic (MAEL), a logic for multi-agent systems based on Moore's autoepistemic logic, into logic programming, and show the correspondence between MAEL extensions and the stable models of the corresponding logic program. Dell'Acqua et al. extend their previous work on abductive logic programming based multi-agent systems, in which agents can update themselves and each other, eliminate contradictory update rules, abduce hypotheses to explain observations, and use them to generate actions, with asynchronous based communication through the use of buffers. Harland and Winikoff discuss the formalisation and implementation issues of BDI-type agents, using a Linear Logic based calculus that allows a mixture of forward- and backward-chaining techniques. Session 3 - BDI Agent Systems Bordini and Moreira investigate how far the Asymmetry Thesis Principles formulated by Rao and Georgeff are actually met by the abstract agent specification language AgentSpeak(L), hence contributing to the reconciliation Between practice and theory of BDI-based agents. Araragi et al. formalise and propose a method to solve a verification problem that arises in implementing a commitment strategy for the BDI architecture, namely the verification of the suitability and/or feasibility of the intentions of an agent. Nide et al. extend with mental state consistency features their previously presented deduction system for CTL-based propositional BDI Logics using sequent calculus, as a step towards the use of the expressive power of BDI Logics as executable specification languages of rational agents. Session 4 - Agents: Speculative Computation and Introspection Hayashi et al. address the issue of integrating speculative computation and action execution through logic programming, namely by devising a method for plan modification when speculative computation fails or actions are executed. Iwanuma and Inoue refine the first-order consequence-finding procedure based on clausal tableaux SOL, with conditional answer computation and skip-preference, to formalise speculative computation in a master-slave multi-agent system. Bolander investigates on finding consistent classes of formulas under the syntactical treatment of knowledge and belief, identifying three maximal sets of introspective beliefs that strong introspective agents can consistently maintain so as to avoid the paradoxes of self-reference. Session 5 - Panel Discussion Torroni moderates a panel discussion entitled \",Logics and Multi-agents: towards a new symbolic model of cognition\,". This volume constitutes the proceedings of CLIMA'02. September 2002, Jürgen Dix, João Alexandre Leite and Ken Satoh (Guest Editors)",,,,,,,,,,,,,,,,,,,,
Journal Article,Moiseev NN,,Methods of dynamic programming in the theory of optimum controls.: II. The general case of additive functionals,USSR Computational Mathematics and Mathematical Physics,1965,5,1,58-75,,,,,1965,,0041-5553,https://www.sciencedirect.com/science/article/pii/0041555365900674;http://dx.doi.org/10.1016/0041-5553(65)90067-4,10.1016/0041-5553(65)90067-4,"In Part I of this paper [1] some problems of the calculus of variations were considered, whose numerical solutions could be constructed by a special organisation of excess using a control scale. The method developed in Part I, however, enabled us to consider only a very narrow class of problems. For instance, our reasonings ceased to be valid if the object was to minimize the functional ∫0T F(x, u)dt, where x is a vector which satisfies the differential equation x′ = ƒ(x, u), where u is the control.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Rieger L,Chapter 3 - RECURSIVE CONSTRUCTION OF THE RELATION OF CONSEQUENCE,,1967,,,38-69,,Academic Press,,Algebraic Methods of Mathematical Logic,1967,9781483231235,,https://www.sciencedirect.com/science/article/pii/B9781483231235500070;http://dx.doi.org/10.1016/B978-1-4832-3123-5.50007-0,10.1016/B978-1-4832-3123-5.50007-0,"Publisher Summary This chapter discusses fundamental descriptively-syntactic and semantic rules, recursive construction of the relation of consequence, and theorems on the relation of consequence, and the deduction theorem. A symbolic language of any mathematical theory has to supply a certain minimum number of basic expressive means, that is, a certain minimum of basic mathematical symbols and also of logical particles. Such a minimum of expressive means is provided by a list of basic symbols of two kinds: (1) Individual in determinates, that is, symbols, which may acquire the meaning of arbitrary objects of some basic domain of individuals and (b) Predicate constants, that is, symbols that stand for certain binary or n-ary relations between individuals or for their properties. The chapter presents a mathematically correct syntactic definition (construction) of the set of symbolized theorems of the given idealized theory, the theorems being certain (finite) sequences of basic symbols. The chapter also discusses the recursive construction of the logico-syntactic relation of (formal) consequence between sentential expressions of a symbolized and idealized mathematical theory.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Zaki M,,Design of a graphics interface for computer-based biomedical applications,Computer Languages,1988,13,3,125-141,,,,,1988,,0096-0551,https://www.sciencedirect.com/science/article/pii/0096055188900203;http://dx.doi.org/10.1016/0096-0551(88)90020-3,10.1016/0096-0551(88)90020-3,"In the design of a graphics system two essential factors are always considered. These two factors are the picture processing and the human interface to the computing system. This paper presents an Integrated Interface for Display Generation, IIDG. The design approach of the IIDG system relies on combining the formal grammar for identifying the user actions and the grammatical description of objects into a single context-free grammar. Such grammar represents the input of an interface generator which produces IIDG by using an LR parsing method. Since IIDG is naturally machine-dependent, the grammar which describes the user actions is chosen to be supported by a known hardware system. This grammar is analyzed and its compatibility for implementation is pointed out. Hence a detailed study of a particular biomedical application is given to mechanize the identification of submedian and telocentric chromosomes. The mechanization is based on exploiting the context free grammar to find the canonical collections of the corresponding LR parser. These collections provide the states of a deterministic finite automaton and could be used to construct the parsing table which determines the syntactic structure of a chromosome.","Structural description, Context-free grammar, Action language, Productions, Terminal symbols, String simplicity, Structural consistency, Display generation, Items, Canonical collections, Parsing toble, LR parser",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Levine KM,Masters P",Kahn PM,SYMBOLIC INFORMATION PROCESSING,,1980,,,131-154,,Academic Press,,Computational Probability,1980,9780123946805,,https://www.sciencedirect.com/science/article/pii/B9780123946805500134;http://dx.doi.org/10.1016/B978-0-12-394680-5.50013-4,10.1016/B978-0-12-394680-5.50013-4,"Publisher Summary Symbolic information processing is born of looking at problems in an algebraic, rather than arithmetic, manner. The process of abstraction, from object to symbol, underlies every theoretical model of computation. The Turing machine paradigm is not the only one. Other equally valid formalisms exist; some exhibit more algebraic behavior than others. Although literally isomorphic to Turing's machine, Church's λ calculus is aesthetically of a different nature. The aesthetics make a difference, because the human mind can comprehend very little of the content of a large computer program. This chapter presents the analysis of an algorithm that differentiates polynomials. The traditional solution of the business data processing problem has been the human wave handwritten COBOL program. The economic considerations dictate that in these times of ever-increasing hardware capability per dollar, a more automated solution be found. A solution can be found in the form of a somewhat smart computer program—LINDA.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cannon M,Slotine JJ",,Space-frequency localized basis function networks for nonlinear system estimation and control,Neurocomputing,1995,9,3,293-342,,,,,1995,,0925-2312,https://www.sciencedirect.com/science/article/pii/0925231295000361;http://dx.doi.org/10.1016/0925-2312(95)00036-1,10.1016/0925-2312(95)00036-1,"Stable neural network control and estimation may be viewed formally as a merging of concepts from nonlinear dynamic systems theory with tools from multivariate approximation theory. This paper extends earlier results on adaptive control and estimation of nonlinear systems using gaussian radial basis functions to the on-line generation of irregularly sampled networks, using tools from multiresolution analysis and wavelet theory. This yields much more compact and efficient system representations while preserving global closed-loop stability. Approximation models employing basis functions that are localized in both space and spatial frequency admit a measure of the approximated function's spatial frequency content that is not directly dependent on reconstruction error. As a result, these models afford a means of adaptively selecting basis functions according to the local spatial frequency content of the approximated function. An algorithm for stable, on-line adaptation of output weights simultaneously with node configuration in a class of non-parametric models with wavelet basis functions is presented. An asymptotic bound on the error in the network's reconstruction is derived and shown to be dependent solely on the minimum approximation error associated with the steady state node configuration. In addition, prior bounds on the temporal bandwidth of the system to be identified or controlled are used to develop a criterion for on-line selection of radial and ridge wavelet basis functions, thus reducing the rate of increase in network's size with the dimension of the state vector. Experimental results obtained by using the network to predict the path of an unknown light bluff object thrown through air, in an active-vision based robotic catching system, are given to illustrate the network's performance in a simple real-time application.","Neural networks, Neurocontrol, Adaptive nonlinear control, Function approximation, multi-resolution analysis","Control and Robotics, Part III",,,,,,,,,,,,,,,,,,,,
Journal Article,Roberto (Member EURASIP) V,,Knowledge-based understanding of signals: An introduction,Signal Processing,1993,32,1,29-56,,,,,1993,,0165-1684,https://www.sciencedirect.com/science/article/pii/0165168493900359;http://dx.doi.org/10.1016/0165-1684(93)90035-9,10.1016/0165-1684(93)90035-9,"The paper provides an introductory review to the knowledge-based approach to signal understanding. Basic issues in knowledge-based system (KBS) design are presented following current methodologies, and peculiarities of interpretive problems are discussed in this context. Formal descriptions are given in terms of objects and tasks, the former denoting abstract data and concept representations, the latter generic knowledge-processing steps (numerical, inferential). Understanding patterns is seen as a sequence of task activations; control is a body of knowledge providing a system with dynamical focus of attention. Tasks are analysed by means of examples from the geophysical domain. Strong and weak points of the KBS approach are also discussed, to give an insight into achievements and current limitations: researchers in signal processing are expected to play an important rôle in future developments. Zusammenfassung Der Artikel gibt eine einführende Übersicht zum wissensbasierten Verstehen von Signalen. Grundsätzliche Probleme des Entwurfs wissensbasierter Systeme werden gemäβ den aktuellen Methoden dargelegt und Besonderheiten des Problems der Interpretation werden in diesem Kontext diskutiert. Formale Beschreibungen werden mit den Begriffen ‘Objekt’ und ‘Task’ gegeben, wobei die ersteren abstrakte Daten- und Begriffsrepräsentationen bezeichnen, die letzteren allgemeine Schritte der Wissensverarbeitung (nummerisch, inferenziell). Das Verstehen von Mustern wird als Folge von Taskaktivierungen verstanden; Kontrolle ist ein Wissensbestand, der dem System eine dynamische Steuerung der Aufmerksamkeit ermöglicht. Tasks werden mit Beispielen aus dem Bereich der Geophysik analysiert. Stärken und Schwächen des wissensbasierten Ansatzes werden diskutiert, um einen Einblick in die Möglichkeiten und Grenzen zu geben: es wird erwartet, daβ Forscher im Bereich der Signalverarbeitung eine wichtige Rolle bei künftigen Entwicklungen spielen. Résumé Cet article consiste en un passage en revue introductif de l'approche de la compréhension du signal à base de connaissances. Les aspects fondamentaux de la conception de systèmes à base de connaissances (KBS) sont présentés suivant les méthodologies courantes, et les particularités des problèmes interprétifs sont discutées dans ce contexte. Des descriptions formelles sont données en termes d'objets et de tâches, let premiers dénotant des données abstraites et des représentations de concepts, les secondes des étapes génériques du traitement des connaissances (numériques, inférentes). La compréhension des formes est vue comme une séquence d'activation de tâches; le contrôle est un corpus de connaissances fournissant un système à foyer d'attention dynamique. Les tâches sont analysées au moyen d'examples tirés du domaine de la géophysique. Les points forts et faibles de l'approache KBS sont également discutés afin de donner une aperçu des réalisations et des limitations courantes: les chercheurs en Traitement du Signal sont attendus à jouer un rôle important dans les développements futurs.","Knowledge-based systems, hybrid systems, signal understanding, image understanding, machine vision, automated interpretation, pattern recognition",Intelligent Systems for Signal and Image Understanding,,,,,,,,,,,,,,,,,,,,
Journal Article,"Lopes P,Pino M,Carletti G,Hamidi S,Legué S,Kerhervé H,Benveniste S,Andéol G,Bonsom P,Reingewirtz S,Rigaud AS",,Co-Conception Process of an Innovative Assistive Device to Track and Find Misplaced Everyday Objects for Older Adults with Cognitive Impairment: The TROUVE Project,IRBM,2016,37,2,52-57,,,,,2016,,1959-0318,https://www.sciencedirect.com/science/article/pii/S1959031816000269;http://dx.doi.org/10.1016/j.irbm.2016.02.004,10.1016/j.irbm.2016.02.004,"Purpose: Misplacing or losing personal belongings is a concern of everyday life among people of all ages. Older adults with cognitive impairment are significantly more affected by this problem. It is a source of frustration, anxiety, interpersonal conflict and disability in this population. Informal caregivers are greatly impacted by this problem, which compels them to spend a lot of time searching for misplaced items and comforting the person. Assistive technology could thus be of great benefit in this area. However, existing item locator devices do not appear to meet the needs of older adults with cognitive disorders. The TROUVE project aims to conceive and assess an innovative item locator device that effectively addresses their needs, capacities, and goals. Procedure: The project team conducted a co-design process involving relevant stakeholders (persons with cognitive impairment, informal and formal caregivers, researchers, industry representatives, ethical bodies) using user-tests, focus groups, interviews, and questionnaires. The project plan involved three phases: (1) analysis of end-users' needs, (2) definition of system requirements and iterative prototype development, and (3) prototype assessment. Findings: The analysis of end users' needs and the evaluation of existing item locator devices provided us with details about the items which are the most frequently lost or misplaced by older adults at home and their coping strategies to manage these situations. The analysis of usability problems observed throughout the assessment of existing devices allowed the definition of the system requirements. Prototype assessment showed that spatialized sound can be used to help these users find missing items, and that an item locator device can be part of a more comprehensive assistive and rehabilitation system such as a robot. Conclusions: An item locator that relies on sensory information (spatialized sound) rather than on conceptual reasoning (“the item is located to your left 4 meters away”) appears to be an interesting solution to address the problem of misplacing personal items in elderly with cognitive impairment. Involving end-users and relevant stakeholders throughout the cycle of design and development of assistive technology is an effective method to explore design opportunities and define creative solutions.","Item locator system, Older adults, Alzheimer's disease, Co-design, RFID, Sound localization",TecSan 2012,,,,,,,,,,,,,,,,,,,,
Journal Article,Sørensen HK,,Exceptions and counterexamples: Understanding Abel's comment on Cauchy's Theorem,Historia Mathematica,2005,32,4,453-480,,,,,2005,,0315-0860,https://www.sciencedirect.com/science/article/pii/S0315086004000916;http://dx.doi.org/10.1016/j.hm.2004.11.010,10.1016/j.hm.2004.11.010,"It may seem odd that Abel, a protagonist of Cauchy's new rigor, spoke of “exceptions” when he criticized Cauchy's theorem on the continuity of sums of continuous functions. However, when interpreted contextually, exceptions appear as both valid and viable entities in the early 19th century. First, Abel's use of the term “exception” and the role of the exception in his binomial paper is documented and analyzed. Second, it is suggested how Abel may have acquainted himself with the exception and his use of it in a process denoted critical revision is discussed. Finally, an interpretation of Abel's exception is given that identifies it as a representative example of a more general transition in the understanding of mathematical objects that took place during the period. With this interpretation, exceptions find their place in a fundamental transition during the early 19th century from a formal approach to analysis toward a more conceptual one. Zusammenfassung Es könnte merkwürdig aussehen, daß Abel, ein Protagonist der neuen Strenge von Cauchy, von “Ausnahmen” sprach, als er den Lehrsatz von Cauchy über die Stetigkeit der Reihen von stetigen Funktionen kritisierte. Aber kontextbezogen interpretiert werden Ausnahmen sowohl akzeptable als auch sinnvolle Objekte der Analysis des frühen 19. Jahrhunderts. Zuerst werden Abels Gebrauch des Ausdruckes “Ausnahmen” und die Rolle, die Ausnahme in seinem Binomial-Arbeit spielt, dokumentiert und analysiert. Danach wird angedeutet, wie Abel sich mit den Ausnahmen vertraut gemacht haben könnte, und es wird sein Gebrauch von Ausnahmen in einem Prozess, der “kritischen Revision”, diskutiert. Schliesslich wird eine Interpretation von Abels Ausnahme als Zeichen einer Umwandlung mathematischer Objekte vorgeschlagen. Diese Auslegung zeigt, wie die Ausnahmen ihren Platz in einem fundamentalen Wandel des frühen 19. Jahrhunderts finden, von einem formellen Zugang in Richtung auf eine begrifflichere Auffassung der Mathematik.","Abel, Degen, Exception, Counterexample, Formula-centered, Concept-centered, Critical revision, Cauchy's theorem",,,,,,,,,,,,,,,,,,,,,
Journal Article,Ghilardi S,,An algebraic theory of normal forms,Annals of Pure and Applied Logic,1995,71,3,189-245,,,,,1995,,0168-0072,https://www.sciencedirect.com/science/article/pii/0168007293E00842;http://dx.doi.org/10.1016/0168-0072(93)E0084-2,10.1016/0168-0072(93)E0084-2,"In this paper we present a general theory of normal forms, based on a categorial result (Dubuc, 1974) for the free monoid construction. We shall use the theory mainly for proposictional modal logic, although it seems to have a wider range of applications. We shall formally represent normal forms as combinatorial objects, basically labelled trees and forests. This geometric conceptualization is implicit in (Fine, 1975) and our approach will extend it to other cases and make it more direct: operations of a purely geometric and combinatorial nature (cuts of leaves and roots, renaming labels and more generally segment-by-label replacements) will be introduced in order to give a mathematical description of the basic logical/algebraic constructions (free algebras, morphisms among them, canonical models, the lattice of varieties). We begin (Section 1) by recalling the above-mentioned categorial construction: we need a careful inspection of it because in the various examples considered later (Sections 2 and 3) we plan to deduce from it in a uniform way the normal forms and the description of finitely generated free algebras. This method always works whenever we can describe the category of algebras corresponding to the logic under consideration as a T-objects category. When this simple description seems not to be available, still the general theory might be of some interest, because a description of the category of algebras as a T-objects category plus equation is possible (we shall give examples in Section 5). The central part of the paper (Sections 4 and 5) is more advanced and specific: we show how the general approach presented here can provide some insights even in the basic case of the modal system K. Section 4 contains a contribution to the theory of normal forms, namely the description of the uniform substitution. This result will enable us to give a duality theorem for the category of finitely generated free modal algebras and in Section 5 to provide a characterization of the collections of normal forms which happen to be normal forms for a logic, thus giving a description of the lattice of modal logics. Section 6 (that can be read independently on Section 5) deals with some applications: we shall show how to use normal forms in order to prove for the modal system K the definability of higher-order propositional quantifiers and of the tense operator F (the parallel results for intuitionistic logic are in Pitts, 1992; Ghilardi, 1992; Ghilardi and Zawadowski, 1993). As to the prerequisites, the paper is almost self-contained. The reader is only assumed to have familiarity with standard techniques in algebraic logic (a possible reference is Rasiowa (1974)). Knowledge of the basic facts about adjoint functors is required too, see e.g. McLane (1971) or the appendix.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Blute R,Selinger P",,Preface: Volume 69,Electronic Notes in Theoretical Computer Science,2003,69,,362-365,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805742;http://dx.doi.org/10.1016/S1571-0661(05)80574-2,10.1016/S1571-0661(05)80574-2,"This volume contains the proceedings of the 9th Conference on Category Theory and Computer Science (CTCS'02), which was held at the University of Ottawa from August 15-17, 2002. The purpose of this conference series is the advancement of the foundations of computing using the tools of category theory. Indeed, category theory provides one of the key tools in the analysis of the interaction between logic and the theory of computation. The extent to which category theory has influenced these areas can be seen from the following list of topics, which are typical of the interests of this conference: •coalgebras and computing•concurrent and distributed systems•constructive mathematics•declarative programming and term rewriting•domain theory and topology•foundations of computer security•linear logic•modal and temporal logics•models of computation•program logics, data refinement, and specification•programming language semantics•type theory The list is by no means exhaustive. The vitality of the field is well displayed by the extremely high quality and the diversity of the 18 papers in this volume. For the first time in the history of CTCS, this year's conference was preceded by a “Graduate Student Preconference”, which took place from August 12-14 and which offered introductory courses in areas of importance to the conference. The response to this preconference was extraordinary, with more than 50 students and interested others taking part. This certainly suggests that the field of research of this conference will be strong and active for many years to come. The preconference offered courses in: •Introductory category theory (Susan Niefield)•Categorical logic (Philip Scott)•Concurrency theory (Peter Selinger)•Coalgebraic methods (Jiri Adamek)•Game theory (Robin Cockett)•Linear logic (Rick Blute) To hold this preconference, we received substantial funding from the Centre de Recherches Mathématiques (CRM). We thank them and Jacques Hurtubise, the Director of CRM, for their kind support. Without the help of many individuals in many different capacities, this conference would not have been possible. The editors would especially like to thank the following people: •The organizing committee: ◦E. Moggi, Chair, (Genova)◦S. Abramsky (Oxford)◦P. Dybjer (Chalmers)◦B. Jay (Sydney)◦A. Pitts (Cambridge)•Local organizers: ◦Rick Blute◦Philip Scott•The programme committee: ◦Rick Blute, Chair (Ottawa)◦Robin Cockett (Calgary)◦Thierry Coquand (Chalmers)◦Andrea Corradini (Pisa)◦Thomas Ehrhard (Luminy)◦Ryu Hasegawa (Tokyo)◦Martin Hofmann (Munich)◦Bart Jacobs (Nijmegen)◦Michael Johnson (Macquarie)◦Dusko Pavlovic (Kestrel Institute)◦Alex Simpson (Edinburgh)•Lecturers in the student preconference: ◦Susan Niefield (Union)◦Philip Scott (Ottawa)◦Robin Cockett (Calgary)◦Rick Blute (Ottawa)◦Jiri Adamek (Braunschweig)◦Peter Selinger (Ottawa) Invited speakers CTCS'02 was also lucky to have 4 distinguished invited speakers. They were Eric Goubault (CEA/Saclay), Guy McCusker (Sussex), Peter Selinger (Ottawa), and Paul Syverson (Naval Research Laboratory). Here are the titles and abstracts of their talks: •Eric Goubault - The fundamental category of concurrent processes In this talk, I will present some of the recent advances in the understanding of concurrent computations made with geometric (and of course category-theoretic) reasoning. One very important tool is the fundamental category functor which associates a category of “essential schedules” to the semantics of concurrent processes (seen as some form of partially ordered topological space for instance); hence giving a lot of information about how processes coordinate themselves. I will show how to compute inductively, in some simple cases, this fundamental category; this is part of the “compositionality” problem in concurrency theory. One of the defects is that this category is huge, so I will show how to “compress it” through several constructions of categories of fractions, which again reveal to be fundamental and natural constructions in this framework. This is joint work with Martin Raussen and Emmanuel Haucourt.•Guy McCusker - A graph model for imperative computation. Scott's P-omega graph model is a lambda-algebra based on the observation that continuous endofunctions on P-omega can be represented via their graphs. A graph consists of a set of pairs (S, n) where n is a natural and S is a finite set of naturals.We consider a similar model based on sets of pairs (s,n), where s is a finite sequence rather than a set. Intuitively, this alteration means that we are taking into account the order in which observations are made. This new notion of graph gives rise to a model of affine lambda-calculus which admits an interpretation of imperative constructs including variable assignment, dereferencing and allocation.The category arising as the Karoubi envelope of this untyped model provides a model of typed higher-order imperative computation with an affine type system. An appropriate language of this kind is Reynolds's Syntactic Control of Interference. Our model turns out to be fully abstract for this language. At a concrete level, the model is the same as Reddy's object spaces model, which was the first “state-free” model of a higher-order imperative programming language and an important precursor of games models. Our graph model can therefore be seen as a universal domain for Reddy's model. We also give a simple construction of a category of monoids and relations in which all of this work can be seen to live.•Peter Selinger - Towards a quantum programming language The field of quantum computation suffers from a lack of syntax. In the absence of a convenient programming language, algorithms are frequently expressed in terms of circuits or Turing machines. Neither approach particularly encourages structured programming or abstractions such as data types. In this talk, I describe the syntax and semantics of a simple quantum programming language. The semantics is interesting because it combines notions from geometry of interaction, linear algebra, category theory, and complete partial orders.•Paul Syverson - The Formalization of Anonymity Anonymous communication techniques obscure who is talking to whom and are an important aspect of secure communication. This talk will be an introduction to anonymous communications theory and will be in two parts.The first part of the talk will introduce some of the basic building blocks of anonymous communications systems: proxies, Chaum mixes, DC nets, etc. These offer varying amounts of protection. Typically the stronger the protection afforded by some primitive, the less practical the system that uses it. We will also briefly describe implemented systems, such as Onion Routing and Crowds.In the second part of the talk we will look at some of the ways that have been proposed to define anonymity and related properties. As difficult as it has been to define notions such as authentication and confidentiality, anonymity is even more subtle. For example, protection generally depends on other legitimate users of the system. Otherwise the communicants are exposed. We will set out the various properties in the area, e.g., unobservability or plausible deniability, as well as the attempts to formalize them, e.g., using notions from process algebra and epistemic logic. We will also describe some of the nonformal work on probabilistic and information-theoretic characterizations of anonymity properties. List of accepted papers for CTCS'02 •S. Abramsky and B. Coecke - Physical traces: Quantum vs. classical information processing.•J. Adámek, S. Milius and J. Velebil - On rational monads and free iterative theories.•S. L. Bloom and Z. Ésik - Unique, guarded fixed points in an additive setting.•P. Boudes - Non-uniform hypercoherences.•M. Coccia, F. Gadducci and U. Montanari - GS.Lambda theories: A syntax for higher-order graphs.•R. Cockett and L. Santocanale - Induction, coinduction and adjoints.•E. Haghverdi, P. Tabuada and G. Pappas - Bisimulation relations for dynamical and control systems.•M. Hasegawa - The uniformity principle on traced monoidal categories.•J. Hughes and B. Jacobs - Factorization systems and fibrations: Toward a fibred Birkhoff variety theorem.•J. Koslowski - A monadic approach to polycategories.•J. Laird - A categorical semantics of higher order store.•F. Lamarche - Multiplicative linear logics and fibrations.•P. B. Levy - Adjunction models for call-by-push-value with stacks.•M. E. Maietti - Joyal's arithmetic universes via type theory.•S. Milius - On iteratable endofunctors.•L. Schröder - Classifying categories for partial equational logic.•P. Taylor - Local compactness and the Baire category theorem in abstract Stone duality.•K. Worytkiewicz - Paths and simulations.",,"CTCS'02, Category Theory and Computer Science",,,,,,,,,,,,,,,,,,,,
Journal Article,"Sutton RS,Precup D,Singh S",,Between MDPs and semi-MDPs: A framework for temporal abstraction in reinforcement learning,Artificial Intelligence,1999,112,1,181-211,,,,,1999,,0004-3702,https://www.sciencedirect.com/science/article/pii/S0004370299000521;http://dx.doi.org/10.1016/S0004-3702(99)00052-1,10.1016/S0004-3702(99)00052-1,"Learning, planning, and representing knowledge at multiple levels of temporal abstraction are key, longstanding challenges for AI. In this paper we consider how these challenges can be addressed within the mathematical framework of reinforcement learning and Markov decision processes (MDPs). We extend the usual notion of action in this framework to include options—closed-loop policies for taking action over a period of time. Examples of options include picking up an object, going to lunch, and traveling to a distant city, as well as primitive actions such as muscle twitches and joint torques. Overall, we show that options enable temporally abstract knowledge and action to be included in the reinforcement learning framework in a natural and general way. In particular, we show that options may be used interchangeably with primitive actions in planning methods such as dynamic programming and in learning methods such as Q-learning. Formally, a set of options defined over an MDP constitutes a semi-Markov decision process (SMDP), and the theory of SMDPs provides the foundation for the theory of options. However, the most interesting issues concern the interplay between the underlying MDP and the SMDP and are thus beyond SMDP theory. We present results for three such cases: (1) we show that the results of planning with options can be used during execution to interrupt options and thereby perform even better than planned, (2) we introduce new intra-option methods that are able to learn about an option from fragments of its execution, and (3) we propose a notion of subgoal that can be used to improve the options themselves. All of these results have precursors in the existing literature; the contribution of this paper is to establish them in a simpler and more general setting with fewer changes to the existing reinforcement learning framework. In particular, we show that these results can be obtained without committing to (or ruling out) any particular approach to state abstraction, hierarchy, function approximation, or the macro-utility problem.","Temporal abstraction, Reinforcement learning, Markov decision processes, Options, Macros, Macroactions, Subgoals, Intra-option learning, Hierarchical planning, Semi-Markov decision processes",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Cellérier G,Farnham-Diggory S,CHAPTER 6B - INFORMATION PROCESSING TENDENCIES IN RECENT EXPERIMENTS IN COGNITIVE LEARNING—THEORETICAL IMPLICATIONS,,1972,,,115-123,,Academic Press,,Information Processing in Children,1972,9780122495502,,https://www.sciencedirect.com/science/article/pii/B9780122495502500158;http://dx.doi.org/10.1016/B978-0-12-249550-2.50015-8,10.1016/B978-0-12-249550-2.50015-8,"Publisher Summary This chapter presents the theoretical implications of information processing tendencies in cognitive learning. Structure- and scheme-based representations are two different ways to describe the same observable regularities. They are not trivially equivalent. Their relations are very similar to the ones that can be found in many mathematical systems. The same set of strings of symbols can be described as a Boolean algebra in the classic postulational approach or as cranked out by a formal system. Automata have associated semigroups and there is no simple way to convert one type of representation into the other. The succession of stabilized behaviors in seriation gives rise to a sequence of structural representations of concepts; these concepts and their structure evolve. The process of generating uncoordinated couples can be conceptualized in terms of rules—Piaget's rule of couples. In terms of structure, it is a classification into heavy and light blocks. The corresponding conceptualization is that of weight as an absolute, nonrelational property of objects.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Cugini U,Mandorli F,Vicini I","Olling GJ,Kimura F",USING FEATURES AS KNOWLEDGE FORMALIZATION FOR SIMULTANEOUS ENGINEERING,,1992,,,337-349,,Elsevier,Amsterdam,Human Aspects in Computer Integrated Manufacturing,1992,9780444894656,,https://www.sciencedirect.com/science/article/pii/B9780444894656500326;http://dx.doi.org/10.1016/B978-0-444-89465-6.50032-6,10.1016/B978-0-444-89465-6.50032-6,"The aim of this paper is the presentation of a feature recognition module and how this module is located on the architecture of a new CAD system generation. The research trend on new CAD systems is to develop methodologies that allow a real integration among existing environment in production. Our point of view is that the concept of feature is a good methodology to represent knowledge in the different contexts that compose the production process. Because of features are different in different contexts, tools are required to extract from a common model significant features for each context. Our system architecture is constituted by several functional modules. One of them is the recognition module. This module allows to re-read a common model to reorganize the information related to different contexts. The recognition module implemented is founded on a rule-based architecture that allows a great flexibility and an easy adaptation. The inputs of the system are the solid objects described by using a boundary representation, whereas features are defined by using recognition rules. The later are formalized using a particular re-writing system called CAIL (Conditional Attributed Interactive Lindenmayer system). The use of CAIL supplies a general formal tool for the definition of different features. The rule-based architecture allows to manage new contexts simply introducing new library rules. The systems are written in LISP and at present rules which are able to manage handling and assembling contexts has been created.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Varming C,Birkedal L",,Higher-Order Separation Logic in Isabelle/HOLCF,Electronic Notes in Theoretical Computer Science,2008,218,,371-389,,,,,2008,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066108004167;http://dx.doi.org/10.1016/j.entcs.2008.10.022,10.1016/j.entcs.2008.10.022,"We formalize higher-order separation logic for a first-order imperative language with procedures and local variables in Isabelle/HOLCF. The assertion language is modeled in such a way that one may use any theory defined in Isabelle/HOLCF to construct assertions, e.g., primitive recursion, least or greatest fixed points etc. The higher-order logic ensures that we can show non-trivial algorithms correct without having to extend the semantics of the language as was done previously in verifications based on first-order separation logic [Birkedal, L., N.T. Smith and J.C. Reynolds, Local reasoning about a copying garbage collector, in: Proceedings of the 31st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (2004), pp. 220–231; Yang, H., An example of local reasoning in BI pointer logic: the Schorr-Waite graph marking algorithm (2000)]. We provide non-trivial examples to support this claim and to show how the higher-order logic enables natural assertions in specifications. To support abstract reasoning we have implemented rules for representation hiding and data abstraction as seen in [Biering, B., L. Birkedal and N. Torp-Smith, BI-hyperdoctrines, higher-order separation logic, and abstraction, ACM Trans. Program. Lang. Syst. 29 (2007)]. The logic is represented as lemmas for reasoning about the denotational semantics of the programming language. This follows the definitional approach common in HOL theorem provers, i.e., the soundness of our model only relies on the soundness of Isabelle/HOL [Gordon, M., Introduction to the HOL system, in: HOL Theorem Proving System and Its Applications, 1991., International Workshop on the, 1991, pp. 2–3]. We use our formalization to give a formally verified proof of Cheney's copying garbage collector [Cheney, C.J., A nonrecursive list compacting algorithm, Commun. ACM 13 (1970), pp. 677–678] using a tagged representation of objects. The proof generalizes the results in [Birkedal, L., N.T. Smith and J.C. Reynolds, Local reasoning about a copying garbage collector, in: Proceedings of the 31st ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages (2004), pp. 220–231]. The proof uses an encoding of the separation logic formula this(h) to capture the heap from before the garbage collection and thus shows another novel use of higher-order separation logic.","Copying Garbage Collection, Isabelle/HOL, Reliability, Separation Logic, Verification",Proceedings of the 24th Conference on the Mathematical Foundations of Programming Semantics (MFPS XXIV),,,,,,,,,,,,,,,,,,,,
Book Chapter,Sobolev SL,Sobolev SL,LECTURE 1 - DERIVATION OF THE FUNDAMENTAL EQUATIONS,,1964,,,1-21,,Pergamon,,Partial Differential Equations of Mathematical Physics,1964,9780080104249,,https://www.sciencedirect.com/science/article/pii/B978008010424950007X;http://dx.doi.org/10.1016/B978-0-08-010424-9.50007-X,10.1016/B978-0-08-010424-9.50007-X,"Publisher Summary This chapter discusses derivation of the fundamental equations. The theory of the equations of mathematical physics has, as its object, the study of differential, integral, and functional equations that describe various natural phenomena. A classical theorem of integral calculus enables one to transform the surface integral into a volume integral over the region D bounded by the surface S. The thermal state of a body is defined by its temperature. The transmission of heat from one body to another can take place in several ways. A particle whose mass-centre lies on one side of the surface and has certain energy can transmit energy either by itself passing to the other side of the surface or by colliding with another particle whose mass-centre lies on the other side of the surface.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Agterberg FP,Chapter 6 - Probability and Statistics,,1974,1,,149-192,,Elsevier,,Geomathematics,1974,,0167-5982,https://www.sciencedirect.com/science/article/pii/B9780444410917500112;http://dx.doi.org/10.1016/B978-0-444-41091-7.50011-2,10.1016/B978-0-444-41091-7.50011-2,"Publisher Summary This chapter focuses on probability and statistics. Probability calculus and statistical inference have contributed significantly to the solution of many geologic problems. Statistical considerations form part of almost every application of mathematics in geology. In the earth sciences, the object of study usually is an aggregate of many smaller objects that can be studied individually but, in some situations, only the properties of the aggregate may be meaningful. For example, a sample of sand consists of many grains each of which has many measurable properties. However, only statistical parameters for the entire sand sample, such as an average grain size, are of interest to the geologist. Another example is provided by the average properties of larger masses of rocks. A geophysicist may measure the velocity of seismic waves in various layers of the earth's crust. The resulting numbers are manipulated by using differential equations. These numbers, however, represent averages for assemblages of rocks. A stratigraphic sequence consisting of interbedded shales and sandstone will provide a single average velocity value. This number is useful but only within the framework for the mathematical model formulated by the seismologist.",,,Developments in Geomathematics,,,,,,,,,,,,,,,,,,,
Book Chapter,Kemke C,"Bullinger HJ,Shackel B",Representation of Domain Knowledge in an Intelligent Help System,,1987,,,215-220,,North-Holland,Amsterdam,Human–Computer Interaction–INTERACT '87,1987,9780444703040,,https://www.sciencedirect.com/science/article/pii/B9780444703040500431;http://dx.doi.org/10.1016/B978-0-444-70304-0.50043-1,10.1016/B978-0-444-70304-0.50043-1,"The SINIX Consultant (SC) is an intelligent help system for the SINIX operating system.**SINIX is a UNIX derivative developed by the Siemens AG. The SC project is partially funded by the Siemens AG. It is supposed to answer natural language questions about SINIX concepts and commands and also give unsolicited advice to the user. The basis, in order to fulfill these tasks, is a rich knowledge base with respect to the SINIX system which reflects the technical aspects of the domain as well as a user's view and her use of the system. The SINIX Knowledge Base consists of a taxonomical hierarchy of concepts according to different views or classifications of the domain concepts. Domain concepts are commands and (virtual) objects of the SINIX system; higher level concepts correspond to natural language terms, mental model entities, or more general abstract actions and objects. A single concept is described with respect to it's function, structure, use, and/or relation to other concepts. The main emphasis is on the representation of commands, which includes characterizations of their application and function used for user-adequate explanations. The main ideas of a formal description of their semantics, necessary in order to enable reasoning and problem solving processes, are outlined.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Kaelbling LP,Segre AM,A Formal Framework for Learning in Embedded Systems,,1989,,,350-353,,Morgan Kaufmann,San Francisco (CA),Proceedings of the Sixth International Workshop on Machine Learning,1989,9781558600362,,https://www.sciencedirect.com/science/article/pii/B9781558600362500898;http://dx.doi.org/10.1016/B978-1-55860-036-2.50089-8,10.1016/B978-1-55860-036-2.50089-8,"Publisher Summary This chapter presents a few problems in creating agents that learn about their world, focusing on methods for measuring the performance of learning algorithms for embedded agents. An embedded agent acting in the world can be seen as continually executing a function that maps its perceptual inputs to its effector outputs. It operates in a cycle, receiving an input from the world, doing some computation, and then generating an output that affects the world. The mapping that it uses may have state or memory, allowing its action at any time to depend on the entire stream of inputs that it has received until that time. The problem of programming an agent to behave correctly in an environment is to choose some behavior given that the rest of the parameters of the agent and environment are fixed. One of the most difficult problems that a learning agent must contend with is noise. A learning behavior is a computational object that learns an appropriate behavior for an agent in an environment. Before comparing algorithms for learning behaviors, the criteria on which they are to be judged must be fixed. There are three major considerations that need to be kept in mind in this regard: (1) correctness, (2) convergence, and (3) time–space complexity.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rucker R,Aldowaisan TA",,A design approach for constructing engineering scenario maps,Computers & Mathematics with Applications,1992,23,6,419-440,,,,,1992,,0898-1221,https://www.sciencedirect.com/science/article/pii/089812219290116Y;http://dx.doi.org/10.1016/0898-1221(92)90116-Y,10.1016/0898-1221(92)90116-Y,"We present a cognitively based design approach for the staged construction of a high level linguistic-visual map useful for engineering scenario analysis. This map, which we call a Three Dimensional Conceptual Thematic Map (3D-CT Map), is a linkage of a 3-Dimensional geometric Map (3D-Map) and a semantic net which we have called a Conceptual Thematic Map (CT-Map). The 3D-CT Map is an attempt to specify what is in the environment, where it is, and what is happening to it. The CT-Map component is derived by combining information from two explicit linguistic levels, syntax and semantics. It consists of recursively nested semantic structures linked by thematic roles. The 3D-Map component is derived by combining the information from two explicit visual levels, the 2 1/2 D sketches (which correspond to standard engineering drawings) and three dimensional shape models. The result of these visual combinations is the 3D-Map which shows the object centered three dimensional geometric component of the scenario. Annotating the 3D-Map with selected cross references to the CT-Map constitutes the 3D-CT Map. The theoretical bases of the 3D-CT Map rest on the combined insights of contemporary vision and linguistics researches, principally Ray Jackendoff and David Marr. These linguistic and vision insights are founded on a representationalist view of human understanding and action that includes the formal recognition, analysis, and constructive representation of autonomous levels of mental information structures. Each level of representation has its own set of primitives, well-formedness rules, and links to other levels via inter and intra level correspondence rules. At an even more fundamental level, these insights are in consonance with a view of the human mind/brain as a biological information processor. We illustrate this cognitive design approach by constructing a 3D-CT Map from a scenario drawn from the spatial domain of Numerical Control Part Programming. The inputs to the derivation consist of engineering drawings, a natural-language scenario description of the procedure to be carried out, and the experience of the part programmer. The outputs from the scenario analysis process are: syntactic parse trees, semantic structure graphs, annotated semantic structure graphs (i.e., the CT-Map), 2 12 D sketches of the geometry of the scenario (i.e., engineering drawings), a 3D-Map of the scenario geometry, and finally, a synthesized map of the scenario that links these components together i.e., the Three Dimensional Conceptual Thematic Map.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Bookstein FL,,Shape and the Information in Medical Images: A Decade of the Morphometric Synthesis,Computer Vision and Image Understanding,1997,66,2,97-118,,,,,1997,,1077-3142,https://www.sciencedirect.com/science/article/pii/S107731429790607X;http://dx.doi.org/10.1006/cviu.1997.0607,10.1006/cviu.1997.0607,"In the past decade there have been unprecedented theoretical and practical advances in morphometrics, the multivariate statistics of object shape. In this approach, shapes are defined as equivalence classes of discrete point-sets under the operation of the Euclidean similarity group. Three basic ideas underlie scientific analysis of these constructs. First, a distance (Procrustes distance) between every pair of shapes is characterized by a least-squares formula. This metric makes the set of shapes into a Riemannian manifold (Kendall's shape space) and leads immediately to a sturdy algorithm for averaging samples of shapes. Second, a complete linear multivariate analysis of the equivalence classes goes forward after normal projection of these equivalence classes onto the tangent plane to the manifold in the vicinity of the average shape. Third, effects on shape, such as comparisons of group means, may be visualized by the thin-plate spline, an interpolant that also, indirectly, supplies an orthonormal basis for the tangent space. The methods apply quite generally to representations of scenes in terms of corresponding (landmark) points; many extend to the additional information in smooth curves of characteristic shape. This article reviews the three main features of the present toolkit, the underlying statistical and geometric models, and the extensions, some already demonstrated and some currently under construction, that reach out to the additional information content of biomedical images in common clinical or scientific applications. The tasks for which these tools are suited include standardizing scenes against Euclidean similarity transformations or shear transformations, detecting, testing, encoding, or visualizing patterns of shape variation within or between groups, and averaging images after shape variation is normalized. The optimal protocols the new methods provide for many formal problems of image understanding should be considered for versions of the same problems in diverse other application domains.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Fiume EL,Fiume EL,7 - The Last Word,,1989,,,203-205,,Academic Press,,The Mathematical Structure of Raster Graphics,1989,9780122579608,,https://www.sciencedirect.com/science/article/pii/B9780122579608500142;http://dx.doi.org/10.1016/B978-0-12-257960-8.50014-2,10.1016/B978-0-12-257960-8.50014-2,"Publisher Summary This chapter presents a mathematical structure of raster graphics that was designed to capture the semantics of the important aspects of practical raster graphics systems. For each distinct set of concepts, a notation was adopted that suited that set as best as possible. No attempt was made to develop a single formal specification language that captured all concepts, unless one considers the language of mathematics as fitting into that category. Some of the intuitive notions for which a precise meaning was given include scene, image, object, pixel, texture mapping, clipping, color mapping, visibility, interpenetration, illumination, rendering, rasterization, bitmap, and bit-map operation. Once a mathematical characterization of these notions was established, a number of interesting problems could be posed. The problems includes conformal texture mapping, relation of sorting to the visible surface problem, some approximations to ideal rendering techniques, and complexity of some simple ray-tracing models.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Janas JM,Schwind CB",Findler NV,"EXTENSIONAL SEMANTIC NETWORKS: THEIR REPRESENTATION, APPLICATION, AND GENERATION",,1979,,,267-302,,Academic Press,,Associative Networks,1979,9780122563805,,https://www.sciencedirect.com/science/article/pii/B9780122563805500141;http://dx.doi.org/10.1016/B978-0-12-256380-5.50014-1,10.1016/B978-0-12-256380-5.50014-1,"ABSTRACT This chapter introduces extensional semantic networks (ESNs), a new kind of semantic network that allows two different levels of interpretation, namely, the intensional and the extensional. We present the theoretical background on which these networks have been designed. In addition, we give both precise definitions and practical examples of ESNs and, finally, are concerned with application areas for and the automatic generation of the networks. In an introductory section, we investigate the relationship between concepts and their extensions, i.e., the objects denoted by these concepts; a set of semantic relations that hold between concepts is introduced and some of their properties are derived. Section 2 contains a formal definition of the hierarchical ESNs that are constructed from concepts and relations. Furthermore, the two interpretations of an ESN, on the conceptual level and on the object level, are developed, including a treatment of negation and quantification. Section 3 is concerned with the use of these networks in information retrieval systems and demonstrates the appropriateness of their application in question-answering systems. In Section 4, we discuss how ESNs can be generated automatically from natural language discourse, emphasis being placed on a transparent description of the stepwise generation of a network.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Rathnam S,Madhavan T",,An interactive graphics based visual modelling tool,Mathematical and Computer Modelling,1992,16,4,115-129,,,,,1992,,0895-7177,https://www.sciencedirect.com/science/article/pii/089571779290039N;http://dx.doi.org/10.1016/0895-7177(92)90039-N,10.1016/0895-7177(92)90039-N,"Interactive computer based graphics systems are increasingly being used in modelling environments. In these situations the main design goals for software systems, which support visual output display, are: the ease of prototyping, an easy-to-use interface, a large set of graphic primitives and a powerful image composition scheme. This paper first presents the theoretical basis, and then some of the design issues, for a system we built to aid the visualization of the graphical output from a modelling process. The paper concludes by describing applications of the software in various modelling contexts. The main contribution of our research is that it introduces new and powerful image composition techniques as opposed to providing geometric primitives. The graphical output of any formal mathematical model can be described in terms of either an iterated function system, or a recursive function. We have, in our research, used the recursive function approach to describe graphical objects. This is achieved by creating a context free grammar to describe any recursive function. A picture grammar, that is equivalent to the context free grammar, is then developed. The software implementation section of our work focuses on building an interpreter for the resulting language. The main theoretical issues that we deal with in the paper are the design of the recursive functions and context free grammars for visual modelling tools. The main implementation issues that we deal with in the paper are the design of the dynamic data structures, the LOGO-like command nature of the input interface, the context sensitive help system, the design of complex graphic primitives like splines and panelled polygons, and the creation of composite images using the notion of recursive replacement terminating in primitive geometric structures. The current implementation of the tool has been used in several different contexts. Among them are: the modelling of crystal growths, the animation of dynamic processes (for slides in commercials) and the generation of fractal images (to aid in the creative design of wallpaper and textile patterns).",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Maćkiewicz A,Ratajczak W",,Principal components analysis (PCA),Computers & Geosciences,1993,19,3,303-342,,,,,1993,,0098-3004,https://www.sciencedirect.com/science/article/pii/009830049390090R;http://dx.doi.org/10.1016/0098-3004(93)90090-R,10.1016/0098-3004(93)90090-R,"Principal Components Analysis (PCA) as a method of multivariate statistics was created before the Second World War. However, the wider application of this method only occurred in the 1960s, during the “Quantitative Revolution” in the Natural and Social Sciences. The main reason for this time-lag was the huge difficulty posed by calculations involving this method. Only with the advent and development of computers did the almost unlimited application of multivariate statistical methods, including principal components, become possible. At the same time, requirements arose for precise numerical methods concerning, among other things, the calculation of eigenvalues and eigenvectors, because the application of principal components to technical problems required absolute accuracy. On the other hand, numerous applications in Social Sciences gave rise to a significant increase in the ability to interpret these nonobservable variables, which is just what the principal components are. In the application of principal components, the problem is not only to do with their formal properties but above all, their empirical origins. The authors considered these two tendencies during the creation of the program for principal components. This program—entitled PCA—accompanies this paper. It analyzes consecutively, matrices of variance-covariance and correlations, and performs the following functions: •- the determination of eigenvalues and eigenvectors of these matrices.•- the testing of principal components.•- the calculation of coefficients of determination between selected components and the initial variables, and the testing of these coefficients,•- the determination of the share of variation of all the initial variables in the variation of particular components,•- construction of a dendrite for the initial set of variables,•- the construction of a dendrite for a selected pattern of the principal components,•- the scatter of the objects studied in a selected coordinate system. Thus, the PCA program performs many more functions especially in testing and graphics, than PCA programs in conventional statistical packages. Included in this paper are a theoretical description of principal components, the basic rules for their interpretation and also statistical testing.","Principal Components Analysis, Variance-covariance matrix, Coefficients of determination, Eigenvalues, Eigenvectors, Correlation matrix, Bartlett's statistics, FORTRAN 77",,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Masani PR,Patel RC,Patil DJ","Masani PR,Patel RC,Patil DJ",CHAPTER II - Functions,,1965,,,14-33,,Academic Press,,Elementary Calculus,1965,9781483229577,,https://www.sciencedirect.com/science/article/pii/B9781483229577500088;http://dx.doi.org/10.1016/B978-1-4832-2957-7.50008-8,10.1016/B978-1-4832-2957-7.50008-8,"Publisher Summary Besides the notion of a real number, another fundamental idea required in the calculus is that of a function. This chapter presents sets. A set or class is a collection of objects formed according to some clear-cut rule, such as the set of all Burmese, the set of all integers, and the set of all triangles . The chapter also provides an overview of the classification of real functions. Calculus primarily deals with relations, usually functions, whose values are real numbers and whose arguments are real numbers or ordered pairs of real numbers. Such relations are called as real relations. A constant function is a function such that for all real numbers x, f(x) = c, where c is a given real number. The range of the constant function contains only one member. Real functions, which are not algebraic, are said to be transcendental. The simplest of these with which a student is familiar are the trigonometric, or circular, functions, cos, sin, tan, etc. Numbers can be assigned to objects in many useful ways. The chapter describes quantity as a definite observational or experimental procedure to assign a number or numbers to each object, event, or phenomenon of a certain kind. A number so obtained is called a value of the quantity.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Tendeiro JN,Ten Berge JM,Kiers HA",,"Simplicity transformations for three-way arrays with symmetric slices, and applications to Tucker-3 models with sparse core arrays",Linear Algebra and its Applications,2009,430,4,924-940,,,,,2009,,0024-3795,https://www.sciencedirect.com/science/article/pii/S0024379508004229;http://dx.doi.org/10.1016/j.laa.2008.09.020,10.1016/j.laa.2008.09.020,"Tucker three-way PCA and Candecomp/Parafac are two well-known methods of generalizing principal component analysis to three way data. Candecomp/Parafac yields component matrices A (e.g., for subjects or objects), B (e.g., for variables) and C (e.g., for occasions) that are typically unique up to jointly permuting and rescaling columns. Tucker-3 analysis, on the other hand, has full transformational freedom. That is, the fit does not change when A,B, and C are postmultiplied by nonsingular transformation matrices, provided that the inverse transformations are applied to the so-called core array G̲. This freedom of transformation can be used to create a simple structure in A,B,C, and/or in G̲. This paper deals with the latter possibility exclusively. It revolves around the question of how a core array, or, in fact, any three-way array can be transformed to have a maximum number of zero elements. Direct applications are in Tucker-3 analysis, where simplicity of the core may facilitate the interpretation of a Tucker-3 solution, and in constrained Tucker-3 analysis, where hypotheses involving sparse cores are taken into account. In the latter cases, it is important to know what degree of sparseness can be attained as a tautology, by using the transformational freedom. In addition, simplicity transformations have proven useful as a mathematical tool to examine rank and generic or typical rank of three-way arrays. So far, a number of simplicity results have been attained, pertaining to arrays sampled randomly from continuous distributions. These results do not apply to three-way arrays with symmetric slices in one direction. The present paper offers a number of simplicity results for arrays with symmetric slices of order 2×2,3×3 and 4×4. Some generalizations to higher orders are also discussed. As a mathematical application, the problem of determining the typical rank of 4×3×3 and 5×3×3 arrays with symmetric slices will be revisited, using a sparse form with only 8 out of 36 elements nonzero for the former case and 10 out of 45 elements nonzero for the latter one, that can be attained almost surely for such arrays. The issue of maximal simplicity of the targets to be presented will be addressed, either by formal proofs or by relying on simulation results.","Three-mode component analysis, Candecomp, Parafac, Typical tensorial rank, Tucker transformations, Maximal simplicity, Sparse arrays",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Havelund K,Rosu G",,"Preface: Volume 55, Issue 2",Electronic Notes in Theoretical Computer Science,2001,55,2,287-288,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805778;http://dx.doi.org/10.1016/S1571-0661(05)80577-8,10.1016/S1571-0661(05)80577-8,"RV'2001 Runtime Verification This volume contains the Proceedings of the First Workshop on Runtime Verification (RV'2001). The Workshop was held in Paris, France on 23 July 2001, as a satellite event to CAV'2001. The objective of RV'2001 was to bring scientists from both academia and industry together to debate on how to monitor, analyze and guide the execution of programs. The ultimate longer term goal is to investigate whether the use of lightweight formal methods applied during the execution of programs is a viable complement to the current heavyweight methods proving programs correct always before their execution, such as model checking and theorem proving. Dynamic program monitoring and analysis can occur during testing or during operation. The subject covers several technical fields as outlined below. •Dynamic Program Analysis. Techniques that gather information during program execution and use it to conclude properties about the program, either during test or in operation. Algorithms for detecting multi-threading errors in execution traces, such as deadlocks and data races.•Specification Languages and Logics. Formal methods scientists have investigated logics and developed technologies that are suitable for model checking and theorem proving, but monitoring can reveal new observation-based foundational logics.•Program Instrumentation. Techniques for instrumenting programs, at the source code or object code/byte code level, to emit relevant events to an observer.•Program Guidance. Techniques for guiding the behavior of a program once its specification is violated. This ranges from standard exceptions to advanced planning. Guidance can also be used during testing to expose errors. Both foundational and practical aspects of dynamic monitoring were encouraged. The papers in this volume were reviewed by the program committee consisting, besides editors, of Saddek Bensalem(VERIMAG Laboratory)Rance Cleaveland(State University of New York at Stony Brook)Michael Ernst(Massachusetts Institute of Technology)Patrice Godefroid(Bell Laboratories)Gerard Holzmann(Bell Laboratories)Jim Larus(Microsoft Research)Insup Lee(University of Pennsylvania)John Rushby(SRI International)Joseph Sifakis(VERIMAG Laboratory)Reid Simmons(Carnegie Mellon University)Olog Sokolsky(University of Pennsylvania) also by Susanne Graf, Moonjoo Kim, Oded Maler, Laurent Mounier, and Stavros Tripakis. This volume will be published as volume 55, issue 2, in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL http://www.elsevier.nl/locate/entcs A printed version of the current volume is distributed to the participants at the workshop in Berlin. 23 July 2001 Klaus Havelund, Grigore Rosu",,"RV'2001, Runtime Verification (in connection with CAV '01)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Triantafillou P,Faloutsos C",,Overlay striping and optimal parallel I/O for modern applications,Parallel Computing,1998,24,1,21-43,,,,,1998,,0167-8191,https://www.sciencedirect.com/science/article/pii/S0167819197001154;http://dx.doi.org/10.1016/S0167-8191(97)00115-4,10.1016/S0167-8191(97)00115-4,"Disk array systems are rapidly becoming the secondary-storage media of choice for many emerging applications with large storage and high bandwidth requirements. Striping data across the disks of a disk array introduces significant performance benefits mainly because the effective transfer rate of the secondary storage is increased by a factor equal to the stripe width. However, the choice of the optimal stripe width is an open problem: no general formal analysis has been reported and intuition alone fails to provide good guidelines. As a result one may find occasionally contradictory recommendations in the literature. With this work we first contribute an analytical calculation of the optimal stripe width. Second, we recognize that the optimal stripe width is sensitive to the multiprogramming level, which is not known a priori and fluctuates with time. Thus, calculations of the optimal stripe width are, by themselves only, of little practical use. For this reason we propose a novel striping technique, called overlay striping, which allows objects to be retrieved using a number of alternative stripe widths. We provide the detailed algorithms for our overlay striping method and we study the associated storage overhead and performance improvements and we show that we can achieve near optimal performance for very wide ranges of the possible multiprogramming levels, while incurring small storage overheads.","Disk subsystems, Parallel I/O, Overlay striping",Parallel data servers and applications,,,,,,,,,,,,,,,,,,,,
Journal Article,"Havelund K,Rosu G",,"Preface: Volume 70, Issue 4",Electronic Notes in Theoretical Computer Science,2002,70,4,201-202,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805857;http://dx.doi.org/10.1016/S1571-0661(05)80585-7,10.1016/S1571-0661(05)80585-7,"Runtime Verification 2002 This volume contains the Proceedings of the Second Workshop on Runtime Verification (RV'02). The Workshop was held in Copenhagen, Denmark, on 26 July 2002, as a satellite event to CAV'02. The First Workshop on Runtime Verification (RV'01) was held in Paris, France, on 23 July 2001, as a satellite event to CAV'01. The objective of the RV workshops is to bring scientists from both academia and industry together to debate on how to monitor, analyze and guide the execution of programs. The ultimate longer term goal is to investigate whether the use of lightweight formal methods applied during the execution of programs is a viable complement to the current heavyweight methods proving programs correct always before their execution, such as model checking and theorem proving. Dynamic program monitoring and analysis can occur during testing or during operation. The subject covers several technical fields as outlined below. Dynamic Program Analysis. Techniques that gather information during program execution and use it to conclude properties about the program, either during test or in operation. Algorithms for detecting multi-threading errors in execution traces, such as deadlocks and data races. Specification Languages and Logics. Formal methods scientists have investigated logics and developed technologies that are suitable for model checking and theorem proving, but monitoring can reveal new observation-based foundational logics. Program Instrumentation. Techniques for instrumenting programs, at the source code or object code/byte code level, to emit relevant events to an observer. Program Guidance. Techniques for guiding the behavior of a program once its specification is violated. This ranges from standard exceptions to advanced planning. Guidance can also be used during testing to expose errors. Both foundational and practical aspects of dynamic monitoring were encouraged. Invited speaker was Doron Peled with the paper “Tracing the executions of concurrent programs”. 26 July 2002, Klaus Havelund and Grigore Rosu Program Committee Saddek Bensalem(VERIMAG Laboratory, France)Nikolaj BjornerXDegrees, USARance CleavelandState University of New York at Stony Brook, USAMichael ErnstMassachusetts Institute of Technology, USAPatrice GodefroidBell Laboratories, USAKlaus HavelundNASA Ames Research Center/Kestrel Technology, USAGerard HolzmannBell Laboratories, USASampath KannanUniversity of Pennsylvania, USAJim LarusMicrosoft Research, USAInsup LeeUniversity of Pennsylvania, USAGrigore RosuNASA Ames Research Center/RIACS, USAJohn RushbySRI International, USAJoseph SifakisVERIMAG Laboratory, FranceReid SimmonsCarnegie Mellon University, USAHenny SipmaStanford University, USAOleg SokolskyUniversity of Pennsylvania, USA Organizers Klaus HavelundNASA Ames Research Center/Kestrel Technology, USAGrigore RosuNASA Ames Research Center/RIACS, USA",,"RV'02, Runtime Verification 2002 (FLoC Satellite Event)",,,,,,,,,,,,,,,,,,,,
Journal Article,Marty R,,"Foliated semantic networks: Concepts, facts, qualities",Computers & Mathematics with Applications,1992,23,6,679-696,,,,,1992,,0898-1221,https://www.sciencedirect.com/science/article/pii/0898122192901296;http://dx.doi.org/10.1016/0898-1221(92)90129-6,10.1016/0898-1221(92)90129-6,"This paper suggests a general perception-based theory of representation within the framework of the phenomenology of C. S. Peirce (named by him “phaneroscopy”) by means of the generalization of R. Wille's basic lattice-concepts theory of objects and their attributes. We first summarize Peirce's main categorization of all n-adic relations into three fundamental kinds: Firstness, Secondness and Thirdness (i.e., relations requiring monads, dyads and triads, respectively, in their definitions). His “reduction thesis” reduces all relations of higher adicity into these three kinds. We then use elementary Category Theory to develop “relation-structures” of concepts, relations and higher order relations, based entirely on experienced simple “qualities of feeling”. A relational algebra results which includes semantic nets as relation-structures. In terms of this algebra we use Peirce's “reduction theorem” in order to build a “foliation” of all conceptual/relational-structures by means of levels (“sheets”) algebraically defined. This provides a canonical “normal form” for networks of n-adic relations. This can be done to existing semantic network formalisms to help make sense of phenomenologically confused components. Analogously to Wille's lattice-concepts theory connecting objects and attributes, we define “representation-contexts” connecting two corresponding classes of phenomena formalized in terms of Category Theory by diagrams in a category we call relational structures provided with natural transformations as morphisms. This leads us to a foliated conception of semantic networks with each concept and relation assigned to a particular phenomenological level. Thus a foliated network represents not only a state of things but also the mode of connection of the network with the state of things. One consequence of foliation is that we now have a method for relational subsumption using the generalization-hierarchy of relations. In addition to the insight afforded by this formal analysis, we also obtain a lattice of representation-relations which may be computationally used as an IS-A hierarchy sub-element for the purpose of automatic inference, in all subject-domains involving representation.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Revere D,Turner AM,Madhavan A,Rambo N,Bugni PF,Kimball A,Fuller SS",,Understanding the information needs of public health practitioners: A literature review to inform design of an interactive digital knowledge management system,Journal of Biomedical Informatics,2007,40,4,410-421,,,,,2007,,1532-0464,https://www.sciencedirect.com/science/article/pii/S1532046407000020;http://dx.doi.org/10.1016/j.jbi.2006.12.008,10.1016/j.jbi.2006.12.008,"The need for rapid access to information to support critical decisions in public health cannot be disputed; however, development of such systems requires an understanding of the actual information needs of public health professionals. This paper reports the results of a literature review focused on the information needs of public health professionals. The authors reviewed the public health literature to answer the following questions: (1) What are the information needs of public health professionals? (2) In what ways are those needs being met? (3) What are the barriers to meeting those needs? (4) What is the role of the Internet in meeting information needs? The review was undertaken in order to develop system requirements to inform the design and development of an interactive digital knowledge management system. The goal of the system is to support the collection, management, and retrieval of public health documents, data, learning objects, and tools. Method: The search method extended beyond traditional information resources, such as bibliographic databases, tables of contents (TOC), and bibliographies, to include information resources public health practitioners routinely use or have need to use—for example, grey literature, government reports, Internet-based publications, and meeting abstracts. Results: Although few formal studies of information needs and information-seeking behaviors of public health professionals have been reported, the literature consistently indicated a critical need for comprehensive, coordinated, and accessible information to meet the needs of the public health workforce. Major barriers to information access include time, resource reliability, trustworthiness/credibility of information, and “information overload”. Conclusions: Utilizing a novel search method that included the diversity of information resources public health practitioners use, has produced a richer and more useful picture of the information needs of the public health workforce than other literature reviews. There is a critical need for public health digital knowledge management systems designed to reflect the diversity of public health activities, to enable human communications, and to provide multiple access points to critical information resources. Public health librarians and other information specialists can serve a significant role in helping public health professionals meet their information needs through the development of evidence-based decision support systems, human-mediated expert searching and training in the use information retrieval systems.","Grey literature, Information needs, Information resources, Information systems, Knowledge management, Literature review, Public health",Public Health Informatics,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Kolman B,Shapiro A","Kolman B,Shapiro A",CHAPTER TWELVE - TOPICS IN ALGEBRA,,1981,,,462-506,,Academic Press,,Introduction to Algebra and Trigonometry,1981,9780124178304,,https://www.sciencedirect.com/science/article/pii/B9780124178304500189;http://dx.doi.org/10.1016/B978-0-12-417830-4.50018-9,10.1016/B978-0-12-417830-4.50018-9,"Publisher Summary This chapter discusses some topics of algebra such as sequences that deals with functions whose domain is the set of natural numbers. An important reason for studying sequences and series is that the underlying concepts can be used as an introduction to calculus. Another of these topics, mathematical induction, provides a means of proving certain theorems involving the natural numbers that appear to resist other means of proof. The chapter presents the use of mathematical induction to prove that the sum of the first n consecutive integers is n(n + l)/2. Probability theory, a very useful topic in algebra, enables one to state the likelihood of occurrence of a given event and has obvious applications to games of chance. The theory of permutations and combinations enables one to count the ways in which one can arrange or select a subset of a set of objects and is necessary background to a study of probability theory.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Kustikova YO,,Application FRP-rebar in the Manufacture of Reinforced Concrete Structures,Procedia Engineering,2016,153,,361-365,,,,,2016,,1877-7058,https://www.sciencedirect.com/science/article/pii/S1877705816322755;http://dx.doi.org/10.1016/j.proeng.2016.08.128,10.1016/j.proeng.2016.08.128,"Reinforced concrete is one of the first places in terms of use in various areas of construction. This is primarily determined by its relative cheapness and durability. Concrete Durability significantly associated with metal reinforcement durability. Durability depends upon the metal reinforcement corrosion that occurs under the influence of an aggressive environment. As a result, corrosion of the metallic reinforcement and, to some extent, of the concrete, there is a loss of bearing capacity of concrete structures in general and buildings. To ensure the durability of concrete structures is necessary to take measures against the development of concrete and reinforcement corrosion. The object of the study are reinforced concrete constructions basalt reinforcement. Restore the bearing capacity of reinforced concrete structures with corroded reinforcement is possible using known design techniques. However, essentially no use of technology in the construction field and specific data on the bearing capacity of concrete structures with basalt reinforcement. No complete information on the value of its adhesion to concrete and its dependence: the composition of concrete and its method of compression; treatment of the outer surface of basalt reinforcement in various ways to increase its adhesion to concrete; destruction of the nature of such structures from the effects of external loads. The search for alternative ways of replacement of the metal reinforcement in concrete structures bearing on the composite, not subject to corrosion and, at the same time having a high load-bearing capacity, is the actual research task. It is known that composite materials to minimize corrosion and other security and environmental impact. At the same time, they must be extremely reliable to manufacture environmentally friendly and does not emit harmful substances polluting the environment. Currently, intensive research to find ways to replace metal in structures of the other valves. An example of such research is to create different types of plastics, which are gradually replacing it. Work is underway in the field of replacement of the metal reinforcement in the non-metallic fittings on the basis of modern composite materials. A major breakthrough in this direction in recent years was the opening of “basaltic technology” that allowed the “update” the base of building materials for new building designs types of valves.","information modeling, organizational and technological documentation, formal language, CAD systems",XXV Polish – Russian – Slovak Seminar “Theoretical Foundation of Civil Engineering\,,,,,,,,,,,,,,,,,,,,
Journal Article,"Mazaher S,Berry DM",,Deriving a compiler from an operational semantics written in VDL,Computer Languages,1985,10,2,147-164,,,,,1985,,0096-0551,https://www.sciencedirect.com/science/article/pii/0096055185900049;http://dx.doi.org/10.1016/0096-0551(85)90004-9,10.1016/0096-0551(85)90004-9,"This paper addresses the issue of compiler correctness. The approach taken is to systematically construct a correct compiler for a language from a formal semantic definition of the language. For this purpose, an operational semantics of a language is chosen as the basis for the approach. That is, the compiler for a language is derived from an interpreter of the language. The derivation process uses the notion of mixed computation proposed by Ershov. Briefly stated, one begins interpreting and when a primitive state changing instruction is about to be executed, the instruction is emitted as code instead. The correctness of all compilers produced by the method is guaranteed by proving the derivation rules correct. This proof is a one-time task for each specification language. The specification language studied in this paper is the Vienna Definition Language (VDL). The object code generated by the compiler is in an intermediate language close to an assembly language. Therefore, the translation from the intermediate language into the assembly language should be straightforward.","Compilers, Compiler Correctness, Compiler Generation, Operational Semantics, VDL",,,,,,,,,,,,,,,,,,,,,
Journal Article,"L’vov VS,Procaccia I",,Computing the scaling exponents in fluid turbulence from first principles: the formal setup,Physica A: Statistical Mechanics and its Applications,1998,257,1,165-196,,,,,1998,,0378-4371,https://www.sciencedirect.com/science/article/pii/S0378437198001393;http://dx.doi.org/10.1016/S0378-4371(98)00139-3,10.1016/S0378-4371(98)00139-3,We propose a scheme for the calculation from the Navier–Stokes equations of the scaling exponents ζn of the nth order correlation functions in fully developed hydrodynamic turbulence. The scheme is nonperturbative and constructed to respect the fundamental rescaling symmetry of the Euler equation. It constitutes an infinite hierarchy of coupled equations that are obeyed identically with respect to scaling for any set of scaling exponents ζn. As a consequence the scaling exponents are determined by solvability conditions and not from power counting. It is argued that in order to achieve such a formulation one must recognize that the many-point space-time correlation functions are not scale invariant in their time arguments. The assumption of full scale invariance leads unavoidably to Kolmogorov exponents. It is argued that the determination of all the scaling exponents ζn requires equations for infinitely many renormalized objects. One can however proceed in controlled successive approximations by successive truncations of the infinite hierarchy of equations. Clues as to how to truncate without reintroducing power counting can be obtained from renormalized perturbation theory. To this aim we show that the fully resummed perturbation theory is equivalent in its contents to the exact hierarchy of equations obeyed by the nth order correlation functions and Green’s function. In light of this important result we can safely use finite resummations to construct successive closures of the infinite hierarchy of equations. This paper presents the conceptual and technical details of the scheme. The analysis of the high-order closure procedures which do not destroy the rescaling symmetry and the actual calculations for truncated models will be presented in a forthcoming paper in collaboration with V. Belinicher.,,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Brouwer LE,Heyting A,1955 - THE EFFECT OF INTUITIONISM ON CLASSICAL ALGEBRA OF LOGIC,,1975,,,551-554,,North-Holland,,Philosophy and Foundations of Mathematics,1975,9780720420760,,https://www.sciencedirect.com/science/article/pii/B9780720420760500714;http://dx.doi.org/10.1016/B978-0-7204-2076-0.50071-4,10.1016/B978-0-7204-2076-0.50071-4,"Publisher Summary This chapter discusses the effect of intuitionism on classical algebra of logic. Classical algebra of logic, furnishes a formal image of the laws of common-sensical thought. This common-sensical thought is based on the conscious or subconscious, threefold belief including the belief in a truth existing independently of human thought, and expressible by the means of sentences called true assertions, mainly assigning certain properties to certain objects, or stating that objects possessing certain properties exist, or that certain phenomena behave according to certain laws. Furthermore, in the possibility of extending ones knowledge of truth by the mental process of thinking, in particular thinking accompanied by linguistic operations independent of experience called logical reasoning, which to a limited stock of evidently true assertions mainly founded on experience, and sometimes called axioms, contrives to add an abundance of further truths. Closely connected with the principle of the excluded third, also called principle of judgeability, is the principle of reciprocity of absurdity saying that a mathematical assertion whose noncontradictority has been established is true.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Zeigler BP,Zeigler BP,Chapter 3 - DEVS FORMALISM AND DEVS-SCHEME,,1990,,,41-67,,Academic Press,,"Object-Oriented Simulation with Hierarchical, Modular Models",1990,9780127784526,,https://www.sciencedirect.com/science/article/pii/B9780127784526500078;http://dx.doi.org/10.1016/B978-0-12-778452-6.50007-8,10.1016/B978-0-12-778452-6.50007-8,"Publisher Summary This chapter discusses the discrete event system specification (DEVS) formalism and its implementation in DEVS-Scheme. Its basic features help to understand how hierarchical, modular simulation models are specified in DEVS-Scheme. The chapter describes that DEVS formalism provides a means of specifying a mathematical object called a system. Basically, a system has a time base, inputs, states, and outputs, and functions for determining next states and outputs given current states and inputs. The insight provided by the DEVS formalism is that it characterizes the way discrete event simulation languages specify discrete event system parameters. It is more than just a means of constructing simulation models. It provides a formal representation of discrete event systems capable of mathematical manipulation just as differential equations serve this role for continuous systems. Such manipulation includes behavioral analysis, whereby properties of the behavior of a system are deduced by examining its structure. In the DEVS-Scheme realization, the DEVS formalism is refined so that both the input and output sets X, Y consist of pairs of the form (port, value). Thus, an external input event of the form x = (p, v) signals the fact that a value v has been received at an input port p. Similarly, y = (p, v) represents the sending of a value v to output port p.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Soergel D,,Mathematical analysis of documentation systems: An attempt to a theory of classification and search request formulation,Information Storage and Retrieval,1967,3,3,129-173,,,,,1967,,0020-0271,https://www.sciencedirect.com/science/article/pii/002002716790006X;http://dx.doi.org/10.1016/0020-0271(67)90006-X,10.1016/0020-0271(67)90006-X,"As an attempt to make a general structural theory of information retrieval, a documentation system (DS) is defined as a formal system consisting of (a) a set of objects (documents); (b) a set A+ + of elementary attributes (key-words), from which further attributes may be constructed: A+ + generates A; (c) a set of axioms of the form X+ +(x) = M (M ϵ M, M a set of constants) connecting attributes with objects: from the axioms further theorems (= true statements) may be constructed. By use of the theorems, different mappings A → B(a) (B(a) set of all subsets of a) (search question → set of documents retrieved) are defined. The type of a DS depends on two basic decisions: (1) choice of the rules for the construction of attributes and theorems, e.g., logical product in coordinate indexing; links. (2) choice of M: M may consist of the two constants “applicable” and “not applicable”, or some positive integers, … ; Further practical decisions: A+ + hierarchical or not; kind of mapping; introduction of roles (= further attributes). The most simple case—ordinary two-valued Coordinate Indexing—is discussed in detail: A is a free distributive (but not Boolean) lattice, the homomorphic image a ring of subsets of a ; instead of negation which is not useful, a useful retrieval operation “praeternegation” is introduced. Furthermore these are discussed: a generalized definition of superimposed coding; some functions for the distance of objects or attributes; optimization and automatic derivation of classifications. The model takes into account term-term relations and document-document relations. It may serve as a structural framework in terms of which the functional problems of retrieval theory may be expressed more clearly.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Labhalla S,Lombardi H",,"Real numbers, continued fractions and complexity classes",Annals of Pure and Applied Logic,1990,50,1,1-28,,,,,1990,,0168-0072,https://www.sciencedirect.com/science/article/pii/0168007290900524;http://dx.doi.org/10.1016/0168-0072(90)90052-4,10.1016/0168-0072(90)90052-4,"We study some representations of real numbers. We compare these representations, on the one hand from the viewpoint of recursive functionals, and of complexity on the other hand. The impossibility of obtaining some functions as recursive functionals is, in general, easy. This impossibility may often be explicited (and reinforced) in terms of complexity: - existence of a sequence of low complexity whose image is not a recursive sequence, - existence of objects of low complexity but whose images have arbitrarily high time- complexity (often, the ‘low complexity’ is linear time or polynomial time). Moreover, some representations of real numbers that are equivalent from the viewpoint of recursive functionals, are very distinct from the viewpoint of complexity. We make a particular study of representations via continued fractions (dfc). We precise exactly what part of information available in the x's dfc is equivalent to the information available in its Dedekinds cut. We show that the sum of two reals whose dfcs are polynomial-time computable may be a real whose dfc has time complexity arbitrarily high. This work confirms that the unique representation of real numbers suitable for the ordinary calculus is via explicit Cauchy sequences of rationals. Résumé Nous étudions différentes manières de présenter les nombres réels. Nous comparons ces présentations du point de vue des fonctionnelles récursives d'une part, et de celui des classes de complexité d'autre part. L'impossibilité d'obtenir certaines fonctions sous forme de fonctionnelles récursives est en général facile à établir. Cette impossiblité peut souvent être explicitée (et renforcée) en termes de complexité: - il existe une suite de faible complexité dont l'image est une suite non récursive, - il existe des objets de faible complexité mais dont les images sont des objets de complexité arbitrairement grande (le plus souvent la ‘faible complexité’ est celle en temps linéaire ou polynomial). En outre, certaines présentations des réels équivalentes du point de vue des fonctionnelles récursives se distinguent nettement du point de vue de la complexité. Nous faisons une étude particulière concernant les développements en fraction continue (dfc). Nous précisions exactement quelle est la partie de l'information disponible dans le dfc d'un réel x qui équivaut à l'information disponible dans sa coupure de Dedekind. Nous montrons également que la somme de deux réels dont le dfc est calculable en temps polynomial peut être un réel dont le dfc est de complexité arbitrairement grande. Ce travail confirme que seule une présentation des réels via des suites de rationnels explicitement de Cauchy est adaptée aux calculs avec les réels.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Brodie ML,Ridjanovic D","Mylopolous J,Brodie M",On the Design and Specification of Database Transactions,,1989,,,185-206,,Morgan Kaufmann,San Francisco (CA),Readings in Artificial Intelligence and Databases,1989,9780934613538,,https://www.sciencedirect.com/science/article/pii/B9780934613538500182;http://dx.doi.org/10.1016/B978-0-934613-53-8.50018-2,10.1016/B978-0-934613-53-8.50018-2,"A complete design and specification of database transactions must include both structural and behavioural properties. Structure deals with states and static properties while behaviour concerns state transitions and dynamic properties. Database design techniques emphasize the importance of behaviour but seldom provide for modelling and integrating behaviour and structure. This chapter presents concepts, tools, and techniques for the design and specification of behavioural and structural properties of database transactions. The concepts, tools, and techniques result from the integration of programming language (PL) and database (DB) technologies. Design principles from PLs (e.g., abstraction and refinement), are applied to DB design and a new DB design principle, called localization, is proposed. PL concepts such as procedural abstractions, abstract data types, control structures, and specification techniques are integrated with DB concepts such as data abstractions, integrity constraints, data structures, and data models to produce a semantic data model for the conceptual design of databases and their associated transactions. The integration is based on the correspondence between the structure of complex databases and the structure of the associated transactions. In the proposed methodology, hierarchies of transactions and their constituent actions are designed in correspondence with the hierarchies designed to relate objects. As proposed in both artificial intelligence and PLs, design and specification are leveled. Gross design is done using graphic notation while detailed design is done using a conventional predicate based specification language. Appropriate concepts, tools, and techniques are presented for each level. The methodology is adequate for most database applications. However, complex and critical database applications (e.g., critical patient care, nuclear power plants) require precise, structured specifications. An appropriate formal specification technique, based on functional programming, is introduced. Formal specifications support increased precision and permit automated analysis and verification. The motivation for this work is similar to that for precise specifications in PLs. However, the existence of a database changes the nature of the problem and the required solution. The relationship between this chapter and other chapters is presented in a concluding Epilogue.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Aguado AS,Montiel E,Nixon MS",,Invariant characterisation of the Hough transform for pose estimation of arbitrary shapes,Pattern Recognition,2002,35,5,1083-1097,,,,,2002,,0031-3203,https://www.sciencedirect.com/science/article/pii/S0031320301000991;http://dx.doi.org/10.1016/S0031-3203(01)00099-1,10.1016/S0031-3203(01)00099-1,"In this paper, we develop a new formulation and methodology for including invariance in a general form of the Hough transform. Essentially, the transformations that control a shape's appearance are extracted using invariance, for arbitrary shapes with a continuous description. We first develop a formal definition of the Hough transform mapping for arbitrary shapes and general transformations. We then include an invariant characterisation of shapes and develop and apply our new technique to extract shapes under similarity and affine transformations. Our formulation and implementation is based directly on parametric curves and so avoids the use of indexed look-up tables. This confers the attributes of a continuous shape description avoiding discretisation problems inherent in earlier formulations. To obtain an invariant characterisation, each point in the model is related to a collection of other points defining a geometric arrangement. This characterisation does not require the computation of properties for lines or other primitives that compose the model, but is based solely on the local geometry of the points on shapes. The transformation is obtained by solving for the parameters of the curve according to an arrangement of points defined for a point in the image and a corresponding arrangement of points for a point in the model with the same invariant properties. The location parameters can be gathered in a 2D accumulator space independent of the transformation and of a shape's complexity. Experimental results show that the new technique is capable of extracting arbitrary shapes under occlusion and when the image contains significant noise.","Shape extraction, Hough transform, Object recognition, Invariance, Similarity transformations, Affine transformations",Handwriting Processing and Applications,,,,,,,,,,,,,,,,,,,,
Book Chapter,Caelli T,Caelli T,CHAPTER 5 - Introduction to Geometric Structures,,1981,,,71-100,,Pergamon,,Visual Perception,1981,9780080244204,,https://www.sciencedirect.com/science/article/pii/B9780080244204500111;http://dx.doi.org/10.1016/B978-0-08-024420-4.50011-1,10.1016/B978-0-08-024420-4.50011-1,"Publisher Summary This chapter introduces geometric structures. It presents geometries of various types. Perspective or projective geometry is relevant for judging depth and motions in depth while more metric geometries are obviously involved in judging size, length, and orientations of objects in the fronto-parallel plane. Geometry is concerned with the study of spatial relations or relations that can be described in a formal way. It is not necessarily concerned with measurement. Geometry is largely concerned with the study of the types of transformations that do not change the defined spatial relationships between objects (object invariance). Affine geometry preserves parallelism, while projective geometry only preserves cross-ratios. Euclid into the axiomatic system of Euclidean geometry summarized the geometry inherited from the Egyptians and Greeks. The following are the postulates: (1) a straight line may be drawn from any point to any other point; (2) a finite straight line may be extended continuously in a straight line; (3) a circle may be described with any center and any radius; (4) all right angles are equal to one another; and (5) if a straight line meets two other straight lines so as to make the two interior angles on one side of it together less than two right angles, the other straight lines, if extended indefinitely, will meet on that side on which the angles are less than two right angles.",,,"Pergamon International Library of Science, Technology, Engineering and Social Studies",,,,,,,,,,,,,,,,,,,
Book Chapter,Kurth R,Kurth R,CHAPTER II - MATHEMATICAL TOOLS,,1960,11,,3-46,,Pergamon,,Axiomatics of Classical Statistical Mechanics,1960,,0278-3231,https://www.sciencedirect.com/science/article/pii/B9781483167305500079;http://dx.doi.org/10.1016/B978-1-4831-6730-5.50007-9,10.1016/B978-1-4831-6730-5.50007-9,"Publisher Summary A set is a collection of different objects, real or intellectual, into a whole. The objects collected in a set are called its elements and it is said that “the elements form or make the set,” “they belong to it,” “the set consists of the elements,” and “it contains these elements.” It is formally useful to admit sets consisting of only one element and even to admit a set containing no element at all. The latter set is called an empty set. A set S1 is called a subset of a set S if each element of S1 is contained in S. If there is at least one element of S that does not belong to S1, the set S1 is called a proper subject of the set S. The empty set is regarded as a subset of every set. A set is called finite if it consists of a finite number of elements. Otherwise it is called infinite. A set is called enumerable if there is an ordinal number for each element and, conversely, an element for each ordinal number, that is, if there is a one-to-one correspondence between the elements of the set and the ordinal numbers.",,,International Series of Monographs on Pure and Applied Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Volz RA,Krishnan P,Theriault R",,Distributed Ada: case study,Information and Software Technology,1991,33,4,292-300,,,,,1991,,0950-5849,https://www.sciencedirect.com/science/article/pii/0950584991901544;http://dx.doi.org/10.1016/0950-5849(91)90154-4,10.1016/0950-5849(91)90154-4,"The paper describes the design and implementation of a distributed Ada system. Ada is not well defined with respect to distribution, and any implementation for distributed execution must make a number of decisions about the language. The objectives in the implementation described here are to remain as close to the current definition of Ada as possible, and to learn through experience what changes are necessary in future versions of the language. The approach taken to distributing a single program is to assign library units that compose it to nodes of the distributed system. In a formal sense the semantics of a program is independent of the distribution because the semantics is interpreted to include all possible behaviours that result from different distributions. However, the functionality of the distributed program may then depend on the distribution in the sense that program behaviour may be impacted by the time required for communication among the distributed modules, or parts of the program may continue to function in presence of failures. The implementation technique converts each distributed module into a standalone program that communicates with its correspondents; each of these may then be compiled by an existing Ada compiler. Issues discussed include the ramifications of sharing of data types, objects, subprograms, tasks, and task types. The implementation techniques used in the translator are described.","case study, distributed systems, Ada",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Cleaveland R,Mislove M,Mulry P",,"Preface: Volume 14, Isuue 1",Electronic Notes in Theoretical Computer Science,1998,14,,44228,,,,,1998,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105802257;http://dx.doi.org/10.1016/S1571-0661(05)80225-7,10.1016/S1571-0661(05)80225-7,"US - Brazil Joint Workshops on the Formal Foundations of Software Systems Rio de Janeiro, May 5 - 9, 1997 and New Orleans, November 13 - 16, 1997 The papers in this volume form the Proceedings of two workshops that took place in 1997. The first workshop took place in Rio de Janeiro in May, 1997, and the second took place in New Orleans the following November. Both meetings were sponsored jointly by the US National Science Foundation and its Brazilian counterpart, CNPq. The goal of the workshops was to foster collaborative research efforts between US and Brazilian researchers. These workshops marked the culmination of two years of talks, visits, and planning by the members of NSF and CNPq, and their respective constituencies. Out of the same series of exchanges sprang another workshop in Porto Alegre, Brazil on Robotics and Intelligent Systems. While many Brazilian students come to US for advanced studies, the majority still choose institutions in Western Europe; nonetheless, these workshops have uncovered a wealth of common interests and encouraged several new collaborations. Beyond the workshops, the contacts have facilitated additional joint ventures, such as the new NSF-CNPq Program for the CISE Directorate which has received a significant number of proposals from collaborators unrelated to the workshops. The workshops helped the participants build a foundation for such efforts by providing a forum where participants could learn about each others' research interests and begin to establish a basis for collaborative work. The topics of interest ranged from theoretical concepts and formalisms to techniques and tools for the systematic construction of software systems. The areas where research collaboration possibilities have emerged or are about to emerge include object-based programming, tools and specification techniques, functional programming and domain-specific languages, and basic theoretical areas ranging from domain theory and category theory to type theory and concurrency. More detailed information about the workshops can be accessed on line. The list of participants and other information about each workshop are available as follows. Information about the Rio workshop can be found at www.kestrel.edu/ jullig/rio97, and information about the following New Orleans workshop can be found at www.math.tulane.edu/usbrazil.html. Of particular interest may be the position statements the participants submitted that describe the areas where they expect collaboration may be forthcoming. As a result of the efforts of NSF and CNPq, programs have been established in both agencies specifically aimed at providing support for emerging collaborations between researchers in both countries. Information about these programs can be found on line at the NSF and CNPq web sites: www.nsf.gov and www.cnpq.br. The Organizers of the meetings wish to thank the participants who took part in the meetings, but most especially the representatives of NSF: Frank Anger and Rita Virginia Rodriguez, and the representatives of CNPq: Virgilio Almeida and Rosa Maria Viccari, all of whom provided financial support for the workshops. Without their encouragement and the initiative they fostered, neither the workshops nor the joint research support program would have taken place.",,US-Brazil Joint Workshops on the Formal Foundations of Software Systems,,,,,,,,,,,,,,,,,,,,
Journal Article,"Février M,Nica A",,Infinitesimal non-crossing cumulants and free probability of type B,Journal of Functional Analysis,2010,258,9,2983-3023,,,,,2010,,0022-1236,https://www.sciencedirect.com/science/article/pii/S0022123609004200;http://dx.doi.org/10.1016/j.jfa.2009.10.010,10.1016/j.jfa.2009.10.010,"Free probabilistic considerations of type B first appeared in the paper of Biane, Goodman and Nica [P. Biane, F. Goodman, A. Nica, Non-crossing cumulants of type B, Trans. Amer. Math. Soc. 355 (2003) 2263–2303]. Recently, connections between type B and infinitesimal free probability were put into evidence by Belinschi and Shlyakhtenko [S.T. Belinschi, D. Shlyakhtenko, Free probability of type B: Analytic aspects and applications, preprint, 2009, available online at www.arxiv.org under reference arXiv:0903.2721]. The interplay between “type B” and “infinitesimal” is also the object of the present paper. We study infinitesimal freeness for a family of unital subalgebras A1,…,Ak in an infinitesimal noncommutative probability space (A,φ,φ′) and we introduce a concept of infinitesimal non-crossing cumulant functionals for (A,φ,φ′), obtained by taking a formal derivative in the formula for usual non-crossing cumulants. We prove that the infinitesimal freeness of A1,…,Ak is equivalent to a vanishing condition for mixed cumulants; this gives the infinitesimal counterpart for a theorem of Speicher from “usual” free probability. We show that the lattices NC(B)(n) of non-crossing partitions of type B appear in the combinatorial study of (A,φ,φ′), in the formulas for infinitesimal cumulants and when describing alternating products of infinitesimally free random variables. As an application of alternating free products, we observe the infinitesimal analogue for the well-known fact that freeness is preserved under compression with a free projection. As another application, we observe the infinitesimal analogue for a well-known procedure used to construct free families of free Poisson elements. Finally, we discuss situations when the freeness of A1,…,Ak in (A,φ) can be naturally upgraded to infinitesimal freeness in (A,φ,φ′), for a suitable choice of a “companion functional” φ′:A→C.","Free probability (of type B), Infinitesimal freeness, Infinitesimal non-crossing cumulants, Dual derivation system",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Jensen RB,Crossley JN,Concrete Models of Set Theory,,1967,46,,44-74,,Elsevier,,"Sets, Models and Recursion Theory",1967,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08715027;http://dx.doi.org/10.1016/S0049-237X(08)71502-7,10.1016/S0049-237X(08)71502-7,"Publisher Summary This chapter provides an introduction to Cohen's forcing method. It presents Cohen's basic method and a proof of the independence of the continuum hypothesis as a typical application. The chapter describes the formal system of Zernielo–Fraenkel set theory (ZF) and introduces the basic notations. The metalinguistic framework of the investigation and an arithmetisation of the object language are described in the chapter. The class of concrete models is introduced in the chapter. The chapter describes the notion of constructible closure and contains a proof that every constructibly closed inner model of a concrete ZF model M is a ZF model. Later, the notions of forcing and generic model are introduced in the chapter. By a straightforward modification, it is proved that every generic model is a ZF model. It is also proved that each of a class of axioms, which violates the general continuum hypothesis, is consistent.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"MacEachren AM,Pike W,Yu C,Brewer I,Gahegan M,Weaver SD,Yarnal B",,Building a geocollaboratory: Supporting Human–Environment Regional Observatory (HERO) collaborative science activities,"Computers, Environment and Urban Systems",2006,30,2,201-225,,,,,2006,,0198-9715,https://www.sciencedirect.com/science/article/pii/S0198971505000918;http://dx.doi.org/10.1016/j.compenvurbsys.2005.10.005,10.1016/j.compenvurbsys.2005.10.005,"Collaboratories have been defined as centers without walls, virtual places where teams of scientists can undertake coordinated research. As part of the Human–Environment Regional Observatory (HERO) infrastructure project, we have been developing a geocollaboratory to support work by geographically distributed scientists about geographic problems. Our specific focus is on science teams developing and applying protocols for long-term study of the local and regional scale human impacts of global environmental change. The HERO geocollaboratory includes web and other Internet-based tools to enable same-time and different-time (thus synchronous and asynchronous) different-place collaboration. Methods and tools have been developed to support (1) synchronous distributed meetings that include video links and shared visual display of geospatial information; (2) asynchronous perspective comparison and consensus building activities; and (3) long-term information sharing and knowledge development. This paper introduces the research effort, sketches the conceptual framework within which the geocollaboratory is being developed, outlines progress thus far in the three collaboratory components listed above, and discusses our experiences using these tools for distributed science as well as our plans for continued development. We direct specific attention to three web-based, collaborative tools we have developed in support of components 2 and 3 above: an e-Delphi tool (supporting sharing and comparing of expert opinions), a concept-mapping tool that supports building, sharing, and comparing concept relationship diagrams linked to formal ontologies, and a web portal (called Codex) that provides a personal workspace, mechanisms for forming groups and accessing group resources, and methods for encoding knowledge objects that include geographic referencing.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,"Kreisel G,Krivine JL",Chapter 5 Predicate Calculus with Several Types of Objects: The Hierarchy of Finite Types,,1967,48,,80-114,,Elsevier,,Elements of Mathematical Logic,1967,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08717245;http://dx.doi.org/10.1016/S0049-237X(08)71724-5,10.1016/S0049-237X(08)71724-5,"Publisher Summary This chapter discusses a method for developing first order predicate logic, including the reduction of the theory of functions to that of their graphs. In the chapter, the essential results are formulated and proved directly for languages with several types of variables that are common in mathematics. These languages are useful because they allow simple formulations of certain results, for example, an improved version of the Interpolation Lemma. The chapter also discusses languages along with the construction of several types of variables such as (1) one type for individuals, (2) one for sets of individuals, (3) one for families of such sets, and so on for a finite number of steps. These languages are familiar from axiomatic mathematics where, for example, in the theory of groups, the elements of the given group constitute the individuals while the sub-groups are sets of such individuals. More generally, the languages considered in the chapter concern the finite levels in the structure or hierarchy of (simple) types.",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Kasangian S,Labella A",,Conduché property and Tree-based categories,Journal of Pure and Applied Algebra,2010,214,3,221-235,,,,,2010,,0022-4049,https://www.sciencedirect.com/science/article/pii/S0022404909001261;http://dx.doi.org/10.1016/j.jpaa.2009.05.008,10.1016/j.jpaa.2009.05.008,"This paper focuses on a property of enriched functors reflecting the factorisation of morphisms, used in concurrency semantics. According to Lawvere [F.W. Lawvere, State categories and response functors, 1986, Unpublished manuscript], a functor strictly reflecting morphism factorisation induces a notion of state on its domain, when it is considered as a control functor. This intuition works both in case of physical and computing processes [M. Bunge, M.P. Fiore, Unique factorisation lifting functors and categories of linearly-controlled processes, Math. Structures Comput. Sci. 10 (2) 2000 137–163; M.P. Fiore, Fibered models of processes: Discrete, continuous and hybrid systems, in: Proc. of IFIP TCS 2000, in: LNCS, vol. 1872, 2000, pp. 457–473]. In this note we investigate a more general property in the family of models we proposed elsewhere for communicating processes, and we assess their bisimulation relations [S. Kasangian, A. Labella, Observational trees as models for concurrency, Math. Structures. Comput. Sci. 9 (1999) 687–718; R. De Nicola, D. Gorla, A. Labella, Tree-Functors, determinacy and bisimulations, Technical Report, 02/2006, Dip. di Informatica, Univ. di Roma “La Sapienza” (Italy), 2008 (submitted for publication), http://www.dsi.uniroma1.it/%7Egorla/papers/DGL-TR0206.pdf]. Hence, we adapt the notion of “Conduché condition” [F. Conduché, Au sujet de l’existence d’adjoints à droîte aux foncteurs image reciproque dans la catégorie des catégories, C. R. Acad. Sci. Paris 275 (1972) A891–894] to the context of enriched category theory. This notion, weaker than the original “Moebius condition” used by Lawvere, seems to be more suitable for the description of the concurrency models parametrised w.r.t. a base category via the mechanism of change of base, actually. The base category is a monoidal 2-category; a category of generalised trees, Tree, is obtained from it. We consider Conduché Tree-based categories, where enrichment reflects factorisation of objects in the base category. We prove that a form of Conduché’s theorem holds for Conduché Tree-functors. We also show how the Conduché condition plays a crucial role in modelling concurrent processes and bisimulations between them. The notions of “state preservation” and “determinacy” [R. Milner, Communication and Concurrency, Prentice Hall International, 1989] are formally characterised.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Finch PD,"Hall TE,Jones PR,Preston GB",THE FORMAL STRUCTURE OF OBSERVATIONAL PROCEDURES,,1980,,,239-255,,Academic Press,,Semigroups,1980,9780123194503,,https://www.sciencedirect.com/science/article/pii/B9780123194503500244;http://dx.doi.org/10.1016/B978-0-12-319450-3.50024-4,10.1016/B978-0-12-319450-3.50024-4,"Observational procedures are characterised in terms of certain subsets of the Cartesian product P* × R* of free semigroups generated by a set of pointers P and a set of readings R. Experiments, designs, objects, systems and states are defined in terms of pointer-readings. Temporal development in a non-relativistic setting is defined by a one-parameter semigroup of transformations of state-space. It is shown that the structure of what can be known by observation can be classified in two ways according as the results of later observations do or do not depend on whether we make earlier ones. The latter is the so-called classical case, the former is referred to as non-classical. The classical case reduces to the population model of classical statistics whereas the structure of the non-classical case is that of a sequential computing machine. Some formal analogies between the structure of observational procedures and the standard methods of quantum mechanics are discussed very briefly.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Wolf KB,,"A conserved W-spin algebra for collinear processes involving time-, space-, light-like or null objects",Nuclear Physics B,1969,11,1,159-169,,,,,1969,,0550-3213,https://www.sciencedirect.com/science/article/pii/0550321369900194;http://dx.doi.org/10.1016/0550-3213(69)90019-4,10.1016/0550-3213(69)90019-4,"A W-spin algebra is defined on the (Bargmann-Wigner) internal carrier space of the spin group of any kind of object: time-, space-, light-like or null. This W-spin algebra is the same in all four cases and is conserved in collinear processes. For time-like systems, the usual W-spin formalism is regained. Space-like objects of definite W-spin are shown to be (finite-dimensional) non-unitary irreducible representations of their O(2, 1) spin group, formally resembling the O(3) spin of a time-like object of the same W-spin and quark composition. Light-like objects of definite W-spin are shown to be collections of ‘photon-like’ representations of their E(2) spin group. Null systems allow a larger O(3, 1) W-spin algebra.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Srivastava HM,Panda R",,Certain multidimensional integral transformations (I),Indagationes Mathematicae (Proceedings),1978,81,1,118-131,,,,,1978,,1385-7258,https://www.sciencedirect.com/science/article/pii/138572587890029X;http://dx.doi.org/10.1016/1385-7258(78)90029-X,10.1016/1385-7258(78)90029-X,"Summary The object of this paper is to introduce a general multiple integral transformation whose kernel involves the H-function of several complex variables, which was defined and studied elsewhere by the present authors ([25], [26] and [27]). This integral transform, defined by Equation (1.1) below, and its confluent form (1.15), not only provide interesting unifications (and extensions) of the various classes of known integral transformations whose kernels are expressible in terms of the familiar E, G and H functions of one and two variables, or the product of several such functions, but also offer the possibility of their appropriate further generalizations involving multiple integrals. Since a great variety of functions that occur rather frequently in problems of applied mathematics and mathematical analysis are special cases of the kernel used here, and since the need for a simultaneous operational calculus (based upon multidimensional integral transformations) presents itself quite naturally when problems dependent on several variables are to be treated operationally, a systematic study of the integral transform (1.1) and its confluent form (1.15) is believed to yield deeper, general and useful results.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Kreisel G,Fenstad JE,A Survey of Proof Theory II,,1971,63,,109-170,,Elsevier,,Proceedings of the Second Scandinavian Logic Symposium,1971,,0049-237X,https://www.sciencedirect.com/science/article/pii/S0049237X08708450;http://dx.doi.org/10.1016/S0049-237X(08)70845-0,10.1016/S0049-237X(08)70845-0,"Abstract This paper explains recent work in proof theory from a neglected point of view. Proofs and their representations by formal derivations are treated as principal objects of study, not as mere tools for analyzing the consequence relation. Though the paper is principally expository it also contains some material not developed in the literature. In particular, adequacy conditions on criteria for the identity of proofs (in § 1c), and a reformulation of Gödeľs second theorem in terms of the notion of canonical representation (in § 1d); the use of normalization, instead of normal form, theorems for a direct proof of closure under Church's rule of the theory of species [in § 2a(ii)] and the useless-ness of bar recursive functionals for (functional) interpretations of systems containing Church's thesis [in §2b(iii)]; the use of ordinal structures in a quantifier-free formulation of transfinite induction (in § 3); the irrelevance of axioms of choice to the explicit realizability of existential theorems both for classical and for Heyting's logical rules (in § 4c) and some new uses of Heyting's rules for analyzing the indefinite cumulative hierarchy of sets (in § 4d); a semantics for equational calculi suitable when terms are interpreted as rules for computation [in Appl. Ia(iii)], and, above all, an analysis of formalist semantics and its relation to realizability interpretations (in App. Ic). A less technical account of the present point of view is in [21].",,,Studies in Logic and the Foundations of Mathematics,,,,,,,,,,,,,,,,,,,
Journal Article,"Zeigler BP,Rada R",,Abstraction in methodology: A framework for computer support,Information Processing & Management,1984,20,1,63-79,,,,,1984,,0306-4573,https://www.sciencedirect.com/science/article/pii/0306457384900402;http://dx.doi.org/10.1016/0306-4573(84)90040-2,10.1016/0306-4573(84)90040-2,"Computer-based methodologies for systems modelling, design, and analysis require the user to understand and manipulate abstractions of the objects of direct interest. The success of such methodologies may hang on human ability to deal with such abstractions and the degree to which the computer assistance meshes with this ability. This paper formulates systems methodologies within a problem solving frame-work in which abstractions, and the role they play, are formally represented. Two kinds of abstraction-based methodologies are distinguished: information-based methodologies employ abstractions to provide projections of the current state of the problem solving process, subsearch methodologies augment the underlying solution space with abstract representations that are intended to facilitate better perception of goal directions and improved quality of solutions. In this framework, implementation of abstraction classes is shown to involve overhead costs to both software and “brainware” that may vitiate the intended benefits. Components of, and approaches to, such a cost/benefit analysis are presented.",,Special Issue Empirical Foundations of Information and Software Science,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ernst GW,Hookway RJ,Menegay JA,Ogden WF",,Modular verification of Ada generics,Computer Languages,1991,16,3,259-280,,,,,1991,,0096-0551,https://www.sciencedirect.com/science/article/pii/0096055191900107;http://dx.doi.org/10.1016/0096-0551(91)90010-7,10.1016/0096-0551(91)90010-7,"This paper develops modular verification rules for Ada generics which are proven to be sound and complete. The generic mechanism in Ada allows modules to be parameterized by types, procedures and functions. The modularity property allows a generic to be verified once, and then exported to other modules which assume that it is correct. This requires the generic to have a specification which is used in verifying other modules, but its implementation cannot be used for this purpose. Thus, modular verification cannot be based on removing generics by macro expansion which requires the use of the generic's implementation. The main difficulty with specifying and verifying a generic is that the specification language may need to be extended with a new theory for specifying and reasoning about properties of objects whose type is a parameter to the generic. Such theories must be part of the specification of the generic, and this raises the possibility that the extended specification language may not be expressive, even if it was before the extension. The use of strings in our specification language prevents this from happening, which is proven in the paper; this is a major step toward establishing the completeness of our rules. Modularity also had a large impact on our semantics for programming constructs which is quite different from the usual semantics in the literature, even though it is still based the denotational semantics of Scott and Strachey. The main reason for this is that we had to modify the standard definition of validity. Modularity requires that validity depend on certain internal assertions in a program, such as the precondition of a procedure invoked in the program.","Verification, Program correctness, Ada generics, Formal specification, Program semantics, Logical soundness, Program validity",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Breeding KJ,Amoss JO",,A pattern description language—PADEL,Pattern Recognition,1972,4,1,19-36,,,,,1972,,0031-3203,https://www.sciencedirect.com/science/article/pii/0031320372900179;http://dx.doi.org/10.1016/0031-3203(72)90017-9,10.1016/0031-3203(72)90017-9,"This paper describes an artificial language, called PADEL, which may be used to describe line drawings. The descriptions consist of strings of concatenated symbols denoting vertices and branches of the picture or line drawing. These picture elements are formally defined followed by a description of the grammar which generates the language. The actual construction of the descriptive strings from a given picture is then discussed. The language is then analyzed and noted to be phrase structured, finite, context free language. The regular expression which describes all strings in the language is then derived. Using the language just described, a set of topological manipulations of the picture are defined by operations on the descriptive strings. Manipulations such as rotations, reflections and scaling are defined on two dimensional picture descriptions. A nonuniform scale change, which may be termed “rubber sheet warping,” is also described. The pattern description language is next extended to the description of three dimensional objects by representing the branch labels as three tuples which are the direction angles of the branch unit vectors. Rotations of such pictures about the coordinate axis are then described. It is then shown that the angular relationships among the branches of the picture remain invariant under these transformations and, thus, the “shape” of the object remains invariant. An inverse rotation is next introduced. Finally projections of the picture onto the principal planes and more generally onto an arbitrary plane is described.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Ibarra OH,Păun G",,Characterizations of context-sensitive languages and other language classes in terms of symport/antiport P systems,Theoretical Computer Science,2006,358,1,88-103,,,,,2006,,0304-3975,https://www.sciencedirect.com/science/article/pii/S0304397506002180;http://dx.doi.org/10.1016/j.tcs.2006.03.003,10.1016/j.tcs.2006.03.003,"We give “syntactic’’ characterizations of context-sensitive languages (CSLs) in terms of some restricted models of symport/antiport P systems. These are the first such characterizations of CSLs in terms of P systems. In particular, we show the following for any language L over a binary alphabet:(1)Let m be any integer ≥1. Then L is a CSL if and only if it can be accepted by a restricted symport/antiport P system with m membranes and multiple number of symbols (objects). Moreover, holding the number of membranes at m, there is an infinite hierarchy in computational power (within the class of binary CSLs) with respect to the number of symbols.(2)Let s be any integer ≥14. Then L is a CSL if and only if it can be accepted by a restricted symport/antiport P system with s symbols and multiple number of membranes. Moreover, holding the number of symbols at s, there is an infinite hierarchy in computational power with respect to the number of membranes.(Similar results hold for languages over an alphabet of k≥2 symbols.) Thus (1) and (2) say that in order for the restricted symport/antiport P systems to accept all binary CSLs, at least one parameter (either the number of symbols or the number of membranes) must grow. These are the first results of their kind in the P systems area. They contrast a known result that (unrestricted) symport/antiport P systems with s≥2 symbols and m≥1 membranes accept (or generate) exactly the recursively enumerable sets of numbers even for s+m=6. We also note that previous characterizations of formal languages in the membrane computing literature are mostly for the Parikh images of languages. Variations of our model yield characterizations of regular languages, languages accepted by one-way logn space-bounded Turing machines, and recursively enumerable languages.","Symport/antiport P system, Context-sensitive language, Linear-bounded automaton, One-way space-bounded turing machine, Two-way multihead finite automaton",,,,,,,,,,,,,,,,,,,,,
Journal Article,Motus L,,Semantics and implementation problems of interprocess communication in a DCCS specification,IFAC Proceedings Volumes,1985,18,1,31-38,,,,,1985,,1474-6670,https://www.sciencedirect.com/science/article/pii/B9780080316642500115;http://dx.doi.org/10.1016/B978-0-08-031664-2.50011-5,10.1016/B978-0-08-031664-2.50011-5,"In a DCCS software specification model (the Quirk's model) a high level communication and synchronization concept (channels) is proposed. In this paper we consider some problems arised by implementation of this concept. To describe and analyse practically achievable synchronization of events, several intervals (tolerance, equivalence, and simultaneity intervals) are defined. The mutual relation of these intervals enable us to analyse adequacy of events in the control object, in the specification and in the computer system. The use of channels for data communication is also described. A detailed functioning of different types of channels is analysed and some details of their implementation are discussed. Data communication can be reduced to send primitive without waiting for positive acknowledgement. The message validity time, necessary for reliable communication, is obtained from the specification.","DCCS formal specification, hard real-time, communication and synchronization, the concept of channels, channel implementation problems","6th IFAC Workshop on Distributed Computer Control Systems, Monterey, USA, 20-22 May",,,,,,,,,,,,,,,,,,,,
Book Chapter,Korfhage RR,Korfhage RR,CHAPTER 5 - Formal and Natural Languages,,1974,,,166-182,,Academic Press,,Discrete Computational Structures,1974,9780124208506,,https://www.sciencedirect.com/science/article/pii/B9780124208506500097;http://dx.doi.org/10.1016/B978-0-12-420850-6.50009-7,10.1016/B978-0-12-420850-6.50009-7,"Publisher Summary This chapter discusses formal and natural languages. An algebra or algebraic system is a set S together with a set F of finitary operators defined on S. Because of the simplicity of definition, semigroups form a large and complex class of objects with little structure. The simplest of algebraic systems are those having only a single binary operator. A formal language can be specified in terms of an alphabet and a grammar. An alphabet is a finite set of symbols. A natural language develops and grows through daily use by many people. A grammar for a natural language is subsequently developed to codify rules for the language. Thus, the language comes first and the grammar follows it. However, for a formal language, the grammar is developed first and firmly fixed. Thus, the formal language grows out of its grammar rather than the grammar arising from the already developed language. The formal languages are called phrase structure languages. A grammar for a language can be either generative, starting with the concept sentence and generating particular sentences, or descriptive, starting with a particular string of words and describing exactly how it can be deemed a sentence.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Hutchinson G,,Modular lattices and abelian categories,Journal of Algebra,1971,19,2,156-184,,,,,1971,,0021-8693,https://www.sciencedirect.com/science/article/pii/0021869371901037;http://dx.doi.org/10.1016/0021-8693(71)90103-7,10.1016/0021-8693(71)90103-7,"A concept of “abelian lattice” is defined by adding a certain existence axiom to the modular lattice axioms. From an abelian lattice L, a small abelian category AL can be constructed. The construction is based upon identification of specified elements of L as formal graphs of morphisms of AL. The objects of AL correspond to the intervals [x, y] for x ⊂y in L. The subobject and quotient object lattices of [x, y] as an object of AL are isomorphic to the interval sublattice [x, y] of L. Two objects of AL are isomorphic if and only if the corresponding intervals are projective in L. The construction can be extended to a functor from the category of abelian lattices and lattice homomorphisms to the category of small abelian categories and exact functors. A method of constructing an abelian lattice from an abelian group is displayed. It is proved that a lattice can be embedded in an interval sublattice of an abelian lattice if and only if it can be embedded in the lattice of subgroups of some abelian group.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Thetford A,,The basic theory of multilayers,Optics & Laser Technology,1971,3,3,131-135,,,,,1971,,0030-3992,https://www.sciencedirect.com/science/article/pii/0030399271900648;http://dx.doi.org/10.1016/0030-3992(71)90064-8,10.1016/0030-3992(71)90064-8,"This article is the first of an occasional series comprising contributions suitable for the education of personnel in important aspects of optics. The series is aimed at technicians with HND qualifications or at recent university graduates who require an introduction to optics. Other important areas to be covered are: Autocollimation and alignment, Optical transfer function, Non-linear optics, Lens design, Photographic techniques, Polarising devices, Practical photometry, Interferometry, Spectroscopy. A multilayer consists in general, of a series of metal and dielectric films of various refractive indices and of various thicknesses, which are vacuum deposited one on top of the other. Anti-reflection coatings, band-pass interference filters, dichroic mirrors and polarizing beam splitters are among the most common multilayer devices in use today. They have both desirable and undesirable characteristics and it is the object of this article to explain the basic theory and hence enable the reader to gain at least a little insight into the reasons why multilayers behave in the way they do. In the space available there is no time to give formal proofs of equations, so for a detailed analysis one of the standard texts∗∗eg Thin film optical filters, Macleod, Hilger 1970. should be consulted. It is only intended to show how the reflectance and transmittance of a given system can be determined. The inverse problem of designing a system to have a given reflectance and transmittance is far more difficult and is inappropriate to consider here.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Mioduszewski J,Rudolf L",,A FORMAL CONNECTION BETWEEN PROJECTIVENESS FOR COMPACT AND NOT NECESSARILY COMPACT COMPLETELY REGULAR SPACES,,1967,,,256-258,,Academic Press,,General Topology and its Relations to Modern Analysis and Algebra,1967,9781483198507,,https://www.sciencedirect.com/science/article/pii/B9781483198507500679;http://dx.doi.org/10.1016/B978-1-4831-9850-7.50067-9,10.1016/B978-1-4831-9850-7.50067-9,"Publisher Summary This chapter presents a formal connection between the notions of projective spaces and projective resolutions for compact and noncompact completely regular spaces. In the category of compact, completely regular spaces projective spaces are assumed to be projective objects in regard to the class A of all mappings onto. The class of all projective spaces of this category is equal to each of the class of spaces: (1) all extremally disconnected spaces, (2) all spaces each mapping onto which is a retraction. In the category of completely regular spaces, to exclude the triviality (= discreteness), projective spaces are assumed to be projective objects in regard to the class A of all perfect mappings onto, that is, closed mappings onto, for which all inverse images of points are compact.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Reisig GH,,Information-system structure by communication-technology concepts: A cybernetic model approach,Information Processing & Management,1978,14,6,405-417,,,,,1978,,0306-4573,https://www.sciencedirect.com/science/article/pii/0306457378900055;http://dx.doi.org/10.1016/0306-4573(78)90005-5,10.1016/0306-4573(78)90005-5,"Information-systems are classified into two types, termed “Evidence-of Existence” and “Presentation” of information. The objective of the evidence-type system lies in the domain of documentation and retrieval of information. The structure of this system-type is developed, with application of cybernetic concepts, as an isomorphic model in analogy to the system-structure of communication technology. The latter postulates three criteria of structuring: (1) Source-Channel-Sink, with input-output characteristics, (2) Filter-type communication-channel, (3) Reversable code. These criteria are applied to the structuring of information-systems of the evidence-of-existence type. For the purpose of two-way communication the information-systems have to be represented by closed-loop models. The selective-retrieval requirements necessitate the system-channel to be a filter of information. These information-filters are implemented by keyword-phrases, being identical with the codewords. They yield a uniquely decodable code which is totally reversible to adequately serve both the documentation and the retrieval of documents. It is proven that hierarchic information-systems, applying categorization or subject-heading objects of information, do not meet the mandatory code-requirements. The inherent coding-deficiencies of hierarchic systems generate intolerable retrieval ambiguities. The same critique applies to the thesaurus concept. The development of a novel species of thesaurus is suggested, realizing a kind of Linnéan encyclopedia of general human knowledge, presenting all relevant interrelations of objects of knowledge. Such thesaurus would provide the much needed support for formulating efficient search queries. Other relevant features of communication technology, like the information-potential, should be isomorphically transformed into information-system models.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,Bijl A,Pipes A,"Chapter 11 - Designing with words and pictures in a logic modelling environment**This chapter is similar to a paper on Computer-Aided Design and Artificial Intelligence presented at the Reading ESCAD'85 Workshop on this topic, July 1985",,1986,,,128-145,,Butterworth-Heinemann,,Computer-Aided Architectural Design Futures,1986,9780408053006,,https://www.sciencedirect.com/science/article/pii/B9780408053006500196;http://dx.doi.org/10.1016/B978-0-408-05300-6.50019-6,10.1016/B978-0-408-05300-6.50019-6,"Publisher Summary This chapter discusses the new design approach in which one designs with words and pictures in a logic modeling environment. The approach is to decompose a problem into parts until individual parts are recognized as being amenable to known operations and results are reassembled into a solution. This process has a peripheral role in design when evaluating selected aspects of tentative design proposals, but the absence of well-defined and widely recognized criteria for design excludes it from the main stream of analytical developments. One can identify the key characteristics of design as: (1) design objects that subject to diversity of expression, different perceptions of things, lack of agreed abstract definitions; (2) design processes that are do solve problem in the orthodox form of problem statements that reveal solution paths, conflicting criteria for validating results, many solutions; and (3) in this approach there is no formal, complete and shared knowledge base; it relies on integration of overt and intuitive knowledge; necessarily manifest in idiosyncratic design practices.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Bottoni P,Minas M",,"Preface: Volume 72, Issue 3",Electronic Notes in Theoretical Computer Science,2003,72,3,176-177,,,,,2003,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105806206;http://dx.doi.org/10.1016/S1571-0661(05)80620-6,10.1016/S1571-0661(05)80620-6,"This volume contains the Proceedings of the Workshop on Graph Transformation and Visual Modelling Techniques (GT-VMT 2002). The Workshop was held in Barcelona, Spain, on October 11 and 12, 2002, as satellite event of the First International Conference on Graph Transformation (ICGT 2002). Background Diagrammatic notations have accompanied the development of technical and scientific disciplines in fields as diverse as mechanical engineering, quantum physics, category theory, and software engineering. In general, diagrammatic notations allow the construction of images associated with an interpretation based on considering as significant some well-defined spatial relations among graphical tokens. These tokens either derive from conventional notations employed in a user community or are elements specially designed to convey some meaning. The notations serve the purpose of defining the (types of) entities one is interested in and the types of relations among these entities. Hence, types must be distinguishable from one another and no ambiguity may arise as to their interpretation. Moreover, the set of spatial relations to be considered must be clearly defined, and the holding of any relation among any set of elements must be decidable. The evolution of diagrammatic notations usually follows a pattern that, from their usage as illustrations of sentences written in some formal or natural language, leads to the definition of \",modelling languages\,. These languages are endowed with rules for the construction of \,visual sentences\,,,,,,,,,,,,,,,,,,,
Journal Article,"Mens T,Schürr A,Taentzer G",,"Barcelona, Spain, October 7-8, 2002: Graph-Based Tools (GraBaTs 2002)",Electronic Notes in Theoretical Computer Science,2002,72,2,11-13,,,,,2002,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805237;http://dx.doi.org/10.1016/S1571-0661(05)80523-7,10.1016/S1571-0661(05)80523-7,"Graphs are well-known, well-understood, and frequently used means to depict networks of related items. They are successfully used as the underlying mathematical concept in various application domains. In all these domains tools are developed that store, retrieve, manipulate and display graphs as underlying data structures, despite of the fact that in most cases these graphs have a different name such as object diagrams, (meta) class diagrams, hyper documents, semantic webs etc. It is the purpose of this workshop to summarize the state of the art of graph-based tool development, bring together developers of graph-based tools in different application fields and to encourage new tool development cooperations. Motivation Graphs are an obvious means to describe structural aspects in various fields of computer science. They have been successfully used in application areas such as compiler compiler toolkits, constraint solving problems, generation of CASE tools, pattern recognition techniques, program analysis, software engineering, software evolution, software visualization and animation, and visual languages. In all these areas tools have been developed that use graphs as an important underlying data structure. Since graphs are a very general structure mechanism, it is a challenge to handle graphs in an effective way. Using graphs inside tools the following topics play an important role: efficient graph algorithms, empirical and experimental results on the scalability of graphs, reusable graph-manipulating software components, software architectures and frameworks for graph-based tools, standard data exchange formats for graphs, more general graph-based tool integration techniques, and meta CASE tools or generators for graph-based tools. The aim of the workshop on graph-based tools (GraBaTs) is to bring together developers of all kinds of graph-based tools in order to exchange their experiences, problems, and solutions concerning the efficient handling of graphs. The GraBaTs workshop is, therefore, of special relevance for the http://link.springer.de/link/service/series/0558/tocs/t2505.htm 1st Intl. Conference on Graph Transformation (ICGT) which hosts GraBaTs as a satellite event: In many cases the application of graph transformation technology requires the existence of reliable, user-friendly and efficiently working graph transformation tools. These tools in turn have to be built on top of basic services or frameworks for graphs, which are the main topic of our workshop. Today, several graph transformation tool implementations have emerged which do not share any basic graph services (e.g. for graph pattern matching or graph layout purposes) and which implement rather different graph concepts and graph transformation approaches. Some of these tools - as a kind of survey of the state of the art - were presented in a special session, which is part of the main conference as well as of this satellite workshop. The presented tools are AGG, DiaGen, Fujaba, GenGED, and UPGRADE. The GraBaTs workshop was held for 1 12 days. Its schedule contained in addition to the afore-mentioned session on graph transformation tools, an invited talk by Tiziana Margaria (University of Dortmund, Germany) on ETI, an electronic tool integration platform where graph-based tools will play an important role. Apart from four sessions with presentations of 15 accepted papers (out of 19 submissions) on various graph-based tools and tool-relevant topics, a successful discussion ''Towards Standard Exchange Formats for Graph and Graph Transformation'' took place. Workshop Issues The workshop aims at bringing together tool developers from different fields, dealing with graphs from different perspectives. In the following, we give an overview on the most important perspectives. Meta-modeling by Graphs For a long time the syntax and static semantics of most visual modeling or programming languages was only defined by means of characteristic examples and informal descriptions. To improve this situation the visual language community invented grammar-based formalisms for the definition of the syntax of their languages, such as constraint grammars, graph grammars, relational grammars, etc. Unfortunately it turned out that the grammar-based definition of visual languages is rather complicated compared with the meta-modeling approach developed in parallel. The Meta-modeling approach for the definition of visual languages uses a combination of class diagrams (ER-diagrams, etc.) and predicate logic expressions (Z, OCL, etc.) to define the syntax and static semantics of visual languages. It became popular with the standardization of the OO-modeling language UML and is used by various meta-modeling (meta-CASE) tools which are able to generate domain-specific CASE tools. The so-called MOF approach (Meta-Object Facility) is one attempt to come up with a meta-modeling standard. Despite of its limited expressiveness (compared with ER diagrams or UML class diagrams) MOF builds the basis for the formal definition of UML and other visual languages. All meta-modeling approaches used nowadays have one common property: they offer graph-like diagrams for the definition of the structure (syntax) of graph-like diagram languages. Therefore, meta-modeling is in fact the formal definition of graph languages by means of graphs which are instances of “meta” graph languages. As a consequence, meta-CASE tools are a special class of graph-based tools, which need at least basic services for storing, visualizing, and analyzing graphs. Graph Visualization Facilities for visualizing graphs are needed by all kinds of graph-based tools, independent of the fact whether they are e.g. used for meta-modeling or rule-based programming purposes. Furthermore, graph visualization techniques are the most important means for visualizing various aspects of softwarearchitectures, the dynamic behavior of running systems, their evolution history, and so forth. Software components developed for these purposes usually have to deal with huge graphs and need services for making these graphs persistent, for introducing abstractions based on hierarchical graph models, for computing reasonable graph layouts (efficiently), and for displaying graphs effectively using “fish-eye-techniques” and the like. And last but not least, graph visualization techniques are often employed for teaching purposes in computer science courses on “data structures and (graph) algorithms”. To summarize, almost all kinds of graph-based tools urgently need efficiently and effectively working graph visualization services, whereas graph visualization tools may profit from research activities on graph query and graph transformation engines for the computation of graph abstractions or views. We, therefore, hope that this workshop encourages researchers to start new cooperations, such as adapting graph visualization tools to the needs of graph manipulation tools or exploiting graph manipulation and transformation techniques to compute sensible abstractions of huge graphs. Graph Queries and Graph Algorithms Most, if not all, graph-based tools use to a certain degree software components (libraries, subsystems, etc.) for executing graph queries and/or various kinds of standard graph algorithms. For example, graph transformation tools rely on rather sophisticated means for computing graph matches (rule occurrences) and graph-based reverse engineering tools need rather powerful query engines for determining critical substructures of software architectures. On the other hand, quite a number of database management systems have already been developed using graphs (networks of related objects) as the underlying data model and offering query languages based on graph path expressions or even graph transformations. Vice versa, graph transformation languages like PROGRES are not only used for specifying and visualizing graph algorithms, but incorporate many elements of database query languages such as means for the construction of indexes, the materialization and incremental update of views, etc. Therefore, we like to encourage tool developers again to start cooperating across the boundaries of research areas. Graph Transformation Graph transformation means the rule-based manipulation of graphs. Several graph transformation approaches have emerged which differ w.r.t. to the underlying kind of graphs as well as in the way how rules are applied to graphs, i.e. graph transformation takes place. The kind of graphs used by these tools include labeled, directed graphs, hypergraphs, and graph structures. Their rules, the basic means to manipulate graphs, differ w.r.t. to the formal definition of their semantics, the way how occurrences (matches) are searched for, and how matching rules are applied eventually. In tools, graph transformation is applied to visual languages, specification, code generation, verification, restructuring, evolution and programming of software systems, etc. Developers of graph transformation tools may profit from other workshop participants concerning more efficient realizations of basic functionality, while developers of other graph-based tools might find the graph transformation paradigm attractive to implement certain graph manipulations. The workshop may also provide insights to apply these tools to other application domains. Common Exchange Formats for Graphs and Graph Transformation To support interoperability between various graph-based tools, several initiatives on the development of common exchange formats for graphs have been founded. These formats are all based on the extensible markup language XML developed to interchange documents of arbitrary types. Preceding events like three subgroup meetings of the EU Working Group APPLIGRAPH, a Workshop on Standard Exchange Formats, and a satellite workshop of the 8th Intl. Symposium on Graph Drawing (GD 2000)discussed various ideas which are currently converging to one format being GXL. During the GraBaTs workshop a further discussion round on this topic was organized focusing especially on graph layout and graph attributes. Another topic of interest for this discussion is an exchange format for graph transformation systems called GTXL, which is under development and which will be built on top of GXL. Workshop Organizers The Program Committee of the workshop consists of: Luciano Baresi (Italy)Giuseppe Di Battista (Italy)Ulrik Brandes (Germany)Scott Marshall (The Netherlands)Tom Mens (Belgium) (Co-chair)Andy Schürr (Germany) (Co-chair)Gabriele Taentzer (Germany) (Co-chair)Andreas Winter (Germany)Albert Zündorf (Germany) We are very grateful to Hartmut Ehrig for his help with the organization of the Workshop as satellite event of the 1st Int. Conference on Graph Transformation (ICGT) and to Mike Mislove, one of the Managing Editors of the ENTCS series. Thanks are also due to Fernando Orejas and his local organizers at UPC in Barcelona who supplied preprints of this volume for all workshop participants.",,"GraBaTs 2002, Graph-Based Tools (First International Conference on Graph Transformation)",,,,,,,,,,,,,,,,,,,,
Journal Article,Davies ER,,Optimal template masks for detecting signals with varying background level,Signal Processing,1992,29,2,183-189,,,,,1992,,0165-1684,https://www.sciencedirect.com/science/article/pii/016516849290020W;http://dx.doi.org/10.1016/0165-1684(92)90020-W,10.1016/0165-1684(92)90020-W,"This paper studies the problem of designing templates for detecting signals which will be subject to a varying background level B. An approach based on use of noise-whitening and spatial matched filters shows that templates must be adjusted towards zero mean: a formal mathematical analysis specifies precisely the required forms of the masks. It is shown that such templates are required in several applications - e.g. when objects in images are subject to conditions of variable lighting and shadow, or radar signals are subject to baseline drift. Zusammenfassung Studiert wird das problem des Musterentwurfs zur Detektion von Signalen, die einer Variation des Hintergrundniveaus B unterworfen sind. Ein Ansatz auf der Grundlage einer Rausch-Dekorrelation und räumlicher Optimalfilter zeigt daß die Muster in Richtung auf einen verschwindenden Mittelwert getrimmt werden müssen: eine formale mathematische Analyse legt die erforderliche Form der Masken der Masken exakt fest. Es wird gezeigt, daß solche Muster in verschiedenen Anwendungen nötig sind - z.B. dann wenn Bildobjekte wechselnden Licht- und Schatten-Bedingungen unterworfen sind oder Radarsignale eine Baseline-Drift erfahren. Résumé Cet article étudie le probléme de la conception de gabarits pour la détection de signaux qui seront sujets à un niveau variable B de bruit de fond. Une approche basée sur l'utilisation de filtres de blanchissement de bruit et de filtres adaptés spatialement montre que les gabarits doivent être ajustés à moyenne nulle: une analyse mathématique formelle spécifie précisément les formes requises pour les masques. Nous montrons que de tels gabarits sont requis dans plusieurs applications - p.e. lorsque des objets dans des images sont soumis à des conditions d'éclairage variable et d'ombre, ou lorsque des signaux de radars sont soumis à une dérive de la ligne de base.","Template matching, variable background, noise suppression, matched filtering, noise-whitening, optimal detection",,,,,,,,,,,,,,,,,,,,,
Journal Article,"Comon P,Mourrain B",,Decomposition of quantics in sums of powers of linear forms,Signal Processing,1996,53,2,93-107,,,,,1996,,0165-1684,https://www.sciencedirect.com/science/article/pii/0165168496000795;http://dx.doi.org/10.1016/0165-1684(96)00079-5,10.1016/0165-1684(96)00079-5,"Symmetric tensors of order larger than two arise more and more often in signal and image processing and automatic control, because of the recent complementary use of high-order statistics (HOS). However, very few special purpose tools are at our disposal for manipulating such objects in engineering problems. In this paper, the decomposition of a symmetric tensor into a sum of simpler ones is focused on, and links with the theory of homogeneous polynomials in several variables (i.e. quantics) are pointed out. This decomposition may be seen as a formal extension of the eigenvalue decomposition (EVD), known for symmetric matrices. By reviewing the state of the art, quite surprising statements are emphasized, that explain why the problem is much more complicated in the tensor case than in the matrix case. Very few theoretical results can be applied in practice, even for cubics or quartics, because proofs are not constructive. Nevertheless in the binary case, we have more freedom to devise numerical algorithms. Zusammenfassung Symmetrische Tensoren einer Ordnung von mehr als zwei kommen in der Signal- und Bildverarbeitung immer öfter vor, weil man in neuerer Zeit verstärkt Statistiken höherer Ordnung verwendet. Es sind jedoch sehr wenige spezielle Werkzeuge zur Handhabung solcher Objekte in technischen Problemen verfügbar. In diesem Beitrag steht die Zerlegung eines symmetrischen Tensors in eine Summe einfacherer Tensoren im Mittelpunkt, und es werden Verbindungen zur Theorie homogener Polynome in mehreren Variablen (‘Quantics’) aufgezeigt. Diese Zerlegung kann man als formale Erweiterung der Eigenwertzerlegung betrachten, wie sie für symmetrische Matrizen bekannt ist. In einem Überblick über den Stand der Technik werden recht überraschende Feststellungen betont; sie erklären, warum das Problem im Tensorfall viel komplizierter ist als im Matrixfall. Sehr wenige theoretische Resultate sind praktisch anwendbar, selbst für drei- oder vierdimensionale Fälle, da die Beweisführung nicht konstruktiv ist. Nichtsdestoweniger haben wir im binären Fall mehr Freiheiten bei der Auslegung numerischer Algorithmen. Résumé Les tenseurs symétriques d'ordre supérieur à deux apparaissent de plus en plus en traitement de signaux et d'images ainsi qu'en automatique, à cause de l'usage complémentaire récent des statistiques d'ordre élevé Malgré cela, tres peu d'outils specialisés sont diponibles. Dans cet article, la décompostion d'un tenseur symétrique en une somme de tenseurs plus simples est presentée, et des liens avec la théorie des polynômes homogènes de plusieurs variables (quartiques) sont mis en évidence. Cette décomposition peut être vue comme une extension formelle de la décomposition en vecteurs propres connue pour les matrices symétriques. Notre état de l'art met en avant des points surprenants expliquant pourquoi ce problème est plus complexe dans le cas des tenseurs que dans le cas des matrices. Tres peu de resultats théoriques peuvent etre appliqués, même pour les cubiques et les quatriques, parce que les preuves ne sont pas constructives. Malgré tout, dans le cas binaire, nous disposons de plus de liberté pour concevoir des algorithmes numériques.","Tensors, Polynomials, Diagonalization, EVD, High-order statistics, Cumulants",Higher Order Statistics,,,,,,,,,,,,,,,,,,,,
Journal Article,Bos J,,Applying automated deduction to natural language understanding,Journal of Applied Logic,2009,7,1,100-112,,,,,2009,,1570-8683,https://www.sciencedirect.com/science/article/pii/S1570868307000651;http://dx.doi.org/10.1016/j.jal.2007.07.008,10.1016/j.jal.2007.07.008,"Very few natural language understanding applications employ methods from automated deduction. This is mainly because (i) a high level of interdisciplinary knowledge is required, (ii) there is a huge gap between formal semantic theory and practical implementation, and (iii) statistical rather than symbolic approaches dominate the current trends in natural language processing. Moreover, abduction rather than deduction is generally viewed as a promising way to apply reasoning in natural language understanding. We describe three applications where we show how first-order theorem proving and finite model construction can efficiently be employed in language understanding. The first is a text understanding system building semantic representations of texts, developed in the late 1990s. Theorem provers are here used to signal inconsistent interpretations and to check whether new contributions to the discourse are informative or not. This application shows that it is feasible to use general-purpose theorem provers for first-order logic, and that it pays off to use a battery of different inference engines as in practice they complement each other in terms of performance. The second application is a spoken-dialogue interface to a mobile robot and an automated home. We use the first-order theorem prover spass for checking inconsistencies and newness of information, but the inference tasks are complemented with the finite model builder mace used in parallel to the prover. The model builder is used to check for satisfiability of the input; in addition, the produced finite and minimal models are used to determine the actions that the robot or automated house has to execute. When the semantic representation of the dialogue as well as the number of objects in the context are kept fairly small, response times are acceptable to human users. The third demonstration of successful use of first-order inference engines comes from the task of recognising entailment between two (short) texts. We run a robust parser producing semantic representations for both texts, and use the theorem prover vampire to check whether one text entails the other. For many examples it is hard to compute the appropriate background knowledge in order to produce a proof, and the model builders mace and paradox are used to estimate the likelihood of an entailment.","Automated reasoning, Natural language understanding, First-order logic, Theorem proving, Model building",Special Issue: Empirically Successful Computerized Reasoning,,,,,,,,,,,,,,,,,,,,
Journal Article,"Marchand P,Brisebois A,Bédard Y,Edwards G",,Implementation and evaluation of a hypercube-based method for spatiotemporal exploration and analysis,ISPRS Journal of Photogrammetry and Remote Sensing,2004,59,1,6-20,,,,,2004,,0924-2716,https://www.sciencedirect.com/science/article/pii/S0924271603000753;http://dx.doi.org/10.1016/j.isprsjprs.2003.12.002,10.1016/j.isprsjprs.2003.12.002,"This paper presents the results obtained with a new type of spatiotemporal topological dimension implemented within a hypercube, i.e., within a multidimensional database (MDDB) structure formed by the conjunction of several thematic, spatial and temporal dimensions. Our goal is to support efficient SpatioTemporal Exploration and Analysis (STEA) in the context of Automatic Position Reporting System (APRS), the worldwide amateur radio system for position report transmission. Mobile APRS stations are equipped with GPS navigation systems to provide real-time positioning reports. Previous research about the multidimensional approach has proved good potential for spatiotemporal exploration and analysis despite a lack of explicit topological operators (spatial, temporal and spatiotemporal). Our project implemented such operators through a hierarchy of operators that are applied to pairs of instances of objects. At the top of the hierarchy, users can use simple operators such as “same place”, “same time” or “same time, same place”. As they drill down into the hierarchy, more detailed topological operators are made available such as “adjacent immediately after”, “touch during” or more detailed operators. This hierarchy is structured according to four levels of granularity based on cognitive models, generalized relationships and formal models of topological relationships. In this paper, we also describe the generic approach which allows efficient STEA within the multidimensional approach. Finally, we demonstrate that such an implementation offers query run times which permit to maintain a “train-of-thought” during exploration and analysis operations as they are compatible with Newell's cognitive band (query runtime<10 s) (Newell, A., 1990. Unified theories of cognition. Harvard University Press, Cambridge MA, 549 p.).","spatiotemporal topological operator dimension, spatial dimension, spatial measure, multidimensional approach, On-Line Analytical Processing (OLAP), automatic position reporting system, spatiotemporal exploration, cognition",Advanced Techniques for Analysis of Geo-spatial Data,,,,,,,,,,,,,,,,,,,,
Book Chapter,"Krantz DH,Suppes P,Luce RD,Tversky A","Krantz DH,Suppes P,Luce RD,Tversky A",Chapter 1 - Introduction,,1971,,,1-37,,Academic Press,,Additive and Polynomial Representations,1971,9780124254015,,https://www.sciencedirect.com/science/article/pii/B978012425401550009X;http://dx.doi.org/10.1016/B978-0-12-425401-5.50009-X,10.1016/B978-0-12-425401-5.50009-X,"Publisher Summary When measuring some attribute of a class of objects or events, numbers are associated with the objects in such a way that the properties of the attribute are faithfully represented as numerical properties. This chapter highlights various systems of formal properties of attributes that lead to measurement in this sense. Some commentators on physical measurement have claimed that an attribute should exhibit a more or less unique set of formal properties for it to have a fundamental measure—one that does not require the prior measurement of other quantities. For example, length can be measured fundamentally, whereas density = mass/volume depends on the prior measurement of mass and volume. The intuitive distinction between fundamental and other sorts of measurement is an elusive, but whatever it is, it is wrong to think that there is only one fundamental system of properties adequate to lead to numerical measurement.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Wos L,,The resonance strategy,Computers & Mathematics with Applications,1995,29,2,133-178,,,,,1995,,0898-1221,https://www.sciencedirect.com/science/article/pii/089812219400220F;http://dx.doi.org/10.1016/0898-1221(94)00220-F,10.1016/0898-1221(94)00220-F,"Especially in mathematics and in logic, lemmas (basic truths) play a key role for proving theorems. In ring theory, for example, a useful lemma asserts that, for all elements x, the product in either order of 0 and x is 0; in two-valued sentential (or propositional) calculus, a useful lemma asserts that, for all x, x implies x. Even in algorithm writing and in circuit design, lemmas play a key role: minus(minus(x)) = x in the former and NOT(AND(x,y)) = OR(NOT(x),NOT(y)) in the latter. Whether the object is to prove a theorem, write an algorithm, or design a circuit, and whether the assignment is given to a person or (preferably) to an automated reasoning program, the judicious use of lemmas often spells the difference between success and failure. In this article, we focus on what might be thought of as a generalization of the concept of lemma, namely, the concept of resonator, and on a strategy, the resonance strategy, that keys on resonators. For example, where in Boolean groups—those in which the square of every x is the identity element e—the lemmas yzyz = e and yyzz = e are such that neither generalizes the other, the resonator (formula schema) ∗ ∗ ∗∗ = e, by using each occurrence of “star” to assert the presence of some variable, generalizes and captures (in a manner that is discussed in this article) both lemmas. Note that the cited resonator, if viewed as a lemma with star replaced by some chosen variable, captures neither cited lemma as an instance. Lemmas of a theory are provably “true” in the theory and, therefore, can be used to complete an assignment. In contrast, resonators, which capture collections of equations or collections of formulas that may or may not include truths, are used by the resonance strategy to direct the search for the information needed for assignment completion. In addition to discussing how one finds useful resonators, we detail various successes, in some of which the resonance strategy played a key role in obtaining a far better proof and in some of which the resonance strategy proved indispensable. The successes are taken from group theory, Robbins algebra, and various logic calculi.","Automated reasoning, Group theory, Logic calculi, Open questions, OTTER, Resonance strategy, Robbins algebra",,,,,,,,,,,,,,,,,,,,,
Journal Article,"van den Brand M,Verma R",,"Preface: Volume 59, Issue 4",Electronic Notes in Theoretical Computer Science,2001,59,4,425-426,,,,,2001,,1571-0661,https://www.sciencedirect.com/science/article/pii/S1571066105805596;http://dx.doi.org/10.1016/S1571-0661(05)80559-6,10.1016/S1571-0661(05)80559-6,"Foreword This volume contains the Proceedings of the Second International Workshop on Rule-Based Programming (RULE2001). The Workshop was held in Firenze, Italy on September 4, 2001, as satellite event to PLI2001. This is the second edition of the International Workshop on Rule-Based Programming (RULE'2001). We aim with this workshop at a fruitful cross fertilization of the theoretical foundations of rule-based programming with practical applications and implementation of rule-based systems. We are very pleased with the broad range of papers: quite a number of very theoretical ones upto papers describing a system and a paper describing a comparison between a number of rule-based systems to tackle a bio-medical problem. Rule-based programming began with AI rule-based systems in the seventies. This paradigm is inherent in Prolog and has been used in program-manipulation systems like Refine. Indeed, the rewriting concept appears throughout computer science, from its theoretical foundations to very practical implementations. Extreme examples include the mail system in Unix which uses rules in order to rewrite mail addresses to canonical forms and the transition rules describing the behaviour of tree automata. Rewriting is used in semantics in order to describe the meaning of programming languages, as well as in program transformations like the re-engineering of Cobol programs. It is used to compute, implicitly or explicitly, as in Mathematica or OBJ, but also to perform deduction when using inference rules to describe a logic, theorem prover or constraint solver. Last, but not least, this approach is central to systems that raise the notion of rule to an explicit first class object, like expert systems, programming languages based on equational logic, algebraic specifications (e.g. OBJ), functional programming (e.g. ML) and transition systems (e.g. Murphi). Rule-based programming is currently experiencing a renewed period of growth with the emergence of new concepts and systems that allow one to better understand and better use it. From the theoretical side, after the in-depth study of rewriting concepts during the eighties, the nineties saw the emergence of the general concepts of rewriting logic and of the rewriting calculus. On the practical side, new languages, like ASM, ASF+SDF, Claire, ELAN and Maude, systems like LRR, and also commercial products, like Ilog Rules, have shown that the concept of rule could be of major interest as a programming tool. In particular, because it is now of practical use, fundamental questions arise, like the theoretical study of the algorithmic complexity of programs written in such languages, as well as their optimisation. Of course, semantics of such languages, compilation techniques and methodological studies of their use should also be explored. Rule based programming is closely related to both functional programming (when the term rewrite system is confluent and terminating) as well as classical logic programming (when the rewrite system is used for nondeterministic search). Accordingly, the purpose of this workshop is to bring together researchers from these various domains to foster fertilisation between theory and practice, as well as to favour the growth of this programming paradigm. Mark van den Brand(CWI Amsterdam)Iliano Cervesato(ITT Industries)Nachum Dershowitz(Tel-Aviv University)Bernd Fischer(RIACS/NASA Ames, Moffett Field)Claude Kirchner(LORIA Nancy)Jean-Yves Marion(LORIA Nancy)Narciso Marti-Oliet(Universidad Complutense de Madrid)Rakesh M. Verma(University of Houston)Eelco Visser(Utrecht University) This volume will be published as volume 44-2 in the series Electronic Notes in Theoretical Computer Science (ENTCS). This series is published electronically through the facilities of Elsevier Science B.V. and its auspices. The volumes in the ENTCS series can be accessed at the URL We would like to thank the program committee members for their help in evaluating the papers and making a scientifically interesting selection. Furthermore, we would like to thank the \bf PLI organizing committee for taking care of the local organization of our workshop. We thank the ACM organization for sponsoring this workshop. We thank Elsevier for publishing these proceedings in the Electronic Notes in Theoretical Computer Science (ENTCS). Finally, we thank Professor Michael Mislove for providing and adapting the style files for ENTCS. November, 2001 Mark van den Brand and Rakesh M. Verma",,"RULE 2001, Second International Workshop on Rule-Based Programming (Satellite Event of PLI 2001)",,,,,,,,,,,,,,,,,,,,
Journal Article,"Lee MJ,Whang KY,Han WS,Song IY",,Adaptive row major order: a new space filling curve for efficient spatial join processing in the transform space,Journal of Systems and Software,2005,78,3,257-269,,,,,2005,,0164-1212,https://www.sciencedirect.com/science/article/pii/S016412120400202X;http://dx.doi.org/10.1016/j.jss.2004.10.012,10.1016/j.jss.2004.10.012,"A transform-space index indexes spatial objects represented as points in the transform space. An advantage of a transform-space index is that optimization of spatial join algorithms using these indexes can be more formal. The authors earlier proposed the Transform-Based Spatial Join algorithm that joins two transform-space indexes. It renders global optimization easy with little overhead by utilizing the characteristics of the transform space. In particular, it allows us to globally determine the order of accessing disk pages, which makes a significant impact on the performance of joins. For this purpose, we use various space filling curves. In this paper, we propose a new space filling curve called the adaptive row major order (ARM order). The ARM order adaptively controls the order of accessing pages and significantly reduces the one-pass buffer size (the minimum buffer size required for guaranteeing one disk access per page) and the number of disk accesses for a given buffer size. Through analysis and experiments, we verify excellence of the ARM order when used with the Transform-Based Spatial Join. The Transform-Based Spatial Join with the ARM order always outperforms those with other conventional space filling curves in terms of both measures used: the one-pass buffer size and the number of disk accesses. Specifically, it reduces the one-pass buffer size by up to 25.9 times and the number of disk accesses by up to 2.11 times. We conclude that we achieve these results mainly due to global optimization of the order of accessing disk pages using an adaptive space filling curve.","Spatial join, Corner transformation, Databases",,,,,,,,,,,,,,,,,,,,,
Journal Article,Grodzki Z,,The theory of shift-registers,Information and Control,1972,21,3,196-205,,,,,1972,,0019-9958,https://www.sciencedirect.com/science/article/pii/S0019995872800020;http://dx.doi.org/10.1016/S0019-9958(72)80002-0,10.1016/S0019-9958(72)80002-0,"This paper is a continuation of the earlier Z. Grodzki's (1970a) and (1970b) papers and is related to the k-machines. A k-machine is a formal notion to which corresponds a physical object called shift-register. In the above-mentioned papers the fundamental properties of computations and of the sets of all computations of the k-machines were given. Let Ck(Ck∞) for k ⩾ 1 denote the set of all computations (infinite ones) of all k-machines defined in some nonempty set M (finite or infinite). The principal properties of the sets Ck, Ck∞ and of the complement of the set ∪i=1∞ Ci∞ are studied in this paper. Let Dk∞ for k ⩾ 1 denote the set of each set of computations of all k-machines of the class Ak defined in some finite nonempty set M and such that a transition function of every k-machine of the class Ak is total. It has been proved that the set ∪i=1∞ Di∞ is closed under union, intersection but is not closed under complement.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,Solomatin AM,,A game theoretic approach — evasion problem for a linear system with integral constraints imposed on the player control,Journal of Applied Mathematics and Mechanics,1984,48,4,401-405,,,,,1984,,0021-8928,https://www.sciencedirect.com/science/article/pii/0021892884900054;http://dx.doi.org/10.1016/0021-8928(84)90005-4,10.1016/0021-8928(84)90005-4,"A differential approach-evasion game with integral constraints imposed on the player controls is considered. A positional strategy is proposed, supplying a solution to the approach problem, and conditions are given under which the set of programmed absorption has the property of stability. Differential games of this type were first studied in /1, 2/ where the pursuit-evasion problem was considered for single type systems, and auxiliary constructions were proposed for use as a basis in constructing a positional strategy in the form of the strategies of external aiming. Stable bridges of programmed absorption /3/ for linear, generally speaking, non-single type objects, were considered, and the construction of strategies extremal with respect to these bridges were demonstrated. A solution of the problem of approach in the class of positional procedures of control with a guide was proposed in /4/. It should be noted that the question of whether it is possible to construct resolving positional strategies in differential games with integral constraints, remains open. The present paper is related to the investigations described in /1–8/.",,,,,,,,,,,,,,,,,,,,,,
Book Chapter,,Rieger L,Chapter 8 - ALGEBRAIC LAWS OF SEMANTICS OF FIRST-ORDER PREDICATE LOGIC,,1967,,,181-199,,Academic Press,,Algebraic Methods of Mathematical Logic,1967,9781483231235,,https://www.sciencedirect.com/science/article/pii/B9781483231235500124;http://dx.doi.org/10.1016/B978-1-4832-3123-5.50012-4,10.1016/B978-1-4832-3123-5.50012-4,"Publisher Summary This chapter discusses the laws of the relation of consequence between sentential expressions with respect to the semantic aspect of the symbolized languages of mathematical theories, that is, the laws concerning the connection of mathematical theories with the underlying subject matter. The chapter discusses whether the consequential formalism of predicate logic or other equivalent formalismsyields all the logically self-evident sentential expressions, that is, all expressions true relative to any possible meaning ascribed to them and whether given a formally logically consistent system of formally conceived sentences, it is always possible to ascribe some meaning to these sentences, a meaning such that the sentences become statements of true properties of some mathematical objects.",,,,,,,,,,,,,,,,,,,,,,
Journal Article,"Goldfarb L,Abela J,Bhavsar VC,Kamat VN",,Can a vector space based learning model discover inductive class generalization in a symbolic environment?,Pattern Recognition Letters,1995,16,7,719-726,,,,,1995,,0167-8655,https://www.sciencedirect.com/science/article/pii/016786559500024B;http://dx.doi.org/10.1016/0167-8655(95)00024-B,10.1016/0167-8655(95)00024-B,"We outline a general framework for inductive learning based on the recently proposed evolving transformation system model. Mathematical foundations of this framework include two basic components: a set of operations (on objects) and the corresponding geometry defined by means of these operations. According to the framework, to perform inductive learning in a symbolic environment, the set of operations (class features) may need to be dynamically updated, and this requires that the geometric component allows for an evolving topology. In symbolic systems, as defined in this paper, the geometric component allows for a dynamic change in topology, whereas finite-dimensional numeric systems (vector spaces) can essentially have only one natural topology. This fact should form the basis of a complete formal proof that, in a symbolic setting, the vector space based models, e. g. artificial neural networks, cannot capture inductive generalization. Since the presented argument indicates that the symbolic learning process is more powerful than the numeric process, it appears that only the former should be properly called an inductive learning process.","Inductive learning, Inductive generalization, Vector space learning models, Artificial neural networks, Symbolic models, Evolving transformation system, Learning topologies",,,,,,,,,,,,,,,,,,,,,
Book Chapter,Tsang E,Tsang E,Chapter 1 - Introduction,,1993,,,1-30,,Academic Press,,Foundations of Constraint Satisfaction,1993,9780127016108,,https://www.sciencedirect.com/science/article/pii/B9780127016108500094;http://dx.doi.org/10.1016/B978-0-12-701610-8.50009-4,10.1016/B978-0-12-701610-8.50009-4,"Publisher Summary The constraint satisfaction problems (CSPs) appear in many areas, for instance, vision, resource allocation in scheduling, and temporal reasoning. The CSPs are worth studying in isolation because it is a general problem that has unique features that can be exploited to arrive at solutions. This chapter presents the definition of the standard CSP and the important concepts around it. To avoid ambiguity, concepts are defined both verbally and in first order predicate calculus (FOPC). A CSP is a problem composed of a finite set of variables, each of which is associated with a finite domain, and a set of constraints that restricts the values the variables can simultaneously take. The task is to assign a value to each variable satisfying all the constraints. The domain of a variable is a set of all possible values that can be assigned to the variable. If x is a variable, then Dx is used to denote the domain of it. When the domain contains numbers only, the variables are called numerical variables. The domain of a numerical variable may be further restricted to integers, rational numbers, or real numbers. When the domain contains boolean values only, the variables are called Boolean variables. When the domain contains an enumerated type of objects, the variables are called symbolic variables. For example, a variable that represents a day of the week is a symbolic variable of which the domain is the finite set (Sunday, Monday, Tuesday, Wednesday, Thursday, Friday, Saturday).",,,,,,,,,,,,,,,,,,,,,,